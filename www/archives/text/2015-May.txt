From metamarc at metamarket.biz  Fri May  1 22:57:55 2015
From: metamarc at metamarket.biz (Marc D. Wood)
Date: Fri, 1 May 2015 18:57:55 -0400
Subject: [Bitcoin-development] [ANN] METAmarket - Trustless Federated
	Marketplaces
Message-ID: <7cfbfe793dd4be50dd97cfc1fe937880.squirrel@server151.web-hosting.com>

METAmarket: Trustless Federated Marketplaces
>>> http://metamarket.biz <<<

* * *
Introduction

METAmarket is an open source protocol and proof-of-concept reference
client specifying a trustless federated marketplace which uses Bitcoin as
a universal currency and Bitmessage as a P2P communication network.
Time-locked refund transactions ensure that incentives are aligned toward
completing the trade without the need for trusted third parties. Systemic
vulnerabilities such as transaction malleability are mitigated through the
use of a federated reputation model. This document is a non-technical
overview of how the METAmarket client and protocol work. For more
technical details, see the protocol specification.

Motivation

Overly centralized marketplaces and payment services extract high fees,
impose and abuse excessive control and remove any hope of privacy from
users. As more commerce moves online, many consumers may find their
lifetime history of purchases (including books, personal items and
location details) for sale to advertisers, employers, curious neighbors,
stalkers, political opponents and government agencies. An ideal system
would be one of secure private transactions directly between buyer and
seller without middle men collecting data or adding fees. Such systems are
now feasible by combining recently developed technologies for anonymous
decentralized payment and messaging systems.

Client

To use the marketplaces, a client application which implements the
METAmarket protocol is required. The client is used to post, browse and
execute trades. It also requires a Bitcoin Core wallet to handle payments
and refunds. A working client is available at:

http://github.com/metamarcdw/metamarket




From melvincarvalho at gmail.com  Sat May  2 02:01:35 2015
From: melvincarvalho at gmail.com (Melvin Carvalho)
Date: Sat, 2 May 2015 04:01:35 +0200
Subject: [Bitcoin-development] [ANN] METAmarket - Trustless Federated
	Marketplaces
In-Reply-To: <7cfbfe793dd4be50dd97cfc1fe937880.squirrel@server151.web-hosting.com>
References: <7cfbfe793dd4be50dd97cfc1fe937880.squirrel@server151.web-hosting.com>
Message-ID: <CAKaEYhKxw+aUO_j6=nCAtNUw=5gSQ6TSGTa8YP1ATFHn-EW5_A@mail.gmail.com>

On 2 May 2015 at 00:57, Marc D. Wood <metamarc at metamarket.biz> wrote:

> METAmarket: Trustless Federated Marketplaces
> >>> http://metamarket.biz <<<
>
> * * *
> Introduction
>
> METAmarket is an open source protocol and proof-of-concept reference
> client specifying a trustless federated marketplace which uses Bitcoin as
> a universal currency and Bitmessage as a P2P communication network.
> Time-locked refund transactions ensure that incentives are aligned toward
> completing the trade without the need for trusted third parties. Systemic
> vulnerabilities such as transaction malleability are mitigated through the
> use of a federated reputation model. This document is a non-technical
> overview of how the METAmarket client and protocol work. For more
> technical details, see the protocol specification.
>
> Motivation
>
> Overly centralized marketplaces and payment services extract high fees,
> impose and abuse excessive control and remove any hope of privacy from
> users. As more commerce moves online, many consumers may find their
> lifetime history of purchases (including books, personal items and
> location details) for sale to advertisers, employers, curious neighbors,
> stalkers, political opponents and government agencies. An ideal system
> would be one of secure private transactions directly between buyer and
> seller without middle men collecting data or adding fees. Such systems are
> now feasible by combining recently developed technologies for anonymous
> decentralized payment and messaging systems.
>
> Client
>
> To use the marketplaces, a client application which implements the
> METAmarket protocol is required. The client is used to post, browse and
> execute trades. It also requires a Bitcoin Core wallet to handle payments
> and refunds. A working client is available at:
>
> http://github.com/metamarcdw/metamarket
>

Is there any relation between this and the work satoshi was putting into
the core before he left?

https://github.com/bitcoin/bitcoin/commit/5253d1ab77fab1995ede03fb934edd67f1359ba8

>
>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150502/aed666ab/attachment.html>

From metamarc at metamarket.biz  Sat May  2 15:45:35 2015
From: metamarc at metamarket.biz (Marc D. Wood)
Date: Sat, 2 May 2015 11:45:35 -0400
Subject: [Bitcoin-development] [ANN] METAmarket - Trustless Federated
 Marketplaces
In-Reply-To: <CAKaEYhKxw+aUO_j6=nCAtNUw=5gSQ6TSGTa8YP1ATFHn-EW5_A@mail.gmail.com>
References: <7cfbfe793dd4be50dd97cfc1fe937880.squirrel@server151.web-hosting.com>
	<CAKaEYhKxw+aUO_j6=nCAtNUw=5gSQ6TSGTa8YP1ATFHn-EW5_A@mail.gmail.com>
Message-ID: <af2e7d55c4cf9f44ad2fc0c5cf9d1d7f.squirrel@server151.web-hosting.com>

On Fri, May 1, 2015 10:01 pm, Melvin Carvalho wrote:
>
> Is there any relation between this and the work satoshi was putting into
> the core before he left?
>
> https://github.com/bitcoin/bitcoin/commit/5253d1ab77fab1995ede03fb934edd6
> 7f1359ba8
>
>

Melvin,

This is certainly a similar concept. It is a software for creating markets
with variable levels of privacy and censorship resistance. It is built
directly on top of Bitcoin Core and Bitmessage.

I believe this project to be in the spirit of Satoshi's original plan for
a bitcoin marketplace but it is not the same project, and I certainly am
not Satoshi. :)

Marc D. Wood




From bitcoin-list at bluematt.me  Mon May  4 02:15:47 2015
From: bitcoin-list at bluematt.me (Matt Corallo)
Date: Mon, 04 May 2015 02:15:47 +0000
Subject: [Bitcoin-development] Relative CHECKLOCKTIMEVERIFY (was CLTV
 proposal)
In-Reply-To: <20150421075912.GA25282@savin.petertodd.org>
References: <20141001130826.GM28710@savin.petertodd.org>
	<55075795.20904@bluematt.me>
	<20150421075912.GA25282@savin.petertodd.org>
Message-ID: <5546D653.4070404@bluematt.me>



On 04/21/15 07:59, Peter Todd wrote:
> On Mon, Mar 16, 2015 at 10:22:13PM +0000, Matt Corallo wrote:
>> In building some CLTV-based contracts, it is often also useful to have a
>> method of requiring, instead of locktime-is-at-least-N,
>> locktime-is-at-least-N-plus-the-height-of-my-input. ie you could imagine
>> an OP_RELATIVECHECKLOCKTIMEVERIFY that reads (does not pop) the top
>> stack element, adds the height of the output being spent and then has
>> identical semantics to CLTV.
> 
> Depending on what you mean by "identical" this isn't actually reorg
> safe. For instance consider this implementation:
> 
>     nLockTime = stack[-1] + prevout.nHeight
>     if (nLockTime > txTo.nLockTime):
>         return False
> 
> Used with this scriptPubKey:
> 
>     10 RCLTV DROP <pubkey> CHECKSIG
> 
> If I create that output in tx1 which is mined at height 42 I can spend
> it in a tx2 at height > 42+10 by setting tx2's nLockTime to >42+10, for
> instance 53. However if a reorg happens and tx1 ends up at height 43
> after the reorg I'm stuck - tx2's nLockTime is set at 42.
> 
> Thus RCTLV is only reorg safe if the height is compared against the
> actual block height of the block containing the spending transaction,
> not the spending transaction's nLockTime.

Yes, as discussed on IRC months ago when the first email was sent, the
assumption is that you would require N be at least 100. That way you are
reorg safe up to the same limit as coinbase transactions, which are also
only reorg safe in the case of no 100-block reorgs. Its not ideal in
some contracts, but keeping the no-second-nLockTime-equivalent property
is worth it IMO, and its still incredibly useful in many contracts.

>> A slightly different API (and different name) was described by maaku at
>> http://www.reddit.com/r/Bitcoin/comments/2z2l91/time_to_lobby_bitcoins_core_devs_sf_bitcoin_devs/cpgc154
>> which does a better job of saving softfork-available opcode space.
>>
>> There are two major drawbacks to adding such an operation, however.
>>
>> 1) More transaction information is exposed inside the script (prior to
>> CLTV we only had the sigchecking operation exposed, with a CLTV and
>> RCLTV/OP_CHECK_MATURITY_VERIFY we expose two more functions).
>>
>> 2) Bitcoin Core's mempool invariant of "all transactions in the mempool
>> could be thrown into one overside block and aside from block size, it
>> would be valid" becomes harder to enforce. Currently, during reorgs,
>> coinbase spends need checked (specifically, anything spending THE
>> coinbase 100 blocks ago needs checked) and locktime transactions need
>> checked. With such a new operation, any script which used this new
>> opcode during its execution would need to be re-evaluated during reorgs.
> 
> Yup, definitely kinda ugly.
> 
> If the above style of RCTLV was used, one possibility might be to make
> the relative locktime difference be required to be at least 100 blocks,
> same as the coinbase maturity, and just accept that it's probably not
> going to cause any problems, but could in an extremely big reorg. But
> re-orgs that big might be big enough that we're screwed anyway...
> 
> With the 100 block rule, during a sufficiently large reorg that
> coinbases become unavailble, simply disconnect entire blocks - all
> txouts created by them.
> 
>> I think both of these requirements are reasonable and not particularly
>> cumbersome, and the value of such an operation is quite nice for some
>> protocols (including settings setting up a contest interval in a
>> sidechain data validation operation).
> 
> So to be clear, right now the minimal interface to script execution is
> simply:
> 
>     int bitcoinconsensus_verify_script(const unsigned char *scriptPubKey, unsigned int scriptPubKeyLen,
>                                        const unsigned char *txTo        , unsigned int txToLen,
>                                        unsigned int nIn, unsigned int flags, bitcoinconsensus_error* err);
> 
> Where scriptPubKey is derived from the unspent coin in the UTXO set and
> txTo is the transaction containing the script that is being executed.
> The UTXO set itself currently contains CCoins entries, one for each
> transaction with unspent outputs, which basically contain:
> 
>     nVersion - tx nVersion
>     nHeight  - Height of the block the transaction is contained in.
>     vout     - Unspent CTxOut's of the transaction.
> 
> The block nTime isn't directly available through the UTXO set, although
> it can be found in the block headers. This does require nodes to have
> the block headers, but at 4MB/year growth it's reasonable to assume the
> UTXO set will grow faster.
> 
> Script execution does not have direct access to the current block
> height/block time, however it does have indirect access via nLockTime.
> 
> Thus we have a few possibilities:
> 
> 1) RCLTV against nLockTime
> 
> Needs a minimum age > COINBASE_MATURITY to be safe.
> 
> 
> 2) RCLTV against current block height/time
> 
> Completely reorg safe.
> 
> 
> 3) GET_TXOUT_HEIGHT/TIME <diff> ADD CLTV
> 
> To be reorg safe GET_TXOUT_HEIGHT/TIME must fail if minimum age <
> COINBASE_MATURITY. This can be implemented by comparing against
> nLockTime.
> 
> 
> All three possibilities require us to make information about the
> prevout's height/time available to VerifyScript(). The only question is
> if we want VerifyScript() to also take the current block height/time - I
> see no reason why it can't. As for the mempool, keeping track of what
> transactions made use of these opcodes so they can be reevaluated if
> their prevouts are re-organised seems fine to me.
> 
> 
> Absolute CLTV
> =============
> 
> If we are going to make the block height/time available to
> VerifyScript() to implement RCLTV, should absolute CLTV should continue
> to have the proposed behavior of checking against nLockTime? If we go
> with RCLTV against current block height/time, I'm going to vote no,
> because doing so needlessly limits it to only being able to compare
> against a block height or a block time in a single transaction.
> Similarly it can complicate multi-party signatures in some
> circumstances, as all parties must agree on a common nLockTime.
> 
> 
> Time-based locks
> ================
> 
> Do we want to support them at all? May cause incentive issues with
> mining, see #bitcoin-wizards discussion, Jul 17th 2013:
> 
> https://download.wpsoftware.net/bitcoin/wizards/2013/07/13-07-17.log
> 



From pete at petertodd.org  Mon May  4 04:36:01 2015
From: pete at petertodd.org (Peter Todd)
Date: Mon, 4 May 2015 00:36:01 -0400
Subject: [Bitcoin-development] New release of replace-by-fee for Bitcoin
	Core v0.10.1
In-Reply-To: <20150212064719.GA6563@savin.petertodd.org>
References: <20150212064719.GA6563@savin.petertodd.org>
Message-ID: <20150504043601.GA14728@savin.petertodd.org>

My replace-by-fee patch is now available for the v0.10.1 release:

    https://github.com/petertodd/bitcoin/tree/replace-by-fee-v0.10.1

No new features in this version; this is simply a rebase for the Bitcoin
Core v0.10.1 release. (there weren't even any merge conflicts) As with
the Bitcoin Core v0.10.1, it's recommended to upgrade.


The following text is the copied verbatim from the previous release:

What's replace-by-fee?
----------------------

Currently most Bitcoin nodes accept the first transaction they see
spending an output to the mempool; all later transactions are rejected.
Replace-by-fee changes this behavior to accept the transaction paying
the highest fee, both absolutely, and in terms of fee-per-KB. Replaced
children are also considered - a chain of transactions is only replaced
if the replacement has a higher fee than the sum of all replaced
transactions.

Doing this aligns standard node behavior with miner incentives: earn the
most amount of money per block. It also makes for a more efficient
transaction fee marketplace, as transactions that are "stuck" due to bad
fee estimates can be "unstuck" by double-spending them with higher
paying versions of themselves. With scorched-earth techniques? it gives
a path to making zeroconf transactions economically secure by relying on
economic incentives, rather than "honesty" and alturism, in the same way
Bitcoin mining itself relies on incentives rather than "honesty" and
alturism.

Finally for miners adopting replace-by-fee avoids the development of an
ecosystem that relies heavily on large miners punishing smaller ones for
misbehavior, as seen in Harding's proposal? that miners collectively 51%
attack miners who include doublespends in their blocks - an unavoidable
consequence of imperfect p2p networking in a decentralized system - or
even Hearn's proposal? that a majority of miners be able to vote to
confiscate the earnings of the minority and redistribute them at will.


Installation
------------

Once you've compiled the replace-by-fee-v0.10.1 branch just run your
node normally. With -debug logging enabled, you'll see messages like the
following in your ~/.bitcoin/debug.log indicating your node is replacing
transactions with higher-fee paying double-spends:

    2015-02-12 05:45:20 replacing tx ca07cc2a5eaf55ab13be7ed7d7526cb9d303086f116127608e455122263f93ea with c23973c08d71cdadf3a47bae45566053d364e77d21747ae7a1b66bf1dffe80ea for 0.00798 BTC additional fees, -1033 delta bytes

Additionally you can tell if you are connected to other replace-by-fee
nodes, or Bitcoin XT nodes, by examining the service bits advertised by
your peers:

    $ bitcoin-cli getpeerinfo | grep services | egrep '((0000000000000003)|(0000000004000001))'
            "services" : "0000000000000003",
            "services" : "0000000004000001",
            "services" : "0000000004000001",
            "services" : "0000000000000003",
            "services" : "0000000004000001",
            "services" : "0000000004000001",
            "services" : "0000000000000003",
            "services" : "0000000000000003",

Replace-by-fee nodes advertise service bit 26 from the experimental use
range; Bitcoin XT nodes advertise service bit 1 for their getutxos
support. The code sets aside a certain number of outgoing and incoming
slots just for double-spend relaying nodes, so as long as everything is
working you're node should be connected to like-minded nodes a within 30
minutes or so of starting up.

If you *don't* want to advertise the fact that you are running a
replace-by-fee node, just checkout a slightly earlier commit in git; the
actual mempool changes are separate from the preferential peering
commits. You can then connect directly to a replace-by-fee node using
the -addnode command line flag.

1) https://github.com/bitcoinxt/bitcoinxt
2) https://github.com/bitcoin/bitcoin/pull/3883
3) https://github.com/bitcoin/bitcoin/pull/3883#issuecomment-45543370
4) https://github.com/luke-jr/bitcoin/tree/0.10.x-ljrP
5) http://www.mail-archive.com/bitcoin-development%40lists.sourceforge.net/msg05211.html
6) http://www.mail-archive.com/bitcoin-development at lists.sourceforge.net/msg06970.html
7) http://www.mail-archive.com/bitcoin-development%40lists.sourceforge.net/msg04972.html

-- 
'peter'[:-1]@petertodd.org
0000000000000000059a3dd65f0e5ffb8fdf316d6f31921fefcf0ef726120be9
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150504/5f06134a/attachment.sig>

From pete at petertodd.org  Mon May  4 05:07:15 2015
From: pete at petertodd.org (Peter Todd)
Date: Mon, 4 May 2015 01:07:15 -0400
Subject: [Bitcoin-development] CLTV opcode allocation; long-term plans?
Message-ID: <20150504050715.GA18856@savin.petertodd.org>

Matt Corallo brought up? the issue of OP_NOP scarcity on the mempool
only CLTV pull-req?:

    "I like merging this, but doing both CLTV things in one swoop would be
    really nice. Certainly if we're gonna use one of the precious few
    OP_NOPs we have we might as well make it more flexible."

I have two lines of thought on this:

1) We're going to end up with a Script v2.0 reasonably soon, probably
   based on Russel O'Connor and Pieter Wuille's Merkelized Abstract Syntax
   Tree? idea. This needs at most a single OP_NOPx to implement and mostly
   removes the scarcity of upgradable NOP's.

2) Similarly in script v1.0 even if we do use up all ten OP_NOPx's, the
   logical thing to do is implement an <actual opcode #> OP_EXTENDED.

3) It's not clear what form a relative CLTV will actually take; the BIP
   itself proposes a OP_PREVOUT_HEIGHT_VERIFY/OP_PREVOUT_DATA along with
   OP_ADD, with any opcode accessing non-reorg-safe prevout info being made
   unavailable until the coinbase maturity period has passed for
   soft-fork safeness.

That said, if people have strong feelings about this, I would be willing
to make OP_CLTV work as follows:

    <nLockTime> 1 OP_CLTV

Where the 1 selects absolute mode, and all others act as OP_NOP's. A
future relative CLTV could then be a future soft-fork implemented as
follows:

    <relative nLockTime> 2 OP_CLTV

On the bad side it'd be two or three days of work to rewrite all the
existing tests and example code and update the BIP, and (slightly) gets
us away from the well-tested existing implementation. It also may
complicate the codebase compared to sticking with just doing a Script
v2.0, with the additional execution environment data required for v2.0
scripts cleanly separated out. But all in all, the above isn't too big
of a deal.

Interested in your thoughts.

1) https://github.com/bitcoin/bitcoin/pull/5496#issuecomment-98568239
2) https://github.com/bitcoin/bitcoin/pull/5496
3) http://css.csail.mit.edu/6.858/2014/projects/jlrubin-mnaik-nityas.pdf

-- 
'peter'[:-1]@petertodd.org
00000000000000000908b2eb1cb0660069547abdddad7fa6ad4e743cebe549de
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150504/7912b3b9/attachment.sig>

From jtimon at jtimon.cc  Mon May  4 11:24:44 2015
From: jtimon at jtimon.cc (=?UTF-8?B?Sm9yZ2UgVGltw7Nu?=)
Date: Mon, 4 May 2015 13:24:44 +0200
Subject: [Bitcoin-development] Relative CHECKLOCKTIMEVERIFY (was CLTV
	proposal)
In-Reply-To: <5546D653.4070404@bluematt.me>
References: <20141001130826.GM28710@savin.petertodd.org>
	<55075795.20904@bluematt.me>
	<20150421075912.GA25282@savin.petertodd.org>
	<5546D653.4070404@bluematt.me>
Message-ID: <CABm2gDqcD4ENex3LzKfeGqaotoO-XxLHhLzOEPwk92SaiD8snQ@mail.gmail.com>

What I was describing was an attempt to fix a similar proposal by Mark
Friedenbach, but it didn't needed fixing: I was simply
misunderstanding it.
Mark's RCLTV is completely reorg safe, so there's no need for the 100
block restriction. It also keeps the script validation independent
from the utxo.
Here's is how it works:

The operator takes a relative_height parameter and it checks that the
nSequence of the input is lower than that parameter.

Additionally, a new check at the transaction level:

for (unsigned int i = 0; i < tx.vin.size(); i++) {
// ...
            if (coins->nHeight + tx.vin[i].nSequence < nSpendHeight)
                return state.Invalid(false, REJECT_INVALID,
"bad-txns-non-final-input");
// ...
}

Well, this is assuming that we're only using it with heights and not timestamps.
Mark, feel free to elaborate further.



From btcdrak at gmail.com  Tue May  5 00:41:52 2015
From: btcdrak at gmail.com (Btc Drak)
Date: Tue, 5 May 2015 01:41:52 +0100
Subject: [Bitcoin-development] Relative CHECKLOCKTIMEVERIFY (was CLTV
	proposal)
In-Reply-To: <CABm2gDqcD4ENex3LzKfeGqaotoO-XxLHhLzOEPwk92SaiD8snQ@mail.gmail.com>
References: <20141001130826.GM28710@savin.petertodd.org>
	<55075795.20904@bluematt.me>
	<20150421075912.GA25282@savin.petertodd.org>
	<5546D653.4070404@bluematt.me>
	<CABm2gDqcD4ENex3LzKfeGqaotoO-XxLHhLzOEPwk92SaiD8snQ@mail.gmail.com>
Message-ID: <CADJgMztaJgUH81Bc1s4P45d2u-35Si7=7rON=UdZn4piycxHpw@mail.gmail.com>

On Mon, May 4, 2015 at 12:24 PM, Jorge Tim?n <jtimon at jtimon.cc> wrote:

> What I was describing was an attempt to fix a similar proposal by Mark
> Friedenbach, but it didn't needed fixing: I was simply
> misunderstanding it.
> Mark's RCLTV is completely reorg safe, so there's no need for the 100
> block restriction. It also keeps the script validation independent
> from the utxo.
> Here's is how it works:
>
> The operator takes a relative_height parameter and it checks that the
> nSequence of the input is lower than that parameter.
>
> Additionally, a new check at the transaction level:
>
> for (unsigned int i = 0; i < tx.vin.size(); i++) {
> // ...
>             if (coins->nHeight + tx.vin[i].nSequence < nSpendHeight)
>                 return state.Invalid(false, REJECT_INVALID,
> "bad-txns-non-final-input");
> // ...
> }
>
> Well, this is assuming that we're only using it with heights and not
> timestamps.
> Mark, feel free to elaborate further.


Does dropping timestamp refer just to RCLTV or absolutely CLTV also? For
absolute CLTV I think it's important to have timestamps so that trust fund
use cases are practical (e.g. spendable on 18th birthday), because the
exact date a future block will be mined on is unpredictable if it's far
enough in the future (out by days or even weeks).
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150505/5cc624fb/attachment.html>

From btcdrak at gmail.com  Tue May  5 00:54:33 2015
From: btcdrak at gmail.com (Btc Drak)
Date: Tue, 5 May 2015 01:54:33 +0100
Subject: [Bitcoin-development] CLTV opcode allocation; long-term plans?
In-Reply-To: <20150504050715.GA18856@savin.petertodd.org>
References: <20150504050715.GA18856@savin.petertodd.org>
Message-ID: <CADJgMzs3D=6pNOQhU3ubi6=C8javRtwL0VuGFWvU+6SiuB0YWg@mail.gmail.com>

On Mon, May 4, 2015 at 6:07 AM, Peter Todd <pete at petertodd.org> wrote:

> Matt Corallo brought up? the issue of OP_NOP scarcity on the mempool
> only CLTV pull-req?:
>
>     "I like merging this, but doing both CLTV things in one swoop would be
>     really nice. Certainly if we're gonna use one of the precious few
>     OP_NOPs we have we might as well make it more flexible."
>
> [snip]

> That said, if people have strong feelings about this, I would be willing
> to make OP_CLTV work as follows:
>
>     <nLockTime> 1 OP_CLTV
>
> Where the 1 selects absolute mode, and all others act as OP_NOP's. A
> future relative CLTV could then be a future soft-fork implemented as
> follows:
>
>     <relative nLockTime> 2 OP_CLTV
>
> On the bad side it'd be two or three days of work to rewrite all the
> existing tests and example code and update the BIP, and (slightly) gets
> us away from the well-tested existing implementation. It also may
> complicate the codebase compared to sticking with just doing a Script
> v2.0, with the additional execution environment data required for v2.0
> scripts cleanly separated out. But all in all, the above isn't too big
> of a deal.


Adding a parameter to OP_CLTV makes it much more flexible and is the most
economic use of precious NOPs.
The extra time required is ok and it would be good to make this change to
the PR in time for the feature freeze.

Drak
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150505/677b8096/attachment.html>

From kgreenek at gmail.com  Tue May  5 02:23:09 2015
From: kgreenek at gmail.com (Kevin Greene)
Date: Mon, 4 May 2015 19:23:09 -0700
Subject: [Bitcoin-development] New release of replace-by-fee for Bitcoin
 Core v0.10.1
In-Reply-To: <20150504043601.GA14728@savin.petertodd.org>
References: <20150212064719.GA6563@savin.petertodd.org>
	<20150504043601.GA14728@savin.petertodd.org>
Message-ID: <CAEY8wq50ETVXX5V22KybiEMXiXVVhsB7OJdvgF_zFjn=KQ-hCg@mail.gmail.com>

I feel compelled to re-share Mike Hearn's counter-argument *against *
replace-by-fee:
https://medium.com/@octskyward/replace-by-fee-43edd9a1dd6d

Please carefully consider the effects of replace-by-fee before applying
Peter's patch.

On Sun, May 3, 2015 at 9:36 PM, Peter Todd <pete at petertodd.org> wrote:

> My replace-by-fee patch is now available for the v0.10.1 release:
>
>     https://github.com/petertodd/bitcoin/tree/replace-by-fee-v0.10.1
>
> No new features in this version; this is simply a rebase for the Bitcoin
> Core v0.10.1 release. (there weren't even any merge conflicts) As with
> the Bitcoin Core v0.10.1, it's recommended to upgrade.
>
>
> The following text is the copied verbatim from the previous release:
>
> What's replace-by-fee?
> ----------------------
>
> Currently most Bitcoin nodes accept the first transaction they see
> spending an output to the mempool; all later transactions are rejected.
> Replace-by-fee changes this behavior to accept the transaction paying
> the highest fee, both absolutely, and in terms of fee-per-KB. Replaced
> children are also considered - a chain of transactions is only replaced
> if the replacement has a higher fee than the sum of all replaced
> transactions.
>
> Doing this aligns standard node behavior with miner incentives: earn the
> most amount of money per block. It also makes for a more efficient
> transaction fee marketplace, as transactions that are "stuck" due to bad
> fee estimates can be "unstuck" by double-spending them with higher
> paying versions of themselves. With scorched-earth techniques? it gives
> a path to making zeroconf transactions economically secure by relying on
> economic incentives, rather than "honesty" and alturism, in the same way
> Bitcoin mining itself relies on incentives rather than "honesty" and
> alturism.
>
> Finally for miners adopting replace-by-fee avoids the development of an
> ecosystem that relies heavily on large miners punishing smaller ones for
> misbehavior, as seen in Harding's proposal? that miners collectively 51%
> attack miners who include doublespends in their blocks - an unavoidable
> consequence of imperfect p2p networking in a decentralized system - or
> even Hearn's proposal? that a majority of miners be able to vote to
> confiscate the earnings of the minority and redistribute them at will.
>
>
> Installation
> ------------
>
> Once you've compiled the replace-by-fee-v0.10.1 branch just run your
> node normally. With -debug logging enabled, you'll see messages like the
> following in your ~/.bitcoin/debug.log indicating your node is replacing
> transactions with higher-fee paying double-spends:
>
>     2015-02-12 05:45:20 replacing tx
> ca07cc2a5eaf55ab13be7ed7d7526cb9d303086f116127608e455122263f93ea with
> c23973c08d71cdadf3a47bae45566053d364e77d21747ae7a1b66bf1dffe80ea for
> 0.00798 BTC additional fees, -1033 delta bytes
>
> Additionally you can tell if you are connected to other replace-by-fee
> nodes, or Bitcoin XT nodes, by examining the service bits advertised by
> your peers:
>
>     $ bitcoin-cli getpeerinfo | grep services | egrep
> '((0000000000000003)|(0000000004000001))'
>             "services" : "0000000000000003",
>             "services" : "0000000004000001",
>             "services" : "0000000004000001",
>             "services" : "0000000000000003",
>             "services" : "0000000004000001",
>             "services" : "0000000004000001",
>             "services" : "0000000000000003",
>             "services" : "0000000000000003",
>
> Replace-by-fee nodes advertise service bit 26 from the experimental use
> range; Bitcoin XT nodes advertise service bit 1 for their getutxos
> support. The code sets aside a certain number of outgoing and incoming
> slots just for double-spend relaying nodes, so as long as everything is
> working you're node should be connected to like-minded nodes a within 30
> minutes or so of starting up.
>
> If you *don't* want to advertise the fact that you are running a
> replace-by-fee node, just checkout a slightly earlier commit in git; the
> actual mempool changes are separate from the preferential peering
> commits. You can then connect directly to a replace-by-fee node using
> the -addnode command line flag.
>
> 1) https://github.com/bitcoinxt/bitcoinxt
> 2) https://github.com/bitcoin/bitcoin/pull/3883
> 3) https://github.com/bitcoin/bitcoin/pull/3883#issuecomment-45543370
> 4) https://github.com/luke-jr/bitcoin/tree/0.10.x-ljrP
> 5)
> http://www.mail-archive.com/bitcoin-development%40lists.sourceforge.net/msg05211.html
> 6)
> http://www.mail-archive.com/bitcoin-development at lists.sourceforge.net/msg06970.html
> 7)
> http://www.mail-archive.com/bitcoin-development%40lists.sourceforge.net/msg04972.html
>
> --
> 'peter'[:-1]@petertodd.org
> 0000000000000000059a3dd65f0e5ffb8fdf316d6f31921fefcf0ef726120be9
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150504/2d3b72a5/attachment.html>

From jtimon at jtimon.cc  Tue May  5 19:19:00 2015
From: jtimon at jtimon.cc (=?UTF-8?B?Sm9yZ2UgVGltw7Nu?=)
Date: Tue, 5 May 2015 21:19:00 +0200
Subject: [Bitcoin-development] Relative CHECKLOCKTIMEVERIFY (was CLTV
	proposal)
In-Reply-To: <CADJgMztaJgUH81Bc1s4P45d2u-35Si7=7rON=UdZn4piycxHpw@mail.gmail.com>
References: <20141001130826.GM28710@savin.petertodd.org>
	<55075795.20904@bluematt.me>
	<20150421075912.GA25282@savin.petertodd.org>
	<5546D653.4070404@bluematt.me>
	<CABm2gDqcD4ENex3LzKfeGqaotoO-XxLHhLzOEPwk92SaiD8snQ@mail.gmail.com>
	<CADJgMztaJgUH81Bc1s4P45d2u-35Si7=7rON=UdZn4piycxHpw@mail.gmail.com>
Message-ID: <CABm2gDpn-VdNQaMzKSA1tvGhhec3UxdGp-9x-U+ruTWd4ApbiA@mail.gmail.com>

Well, apparently the timestamp can be make compatible with Mark's
nSequence-based RCLTV by adding an additional check at the block level
but I was only explaining the concept using heights (which is the most
interesting part IMO).
I'm also not sure I understood the details and I don't want to confuse
people again, so I'll wait for someone else to explain that part.
ACLTV can work with timestamps too unless I'm missing something. It's
just more complexity and I was never convinced that there's enough use
cases relying on timestamps to justify them. But the timestamp
discussion is quite orthogonal to the nSequence-based RCLTV proposal
itself.

On Tue, May 5, 2015 at 2:41 AM, Btc Drak <btcdrak at gmail.com> wrote:
> On Mon, May 4, 2015 at 12:24 PM, Jorge Tim?n <jtimon at jtimon.cc> wrote:
>>
>> What I was describing was an attempt to fix a similar proposal by Mark
>> Friedenbach, but it didn't needed fixing: I was simply
>> misunderstanding it.
>> Mark's RCLTV is completely reorg safe, so there's no need for the 100
>> block restriction. It also keeps the script validation independent
>> from the utxo.
>> Here's is how it works:
>>
>> The operator takes a relative_height parameter and it checks that the
>> nSequence of the input is lower than that parameter.
>>
>> Additionally, a new check at the transaction level:
>>
>> for (unsigned int i = 0; i < tx.vin.size(); i++) {
>> // ...
>>             if (coins->nHeight + tx.vin[i].nSequence < nSpendHeight)
>>                 return state.Invalid(false, REJECT_INVALID,
>> "bad-txns-non-final-input");
>> // ...
>> }
>>
>> Well, this is assuming that we're only using it with heights and not
>> timestamps.
>> Mark, feel free to elaborate further.
>
>
> Does dropping timestamp refer just to RCLTV or absolutely CLTV also? For
> absolute CLTV I think it's important to have timestamps so that trust fund
> use cases are practical (e.g. spendable on 18th birthday), because the exact
> date a future block will be mined on is unpredictable if it's far enough in
> the future (out by days or even weeks).
>



From tier.nolan at gmail.com  Tue May  5 20:38:44 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Tue, 5 May 2015 21:38:44 +0100
Subject: [Bitcoin-development] Relative CHECKLOCKTIMEVERIFY (was CLTV
	proposal)
In-Reply-To: <CABm2gDqcD4ENex3LzKfeGqaotoO-XxLHhLzOEPwk92SaiD8snQ@mail.gmail.com>
References: <20141001130826.GM28710@savin.petertodd.org>
	<55075795.20904@bluematt.me>
	<20150421075912.GA25282@savin.petertodd.org>
	<5546D653.4070404@bluematt.me>
	<CABm2gDqcD4ENex3LzKfeGqaotoO-XxLHhLzOEPwk92SaiD8snQ@mail.gmail.com>
Message-ID: <CAE-z3OVrHqK1gyxCimz3ATBV3ojuyBNO-Jj6bzmcxMgfWe9jkg@mail.gmail.com>

I think that should be greater than in the comparison?  You want it to fail
if the the height of the UTXO plus the sequence number is greater than the
spending block's height.

There should be an exception for final inputs.  Otherwise, they will count
as relative locktime of 0xFFFFFFFF.  Is this check handled elsewhere?

if (!tx.vin[i].IsFinal() && nSpendHeight < coins->nHeight +
tx.vin[i].nSequence)
       return state.Invalid(false, REJECT_INVALID,
"bad-txns-non-final-input");

Is the intention to let the script check the sequence number?

<number> OP_RELATIVELOCKTIMEVERIFY

would check if <number> is less than or equal to the sequence number.

It does make sequence mean something completely different from before.
Invalidating previously valid transactions has the potential to reduce
confidence in the currency.

A workaround would be to have a way to enable it in the sigScript by
extending Peter Todd's suggestion in the other email chain.

<1> OP_NOP2 means OP_CHECKLOCKTIMEVERIFY (absolute)
<2> OP_NOP2 means OP_RELATIVECHECKLOCKTIMEVERIFY

<3> OP_NOP2 means OP_SEQUENCE_AS_RELATIVE_HEIGHT

OP_SEQUENCE_AS_RELATIVE_HEIGHT would cause the script to fail unless it was
the first opcode in the script.  It acts as a flag to enable using the
sequence number as for relative block height.

This can be achieved using a simple pattern match.

bool CScript::IsSequenceAsRelativeHeight() const
{
    // Extra-fast test for pay-to-script-hash CScripts:
    return (this->size() >= 4 &&
            this->at(0) == OP_PUSHDATA1 &&
            this->at(1) == 1 &&
            this->at(2) == 0xFF &&
            this->at(3) == OP_NOP2);
}

if (!tx.vin[i].IsFinal() &&
tx.vin[i].scriptSig.IsSequenceAsRelativeHeight() && nSpendHeight <
coins->nHeight + tx.vin[i].nSequence)
       return state.Invalid(false, REJECT_INVALID,
"bad-txns-non-final-input");

On Mon, May 4, 2015 at 12:24 PM, Jorge Tim?n <jtimon at jtimon.cc> wrote:

> for (unsigned int i = 0; i < tx.vin.size(); i++) {
> // ...
>             if (coins->nHeight + tx.vin[i].nSequence < nSpendHeight)
>                 return state.Invalid(false, REJECT_INVALID,
> "bad-txns-non-final-input");
> // ...
> }
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150505/a857b67b/attachment.html>

From jtimon at jtimon.cc  Wed May  6 07:37:37 2015
From: jtimon at jtimon.cc (=?UTF-8?B?Sm9yZ2UgVGltw7Nu?=)
Date: Wed, 6 May 2015 09:37:37 +0200
Subject: [Bitcoin-development] Relative CHECKLOCKTIMEVERIFY (was CLTV
	proposal)
In-Reply-To: <CAE-z3OVrHqK1gyxCimz3ATBV3ojuyBNO-Jj6bzmcxMgfWe9jkg@mail.gmail.com>
References: <20141001130826.GM28710@savin.petertodd.org>
	<55075795.20904@bluematt.me>
	<20150421075912.GA25282@savin.petertodd.org>
	<5546D653.4070404@bluematt.me>
	<CABm2gDqcD4ENex3LzKfeGqaotoO-XxLHhLzOEPwk92SaiD8snQ@mail.gmail.com>
	<CAE-z3OVrHqK1gyxCimz3ATBV3ojuyBNO-Jj6bzmcxMgfWe9jkg@mail.gmail.com>
Message-ID: <CABm2gDpp-tKPa4NtX29FhB5AN9sKcJJ9CboZoaczt2bU2h=5tQ@mail.gmail.com>

On Tue, May 5, 2015 at 10:38 PM, Tier Nolan <tier.nolan at gmail.com> wrote:
> I think that should be greater than in the comparison?  You want it to fail
> if the the height of the UTXO plus the sequence number is greater than the
> spending block's height.

Yes, sorry, I changed it just before sending from "what needs to be
satisfied for the validation error to trigger" to "what needs to be
satisfied for the tx to be valid".
You're right.

> There should be an exception for final inputs.  Otherwise, they will count
> as relative locktime of 0xFFFFFFFF.  Is this check handled elsewhere?
>
> if (!tx.vin[i].IsFinal() && nSpendHeight < coins->nHeight +
> tx.vin[i].nSequence)
>        return state.Invalid(false, REJECT_INVALID,
> "bad-txns-non-final-input");

Yes, this would be the simplest solution. Another option would be to
have a new tx version in which IsFinal(CTransaction) doesn't check the
inputs sequences to be 0xFFFFFFFF for the tx to be final.

> Is the intention to let the script check the sequence number?
>
> <number> OP_RELATIVELOCKTIMEVERIFY
>
> would check if <number> is less than or equal to the sequence number.

Yes.

> It does make sequence mean something completely different from before.
> Invalidating previously valid transactions has the potential to reduce
> confidence in the currency.

Well, the semantics of nSequence don't really change completely. In
fact, one could argue that this put it closer to its original
semantics.
But in any case, yes, already signed transaction should remain valid.
No transaction would become invalid, just non-final.
As soon as the height of its inputs plus their respective nSquences
get higher than current height they will become final again.
I cannot think of any use case where a tx becomes invalid forever.
Also, probably most people have usedrelatively low values for
nSequence given the original semantics, just like the relative lock
nSquence will likely be used as well.

> A workaround would be to have a way to enable it in the sigScript by
> extending Peter Todd's suggestion in the other email chain.
>
> <1> OP_NOP2 means OP_CHECKLOCKTIMEVERIFY (absolute)
> <2> OP_NOP2 means OP_RELATIVECHECKLOCKTIMEVERIFY
>
> <3> OP_NOP2 means OP_SEQUENCE_AS_RELATIVE_HEIGHT

To be clear, this proposal is supposed to replace RCLTV, so there
would still be 2 options. But please let's imagine we have infinite
opcodes in this thread and let the "should we design an uglier
scripting langues to save opcodes?" question in the other one.

> OP_SEQUENCE_AS_RELATIVE_HEIGHT would cause the script to fail unless it was
> the first opcode in the script.  It acts as a flag to enable using the
> sequence number as for relative block height.
>
> This can be achieved using a simple pattern match.
>
> bool CScript::IsSequenceAsRelativeHeight() const
> {
>     // Extra-fast test for pay-to-script-hash CScripts:
>     return (this->size() >= 4 &&
>             this->at(0) == OP_PUSHDATA1 &&
>             this->at(1) == 1 &&
>             this->at(2) == 0xFF &&
>             this->at(3) == OP_NOP2);
> }
>
> if (!tx.vin[i].IsFinal() && tx.vin[i].scriptSig.IsSequenceAsRelativeHeight()
> && nSpendHeight < coins->nHeight + tx.vin[i].nSequence)
>        return state.Invalid(false, REJECT_INVALID,
> "bad-txns-non-final-input");

This gives you less flexibility and I don't think it's necessary.
Please let's try to avoid this if it's possible.


> On Mon, May 4, 2015 at 12:24 PM, Jorge Tim?n <jtimon at jtimon.cc> wrote:
>>
>> for (unsigned int i = 0; i < tx.vin.size(); i++) {
>> // ...
>>             if (coins->nHeight + tx.vin[i].nSequence < nSpendHeight)
>>                 return state.Invalid(false, REJECT_INVALID,
>> "bad-txns-non-final-input");
>> // ...
>> }
>
>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>



From tier.nolan at gmail.com  Wed May  6 22:09:59 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Wed, 6 May 2015 23:09:59 +0100
Subject: [Bitcoin-development] Relative CHECKLOCKTIMEVERIFY (was CLTV
	proposal)
In-Reply-To: <CABm2gDpp-tKPa4NtX29FhB5AN9sKcJJ9CboZoaczt2bU2h=5tQ@mail.gmail.com>
References: <20141001130826.GM28710@savin.petertodd.org>
	<55075795.20904@bluematt.me>
	<20150421075912.GA25282@savin.petertodd.org>
	<5546D653.4070404@bluematt.me>
	<CABm2gDqcD4ENex3LzKfeGqaotoO-XxLHhLzOEPwk92SaiD8snQ@mail.gmail.com>
	<CAE-z3OVrHqK1gyxCimz3ATBV3ojuyBNO-Jj6bzmcxMgfWe9jkg@mail.gmail.com>
	<CABm2gDpp-tKPa4NtX29FhB5AN9sKcJJ9CboZoaczt2bU2h=5tQ@mail.gmail.com>
Message-ID: <CAE-z3OXrrYWGROK1=3zVQxjqzeyYBwa1SGxEMeb4b4V3_S9KfQ@mail.gmail.com>

On Wed, May 6, 2015 at 8:37 AM, Jorge Tim?n <jtimon at jtimon.cc> wrote:

>
> This gives you less flexibility and I don't think it's necessary.
> Please let's try to avoid this if it's possible.


It is just a switch that turns on and off the new mode.

In retrospect, it would be better to just up the transaction version.

In transactions from v2 onwards, the sequence field means height.  That
means legacy transactions would be spendable.

This is a pure soft-fork.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150506/ebbb9a52/attachment.html>

From bitcoin-list at bluematt.me  Wed May  6 22:12:14 2015
From: bitcoin-list at bluematt.me (Matt Corallo)
Date: Wed, 06 May 2015 22:12:14 +0000
Subject: [Bitcoin-development] Block Size Increase
Message-ID: <554A91BE.6060105@bluematt.me>

Recently there has been a flurry of posts by Gavin at
http://gavinandresen.svbtle.com/ which advocate strongly for increasing
the maximum block size. However, there hasnt been any discussion on this
mailing list in several years as far as I can tell.

Block size is a question to which there is no answer, but which
certainly has a LOT of technical tradeoffs to consider. I know a lot of
people here have varying levels of strong or very strong opinions about
this, and the fact that it is not being discussed in a technical
community publicly anywhere is rather disappointing.

So, at the risk of starting a flamewar, I'll provide a little bait to
get some responses and hope the discussion opens up into an honest
comparison of the tradeoffs here. Certainly a consensus in this kind of
technical community should be a basic requirement for any serious
commitment to blocksize increase.

Personally, I'm rather strongly against any commitment to a block size
increase in the near future. Long-term incentive compatibility requires
that there be some fee pressure, and that blocks be relatively
consistently full or very nearly full. What we see today are
transactions enjoying next-block confirmations with nearly zero pressure
to include any fee at all (though many do because it makes wallet code
simpler).

This allows the well-funded Bitcoin ecosystem to continue building
systems which rely on transactions moving quickly into blocks while
pretending these systems scale. Thus, instead of working on technologies
which bring Bitcoin's trustlessness to systems which scale beyond a
blockchain's necessarily slow and (compared to updating numbers in a
database) expensive settlement, the ecosystem as a whole continues to
focus on building centralized platforms and advocate for changes to
Bitcoin which allow them to maintain the status quo[1].

Matt

[1] https://twitter.com/coinbase/status/595741967759335426



From tier.nolan at gmail.com  Wed May  6 22:44:53 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Wed, 6 May 2015 23:44:53 +0100
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554A91BE.6060105@bluematt.me>
References: <554A91BE.6060105@bluematt.me>
Message-ID: <CAE-z3OXnjayLUeHBU0hdwU5pKrJ6fpj7YPtGBMQ7hKXG3Sj6hw@mail.gmail.com>

On Wed, May 6, 2015 at 11:12 PM, Matt Corallo <bitcoin-list at bluematt.me>
wrote:

> Personally, I'm rather strongly against any commitment to a block size
> increase in the near future.


Miners can already soft-fork to reduce the maximum block size.  If 51% of
miners agree to a 250kB block size, then that is the maximum block size.

The question being discussed is what is the maximum block size merchants
and users will accept.  This puts a reasonable limit on the maximum size
miners can increase the block size to.

In effect, the block size is set by the minimum of the miner's and the
merchants/user's size.min(miner, merchants/users).


> This allows the well-funded Bitcoin ecosystem to continue building
> systems which rely on transactions moving quickly into blocks while
> pretending these systems scale. Thus, instead of working on technologies
> which bring Bitcoin's trustlessness to systems which scale beyond a
> blockchain's necessarily slow and (compared to updating numbers in a
> database) expensive settlement, the ecosystem as a whole continues to
> focus on building centralized platforms and advocate for changes to
> Bitcoin which allow them to maintain the status quo[1].
>

Would you accept a rule that the maximum size is 20MB (doubling every 2
years), but that miners have an efficient method for choosing a lower size?

If miners could specify the maximum block size in their block headers, then
they could coordinate to adjust the block size.  If 75% vote to lower the
size, then it is lowered and vice versa for raiding.

Every 2016 blocks, the votes are counter.  If the 504th lowest of the 2016
blocks is higher than the previous size, then the size is set to that
size.  Similarly, if the 504th highest is lower than the previous size, it
becomes the new size.

There could be 2 default trajectories.  The reference client might always
vote to double the size every 4 years.

To handle large blocks (>32MB) requires a change to the p2p protocol
message size limits, or a way to split blocks over multiple messages.

It would be nice to add new features to any hard-fork.

I favour adding an auxiliary header.  The Merkle root in the header could
be replaced with hash(merkle_root | hash(aux_header)).  This is a fairly
simple change, but helps with things like commitments.  One of the fields
in the auxiliary header could be an extra nonce field.  This would mean
fast regeneration of the merkle root for ASIC miners.  This is a pretty
simple change.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150506/58ef0a86/attachment.html>

From slush at centrum.cz  Wed May  6 22:30:12 2015
From: slush at centrum.cz (slush)
Date: Thu, 7 May 2015 00:30:12 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554A91BE.6060105@bluematt.me>
References: <554A91BE.6060105@bluematt.me>
Message-ID: <CAJna-HjDHC=cHaUPKMB0c0Myg6EH4EX+aN4qECyq7L8p37VG=w@mail.gmail.com>

I don't have strong opinion @ block size topic.

But if there'll be a fork, PLEASE, include SIGHASH_WITHINPUTVALUE (
https://bitcointalk.org/index.php?topic=181734.0) or its alternative. All
developers of lightweight (blockchain-less) clients will adore you!

slush

On Thu, May 7, 2015 at 12:12 AM, Matt Corallo <bitcoin-list at bluematt.me>
wrote:

> Recently there has been a flurry of posts by Gavin at
> http://gavinandresen.svbtle.com/ which advocate strongly for increasing
> the maximum block size. However, there hasnt been any discussion on this
> mailing list in several years as far as I can tell.
>
> Block size is a question to which there is no answer, but which
> certainly has a LOT of technical tradeoffs to consider. I know a lot of
> people here have varying levels of strong or very strong opinions about
> this, and the fact that it is not being discussed in a technical
> community publicly anywhere is rather disappointing.
>
> So, at the risk of starting a flamewar, I'll provide a little bait to
> get some responses and hope the discussion opens up into an honest
> comparison of the tradeoffs here. Certainly a consensus in this kind of
> technical community should be a basic requirement for any serious
> commitment to blocksize increase.
>
> Personally, I'm rather strongly against any commitment to a block size
> increase in the near future. Long-term incentive compatibility requires
> that there be some fee pressure, and that blocks be relatively
> consistently full or very nearly full. What we see today are
> transactions enjoying next-block confirmations with nearly zero pressure
> to include any fee at all (though many do because it makes wallet code
> simpler).
>
> This allows the well-funded Bitcoin ecosystem to continue building
> systems which rely on transactions moving quickly into blocks while
> pretending these systems scale. Thus, instead of working on technologies
> which bring Bitcoin's trustlessness to systems which scale beyond a
> blockchain's necessarily slow and (compared to updating numbers in a
> database) expensive settlement, the ecosystem as a whole continues to
> focus on building centralized platforms and advocate for changes to
> Bitcoin which allow them to maintain the status quo[1].
>
> Matt
>
> [1] https://twitter.com/coinbase/status/595741967759335426
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/6bdab3de/attachment.html>

From elombrozo at gmail.com  Wed May  6 23:06:00 2015
From: elombrozo at gmail.com (Eric Lombrozo)
Date: Wed, 6 May 2015 16:06:00 -0700
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CAJna-HjDHC=cHaUPKMB0c0Myg6EH4EX+aN4qECyq7L8p37VG=w@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CAJna-HjDHC=cHaUPKMB0c0Myg6EH4EX+aN4qECyq7L8p37VG=w@mail.gmail.com>
Message-ID: <0F6580B4-8BB5-4287-94DE-5F625AC1BBA3@gmail.com>

I don?t really have a strong opinion on block size either?but if we?re going to do a hard fork, let?s use this as an opportunity to create a good process for hard forks (which we?ll inevitably need to do again in the future). The change in block size is a very simple change that still allows us to explore all the complexities involved with deployment of hard forks. Let?s not just do a one-off ad-hoc thing.

- Eric Lombrozo

> On May 6, 2015, at 3:30 PM, slush <slush at centrum.cz> wrote:
> 
> I don't have strong opinion @ block size topic.
> 
> But if there'll be a fork, PLEASE, include SIGHASH_WITHINPUTVALUE (https://bitcointalk.org/index.php?topic=181734.0 <https://bitcointalk.org/index.php?topic=181734.0>) or its alternative. All developers of lightweight (blockchain-less) clients will adore you!
> 
> slush
> 
> On Thu, May 7, 2015 at 12:12 AM, Matt Corallo <bitcoin-list at bluematt.me <mailto:bitcoin-list at bluematt.me>> wrote:
> Recently there has been a flurry of posts by Gavin at
> http://gavinandresen.svbtle.com/ <http://gavinandresen.svbtle.com/> which advocate strongly for increasing
> the maximum block size. However, there hasnt been any discussion on this
> mailing list in several years as far as I can tell.
> 
> Block size is a question to which there is no answer, but which
> certainly has a LOT of technical tradeoffs to consider. I know a lot of
> people here have varying levels of strong or very strong opinions about
> this, and the fact that it is not being discussed in a technical
> community publicly anywhere is rather disappointing.
> 
> So, at the risk of starting a flamewar, I'll provide a little bait to
> get some responses and hope the discussion opens up into an honest
> comparison of the tradeoffs here. Certainly a consensus in this kind of
> technical community should be a basic requirement for any serious
> commitment to blocksize increase.
> 
> Personally, I'm rather strongly against any commitment to a block size
> increase in the near future. Long-term incentive compatibility requires
> that there be some fee pressure, and that blocks be relatively
> consistently full or very nearly full. What we see today are
> transactions enjoying next-block confirmations with nearly zero pressure
> to include any fee at all (though many do because it makes wallet code
> simpler).
> 
> This allows the well-funded Bitcoin ecosystem to continue building
> systems which rely on transactions moving quickly into blocks while
> pretending these systems scale. Thus, instead of working on technologies
> which bring Bitcoin's trustlessness to systems which scale beyond a
> blockchain's necessarily slow and (compared to updating numbers in a
> database) expensive settlement, the ecosystem as a whole continues to
> focus on building centralized platforms and advocate for changes to
> Bitcoin which allow them to maintain the status quo[1].
> 
> Matt
> 
> [1] https://twitter.com/coinbase/status/595741967759335426 <https://twitter.com/coinbase/status/595741967759335426>
> 
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y <http://ad.doubleclick.net/ddm/clk/290420510;117567292;y>
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net <mailto:Bitcoin-development at lists.sourceforge.net>
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development <https://lists.sourceforge.net/lists/listinfo/bitcoin-development>
> 
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y_______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150506/a8deea31/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 842 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150506/a8deea31/attachment.sig>

From bitcoin-list at bluematt.me  Wed May  6 23:12:17 2015
From: bitcoin-list at bluematt.me (Matt Corallo)
Date: Wed, 06 May 2015 23:12:17 +0000
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CAE-z3OXnjayLUeHBU0hdwU5pKrJ6fpj7YPtGBMQ7hKXG3Sj6hw@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CAE-z3OXnjayLUeHBU0hdwU5pKrJ6fpj7YPtGBMQ7hKXG3Sj6hw@mail.gmail.com>
Message-ID: <554A9FD1.80103@bluematt.me>

Replies inline.

On 05/06/15 22:44, Tier Nolan wrote:
> On Wed, May 6, 2015 at 11:12 PM, Matt Corallo <bitcoin-list at bluematt.me
> <mailto:bitcoin-list at bluematt.me>> wrote:
>     Personally, I'm rather strongly against any commitment to a block size
>     increase in the near future.
-snip-
> The question being discussed is what is the maximum block size merchants
> and users will accept.  This puts a reasonable limit on the maximum size
> miners can increase the block size to.
> 
> In effect, the block size is set by the minimum of the miner's and the
> merchants/user's size.min(miner, merchants/users).

Indeed, "the bitcoin community of users and miners can decide to do
whatever they want", but this is univeral - "they" could decide whatever
they want if "they" want to hardfork. That said, "we" should be having a
rigorous technical discussion about whether it is sane to recommend a
given course of action by releasing software which makes it happen.

> 
>     This allows the well-funded Bitcoin ecosystem to continue building
>     systems which rely on transactions moving quickly into blocks while
>     pretending these systems scale. Thus, instead of working on technologies
>     which bring Bitcoin's trustlessness to systems which scale beyond a
>     blockchain's necessarily slow and (compared to updating numbers in a
>     database) expensive settlement, the ecosystem as a whole continues to
>     focus on building centralized platforms and advocate for changes to
>     Bitcoin which allow them to maintain the status quo[1].
> 
> 
> Would you accept a rule that the maximum size is 20MB (doubling every 2
> years), but that miners have an efficient method for choosing a lower size?
> 
> If miners could specify the maximum block size in their block headers,
> then they could coordinate to adjust the block size.  If 75% vote to
> lower the size, then it is lowered and vice versa for raiding.
> 
> Every 2016 blocks, the votes are counter.  If the 504th lowest of the
> 2016 blocks is higher than the previous size, then the size is set to
> that size.  Similarly, if the 504th highest is lower than the previous
> size, it becomes the new size.
> 
> There could be 2 default trajectories.  The reference client might
> always vote to double the size every 4 years.
> 
> To handle large blocks (>32MB) requires a change to the p2p protocol
> message size limits, or a way to split blocks over multiple messages.
> 
> It would be nice to add new features to any hard-fork.
> 
> I favour adding an auxiliary header.  The Merkle root in the header
> could be replaced with hash(merkle_root | hash(aux_header)).  This is a
> fairly simple change, but helps with things like commitments.  One of
> the fields in the auxiliary header could be an extra nonce field.  This
> would mean fast regeneration of the merkle root for ASIC miners.  This
> is a pretty simple change.

The point of the hard block size limit is exactly because giving miners
free rule to do anything they like with their blocks would allow them to
do any number of crazy attacks. The incentives for miners to pick block
sizes are no where near compatible with what allows the network to
continue to run in a decentralized manner.



From bitcoin-list at bluematt.me  Wed May  6 23:13:22 2015
From: bitcoin-list at bluematt.me (Matt Corallo)
Date: Wed, 06 May 2015 23:13:22 +0000
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <1569618.2AHoSKjX9r@crushinator>
References: <554A91BE.6060105@bluematt.me> <1569618.2AHoSKjX9r@crushinator>
Message-ID: <554AA012.8090008@bluematt.me>

For now, lets leave the discussion to JUST the block size increase. If
it helps - everyone should assume that their pet feature is included in
a hard fork or, if you prefer, that no other features are included in a
hard fork.

On 05/06/15 23:11, Matt Whitlock wrote:
> I'm not so much opposed to a block size increase as I am opposed to a hard fork. My problem with a hard fork is that everyone and their brother wants to seize the opportunity of a hard fork to insert their own pet feature, and such a mad rush of lightly considered, obscure feature additions would be extremely risky for Bitcoin. If it could be guaranteed that raising the block size limit would be the only incompatible change introduced in the hard fork, then I would support it, but I strongly fear that the hard fork itself will become an excuse to change other aspects of the system in ways that will have unintended and possibly disastrous consequences.
> 



From bip at mattwhitlock.name  Wed May  6 23:11:04 2015
From: bip at mattwhitlock.name (Matt Whitlock)
Date: Wed, 06 May 2015 19:11:04 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554A91BE.6060105@bluematt.me>
References: <554A91BE.6060105@bluematt.me>
Message-ID: <1569618.2AHoSKjX9r@crushinator>

I'm not so much opposed to a block size increase as I am opposed to a hard fork. My problem with a hard fork is that everyone and their brother wants to seize the opportunity of a hard fork to insert their own pet feature, and such a mad rush of lightly considered, obscure feature additions would be extremely risky for Bitcoin. If it could be guaranteed that raising the block size limit would be the only incompatible change introduced in the hard fork, then I would support it, but I strongly fear that the hard fork itself will become an excuse to change other aspects of the system in ways that will have unintended and possibly disastrous consequences.



From tier.nolan at gmail.com  Wed May  6 23:33:56 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Thu, 7 May 2015 00:33:56 +0100
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554A9FD1.80103@bluematt.me>
References: <554A91BE.6060105@bluematt.me>
	<CAE-z3OXnjayLUeHBU0hdwU5pKrJ6fpj7YPtGBMQ7hKXG3Sj6hw@mail.gmail.com>
	<554A9FD1.80103@bluematt.me>
Message-ID: <CAE-z3OUCHr9KK_GE2iATu5zWxbXBF5Rvt8mvKJ=rjD3NsDDcOQ@mail.gmail.com>

On Thu, May 7, 2015 at 12:12 AM, Matt Corallo <bitcoin-list at bluematt.me>
wrote:

> The point of the hard block size limit is exactly because giving miners
> free rule to do anything they like with their blocks would allow them to
> do any number of crazy attacks. The incentives for miners to pick block
> sizes are no where near compatible with what allows the network to
> continue to run in a decentralized manner.
>

Miners can always reduce the block size (if they coordinate).  Increasing
the maximum block size doesn't necessarily cause an increase.  A majority
of miners can soft-fork to set the limit lower than the hard limit.

Setting the hard-fork limit higher means that a soft fork can be used to
adjust the limit in the future.

The reference client would accept blocks above the soft limit for wallet
purposes, but not build on them.  Blocks above the hard limit would be
rejected completely.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/b5a9be4e/attachment.html>

From bitcoin-list at bluematt.me  Wed May  6 23:41:37 2015
From: bitcoin-list at bluematt.me (Matt Corallo)
Date: Wed, 06 May 2015 23:41:37 +0000
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CAE-z3OUCHr9KK_GE2iATu5zWxbXBF5Rvt8mvKJ=rjD3NsDDcOQ@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>	<CAE-z3OXnjayLUeHBU0hdwU5pKrJ6fpj7YPtGBMQ7hKXG3Sj6hw@mail.gmail.com>	<554A9FD1.80103@bluematt.me>
	<CAE-z3OUCHr9KK_GE2iATu5zWxbXBF5Rvt8mvKJ=rjD3NsDDcOQ@mail.gmail.com>
Message-ID: <554AA6B1.8030701@bluematt.me>



On 05/06/15 23:33, Tier Nolan wrote:
> On Thu, May 7, 2015 at 12:12 AM, Matt Corallo <bitcoin-list at bluematt.me
> <mailto:bitcoin-list at bluematt.me>> wrote:
> 
>     The point of the hard block size limit is exactly because giving miners
>     free rule to do anything they like with their blocks would allow them to
>     do any number of crazy attacks. The incentives for miners to pick block
>     sizes are no where near compatible with what allows the network to
>     continue to run in a decentralized manner.
> 
> 
> Miners can always reduce the block size (if they coordinate). 
> Increasing the maximum block size doesn't necessarily cause an
> increase.  A majority of miners can soft-fork to set the limit lower
> than the hard limit.

Sure, of course.

> Setting the hard-fork limit higher means that a soft fork can be used to
> adjust the limit in the future. 
> 
> The reference client would accept blocks above the soft limit for wallet
> purposes, but not build on them.  Blocks above the hard limit would be
> rejected completely.

Yes, but this does NOT make an actual policy. Note that the vast
majority of miners already apply their own patches to Bitcoin Core, so
applying one more is not all that hard. When blocks start to become
limited (ie there is any fee left on the table by transactions not
included in a block) there becomes incentive for miners to change that
behavior pretty quick. Not just that, the vast majority of the hashpower
is behind very large miners, who have little to no decentralization
pressure. This results in very incompatible incentives, mainly that the
incentive would be for the large miners to interconnect in a private
network and generate only maximum-size blocks, creating a strong
centralization pressure in the network.



From tomh at thinlink.com  Thu May  7 00:00:46 2015
From: tomh at thinlink.com (Tom Harding)
Date: Wed, 06 May 2015 17:00:46 -0700
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554A91BE.6060105@bluematt.me>
References: <554A91BE.6060105@bluematt.me>
Message-ID: <554AAB2E.6000006@thinlink.com>

On 5/6/2015 3:12 PM, Matt Corallo wrote:
> Long-term incentive compatibility requires
> that there be some fee pressure, and that blocks be relatively
> consistently full or very nearly full.

I think it's way too early to even consider a future era when the fiat 
value of the block reward is no longer the biggest-by-far mining incentive.

Creating fee pressure means driving some people to choose something 
else, not bitcoin. "Too many people using bitcoin" is nowhere on the 
list of problems today.  It's reckless to tinker with adoption in hopes 
of spurring innovation on speculation, while a "can kick" is available.

Adoption is currently at miniscule, test-flight, relatively 
insignificant levels when compared to global commerce.  As Gavin 
discussed in the article, under "Block size and miner fees? again," the 
best way to maximize miner incentives is to focus on doing things that 
are likely to increase adoption, which, in our fiat-dominated world, 
lead to a justifiably increased exchange rate.

Any innovation attractive enough to relieve the block size pressure will 
do so just as well without artificial stimulus.

Thanks for kicking off the discussion.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150506/259707d3/attachment.html>

From kanzure at gmail.com  Thu May  7 00:07:41 2015
From: kanzure at gmail.com (Bryan Bishop)
Date: Wed, 6 May 2015 19:07:41 -0500
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554A91BE.6060105@bluematt.me>
References: <554A91BE.6060105@bluematt.me>
Message-ID: <CABaSBazDvNo0Z28joPZLp9iBpus4diiuRUb5JEY-OHzgDkuDQQ@mail.gmail.com>

On Wed, May 6, 2015 at 5:12 PM, Matt Corallo <bitcoin-list at bluematt.me> wrote:
> the maximum block size. However, there hasnt been any discussion on this
> mailing list in several years as far as I can tell.

Well, there has been significant public discussion in #bitcoin-wizards
on irc.freenode.net which is available in public logs, specifically
about why increasing the max block size is kicking the can down the
road while possibly compromising blockchain security. There were many
excellent objections that were raised that, sadly, I see are not
referenced at all in the recent media blitz. Frankly I can't help but
feel that if contributions, like those from #bitcoin-wizards, have
been ignored in lieu of technical analysis, and the absence of
discussion on this mailing list, that I feel perhaps there are other
subtle and extremely important technical details that are completely
absent from this--and other-- proposals. I have some rather general
thoughts to offer.

Secured decentralization is the most important and most interesting
property of bitcoin. Everything else is rather trivial and could be
achieved millions of times more efficiently with conventional
technology. Our technical work should be informed by the technical
nature of the system we have constructed.

I suspect that as bitcoin continues to grow in all dimensions and
metrics, that we will see an unending wave of those who are excited by
the idea of Something Different in the face of archaic, crumbling
software and procedures in the rest of the financial world. Money has
found its way into every aspect of human life. There's no doubt in my
mind that bitcoin will always see the most extreme campaigns and the
most extreme misunderstandings. Like moths to a flame or water in the
desert, almost everyone is excited by ANY status quo change
whatsoever. This is something that we have to be vigilante about,
because their excitement is motivation to do excellent work, not
simply any work. For some who are excited about general status quo
changes that bitcoin represents, they may not mind if bitcoin
decentralization disappears and is replaced with just a handful of
centralized nodes. Whereas for development purposes we must hold
ourselves to extremely high standards before proposing changes,
especially to the public, that have the potential to be unsafe and
economically unsafe. We have examples from NASA about how to engineer
extremely fault tolerant systems, and we have examples from Linux
about how to have high standards in open-source projects. Safety is
absolutely critical, even in the face of seemingly irrational
excuberance of others who want to scale to trillions of daily coffee
transactions individually stored forever in the blockchain.

When designing bitcoin or even some other system, an important design
target is what the system should be capable of. How many transactions
should the system perform? What is the correct number of transactions
for a healthy, modern civilization to perform every day? And how fast
should that (not) grow? Should we allow for 2 billion trillion coffee
transactions every day, or what about 100 trillion transactions per
second? I suspect that these sorts of questions are entirely
unanswerable and boring. So in the absence of technical targets to
reach during the design phase, I suspect that Jeff Garzik was right
when he pointed out a few months ago that bitcoin is good at
settlement and clearing. There are many potential technical solutions
for aggregating millions (trillions?) of transactions into tiny
bundles. As a small proof-of-concept, imagine two parties sending
transactions back and forth 100 million times. Instead of recording
every transaction, you could record the start state and the end state,
and end up with two transactions or less. That's a 100 million fold,
without modifying max block size and without potentially compromising
secured decentralization.

The MIT group should listen up and get to work figuring out how to
measure decentralization and its security :-). Maybe we should be
collectively pestering Andrew Miller to do this, too. No pressure,
dude. Getting this measurement right would be really beneficial
because we would have a more academic and technical understanding to
work with. I would also characterize this as high priority next to the
"formally verified correctness proofs for Script and
libbitcoinconsensus".

Also, I think that getting this out in the open on this mailing list
is an excellent step forward.

- Bryan
http://heybryan.org/
1 512 203 0507



From gmaxwell at gmail.com  Thu May  7 00:37:54 2015
From: gmaxwell at gmail.com (Gregory Maxwell)
Date: Thu, 7 May 2015 00:37:54 +0000
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554A91BE.6060105@bluematt.me>
References: <554A91BE.6060105@bluematt.me>
Message-ID: <CAAS2fgSGb2eNpDO=wwv5xqvHqhyXvhXZdRM0FkoVy96bF8D4mw@mail.gmail.com>

On Wed, May 6, 2015 at 10:12 PM, Matt Corallo <bitcoin-list at bluematt.me>
wrote: > Recently there has been a flurry of posts by Gavin at >
http://gavinandresen.svbtle.com/ which advocate strongly for increasing >
the maximum block size. However, there hasnt been any discussion on this >
mailing list in several years as far as I can tell.

Thanks Matt; I was actually really confused by this sudden push with
not a word here or on Github--so much so that I responded on Reddit to
people pointing to commits in Gavin's personal repository saying they
were reading too much into it.

So please forgive me for the more than typical disorganization in this
message; I've been caught a bit flatfooted on this and I'm trying to
catch up. I'm juggling a fair amount of sudden pressure in my mailbox,
and trying to navigate complex discussions in about eight different
forums concurrently.

There have been about a kazillion pages of discussion elsewhere
(e.g. public IRC and Bitcointalk; private discussions in the past),
not all of which is well known, and I can't hope to summarize even a
tiny fraction of it in a single message-- but that's no reason to not
start on it.

> Block size is a question to which there is no answer, but which >
certainly has a LOT of technical tradeoffs to consider.

There are several orthogonal angles from which block size is a concern
(both increases and non-increases). Most of them have subtle implications
and each are worth its own research paper or six, so it can be difficult
to only touch them slightly without creating a gish gallop that is hard
to respond to.

We're talking about tuning one of the fundamental scarcities of the
Bitcoin Economy and cryptosystem--leaving the comfort of "rule by
math" and venturing into the space of political decisions; elsewhere
you'd expect to see really in-depth neutral analysis of the risks and
tradeoffs, technically and economically.  And make no mistake: there
are real tradeoffs here, though we don't know their exact contours.

Fundamentally this question exposes ideological differences between people
interested in Bitcoin.  Is Bitcoin more of a digital gold or is it more
of a competitor to Square?  Is Bitcoin something that should improve
personal and commercial autonomy from central banks?  From commercial
banks? Or from just the existing status-quo commercial banks?   What are
people's fundamental rights with Bitcoin?  Do participants have a
right to mine? How much control should third parties have over their
transactions?  How much security must be provided? Is there a deadline
for world domination or bust?  Is Bitcoin only for the developed world?
Must it be totally limited by the most impoverished parts of the world?

Bitcoin exists at the intersection of many somewhat overlapping belief
systems--and people of many views can find that Bitcoin meets their
needs even when they don't completely agree politically.  When Bitcoin
is changed fundamentally, via a hard fork, to have different properties,
the change can create winners or losers (if nothing else, then in terms
of the kind of ideology supported by it).

There are non-trivial number of people who hold extremes on any of
these general belief patterns; Even among the core developers there is
not a consensus on Bitcoin's optimal role in society and the commercial
marketplace.

To make it clear how broad the views go, even without getting into
monetary policy... some people even argue that Bitcoin should act
as censor-resistant storage system for outlawed content; -- I think
this view is unsound, not achievable with the technology, and largely
incompatible with Bitcoin's use as a money (because it potentially
creates an externalized legal/harassment liability for node operators);
but these are my personal value judgments; the view is earnestly held
by more than a few; and that's a group that certainly wants the largest
possible blocksizes (though even then that won't be enough).

The subject is complicated even more purely on the technical side
by the fact that Bitcoin has a layered security model which is not
completely defined or understood: Bitcoin is secure if a majority of
hashrate is "honest" (where "honesty" is a technical term which means
"follows the right rules" without fail, even at a loss), but why might
it be honest? That sends us into complex economic and social arguments,
and the security thresholds start becoming worse when we assume some
miners are economically rational instead of "honest".

> increase in the near future. Long-term incentive compatibility requires
> that there be some fee pressure, and that blocks be relatively >
consistently full or very nearly full. What we see today are

To elaborate, in my view there is a at least a two fold concern on this
particular ("Long term Mining incentives") front:

One is that the long-held argument is that security of the Bitcoin system
in the long term depends on fee income funding autonomous, anonymous,
decentralized miners profitably applying enough hash-power to make
reorganizations infeasible.

For fees to achieve this purpose, there seemingly must be an effective
scarcity of capacity.  The fact that verifying and transmitting
transactions has a cost isn't enough, because all the funds go to pay
that cost and none to the POW "artificial" cost; e.g., if verification
costs 1 then the market price for fees should converge to 1, and POW
cost will converge towards zero because they adapt to whatever is
being applied. Moreover, the transmission and verification costs can
be perfectly amortized by using large centralized pools (and efficient
differential block transmission like the "O(1)" idea) as you can verify
one time instead of N times, so to the extent that verification/bandwidth
is a non-negligible cost to miners at all, it's a strong pressure to
centralize.  You can understand this intuitively: think for example of
carbon credit cap-and-trade: the trade part doesn't work without an
actual cap; if everyone was born with a 1000 petaton carbon balance,
the market price for credits would be zero and the program couldn't hope
to share behavior. In the case of mining, we're trying to optimize the
social good of POW security. (But the analogy applies in other ways too:
increases to the chain side are largely an externality; miners enjoy the
benefits, everyone else takes the costs--either in reduced security or
higher node operating else.)

This area has been subject to a small amount of academic research
(e.g. http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2400519). But
there is still much that is unclear.

The second is that when subsidy has fallen well below fees, the incentive
to move the blockchain forward goes away.  An optimal rational miner
would be best off forking off the current best block in order to capture
its fees, rather than moving the blockchain forward, until they hit
the maximum. That's where the "backlog" comment comes from, since when
there is a sufficient backlog it's better to go forward.  I'm not aware
of specific research into this subquestion; it's somewhat fuzzy because
of uncertainty about the security model. If we try to say that Bitcoin
should work even in the face of most miners being profit-maximizing
instead of altruistically-honest, we must assume the chain will not
more forward so long as a block isn't full.  In reality there is more
altruism than zero; there are public pressures; there is laziness, etc.

One potential argument is that maybe miners would be _regulated_ to
behave correctly. But this would require undermining the openness of the
system--where anyone can mine anonymously--in order to enforce behavior,
and that same enforcement mechanism would leave a political level to
impose additional rules that violate the extra properties of the system.

So far the mining ecosystem has become incredibly centralized over time.
I believe I am the only remaining committer who mines, and only a few
of the regular contributors to Bitcoin Core do. Many participants
have never mined or only did back in 2010/2011... we've basically
ignored the mining ecosystem, and this has had devastating effects,
causing a latent undermining of the security model: hacking a dozen or
so computers--operated under totally unknown and probably not strong
security policies--could compromise the network at least at the tip...
Rightfully we should be regarding this an an emergency, and probably
should have been have since 2011.  This doesn't bode well for our ability
to respond if a larger blocksize goes poorly. In kicking the can with
the trivial change to just bump the size, are we making an implicit
decision to go down a path that has a conclusion we don't want?

(There are also shorter term mining incentives concerns; which Peter
Todd has written more about, that I'll omit for now)

> pretending these systems scale. Thus, instead of working on technologies
> which bring Bitcoin's trustlessness to systems which scale beyond a

I made a few relevant points back in 2011
(https://en.bitcoin.it/w/index.php?title=Scalability&action=historysubmit&diff=14273&oldid=14112)
after Dan Kaminsky argued that Bitcoin's decentralization was pretext:
that it was patently centralized since scaling directly in the network
would undermine decentralization, that the Bitcoin network necessarily
makes particular tradeoffs which prevent it from concurrently being all
things to all people.  But tools like the Lightning network proposal could
well allow us to hit a greater spectrum of demands at once--including
secure zero-confirmation (something that larger blocksizes reduce if
anything), which is important for many applications.  With the right
technology I believe we can have our cake and eat it too, but there needs
to be a reason to build it; the security and decentralization level of
Bitcoin imposes a _hard_ upper limit on anything that can be based on it.

Another key point here is that the small bumps in blocksize which
wouldn't clearly knock the system into a largely centralized mode--small
constants--are small enough that they don't quantitatively change the
operation of the system; they don't open up new applications that aren't
possible today. Deathandtaxes on the forum argued that Bitcoin needs
a several hundred megabyte blocksize to directly meet the worldwide
transaction needs _without retail_... Why without retail? Retail needs
near instant soft security, which cannot be achieved directly with a
global decentralized blockchain.

I don't think 1MB is magic; it always exists relative to widely-deployed
technology, sociology, and economics. But these factors aren't a simple
function; the procedure I'd prefer would be something like this: if there
is a standing backlog, we-the-community of users look to indicators to
gauge if the network is losing decentralization and then double the
hard limit with proper controls to allow smooth adjustment without
fees going to zero (see the past proposals for automatic block size
controls that let miners increase up to a hard maximum over the median
if they mine at quadratically harder difficulty), and we don't increase
if it appears it would be at a substantial increase in centralization
risk. Hardfork changes should only be made if they're almost completely
uncontroversial--where virtually everyone can look at the available data
and say "yea, that isn't undermining my property rights or future use
of Bitcoin; it's no big deal".  Unfortunately, every indicator I can
think of except fee totals has been going in the wrong direction almost
monotonically along with the blockchain size increase since 2012 when
we started hitting full blocks and responded by increasing the default
soft target.  This is frustrating; from a clean slate analysis of network
health I think my conclusion would be to _decrease_ the limit below the
current 300k/txn/day level.

This is obviously not acceptable, so instead many people--myself
included--have been working feverishly hard behind the scenes on Bitcoin
Core to increase the scalability.  This work isn't small-potatoes
boring software engineering stuff; I mean even my personal contributions
include things like inventing a wholly new generic algebraic optimization
applicable to all EC signature schemes that increases performance by 4%,
and that is before getting into the R&D stuff that hasn't really borne
fruit yet, like fraud proofs.  Today Bitcoin Core is easily >100 times
faster to synchronize and relay than when I first got involved on the
same hardware, but these improvements have been swallowed by the growth.
The ironic thing is that our frantic efforts to keep ahead and not
lose decentralization have both not been enough (by the best measures,
full node usage is the lowest its been since 2011 even though the user
base is huge now) and yet also so much that people could seriously talk
about increasing the block size to something gigantic like 20MB. This
sounds less reasonable when you realize that even at 1MB we'd likely
have a smoking hole in the ground if not for existing enormous efforts
to make scaling not come at a loss of decentralization.


I'm curious as to what discussions people have seen; e.g., are people
even here aware of these concerns? Are you aware of things like the
hashcash mediated dynamic blocksize limiting?  About proposals like
lightning network (instant transactions and massive scale, in exchange
for some short term DOS risk if a counterparty opts out)?   Do people
(other than Mike Hearn; I guess) think a future where everyone depends
on a small number of "Google scale" node operations for the system is
actually okay? (I think not, and if so we're never going to agree--but
it can be helpful to understand when a disagreement is ideological).



From pete at petertodd.org  Thu May  7 01:49:52 2015
From: pete at petertodd.org (Peter Todd)
Date: Wed, 6 May 2015 21:49:52 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554A91BE.6060105@bluematt.me>
References: <554A91BE.6060105@bluematt.me>
Message-ID: <20150507014952.GA5657@savin.petertodd.org>

On Wed, May 06, 2015 at 10:12:14PM +0000, Matt Corallo wrote:
> Personally, I'm rather strongly against any commitment to a block size
> increase in the near future. Long-term incentive compatibility requires
> that there be some fee pressure, and that blocks be relatively
> consistently full or very nearly full. What we see today are
> transactions enjoying next-block confirmations with nearly zero pressure
> to include any fee at all (though many do because it makes wallet code
> simpler).

Agreed.

I'm not sure if you've seen this, but a good paper on this topic was
published recently: "The Economics of Bitcoin Transaction Fees"

    Abstract
    --------

    We study the economics of Bitcoin transaction fees in a simple static
    partial equilibrium model with the specificity that the system security
    is directly linked to the total computational power of miners. We show
    that any situation with a fixed fee is equivalent to another situation
    with a limited block size. In both cases, we give the optimal value of
    the transaction fee or of the block size. We also show that making the
    block size a non binding constraint and, in the same time, letting the
    fee be fixed as the outcome of a decentralized competitive market cannot
    guarantee the very existence of Bitcoin in the long-term.

-http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2400519

In short, without either a fixed blocksize or fixed fee per transaction
Bitcoin will will not survive as there is no viable way to pay for PoW
security. The latter option - fixed fee per transaction - is non-trivial
to implement in a way that's actually meaningful - it's easy to give
miners "kickbacks" - leaving us with a fixed blocksize.

> This allows the well-funded Bitcoin ecosystem to continue building
> systems which rely on transactions moving quickly into blocks while
> pretending these systems scale. Thus, instead of working on technologies

I think this lack of understanding of the limitations of blockchain tech
is very dangerous, never mind, downright misleading. I keep running into
startups at conferences with completely unrealistic ideas about how
large they'll be able to grow their on-blockchain businesses. For
example, a few weeks ago at the Stanford blockchain conference I spoke
to a company planning on using multisig escrow contracts to settle
financial instruments, and expected to be doing about as many
transactions/day on the blockchain for their business within a year or
so as all other Bitcoin users currently do combined. These guys quite
frankly had no understanding of the issues, and had apparently based
their plans on the highly optimistic Bitcoin wiki page on
scalability.(1) (I'd fix this now, but the wiki seems to not be allowing
logins)

We'd do a lot of startups a lot of good to give them accurate, and
honest, advice about the scalability of the system. The wiki definitely
isn't that. Neither is the bitcoin.org developer documentation(2), which
doesn't mention scalability at all.

> which bring Bitcoin's trustlessness to systems which scale beyond a
> blockchain's necessarily slow and (compared to updating numbers in a
> database) expensive settlement, the ecosystem as a whole continues to
> focus on building centralized platforms and advocate for changes to
> Bitcoin which allow them to maintain the status quo[1].

Even a relatively small increase to 20MB will greatly reduce the number
of people who can participate fully in Bitcoin, creating an environment
where the next increase requires the consent of an even smaller portion
of the Bitcoin ecosystem. Where does that stop? What's the proposed
mechanism that'll create an incentive and social consensus to not just
'kick the can down the road'(3) and further centralize but actually
scale up Bitcoin the hard way? The only proposal that I've seen that
attempts to do this is John Dillon's proof-of-stake blocksize vote(4),
and that is far from getting consensus.

1) https://en.bitcoin.it/wiki/Scalability
2) https://bitcoin.org/en/developer-guide
3) http://gavinandresen.ninja/it-must-be-done-but-is-not-a-panacea
4) http://www.mail-archive.com/bitcoin-development at lists.sourceforge.net/msg02323.html

-- 
'peter'[:-1]@petertodd.org
000000000000000004dc867e4541315090329f45ed4dd30e2fd7423a38a72c0e
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150506/113bc44d/attachment.sig>

From pete at petertodd.org  Thu May  7 02:16:44 2015
From: pete at petertodd.org (Peter Todd)
Date: Wed, 6 May 2015 22:16:44 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554AA6B1.8030701@bluematt.me>
References: <554A91BE.6060105@bluematt.me>
	<CAE-z3OXnjayLUeHBU0hdwU5pKrJ6fpj7YPtGBMQ7hKXG3Sj6hw@mail.gmail.com>
	<554A9FD1.80103@bluematt.me>
	<CAE-z3OUCHr9KK_GE2iATu5zWxbXBF5Rvt8mvKJ=rjD3NsDDcOQ@mail.gmail.com>
	<554AA6B1.8030701@bluematt.me>
Message-ID: <20150507021644.GA21742@savin.petertodd.org>

On Wed, May 06, 2015 at 11:41:37PM +0000, Matt Corallo wrote:
> Yes, but this does NOT make an actual policy. Note that the vast
> majority of miners already apply their own patches to Bitcoin Core, so
> applying one more is not all that hard. When blocks start to become
> limited (ie there is any fee left on the table by transactions not
> included in a block) there becomes incentive for miners to change that
> behavior pretty quick. Not just that, the vast majority of the hashpower
> is behind very large miners, who have little to no decentralization
> pressure. This results in very incompatible incentives, mainly that the
> incentive would be for the large miners to interconnect in a private
> network and generate only maximum-size blocks, creating a strong
> centralization pressure in the network.

I'll also point out that miners with the goal of finding more blocks
than their competition - a viable long-term strategy to increase market
share and/or a short-term strategy to get more transaction fees -
actually have a perverse incentive(1) to ensure their blocks do *not*
get to more than ~30% of the hashing power. The main thing holding them
back from doing that is that the inflation subsidy is still quite high -
better to get the reward now than try to push your competition out of
business.

It's plausible that with a limited blocksize there won't be an
opportunity to delay propagation by broadcasting larger blocks - if
blocks propagate in a matter of seconds worst case there's no
opportunity for gaming the system. But it does strongly show that we
must build systems where that worst case propagation time in all
circumstances is very short relative to the block interval.

1) http://www.mail-archive.com/bitcoin-development at lists.sourceforge.net/msg03200.html

-- 
'peter'[:-1]@petertodd.org
000000000000000004dc867e4541315090329f45ed4dd30e2fd7423a38a72c0e
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150506/1e8954f8/attachment.sig>

From justusranvier at riseup.net  Thu May  7 03:03:47 2015
From: justusranvier at riseup.net (Justus Ranvier)
Date: Thu, 07 May 2015 05:03:47 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <20150507014952.GA5657@savin.petertodd.org>
References: <554A91BE.6060105@bluematt.me>
	<20150507014952.GA5657@savin.petertodd.org>
Message-ID: <554AD613.6000606@localhost.local>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 05/07/2015 03:49 AM, Peter Todd wrote:
> I'm not sure if you've seen this, but a good paper on this topic
> was published recently: "The Economics of Bitcoin Transaction
> Fees"

..for some very strange definitions of "good".

That paper may present valid game theory, yet game theory has a
well-known limitation when it comes to predicting real world behavior
in that the predictions are only as good as the simplified model those
predictions are based on is accurate.

At the very least, we should wait to draw any conclusions from that
paper until it has been sanity checked by a praxeological review.
-----BEGIN PGP SIGNATURE-----

iQIcBAEBAgAGBQJVStYTAAoJECpf2nDq2eYjqzAQAJkLwVq3cJxaP5MirS6j+SkN
NuRIQS8EzJkvojZvHCSRz3xPZpl9Cx2T6/hsLjIfzvMuDHKsaOkkLlL0q95ekv4T
acfami64326DFAxiO0ptspPjCRipagmjSEwZGZwC/QZtTdnt+N9LsH0SFDP6hxbY
Kf11LRd11Ap4v/VnBg/zb4daZnVm0k0nfZxK4rG1zN14r5JEu6eiodUBZc6e4qih
LmopoddIwJS4MY1GoR2kCehAbJseZZyQQmHFEX1Vhc74ETGXWApfgF0tpo6ZMutd
OT0WGhCpj4yG1u5bRaiNnsOy9WcBTKzDOLZUVVh/GhUGHWUulZu8ujYrX7Q6GR5S
VPvOOL6Ts/RGEAE1UWKzHfPjrLZAHKgLAzBjm6o1ZXdBcnV+FsThNvd7fxHvaJsO
pWGSu8qDmN/wH657Tphbthb4T/awnuf4rO6oBP+OGu+ydPIlIlt6rM2E4Bq366yy
CJbzSR3x/P7fRmT2bbSg4rxTDyLFJpNIWOcNaMRBeO69OdNZxlranvFvEl/6FfqK
GO/LPQiYCe/+yhXgUJzzlYpayPiPFWCg0FxwQ+xl1josTsrfPE4BUivkZvIlqOIY
LX1fDHt/IIUNp8OUkY2eERxeB//dlY55nP7VGUEJLNnBkXuoBd70lMtGXxtgvw2M
Wy5VER9CiEOUMMwzWi3Q
=8mit
-----END PGP SIGNATURE-----
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0xEAD9E623.asc
Type: application/pgp-keys
Size: 18381 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/7528c1aa/attachment.bin>

From pieter.wuille at gmail.com  Thu May  7 03:47:16 2015
From: pieter.wuille at gmail.com (Pieter Wuille)
Date: Thu, 7 May 2015 05:47:16 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554A91BE.6060105@bluematt.me>
References: <554A91BE.6060105@bluematt.me>
Message-ID: <CAPg+sBgKqsb7NRj4kxbqkbhJac12GeOMY-oJbZyS1zZMuDhA4g@mail.gmail.com>

On Thu, May 7, 2015 at 12:12 AM, Matt Corallo <bitcoin-list at bluematt.me>
wrote:

> Recently there has been a flurry of posts by Gavin at
> http://gavinandresen.svbtle.com/ which advocate strongly for increasing
> the maximum block size. However, there hasnt been any discussion on this
> mailing list in several years as far as I can tell.
>

Thanks for bringing this up. I'll try to keep my arguments brief, to avoid
a long wall of text. I may be re-iterating some things that have been said
before, though.

I am - in general - in favor of increasing the size blocks: as technology
grows, there is no reason why the systems built on them can't scale
proportionally. I have so far not commented much about this, in a hope to
avoid getting into a public debate, but the way seems to be going now,
worries me greatly.

* Controversial hard forks. I hope the mailing list here today already
proves it is a controversial issue. Independent of personal opinions pro or
against, I don't think we can do a hard fork that is controversial in
nature. Either the result is effectively a fork, and pre-existing coins can
be spent once on both sides (effectively failing Bitcoin's primary
purpose), or the result is one side forced to upgrade to something they
dislike - effectively giving a power to developers they should never have.
Quoting someone: "I did not sign up to be part of a central banker's
committee".

* The reason for increasing is "need". If "we need more space in blocks" is
the reason to do an upgrade, it won't stop after 20 MB. There is nothing
fundamental possible with 20 MB blocks that isn't with 1 MB blocks.
Changetip does not put their microtransactions on the chain, not with 1 MB,
and I doubt they would with 20 MB blocks. The reason for increase should be
"because we choose to accept the trade-offs".

* Misrepresentation of the trade-offs. You can argue all you want that none
of the effects of larger blocks are particularly damaging, so everything is
fine. They will damage something (see below for details), and we should
analyze these effects, and be honest about them, and present them as a
trade-off made we choose to make to scale the system better. If you just
ask people if they want more transactions, of course you'll hear yes. If
you ask people if they want to pay less taxes, I'm sure the vast majority
will agree as well.

* Miner centralization. There is currently, as far as I know, no technology
that can relay and validate 20 MB blocks across the planet, in a manner
fast enough to avoid very significant costs to mining. There is work in
progress on this (including Gavin's IBLT-based relay, or Greg's block
network coding), but I don't think we should be basing the future of the
economics of the system on undemonstrated ideas. Without those (or even
with), the result may be that miners self-limit the size of their blocks to
propagate faster, but if this happens, larger, better-connected, and more
centrally-located groups of miners gain a competitive advantage by being
able to produce larger blocks. I would like to point out that there is
nothing evil about this - a simple feedback to determine an optimal block
size for an individual miner will result in larger blocks for better
connected hash power. If we do not want miners to have this ability, "we"
(as in: those using full nodes) should demand limitations that prevent it.
One such limitation is a block size limit (whatever it is).

* Ability to use a full node. I very much dislike the trend of people
saying "we need to encourage people to run full nodes, in order to make the
network more decentralized". Running 1000 nodes which are otherwise unused
only gives some better ability for full nodes to download the block chain,
or for SPV nodes to learn about transactions (or be Sybil-attacked...).
However, *using* a full node for validating your business (or personal!)
transactions empowers you to using a financial system that requires less
trust in *anyone* (not even in a decentralized group of peers) than
anything else. Moreover, using a full node is what given you power of the
systems' rules, as anyone who wants to change it now needs to convince you
to upgrade. And yes, 20 MB blocks will change people's ability to use full
nodes, even if the costs are small.

* Skewed incentives for improvements. I think I can personally say that I'm
responsible for most of the past years' performance improvements in Bitcoin
Core. And there is a lot of room for improvement left there - things like
silly waiting loops, single-threaded network processing, huge memory sinks,
lock contention, ... which in my opinion don't nearly get the attention
they deserve. This is in addition to more pervasive changes like optimizing
the block transfer protocol, support for orthogonal systems with a
different security/scalability trade-off like Lightning, making full
validation optional, ... Call me cynical, but without actual pressure to
work on these, I doubt much will change. Increasing the size of blocks now
will simply make it cheap enough to continue business as usual for a while
- while forcing a massive cost increase (and not just a monetary one) on
the entire ecosystem.

* Fees and long-term incentives. I put this last, not because I don't think
it is not serious, but because I don't understand nearly enough about it.
I'll let others comment.

I don't think 1 MB is optimal. Block size is a compromise between
scalability of transactions and verifiability of the system. A system with
10 transactions per day that is verifiable by a pocket calculator is not
useful, as it would only serve a few large bank's settlements. A system
which can deal with every coffee bought on the planet, but requires a
Google-scale data center to verify is also not useful, as it would be
trivially out-competed by a VISA-like design. The usefulness needs in a
balance, and there is no optimal choice for everyone. We can choose where
that balance lies, but we must accept that this is done as a trade-off, and
that that trade-off will have costs such as hardware costs, decreasing
anonymity, less independence, smaller target audience for people able to
fully validate, ...

Choose wisely.

Thanks for reading this,

-- 
Pieter
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/29c77115/attachment.html>

From mike at plan99.net  Thu May  7 09:25:04 2015
From: mike at plan99.net (Mike Hearn)
Date: Thu, 7 May 2015 11:25:04 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554A91BE.6060105@bluematt.me>
References: <554A91BE.6060105@bluematt.me>
Message-ID: <CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>

Hey Matt,

OK, let's get started ....

However, there hasnt been any discussion on this
> mailing list in several years as far as I can tell.
>

Probably because this list is not a good place for making progress or
reaching decisions. Those are triggered by pull requests (sometimes).

If you're wondering "why now", that's probably my fault. A few days ago
Wladimir posted a release timeline. I observed to Wladimir and Gavin in
private that this timeline meant a change to the block size was unlikely to
get into 0.11, leaving only 0.12, which would give everyone only a few
months to upgrade in order to fork the chain by the end of the winter
growth season. That seemed tight.

Wladimir did not reply to this email, unfortunately. Perhaps he would like
the issue to go away. It won't - if Bitcoin continues on its current growth
trends it *will* run out of capacity, almost certainly by some time next
year.

What we need to see right now is leadership and a plan, that fits in the
available time window.


> Certainly a consensus in this kind of technical community should be a
> basic requirement for any serious commitment to blocksize increase.
>

I'm afraid I have come to disagree. I no longer believe this community can
reach consensus on anything protocol related. Some of these arguments have
dragged on for years. Consensus isn't even well defined - consensus of who?
Anyone who shows up? And what happens when, inevitably, no consensus is
reached? Stasis forever?


> Long-term incentive compatibility requires that there be some fee
> pressure, and that blocks be relatively consistently full or very nearly
> full.


I disagree. When the money supply eventually dwindles I doubt it will be
fee pressure that funds mining, but as that's a long time in the future,
it's very hard to predict what might happen.


> What we see today are
> transactions enjoying next-block confirmations with nearly zero pressure
> to include any fee at all (though many do because it makes wallet code
> simpler).
>

Many do because free transactions are broken - the relay limiter means
whether a free transaction actually makes it across the network or not is
basically pot luck and there's no way for a wallet to know, short of either
trying it or actually receiving every single transaction and repeating the
calculations. If free transactions weren't broken for all non-full nodes
they'd probably be used a lot more.


> This allows the well-funded Bitcoin ecosystem to continue building
> systems which rely on transactions moving quickly into blocks while
> pretending these systems scale.


I have two huge problems with this line of thinking.

Firstly, no, the "Bitcoin ecosystem" is not well funded. Blockstream might
be, but significant numbers of users are running programs developed by tiny
startups, or volunteers who don't have millions in venture capital to play
with.

Arm-twisting "the ecosystem" into developing complicated Rube Goldberg
machines in double quick time, just to keep the Bitcoin show on the road,
is in fact the opposite of decentralisation - it will effectively exclude
anyone who isn't able to raise large amounts of corporate funding from
writing code that uses the Bitcoin network. Decentralisation benefits from
simplicity, and bigger blocks are (in Gavin's words) "the simplest thing
that will work".

My second problem is the claim that everyone is playing pretend about
Bitcoin, except you guys. I would put it another way - I would say those
people are building products and getting users, by making reasonable
engineering tradeoffs and using systems that work. Yes, one day those
systems might have to change. That's the nature of scaling. It's the nature
of progress. But not today. Probably not tomorrow either.

What I would like to see from Blockstream is a counter-proposal. So far you
have made lots of vague comments that we all agree with - yes,
decentralisation is good, yes some block size limit must exist, if only
because computers are finite machines.

What I don't see from you yet is a *specific and credible plan* that fits
within the next 12 months and which allows Bitcoin to keep growing. Not
some vague handwave like "let's all use the Lightning network" (which does
not exist), or "let's do more research" (Gavin has done plenty of
research), or "but what about the risks" (Bitcoin is full of risks). A
plan, with dates attached, and a strong chance of actually being deployed
in time.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/81942b17/attachment.html>

From pete at petertodd.org  Thu May  7 10:12:50 2015
From: pete at petertodd.org (Peter Todd)
Date: Thu, 7 May 2015 06:12:50 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
Message-ID: <20150507101250.GA19538@savin.petertodd.org>

On Thu, May 07, 2015 at 11:25:04AM +0200, Mike Hearn wrote:
> > Certainly a consensus in this kind of technical community should be a
> > basic requirement for any serious commitment to blocksize increase.
> >
> 
> I'm afraid I have come to disagree. I no longer believe this community can
> reach consensus on anything protocol related. Some of these arguments have
> dragged on for years. Consensus isn't even well defined - consensus of who?
> Anyone who shows up? And what happens when, inevitably, no consensus is
> reached? Stasis forever?

Care to be specific?

We've made lots of protocol related changes, as well as non-consensus
policy changes, often in quite short timeframes, and with little drama.
For instance BIP66 adopting is progressing smoothly, and itself was very
quickly developed as part of a broader response to a serious OpenSSL
flaw. My own BIP65 is getting wide consensus with little drama and good
peer review, and that's happening even without as much attention paid to
it from myself as I should have been giving it. The BIP62 malleability
softfork is going more slowly, but that's because peer review is finding
issues and fixing them - something to be expected in an environment
where we simply must be cautious.

As for the v0.11 release, it will have pruning, perhaps the biggest
change to the way Bitcoin Core works that we've ever made. Equally it's
notable how many people collaborated on the implementation of pruning,
again with little drama.

Sure, some stuff has been hard to get consensus on. But those things
carry high risks, and involve code and practices known to be dangerous.
In most cases we've found out the lack of consensus was spot on, and
controversial changes turn out later to have severe security
vulnerabilities. I read that as a sign that the peer review and
consensus building process works just fine.

-- 
'peter'[:-1]@petertodd.org
00000000000000000af0c4ba9d91c00d48c4493899d7235fd819ac76f16d148d
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/9dc82f9c/attachment.sig>

From btcdrak at gmail.com  Thu May  7 10:42:19 2015
From: btcdrak at gmail.com (Btc Drak)
Date: Thu, 7 May 2015 11:42:19 +0100
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
Message-ID: <CADJgMzsCyHm7DZhSqq1OTujz+0U9Dzj2jNEKsOn3Jj0noMCKpg@mail.gmail.com>

On Thu, May 7, 2015 at 10:25 AM, Mike Hearn <mike at plan99.net> wrote:

> What I don't see from you yet is a *specific and credible plan* that fits
> within the next 12 months and which allows Bitcoin to keep growing. Not
> some vague handwave like "let's all use the Lightning network" (which does
> not exist), or "let's do more research" (Gavin has done plenty of
> research), or "but what about the risks" (Bitcoin is full of risks). A
> plan, with dates attached, and a strong chance of actually being deployed
> in time.
>

Would you please explain where this 12 months timeframe comes from?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/55cd10b4/attachment.html>

From jtimon at jtimon.cc  Thu May  7 10:52:26 2015
From: jtimon at jtimon.cc (=?UTF-8?B?Sm9yZ2UgVGltw7Nu?=)
Date: Thu, 7 May 2015 12:52:26 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
Message-ID: <CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>

On Thu, May 7, 2015 at 11:25 AM, Mike Hearn <mike at plan99.net> wrote:
> I observed to Wladimir and Gavin in private that this timeline meant a change to the block size was unlikely to get into 0.11, leaving only 0.12, which would give everyone only a few months to upgrade in order to fork the chain by the end of the winter growth season. That seemed tight.

Can you please elaborate on what terrible things will happen if we
don't increase the block size by winter this year?
I assume that you are expecting full blocks by then, have you used any
statistical technique to come up with that date or is it just your
guess?
Because I love wild guesses and mine is that full 1 MB blocks will not
happen until June 2017.

> What we need to see right now is leadership and a plan, that fits in the
> available time window.
>
>>
>> Certainly a consensus in this kind of technical community should be a
>> basic requirement for any serious commitment to blocksize increase.
>
>
> I'm afraid I have come to disagree. I no longer believe this community can
> reach consensus on anything protocol related. Some of these arguments have
> dragged on for years. Consensus isn't even well defined - consensus of who?
> Anyone who shows up? And what happens when, inevitably, no consensus is
> reached? Stasis forever?

We've successfully reached consensus for several softfork proposals already.
I agree with others that hardfork need to be uncontroversial and there
should be consensus about them.
If you have other ideas for the criteria for hardfork deployment all I'm ears.
I just hope that by  "What we need to see right now is leadership" you
don't mean something like "when Gaving and Mike agree it's enough to
deploy a hardfork" when you go from vague to concrete.


>> Long-term incentive compatibility requires that there be some fee
>> pressure, and that blocks be relatively consistently full or very nearly
>> full.
>
>
> I disagree. When the money supply eventually dwindles I doubt it will be fee
> pressure that funds mining, but as that's a long time in the future, it's
> very hard to predict what might happen.

Oh, so your answer to "bitcoin will eventually need to live on fees
and we would like to know more about how it will look like then" it's
"no bitcoin long term it's broken long term but that's far away in the
future so let's just worry about the present".
I agree that it's hard to predict that future, but having some
competition for block space would actually help us get more data on a
similar situation to be able to predict that future better.
What you want to avoid at all cost (the block size actually being
used), I see as the best opportunity we have to look into the future.

>> What we see today are
>> transactions enjoying next-block confirmations with nearly zero pressure
>> to include any fee at all (though many do because it makes wallet code
>> simpler).
>
>
> Many do because free transactions are broken - the relay limiter means
> whether a free transaction actually makes it across the network or not is
> basically pot luck and there's no way for a wallet to know, short of either
> trying it or actually receiving every single transaction and repeating the
> calculations. If free transactions weren't broken for all non-full nodes
> they'd probably be used a lot more.

Free transactions are a gift from miners that run an altruistic policy.
That's great but we shouldn't rely on them for the future. They will
likely disappear at some point and that's ok.
In any case, he's not complaining about the lack of free transactions,
more like the opposite.
He is saying that's very easy to get free transactions in the next
block and blocks aren't full so there's no incentive to include fees
to compete for the space.
We can talk a lot about "a fee market" and build a theoretically
perfect fee estimator but we won't actually have a fee market until
there's some competition for space.
Nobody will pay for space that's abundant just like people don't pay
for the air they breath.

> What I don't see from you yet is a specific and credible plan that fits
> within the next 12 months and which allows Bitcoin to keep growing. Not some
> vague handwave like "let's all use the Lightning network" (which does not
> exist), or "let's do more research" (Gavin has done plenty of research), or
> "but what about the risks" (Bitcoin is full of risks). A plan, with dates
> attached, and a strong chance of actually being deployed in time.

Ok, this is my plan: we wait 12 months, hope that your estimations are
correct (in case that my guess was better than yours, we keep waiting
until June 2017) and start having full blocks and people having to
wait 2 blocks for their transactions to be confirmed some times.
That would be the beginning of a true "fee market", something that
Gavin used to say was his #1 priority not so long ago (which seems
contradictory with his current efforts to avoid that from happening).
Having a true fee market seems clearly an advantage.
What are supposedly disastrous negative parts of this plan that make
an alternative plan (ie: increasing the block size) so necessary and
obvious.
I think the advocates of the size increase are failing to explain the
disadvantages of maintaining the current size. It feels like the
explanation are missing because it should be somehow obvious how the
sky will burn if we don't increase the block size soon.
But, well, it is not obvious to me, so please elaborate on why having
a fee market (instead of just an price estimator for a market that
doesn't even really exist) would be a disaster.



From onelineproof at gmail.com  Thu May  7 11:15:57 2015
From: onelineproof at gmail.com (Andrew)
Date: Thu, 7 May 2015 11:15:57 +0000
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
Message-ID: <CAL8tG==YbM8Lv4+iW3PVO34Dcs_kJ7CMbw9koOSr7GpOYmbE=Q@mail.gmail.com>

I'm mainly just an observer on this. I mostly agree with Pieter. Also, I
think the main reason why people like Gavin and Mike Hearn are trying to
rush this through is because they have some kind of "apps" that depend on
zero conf instant transactions, so this would of course require more
traffic on the blockchain. I think people like Gavin or Mike should state
clearly what kind of (rigorous) system for instant transactions is
satisfactory for use in their applications. Be it lightning or something
similar, what is good enough? And no zero conf is not a real secure system.
Then once we know what is good enough for them (and everyone else), we can
implement it as a soft fork into the protocol, and it's a win win situation
for both sides (we can also benefit from all the new users people like Mike
are trying bring in).

On Thu, May 7, 2015 at 10:52 AM, Jorge Tim?n <jtimon at jtimon.cc> wrote:

> On Thu, May 7, 2015 at 11:25 AM, Mike Hearn <mike at plan99.net> wrote:
> > I observed to Wladimir and Gavin in private that this timeline meant a
> change to the block size was unlikely to get into 0.11, leaving only 0.12,
> which would give everyone only a few months to upgrade in order to fork the
> chain by the end of the winter growth season. That seemed tight.
>
> Can you please elaborate on what terrible things will happen if we
> don't increase the block size by winter this year?
> I assume that you are expecting full blocks by then, have you used any
> statistical technique to come up with that date or is it just your
> guess?
> Because I love wild guesses and mine is that full 1 MB blocks will not
> happen until June 2017.
>
> > What we need to see right now is leadership and a plan, that fits in the
> > available time window.
> >
> >>
> >> Certainly a consensus in this kind of technical community should be a
> >> basic requirement for any serious commitment to blocksize increase.
> >
> >
> > I'm afraid I have come to disagree. I no longer believe this community
> can
> > reach consensus on anything protocol related. Some of these arguments
> have
> > dragged on for years. Consensus isn't even well defined - consensus of
> who?
> > Anyone who shows up? And what happens when, inevitably, no consensus is
> > reached? Stasis forever?
>
> We've successfully reached consensus for several softfork proposals
> already.
> I agree with others that hardfork need to be uncontroversial and there
> should be consensus about them.
> If you have other ideas for the criteria for hardfork deployment all I'm
> ears.
> I just hope that by  "What we need to see right now is leadership" you
> don't mean something like "when Gaving and Mike agree it's enough to
> deploy a hardfork" when you go from vague to concrete.
>
>
> >> Long-term incentive compatibility requires that there be some fee
> >> pressure, and that blocks be relatively consistently full or very nearly
> >> full.
> >
> >
> > I disagree. When the money supply eventually dwindles I doubt it will be
> fee
> > pressure that funds mining, but as that's a long time in the future, it's
> > very hard to predict what might happen.
>
> Oh, so your answer to "bitcoin will eventually need to live on fees
> and we would like to know more about how it will look like then" it's
> "no bitcoin long term it's broken long term but that's far away in the
> future so let's just worry about the present".
> I agree that it's hard to predict that future, but having some
> competition for block space would actually help us get more data on a
> similar situation to be able to predict that future better.
> What you want to avoid at all cost (the block size actually being
> used), I see as the best opportunity we have to look into the future.
>
> >> What we see today are
> >> transactions enjoying next-block confirmations with nearly zero pressure
> >> to include any fee at all (though many do because it makes wallet code
> >> simpler).
> >
> >
> > Many do because free transactions are broken - the relay limiter means
> > whether a free transaction actually makes it across the network or not is
> > basically pot luck and there's no way for a wallet to know, short of
> either
> > trying it or actually receiving every single transaction and repeating
> the
> > calculations. If free transactions weren't broken for all non-full nodes
> > they'd probably be used a lot more.
>
> Free transactions are a gift from miners that run an altruistic policy.
> That's great but we shouldn't rely on them for the future. They will
> likely disappear at some point and that's ok.
> In any case, he's not complaining about the lack of free transactions,
> more like the opposite.
> He is saying that's very easy to get free transactions in the next
> block and blocks aren't full so there's no incentive to include fees
> to compete for the space.
> We can talk a lot about "a fee market" and build a theoretically
> perfect fee estimator but we won't actually have a fee market until
> there's some competition for space.
> Nobody will pay for space that's abundant just like people don't pay
> for the air they breath.
>
> > What I don't see from you yet is a specific and credible plan that fits
> > within the next 12 months and which allows Bitcoin to keep growing. Not
> some
> > vague handwave like "let's all use the Lightning network" (which does not
> > exist), or "let's do more research" (Gavin has done plenty of research),
> or
> > "but what about the risks" (Bitcoin is full of risks). A plan, with dates
> > attached, and a strong chance of actually being deployed in time.
>
> Ok, this is my plan: we wait 12 months, hope that your estimations are
> correct (in case that my guess was better than yours, we keep waiting
> until June 2017) and start having full blocks and people having to
> wait 2 blocks for their transactions to be confirmed some times.
> That would be the beginning of a true "fee market", something that
> Gavin used to say was his #1 priority not so long ago (which seems
> contradictory with his current efforts to avoid that from happening).
> Having a true fee market seems clearly an advantage.
> What are supposedly disastrous negative parts of this plan that make
> an alternative plan (ie: increasing the block size) so necessary and
> obvious.
> I think the advocates of the size increase are failing to explain the
> disadvantages of maintaining the current size. It feels like the
> explanation are missing because it should be somehow obvious how the
> sky will burn if we don't increase the block size soon.
> But, well, it is not obvious to me, so please elaborate on why having
> a fee market (instead of just an price estimator for a market that
> doesn't even really exist) would be a disaster.
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>



-- 
PGP: B6AC 822C 451D 6304 6A28  49E9 7DB7 011C D53B 5647
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/1bc393f5/attachment.html>

From laanwj at gmail.com  Thu May  7 11:20:43 2015
From: laanwj at gmail.com (Wladimir J. van der Laan)
Date: Thu, 7 May 2015 13:20:43 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554A91BE.6060105@bluematt.me>
References: <554A91BE.6060105@bluematt.me>
Message-ID: <20150507112042.GB30564@amethyst.visucore.com>

On Wed, May 06, 2015 at 10:12:14PM +0000, Matt Corallo wrote:

> Personally, I'm rather strongly against any commitment to a block size
> increase in the near future. Long-term incentive compatibility requires
> that there be some fee pressure, and that blocks be relatively
> consistently full or very nearly full. What we see today are
> transactions enjoying next-block confirmations with nearly zero pressure
> to include any fee at all (though many do because it makes wallet code
> simpler).

I'm weakly against a block size increase in the near future. Some arguments follow. For sake of brevity, this ignores the inherent practical and political issues in scheduling a hardfork.

Against:

1. The everyone-verifies-everything approach inherently doesn't scale well. Yes, it is possible to increase the capacity, within limits, without completely destroying the system, but if scaling turns out to be a success, even a 20-fold increase is just a drop in the bucket (this will not make a decentralized Changetip possible). The gain will always be linear, at a total cost that scales in the number of (full node) users times the block size. The whole idea of everyone verifying the whole world's bus tickets and coffee purchases seems ludicrous to me. For true scaling, as well as decentralized microtransactions, the community needs to work on non-centralized 'level 2' protocols for transactions, for example the Lightning network.

  I prefer not to rely on faith that 'Moore's law' - which isn't a physical law but a trend - will save us. And it doesn't so much apply to communication bandwidth as its techniques are more diverse. E.g. for Bitsat, 20MB blocks will push the limit.

2a. Pushing up bandwidth and CPU usage will, inevitably, push people at the lower end away from running their own full nodes. Mind you, the sheer number of full nodes is not the issue, but Bitcoin's security model is based on being able to verify the shared consensus on one's own. A lot of recent development effort went into making the node software less heavy. Yes, one could switch to SPV, but that is a serious privacy compromise. In the worst case people will feel forced to move to webwallets.

  That was about sustained bandwidth - syncing a new node from scratch through the internet will become unwieldy sooner - this can be worked around with UTXO snapshots, but doing this in a way that doesn't completely pull the rug under the security model needs research (I'm aware that this could be construed the other way, that such a solution will be needed eventually and fast block chain growth just accelerates it).

2b. The bandwidth bound for just downloading blocks is ~4GB per month now, it will be ~52GB per month. Behind Tor and other anonimity networks, nodes will reveal themselves by the sheer volume of data transferred even to only download the block chain. This may already be the case, but will become worse. It may even become harmful to Tor itself.

3a. The costs are effectively externalized to users. I, hence, don't like calling the costs "trivial". I don't like making this decision for others, I'm not convinced that they are trivial for everyone. Besides, this will increase supply of block chain space, and thus push down transaction fees, but at cost to *all users*, even users that hardly do any transactions. Hence it favors those that generate lots of transactions (is that a perverse incentive? not sure, but it needs to be weighted in any decision).

3b. A mounting fee pressure, resulting in a true fee market where transactions compete to get into blocks, results in urgency to develop decentralized off-chain solutions. I'm afraid increasing the block size will kick this can down the road and let people (and the large Bitcoin companies) relax, until it's again time for a block chain increase, and then they'll rally Gavin again, never resulting in a smart, sustainable solution but eternal awkward discussions like this.

4. We haven't solved the problem of arbitrary data storage, and increasing the block size would compound that problem. More data storage more storage available for the same price - and up to 20x faster growth of the UTXO set, which is permanent (more externalization). More opportunity for pedonazis to insert double-plus ungood data, exposing users to possible legal ramifications.

For:

1. First, the obvious: It gives some breathing room in a year (or whenever the hard fork is planned). If necessary, it will allow more transactions to be on-chain for a while longer while other solutions are being implemented.

2. *Allowing* 20MB blocks does not mean miners will immediately start making them. Many of them aren't even filling up to the 1MB limit right now, probably due to latency/stale block issues. This makes objection 2 milder, which is about *worst case* bandwidth, as well as 4, as the end result may not be 20MB blocks filled with arbitrary "junk".

3. Investment in off-chain solutions is guided by not only fee pressure, but also other reasons such as speed of confirmation, which is unreliable on-chain. This eases objection 3b. 

Whew, this grew longer than I expected. To conclude, I understand the advantages of scaling, I do not doubt a block size increase will *work* Although there may be unforseen issues, I'm confident they'll be resolved. However, it may well make Bitcoin less useful for what sets it apart from other systems in the first place: the possibility for people to run their own own "bank" without special investment in connectivity and computing hardware. 
Also the politics aspect (at some point it becomes a question of who decides for who? who is excluded? all those human decisions...) of this I don't like in the least. Possibly unavoidable at some point, but that's something *I*'d like to kick down the road.

Wladimir




From mike at plan99.net  Thu May  7 11:29:44 2015
From: mike at plan99.net (Mike Hearn)
Date: Thu, 7 May 2015 13:29:44 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
Message-ID: <CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>

>
> Can you please elaborate on what terrible things will happen if we
> don't increase the block size by winter this year?
>

I was referring to winter next year. 0.12 isn't scheduled until the end of
the year, according to Wladimir. I explained where this figure comes from
in this article:

https://medium.com/@octskyward/bitcoin-s-seasonal-affective-disorder-35733bab760d

It's a fairly simple estimate based on previous growth patterns.

Because I love wild guesses and mine is that full 1 MB blocks will not
> happen until June 2017.
>

OK, it could be. But do you think this debate will play out significantly
differently if you are right, I am wrong, and we have this discussion next
summer instead? Because in several years of watching these debates, I
haven't seen much change in them.


> We've successfully reached consensus for several softfork proposals
> already.
>

Are you sure about that?

What if Gavin popped up right now and said he disagreed with every current
proposal, he disagreed with side chains too, and there would be no
consensus on any of them until the block size limit was raised.

Would you say, oh, OK, guess that's it then. There's no consensus so might
as well scrap all those proposals, as they'll never happen anyway. Bye bye
side chains whitepaper.



> I just hope that by  "What we need to see right now is leadership" you
> don't mean something like "when Gaving and Mike agree it's enough to
> deploy a hardfork" when you go from vague to concrete.
>

No. What I meant is that someone (theoretically Wladimir) needs to make a
clear decision. If that decision is "Bitcoin Core will wait and watch the
fireworks when blocks get full", that would be showing leadership .....
albeit I believe in the wrong direction. It would, however, let people know
what's what and let them start to make longer term plans.

This dillydallying around is an issue - people just make vague points that
can't really be disagreed with (more nodes would be nice, smaller pools
would also be nice etc), and nothing gets done.


> "no bitcoin long term it's broken long term but that's far away in the
> future so let's just worry about the present".
>

I never said Bitcoin is broken in the long term. Far from it - I laid out
my ideas for what will happen when the block subsidy dwindles years ago.

But yes, it's hard for me to care overly much about what happens 30 years
from now, for the same reason you probably care more about what happens
tomorrow than what happens after you are dead. The further into the future
you try and plan, the less likely your plans are to survive unscathed.


> What you want to avoid at all cost (the block size actually being
> used), I see as the best opportunity we have to look into the future.
>

I think I see one of the causes of disagreement now.

I will write more on the topic of what will happen if we hit the block size
limit soon, maybe this evening. I have some other tasks to do first.

Regardless, I don't believe we will get any useful data out of such an
event. I've seen distributed systems run out of capacity before. What will
happen instead is technological failure followed by rapid user abandonment
that pushes traffic back below the pressure threshold .... and those users
will most likely not come back any time soon.


> Ok, this is my plan: we wait 12 months, hope that your estimations are
> correct (in case that my guess was better than yours, we keep waiting
> until June 2017) and start having full blocks and people having to
> wait 2 blocks for their transactions to be confirmed some times.
>

I disagree that'd be the outcome, but good, this is progress. Now we need
to hear something like that from Wladimir, or whoever has the final say
around here.

With respect to the fee market: I think it's fairer to say Gavin wants a
market to exist, and he also wants supply to be plentiful. 20mb limit
doesn't actually mean every block will be 20mb the day after, no more than
they're all 1mb today. Miners may discover that if they go beyond 5mb they
have too many orphans and then propagation speed will have to be optimised
to break through the next bottleneck. Scaling is always about finding the
next bottleneck and removing it, ideally, before you hit it.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/c1f84cb2/attachment.html>

From elombrozo at gmail.com  Thu May  7 11:30:49 2015
From: elombrozo at gmail.com (Eric Lombrozo)
Date: Thu, 7 May 2015 04:30:49 -0700
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <20150507112042.GB30564@amethyst.visucore.com>
References: <554A91BE.6060105@bluematt.me>
	<20150507112042.GB30564@amethyst.visucore.com>
Message-ID: <C4214F65-282D-47DD-95B9-A129526A2616@gmail.com>


> On May 7, 2015, at 4:20 AM, Wladimir J. van der Laan <laanwj at gmail.com> wrote:
> 
> For sake of brevity, this ignores the inherent practical and political issues in scheduling a hardfork.

IMHO, these issues are the elephant in the room and the talk of block size increases is just a distraction.

- Eric Lombrozo
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/5de81f02/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 842 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/5de81f02/attachment.sig>

From dave at hashingit.com  Thu May  7 11:55:49 2015
From: dave at hashingit.com (Dave Hudson)
Date: Thu, 7 May 2015 12:55:49 +0100
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
Message-ID: <5049F137-E123-47F6-9D24-FE51B92629FF@hashingit.com>


> On 7 May 2015, at 11:52, Jorge Tim?n <jtimon at jtimon.cc> wrote:
> 
> On Thu, May 7, 2015 at 11:25 AM, Mike Hearn <mike at plan99.net> wrote:
>> I observed to Wladimir and Gavin in private that this timeline meant a change to the block size was unlikely to get into 0.11, leaving only 0.12, which would give everyone only a few months to upgrade in order to fork the chain by the end of the winter growth season. That seemed tight.
> 
> Can you please elaborate on what terrible things will happen if we
> don't increase the block size by winter this year?
> I assume that you are expecting full blocks by then, have you used any
> statistical technique to come up with that date or is it just your
> guess?
> Because I love wild guesses and mine is that full 1 MB blocks will not
> happen until June 2017.

I've been looking at this problem for quite a while (Gavin cited some of my work a few days ago) so thought I'd chime in with a few thoughts (some of which I've not published). I believe the major problem here is that this isn't just an engineering decision; the reaction of the miners will actually determine the success or failure of any course of action. In fact any decision forced upon them may backfire if they collectively take exception to it. It's worth bearing in mind that most of the hash rate is now under the control of relatively large companies, many of whom have investors who are expecting to see returns; it probably isn't sufficient to just expect them to "do the right thing".

We're seeing plenty of full 1M byte blocks already and have been for months. Typically whenever we have one of the large inter-block gaps then these are often followed by one (and sometimes several) completely full blocks (full by the definition of whatever the miner wanted to use as a size limit).

The problem with this particular discussion is that there are quite a few "knowns" but an equally large number of "unknowns". Let's look at them:

Known: There has been a steady trend towards the mean block size getting larger. See https://blockchain.info/charts/avg-block-size?timespan=all&showDataPoints=false&daysAverageString=7&show_header=true&scale=0&address= <https://blockchain.info/charts/avg-block-size?timespan=all&showDataPoints=false&daysAverageString=7&show_header=true&scale=0&address=>

Known: Now the trend was definitely increasing quite quickly last year but for the last few months has been slowing down, however we did see pretty much a 2x increase in mean block sizes in 2014.

Known: For most of 2015 we've actually been seeing that rate slow quite dramatically, but the total numbers of transactions are still rising so we're seeing mean transaction sizes have been reducing, and that tallies with seeing more transactions per block: https://blockchain.info/charts/n-transactions-per-block?timespan=all&showDataPoints=false&daysAverageString=7&show_header=true&scale=0&address= <https://blockchain.info/charts/n-transactions-per-block?timespan=all&showDataPoints=false&daysAverageString=7&show_header=true&scale=0&address=>

Unknown: Why are seeing more smaller transactions? Are we simply seeing more efficient use of blockchain resources or have some large consumers of block space going away? How much more block space compression might be possible in, say, the next 12 months?

Known: If we reach the point where all blocks are 1M bytes then there's a major problem in terms of transaction confirmation. I published an analysis of the impact of different mean block sizes against confirmation times: http://hashingit.com/analysis/34-bitcoin-traffic-bulletin <http://hashingit.com/analysis/34-bitcoin-traffic-bulletin>. The current 35% to 45% mean block size doesn't have a huge impact on transaction confirmations (assuming equal fees for all) but once we're up at 80% then things start to get unpleasant. Instead of 50% of first confirmations taking about 7 minutes they instead take nearer to 19 minutes.

Known: There are currently a reasonably large number of zero-fee transactions getting relayed and mined. If things start to slow down then there will be a huge incentive to delay them (or drop them altogether).

Unknown: If block space starts to get more scarce then how will this affect the use of the blockchain? Do the zero-fee TXs move to some batched transfer solution via third party? Do people start to get smarter about how TXs are encoded? Do some TXs go away completely (there are a lot of long-chain transactions that may simply be "noise" creating an artificially inflated view of transaction volumes)?

Known: There's a major problem looming for miners at the next block reward halving. Many are already in a bad place and without meaningful fees then sans a 2x increase in the USD:BTC ratio then many will simply have to leave the network, increasing centralisation risks. There seems to be a fairly pervasive assumption that the 300-ish MW of power that they currently use is going to pay for itself (ignoring capital and other operating costs).

Unknown: If the block size is increased and yet more negligible fee transactions are dumped onto the network then that might well motivate some large fraction of miners to start to clamp block sizes or reject transactions below a certain fee threshold; they can easily create their own artificial scarcity if enough of them feel it is in their interest (it's not the most tricky setting to change). One can well imagine VC investors in mining groups asking why they're essentially subsidising all of the other VC-funded Bitcoin startups.

Known: the orphan rate is still pretty-high even with everyone's fast connections. If we assume that 20M byte blocks become possible then that's likely to increase.

Unknown: What are the security implications for larger blocks (this one (at least) can be simulated though)? For example, could large blocks with huge numbers of trivial transactions be used to put other validators at a disadvantage in a variant of a selfish mining attack? I've seen objections that such bad actors could be blacklisted in the future but it's not clear to me how. A private mining pool can trivially be made to appear like 100 pools of 1% of the size without significantly affecting the economics of running that private mine.


Cheers,
Dave

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/360dfd3b/attachment.html>

From jtimon at jtimon.cc  Thu May  7 12:26:10 2015
From: jtimon at jtimon.cc (=?UTF-8?B?Sm9yZ2UgVGltw7Nu?=)
Date: Thu, 7 May 2015 14:26:10 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
Message-ID: <CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>

On Thu, May 7, 2015 at 1:29 PM, Mike Hearn <mike at plan99.net> wrote:
> I was referring to winter next year. 0.12 isn't scheduled until the end of
> the year, according to Wladimir. I explained where this figure comes from in
> this article:
>
> https://medium.com/@octskyward/bitcoin-s-seasonal-affective-disorder-35733bab760d
>
> It's a fairly simple estimate based on previous growth patterns.

Ok, thanks.

>> We've successfully reached consensus for several softfork proposals
>> already.
>
>
> Are you sure about that?

Yes, Peter Todd gave more details.

> What if Gavin popped up right now and said he disagreed with every current
> proposal, he disagreed with side chains too, and there would be no consensus
> on any of them until the block size limit was raised.
>
> Would you say, oh, OK, guess that's it then. There's no consensus so might
> as well scrap all those proposals, as they'll never happen anyway. Bye bye
> side chains whitepaper.

Well, yes, it is true that "universally uncontroversial" (which is
what I think the requirement should be for hard forks) is a vague
qualifier that's not formally defined anywhere.
I guess we should only consider rational arguments. You cannot just
nack something without further explanation.
If his explanation was "I will change my mind after we increase block
size", I guess the community should say "then we will just ignore your
nack because it makes no sense".
In the same way, when people use fallacies (purposely or not) we must
expose that and say "this fallacy doesn't count as an argument".
But yeah, it would probably be good to define better what constitutes
a "sensible objection" or something. That doesn't seem simple though.

>> I just hope that by  "What we need to see right now is leadership" you
>> don't mean something like "when Gaving and Mike agree it's enough to
>> deploy a hardfork" when you go from vague to concrete.
>
>
> No. What I meant is that someone (theoretically Wladimir) needs to make a
> clear decision. If that decision is "Bitcoin Core will wait and watch the
> fireworks when blocks get full", that would be showing leadership .....
> albeit I believe in the wrong direction. It would, however, let people know
> what's what and let them start to make longer term plans.
>
> This dillydallying around is an issue - people just make vague points that
> can't really be disagreed with (more nodes would be nice, smaller pools
> would also be nice etc), and nothing gets done.

Well, there's two different things here.
One thing is the Bitcoin core project where you could argue that the 5
committers decide (I don't know why Wladimir would have any more
authority than the others).
But what the bitcoin network itself does it's very different because
unlike the bitcoin core software project, the Bitcoin network is
decentralized.
If the people with commit access go nuts and decide something that's
clearly stupid or evil, people can just fork the project because it is
free software.
You cannot be forced to use specific features of free software, you
can always remove them and recompile, that's the whole point.
So, no, there's no authority to decide on hardforks and that's why I
think that only clearly uncontroversial things can get through as
hardforks.

>> What you want to avoid at all cost (the block size actually being
>> used), I see as the best opportunity we have to look into the future.
>
>
> I think I see one of the causes of disagreement now.
>
> I will write more on the topic of what will happen if we hit the block size
> limit soon, maybe this evening. I have some other tasks to do first.
>
> Regardless, I don't believe we will get any useful data out of such an
> event. I've seen distributed systems run out of capacity before. What will
> happen instead is technological failure followed by rapid user abandonment
> that pushes traffic back below the pressure threshold .... and those users
> will most likely not come back any time soon.

Ok, so in simple terms, you expect people to have to pay enormous fees
and/or wait thousands of blocks for their transactions to get included
in the chain.
Is that correct?

>> Ok, this is my plan: we wait 12 months, hope that your estimations are
>> correct (in case that my guess was better than yours, we keep waiting
>> until June 2017) and start having full blocks and people having to
>> wait 2 blocks for their transactions to be confirmed some times.
>
>
> I disagree that'd be the outcome, but good, this is progress. Now we need to
> hear something like that from Wladimir, or whoever has the final say around
> here.

As said above there's no authority to decide on what Bitcoin the p2p
network does. Again, that's the whole point.
But, yes, I agree that both sides understanding each other better is progress.

> With respect to the fee market: I think it's fairer to say Gavin wants a
> market to exist, and he also wants supply to be plentiful. 20mb limit
> doesn't actually mean every block will be 20mb the day after, no more than
> they're all 1mb today. Miners may discover that if they go beyond 5mb they
> have too many orphans and then propagation speed will have to be optimised
> to break through the next bottleneck. Scaling is always about finding the
> next bottleneck and removing it, ideally, before you hit it.

I'm sure he wants a fee market to eventually exist as well.
But it seems that some people would like to see that happening before
the subsidies are low (not necessarily null), while other people are
fine waiting for that but don't want to ever be close to the scale
limits anytime soon.
I would also like to know for how long we need to prioritize short
term adoption in this way. As others have said, if the answer is
"forever, adoption is always the most important thing" then we will
end up with an improved version of Visa.
But yeah, this is progress, I'll wait for your more detailed
description of the tragedies that will follow hitting the block
limits, assuming for now that it will happen in 12 months.
My previous answer to the nervous "we will hit the block limits in 12
months if we don't do anything" was "not sure about 12 months, but
whatever, great, I'm waiting for that to observe how fees get
affected".
But it should have been a question "what's wrong with hitting the
block limits in 12 months?"



From pete at petertodd.org  Thu May  7 13:02:40 2015
From: pete at petertodd.org (Peter Todd)
Date: Thu, 7 May 2015 09:02:40 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
Message-ID: <20150507130240.GA16681@savin.petertodd.org>

On Thu, May 07, 2015 at 01:29:44PM +0200, Mike Hearn wrote:
> What if Gavin popped up right now and said he disagreed with every current
> proposal, he disagreed with side chains too, and there would be no
> consensus on any of them until the block size limit was raised.
> 
> Would you say, oh, OK, guess that's it then. There's no consensus so might
> as well scrap all those proposals, as they'll never happen anyway. Bye bye
> side chains whitepaper.

If Gavin had good points to make, he'd probably eventually change
everyone's mind.

But if he fails to do that at some point he'll just get ignored and for
all practical purposes won't be considered part of the consensus. Not
unlike how if someone suggested we power the blockchain via perpetual
motion machines they'd be ignored. Bitcoin is after all a decentralized
system so all power over the development process is held only by social
consent and respect.

At that point I'd suggest Gavin fork the project and go to the next
level of consensus gathering, the community at large; I'm noticing this
is exactly what you and Gavin are doing.

Speaking of, are you and Gavin still thinking about forking Bitcoin
Core? If so I wish you the best of luck.

Sent: Wednesday, July 23, 2014 at 2:42 PM
From: "Mike Hearn" <mike at plan99.net>
To: "Satoshi Nakamoto" <satoshin at gmx.com>
Subject: Thinking about a fork
I don't expect a reply, just getting some thoughts off my chest. Writing them down helps.

Forking Bitcoin-Qt/Core has been coming up more and more often lately in conversation (up from zero not that long ago). Gavin even suggested me and him fork it ... I pointed out that maintainers don't normally fork their own software :)

The problem is that the current community of developers has largely lost interest in supporting SPV wallets. Indeed any protocol change that might mean any risk at all, for anyone, is now being bogged down in endless circular arguments that never end. The Bitcoin developers have effectively become the new financial regulators: restricting options within their jurisdiction with "someone might do something risky" being used as the justification.

If alternative low-risk protocols were always easily available this would be no problem, but often they require enormous coding and deployment effort or just don't exist at all. Yet, wallets must move forward. If we carry on as now there simply won't be any usable decentralised wallets left and Bitcoin will have become an energy-wasting backbone for a bunch of banks and payment processors. That's so far from your original vision, it's sad.

I know you won't return and that's wise, but sometimes I wish you'd left a clearer design manifesto before handing the reigns over to Gavin, who is increasingly burned out due to all the arguments (as am I).

Source: https://www.reddit.com/r/Bitcoin/comments/2g9c0j/satoshi_email_leak/

-- 
'peter'[:-1]@petertodd.org
0000000000000000066f25b3196b51d30df5c1678fc206fdf55b65dd6e593b05
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/077ae65e/attachment.sig>

From jtimon at jtimon.cc  Thu May  7 13:40:23 2015
From: jtimon at jtimon.cc (=?UTF-8?B?Sm9yZ2UgVGltw7Nu?=)
Date: Thu, 7 May 2015 15:40:23 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <5049F137-E123-47F6-9D24-FE51B92629FF@hashingit.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<5049F137-E123-47F6-9D24-FE51B92629FF@hashingit.com>
Message-ID: <CABm2gDpceBQ=SqH-axgbMgOGOf8cOe1wLyJgJY5TEFu4taiNwA@mail.gmail.com>

On Thu, May 7, 2015 at 1:55 PM, Dave Hudson <dave at hashingit.com> wrote:
> Known: There has been a steady trend towards the mean block size getting
> larger. See
> https://blockchain.info/charts/avg-block-size?timespan=all&showDataPoints=false&daysAverageString=7&show_header=true&scale=0&address=

Looking at this graph and in retrospective, we shouldn't have removed
the standard policy limit without observing the supposedly disastrous
effects of hitting the limit first.
Removing the standard limit would have been trivial (bdb issues aside)
at any point after seeing the effects.

> Known: If we reach the point where all blocks are 1M bytes then there's a
> major problem in terms of transaction confirmation. I published an analysis
> of the impact of different mean block sizes against confirmation times:
> http://hashingit.com/analysis/34-bitcoin-traffic-bulletin. The current 35%
> to 45% mean block size doesn't have a huge impact on transaction
> confirmations (assuming equal fees for all) but once we're up at 80% then
> things start to get unpleasant. Instead of 50% of first confirmations taking
> about 7 minutes they instead take nearer to 19 minutes.

Well, this is only for first confirmations of free transaction.
A higher fee should increase your probabilities, but if you're sending
free transactions you may not care about them taking longer to be
included.

> Known: There are currently a reasonably large number of zero-fee
> transactions getting relayed and mined. If things start to slow down then
> there will be a huge incentive to delay them (or drop them altogether).

Well, maybe "instant and free" it's not a honest form of bitcoin
marketing and it just has to disappear.
Maybe we just need to start being more honest about pow being good for
processing micro-transactions: it is not.
Hopefully lightning will be good for that.
Free and fast in-chain transactions is something temporary that we
know will eventually disappear.
If people think it would be a adoption disaster that it happens soon,
then they could also detail an alternative plan to roll that out
instead of letting it happen.
But if the plan is to delay it forever...then I'm absolutely against.

> Known: There's a major problem looming for miners at the next block reward
> halving. Many are already in a bad place and without meaningful fees then
> sans a 2x increase in the USD:BTC ratio then many will simply have to leave
> the network, increasing centralisation risks. There seems to be a fairly
> pervasive assumption that the 300-ish MW of power that they currently use is
> going to pay for itself (ignoring capital and other operating costs).

I take this as an argument for increasing fee competition and thus,
against increasing the block size.

> Known: the orphan rate is still pretty-high even with everyone's fast
> connections. If we assume that 20M byte blocks become possible then that's
> likely to increase.
>
> Unknown: What are the security implications for larger blocks (this one (at
> least) can be simulated though)? For example, could large blocks with huge
> numbers of trivial transactions be used to put other validators at a
> disadvantage in a variant of a selfish mining attack? I've seen objections
> that such bad actors could be blacklisted in the future but it's not clear
> to me how. A private mining pool can trivially be made to appear like 100
> pools of 1% of the size without significantly affecting the economics of
> running that private mine.

No blacklisting, please, that's centralized.
In any case, a related known: bigger blocks give competitive advantage
to bigger miners.



From mike at plan99.net  Thu May  7 14:05:41 2015
From: mike at plan99.net (Mike Hearn)
Date: Thu, 7 May 2015 16:05:41 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
Message-ID: <CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>

>
> If his explanation was "I will change my mind after we increase block
>
size", I guess the community should say "then we will just ignore your
> nack because it makes no sense".
>

Oh good! We can just kick anyone out of the consensus process if we think
they make no sense.

I guess that means me and Gavin can remove everyone else from the developer
consensus, because we think trying to stop Bitcoin growing makes no sense.

Do you see the problem with this whole notion? It cannot possibly work.
Whenever you try and make the idea of developer consensus work, what you
end up with is "I believe in consensus as long as it goes my way". Which is
worthless.


> One thing is the Bitcoin core project where you could argue that the 5
> committers decide (I don't know why Wladimir would have any more
> authority than the others).
>

Because he is formally the maintainer.

Maybe you dislike that idea. It's so .... centralised. So let's say Gavin
commits his patch, because his authority is equal to all other committers.
Someone else rolls it back. Gavin sets up a cron job to keep committing the
patch. Game over.

You cannot have committers fighting over what goes in and what doesn't.
That's madness. There must be a single decision maker for any given
codebase.


> Ok, so in simple terms, you expect people to have to pay enormous fees
> and/or wait thousands of blocks for their transactions to get included
> in the chain. Is that correct?
>

No. I'll write an article like the others, it's better than email for more
complicated discourse.

As others have said, if the answer is "forever, adoption is always the most
> important thing" then we will end up with an improved version of Visa.
>

This appears to be another one of those fundamental areas of disagreement.
I believe there is no chance of Bitcoin ending up like Visa, even if it is
wildly successful. I did the calculations years ago that show that won't
happen:

    https://en.bitcoin.it/wiki/Scalability

Decentralisation is a spectrum and Bitcoin will move around on that
spectrum over time. But claiming we have to pick between 1mb blocks and
"Bitcoin = VISA" is silly.



Peter:   your hypocrisy really is bottomless, isn't it? You constantly
claim to be a Righteous Defender of Privacy, but don't even hesitate before
publishing hacked private emails when it suits you.

Satoshi's hacker had no illusions about your horrible personality, which is
why he forwarded that email to you specifically. He knew you'd use it. You
should reflect on that fact. It says nothing good about you at all.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/2785795e/attachment.html>

From jgarzik at bitpay.com  Thu May  7 14:04:21 2015
From: jgarzik at bitpay.com (Jeff Garzik)
Date: Thu, 7 May 2015 10:04:21 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
Message-ID: <CAJHLa0Mr6aQcVRKtidc+qVR7-esriyp5kzAw1LMHHwOcXhhG+Q@mail.gmail.com>

I have a lot more written down, a WIP; here are the highlights.

- The 1MB limit is an ancient anti-spam limit, and needs to go.

- The 1MB limit is economically entrenched at this point, and cannot be
removed at a whim.

- This is a major change to the economics of a $3.2B system.  This change
picks winners and losers.  There is attendant moral hazard.

- The core dev team is not and should not be an FOMC.

- The bar for "major economic change to a $3.2B system" should necessarily
be high.  In the more boring world of investments, this would accompanied
by Due Diligence including but not limited to projections for success,
failure scenarios, upside risks and downside risks.  Projections and
fact-based simulations.

- There are significant disruption risks on the pro (change it) and con
(keep 1MB) sides of the debate.

- People are privately lobbying Gavin for this.  That is the wrong way to
go.   I have pushed for a more public debate, and public endorsements (or
condemnations) from major miners, merchants, payment processors,
stackholders, ...   It is unfair to criticize Gavin to doing this.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/a47b125e/attachment.html>

From kanzure at gmail.com  Thu May  7 14:18:17 2015
From: kanzure at gmail.com (Bryan Bishop)
Date: Thu, 7 May 2015 09:18:17 -0500
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
Message-ID: <CABaSBaxP2VGcH4gugZgr=t35NGSTF7QPPdQnYOo3osMg3J5tGg@mail.gmail.com>

On Thu, May 7, 2015 at 9:05 AM, Mike Hearn <mike at plan99.net> wrote:
> Maybe you dislike that idea. It's so .... centralised. So let's say Gavin
> commits his patch, because his authority is equal to all other committers.
> Someone else rolls it back. Gavin sets up a cron job to keep committing the
> patch. Game over.
>
> You cannot have committers fighting over what goes in and what doesn't.
> That's madness. There must be a single decision maker for any given
> codebase.

Hmm, git repositories don't quite work like that. Instead, you should
imagine everyone having a local copy of the git repository. Each
developer synchronizes their git repository with other developers.
They merge changes from specific remote branches that they have
received. Each developer has their own branch and each developer is
the "single decision maker" for the artifact that they compile.

- Bryan
http://heybryan.org/
1 512 203 0507



From pete at petertodd.org  Thu May  7 14:22:24 2015
From: pete at petertodd.org (Peter Todd)
Date: Thu, 7 May 2015 10:22:24 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
Message-ID: <20150507142224.GA32602@savin.petertodd.org>

On Thu, May 07, 2015 at 04:05:41PM +0200, Mike Hearn wrote:
> Peter:   your hypocrisy really is bottomless, isn't it? You constantly
> claim to be a Righteous Defender of Privacy, but don't even hesitate before
> publishing hacked private emails when it suits you.
>
> Satoshi's hacker had no illusions about your horrible personality, which is
> why he forwarded that email to you specifically. He knew you'd use it. You
> should reflect on that fact. It says nothing good about you at all.

As you know I was forwarded that email first, and because I *do* respect
your privacy I consulting with you via private IRC chat first, and as
you wished I didn't publish it. The hacker presumably gave up waiting
for me to do so and published it themselves seven months ago; to make
that clear I linked the source(1) of the email in my message. Those
emails simply are no longer private.

Frankly personal attacks like this - "your hypocrisy really is
bottomless, isn't it?", "Satoshi's hacker had no illusions about your
horrible personality" - simply don't belong on this mailing list and I
think we would all appreciate an apology.

1) https://www.reddit.com/r/Bitcoin/comments/2g9c0j/satoshi_email_leak/

-- 
'peter'[:-1]@petertodd.org
000000000000000012a3e40d5ee5c7fc2fb8367b720a9d499468ceb25366c1f3
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/0c0461b8/attachment.sig>

From pete at petertodd.org  Thu May  7 14:32:34 2015
From: pete at petertodd.org (Peter Todd)
Date: Thu, 7 May 2015 10:32:34 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CAJHLa0Mr6aQcVRKtidc+qVR7-esriyp5kzAw1LMHHwOcXhhG+Q@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CAJHLa0Mr6aQcVRKtidc+qVR7-esriyp5kzAw1LMHHwOcXhhG+Q@mail.gmail.com>
Message-ID: <20150507143234.GB32602@savin.petertodd.org>

On Thu, May 07, 2015 at 10:04:21AM -0400, Jeff Garzik wrote:
> I have a lot more written down, a WIP; here are the highlights.
> 
> - The 1MB limit is an ancient anti-spam limit, and needs to go.
> 
> - The 1MB limit is economically entrenched at this point, and cannot be
> removed at a whim.
> 
> - This is a major change to the economics of a $3.2B system.  This change
> picks winners and losers.  There is attendant moral hazard.
> 
> - The core dev team is not and should not be an FOMC.
> 
> - The bar for "major economic change to a $3.2B system" should necessarily
> be high.  In the more boring world of investments, this would accompanied
> by Due Diligence including but not limited to projections for success,
> failure scenarios, upside risks and downside risks.  Projections and
> fact-based simulations.
> 
> - There are significant disruption risks on the pro (change it) and con
> (keep 1MB) sides of the debate.
> 
> - People are privately lobbying Gavin for this.  That is the wrong way to
> go.   I have pushed for a more public debate, and public endorsements (or
> condemnations) from major miners, merchants, payment processors,
> stackholders, ...   It is unfair to criticize Gavin to doing this.

The hard part here will be including the players who aren't individually
"major", but are collectively important; who is the community?

How do you give the small merchants a voice in this discussion? The
small time traders? The small time miners? The people in repressive
countries who are trying to transact on thier own terms?

Legality? Should people involved in 3rd world remittances be
included? Even if what they're doing is technically illegal? What about
dark markets? If DPR voiced his opinion, should we ignore it?

Personally, I'm dubious about trying to make ecosystem-wide decisions
like this without cryptographic consensus; fuzzy human social consensus
is easy to manipulate.

-- 
'peter'[:-1]@petertodd.org
000000000000000013e67b343b1f6d75cc87dfb54430bdb3bcf66d8d4b3ef6b8
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/f7904ca9/attachment.sig>

From justusranvier at riseup.net  Thu May  7 14:38:22 2015
From: justusranvier at riseup.net (Justus Ranvier)
Date: Thu, 07 May 2015 16:38:22 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CAJHLa0Mr6aQcVRKtidc+qVR7-esriyp5kzAw1LMHHwOcXhhG+Q@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CAJHLa0Mr6aQcVRKtidc+qVR7-esriyp5kzAw1LMHHwOcXhhG+Q@mail.gmail.com>
Message-ID: <554B78DE.20600@localhost.local>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 05/07/2015 04:04 PM, Jeff Garzik wrote:
> - This is a major change to the economics of a $3.2B system.  This
> change picks winners and losers.  There is attendant moral hazard.

This is exactly true.

There are a number of projects which aren't Bitcoin that benefit from
filling in the gap left by Bitcoin's restricted transaction rate
capability.

If Bitcoin fills that gap, Bitcoin wins and those other projects lose.

Should decisions about Bitcoin development take into account the
desires of competing projects?

-----BEGIN PGP SIGNATURE-----

iQIcBAEBAgAGBQJVS3jeAAoJECpf2nDq2eYj3hMP/0yk8HxypEfNa4vZo0IcKD+p
bn2dftQsOEeOenBh8QT48vS3AhcjNkUsw722YwbKz6Znkyi2iU7njaUM9DV+QHwg
Oytmh8XVZtviLgg3854ujdj4oAWyP4DpppVTRxTDyRdSpRj+D9y6+sGFls6z0q3/
XRcKOY23zx6/qN1k5fqUncpIpYEDhpmE7cGy26Yz0G4MtuYeceHT4LdJAHHr0iFL
OY0WVM32b4F3HfkfJtt8rE0yeB7u5dbeu8KmLB0yqZQkY87sLxtT6qeoyHO6CG+N
8Iu9OWaRIZHfrZK2XlDzDKQIkTnlSxFtj4wY7/Yb4NIDO6mhMjYTSz8lWqN4ofKg
9fFHlwGS3QXXDTB+5d1IzZS5C0qF92n1NJiJjkLqhKqYuVn4U74oslZhVLxHBGHH
ZAvW09obZXi5DVzhuxPzlFkpYaB+XLdmBUPEr5hx5K4I2qiL/Nvu0h031UDcMeLm
x9mEHO5ZODlF9tWAVnM/b0VtwT9h6Q88NWe/OUQQZKp6D/Etcd3JE55GBNtNPDnE
2UubyHkNO4mbrEMluh24TvhZK3BB/lieq+kkHZCP7eC58eRY078lSF8R36XGdbn4
Pili15bYSrRrfmjDz24zhJX8759LPt2Zsf/Irc8Za4SoaEaYAqQU4vAmYlZyCNxj
EvxXAasffnjR2K3cnZxr
=YkTz
-----END PGP SIGNATURE-----
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0xEAD9E623.asc
Type: application/pgp-keys
Size: 18381 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/08be2d04/attachment.bin>

From pete at petertodd.org  Thu May  7 14:40:12 2015
From: pete at petertodd.org (Peter Todd)
Date: Thu, 7 May 2015 10:40:12 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
Message-ID: <20150507144012.GC32602@savin.petertodd.org>

On Thu, May 07, 2015 at 04:05:41PM +0200, Mike Hearn wrote:
> > One thing is the Bitcoin core project where you could argue that the 5
> > committers decide (I don't know why Wladimir would have any more
> > authority than the others).
> >
> 
> Because he is formally the maintainer.

I quite liked Wladimir's description of what someone with the ability
to merge pull requests into Bitcoin Core is:

    @orionwl github.com/bitcoin/bitcoin repository admin, or maybe just "janitor"

-https://twitter.com/orionwl/status/563688293737697281

In any case, we can't force people to run Bitcoin Core - an unpopular
patch that fails to reach consensus is a strong sign that it may not get
user acceptance either - so we might as well accept that centralized
authority over the development process isn't going to fly and deal with
the sometimes messy consequences.

Like I said, you're welcome to fork the project and try to get user
acceptance for the fork.

-- 
'peter'[:-1]@petertodd.org
000000000000000013e67b343b1f6d75cc87dfb54430bdb3bcf66d8d4b3ef6b8
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/cd705b97/attachment.sig>

From pete at petertodd.org  Thu May  7 14:49:18 2015
From: pete at petertodd.org (Peter Todd)
Date: Thu, 7 May 2015 10:49:18 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554B78DE.20600@localhost.local>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CAJHLa0Mr6aQcVRKtidc+qVR7-esriyp5kzAw1LMHHwOcXhhG+Q@mail.gmail.com>
	<554B78DE.20600@localhost.local>
Message-ID: <20150507144918.GA6761@savin.petertodd.org>

On Thu, May 07, 2015 at 04:38:22PM +0200, Justus Ranvier wrote:
> On 05/07/2015 04:04 PM, Jeff Garzik wrote:
> > - This is a major change to the economics of a $3.2B system.  This
> > change picks winners and losers.  There is attendant moral hazard.
> 
> This is exactly true.
> 
> There are a number of projects which aren't Bitcoin that benefit from
> filling in the gap left by Bitcoin's restricted transaction rate
> capability.
> 
> If Bitcoin fills that gap, Bitcoin wins and those other projects lose.
> 
> Should decisions about Bitcoin development take into account the
> desires of competing projects?

Well, basically you're asking if we shouldn't assume the people in this
discussion have honest intentions. If you want to go down that path,
keep in mind where it leads.

I think we'll find an basic assumption of civility to be more
productive, until proven otherwise. (e.g. NSA ties)

-- 
'peter'[:-1]@petertodd.org
00000000000000000d49f263bbbb80f264abc7cc930fc9cbc7ba80ac068d9648
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/b35acd17/attachment.sig>

From gavinandresen at gmail.com  Thu May  7 14:52:54 2015
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Thu, 7 May 2015 10:52:54 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
Message-ID: <CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>

For reference: the blog post that (re)-started this debate, and which links
to individual issues, is here:
  http://gavinandresen.ninja/time-to-roll-out-bigger-blocks

In it, I asked people to email me objections I might have missed. I would
still appreciate it if people do that; it is impossible to keep up with
this mailing list, /r/bitcoin posts and comments, and #bitcoin-wizards and
also have time to respond thoughtfully to the objections raised.

I would very much like to find some concrete course of action that we can
come to consensus on. Some compromise so we can tell entrepreneurs "THIS is
how much transaction volume the main Bitcoin blockchain will be able to
support over the next eleven years."

I've been pretty clear on what I think is a reasonable compromise (a
one-time increase scheduled for early next year), and I have tried to
explain why I think it it is the right set of tradeoffs.

There ARE tradeoffs here, and the hard question is what process do we use
to decide those tradeoffs?  How do we come to consensus? Is it worth my
time to spend hours responding thoughtfully to every new objection raised
here, or will the same thing happen that happened last year and the year
before-- everybody eventually gets tired of arguing
angels-dancing-on-the-head-of-a-pin, and we're left with the status quo?

I AM considering contributing some version of the bigger blocksize-limit
hard-fork patch to the Bitcoin-Xt fork (probably  "target a hobbyist with a
fast Internet connection, and assume Nelson's law to increase over time),
and then encouraging merchants and exchanges and web wallets and
individuals who think it strikes a reasonable balance to run it.

And then, assuming it became a super-majority of nodes on the network,
encourage miners to roll out a soft-fork to start producing bigger blocks
and eventually trigger the hard fork.

Because ultimately consensus comes down to what software people choose to
run.

-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/125b7e32/attachment.html>

From pete at petertodd.org  Thu May  7 14:56:58 2015
From: pete at petertodd.org (Peter Todd)
Date: Thu, 7 May 2015 10:56:58 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
Message-ID: <20150507145658.GA9648@savin.petertodd.org>

On Thu, May 07, 2015 at 10:52:54AM -0400, Gavin Andresen wrote:
> I AM considering contributing some version of the bigger blocksize-limit
> hard-fork patch to the Bitcoin-Xt fork (probably  "target a hobbyist with a
> fast Internet connection, and assume Nelson's law to increase over time),
> and then encouraging merchants and exchanges and web wallets and
> individuals who think it strikes a reasonable balance to run it.
> 
> And then, assuming it became a super-majority of nodes on the network,
> encourage miners to roll out a soft-fork to start producing bigger blocks
> and eventually trigger the hard fork.

Would you please explain what you mean by "a soft-fork to start
producing bigger blocks"

-- 
'peter'[:-1]@petertodd.org
00000000000000000d49f263bbbb80f264abc7cc930fc9cbc7ba80ac068d9648
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/2223f818/attachment.sig>

From morcos at gmail.com  Thu May  7 15:04:25 2015
From: morcos at gmail.com (Alex Morcos)
Date: Thu, 7 May 2015 11:04:25 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
Message-ID: <CAPWm=eUFe7dKJCLeNACZ4n9vw0Xj9rHVM_RRLSczGXNU-ShR2w@mail.gmail.com>

That strikes me as a dangerous path forward.

I don't actually think there is anything wrong with this: "everybody
eventually gets tired of arguing angels-dancing-on-the-head-of-a-pin, and
we're left with the status quo"

What gives Bitcoin value aren't its technical merits but the fact that
people believe in it.   The biggest risk here isn't that 20MB blocks will
be bad or that 1MB blocks will be bad, but that by forcing a hard fork that
isn't nearly universally agreed upon, we will be damaging that belief.   If
I strongly believed some hard fork would be better for Bitcoin, say
permanent inflation of 1% a year to fund mining, and I managed to convince
80% of users, miners, businesses and developers to go along with me, I
would still vote against doing it.  Because that's not nearly universal
agreement, and it changes what people chose to believe in without their
consent. Forks should be hard, very hard.  And both sides should recognize
that belief in the value of Bitcoin might be a fragile thing.   I'd argue
that if we didn't force through a 20MB fork now, and we ran into major
network difficulties a year from now and had no other technical solutions,
that maybe we would get nearly universal agreement, and the businesses and
users that were driven away by the unusable system would be a short term
loss in value considerably smaller than the impairment we risk by forcing a
change.



On Thu, May 7, 2015 at 10:52 AM, Gavin Andresen <gavinandresen at gmail.com>
wrote:

> For reference: the blog post that (re)-started this debate, and which
> links to individual issues, is here:
>   http://gavinandresen.ninja/time-to-roll-out-bigger-blocks
>
> In it, I asked people to email me objections I might have missed. I would
> still appreciate it if people do that; it is impossible to keep up with
> this mailing list, /r/bitcoin posts and comments, and #bitcoin-wizards and
> also have time to respond thoughtfully to the objections raised.
>
> I would very much like to find some concrete course of action that we can
> come to consensus on. Some compromise so we can tell entrepreneurs "THIS is
> how much transaction volume the main Bitcoin blockchain will be able to
> support over the next eleven years."
>
> I've been pretty clear on what I think is a reasonable compromise (a
> one-time increase scheduled for early next year), and I have tried to
> explain why I think it it is the right set of tradeoffs.
>
> There ARE tradeoffs here, and the hard question is what process do we use
> to decide those tradeoffs?  How do we come to consensus? Is it worth my
> time to spend hours responding thoughtfully to every new objection raised
> here, or will the same thing happen that happened last year and the year
> before-- everybody eventually gets tired of arguing
> angels-dancing-on-the-head-of-a-pin, and we're left with the status quo?
>
> I AM considering contributing some version of the bigger blocksize-limit
> hard-fork patch to the Bitcoin-Xt fork (probably  "target a hobbyist with a
> fast Internet connection, and assume Nelson's law to increase over time),
> and then encouraging merchants and exchanges and web wallets and
> individuals who think it strikes a reasonable balance to run it.
>
> And then, assuming it became a super-majority of nodes on the network,
> encourage miners to roll out a soft-fork to start producing bigger blocks
> and eventually trigger the hard fork.
>
> Because ultimately consensus comes down to what software people choose to
> run.
>
> --
> --
> Gavin Andresen
>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/30afcdf6/attachment.html>

From jgarzik at bitpay.com  Thu May  7 15:04:58 2015
From: jgarzik at bitpay.com (Jeff Garzik)
Date: Thu, 7 May 2015 11:04:58 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554B78DE.20600@localhost.local>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CAJHLa0Mr6aQcVRKtidc+qVR7-esriyp5kzAw1LMHHwOcXhhG+Q@mail.gmail.com>
	<554B78DE.20600@localhost.local>
Message-ID: <CAJHLa0OXpbAeDsQknR0HewasPq0PYPLNU3yWJ+xzerB6CXX7jw@mail.gmail.com>

On Thu, May 7, 2015 at 10:38 AM, Justus Ranvier <justusranvier at riseup.net>
wrote:

> On 05/07/2015 04:04 PM, Jeff Garzik wrote:
> > - This is a major change to the economics of a $3.2B system.  This
> > change picks winners and losers.  There is attendant moral hazard.
>
> This is exactly true.
>
> There are a number of projects which aren't Bitcoin that benefit from
> filling in the gap left by Bitcoin's restricted transaction rate
> capability.
>
> If Bitcoin fills that gap, Bitcoin wins and those other projects lose.
>
> Should decisions about Bitcoin development take into account the
> desires of competing projects?


heh - I tend to think people here want bitcoin to succeed.  My statement
refers to picking winners and losers from within the existing bitcoin
community & stakeholders.

The existential question of the block size increase is larger - will
failing to increase the 1MB limit permanently stunt bitcoin's growth?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/c23956f4/attachment.html>

From jgarzik at bitpay.com  Thu May  7 15:09:18 2015
From: jgarzik at bitpay.com (Jeff Garzik)
Date: Thu, 7 May 2015 11:09:18 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CAPWm=eUFe7dKJCLeNACZ4n9vw0Xj9rHVM_RRLSczGXNU-ShR2w@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<CAPWm=eUFe7dKJCLeNACZ4n9vw0Xj9rHVM_RRLSczGXNU-ShR2w@mail.gmail.com>
Message-ID: <CAJHLa0MB8Hh-7np8EpFMj0jioNpxH_D-C=KZrt_Ri6p_Bovc5w@mail.gmail.com>

100% agree, RE hard forks should be hard.

However, it is the paradox of growth, morale and adoption that bitcoin
might never reach the point where it is saturated & expensive to the point
where larger blocks are demanded by 95%+...  simply because people and
companies chose not to adopt bitcoin in the first place due to an unmoving,
[perceived | real] scalability roadblock.


On Thu, May 7, 2015 at 11:04 AM, Alex Morcos <morcos at gmail.com> wrote:

> That strikes me as a dangerous path forward.
>
> I don't actually think there is anything wrong with this: "everybody
> eventually gets tired of arguing angels-dancing-on-the-head-of-a-pin, and
> we're left with the status quo"
>
> What gives Bitcoin value aren't its technical merits but the fact that
> people believe in it.   The biggest risk here isn't that 20MB blocks will
> be bad or that 1MB blocks will be bad, but that by forcing a hard fork that
> isn't nearly universally agreed upon, we will be damaging that belief.   If
> I strongly believed some hard fork would be better for Bitcoin, say
> permanent inflation of 1% a year to fund mining, and I managed to convince
> 80% of users, miners, businesses and developers to go along with me, I
> would still vote against doing it.  Because that's not nearly universal
> agreement, and it changes what people chose to believe in without their
> consent. Forks should be hard, very hard.  And both sides should recognize
> that belief in the value of Bitcoin might be a fragile thing.   I'd argue
> that if we didn't force through a 20MB fork now, and we ran into major
> network difficulties a year from now and had no other technical solutions,
> that maybe we would get nearly universal agreement, and the businesses and
> users that were driven away by the unusable system would be a short term
> loss in value considerably smaller than the impairment we risk by forcing a
> change.
>
>
>
> On Thu, May 7, 2015 at 10:52 AM, Gavin Andresen <gavinandresen at gmail.com>
> wrote:
>
>> For reference: the blog post that (re)-started this debate, and which
>> links to individual issues, is here:
>>   http://gavinandresen.ninja/time-to-roll-out-bigger-blocks
>>
>> In it, I asked people to email me objections I might have missed. I would
>> still appreciate it if people do that; it is impossible to keep up with
>> this mailing list, /r/bitcoin posts and comments, and #bitcoin-wizards and
>> also have time to respond thoughtfully to the objections raised.
>>
>> I would very much like to find some concrete course of action that we can
>> come to consensus on. Some compromise so we can tell entrepreneurs "THIS is
>> how much transaction volume the main Bitcoin blockchain will be able to
>> support over the next eleven years."
>>
>> I've been pretty clear on what I think is a reasonable compromise (a
>> one-time increase scheduled for early next year), and I have tried to
>> explain why I think it it is the right set of tradeoffs.
>>
>> There ARE tradeoffs here, and the hard question is what process do we use
>> to decide those tradeoffs?  How do we come to consensus? Is it worth my
>> time to spend hours responding thoughtfully to every new objection raised
>> here, or will the same thing happen that happened last year and the year
>> before-- everybody eventually gets tired of arguing
>> angels-dancing-on-the-head-of-a-pin, and we're left with the status quo?
>>
>> I AM considering contributing some version of the bigger blocksize-limit
>> hard-fork patch to the Bitcoin-Xt fork (probably  "target a hobbyist with a
>> fast Internet connection, and assume Nelson's law to increase over time),
>> and then encouraging merchants and exchanges and web wallets and
>> individuals who think it strikes a reasonable balance to run it.
>>
>> And then, assuming it became a super-majority of nodes on the network,
>> encourage miners to roll out a soft-fork to start producing bigger blocks
>> and eventually trigger the hard fork.
>>
>> Because ultimately consensus comes down to what software people choose to
>> run.
>>
>> --
>> --
>> Gavin Andresen
>>
>>
>>
>> ------------------------------------------------------------------------------
>> One dashboard for servers and applications across Physical-Virtual-Cloud
>> Widest out-of-the-box monitoring support with 50+ applications
>> Performance metrics, stats and reports that give you Actionable Insights
>> Deep dive visibility with transaction tracing using APM Insight.
>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>


-- 
Jeff Garzik
Bitcoin core developer and open source evangelist
BitPay, Inc.      https://bitpay.com/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/435a17c4/attachment.html>

From mike at plan99.net  Thu May  7 15:12:38 2015
From: mike at plan99.net (Mike Hearn)
Date: Thu, 7 May 2015 17:12:38 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CAPWm=eUFe7dKJCLeNACZ4n9vw0Xj9rHVM_RRLSczGXNU-ShR2w@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<CAPWm=eUFe7dKJCLeNACZ4n9vw0Xj9rHVM_RRLSczGXNU-ShR2w@mail.gmail.com>
Message-ID: <CANEZrP1tCda9EbYgYu5QHN8ZgBCtGP7zRiDaXnq-rWU0ZHR9NQ@mail.gmail.com>

>
> What gives Bitcoin value aren't its technical merits but the fact that
> people believe in it.
>

Much of the belief in Bitcoin is that it has a bright future. Certainly the
huge price spikes we've seen were not triggered by equally large spikes in
usage - it's speculation on that future.

I quite agree that if people stop believing in Bitcoin, that will be bad. A
fast way to bring that about will be to deliberately cripple the technology
in order to force people onto something quite different (which probably
won't be payment channel networks).


> I'd argue that if we didn't force through a 20MB fork now, and we ran into
> major network difficulties a year from now and had no other technical
> solutions, that maybe we would get nearly universal agreement
>

I doubt it. The disagreement seems more philosophical than technical. If
Bitcoin fell off a cliff then that'd just be taken as more evidence that
block chains don't work and we should all use some network of payment hubs,
or whatever the fashion of the day is. Or anyone who doesn't want to pay
high fees is unimportant. See all the other justifications Gavin is working
his way through on his blog.

That's why I conclude the opposite - if there is no fork, then people's
confidence in Bitcoin will be seriously damaged. If it's impossible to do
something as trivial as removing a temporary hack Satoshi put in place,
then what about bigger challenges? If the community is really willing to
drive itself off a cliff due to political deadlock, then why bother
building things that use Bitcoin at all?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/56a1fd00/attachment.html>

From justusranvier at riseup.net  Thu May  7 15:13:34 2015
From: justusranvier at riseup.net (Justus Ranvier)
Date: Thu, 07 May 2015 17:13:34 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <20150507144918.GA6761@savin.petertodd.org>
References: <554A91BE.6060105@bluematt.me>	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>	<CAJHLa0Mr6aQcVRKtidc+qVR7-esriyp5kzAw1LMHHwOcXhhG+Q@mail.gmail.com>	<554B78DE.20600@localhost.local>
	<20150507144918.GA6761@savin.petertodd.org>
Message-ID: <554B811E.8050000@localhost.local>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 05/07/2015 04:49 PM, Peter Todd wrote:
> 
> I think we'll find an basic assumption of civility to be more 
> productive, until proven otherwise. (e.g. NSA ties)

I'm not sure why you'd construe my post as having anything to do with
accusations like NSA ties.

By "non-Bitcoin" projects I mean any altcoin or off-chain processing
solution.

-----BEGIN PGP SIGNATURE-----

iQIcBAEBAgAGBQJVS4EeAAoJECpf2nDq2eYj/vcQAIUrD+ejUKHQb0k/pcPyzmvy
rl3spbbdLSFN9cBhBOgh5LaVFkCrv4/gW2X4Ih6GGYG3siXjZ2HPDXt+Zbs+bfQE
nrw+IpGTYlbnJ26cFVhZWehr45qY1kMO+DVdnKufEgfVKUdYeq/d3bwL1uru4RU6
UfWihvgGGQkjEb/5ZIpRbWmb7XRP9piZCHi0pgFSa8tNDVjbb9ucKjIfrRuRe+DK
GMhIAQLvIQK4M30SxOnMQLIe3upsQ6JzY+5M28HkcBNKgd0dpZbwByHIJh6/ELTO
Iaf08S0mCySKoZAJFEkeQ3YOgdIlZvwYsflxiEs62Mz9Mz8uuxTo6E21XyFr6iN/
XndXCzlAZBIQuiayEUL4fUM2cmeHcvhHpGNyYjBuLibuiaIzKMBzFQqEZHGA0QzH
QhptbHjTwXLxIEZy94ELH2FbQnTrnOBxOdYfmxGvlmJ0328hThW6N181L3fPHK0v
6zTChZziMhlIoZPX8AGNNsUYJFKBJs/khlbse/tQhXmm5zuIyq+Lt0nKjbhHkWJw
n9y4PHxLVtmmOvptPMm00l5/w6yb8Qmxo81d6kq75ZEupjxupHH6YwjHWTehT/x2
Pt8iMX2NWVnVwVdsaqE/rH+JrgH1Pvl7TMqXMr8d7tuSWTeTBWlrcmZbS1rl0Z3T
f8K2rBX6sBqmrD1xKDsn
=5pB6
-----END PGP SIGNATURE-----
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0xEAD9E623.asc
Type: application/pgp-keys
Size: 18381 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/4f43f1c8/attachment.bin>

From justusranvier at riseup.net  Thu May  7 15:16:50 2015
From: justusranvier at riseup.net (Justus Ranvier)
Date: Thu, 07 May 2015 17:16:50 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CAJHLa0OXpbAeDsQknR0HewasPq0PYPLNU3yWJ+xzerB6CXX7jw@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>	<CAJHLa0Mr6aQcVRKtidc+qVR7-esriyp5kzAw1LMHHwOcXhhG+Q@mail.gmail.com>	<554B78DE.20600@localhost.local>
	<CAJHLa0OXpbAeDsQknR0HewasPq0PYPLNU3yWJ+xzerB6CXX7jw@mail.gmail.com>
Message-ID: <554B81E2.6070607@localhost.local>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 05/07/2015 05:04 PM, Jeff Garzik wrote:
> heh - I tend to think people here want bitcoin to succeed.  My
> statement refers to picking winners and losers from within the
> existing bitcoin community & stakeholders.

"Success" is not a sufficiently precise term in this context.

There is a large contingent of people for whom the definition of
Bitcoin "success" means serving as a stable backend which can meet the
needs of their non-Bitcoin platform - and nothing more.

To be extremely specific: should Bitcoin development intenionally
limit the network's capabilities to leave room for other projects, or
should Bitcoin attempt to be the best system possible and let the
other projects try to keep up as best they can?

-----BEGIN PGP SIGNATURE-----

iQIcBAEBAgAGBQJVS4HiAAoJECpf2nDq2eYj23wP/j4ksm2dgzDkccMRbqFM8Pm8
oV6ImxM26bG3DJB+Rh6ttTY4DrUnZJmzQUUxfZUd3TmH/xOM4Lu35gKKhpvHTdR8
vMQz76CaTba6PzzFKC+GYyHueXLtwJxEHEZjR8m5ijPMfZoImfMbduggDaPLv/sz
AUcTDtYWBoPZ9Matms4NZIOsH1S1pHw5YjcFYgxmY6ErHZPqZjoKzcc4wZnrOU+Q
HCmiHOJ1U87jEge4QEJCXidCJFakyMTWt5P6hjdOFfky3VYmcoivYRA1ZemgyV2Y
YyLtmHBcK7k67Tczep8rjggvK2C2oJArFGPLWHZH9bxXILaNXSpZX5G5rXZjp1vm
1voc6JDaK/slXIlfG+BZ56WyprKkiFbN6u4Wd8LG5W8gKiuCyLYr2IGKz9O3fvor
NYtk6ELPfX1+0JBD0ureI7kV85D/ybNnnmMp/NyfmBKzzmqnANRrrqL5zgILuUP4
YaokcVdPpTqkN0vuAXchehEemF5MtJIYf9BayZ86ck68aMjvVJi0nX3n63f1MulP
IbRbYY/8eu1891lNIPiSzbmT0zjjplo8jYEOTg32mIvEDZAy8sWwTPYS25tPd37l
3kxRCxqS1ALbAqLZprmxQ375PigE2esXZlpBHzyY4Kf+3UD/k/X8D92vdNiF7mkS
HSA+TX4lf310Eq6Mb4LR
=5vaU
-----END PGP SIGNATURE-----
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0xEAD9E623.asc
Type: application/pgp-keys
Size: 18381 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/93fd7d2d/attachment.bin>

From jgarzik at bitpay.com  Thu May  7 15:17:03 2015
From: jgarzik at bitpay.com (Jeff Garzik)
Date: Thu, 7 May 2015 11:17:03 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CANEZrP1tCda9EbYgYu5QHN8ZgBCtGP7zRiDaXnq-rWU0ZHR9NQ@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<CAPWm=eUFe7dKJCLeNACZ4n9vw0Xj9rHVM_RRLSczGXNU-ShR2w@mail.gmail.com>
	<CANEZrP1tCda9EbYgYu5QHN8ZgBCtGP7zRiDaXnq-rWU0ZHR9NQ@mail.gmail.com>
Message-ID: <CAJHLa0Nrp4QEQqrBu6Tb+dohxX2VhWKMnO40xscZF1OJdfPF-A@mail.gmail.com>

On Thu, May 7, 2015 at 11:12 AM, Mike Hearn <mike at plan99.net> wrote:

>
> That's why I conclude the opposite - if there is no fork, then people's
> confidence in Bitcoin will be seriously damaged.
>

Yes, that is a possibility.



> If it's impossible to do something as trivial as removing a temporary hack
> Satoshi put in place, then what about bigger challenges?
>

This is absolutely not a trivial change.

It is a trivial *code* change.  It is not a trivial change to the economics
of a $3.2B system.

-- 
Jeff Garzik
Bitcoin core developer and open source evangelist
BitPay, Inc.      https://bitpay.com/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/9ef5c02d/attachment.html>

From pete at petertodd.org  Thu May  7 15:25:03 2015
From: pete at petertodd.org (Peter Todd)
Date: Thu, 7 May 2015 11:25:03 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554B811E.8050000@localhost.local>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CAJHLa0Mr6aQcVRKtidc+qVR7-esriyp5kzAw1LMHHwOcXhhG+Q@mail.gmail.com>
	<554B78DE.20600@localhost.local>
	<20150507144918.GA6761@savin.petertodd.org>
	<554B811E.8050000@localhost.local>
Message-ID: <20150507152503.GA11268@savin.petertodd.org>

On Thu, May 07, 2015 at 05:13:34PM +0200, Justus Ranvier wrote:
> On 05/07/2015 04:49 PM, Peter Todd wrote:
> > 
> > I think we'll find an basic assumption of civility to be more 
> > productive, until proven otherwise. (e.g. NSA ties)
> 
> I'm not sure why you'd construe my post as having anything to do with
> accusations like NSA ties.

I'm not.

I'm saying dealing with someone with proven NSA ties is one of the few
times when I think the assumption of honest intent should be ignored in
this forum.

Altcoins and non-Bitcoin-blockchain tx systems? Assuming anything other
than honest intent isn't productive in this forum.

-- 
'peter'[:-1]@petertodd.org
00000000000000000622ff7c71c105480baf123fe74df549b5a42596fd8bfbcb
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/ae855353/attachment.sig>

From jgarzik at bitpay.com  Thu May  7 15:27:39 2015
From: jgarzik at bitpay.com (Jeff Garzik)
Date: Thu, 7 May 2015 11:27:39 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554B81E2.6070607@localhost.local>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CAJHLa0Mr6aQcVRKtidc+qVR7-esriyp5kzAw1LMHHwOcXhhG+Q@mail.gmail.com>
	<554B78DE.20600@localhost.local>
	<CAJHLa0OXpbAeDsQknR0HewasPq0PYPLNU3yWJ+xzerB6CXX7jw@mail.gmail.com>
	<554B81E2.6070607@localhost.local>
Message-ID: <CAJHLa0PtftFQiPhMBiYbAP98wMo48RtVvMSZRFuvf=2Gch8cxg@mail.gmail.com>

On Thu, May 7, 2015 at 11:16 AM, Justus Ranvier <justusranvier at riseup.net>
wrote:

> To be extremely specific: should Bitcoin development intenionally
> limit the network's capabilities to leave room for other projects, or
> should Bitcoin attempt to be the best system possible and let the
> other projects try to keep up as best they can?
>


Avoid such narrow, binary thinking.

Referencing the problem described in
http://gavinandresen.ninja/why-increasing-the-max-block-size-is-urgent
(not the solution - block size change - just the problem, tx/block Poisson
mismatch)

This problem - block creation is bursty - is fundamental to bitcoin.
Raising block size does not fix this problem (as [1] notes), but merely
kicks the can down the road a bit, by hiding it from users a bit longer.

Bitcoin is a settlement system, at the most fundamental engineering level.
It will never be an instant payment system for all the world's coffees (or
all the world's stock trades).  It is left to "Layer 2" projects to
engineer around bitcoin's gaps, to produce an instant, secure, trustless,
egalitarian payment system using the bitcoin token.  [1] also notes this.

It is therefore not a binary decision of leaving room for other projects,
or not.  Layer-2 projects are critical to the success of bitcoin, and
complement bitcoin.






[1] http://gavinandresen.ninja/it-must-be-done-but-is-not-a-panacea

Holistic thinking implies you build a full-stack system with bitcoin
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/53f7c4d5/attachment.html>

From mike at plan99.net  Thu May  7 15:29:10 2015
From: mike at plan99.net (Mike Hearn)
Date: Thu, 7 May 2015 17:29:10 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CAJHLa0Nrp4QEQqrBu6Tb+dohxX2VhWKMnO40xscZF1OJdfPF-A@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<CAPWm=eUFe7dKJCLeNACZ4n9vw0Xj9rHVM_RRLSczGXNU-ShR2w@mail.gmail.com>
	<CANEZrP1tCda9EbYgYu5QHN8ZgBCtGP7zRiDaXnq-rWU0ZHR9NQ@mail.gmail.com>
	<CAJHLa0Nrp4QEQqrBu6Tb+dohxX2VhWKMnO40xscZF1OJdfPF-A@mail.gmail.com>
Message-ID: <CANEZrP0bmh5braGO5OKTNJU9VC_9=_1RDqHMx=aJBxT1w-q8oA@mail.gmail.com>

>
> It is a trivial *code* change.  It is not a trivial change to the
> economics of a $3.2B system.
>

Hmm - again I'd argue the opposite.

Up until now Bitcoin has been unconstrained by the hard block size limit.

If we raise it, Bitcoin will continue to be unconstrained by it. That's the
default "continue as we are" position.

If it's not raised, then ....... well, then we're in new territory
entirely. Businesses built on the assumption that Bitcoin could become
popular will suddenly have their basic assumptions invalidated. Users will
leave. The technical code change would be zero, but the economic change
would be significant.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/29da17a8/attachment.html>

From jtimon at jtimon.cc  Thu May  7 15:33:54 2015
From: jtimon at jtimon.cc (=?UTF-8?B?Sm9yZ2UgVGltw7Nu?=)
Date: Thu, 7 May 2015 17:33:54 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
Message-ID: <CABm2gDpgBNjuPLnFiU2TspgLws7JjWnsxih09JG9bQycraS=sQ@mail.gmail.com>

On Thu, May 7, 2015 at 4:05 PM, Mike Hearn <mike at plan99.net> wrote:
>> If his explanation was "I will change my mind after we increase block
>>
>> size", I guess the community should say "then we will just ignore your
>> nack because it makes no sense".
>
>
> Oh good! We can just kick anyone out of the consensus process if we think
> they make no sense.
>
> I guess that means me and Gavin can remove everyone else from the developer
> consensus, because we think trying to stop Bitcoin growing makes no sense.
>
> Do you see the problem with this whole notion? It cannot possibly work.
> Whenever you try and make the idea of developer consensus work, what you end
> up with is "I believe in consensus as long as it goes my way". Which is
> worthless.

That is not what I said. Then you demonstrated that it was absurd.
That's called a straw man argument and it's a well known fallacy, it
is precisely the example of arguments that can be safely ignored.
It is an argument against my admittedly vague definition of
"non-controversial change".
More importantly, I never said anything about "removing anyone", I was
always talking about arguments and not people.
One person could use fallacious arguments to attack or defend a given
proposal and use perfectly valid ones in another, a person can even
mix valid and invalid arguments in the same mail.

>> One thing is the Bitcoin core project where you could argue that the 5
>> committers decide (I don't know why Wladimir would have any more
>> authority than the others).
>
>
> Because he is formally the maintainer.

Yes, the maintainer of the Bitcoin core free software project (I
cannot stressed this enough, that can be forked by anyone), not the
president of Bitcoin the p2p network.

> Maybe you dislike that idea. It's so .... centralised. So let's say Gavin
> commits his patch, because his authority is equal to all other committers.
> Someone else rolls it back. Gavin sets up a cron job to keep committing the
> patch. Game over.
>
> You cannot have committers fighting over what goes in and what doesn't.
> That's madness. There must be a single decision maker for any given
> codebase.

I'm sure that if they become that stupid, developers would move to a
fork of the project in no time.

>> Ok, so in simple terms, you expect people to have to pay enormous fees
>> and/or wait thousands of blocks for their transactions to get included
>> in the chain. Is that correct?
>
>
> No. I'll write an article like the others, it's better than email for more
> complicated discourse.

Ok, thanks in advance.

>> As others have said, if the answer is "forever, adoption is always the
>> most important thing" then we will end up with an improved version of Visa.
>
>
> This appears to be another one of those fundamental areas of disagreement. I
> believe there is no chance of Bitcoin ending up like Visa, even if it is
> wildly successful. I did the calculations years ago that show that won't
> happen:
>
>     https://en.bitcoin.it/wiki/Scalability
>
> Decentralisation is a spectrum and Bitcoin will move around on that spectrum
> over time. But claiming we have to pick between 1mb blocks and "Bitcoin =
> VISA" is silly.

Again, I didn't say any of that. My point is that a network that
becomes too "centralized" (like visa, that is centralized vs p2p, not
vs distributed) doesn't offer any security or decentralization
advantage over current networks (and of course I meant that could
happen with larger blocks, not 1 MB blocks).
I'm sure that's not what the proponents of the size increase want, and
I'm not defending 1 MB as a sacred limit  or anything, but my question
is "where is the limit for them?"
Even a limitless block size would technically work because miners
would limit it to limit the orphan rate. So "no hardcoded consensus
limit on transaction volume/block size" could be a valid answer to the
question "what is the right consensus limit to block size?" for which
there's no real right answer because there is a tradeoff between
transaction volume and centralization.

Should we maintain 1 MB forever? Probably not.
Is 20 MB a bad size? I honestly don't know.
Is this urgent? I don't think so.
Should we rush things when we don't have clear answers to many related
questions? I don't think so.

You think that it is too soon to start restricting transaction volume
in any way. You will answer why in your post.
When is the right time and what is the right limitation then?

I want to have fee competition as soon as possible, at least
temporarily. But you say that it can wait for later.
Ok, when do you think we should make that happen then?
When 20 MB are full, will that be the right time to let the fee market
develop then or will it be urgent to increase the block size again?
Should we directly remove the limit then and let miners handle it as
they want?
If so, why not now?
Maybe we can increase to 2 MB, then wait for fee competition, then
wait for 2 more subsidy halvings and then increase to 11 or 20 MB?
There's so many possibilities that I don't understand how can be
surprising that "20 MB, as soon as possible" is not the obvious answer
to everyone...



From justusranvier at riseup.net  Thu May  7 15:33:45 2015
From: justusranvier at riseup.net (Justus Ranvier)
Date: Thu, 07 May 2015 15:33:45 +0000
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CAJHLa0PtftFQiPhMBiYbAP98wMo48RtVvMSZRFuvf=2Gch8cxg@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CAJHLa0Mr6aQcVRKtidc+qVR7-esriyp5kzAw1LMHHwOcXhhG+Q@mail.gmail.com>
	<554B78DE.20600@localhost.local>
	<CAJHLa0OXpbAeDsQknR0HewasPq0PYPLNU3yWJ+xzerB6CXX7jw@mail.gmail.com>
	<554B81E2.6070607@localhost.local>
	<CAJHLa0PtftFQiPhMBiYbAP98wMo48RtVvMSZRFuvf=2Gch8cxg@mail.gmail.com>
Message-ID: <554B85D9.4010304@localhost.local>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 05/07/2015 03:27 PM, Jeff Garzik wrote:
> On Thu, May 7, 2015 at 11:16 AM, Justus Ranvier
> <justusranvier at riseup.net> wrote:
> 
>> To be extremely specific: should Bitcoin development
>> intenionally limit the network's capabilities to leave room for
>> other projects, or should Bitcoin attempt to be the best system
>> possible and let the other projects try to keep up as best they
>> can?
>> 
> 
> 
> Avoid such narrow, binary thinking.

On 05/07/2015 03:25 PM, Peter Todd wrote:
> Altcoins and non-Bitcoin-blockchain tx systems? Assuming anything 
> other than honest intent isn't productive in this forum.
> 


In summary, I asked a question neither you, nor Peter Todd, want to
answer and want to actively discourage people from even asking at all.

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQIcBAEBAgAGBQJVS4XZAAoJECpf2nDq2eYjwZcP/j4ypIBctC4Wt71KJCx4eJ3u
u8DQAJKKr8BfL/zDu5bwVz0qbIX1+Wv9EwkBSYuYQaLDozDCnlttptr7qNWm62QI
d5Z6HUU+g/Zbk2DSgVK57Hf3G7pzcodRq+fp6O/kNgtdE9OyZnv9giApd6F1Yy7l
wgZxjlpKGMA+qKigHSHIQyu1L2JfWjw7eEiirnDtFaCgTpJqPErigX+2eMdpj8/r
jTP3mEN2qStWYydWfYxfcM68gOZsvFiVBfT7qTkFXSeOdigC4bHMDMew9nqP1hlB
9uo/JESNQ4Z0/WHgDSn9fLbc/UX6SIPVn7vDAj7mZAeyaXYBrXhbHpdqhnOGhDmt
R9aUopGHleY44RujES1rQWSo6D8SWlbmpXThgHU5rlRFKKSCu9/s99s7kVdLFqpS
bGg42qs1LwxDiq2TuMV/9TuP10ibB4mSnKwaglcAHcrbo26ZdMF4T9YwKcEmHIrv
0hCUA0qyvKP3fqfQUVzcssJfWdvjx7/bnwLadrxSOur1IZj+2jJdzPYsT1tSiwL/
XChSN5a00LJWW5+b0ka155sEg8XcBdUECXIQtRpFedCURjeinGuMnEf6gM8NbcNS
yVm5Kptf8BO11r154J93nkc3gU4VFcxudg8smaDcq3amPDkyaNBXQm+rcwIApchL
SOzHWwxtA1q+pLHvxnlk
=Fcdg
-----END PGP SIGNATURE-----
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0xEAD9E623.asc
Type: application/pgp-keys
Size: 18399 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/9cfc7eb5/attachment.bin>

From jgarzik at bitpay.com  Thu May  7 15:35:47 2015
From: jgarzik at bitpay.com (Jeff Garzik)
Date: Thu, 7 May 2015 11:35:47 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CANEZrP0bmh5braGO5OKTNJU9VC_9=_1RDqHMx=aJBxT1w-q8oA@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<CAPWm=eUFe7dKJCLeNACZ4n9vw0Xj9rHVM_RRLSczGXNU-ShR2w@mail.gmail.com>
	<CANEZrP1tCda9EbYgYu5QHN8ZgBCtGP7zRiDaXnq-rWU0ZHR9NQ@mail.gmail.com>
	<CAJHLa0Nrp4QEQqrBu6Tb+dohxX2VhWKMnO40xscZF1OJdfPF-A@mail.gmail.com>
	<CANEZrP0bmh5braGO5OKTNJU9VC_9=_1RDqHMx=aJBxT1w-q8oA@mail.gmail.com>
Message-ID: <CAJHLa0O28N+pKuqaZOvgCV8+TQVqkkOUxUMbSGEta+2MkZjZsA@mail.gmail.com>

Yes - but you must recognize that is precisely 50% of the picture.

Others have made different assumptions - taking the [1MB-constrained]
market *as it exists today*, rather than in some projected future.

Raising the block size limit then becomes a *human decision* to favor some
users over others, a *human decision* to prevent an active and competitive
free fee market developing at 1MB, a *human decision* to keep transaction
fees low to incentivize bitcoin adoption, a *human decision* to value
adoption over decentralization.

These statements are not value judgements - not saying you are wrong -
these are observations of some rather huge, relevant blind spots in this
debate.





On Thu, May 7, 2015 at 11:29 AM, Mike Hearn <mike at plan99.net> wrote:

> It is a trivial *code* change.  It is not a trivial change to the
>> economics of a $3.2B system.
>>
>
> Hmm - again I'd argue the opposite.
>
> Up until now Bitcoin has been unconstrained by the hard block size limit.
>
> If we raise it, Bitcoin will continue to be unconstrained by it. That's
> the default "continue as we are" position.
>
> If it's not raised, then ....... well, then we're in new territory
> entirely. Businesses built on the assumption that Bitcoin could become
> popular will suddenly have their basic assumptions invalidated. Users will
> leave. The technical code change would be zero, but the economic change
> would be significant.
>



-- 
Jeff Garzik
Bitcoin core developer and open source evangelist
BitPay, Inc.      https://bitpay.com/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/a084642c/attachment.html>

From btcdrak at gmail.com  Thu May  7 15:39:32 2015
From: btcdrak at gmail.com (Btc Drak)
Date: Thu, 7 May 2015 16:39:32 +0100
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
Message-ID: <CADJgMzsG-SwaYWHEj7=kGtLTDvyGLeJSbB7-8=03v200eZ5gHQ@mail.gmail.com>

On Thu, May 7, 2015 at 3:05 PM, Mike Hearn <mike at plan99.net> wrote:
>
> Maybe you dislike that idea. It's so .... centralised. So let's say Gavin
> commits his patch, because his authority is equal to all other committers.
> Someone else rolls it back. Gavin sets up a cron job to keep committing the
> patch. Game over.
>
> You cannot have committers fighting over what goes in and what doesn't.
> That's madness. There must be a single decision maker for any given
> codebase.
>

You are conflating consensus with commit access. People with commit access
are maintainers who are *able to merge* pull requests. However, the rules
for bitcoin development are that only patches with consensus get merged. If
any of the maintainers just pushed a change without going through the whole
code review and consensus process there would be uproar, plain and simple.

Please don't conflate commit access with permission to merge because it's
just not the case. No-one can sidestep the requirement to get consensus,
not even the 5 maintainers.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/3061743b/attachment.html>

From jgarzik at bitpay.com  Thu May  7 15:47:00 2015
From: jgarzik at bitpay.com (Jeff Garzik)
Date: Thu, 7 May 2015 11:47:00 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554B85D9.4010304@localhost.local>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CAJHLa0Mr6aQcVRKtidc+qVR7-esriyp5kzAw1LMHHwOcXhhG+Q@mail.gmail.com>
	<554B78DE.20600@localhost.local>
	<CAJHLa0OXpbAeDsQknR0HewasPq0PYPLNU3yWJ+xzerB6CXX7jw@mail.gmail.com>
	<554B81E2.6070607@localhost.local>
	<CAJHLa0PtftFQiPhMBiYbAP98wMo48RtVvMSZRFuvf=2Gch8cxg@mail.gmail.com>
	<554B85D9.4010304@localhost.local>
Message-ID: <CAJHLa0OnzWwSoKYhz=izzeV4pdkvPoMPeawgv2coH0S_cLycWA@mail.gmail.com>

On Thu, May 7, 2015 at 11:33 AM, Justus Ranvier <justusranvier at riseup.net>
wrote:

> In summary, I asked a question neither you, nor Peter Todd, want to
> answer and want to actively discourage people from even asking at all.
>

Incorrect; your question included built-in assumptions with which I
disagree.

Bitcoin needs to be the best it can be (Layer 1), but all solutions cannot
and should not be implemented at Layer 1.

We need to scale up both bitcoin (L1) and solutions built on top of bitcoin
(L2).
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/1b372d9d/attachment.html>

From justusranvier at riseup.net  Thu May  7 15:50:38 2015
From: justusranvier at riseup.net (Justus Ranvier)
Date: Thu, 07 May 2015 17:50:38 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CAJHLa0OnzWwSoKYhz=izzeV4pdkvPoMPeawgv2coH0S_cLycWA@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CAJHLa0Mr6aQcVRKtidc+qVR7-esriyp5kzAw1LMHHwOcXhhG+Q@mail.gmail.com>
	<554B78DE.20600@localhost.local>
	<CAJHLa0OXpbAeDsQknR0HewasPq0PYPLNU3yWJ+xzerB6CXX7jw@mail.gmail.com>
	<554B81E2.6070607@localhost.local>
	<CAJHLa0PtftFQiPhMBiYbAP98wMo48RtVvMSZRFuvf=2Gch8cxg@mail.gmail.com>
	<554B85D9.4010304@localhost.local>
	<CAJHLa0OnzWwSoKYhz=izzeV4pdkvPoMPeawgv2coH0S_cLycWA@mail.gmail.com>
Message-ID: <554B89CE.4010004@localhost.local>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 05/07/2015 05:47 PM, Jeff Garzik wrote:
> Bitcoin needs to be the best it can be (Layer 1), but all solutions
> cannot and should not be implemented at Layer 1.

I can provisionally agree with that statement as long as "all
solutions cannot and should not be implemented at Layer 1" it taken to
be a hypothesis to be tested in the context of each proposed solution
rather than a law of nature.

-----BEGIN PGP SIGNATURE-----

iQIcBAEBAgAGBQJVS4nOAAoJECpf2nDq2eYjZGEP/jvk+RNQO+Zoyp0jc6aup5Aa
USUFk1TYBqbu47vvc3jFHc4V3/BjiwkUKp5bZ4iIxr3xWIA35CcjfpSJEIlEj0zM
OHS2j+eS0WkNWCmWgj+3sJpQBNnqLmdBOG1q6z0aBLGwG7uabo+YAhJjlP8isfcn
cBQPGjeTW82ZZLdkNaThbFr53oTYiVPNqMIIq6orUe5vetQS/zfTyowi7Y9+OT+b
FMXOEmXQTzF415LImJNXOcGFx51YkLe3SuEPEqqIX/+gOcT4HMPuKbqyAu6xXRQK
O7uI+6AjN1mX7Cvt19wYkUggJ7ddVKrHINSzOfsZ+pdF8mdY4TrdwJJhfN0+fnvo
KYW+pmEAFRMveV8SVGJpHQ/pWECKbFiz1SRnDfjlbX/C5mHiHM4EmqCxC1pVDxOU
uDukt+ZIIiP7GwPYxqSknR4lcuwsdFFJf9ldxD+ZRNsmz1l+PkaUUpdkCc9u9rUW
2IyfvPmeeVUPLP9N675kfiM3aKNO7LHN8GhSUe+1Nt/zcXg6xg0QWKdXjC8nykCa
eH9gn0QoQZaZbfKnb8DLwLjCO5LiOzQTgqdo0ZSJtV/CipqyGcBJtFYW2olG/BvO
Ns6qJKG6Ck76Tv31cu3YGpVbBjCxsIovchLh72KjQ9LscYg8y29evcFlnyagsewY
5CQJsAY8apmvNvmxAhRf
=oRV/
-----END PGP SIGNATURE-----
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0xEAD9E623.asc
Type: application/pgp-keys
Size: 18381 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/57fe1c6f/attachment.bin>

From jgarzik at bitpay.com  Thu May  7 15:56:36 2015
From: jgarzik at bitpay.com (Jeff Garzik)
Date: Thu, 7 May 2015 11:56:36 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554A91BE.6060105@bluematt.me>
References: <554A91BE.6060105@bluematt.me>
Message-ID: <CAJHLa0NTuKX7NWM6cuvSgaDnLqiZ-0+CyBE5nwV0SpCRziwkDQ@mail.gmail.com>

Dear list,

Apparently my emails are being marked as spam, despite being sent from
GMail's web interface.  I've pinged our sysadmin.  Thanks for letting
me know.

-- 
Jeff Garzik
Bitcoin core developer and open source evangelist
BitPay, Inc.      https://bitpay.com/



From matthewmitchell at thelibertyportal.com  Thu May  7 15:58:13 2015
From: matthewmitchell at thelibertyportal.com (Matthew Mitchell)
Date: Thu, 07 May 2015 16:58:13 +0100
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
Message-ID: <554B8B95.60905@thelibertyportal.com>

In my personal opinion, this does make some sense to me, assuming I
understood Gavin.

I suppose it could be done with a new flag (like the P2SH flag) which
displays miner support for larger blocks. The new rules would apply when
a large majority of miners support the new rules by counting the number
of flagged blocks over a certain number of blocks on the network in a
deterministic fashion.

This way miners can continue to produce blocks which are supported by
both old and new clients. When it appears most people have migrated to
the new client, miners can start flagging support for the new rules, and
when a large majority of miners agree, the new rules would kick in for
all miners/clients running the new software. Miners could therefore glue
together the network during the migration phase until enough people have
updated to avoid severe fork scenarios. The only problem is ensuring
that miners will continue to support both networks for long enough to
enable successful migration.

And if too many people disagree to make a clean hard fork (too many
people stubbornly stick to the old rules), then it could be that the
hard fork is aborted and everyone goes back to the old rules, or quite
simply that the miners never give support for the new rules despite the
mechanism being included in the new client. In those cases it would be
as if nothing changed.

This way the hard fork would be determined by user participation as
judged by the miners.

If it is done, I can't think of a fairer way.

Matthew Mitchell

On 07/05/15 15:52, Gavin Andresen wrote:
> For reference: the blog post that (re)-started this debate, and which
> links to individual issues, is here:
>   http://gavinandresen.ninja/time-to-roll-out-bigger-blocks
> 
> In it, I asked people to email me objections I might have missed. I
> would still appreciate it if people do that; it is impossible to keep up
> with this mailing list, /r/bitcoin posts and comments, and
> #bitcoin-wizards and also have time to respond thoughtfully to the
> objections raised.
> 
> I would very much like to find some concrete course of action that we
> can come to consensus on. Some compromise so we can tell entrepreneurs
> "THIS is how much transaction volume the main Bitcoin blockchain will be
> able to support over the next eleven years."
> 
> I've been pretty clear on what I think is a reasonable compromise (a
> one-time increase scheduled for early next year), and I have tried to
> explain why I think it it is the right set of tradeoffs.
> 
> There ARE tradeoffs here, and the hard question is what process do we
> use to decide those tradeoffs?  How do we come to consensus? Is it worth
> my time to spend hours responding thoughtfully to every new objection
> raised here, or will the same thing happen that happened last year and
> the year before-- everybody eventually gets tired of arguing
> angels-dancing-on-the-head-of-a-pin, and we're left with the status quo?
> 
> I AM considering contributing some version of the bigger blocksize-limit
> hard-fork patch to the Bitcoin-Xt fork (probably  "target a hobbyist
> with a fast Internet connection, and assume Nelson's law to increase
> over time), and then encouraging merchants and exchanges and web wallets
> and individuals who think it strikes a reasonable balance to run it.
> 
> And then, assuming it became a super-majority of nodes on the network,
> encourage miners to roll out a soft-fork to start producing bigger
> blocks and eventually trigger the hard fork.
> 
> Because ultimately consensus comes down to what software people choose
> to run.
> 
> -- 
> --
> Gavin Andresen
> 
> 
> 
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud 
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> 
> 
> 
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> 

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 819 bytes
Desc: OpenPGP digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/733b3667/attachment.sig>

From mike at plan99.net  Thu May  7 16:11:11 2015
From: mike at plan99.net (Mike Hearn)
Date: Thu, 7 May 2015 18:11:11 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CABm2gDpgBNjuPLnFiU2TspgLws7JjWnsxih09JG9bQycraS=sQ@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABm2gDpgBNjuPLnFiU2TspgLws7JjWnsxih09JG9bQycraS=sQ@mail.gmail.com>
Message-ID: <CANEZrP1ay64jryeUyDJ9Y+1C-Bre1U_1xMyuB4cqQprd1-qbCA@mail.gmail.com>

>
> It is an argument against my admittedly vague definition of
> "non-controversial change".
>

If it's an argument against something you said, it's not a straw man, right
;)

Consensus has to be defined as agreement between a group of people. Who are
those people? If you don't know, it's impossible to decide when there is
consensus or not.

Right now there is this nice warm fuzzy notion that decisions in Bitcoin
Core are made by consensus. "Controversial" changes are avoided. I am
trying to show you that this is just marketing. Nobody can define what
these terms even mean. It would be more accurate to say decisions are
vetoed by whoever shows up and complains enough, regardless of technical
merit. After all, my own getutxo change was merged after a lot of technical
debate (and trolling) ..... then unmerged a day later because "it's a
shitstorm".

So if Gavin showed up and complained a lot about side chains or whatever,
what you're saying is, oh that's different. We'd ignore him. But when
someone else complains about a change they don't like, that's OK.

Heck, I could easily come up with a dozen reasons to object to almost any
change, if I felt like it. Would I then be considered not a part of the
consensus because that'd be convenient?


> I'm sure that's not what the proponents of the size increase want, and
> I'm not defending 1 MB as a sacred limit  or anything, but my question
> is "where is the limit for them?"
>

20mb is an arbitrary number, just like 1mb. It's good enough to keep the
Bitcoin ecosystem operating as it presently does: gentle growth in usage
with the technology that exists and is implemented. Gavin has discussed in
his blog why he chose 20mb, I think. It's the result of some estimates
based on average network/hardware capabilities.

Perhaps one day 20mb will not be enough. Perhaps then the limit will be
raised again, if there is sufficient demand.

You are correct that "no limit at all" is a possible answer. More
precisely, in that case miners would choose. Gavin's original proposal was
20mb+X where X is decided by some incrementing formula over time, chosen to
approximate expected improvements in hardware and software. That was cool
too. The 20mb figure and the formula were an attempt to address the
concerns of people who are worried about the block size increase:  a
meet-in-the-middle compromise.

Unfortunately it's hard to know what other kinds of meet-in-the-middle
compromise could be made here. I'm sure Gavin would consider them if he
knew. But the concerns provided are too vague to address. There are no
numbers in them, for example:

   - We need more research -> how much more?
   - I'm not against changing the size, just not now -> then when?
   - I'm not wedded to 1mb, but not sure 20mb is right -> then what?
   - Full node count is going down -> then what size do you think would fix
   that? 100kb?
   - It will make mining more centralised -> how do you measure that and
   how much centralisation would you accept?

and so on.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/9b9c6281/attachment.html>

From mike at plan99.net  Thu May  7 16:13:47 2015
From: mike at plan99.net (Mike Hearn)
Date: Thu, 7 May 2015 18:13:47 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CAJHLa0NTuKX7NWM6cuvSgaDnLqiZ-0+CyBE5nwV0SpCRziwkDQ@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CAJHLa0NTuKX7NWM6cuvSgaDnLqiZ-0+CyBE5nwV0SpCRziwkDQ@mail.gmail.com>
Message-ID: <CANEZrP3yU+sZxtxwK55pD9f_tuwDNuSF8Y3SVzRfqE6k9gJzvQ@mail.gmail.com>

>
> Dear list,
>
> Apparently my emails are being marked as spam, despite being sent from
> GMail's web interface.  I've pinged our sysadmin.


It's a problem with the mailing list software, not your setup. BitPay could
disable the phishing protections but that seems like a poor solution. The
only real fix is to send from a non @bitpay.com email address. Gmail or
Hotmail will work, I think. Yahoo won't: they enforce the same strict
policies than bitpay does.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/35329308/attachment.html>

From justusranvier at riseup.net  Thu May  7 16:18:32 2015
From: justusranvier at riseup.net (Justus Ranvier)
Date: Thu, 07 May 2015 16:18:32 +0000
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CAJHLa0O28N+pKuqaZOvgCV8+TQVqkkOUxUMbSGEta+2MkZjZsA@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>	<CAPWm=eUFe7dKJCLeNACZ4n9vw0Xj9rHVM_RRLSczGXNU-ShR2w@mail.gmail.com>	<CANEZrP1tCda9EbYgYu5QHN8ZgBCtGP7zRiDaXnq-rWU0ZHR9NQ@mail.gmail.com>	<CAJHLa0Nrp4QEQqrBu6Tb+dohxX2VhWKMnO40xscZF1OJdfPF-A@mail.gmail.com>	<CANEZrP0bmh5braGO5OKTNJU9VC_9=_1RDqHMx=aJBxT1w-q8oA@mail.gmail.com>
	<CAJHLa0O28N+pKuqaZOvgCV8+TQVqkkOUxUMbSGEta+2MkZjZsA@mail.gmail.com>
Message-ID: <554B9058.8000702@localhost.local>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 05/07/2015 03:35 PM, Jeff Garzik wrote:
> Raising the block size limit then becomes a *human decision* to
> favor some users over others, a *human decision* to prevent an
> active and competitive free fee market developing at 1MB, a *human
> decision* to keep transaction fees low to incentivize bitcoin
> adoption, a *human decision* to value adoption over
> decentralization.

At the moment none of the following assertions have been proven true,
yet are constantly cited as if they have been:

* A competitive fee market will develop when the transaction rate
becomes constrained by the block size limit
* More users of Bitcoin means less decentralization

Furthermore, the term "decentralization" is frequently used without
being precisely defined in a way that would allow for such proofs to
be debated.

If there's going to be a debate on those points, then the people
presenting points on both sides should take the time to show their
work and explain the methodology they used to reach their conclusions.

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQIcBAEBAgAGBQJVS5BXAAoJECpf2nDq2eYjC3kQAKQ0Jj8r1gjwpl813NiuatjA
nwXJ+Zn7E+cS8bYsXbaPK1uUgcSdpi/g2jgW+VuUPlqCaNo08Pbp/O7pG5ady9st
o7xJnPxttg7NO3IB7GODCJKK85uBO3dOwPp+pfs8KYCAo5PFTflpeOi4Idbd4w/R
+tvLynpSX9LIZTQaJH2KEbrYUibYHZrr8hj0net9lJP8KeqMnCuiesYzjJ4pUXyE
zN0SQ1v9QnpltbTVxRu1TdRBMjAxEHTJPg1jsv0hhGqIOQGHdwNavGq7+LJBen4T
CvT8ooTmuq0IdihOTttl9ody6Eh0tyGPlbVHiI3c2Emm0HTxz8hN9Rl4lvPgcGdi
EUW12h8ailKLg5uJL53Zp1PO6fgl0Z/WCx/zqIKRPg4lJMf5Rk5Ow86xAeIZrsbr
d/+cJZEhqzPnObxkxgTIzqtG8NHcg9dhKw1xkGAkVpMXMM7Bzdku8WCntIYU4+xI
btQQZlbc5h/S+X9Vcu0rJWmmQp2Q8xeEVGRh4hhA8LZLc1P+1eyESjAMWvsuq+rk
Wd1kPopekhOgK0zw2j55Ov+kJXVa2pDFA7TOpcqxbdLU4eauKC4D+YQlTM4qj285
vyRq+c/AwMCPiEhBeEbppgdgwrIQP9fJ7s+2TAHaWICYlTJWkLitUjN9EBwqv3Yp
LRBrgV7giz8UIrJr3hQZ
=+Qmg
-----END PGP SIGNATURE-----
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0xEAD9E623.asc
Type: application/pgp-keys
Size: 18399 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/94cff866/attachment.bin>

From jtimon at jtimon.cc  Thu May  7 16:21:50 2015
From: jtimon at jtimon.cc (=?UTF-8?B?Sm9yZ2UgVGltw7Nu?=)
Date: Thu, 7 May 2015 18:21:50 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CANEZrP0bmh5braGO5OKTNJU9VC_9=_1RDqHMx=aJBxT1w-q8oA@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<CAPWm=eUFe7dKJCLeNACZ4n9vw0Xj9rHVM_RRLSczGXNU-ShR2w@mail.gmail.com>
	<CANEZrP1tCda9EbYgYu5QHN8ZgBCtGP7zRiDaXnq-rWU0ZHR9NQ@mail.gmail.com>
	<CAJHLa0Nrp4QEQqrBu6Tb+dohxX2VhWKMnO40xscZF1OJdfPF-A@mail.gmail.com>
	<CANEZrP0bmh5braGO5OKTNJU9VC_9=_1RDqHMx=aJBxT1w-q8oA@mail.gmail.com>
Message-ID: <CABm2gDozyxovazcNEjWsRK0KzNJotWTg9X4m3aOfx7Gr_KprxQ@mail.gmail.com>

On Thu, May 7, 2015 at 4:52 PM, Gavin Andresen <gavinandresen at gmail.com> wrote:
> I would very much like to find some concrete course of action that we can
> come to consensus on. Some compromise so we can tell entrepreneurs "THIS is
> how much transaction volume the main Bitcoin blockchain will be able to
> support over the next eleven years."

Mhmm, I hadn't thought about this. This makes sense and actually
explains the urgency on taking a decision better than anything else
I've heard.

On Thu, May 7, 2015 at 5:29 PM, Mike Hearn <mike at plan99.net> wrote:
> If it's not raised, then ....... well, then we're in new territory entirely.
> Businesses built on the assumption that Bitcoin could become popular will
> suddenly have their basic assumptions invalidated. Users will leave. The
> technical code change would be zero, but the economic change would be
> significant.

This, on the other hand, is a non sequitur [1], another type of fallacy.
Well, several of them, actually:

- If it's not raised, then bitcoin cannot become popular
- If it's not raised, then users will leave
- Businesses built on the assumption that Bitcoin could become popular
were also assuming that it's going to be risen.

These statements may even be true, but they're no logical conclusions
even if they seem obvious to you.
I don't think those claims are strictly true, specially because they
involve predictions about what people will do.
But if they're true they require some proof or at least some explanation.

[1] http://en.wikipedia.org/wiki/Non_sequitur_(logic)#Affirming_the_consequent



From jtimon at jtimon.cc  Thu May  7 16:47:53 2015
From: jtimon at jtimon.cc (=?UTF-8?B?Sm9yZ2UgVGltw7Nu?=)
Date: Thu, 7 May 2015 18:47:53 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CANEZrP1ay64jryeUyDJ9Y+1C-Bre1U_1xMyuB4cqQprd1-qbCA@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABm2gDpgBNjuPLnFiU2TspgLws7JjWnsxih09JG9bQycraS=sQ@mail.gmail.com>
	<CANEZrP1ay64jryeUyDJ9Y+1C-Bre1U_1xMyuB4cqQprd1-qbCA@mail.gmail.com>
Message-ID: <CABm2gDq12a8p8+fB14nM5S8CVz=sdESMowZJUeKBwvx16WDSDQ@mail.gmail.com>

On Thu, May 7, 2015 at 6:11 PM, Mike Hearn <mike at plan99.net> wrote:
>> It is an argument against my admittedly vague definition of
>> "non-controversial change".
>
>
> If it's an argument against something you said, it's not a straw man, right
> ;)

Yes, but it was an argument against something I didn't said ;)

> Consensus has to be defined as agreement between a group of people. Who are
> those people? If you don't know, it's impossible to decide when there is
> consensus or not.
>
> Right now there is this nice warm fuzzy notion that decisions in Bitcoin
> Core are made by consensus. "Controversial" changes are avoided. I am trying
> to show you that this is just marketing. Nobody can define what these terms
> even mean. It would be more accurate to say decisions are vetoed by whoever
> shows up and complains enough, regardless of technical merit.

Yes, that's why I drafted a definition for "uncontroversial change"
rather than "change accepted by consensus".
It will still be vague and hard to define, but consensus seems much harder.
And, yes, you're right, it is more like giving power to anyone with
valid arguments to veto hardfork changes.
But as you say, that could lead to make hardforks actually impossible,
so we should limit what constitutes a valid argument.
I later listed some examples of invalid arguments: logical fallacies,
unrelated arguments, outright lies.
Certainly I don't think technical merits should count here or that we
could veto a particular person from vetoing.
We should filter the arguments, not require an identity layer to
blacklist individuals.
We should even accept arguments from anonymous people in the internet
(you know, it wouldn't be the first time).

> Unfortunately it's hard to know what other kinds of meet-in-the-middle
> compromise could be made here. I'm sure Gavin would consider them if he
> knew. But the concerns provided are too vague to address. There are no
> numbers in them, for example:
>
> We need more research -> how much more?

Some research at all about fee market dynamics with limited size that
hasn't happened at all.
If we're increasing the consensus max size maybe we could at least
maintain the 1MB limit as a standard policy limit, so that we can
study it a little bit (like we could have done instead of removing the
initial policy limit).

> I'm not against changing the size, just not now -> then when?

I don't know yet, but I understand now that having a clearer roadmap
is what's actually urgent, not the change itself.

> I'm not wedded to 1mb, but not sure 20mb is right -> then what?

What about 2 MB consensus limit and 1 MB policy limit for now? I know
that's arbitrary too.

> Full node count is going down -> then what size do you think would fix that?
> 100kb?

As others have explained, the number of full nodes is not the
improtant part, but how easy it is to run one.
I think a modest laptop with the average internet connection of say,
India or Brazil, should be able to run a full node.
I haven't made those numbers myself but I'm sure that's possible with
1 MB blocks today, and probably with 2 MB blocks too.

> It will make mining more centralised -> how do you measure that and how much
> centralisation would you accept?

This is an excellent question for both sides.
Unfortunately I don't know the answer to this. Do you?



From matthewmitchell at thelibertyportal.com  Thu May  7 16:47:41 2015
From: matthewmitchell at thelibertyportal.com (Matthew Mitchell)
Date: Thu, 07 May 2015 17:47:41 +0100
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554B8B95.60905@thelibertyportal.com>
References: <554A91BE.6060105@bluematt.me>	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<554B8B95.60905@thelibertyportal.com>
Message-ID: <554B972D.7010405@thelibertyportal.com>

One thing to add is that perhaps in a future version of Bitcoin Core,
there could be an option for users to continue using the old consensus
rules, or an option to support the new rules (an option when they update
and an ability to change in the settings). Both types of user can
benefit from the software updates and choose with a single piece of
software what they support. Information for whether or not a user is
supporting the changes could be included in the version message.
Possibly this information could be incorporated into transactions also.

If they wish to support the new rules, then their client would support
larger blocks when there is majority miner consensus, otherwise their
clients will always only support the old rules.

This way the decision is not being forced upon the user in any way.

Just an idea.

On 07/05/15 16:58, Matthew Mitchell wrote:
> In my personal opinion, this does make some sense to me, assuming I
> understood Gavin.
> 
> I suppose it could be done with a new flag (like the P2SH flag) which
> displays miner support for larger blocks. The new rules would apply when
> a large majority of miners support the new rules by counting the number
> of flagged blocks over a certain number of blocks on the network in a
> deterministic fashion.
> 
> This way miners can continue to produce blocks which are supported by
> both old and new clients. When it appears most people have migrated to
> the new client, miners can start flagging support for the new rules, and
> when a large majority of miners agree, the new rules would kick in for
> all miners/clients running the new software. Miners could therefore glue
> together the network during the migration phase until enough people have
> updated to avoid severe fork scenarios. The only problem is ensuring
> that miners will continue to support both networks for long enough to
> enable successful migration.
> 
> And if too many people disagree to make a clean hard fork (too many
> people stubbornly stick to the old rules), then it could be that the
> hard fork is aborted and everyone goes back to the old rules, or quite
> simply that the miners never give support for the new rules despite the
> mechanism being included in the new client. In those cases it would be
> as if nothing changed.
> 
> This way the hard fork would be determined by user participation as
> judged by the miners.
> 
> If it is done, I can't think of a fairer way.
> 
> Matthew Mitchell
> 
> On 07/05/15 15:52, Gavin Andresen wrote:
>> For reference: the blog post that (re)-started this debate, and which
>> links to individual issues, is here:
>>   http://gavinandresen.ninja/time-to-roll-out-bigger-blocks
>>
>> In it, I asked people to email me objections I might have missed. I
>> would still appreciate it if people do that; it is impossible to keep up
>> with this mailing list, /r/bitcoin posts and comments, and
>> #bitcoin-wizards and also have time to respond thoughtfully to the
>> objections raised.
>>
>> I would very much like to find some concrete course of action that we
>> can come to consensus on. Some compromise so we can tell entrepreneurs
>> "THIS is how much transaction volume the main Bitcoin blockchain will be
>> able to support over the next eleven years."
>>
>> I've been pretty clear on what I think is a reasonable compromise (a
>> one-time increase scheduled for early next year), and I have tried to
>> explain why I think it it is the right set of tradeoffs.
>>
>> There ARE tradeoffs here, and the hard question is what process do we
>> use to decide those tradeoffs?  How do we come to consensus? Is it worth
>> my time to spend hours responding thoughtfully to every new objection
>> raised here, or will the same thing happen that happened last year and
>> the year before-- everybody eventually gets tired of arguing
>> angels-dancing-on-the-head-of-a-pin, and we're left with the status quo?
>>
>> I AM considering contributing some version of the bigger blocksize-limit
>> hard-fork patch to the Bitcoin-Xt fork (probably  "target a hobbyist
>> with a fast Internet connection, and assume Nelson's law to increase
>> over time), and then encouraging merchants and exchanges and web wallets
>> and individuals who think it strikes a reasonable balance to run it.
>>
>> And then, assuming it became a super-majority of nodes on the network,
>> encourage miners to roll out a soft-fork to start producing bigger
>> blocks and eventually trigger the hard fork.
>>
>> Because ultimately consensus comes down to what software people choose
>> to run.
>>
>> -- 
>> --
>> Gavin Andresen
>>
>>
>>
>> ------------------------------------------------------------------------------
>> One dashboard for servers and applications across Physical-Virtual-Cloud 
>> Widest out-of-the-box monitoring support with 50+ applications
>> Performance metrics, stats and reports that give you Actionable Insights
>> Deep dive visibility with transaction tracing using APM Insight.
>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>>
>>
>>
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
> 
> 
> 
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud 
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> 
> 
> 
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> 

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 819 bytes
Desc: OpenPGP digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/97e8772e/attachment.sig>

From john-bodeen at uiowa.edu  Thu May  7 16:54:35 2015
From: john-bodeen at uiowa.edu (John Bodeen)
Date: Thu, 7 May 2015 11:54:35 -0500
Subject: [Bitcoin-development] Block Size Increase
Message-ID: <CANVz8+9TuWNV7+tzMkE95_kYpDLEQOGXf_==o-F-55GF=AisXA@mail.gmail.com>

If the worry about raising the block size will increase centralization,
could not one could imagine an application which rewarded decentralized
storage of block data? It could even be build aside or on top of the
existing bitcoin protocol.

See the Permacoin paper by Andrew Miller:
http://cs.umd.edu/~amiller/permacoin.pdf

Regards
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/fa9b24b0/attachment.html>

From gavinandresen at gmail.com  Thu May  7 16:59:13 2015
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Thu, 7 May 2015 12:59:13 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CABm2gDq12a8p8+fB14nM5S8CVz=sdESMowZJUeKBwvx16WDSDQ@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABm2gDpgBNjuPLnFiU2TspgLws7JjWnsxih09JG9bQycraS=sQ@mail.gmail.com>
	<CANEZrP1ay64jryeUyDJ9Y+1C-Bre1U_1xMyuB4cqQprd1-qbCA@mail.gmail.com>
	<CABm2gDq12a8p8+fB14nM5S8CVz=sdESMowZJUeKBwvx16WDSDQ@mail.gmail.com>
Message-ID: <CABsx9T1nwastEoN12B2Y-TA2V1fYtDcm9-nkiOQNVhXmbCjcGQ@mail.gmail.com>

Fee dynamics seems to come up over and over again in these discussions,
with lots of talk and theorizing.

I hope some data on what is happening with fees right now might help, so I
wrote another blog post (with graphs, which can't be done in a mailing list
post):
   http://gavinandresen.ninja/the-myth-of-not-full-blocks

We don?t need 100% full one megabyte blocks to start to learn about what is
likely to happen as transaction volume rises and/or the one megabyte block
size limit is raised.

-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/2b7608ba/attachment.html>

From pete at petertodd.org  Thu May  7 17:17:32 2015
From: pete at petertodd.org (Peter Todd)
Date: Thu, 7 May 2015 13:17:32 -0400
Subject: [Bitcoin-development] CLTV opcode allocation; long-term plans?
In-Reply-To: <87lhh188zw.fsf@rustcorp.com.au>
References: <20150504050715.GA18856@savin.petertodd.org>
	<87lhh188zw.fsf@rustcorp.com.au>
Message-ID: <20150507171732.GA6033@savin.petertodd.org>

On Thu, May 07, 2015 at 11:05:47AM +0930, Rusty Russell wrote:
> Peter Todd <pete at petertodd.org> writes:
> > That said, if people have strong feelings about this, I would be willing
> > to make OP_CLTV work as follows:
> >
> >     <nLockTime> 1 OP_CLTV
> >
> > Where the 1 selects absolute mode, and all others act as OP_NOP's. A
> > future relative CLTV could then be a future soft-fork implemented as
> > follows:
> >
> >     <relative nLockTime> 2 OP_CLTV
> 
> Mildly prefer to put that the other way around.
> 
> ie. the OP_NOP1 becomes OP_EXTENSION_PREFIX, the next op defines which
> extended opcode it is (must be a push).

There's no good way to implement that option - when the OP_NOPx is
executed all that's available to it without a lot of complex work is
what's already been pushed to the stack, not what will be pushed to the
stack in the future.

-- 
'peter'[:-1]@petertodd.org
000000000000000002761482983864328320badf24d137101fab9a5861a59d30
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/b2acc7b2/attachment.sig>

From rusty at rustcorp.com.au  Thu May  7 01:35:47 2015
From: rusty at rustcorp.com.au (Rusty Russell)
Date: Thu, 07 May 2015 11:05:47 +0930
Subject: [Bitcoin-development] CLTV opcode allocation; long-term plans?
In-Reply-To: <20150504050715.GA18856@savin.petertodd.org>
References: <20150504050715.GA18856@savin.petertodd.org>
Message-ID: <87lhh188zw.fsf@rustcorp.com.au>

Peter Todd <pete at petertodd.org> writes:
> That said, if people have strong feelings about this, I would be willing
> to make OP_CLTV work as follows:
>
>     <nLockTime> 1 OP_CLTV
>
> Where the 1 selects absolute mode, and all others act as OP_NOP's. A
> future relative CLTV could then be a future soft-fork implemented as
> follows:
>
>     <relative nLockTime> 2 OP_CLTV

Mildly prefer to put that the other way around.

ie. the OP_NOP1 becomes OP_EXTENSION_PREFIX, the next op defines which
extended opcode it is (must be a push).

Cheers,
Rusty.



From bitcoin-list at bluematt.me  Thu May  7 17:26:10 2015
From: bitcoin-list at bluematt.me (Matt Corallo)
Date: Thu, 07 May 2015 17:26:10 +0000
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
Message-ID: <554BA032.4040405@bluematt.me>



On 05/07/15 14:52, Gavin Andresen wrote:
> For reference: the blog post that (re)-started this debate, and which
> links to individual issues, is here:
>   http://gavinandresen.ninja/time-to-roll-out-bigger-blocks
> 
> In it, I asked people to email me objections I might have missed. I
> would still appreciate it if people do that; it is impossible to keep up
> with this mailing list, /r/bitcoin posts and comments, and
> #bitcoin-wizards and also have time to respond thoughtfully to the
> objections raised.

People have been sharing the same objections as on this list for months,
I'm not sure what is new here.

> I would very much like to find some concrete course of action that we
> can come to consensus on. Some compromise so we can tell entrepreneurs
> "THIS is how much transaction volume the main Bitcoin blockchain will be
> able to support over the next eleven years."

I think this is a huge issue. You've been wandering around telling
people that the blocksize will increase soon for months, when there is
very clearly no consensus that it should in the short-term future. The
only answer to this that anyone with a clue should give is "it will
very, very likely be able to support at least 1MB blocks roughly every
10 minutes on average for the next eleven years, and it seems likely
that a block size increase of some form will happen at some point in the
next eleven years", anything else is dishonest.



From pete at petertodd.org  Thu May  7 17:29:56 2015
From: pete at petertodd.org (Peter Todd)
Date: Thu, 7 May 2015 13:29:56 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CABm2gDozyxovazcNEjWsRK0KzNJotWTg9X4m3aOfx7Gr_KprxQ@mail.gmail.com>
References: <CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<CAPWm=eUFe7dKJCLeNACZ4n9vw0Xj9rHVM_RRLSczGXNU-ShR2w@mail.gmail.com>
	<CANEZrP1tCda9EbYgYu5QHN8ZgBCtGP7zRiDaXnq-rWU0ZHR9NQ@mail.gmail.com>
	<CAJHLa0Nrp4QEQqrBu6Tb+dohxX2VhWKMnO40xscZF1OJdfPF-A@mail.gmail.com>
	<CANEZrP0bmh5braGO5OKTNJU9VC_9=_1RDqHMx=aJBxT1w-q8oA@mail.gmail.com>
	<CABm2gDozyxovazcNEjWsRK0KzNJotWTg9X4m3aOfx7Gr_KprxQ@mail.gmail.com>
Message-ID: <20150507172956.GB6033@savin.petertodd.org>

On Thu, May 07, 2015 at 06:21:50PM +0200, Jorge Tim?n wrote:
> On Thu, May 7, 2015 at 4:52 PM, Gavin Andresen <gavinandresen at gmail.com> wrote:
> > I would very much like to find some concrete course of action that we can
> > come to consensus on. Some compromise so we can tell entrepreneurs "THIS is
> > how much transaction volume the main Bitcoin blockchain will be able to
> > support over the next eleven years."
> 
> Mhmm, I hadn't thought about this. This makes sense and actually
> explains the urgency on taking a decision better than anything else
> I've heard.

I've spent a lot of time talking to companies about this, and the
problem is telling them that isn't actually very useful; knowing the
supply side of the equation isn't all that useful if you don't know the
demand side. Problem is we don't really have a good handle on what
Bitcoin will be used for in the future, or even for that matter, what
it's actually being used for right now.

As we saw with Satoshidice before and quite possibly will see with smart
contracts (escrows, futures, etc) it's easy for a relatively small
number of use cases to drive a significant amount of transaction volume.
Yet, as Wladimir and others point out, the fundemental underlying
architecture of the blockchain has inherently poor O(n^2) scaling, so
there's always some level of demand where it breaks, and/or incentivizes
actors in the space to push up against "safety stops" like soft
blocksize limits and get them removed.

Note how the response previously to bumping up against soft policy
limits was highly public calls(1) at the first hint of touble: "Mike
Hearn: Soft block size limit reached, action required by YOU"

1) https://bitcointalk.org/index.php?topic=149668.0

-- 
'peter'[:-1]@petertodd.org
000000000000000002761482983864328320badf24d137101fab9a5861a59d30
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/e4fcb555/attachment.sig>

From gavinandresen at gmail.com  Thu May  7 17:40:59 2015
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Thu, 7 May 2015 13:40:59 -0400
Subject: [Bitcoin-development] Fwd:  Block Size Increase
In-Reply-To: <CABsx9T2vAQyZODRE9apu0R1n=LybssQcuTYD7P3mAQH_Fv6QCQ@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<554BA032.4040405@bluematt.me>
	<CABsx9T2vAQyZODRE9apu0R1n=LybssQcuTYD7P3mAQH_Fv6QCQ@mail.gmail.com>
Message-ID: <CABsx9T1mnVjtpC4pnHPBwQQYLktiSABKrTzco7TbnAtZ4Bmj0w@mail.gmail.com>

On Thu, May 7, 2015 at 1:26 PM, Matt Corallo <bitcoin-list at bluematt.me>
wrote:

> I think this is a huge issue. You've been wandering around telling
> people that the blocksize will increase soon for months


I think the strongest thing I've ever said is:

"There is consensus that the max block size much change sooner or later.
There is not yet consensus on exactly how or when. I will be pushing to
change it this year."

This is what "I will be pushing to change it this year" looks like.

-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/e384dd2e/attachment.html>

From pete at petertodd.org  Thu May  7 17:42:20 2015
From: pete at petertodd.org (Peter Todd)
Date: Thu, 7 May 2015 13:42:20 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CABsx9T1nwastEoN12B2Y-TA2V1fYtDcm9-nkiOQNVhXmbCjcGQ@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABm2gDpgBNjuPLnFiU2TspgLws7JjWnsxih09JG9bQycraS=sQ@mail.gmail.com>
	<CANEZrP1ay64jryeUyDJ9Y+1C-Bre1U_1xMyuB4cqQprd1-qbCA@mail.gmail.com>
	<CABm2gDq12a8p8+fB14nM5S8CVz=sdESMowZJUeKBwvx16WDSDQ@mail.gmail.com>
	<CABsx9T1nwastEoN12B2Y-TA2V1fYtDcm9-nkiOQNVhXmbCjcGQ@mail.gmail.com>
Message-ID: <20150507174220.GC6033@savin.petertodd.org>

On Thu, May 07, 2015 at 12:59:13PM -0400, Gavin Andresen wrote:
> Fee dynamics seems to come up over and over again in these discussions,
> with lots of talk and theorizing.
> 
> I hope some data on what is happening with fees right now might help, so I
> wrote another blog post (with graphs, which can't be done in a mailing list
> post):
>    http://gavinandresen.ninja/the-myth-of-not-full-blocks
> 
> We don?t need 100% full one megabyte blocks to start to learn about what is
> likely to happen as transaction volume rises and/or the one megabyte block
> size limit is raised.

Sounds like you're saying we are bumping up against a 1MB limit. However
other than the occasional user who has sent a transaction with an
extremely low/no fee, what evidence do we have that this is or is not
actually impacting meaningful usage form the user's point of view?

Do we have evidence as to how users are coping? e.g. do they send time
sensitive transactiosn with higher fees? Are people conciously moving
low value transactions off the blockchain? Equally, what about the story
with companies? You of course are an advisor to Coinbase, and could give
us some insight into the type of planning payment processors/wallets are
doing.  For instance, does Coinbase have any plans to work with other
wallet providers/payment processors to aggregate fund transfers between
wallet providers - an obvious payment channel application.

-- 
'peter'[:-1]@petertodd.org
00000000000000000232164c96eaa6bf7cbc3dc61ea055840715b5a81ee8f6be
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/60aac99a/attachment.sig>

From mike at plan99.net  Thu May  7 17:43:30 2015
From: mike at plan99.net (Mike Hearn)
Date: Thu, 7 May 2015 19:43:30 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554BA032.4040405@bluematt.me>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<554BA032.4040405@bluematt.me>
Message-ID: <CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>

> The only answer to this that anyone with a clue should give is "it
> will very, very likely be able to support at least 1MB blocks roughly
> every 10 minutes on average for the next eleven years, and it seems
> likely that a block size increase of some form will happen at some point in
> the next eleven years", anything else is dishonest.


Matt, you know better than that. Gavin neither lacks clue nor is he
dishonest.

He has been working on the assumption that other developers are reasonable,
and some kind of compromise solution can be found that everyone can live
with. Hence trying to find a middle ground, hence considering and writing
articles in response to every single objection raised. Hence asking for
suggestions on what to change about the plan, to make it more acceptable.
What more do you want, exactly?

And I'll ask again. Do you have a *specific, credible alternative*? Because
so far I'm not seeing one.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/55e48fed/attachment.html>

From btcdrak at gmail.com  Thu May  7 18:03:55 2015
From: btcdrak at gmail.com (Btc Drak)
Date: Thu, 7 May 2015 19:03:55 +0100
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<554BA032.4040405@bluematt.me>
	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>
Message-ID: <CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>

On Thu, May 7, 2015 at 6:43 PM, Mike Hearn <mike at plan99.net> wrote:
>
> And I'll ask again. Do you have a *specific, credible alternative*?
> Because so far I'm not seeing one.
>

I think you are rubbing against your own presupposition that people must
find and alternative right now. Quite a lot here do not believe there is
any urgency, nor that there is an immanent problem that has to be solved
before the sky falls in.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/ae2e1450/attachment.html>

From jtimon at jtimon.cc  Thu May  7 18:05:22 2015
From: jtimon at jtimon.cc (=?UTF-8?B?Sm9yZ2UgVGltw7Nu?=)
Date: Thu, 7 May 2015 20:05:22 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CABsx9T1nwastEoN12B2Y-TA2V1fYtDcm9-nkiOQNVhXmbCjcGQ@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABm2gDpgBNjuPLnFiU2TspgLws7JjWnsxih09JG9bQycraS=sQ@mail.gmail.com>
	<CANEZrP1ay64jryeUyDJ9Y+1C-Bre1U_1xMyuB4cqQprd1-qbCA@mail.gmail.com>
	<CABm2gDq12a8p8+fB14nM5S8CVz=sdESMowZJUeKBwvx16WDSDQ@mail.gmail.com>
	<CABsx9T1nwastEoN12B2Y-TA2V1fYtDcm9-nkiOQNVhXmbCjcGQ@mail.gmail.com>
Message-ID: <CABm2gDoF=JPOV=FqWBzXFp21=mJc4jJHGDKb1b5PYx28rGqeSw@mail.gmail.com>

On Thu, May 7, 2015 at 6:59 PM, Gavin Andresen <gavinandresen at gmail.com> wrote:
> Fee dynamics seems to come up over and over again in these discussions, with
> lots of talk and theorizing.
>
> I hope some data on what is happening with fees right now might help, so I
> wrote another blog post (with graphs, which can't be done in a mailing list
> post):
>    http://gavinandresen.ninja/the-myth-of-not-full-blocks
>
> We don?t need 100% full one megabyte blocks to start to learn about what is
> likely to happen as transaction volume rises and/or the one megabyte block
> size limit is raised.

Ok, the fact that the fee increases the probability of getting
included faster already is a good thing, the graphs with the
probability of getting included in the next block were less important
to me.
Although scarce space (beyond what miners chose to limit by
themselves) would increase the fee competition, I didn't knew that
there is actually some competition happening already.
So I guess this diminishes the argument for maintaining the limits
longer to observe the results of more scarce space.
Still, I think maintaining a lower policy limit it's a good idea, even
if we decide not to use it to observe that soon.
For example, say we chose the 20 MB consensus limit, we can maintain
the policy limit at 1 MB or move it to 2 MB, and slowly moving it up
later as needed without requiring everyone to upgrade.
Of course, not all miners have to follow the standard policy, but at
least it's something.
So please take this as a suggestion to improve your proposal. You can
argue it like this "if we want to maintain the limits after the
hardfork or increase them slowly, for observing fee dynamics with more
scarce space or for any other reason, those limits can be partially
enforced by the standard policy". I mean, I think that could be a
reasonable compromise for that concrete line of arguments.



From mike at plan99.net  Thu May  7 18:06:09 2015
From: mike at plan99.net (Mike Hearn)
Date: Thu, 7 May 2015 20:06:09 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<554BA032.4040405@bluematt.me>
	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>
	<CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>
Message-ID: <CANEZrP39jWHLF02z-81Z4+9X1vH5+hMuS=-3ED81=Q1o9U=DKw@mail.gmail.com>

>
> I think you are rubbing against your own presupposition that people must
> find and alternative right now. Quite a lot here do not believe there is
> any urgency, nor that there is an immanent problem that has to be solved
> before the sky falls in.
>

I have explained why I believe there is some urgency, whereby "some
urgency" I mean, assuming it takes months to implement, merge, test,
release and for people to upgrade.

But if it makes you happy, imagine that this discussion happens all over
again next year and I ask the same question.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/90b46e94/attachment.html>

From wardell.c at gmail.com  Thu May  7 18:38:10 2015
From: wardell.c at gmail.com (Chris Wardell)
Date: Thu, 7 May 2015 14:38:10 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<554BA032.4040405@bluematt.me>
	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>
	<CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>
Message-ID: <CAEieSeTafYjBCVUotLKBXX=Z3UHBKdi5kU5CFSxXJEmzCudQMg@mail.gmail.com>

Instead of raising the block size to another static number like 20MB, can
we raise it dynamically?

Make the max block size something like:
pow(2, nHeight/100000) * 1MB;  //double every ~2 years
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/fc013153/attachment.html>

From jrn at jrn.me.uk  Thu May  7 18:21:47 2015
From: jrn at jrn.me.uk (Ross Nicoll)
Date: Thu, 07 May 2015 19:21:47 +0100
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CANEZrP39jWHLF02z-81Z4+9X1vH5+hMuS=-3ED81=Q1o9U=DKw@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>	<554BA032.4040405@bluematt.me>	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>	<CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>
	<CANEZrP39jWHLF02z-81Z4+9X1vH5+hMuS=-3ED81=Q1o9U=DKw@mail.gmail.com>
Message-ID: <554BAD3B.2050404@jrn.me.uk>

Can I just add my own support for this - as has been stated elsewhere in 
this discussion, hard forks are difficult, and risky. The earlier we 
have a decision, and the earlier the change goes into the code, the 
easier that is.

Even if the decision was the actual block size change is fine to leave 
until 2020, I'd like to see the code committed ASAP so that every new 
install, and every upgrade from there on gets the new version.

My personal opinion only is that 7 transactions a second is insanely 
limited even if the main chain does nothing but act as a backbone 
between other chains and transaction networks. I don't think that's 
overly controversial. I think 2016 is too early for a 20mb block size, 
though. I'm inclined to suggest a schedule of expansion, say to 2mb in 
2016, 4mb in 2018, 8mb in 2020 and 20mb in 2022 where it stops. The 
intent would be to provide enough size pressure to motivate scaling 
work, while not limiting Bitcoin overly.

Further, I think this highlights that we need more work on fees. Right 
now fees and transactions included are fairly naive, but I'd like to see 
the absolute block size limit as a hard upper bound, with miners 
imposing soft limits based on a balance cost of storage, number of 
outputs vs inputs (and therefore impact on the UTXOs), and risk of 
orphan blocks to determine which transactions are actually worth 
including in each block. If anyone has numbers on block size vs orphan 
rate that would be really useful, BTW.

Ross

On 07/05/2015 19:06, Mike Hearn wrote:
>
>     I think you are rubbing against your own presupposition that
>     people must find and alternative right now. Quite a lot here do
>     not believe there is any urgency, nor that there is an immanent
>     problem that has to be solved before the sky falls in.
>
>
> I have explained why I believe there is some urgency, whereby "some 
> urgency" I mean, assuming it takes months to implement, merge, test, 
> release and for people to upgrade.
>
> But if it makes you happy, imagine that this discussion happens all 
> over again next year and I ask the same question.
>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>
>
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/11ec6034/attachment.html>

From slashdevnull at hotmail.com  Thu May  7 18:40:50 2015
From: slashdevnull at hotmail.com (Gavin Costin)
Date: Fri, 8 May 2015 02:40:50 +0800
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CANEZrP39jWHLF02z-81Z4+9X1vH5+hMuS=-3ED81=Q1o9U=DKw@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<554BA032.4040405@bluematt.me>
	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>
	<CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>
	<CANEZrP39jWHLF02z-81Z4+9X1vH5+hMuS=-3ED81=Q1o9U=DKw@mail.gmail.com>
Message-ID: <BLU436-SMTP318E346839A76DB15D7DC5C6DF0@phx.gbl>

Can anyone opposed to this proposal articulate in plain english the worst
case scenario(s) if it goes ahead?

Some people in the conversation appear to be uncomfortable, perturbed,
defensive etc about the proposal ?. But I am not seeing specifics on why it
is not a feasible plan.

From:  Mike Hearn <mike at plan99.net>
Date:  Friday, 8 May, 2015 2:06 am
To:  Btc Drak <btcdrak at gmail.com>
Cc:  Bitcoin Dev <bitcoin-development at lists.sourceforge.net>
Subject:  Re: [Bitcoin-development] Block Size Increase

> I think you are rubbing against your own presupposition that people must find
> and alternative right now. Quite a lot here do not believe there is any
> urgency, nor that there is an immanent problem that has to be solved before
> the sky falls in.

I have explained why I believe there is some urgency, whereby "some urgency"
I mean, assuming it takes months to implement, merge, test, release and for
people to upgrade.

But if it makes you happy, imagine that this discussion happens all over
again next year and I ask the same question.

----------------------------------------------------------------------------
-- One dashboard for servers and applications across Physical-Virtual-Cloud
Widest out-of-the-box monitoring support with 50+ applications Performance
metrics, stats and reports that give you Actionable Insights Deep dive
visibility with transaction tracing using APM Insight.
http://ad.doubleclick.net/ddm/clk/290420510;117567292;y_____________________
__________________________ Bitcoin-development mailing list
Bitcoin-development at lists.sourceforge.net
https://lists.sourceforge.net/lists/listinfo/bitcoin-development

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/ecf87458/attachment.html>

From btcdrak at gmail.com  Thu May  7 18:46:14 2015
From: btcdrak at gmail.com (Btc Drak)
Date: Thu, 7 May 2015 19:46:14 +0100
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <BLU436-SMTP318E346839A76DB15D7DC5C6DF0@phx.gbl>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<554BA032.4040405@bluematt.me>
	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>
	<CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>
	<CANEZrP39jWHLF02z-81Z4+9X1vH5+hMuS=-3ED81=Q1o9U=DKw@mail.gmail.com>
	<BLU436-SMTP318E346839A76DB15D7DC5C6DF0@phx.gbl>
Message-ID: <CADJgMzvePYATxggBrvm4C=X-_a4fLKzyjqS_E-1Dk5anmE2cog@mail.gmail.com>

On Thu, May 7, 2015 at 7:40 PM, Gavin Costin <slashdevnull at hotmail.com>
wrote:

> Can anyone opposed to this proposal articulate in plain english the worst
> case scenario(s) if it goes ahead?
>
> Some people in the conversation appear to be uncomfortable, perturbed,
> defensive etc about the proposal ?. But I am not seeing specifics on why it
> is not a feasible plan.
>

See this response:
http://www.mail-archive.com/bitcoin-development at lists.sourceforge.net/msg07462.html
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/7ec7417f/attachment.html>

From alex.mizrahi at gmail.com  Thu May  7 18:55:32 2015
From: alex.mizrahi at gmail.com (Alex Mizrahi)
Date: Thu, 7 May 2015 21:55:32 +0300
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CAEieSeTafYjBCVUotLKBXX=Z3UHBKdi5kU5CFSxXJEmzCudQMg@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<554BA032.4040405@bluematt.me>
	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>
	<CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>
	<CAEieSeTafYjBCVUotLKBXX=Z3UHBKdi5kU5CFSxXJEmzCudQMg@mail.gmail.com>
Message-ID: <CAE28kUQWP1FSS=++SFKkiMn_Wik2Vhhxd=SCiZDxt2Mb2D5_yw@mail.gmail.com>

Just to add to the noise, did you consider linear growth?

Unlike exponential growth, it approximates diminishing returns (i.e. tech
advances become slower with time). And unlike single step, it will give
people time to adapt to new realities.

E.g. 2 MB in 2016, 3 MB in 2017 and so on.
So in 20 years we'll get to 20 MB which "ought to be enough for anybody".
But if miners will find 20 MB blocks too overwhelming, they can limit it
through soft work, based on actual data.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/8308767e/attachment.html>

From jrn at jrn.me.uk  Thu May  7 18:59:41 2015
From: jrn at jrn.me.uk (Ross Nicoll)
Date: Thu, 07 May 2015 19:59:41 +0100
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CAEieSeTafYjBCVUotLKBXX=Z3UHBKdi5kU5CFSxXJEmzCudQMg@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>	<554BA032.4040405@bluematt.me>	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>	<CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>
	<CAEieSeTafYjBCVUotLKBXX=Z3UHBKdi5kU5CFSxXJEmzCudQMg@mail.gmail.com>
Message-ID: <554BB61D.1040602@jrn.me.uk>

I'm presuming that schedule is just an example, as you'd end up with 
insanely large block sizes in a few years.

Absolutely, yes, an increase schedule is an option if people agree on 
it, and I think the better option, as the current limit too low, but 
jumping straight to a value big enough for "indefinitely" is a huge jump.

Gave some thought to scaling block size based on transaction fees, but 
suspect it would end up with miners sending huge fees to themselves with 
transactions that aren't relayed (so they only are actioned if they make 
it into a block that miner mines) to make the network allow bigger blocks.

Ross

On 07/05/2015 19:38, Chris Wardell wrote:
> Instead of raising the block size to another static number like 20MB, 
> can we raise it dynamically?
>
> Make the max block size something like:
> pow(2, nHeight/100000) * 1MB;  //double every ~2 years
>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>
>
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/bcea0e35/attachment.html>

From bitcoin-list at bluematt.me  Thu May  7 19:03:52 2015
From: bitcoin-list at bluematt.me (Matt Corallo)
Date: Thu, 07 May 2015 19:03:52 +0000
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>	<554BA032.4040405@bluematt.me>
	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>
Message-ID: <554BB718.6070104@bluematt.me>

Replies inline.

On 05/07/15 17:43, Mike Hearn wrote:
>     The only answer to this that anyone with a clue should give is "it
>     will very, very likely be able to support at least 1MB blocks
>     roughly every 10 minutes on average for the next eleven years, and
>     it seems likely that a block size increase of some form will happen
>     at some point in the next eleven years", anything else is dishonest.
> 
> 
> Matt, you know better than that. Gavin neither lacks clue nor is he
> dishonest. 

No, I dont think Gavin is being deliberately dishonest, and I'm rather
confident he phrased everything in a way that is technically true (ie
the quote in his response). However, others have definitely not taken
away the correct interpretation of what he said, and this is a serious
problem. Setting expectations correctly as this is a very contentious
issue and one that does not appear to be reaching consensus quickly in
the technical community is important.
More generally, consider the situation we're in now. Gavin is going off
pitching this idea to the general public (which, I agree, is an
important step in pulling off a hardfork) while people who actually
study the issues are left wondering why they're being ignored (ie why is
there no consensus-building happening on this list?).


> He has been working on the assumption that other developers are
> reasonable, and some kind of compromise solution can be found that
> everyone can live with. Hence trying to find a middle ground, hence
> considering and writing articles in response to every single objection
> raised. Hence asking for suggestions on what to change about the plan,
> to make it more acceptable. What more do you want, exactly?

The appropriate method of doing any fork, that we seem to have been
following for a long time, is to get consensus here and on IRC and on
github and *then* go pitch to the general public (either directly or by
releasing software) that they should upgrade. I admit that hardforks are
a bit different in that the level of software upgrade required means
additional lead time, but I'm not sure that means starting the
public-pitching phase before there is any kind of consensus forming
(actually, I'd point out that to me there seems to be rahter clear
consensus outside of you and Gavin that we should delay increasing block
size).
As far as I can tell, there has been no discussion of block sizes on
this list since 2013, and while I know Gavin has had many private
conversations with people in this community about the block size, very
little if any of it has happened in public.
If, instead, there had been an intro on the list as "I think we should
do the blocksize increase soon, what do people think?", the response
could likely have focused much more around creating a specific list of
things we should do before we (the technical community) think we are
prepared for a blocksize increase.

> And I'll ask again. Do you have a *specific, credible alternative*?
> Because so far I'm not seeing one.

A specific credible alternative to what? Committing to blocksize
increases tomorrow? Yes, doing more research into this and developing
software around supporting larger block sizes so people feel comfortable
doing it in six months. I acknowledge that Gavin has been putting a lot
of effort into this front, but, judging by this thread, I am far from
the only one who thinks much more needs done.



From jgarzik at bitpay.com  Thu May  7 19:13:23 2015
From: jgarzik at bitpay.com (Jeff Garzik)
Date: Thu, 7 May 2015 15:13:23 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554BB718.6070104@bluematt.me>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<554BA032.4040405@bluematt.me>
	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>
	<554BB718.6070104@bluematt.me>
Message-ID: <CAJHLa0Pjet092XiEOBHgGyvRgdwmLnd1hVajS+SDgXa1BAojVw@mail.gmail.com>

On Thu, May 7, 2015 at 3:03 PM, Matt Corallo <bitcoin-list at bluematt.me>
wrote:
> More generally, consider the situation we're in now. Gavin is going off
> pitching this idea to the general public (which, I agree, is an
> important step in pulling off a hardfork) while people who actually
> study the issues are left wondering why they're being ignored (ie why is
> there no consensus-building happening on this list?).

This sub-thread threatens to veer off into he-said-she-said.

> If, instead, there had been an intro on the list as "I think we should
> do the blocksize increase soon, what do people think?", the response
> could likely have focused much more around creating a specific list of
> things we should do before we (the technical community) think we are
> prepared for a blocksize increase.

Agreed, but that is water under the bridge at this point.  You - rightly -
opened the topic here and now we're discussing it.

Mike and Gavin are due the benefit of doubt because making a change to a
leaderless automaton powered by leaderless open source software is breaking
new ground.  I don't focus so much on how we got to this point, but rather,
where we go from here.

-- 
Jeff Garzik
Bitcoin core developer and open source evangelist
BitPay, Inc.      https://bitpay.com/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/573b8322/attachment.html>

From bitcoin-list at bluematt.me  Thu May  7 19:14:48 2015
From: bitcoin-list at bluematt.me (Matt Corallo)
Date: Thu, 07 May 2015 19:14:48 +0000
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
Message-ID: <554BB9A8.9040604@bluematt.me>

On 05/07/15 11:29, Mike Hearn wrote:
>     Can you please elaborate on what terrible things will happen if we
>     don't increase the block size by winter this year?
> 
> 
> I was referring to winter next year. 0.12 isn't scheduled until the end
> of the year, according to Wladimir. I explained where this figure comes
> from in this article:

On a related note, I'd like to agree strongly with Peter Todd that we
should get away from doing forks-only-in-releases. We can add code to do
a fork and then enable it in 0.11.1 or 0.11.11 if Gavin prefers more 11s.



From etotheipi at gmail.com  Thu May  7 19:31:46 2015
From: etotheipi at gmail.com (Alan Reiner)
Date: Thu, 07 May 2015 15:31:46 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CANEZrP39jWHLF02z-81Z4+9X1vH5+hMuS=-3ED81=Q1o9U=DKw@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>	<554BA032.4040405@bluematt.me>	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>	<CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>
	<CANEZrP39jWHLF02z-81Z4+9X1vH5+hMuS=-3ED81=Q1o9U=DKw@mail.gmail.com>
Message-ID: <554BBDA2.7040508@gmail.com>

This *is* urgent and needs to be handled right now, and I believe Gavin
has the best approach to this.  I have heard Gavin's talks on increasing
the block size, and the two most persuasive points to me were:

(1) Blocks are essentially nearing "full" now.  And by "full" he means
that the reliability of the network (from the average user perspective)
is about to be impacted in a very negative way (I believe it was due to
the inconsistent time between blocks).  I think Gavin said that his
simulations showed 400 kB - 600 kB worth of transactions per 10 min
(approx 3-4 tps) is where things start to behave poorly for certain
classes of transactions.  In other words, we're very close to the
effective limit in terms of maintaining the current "standard of
living", and with a year needed to raise the block time this actually is
urgent.

(2) Leveraging fee pressure at 1MB to solve the problem is actually
really a bad idea.  It's really bad while Bitcoin is still growing, and
relying on fee pressure at 1 MB severely impacts attractiveness and
adoption potential of Bitcoin (due to high fees and unreliability).  But
more importantly, it ignores the fact that for a 7 tps is pathetic for a
global transaction system.  It is a couple orders of magnitude too low
for any meaningful commercial activity to occur.  If we continue with a
cap of 7 tps forever, Bitcoin *will* fail.  Or at best, it will fail to
be useful for the vast majority of the world (which probably leads to
failure).  We shouldn't be talking about fee pressure until we hit 700
tps, which is probably still too low. 

You can argue that side chains and payment channels could alleviate
this.  But how far off are they?  We're going to hit effective 1MB
limits long before we can leverage those in a meaningful way.  Even if
everyone used them, getting a billion people onto the system just can't
happen even at 1 transaction per year per person to get into a payment
channel or move money between side chains.

We get asked all the time by corporate clients about scalability.  A
limit of 7 tps makes them uncomfortable that they are going to invest
all this time into a system that has no chance of handling the economic
activity that they expect it handle.  We always assure them that 7 tps
is not the final answer. 

Satoshi didn't believe 1 MB blocks were the correct answer.  I
personally think this is critical to Bitcoin's long term future.   And
I'm not sure what else Gavin could've done to push this along in a
meaninful way.

-Alan


On 05/07/2015 02:06 PM, Mike Hearn wrote:
>
>     I think you are rubbing against your own presupposition that
>     people must find and alternative right now. Quite a lot here do
>     not believe there is any urgency, nor that there is an immanent
>     problem that has to be solved before the sky falls in.
>
>
> I have explained why I believe there is some urgency, whereby "some
> urgency" I mean, assuming it takes months to implement, merge, test,
> release and for people to upgrade.
>
> But if it makes you happy, imagine that this discussion happens all
> over again next year and I ask the same question.
>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud 
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>
>
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/8d08315a/attachment.html>

From mike at plan99.net  Thu May  7 19:34:02 2015
From: mike at plan99.net (Mike Hearn)
Date: Thu, 7 May 2015 21:34:02 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554BB718.6070104@bluematt.me>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<554BA032.4040405@bluematt.me>
	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>
	<554BB718.6070104@bluematt.me>
Message-ID: <CANEZrP1N-wJNNHU+73FZu_CBvriXn4n+BgG=G1g-dAnEyw4BUQ@mail.gmail.com>

>
> The appropriate method of doing any fork, that we seem to have been
> following for a long time, is to get consensus here and on IRC and on
> github and *then* go pitch to the general public


So your concern is just about the ordering and process of things, and not
about the change itself?

I have witnessed many arguments in IRC about block sizes over the years.
There was another one just a few weeks ago. Pieter left the channel for his
own sanity. IRC is not a good medium for arriving at decisions on things -
many people can't afford to sit on IRC all day and conversations can be
hard to follow. Additionally, they tend to go circular.

That said, I don't know if you can draw a line between the "ins" and "outs"
like that. The general public is watching, commenting and deciding no
matter what. Might as well deal with that and debate in a format more
accessible to all.


> If, instead, there had been an intro on the list as "I think we should
> do the blocksize increase soon, what do people think?"


There have been many such discussions over time. On bitcointalk. On reddit.
On IRC. At developer conferences. Gavin already knew what many of the
objections would be, which is why he started answering them.

But alright. Let's say he should have started a thread. Thanks for starting
it for him.

Now, can we get this specific list of things we should do before we're
prepared?


> A specific credible alternative to what? Committing to blocksize
> increases tomorrow? Yes, doing more research into this and developing
> software around supporting larger block sizes so people feel comfortable
> doing it in six months.


Do you have a specific research suggestion? Gavin has run simulations
across the internet with modified full nodes that use 20mb blocks, using
real data from the block chain. They seem to suggest it works OK.

What software do you have in mind?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/76327a71/attachment.html>

From mike at plan99.net  Thu May  7 19:37:28 2015
From: mike at plan99.net (Mike Hearn)
Date: Thu, 7 May 2015 21:37:28 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CABm2gDozyxovazcNEjWsRK0KzNJotWTg9X4m3aOfx7Gr_KprxQ@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<CAPWm=eUFe7dKJCLeNACZ4n9vw0Xj9rHVM_RRLSczGXNU-ShR2w@mail.gmail.com>
	<CANEZrP1tCda9EbYgYu5QHN8ZgBCtGP7zRiDaXnq-rWU0ZHR9NQ@mail.gmail.com>
	<CAJHLa0Nrp4QEQqrBu6Tb+dohxX2VhWKMnO40xscZF1OJdfPF-A@mail.gmail.com>
	<CANEZrP0bmh5braGO5OKTNJU9VC_9=_1RDqHMx=aJBxT1w-q8oA@mail.gmail.com>
	<CABm2gDozyxovazcNEjWsRK0KzNJotWTg9X4m3aOfx7Gr_KprxQ@mail.gmail.com>
Message-ID: <CANEZrP0TKWESj3-h4k=Shd0R5SXAyGe31C3tQRq7UwK=y4+JTg@mail.gmail.com>

> These statements may even be true, but they're no logical conclusions
> even if they seem obvious to you.
> I don't think those claims are strictly true, specially because they
> involve predictions about what people will do.
> But if they're true they require some proof or at least some explanation.
>

Thank you for your patience, Jorge.

I have written up an explanation of what I think will happen if we run out
of capacity:

   https://medium.com/@octskyward/crash-landing-f5cc19908e32

Now I'm going to go eat some dinner :)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/d9fb7d51/attachment.html>

From jeremie.dl at gmail.com  Thu May  7 19:44:13 2015
From: jeremie.dl at gmail.com (=?UTF-8?B?SsOpcsOpbWllIER1Ym9pcy1MYWNvc3Rl?=)
Date: Thu, 7 May 2015 21:44:13 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CANEZrP0TKWESj3-h4k=Shd0R5SXAyGe31C3tQRq7UwK=y4+JTg@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<CAPWm=eUFe7dKJCLeNACZ4n9vw0Xj9rHVM_RRLSczGXNU-ShR2w@mail.gmail.com>
	<CANEZrP1tCda9EbYgYu5QHN8ZgBCtGP7zRiDaXnq-rWU0ZHR9NQ@mail.gmail.com>
	<CAJHLa0Nrp4QEQqrBu6Tb+dohxX2VhWKMnO40xscZF1OJdfPF-A@mail.gmail.com>
	<CANEZrP0bmh5braGO5OKTNJU9VC_9=_1RDqHMx=aJBxT1w-q8oA@mail.gmail.com>
	<CABm2gDozyxovazcNEjWsRK0KzNJotWTg9X4m3aOfx7Gr_KprxQ@mail.gmail.com>
	<CANEZrP0TKWESj3-h4k=Shd0R5SXAyGe31C3tQRq7UwK=y4+JTg@mail.gmail.com>
Message-ID: <CAJqsvLB4WkevHPTGbV_cxoDAU3CZ3=2FvHXtu_3vO9LXRVF2Ow@mail.gmail.com>

Any proposal to switch to a new hardcorded value so we have time to
*really* figure out later what's next and all implications, is a road
to a gigantic issue later when we want to switch to that "next".

Sure we would have more time to think about, research all
implications, simulate, discuss, etc. But the ability then to agree
enough on a change to roll it out successfully will be much smaller,
because of the economy being built on top of Bitcoin being much larger
and the technical specifications of Bitcoin being closer to a complete
freeze.

What I'm trying to say is that we should look at long term lasting
solutions even if it takes more effort and time right now and puts the
network into some "troubles" for a while, because they're short term
"troubles". (You define "troubles", depending on which side you stand
at the moment...).

I personally believe in adaptive block size mechanisms, because:

(i) common sense tells me harcoding is never a solution for a system
    whose usage is for many aspects unpredictable
(ii) we can't rely on human consensus to adapt it (seeing the mess
     it is already this time).

It would have the advantage to place this block size issue entirely as
part of the algorithmic contract you agree on when you use Bitcoin,
similar to the difficulty adapation or the block reward.


J?r?mie


2015-05-07 21:37 GMT+02:00 Mike Hearn <mike at plan99.net>:
>
>> These statements may even be true, but they're no logical conclusions
>> even if they seem obvious to you.
>> I don't think those claims are strictly true, specially because they
>> involve predictions about what people will do.
>> But if they're true they require some proof or at least some explanation.
>
>
> Thank you for your patience, Jorge.
>
> I have written up an explanation of what I think will happen if we run out
> of capacity:
>
>    https://medium.com/@octskyward/crash-landing-f5cc19908e32
>
> Now I'm going to go eat some dinner :)
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>



From jgarzik at bitpay.com  Thu May  7 19:54:13 2015
From: jgarzik at bitpay.com (Jeff Garzik)
Date: Thu, 7 May 2015 15:54:13 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554BBDA2.7040508@gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<554BA032.4040405@bluematt.me>
	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>
	<CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>
	<CANEZrP39jWHLF02z-81Z4+9X1vH5+hMuS=-3ED81=Q1o9U=DKw@mail.gmail.com>
	<554BBDA2.7040508@gmail.com>
Message-ID: <CAJHLa0NcxOHkrtW2=-JgfsXQJkCO8Ym7icBwMx_2RsaWcPBnTw@mail.gmail.com>

On Thu, May 7, 2015 at 3:31 PM, Alan Reiner <etotheipi at gmail.com> wrote:

>  (1) Blocks are essentially nearing "full" now.  And by "full" he means
> that the reliability of the network (from the average user perspective) is
> about to be impacted in a very negative way
>

Er, to be economically precise, "full" just means fees are no longer zero.
Bitcoin behaves as it always has.  It is no longer basically free to dump
spam into the blockchain, as it is today.

In the short term, blocks are bursty, with some on 1 minute intervals, some
with 60 minute intervals.  This does not change with larger blocks.



> (2) Leveraging fee pressure at 1MB to solve the problem is actually really
> a bad idea.  It's really bad while Bitcoin is still growing, and relying on
> fee pressure at 1 MB severely impacts attractiveness and adoption potential
> of Bitcoin (due to high fees and unreliability).  But more importantly, it
> ignores the fact that for a 7 tps is pathetic for a global transaction
> system.  It is a couple orders of magnitude too low for any meaningful
> commercial activity to occur.  If we continue with a cap of 7 tps forever,
> Bitcoin *will* fail.  Or at best, it will fail to be useful for the vast
> majority of the world (which probably leads to failure).  We shouldn't be
> talking about fee pressure until we hit 700 tps, which is probably still
> too low.
>
 [...]

1) Agree that 7 tps is too low

2) Where do you want to go?  Should bitcoin scale up to handle all the
world's coffees?

This is hugely unrealistic.  700 tps is 100MB blocks, 14.4 GB/day -- just
for a single feed.  If you include relaying to multiple nodes, plus serving
500 million SPV clients en grosse, who has the capacity to run such a
node?  By the time we get to fee pressure, in your scenario, our network
node count is tiny and highly centralized.

3) In RE "fee pressure" -- Do you see the moral hazard to a software-run
system?  It is an intentional, human decision to flood the market with
supply, thereby altering the economics, forcing fees to remain low in the
hopes of achieving adoption.  I'm pro-bitcoin and obviously want to see
bitcoin adoption - but I don't want to sacrifice every decentralized
principle and become a central banker in order to get there.

-- 
Jeff Garzik
Bitcoin core developer and open source evangelist
BitPay, Inc.      https://bitpay.com/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/52c8aa10/attachment.html>

From bernie at hashplex.com  Thu May  7 19:31:53 2015
From: bernie at hashplex.com (Bernard Rihn)
Date: Thu, 7 May 2015 12:31:53 -0700
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CADJgMzvePYATxggBrvm4C=X-_a4fLKzyjqS_E-1Dk5anmE2cog@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<554BA032.4040405@bluematt.me>
	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>
	<CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>
	<CANEZrP39jWHLF02z-81Z4+9X1vH5+hMuS=-3ED81=Q1o9U=DKw@mail.gmail.com>
	<BLU436-SMTP318E346839A76DB15D7DC5C6DF0@phx.gbl>
	<CADJgMzvePYATxggBrvm4C=X-_a4fLKzyjqS_E-1Dk5anmE2cog@mail.gmail.com>
Message-ID: <CAJBhXOKSb_hgPupj39QSPbr3VyQ3nJ2gd0z+YyUMRis-ahWNxg@mail.gmail.com>

It seems to me like some (maybe most) of the pressure is actually external
from companies that might release something that dramatically increases
"adoption" & transaction rates (and that the data on historic rate of
adoption & slumps is somewhat disconnected from their interests in a quick
roll-out)?

It seems like the question actually becomes what is our maximum acceptable
cost (hardware capex & bandwidth & power opex) associated with running a
full node without hardware acceleration and with hardware acceleration
(something which presumably "doesn't exist" yet)? Are we making the
assumption that hardware acceleration for confirmation will become broadly
available and that the primary limiter will become anonymous bandwidth?

Excuse my ignorance, but I imagine somebody must have already looked at
confirmation times vs. block size for various existing hardware platforms
(like at least 3 or 4? maybe a minnowboard, old laptop, and modern desktop
at least?)? Is there an easy way to setup bitcoind or some other script to
test this? (happy to help)

Re Moore's law: yeah, some say stuff like 5nm may never happen. We're
already using EUV with plasma emitters, immersed reflective optics, and
double-patterning... and in storage land switching to helium. Things may
slow A LOT over the next couple decades and I'd guess that a quadratic
increase (both in storage & compute) probably isn't a safe assumption.

On Thu, May 7, 2015 at 11:46 AM, Btc Drak <btcdrak at gmail.com> wrote:

> On Thu, May 7, 2015 at 7:40 PM, Gavin Costin <slashdevnull at hotmail.com>
> wrote:
>
>> Can anyone opposed to this proposal articulate in plain english the worst
>> case scenario(s) if it goes ahead?
>>
>> Some people in the conversation appear to be uncomfortable, perturbed,
>> defensive etc about the proposal ?. But I am not seeing specifics on why it
>> is not a feasible plan.
>>
>
> See this response:
> http://www.mail-archive.com/bitcoin-development at lists.sourceforge.net/msg07462.html
>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/6a87c722/attachment.html>

From btcdrak at gmail.com  Thu May  7 19:57:20 2015
From: btcdrak at gmail.com (Btc Drak)
Date: Thu, 7 May 2015 20:57:20 +0100
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CANEZrP1ay64jryeUyDJ9Y+1C-Bre1U_1xMyuB4cqQprd1-qbCA@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABm2gDpgBNjuPLnFiU2TspgLws7JjWnsxih09JG9bQycraS=sQ@mail.gmail.com>
	<CANEZrP1ay64jryeUyDJ9Y+1C-Bre1U_1xMyuB4cqQprd1-qbCA@mail.gmail.com>
Message-ID: <CADJgMzueczTRZ57-fvh=JwjytP6KBQoQWzBptXvZLu+VFvvrOQ@mail.gmail.com>

On Thu, May 7, 2015 at 5:11 PM, Mike Hearn <mike at plan99.net> wrote:

> Right now there is this nice warm fuzzy notion that decisions in Bitcoin
>> Core are made by consensus. "Controversial" changes are avoided. I am
>> trying to show you that this is just marketing.
>
>
Consensus is arrived when the people who are most active at the time
(active in contributing to discussions, code review, giving opinions etc.)
agreed to ACK. There are a regular staple of active contributors. Bitcoin
development is clearly a meritocracy. The more people participate and
contribute the more weight their opinions hold.


> Nobody can define what these terms even mean. It would be more accurate to
>> say decisions are vetoed by whoever shows up and complains enough,
>> regardless of technical merit. After all, my own getutxo change was merged
>> after a lot of technical debate (and trolling) ..... then unmerged a day
>> later because "it's a shitstorm".
>
>
I am not sure that is fair, your PR was reverted because someone found a
huge exploit in your PR enough to invalidate all your arguments used to get
it merged in the first place.


> So if Gavin showed up and complained a lot about side chains or whatever,
> what you're saying is, oh that's different. We'd ignore him. But when
> someone else complains about a change they don't like, that's OK.
>
> Heck, I could easily come up with a dozen reasons to object to almost any
> change, if I felt like it. Would I then be considered not a part of the
> consensus because that'd be convenient?
>

I don't think it's as simple as that. Objections for the sake of
objections, or unsound technical objections are going to be seen for what
they are. This is a project with of some of the brightest people in the
world in this field. Sure people can be disruptive but their reputation
stand the test of time.

The consensus system might not be perfect, but it almost feels like you
want to declare a state of emergency and suspend all the normal review
process for this proposed hard fork.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/6d310e9c/attachment.html>

From justusranvier at riseup.net  Thu May  7 19:59:18 2015
From: justusranvier at riseup.net (Justus Ranvier)
Date: Thu, 07 May 2015 21:59:18 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CAJHLa0NcxOHkrtW2=-JgfsXQJkCO8Ym7icBwMx_2RsaWcPBnTw@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>	<554BA032.4040405@bluematt.me>	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>	<CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>	<CANEZrP39jWHLF02z-81Z4+9X1vH5+hMuS=-3ED81=Q1o9U=DKw@mail.gmail.com>	<554BBDA2.7040508@gmail.com>
	<CAJHLa0NcxOHkrtW2=-JgfsXQJkCO8Ym7icBwMx_2RsaWcPBnTw@mail.gmail.com>
Message-ID: <554BC416.6030000@localhost.local>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 05/07/2015 09:54 PM, Jeff Garzik wrote:
> By the time we get to fee pressure, in your scenario, our network 
> node count is tiny and highly centralized.

Again, this assertion requires proof.

Simply saying things is not the same as them being true.

-----BEGIN PGP SIGNATURE-----

iQIcBAEBAgAGBQJVS8QWAAoJECpf2nDq2eYj+/4P/2JXxo2RDAg0ptd9aUYVvzp9
KhL33cdmK8kbKBFOVcOuIrlQRzZn9iydIPC165Y40Y6Wrtgw2PoXctuqdQdXaSZI
M3bHuM7mweHyb3xBHNaNHIxfwrMjQQAdOTGO7PZusghDYz2QEj44dhIcNOzO7uTD
fXkhzgJfwu0l0Wqn3v/R9amRUWLE5nlM566xJ2sVtlfBMEyzR5L1GwX1lKNhxeO8
qvkgegsF2Usjz9pIUMSGFxSWZQuTSjHbhbh28JaT/wi6DI3pcTV0FPw95IPImqUh
rbIqcPh43omXrHKEHV/FB+XMItD3VvR9dxogYaFZLv1EU2gnF2IM0cw5a/oyHr+L
C920uEbXrvrMEJw1ftvxQyu6NY5c3/5iVMqz773oQSjOihkZ8P1JvxQnldU6mcoU
RaKM13cxgjSkCqJ5R1iIldFQPCLLWUKJDkPEnGlwdLPF/vwhnCt1PZJTB5hqoCgC
ab5yBVLpLgo7sbizOeX/R3WGp3NjGXDQC93Af/Vr37uiu1ZT+1P1Ow86hsZTRx6b
4d25tSGg7Tw3Bs/YOhJ9AKtlN092Y8/WBMscQu6MaFt6I/1OMX9OVH+veEj/VjwB
L/dxWTRdC0HEKiYv+EuESIRoyTLlCHKBUDBgKbYSMjetg6WW64hYrpxNX7TH20o6
00bWPVV2PcEWuCc230UF
=1bK6
-----END PGP SIGNATURE-----
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0xEAD9E623.asc
Type: application/pgp-keys
Size: 18381 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/a275c96e/attachment.bin>

From jeremie.dl at gmail.com  Thu May  7 20:20:03 2015
From: jeremie.dl at gmail.com (=?UTF-8?B?SsOpcsOpbWllIER1Ym9pcy1MYWNvc3Rl?=)
Date: Thu, 7 May 2015 22:20:03 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CANEZrP0TKWESj3-h4k=Shd0R5SXAyGe31C3tQRq7UwK=y4+JTg@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<CAPWm=eUFe7dKJCLeNACZ4n9vw0Xj9rHVM_RRLSczGXNU-ShR2w@mail.gmail.com>
	<CANEZrP1tCda9EbYgYu5QHN8ZgBCtGP7zRiDaXnq-rWU0ZHR9NQ@mail.gmail.com>
	<CAJHLa0Nrp4QEQqrBu6Tb+dohxX2VhWKMnO40xscZF1OJdfPF-A@mail.gmail.com>
	<CANEZrP0bmh5braGO5OKTNJU9VC_9=_1RDqHMx=aJBxT1w-q8oA@mail.gmail.com>
	<CABm2gDozyxovazcNEjWsRK0KzNJotWTg9X4m3aOfx7Gr_KprxQ@mail.gmail.com>
	<CANEZrP0TKWESj3-h4k=Shd0R5SXAyGe31C3tQRq7UwK=y4+JTg@mail.gmail.com>
Message-ID: <CAJqsvLADjS6V5a5_3F2cS-+kjGFWWmthMg5Dtj1iY6vh+qZLkw@mail.gmail.com>

> I have written up an explanation of what I think will happen if we run out
> of capacity:
>
>    https://medium.com/@octskyward/crash-landing-f5cc19908e32
Looks like a solid description of what would happen.

I fail to see how this description wouldn't be applicable also to a
20MB-network in some time in the future, say ~3 years from now, if
Bitcoin keeps taking off.
If you agree that it will be harder in the future to change the block
limit again, and we switch to hardcoded 20MB, then aren't we just
going from an immediate relief to a future larger blockage?



>
> Now I'm going to go eat some dinner :)
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>



From roy at gnomon.org.uk  Thu May  7 20:00:23 2015
From: roy at gnomon.org.uk (Roy Badami)
Date: Thu, 7 May 2015 21:00:23 +0100
Subject: [Bitcoin-development] Mechanics of a hard fork
Message-ID: <20150507200023.GI63100@giles.gnomon.org.uk>

I'd love to have more discussion of exactly how a hard fork should be
implemented.  I think it might actually be of some value to have rough
consensus on that before we get too bogged down with exactly what the
proposed hard fork should do.  After all, how can we debate whether a
particular hard fork proposal has consensus if we haven't even decided
what level of supermajority is needed to establish consensus?

For instance, back in 2012 Gavin was proposing, effectively, that a
hard fork should require a supermajority of 99% of miners in order to
succeed:

https://gist.github.com/gavinandresen/2355445

More recently, Gavin has proposed that a supermoajority of only 80% of
miners should be needed in order to trigger the hard fork.

http://www.gavintech.blogspot.co.uk/2015/01/twenty-megabytes-testing-results.html

Just now, on this list (see attached message) Gavin seems to be
aluding to some mechanism for a hard fork which involves consensus of
full nodes, and then a soft fork preceeding the hard fork, which I'd
love to see a full explanation of.

FWIW, I think 80% is far too low to establish consensus for a hard
fork.  I think the supermajority of miners should be sufficiently
large that the rump doesn't constitute a viable coin.  If you don't
have that very strong level of consensus then you risk forking Bitcoin
into two competing coins (and I believe we already have one exchange
promissing to trade both forks as long as the blockchains are alive).

As a starting point, I think 35/36th of miners (approximately 97.2%)
is the minimum I would be comfortable with.  It means that the rump
coin will initially have an average confirmation time of 6 hours
(until difficulty, very slowly, adjusts) which is probably far enough
from viable that the majority of holdouts will quickly desert it too.

Thoughs?

roy
-------------- next part --------------
An embedded message was scrubbed...
From: Gavin Andresen <gavinandresen at gmail.com>
Subject: Re: [Bitcoin-development] Block Size Increase
Date: Thu, 7 May 2015 10:52:54 -0400
Size: 9909
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/ed0c3179/attachment.eml>

From tier.nolan at gmail.com  Thu May  7 21:24:45 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Thu, 7 May 2015 22:24:45 +0100
Subject: [Bitcoin-development] Mechanics of a hard fork
In-Reply-To: <20150507200023.GI63100@giles.gnomon.org.uk>
References: <20150507200023.GI63100@giles.gnomon.org.uk>
Message-ID: <CAE-z3OVgX9S0sJqq-iFdkZn_wK-a=Vs4VpNwxpcagDEYFzNSDQ@mail.gmail.com>

In terms of miners, a strong supermajority is arguably sufficient, even 75%
would be enough.

The near total consensus required is merchants and users.  If (almost) all
merchants and users updated and only 75% of the miners updated, then that
would give a successful hard-fork.

On the other hand, if 99.99% of the miners updated and only 75% of
merchants and 75% of users updated, then that would be a serioud split of
the network.

The advantage of strong miner support is that it effectively kills the fork
that follows the old rules.  The 25% of merchants and users sees a
blockchain stall.

Miners are likely to switch to the fork that is worth the most.  A mining
pool could even give 2 different sub-domains.  A hasher can pick which
rule-set to follow.  Most likely, they would converge on the fork which
paid the most, but the old ruleset would likely still have some hashing
power and would eventually re-target.

On Thu, May 7, 2015 at 9:00 PM, Roy Badami <roy at gnomon.org.uk> wrote:

> I'd love to have more discussion of exactly how a hard fork should be
> implemented.  I think it might actually be of some value to have rough
> consensus on that before we get too bogged down with exactly what the
> proposed hard fork should do.  After all, how can we debate whether a
> particular hard fork proposal has consensus if we haven't even decided
> what level of supermajority is needed to establish consensus?
>
> For instance, back in 2012 Gavin was proposing, effectively, that a
> hard fork should require a supermajority of 99% of miners in order to
> succeed:
>
> https://gist.github.com/gavinandresen/2355445
>
> More recently, Gavin has proposed that a supermoajority of only 80% of
> miners should be needed in order to trigger the hard fork.
>
>
> http://www.gavintech.blogspot.co.uk/2015/01/twenty-megabytes-testing-results.html
>
> Just now, on this list (see attached message) Gavin seems to be
> aluding to some mechanism for a hard fork which involves consensus of
> full nodes, and then a soft fork preceeding the hard fork, which I'd
> love to see a full explanation of.
>
> FWIW, I think 80% is far too low to establish consensus for a hard
> fork.  I think the supermajority of miners should be sufficiently
> large that the rump doesn't constitute a viable coin.  If you don't
> have that very strong level of consensus then you risk forking Bitcoin
> into two competing coins (and I believe we already have one exchange
> promissing to trade both forks as long as the blockchains are alive).
>
> As a starting point, I think 35/36th of miners (approximately 97.2%)
> is the minimum I would be comfortable with.  It means that the rump
> coin will initially have an average confirmation time of 6 hours
> (until difficulty, very slowly, adjusts) which is probably far enough
> from viable that the majority of holdouts will quickly desert it too.
>
> Thoughs?
>
> roy
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/a5867f38/attachment.html>

From bitcoin-list at bluematt.me  Thu May  7 21:29:01 2015
From: bitcoin-list at bluematt.me (Matt Corallo)
Date: Thu, 07 May 2015 21:29:01 +0000
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CANEZrP1N-wJNNHU+73FZu_CBvriXn4n+BgG=G1g-dAnEyw4BUQ@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>	<554BA032.4040405@bluematt.me>	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>	<554BB718.6070104@bluematt.me>
	<CANEZrP1N-wJNNHU+73FZu_CBvriXn4n+BgG=G1g-dAnEyw4BUQ@mail.gmail.com>
Message-ID: <554BD91D.6030201@bluematt.me>



On 05/07/15 19:34, Mike Hearn wrote:
>     The appropriate method of doing any fork, that we seem to have been
>     following for a long time, is to get consensus here and on IRC and on
>     github and *then* go pitch to the general public
> 
> 
> So your concern is just about the ordering and process of things, and
> not about the change itself?

No, I'm very concerned about both.

> I have witnessed many arguments in IRC about block sizes over the years.
> There was another one just a few weeks ago. Pieter left the channel for
> his own sanity. IRC is not a good medium for arriving at decisions on
> things - many people can't afford to sit on IRC all day and
> conversations can be hard to follow. Additionally, they tend to go circular.

I agree, thats why this mailing list was created in the first place
(well, also because bitcointalk is too full of spam, but close enought :))

> That said, I don't know if you can draw a line between the "ins" and
> "outs" like that. The general public is watching, commenting and
> deciding no matter what. Might as well deal with that and debate in a
> format more accessible to all.

Its true, just like its true the general public can opt to run any
version of software they want. That said, the greater software
development community has to update /all/ the software across the entire
ecosystem, and thus provide what amounts to a strong recommendation of
which course to take. Additionally, though there are issues (eg if there
was a push to remove the total coin limit) which are purely political,
and thus which should be up to the greater public to decide, the
blocksize increase is not that. It is intricately tied to Bitcoin's
delicate incentive structure, which many of the development community
are far more farmiliar with than the general Bitcoin public. If there
were a listserv that was comprised primarily of people on
#bitcoin-wizards, I might have suggested a discussion there, first, but
there isnt (as far as I know?).

>     If, instead, there had been an intro on the list as "I think we should
>     do the blocksize increase soon, what do people think?"
> 
> 
> There have been many such discussions over time. On bitcointalk. On
> reddit. On IRC. At developer conferences. Gavin already knew what many
> of the objections would be, which is why he started answering them.
> 
> But alright. Let's say he should have started a thread. Thanks for
> starting it for him.
> 
> Now, can we get this specific list of things we should do before we're
> prepared?

Yes....I'm gonna split the topic since this is already far off course
for that :).

>     A specific credible alternative to what? Committing to blocksize
>     increases tomorrow? Yes, doing more research into this and developing
>     software around supporting larger block sizes so people feel comfortable
>     doing it in six months. 
> 
> 
> Do you have a specific research suggestion? Gavin has run simulations
> across the internet with modified full nodes that use 20mb blocks, using
> real data from the block chain. They seem to suggest it works OK.
> 
> What software do you have in mind?

Let me answer that in a new thread :).



From roy at gnomon.org.uk  Thu May  7 21:42:01 2015
From: roy at gnomon.org.uk (Roy Badami)
Date: Thu, 7 May 2015 22:42:01 +0100
Subject: [Bitcoin-development] Mechanics of a hard fork
In-Reply-To: <CAE-z3OVgX9S0sJqq-iFdkZn_wK-a=Vs4VpNwxpcagDEYFzNSDQ@mail.gmail.com>
References: <20150507200023.GI63100@giles.gnomon.org.uk>
	<CAE-z3OVgX9S0sJqq-iFdkZn_wK-a=Vs4VpNwxpcagDEYFzNSDQ@mail.gmail.com>
Message-ID: <20150507214200.GJ63100@giles.gnomon.org.uk>


> On the other hand, if 99.99% of the miners updated and only 75% of
> merchants and 75% of users updated, then that would be a serioud split of
> the network.

But is that a plausible scenario?  Certainly *if* the concensus rules
required a 99% supermajority of miners for the hard fork to go ahead,
then there would be absoltely no rational reason for merchants and
users to refuse to upgrade, even if they don't support the changes
introduces by the hard fork.  Their only choice, if the fork succeeds,
is between the active chain and the one that is effectively stalled -
and, of course, they can make that choice ahead of time.

roy



From pieter.wuille at gmail.com  Thu May  7 21:49:28 2015
From: pieter.wuille at gmail.com (Pieter Wuille)
Date: Thu, 7 May 2015 23:49:28 +0200
Subject: [Bitcoin-development] Mechanics of a hard fork
In-Reply-To: <20150507214200.GJ63100@giles.gnomon.org.uk>
References: <20150507200023.GI63100@giles.gnomon.org.uk>
	<CAE-z3OVgX9S0sJqq-iFdkZn_wK-a=Vs4VpNwxpcagDEYFzNSDQ@mail.gmail.com>
	<20150507214200.GJ63100@giles.gnomon.org.uk>
Message-ID: <CAPg+sBidvTSAKa6exw-XavfDxPWN_6N83VKJpm8dNSBhbXYgUA@mail.gmail.com>

I would not modify my node if the change introduced a perpetual 100 BTC
subsidy per block, even if 99% of miners went along with it.

A hardfork is safe when 100% of (economically relevant) users upgrade. If
miners don't upgrade at that point, they just lose money.

This is why a hashrate-triggered hardfork does not make sense. Either you
believe everyone will upgrade anyway, and the hashrate doesn't matter. Or
you are not certain, and the fork is risky, independent of what hashrate
upgrades.

And the march 2013 fork showed that miners upgrade at a different schedule
than the rest of the network.
On May 7, 2015 5:44 PM, "Roy Badami" <roy at gnomon.org.uk> wrote:

>
> > On the other hand, if 99.99% of the miners updated and only 75% of
> > merchants and 75% of users updated, then that would be a serioud split of
> > the network.
>
> But is that a plausible scenario?  Certainly *if* the concensus rules
> required a 99% supermajority of miners for the hard fork to go ahead,
> then there would be absoltely no rational reason for merchants and
> users to refuse to upgrade, even if they don't support the changes
> introduces by the hard fork.  Their only choice, if the fork succeeds,
> is between the active chain and the one that is effectively stalled -
> and, of course, they can make that choice ahead of time.
>
> roy
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/8a55d889/attachment.html>

From bitcoin-list at bluematt.me  Thu May  7 22:02:09 2015
From: bitcoin-list at bluematt.me (Matt Corallo)
Date: Thu, 07 May 2015 22:02:09 +0000
Subject: [Bitcoin-development] Block Size Increase Requirements
Message-ID: <554BE0E1.5030001@bluematt.me>

OK, so lets do that. I've seen a lot of "I'm not entirely comfortable
with committing to this right now, but think we should eventually", but
not much "I'd be comfortable with committing to this when I see X". In
the interest of ignoring debate and pushing people towards a consensus
at all costs, ( ;) ) I'm gonna go ahead and suggest we talk about the
second.

Personally, there are several things that worry me significantly about
committing to a blocksize increase, which I'd like to see resolved
before I'd consider supporting a blocksize increase commitment.

 * Though there are many proposals floating around which could
significantly decrease block propagation latency, none of them are
implemented today. I'd expect to see these not only implemented but
being used in production (though I dont particularly care about them
being all that stable). I'd want to see measurements of how they perform
both in production and in the face of high packet loss (eg across the
GFW or in the case of small/moderate DoS). In addition, I'd expect to
see analysis of how these systems perform in the worst-case, not just
packet-loss-wise, but in the face of miners attempting to break the system.

 * I'd very much like to see someone working on better scaling
technology, both in terms of development and in terms of getting
traction in the marketplace. I know StrawPay is working on development,
though its not obvious to me how far they are from their website, but I
dont know of any commitments by large players (either SPV wallets,
centralized wallet services, payment processors, or any others) to
support such a system (to be fair, its probably too early for such
players to commit to anything, since anything doesnt exist in public).

 * I'd like to see some better conclusions to the discussion around
long-term incentives within the system. If we're just building Bitcoin
to work in five years, great, but if we want it all to keep working as
subsidy drops significantly, I'd like a better answer than "we'll deal
with it when we get there" or "it will happen, all the predictions based
on people's behavior today say so" (which are hopefully invalid thanks
to the previous point). Ideally, I'd love to see some real free pressure
already on the network starting to develop when we commit to hardforking
in a year. Not just full blocks with some fees because wallets are
including far greater fees than they really need to, but software which
properly handles fees across the ecosystem, smart fee increases when
transactions arent confirming (eg replace-by-fee, which could be limited
to increase-in-fees-only for those worried about double-spends).

I probably forgot one or two and certainly dont want to back myself into
a corner on committing to something here, but those are a few things I
see today as big blockers on larger blocks.

Luckily, people have been making progress on building the software
needed in all of the above for a while now, but I think they're all
very, very immature today.

On 05/07/15 19:13, Jeff Garzik wrote:> On Thu, May 7, 2015 at 3:03 PM,
Matt Corallo <bitcoin-list at bluematt.me
> <mailto:bitcoin-list at bluematt.me>> wrote:
-snip-
>> If, instead, there had been an intro on the list as "I think we should
>> do the blocksize increase soon, what do people think?", the response
>> could likely have focused much more around creating a specific list of
>> things we should do before we (the technical community) think we are
>> prepared for a blocksize increase.
>
> Agreed, but that is water under the bridge at this point.  You - rightly
> - opened the topic here and now we're discussing it.
>
> Mike and Gavin are due the benefit of doubt because making a change to a
> leaderless automaton powered by leaderless open source software is
> breaking new ground.  I don't focus so much on how we got to this point,
> but rather, where we go from here.



From roy at gnomon.org.uk  Thu May  7 22:08:48 2015
From: roy at gnomon.org.uk (Roy Badami)
Date: Thu, 7 May 2015 23:08:48 +0100
Subject: [Bitcoin-development] Mechanics of a hard fork
In-Reply-To: <CAPg+sBidvTSAKa6exw-XavfDxPWN_6N83VKJpm8dNSBhbXYgUA@mail.gmail.com>
References: <20150507200023.GI63100@giles.gnomon.org.uk>
	<CAE-z3OVgX9S0sJqq-iFdkZn_wK-a=Vs4VpNwxpcagDEYFzNSDQ@mail.gmail.com>
	<20150507214200.GJ63100@giles.gnomon.org.uk>
	<CAPg+sBidvTSAKa6exw-XavfDxPWN_6N83VKJpm8dNSBhbXYgUA@mail.gmail.com>
Message-ID: <20150507220848.GK63100@giles.gnomon.org.uk>

On Thu, May 07, 2015 at 11:49:28PM +0200, Pieter Wuille wrote:
> I would not modify my node if the change introduced a perpetual 100 BTC
> subsidy per block, even if 99% of miners went along with it.

Surely, in that scenario Bitcoin is dead.  If the fork you prefer has
only 1% of the hash power it is trivially vulnerably not just to a 51%
attack but to a 501% attack, not to mention the fact that you'd only
be getting one block every 16 hours.

> 
> A hardfork is safe when 100% of (economically relevant) users upgrade. If
> miners don't upgrade at that point, they just lose money.
> 
> This is why a hashrate-triggered hardfork does not make sense. Either you
> believe everyone will upgrade anyway, and the hashrate doesn't matter. Or
> you are not certain, and the fork is risky, independent of what hashrate
> upgrades.

Beliefs are all very well, but they can be wrong.  Of course we should
not go ahead with a fork that we believe to be dangerous, but
requiring a supermajority of miners is surely a wise precaution.  I
fail to see any realistic scenario where 99% of miners vote for the
hard fork to go ahead, and the econonomic majority votes to stay on
the blockchain whose hashrate has just dropped two orders of magnitude
- so low that the mean time between blocks is now over 16 hours.

> 
> And the march 2013 fork showed that miners upgrade at a different schedule
> than the rest of the network.
> On May 7, 2015 5:44 PM, "Roy Badami" <roy at gnomon.org.uk> wrote:
> 
> >
> > > On the other hand, if 99.99% of the miners updated and only 75% of
> > > merchants and 75% of users updated, then that would be a serioud split of
> > > the network.
> >
> > But is that a plausible scenario?  Certainly *if* the concensus rules
> > required a 99% supermajority of miners for the hard fork to go ahead,
> > then there would be absoltely no rational reason for merchants and
> > users to refuse to upgrade, even if they don't support the changes
> > introduces by the hard fork.  Their only choice, if the fork succeeds,
> > is between the active chain and the one that is effectively stalled -
> > and, of course, they can make that choice ahead of time.
> >
> > roy
> >
> >
> > ------------------------------------------------------------------------------
> > One dashboard for servers and applications across Physical-Virtual-Cloud
> > Widest out-of-the-box monitoring support with 50+ applications
> > Performance metrics, stats and reports that give you Actionable Insights
> > Deep dive visibility with transaction tracing using APM Insight.
> > http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> > _______________________________________________
> > Bitcoin-development mailing list
> > Bitcoin-development at lists.sourceforge.net
> > https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> >



From 21xe14 at gmail.com  Thu May  7 23:05:29 2015
From: 21xe14 at gmail.com (21E14)
Date: Thu, 7 May 2015 23:05:29 +0000
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554BD91D.6030201@bluematt.me>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<554BA032.4040405@bluematt.me>
	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>
	<554BB718.6070104@bluematt.me>
	<CANEZrP1N-wJNNHU+73FZu_CBvriXn4n+BgG=G1g-dAnEyw4BUQ@mail.gmail.com>
	<554BD91D.6030201@bluematt.me>
Message-ID: <CAFZQHkH1HYNXMNj5vHAFtpeE47jQkqCnHbQ0vCnutep7FwYGkg@mail.gmail.com>

I am more fazed by PR 5288 and PR 5925 not getting merged in, than by this
thread. So, casting my ballot in favor of the block size increase. Clearly,
we're still rehearsing proper discourse, and that ain't gonna get fixed
here and now.

On Thu, May 7, 2015 at 9:29 PM, Matt Corallo <bitcoin-list at bluematt.me>
wrote:

>
>
> On 05/07/15 19:34, Mike Hearn wrote:
> >     The appropriate method of doing any fork, that we seem to have been
> >     following for a long time, is to get consensus here and on IRC and on
> >     github and *then* go pitch to the general public
> >
> >
> > So your concern is just about the ordering and process of things, and
> > not about the change itself?
>
> No, I'm very concerned about both.
>
> > I have witnessed many arguments in IRC about block sizes over the years.
> > There was another one just a few weeks ago. Pieter left the channel for
> > his own sanity. IRC is not a good medium for arriving at decisions on
> > things - many people can't afford to sit on IRC all day and
> > conversations can be hard to follow. Additionally, they tend to go
> circular.
>
> I agree, thats why this mailing list was created in the first place
> (well, also because bitcointalk is too full of spam, but close enought :))
>
> > That said, I don't know if you can draw a line between the "ins" and
> > "outs" like that. The general public is watching, commenting and
> > deciding no matter what. Might as well deal with that and debate in a
> > format more accessible to all.
>
> Its true, just like its true the general public can opt to run any
> version of software they want. That said, the greater software
> development community has to update /all/ the software across the entire
> ecosystem, and thus provide what amounts to a strong recommendation of
> which course to take. Additionally, though there are issues (eg if there
> was a push to remove the total coin limit) which are purely political,
> and thus which should be up to the greater public to decide, the
> blocksize increase is not that. It is intricately tied to Bitcoin's
> delicate incentive structure, which many of the development community
> are far more farmiliar with than the general Bitcoin public. If there
> were a listserv that was comprised primarily of people on
> #bitcoin-wizards, I might have suggested a discussion there, first, but
> there isnt (as far as I know?).
>
> >     If, instead, there had been an intro on the list as "I think we
> should
> >     do the blocksize increase soon, what do people think?"
> >
> >
> > There have been many such discussions over time. On bitcointalk. On
> > reddit. On IRC. At developer conferences. Gavin already knew what many
> > of the objections would be, which is why he started answering them.
> >
> > But alright. Let's say he should have started a thread. Thanks for
> > starting it for him.
> >
> > Now, can we get this specific list of things we should do before we're
> > prepared?
>
> Yes....I'm gonna split the topic since this is already far off course
> for that :).
>
> >     A specific credible alternative to what? Committing to blocksize
> >     increases tomorrow? Yes, doing more research into this and developing
> >     software around supporting larger block sizes so people feel
> comfortable
> >     doing it in six months.
> >
> >
> > Do you have a specific research suggestion? Gavin has run simulations
> > across the internet with modified full nodes that use 20mb blocks, using
> > real data from the block chain. They seem to suggest it works OK.
> >
> > What software do you have in mind?
>
> Let me answer that in a new thread :).
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/637e045a/attachment.html>

From nicolas.dorier at gmail.com  Thu May  7 23:14:22 2015
From: nicolas.dorier at gmail.com (Nicolas DORIER)
Date: Fri, 8 May 2015 01:14:22 +0200
Subject: [Bitcoin-development] Solution for Block Size Increase
Message-ID: <CALYO6Xuodj3KOeSMSNQcONZctbp6O_4kavYv1G+KxbmDa9P0QQ@mail.gmail.com>

Executive Summary:

I explain the objectives that we should aim to reach agreement without
drama, controversy, and relief the core devs from the central banker role.
(As Jeff Garzik pointed out)
Knowing the objectives, I propose a solution based on the objectives that
can be agreed on tomorrow, would permanently fix the block size problem
without controversy and would be immediately applicable.

The objectives:

There is consensus on the fact that nobody wants the core developers to be
seen as central bankers.
There is also consensus that more decentralization is better than less.
(assuming there is no cost to it)

This means you should reject all arguments based on economical, political
and ideological principles about what Bitcoin should become. This includes:

1) Whether Bitcoin should be storage of value or suitable for coffee
transaction,
2) Whether we need a fee market, block scarcity, and how much of it,
3) Whether we need to periodically increase block size via some voodoo
formula which speculate on future bandwidth and cost of storage,

Taking decisions based on such reasons is what central bankers do, and you
don?t want to be bankers. This follow that decisions should be taken only
for technical and decentralization considerations. (more about
decentralization after)

Scarcity will evolve without you taking any decisions about it, for the
only reason that storage and bandwidth is not free, nor a transaction,
thanks to increased propagation time.
This backed in scarcity will evolve automatically as storage, bandwidth,
encoding, evolve without anybody taking any decision, nor making any
speculation on the future.

Sadly, deciding how much decentralization should be in the system by
tweaking the block size limit is also an economic decision that should not
have its place between the core devs. This follow :

4) Core devs should not decide about the amount of suitable
decentralization by tweaking block size limit,

Still, removing the limit altogether is a no-no, what would happen if a
block of 100 GB is created? Immediately the network would be decentralized,
not only for miners but also for bitcoin service providers. Also, core devs
might have technical consideration on bitcoin core which impose a temporary
limit until the bug resolved.

The solution:

So here is a proposal that address all my points, and, I think, would get a
reasonable consensus. It can be published tomorrow without any controversy,
would be agreed in one year, and can be safely reiterated every year.
Developers will also not have to play politics nor central banker. (well,
it sounds to good to be true, I waiting for being wrong)

The solution is to use block voting. For each block, a miner gives the size
of the block he would like to have at the next deadline (for example, 30
may 2015). The rational choice for them is just enough to clear the memory
pool, maybe a little less if he believes fee pressure is beneficial for
him, maybe a little more if he believes he should leave some room for
increased use.
At the deadline, we take the median of the votes and implement it as a new
block size limit. Reiterate for the next year.

Objectives reached:


   - No central banking decisions on devs shoulder,
   - Votes can start tomorrow,
   - Implementation has only to be ready in one year, (no kick-in-the-can)
   - Will increase as demand is growing,
   - Will increase as network capacity and storage is growing,
   - Bitcoin becomes what miners want, not what core devs and politician
   wants,
   - Implementation reasonably easy,
   - Will get miner consensus, no impact on existing bitcoin services,


Unknown:

   - Effect on bitcoin core stability (core devs might have a valid
   technical reason to impose a limit)
   - Maybe a better statistical function is possible

Additional input for the debate:

Some people were debating whether miners are altruist or act rationally. We
should always expect them to act rationally, but we should not forget the
peculiarity of TCP backoff game: While it is in the best interest of
players to NOT reemit TCP packet with a backoff if the ACK is not received,
everybody does it. (Because of the fallacy that changing a TCP
implementation is costless)

Often, when we think a real life situation is a prisoner dilemma problem,
it turns out that the incentives where just incorrectly modeled.

Core devs, thanks for all your work, but please step out of the banker's
role and focus on where you are the best, I speak as an entrepreneur that
doesn't want decisions about bitcoin to be taken by who has the biggest.
If the decision of the hard limit is taken for other than purely technical
decisions, ie, for the maximization of whatever metric, it will clearly put
you in banker's shoes. As an entrepreneur, I have other things to speculate
than who gets the biggest gun in the core team.
Please consider my solution,

Nicolas Dorier,
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/6a845fc6/attachment.html>

From tier.nolan at gmail.com  Thu May  7 23:32:12 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Fri, 8 May 2015 00:32:12 +0100
Subject: [Bitcoin-development] Assurance contracts to fund the network with
	OP_CHECKLOCKTIMEVERIFY
Message-ID: <CAE-z3OUiK_s-gJtnPquUZbG5aJkJjfo+VYKHgX+Bfcgem+6i9A@mail.gmail.com>

One of the suggestions to avoid the problem of fees going to zero is
assurance contracts.  This lets users (perhaps large merchants or
exchanges) pay to support the network.  If insufficient people pay for the
contract, then it fails.

Mike Hearn suggests one way of achieving it, but it doesn't actually create
an assurance contract.  Miners can exploit the system to convert the
pledges into donations.

https://bitcointalk.org/index.php?topic=157141.msg1821770#msg1821770

Consider a situation in the future where the minting fee has dropped to
almost zero.  A merchant wants to cause block number 1 million to
effectively have a minting fee of 50BTC.

He creates a transaction with one input (0.1BTC) and one output (50BTC) and
signs it using SIGHASH_ANYONE_CAN_PAY.  The output pays to OP_TRUE.  This
means that anyone can spend it.  The miner who includes the transaction
will send it to an address he controls (or pay to fee).  The transaction
has a locktime of 1 million, so that it cannot be included before that
point.

This transaction cannot be included in a block, since the inputs are lower
than the outputs.  The SIGHASH_ANYONE_CAN_PAY field mean that others can
pledge additional funds.  They add more input to add more money and the
same sighash.

There would need to be some kind of notice boeard system for these pledges,
but if enough pledge, then a valid transaction can be created.  It is in
miner's interests to maintain such a notice board.

The problem is that it counts as a pure donation.  Even if only 10BTC has
been pledged, a miner can just add 40BTC of his own money and finish the
transaction.  He nets the 10BTC of the pledges if he wins the block.  If he
loses, nobody sees his 40BTC transaction.  The only risk is if his block is
orphaned and somehow the miner who mines the winning block gets his 40BTC
transaction into his block.

The assurance contract was supposed to mean "If the effective minting fee
for block 1 million is 50 BTC, then I will pay 0.1BTC".  By adding his
40BTC to the transaction the miner converts it to a pure donation.

The key point is that *other* miners don't get 50BTC reward if they find
the block, so it doesn't push up the total hashing power being committed to
the blockchain, that a 50BTC minting fee would achieve.  This is the whole
point of the assurance contract.

OP_CHECKLOCKTIMEVERIFY could be used to solve the problem.

Instead of paying to OP_TRUE, the transaction should pay 50 BTC to "<1
million> OP_CHECKLOCKTIMEVERIFY OP_TRUE" and 0.01BTC to "OP_TRUE".

This means that the transaction could be included into a block well in
advance of the 1 million block point.  Once block 1 million arrives, any
miner would be able to spend the 50 BTC.  The 0.01BTC is the fee for the
block the transaction is included in.

If the contract hasn't been included in a block well in advance, pledgers
would be recommended to spend their pledged input,

It can be used to pledge to many blocks at once.  The transaction could pay
out to lots of 50BTC outputs but with the locktime increasing by for each
output.

For high value transactions, it isn't just the POW of the next block that
matters but all the blocks that are built on top of it.

A pledger might want to say "I will pay 1BTC if the next 100 blocks all
have at least an effective minting fee of 50BTC"
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/fad4c3c9/attachment.html>

From joseph at lightning.network  Thu May  7 23:24:35 2015
From: joseph at lightning.network (Joseph Poon)
Date: Thu, 7 May 2015 16:24:35 -0700
Subject: [Bitcoin-development] Block Size Increase Requirements
In-Reply-To: <554BE0E1.5030001@bluematt.me>
References: <554BE0E1.5030001@bluematt.me>
Message-ID: <20150507232435.GA3550@lightning.network>

Hi Matt,

I agree that starting discussion on how to approach this problem is
necessary and it's difficult taking positions without details on what is
being discussed.

A simple hard 20-megabyte increase will likely create perverse
incentives, perhaps a method can exist with some safe transition. I
think ultimately, the underlying tension with this discussion is about
the relative power of miners. Any transition of blocksize increase will
increase the influence of miners, and it is about understanding the
tradeoffs for each possible approach.

On Thu, May 07, 2015 at 10:02:09PM +0000, Matt Corallo wrote:
>  * I'd like to see some better conclusions to the discussion around
> long-term incentives within the system. If we're just building Bitcoin
> to work in five years, great, but if we want it all to keep working as
> subsidy drops significantly, I'd like a better answer than "we'll deal
> with it when we get there" or "it will happen, all the predictions based
> on people's behavior today say so" (which are hopefully invalid thanks
> to the previous point). Ideally, I'd love to see some real free pressure
> already on the network starting to develop when we commit to hardforking
> in a year. Not just full blocks with some fees because wallets are
> including far greater fees than they really need to, but software which
> properly handles fees across the ecosystem, smart fee increases when
> transactions arent confirming (eg replace-by-fee, which could be limited
> to increase-in-fees-only for those worried about double-spends).

I think the long-term fee incentive structure needs to be significantly
more granular. We've all seen miners and pools take the path of least
resistance; often they just do whatever the community tells them to
blindly. While this status quo can change in the future, I think
designing sane defaults is a good path for any possible transition.

It seems especially reasonable to maintain fee pressure for normal
transactions during a hard-fork transition. It's possible to do so using
some kind of soft-cap structure. Building in a default soft-cap of 1
megabyte for some far future scheduled fork would seem like a sane thing
to do for bitcoin-core.

It seems also viable to be far more aggressive. What's your (and the
community's) opinion on some kind of coinbase voting protocol for
soft-cap enforcement? It's possible to write in messages to the coinbase
for a enforcible soft-cap that orphans out any transaction which
violates these rules. It seems safest to have the transition has the
first hardforked block be above 1MB, however, the next block default to
an enforced 1MB block. If miners agree to go above this, they must vote
in their coinbase to do so.

There's a separate discussion about this starting on:
CAE-z3OXnjayLUeHBU0hdwU5pKrJ6fpj7YPtGBMQ7hKXG3Sj6hw at mail.gmail.com

I think defaulting some kind of mechanism on reading the coinbase seems
to be a good idea, I think left alone, miners may not do so. That way,
it's possible to have your cake and eat it too, fee pressure will still
exist, while block sizes can increase (provided it's in the miners'
greater interests to do so).

The Lightning Network's security model in the long-term may rely on a
multi-tier soft-cap, but I'm not sure. If 2nd order systemic miner
incentives were not a concern, a system which has an enforced soft-cap
and permits breaching that soft-cap with some agreed upon much higher
fee would work best. LN works without this, but it seems to be more
secure if some kind of miner consensus rule is reached regarding
prioritizing behavior of 2nd-layer consensus states.

No matter how it's done, certain aspects of the security model of
something like Lightning is reliant upon having block-space
availability for transactions to enter into the blockchain in a timely
manner (since "deprecated" channel states become valid again after some
agreed upon block-time).

I think pretty much everyone agrees that the 1MB block cap will
eventually be a problem. While people may disagree with when that will
be and how it'll play out, I think we're all in agreement that
discussion about it is a good idea, especially when it comes to
resolving blocking concerns.

Starting a discussion on how a hypothetical blocksize increase will
occur and the necessary blocking/want-to-have features/tradeoffs seems
to be a great way to approach this problem. The needs for Lightning
Network may be best optimized by being able to prioritizing a large mass
of timeout transactions at once (when a well-connected node stops
communicating).

-- 
Joseph Poon



From pete at petertodd.org  Fri May  8 00:05:56 2015
From: pete at petertodd.org (Peter Todd)
Date: Thu, 7 May 2015 20:05:56 -0400
Subject: [Bitcoin-development] Block Size Increase Requirements
In-Reply-To: <554BE0E1.5030001@bluematt.me>
References: <554BE0E1.5030001@bluematt.me>
Message-ID: <20150508000556.GA16794@savin.petertodd.org>

On Thu, May 07, 2015 at 10:02:09PM +0000, Matt Corallo wrote:
> OK, so lets do that. I've seen a lot of "I'm not entirely comfortable
> with committing to this right now, but think we should eventually", but
> not much "I'd be comfortable with committing to this when I see X". In
> the interest of ignoring debate and pushing people towards a consensus
> at all costs, ( ;) ) I'm gonna go ahead and suggest we talk about the
> second.
> 
> Personally, there are several things that worry me significantly about
> committing to a blocksize increase, which I'd like to see resolved
> before I'd consider supporting a blocksize increase commitment.
> 
>  * Though there are many proposals floating around which could
> significantly decrease block propagation latency, none of them are
> implemented today. I'd expect to see these not only implemented but
> being used in production (though I dont particularly care about them
> being all that stable). I'd want to see measurements of how they perform
> both in production and in the face of high packet loss (eg across the
> GFW or in the case of small/moderate DoS). In addition, I'd expect to
> see analysis of how these systems perform in the worst-case, not just
> packet-loss-wise, but in the face of miners attempting to break the system.

It's really important that we remember that we're building security
software: it *must* hold up well even in the face of attack. That means
we need to figure out how it can be attacked, what the cost/profits of
such attacks are, and if the holes can be patched.  Just testing the
software with simulated loads is insufficient.

Also, re: breaking, don't forget that this may not be a malicious act.
For instance, someone can send contradictory transactions to different
parts of the network simultaneously to prevent mempool consistency -
there's no easy way to fix this. There are also cases where miners have
different policy than others, e.g. version disagreements, commercial
contracts for tx mining, etc.

Finally, remember that it's not in miners' incentives in many situations
for their blocks to propagate to more than ~30% of the hashing power.(1)

Personally, I'm really skeptical that we'll ever find a block
propagation latency reduction technique that sucesfully meets all the
above criteria without changing the consensus algorithm itself.


* How do we ensure miners don't cheat and stop validating blocks fully
before building on them? This is a significant moral hazard with larger
blocks if fees don't become significant, and can lead to dangerous
forks. Also, think of the incentives: Why would a miner ever switch from
the longest chain, even if they don't actually have the blocks to back
it up?

* We need a clear understanding of how we expect new full nodes, pruned
or not, to sync up to the blockchain. Obviously 20MB blocks
significantly increases the time and data required to sync. Are we
planning on simply giving up on full validation and trusting others for
copies of UTXO sets? Are we going to rely on UTXO commitments? What
happens if the UTXO set size itself increases greatly?

>  * I'd very much like to see someone working on better scaling
> technology, both in terms of development and in terms of getting
> traction in the marketplace. I know StrawPay is working on development,
> though its not obvious to me how far they are from their website, but I
> dont know of any commitments by large players (either SPV wallets,
> centralized wallet services, payment processors, or any others) to
> support such a system (to be fair, its probably too early for such
> players to commit to anything, since anything doesnt exist in public).

A good start would be for those players to commit to the general
principles of these systems; if they can't commit explain why.

For instance I'd be very interested in knowing if services like Coinbase
see legal issues with adopting technologies such as payment channels
between hosted wallet providers, payment processors, etc. I certainly
wouldn't be surprised if they see doing anythign not on-blockchain as a
source of legal uncertainty - based on discussions I've had with
regulatory types in this space it sounds like there's a reasonable
chance protocol details such as requiring that transactions happen on a
public blockchain will be "baked into" regulatory requirements.

>  * I'd like to see some better conclusions to the discussion around
> long-term incentives within the system. If we're just building Bitcoin
> to work in five years, great, but if we want it all to keep working as
> subsidy drops significantly, I'd like a better answer than "we'll deal
> with it when we get there" or "it will happen, all the predictions based
> on people's behavior today say so" (which are hopefully invalid thanks
> to the previous point). Ideally, I'd love to see some real free pressure
> already on the network starting to develop when we commit to hardforking
> in a year.

Agreed.

> Not just full blocks with some fees because wallets are
> including far greater fees than they really need to, but software which
> properly handles fees across the ecosystem, smart fee increases when
> transactions arent confirming (eg replace-by-fee, which could be limited
> to increase-in-fees-only for those worried about double-spends).

FWIW I've got some funding to implement first-seen-safe replace-by-fee.

1) http://www.mail-archive.com/bitcoin-development at lists.sourceforge.net/msg03200.html

-- 
'peter'[:-1]@petertodd.org
00000000000000000fe0a96ac84aeb2e4e5c246e947cd8e759bd5fb158a16caf
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/f6c7c97c/attachment.sig>

From tomh at thinlink.com  Fri May  8 01:40:32 2015
From: tomh at thinlink.com (Tom Harding)
Date: Thu, 07 May 2015 18:40:32 -0700
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CAJHLa0NcxOHkrtW2=-JgfsXQJkCO8Ym7icBwMx_2RsaWcPBnTw@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>	<554BA032.4040405@bluematt.me>	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>	<CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>	<CANEZrP39jWHLF02z-81Z4+9X1vH5+hMuS=-3ED81=Q1o9U=DKw@mail.gmail.com>	<554BBDA2.7040508@gmail.com>
	<CAJHLa0NcxOHkrtW2=-JgfsXQJkCO8Ym7icBwMx_2RsaWcPBnTw@mail.gmail.com>
Message-ID: <554C1410.7050406@thinlink.com>

On 5/7/2015 12:54 PM, Jeff Garzik wrote:
> In the short term, blocks are bursty, with some on 1 minute intervals, 
> some with 60 minute intervals.  This does not change with larger blocks.
>

I'm pretty sure Alan meant that blocks are already filling up after long 
inter-block intervals.


>
> 2) Where do you want to go?  Should bitcoin scale up to handle all the 
> world's coffees?

Alan was very clear.  Right now, he wants to go exactly where Gavin's 
concrete proposal suggests.





From joel.kaartinen at gmail.com  Fri May  8 01:51:35 2015
From: joel.kaartinen at gmail.com (Joel Joonatan Kaartinen)
Date: Fri, 8 May 2015 04:51:35 +0300
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554BBDA2.7040508@gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<554BA032.4040405@bluematt.me>
	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>
	<CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>
	<CANEZrP39jWHLF02z-81Z4+9X1vH5+hMuS=-3ED81=Q1o9U=DKw@mail.gmail.com>
	<554BBDA2.7040508@gmail.com>
Message-ID: <CAGKSKfX2We2OmNPRKNMN5VtykTGVi8szfJp+QZG6yvyVvrWVdQ@mail.gmail.com>

Having observed the customer support nightmare it tends to cause for a
small exchange service when 100% full blocks happen, I've been thinking
that the limit really should be dynamic and respond to demand and the
amount of fees offered. It just doesn't feel right when it takes ages to
burn through the backlog when 100% full is hit for a while. So, while
pondering this, I got an idea that I think has a chance of working that I
can't remember seeing suggested anywhere.

How about basing the maximum valid size for a block on the total bitcoin
days destroyed in that block? That should still stop transaction spam but
naturally expand the block size when there's a backlog of real
transactions. It'd also provide for an indirect mechanism for increasing
the maximum block size based on fees if there's a lot of fees but little
bitcoin days destroyed. In such a situation there'd be incentive to pay
someone to spend an older txout to expand the maximum. I realize this is a
rather half baked idea, but it seems worth considering.

- Joel

On Thu, May 7, 2015 at 10:31 PM, Alan Reiner <etotheipi at gmail.com> wrote:

>  This *is* urgent and needs to be handled right now, and I believe Gavin
> has the best approach to this.  I have heard Gavin's talks on increasing
> the block size, and the two most persuasive points to me were:
>
> (1) Blocks are essentially nearing "full" now.  And by "full" he means
> that the reliability of the network (from the average user perspective) is
> about to be impacted in a very negative way (I believe it was due to the
> inconsistent time between blocks).  I think Gavin said that his simulations
> showed 400 kB - 600 kB worth of transactions per 10 min (approx 3-4 tps) is
> where things start to behave poorly for certain classes of transactions.
> In other words, we're very close to the effective limit in terms of
> maintaining the current "standard of living", and with a year needed to
> raise the block time this actually is urgent.
>
> (2) Leveraging fee pressure at 1MB to solve the problem is actually really
> a bad idea.  It's really bad while Bitcoin is still growing, and relying on
> fee pressure at 1 MB severely impacts attractiveness and adoption potential
> of Bitcoin (due to high fees and unreliability).  But more importantly, it
> ignores the fact that for a 7 tps is pathetic for a global transaction
> system.  It is a couple orders of magnitude too low for any meaningful
> commercial activity to occur.  If we continue with a cap of 7 tps forever,
> Bitcoin *will* fail.  Or at best, it will fail to be useful for the vast
> majority of the world (which probably leads to failure).  We shouldn't be
> talking about fee pressure until we hit 700 tps, which is probably still
> too low.
>
> You can argue that side chains and payment channels could alleviate this.
> But how far off are they?  We're going to hit effective 1MB limits long
> before we can leverage those in a meaningful way.  Even if everyone used
> them, getting a billion people onto the system just can't happen even at 1
> transaction per year per person to get into a payment channel or move money
> between side chains.
>
> We get asked all the time by corporate clients about scalability.  A limit
> of 7 tps makes them uncomfortable that they are going to invest all this
> time into a system that has no chance of handling the economic activity
> that they expect it handle.  We always assure them that 7 tps is not the
> final answer.
>
> Satoshi didn't believe 1 MB blocks were the correct answer.  I personally
> think this is critical to Bitcoin's long term future.   And I'm not sure
> what else Gavin could've done to push this along in a meaninful way.
>
> -Alan
>
>
>
> On 05/07/2015 02:06 PM, Mike Hearn wrote:
>
>     I think you are rubbing against your own presupposition that people
>> must find and alternative right now. Quite a lot here do not believe there
>> is any urgency, nor that there is an immanent problem that has to be solved
>> before the sky falls in.
>>
>
>  I have explained why I believe there is some urgency, whereby "some
> urgency" I mean, assuming it takes months to implement, merge, test,
> release and for people to upgrade.
>
>  But if it makes you happy, imagine that this discussion happens all over
> again next year and I ask the same question.
>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>
>
>
> _______________________________________________
> Bitcoin-development mailing listBitcoin-development at lists.sourceforge.nethttps://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/fa4f0644/attachment.html>

From jgarzik at bitpay.com  Fri May  8 02:09:42 2015
From: jgarzik at bitpay.com (Jeff Garzik)
Date: Thu, 7 May 2015 22:09:42 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554C1410.7050406@thinlink.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<554BA032.4040405@bluematt.me>
	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>
	<CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>
	<CANEZrP39jWHLF02z-81Z4+9X1vH5+hMuS=-3ED81=Q1o9U=DKw@mail.gmail.com>
	<554BBDA2.7040508@gmail.com>
	<CAJHLa0NcxOHkrtW2=-JgfsXQJkCO8Ym7icBwMx_2RsaWcPBnTw@mail.gmail.com>
	<554C1410.7050406@thinlink.com>
Message-ID: <CAJHLa0PeEd19ooHbOHUMxX9-5=iyUng-9GWnQFOn_F3aXxVWLQ@mail.gmail.com>

On Thu, May 7, 2015 at 9:40 PM, Tom Harding <tomh at thinlink.com> wrote:

> On 5/7/2015 12:54 PM, Jeff Garzik wrote:
> > 2) Where do you want to go?  Should bitcoin scale up to handle all the
> > world's coffees?
>
> Alan was very clear.  Right now, he wants to go exactly where Gavin's
> concrete proposal suggests.
>

G proposed 20MB blocks, AFAIK - 140 tps
A proposed 100MB blocks - 700 tps
For ref,
Paypal is around 115 tps
VISA is around 2000 tps (perhaps 4000 tps peak)

I ask again:  where do we want to go?   This is the existential question
behind block size.

Are we trying to build a system that can handle Paypal volumes?  VISA
volumes?

It's not a snarky or sarcastic question:  Are we building a system to
handle all the world's coffees?  Is bitcoin's main chain and network -
Layer 1 - going to receive direct connections from 500m mobile phones,
broadcasting transactions?

We must answer these questions to inform the change being discussed today,
in order to decide what makes the most sense as a new limit.  Any
responsible project of this magnitude must have a better story than "zomg
1MB, therefore I picked 20MB out of a hat"  Must be able to answer /why/
the new limit was picked.

As G notes, changing the block size is simply kicking the can down the
road: http://gavinandresen.ninja/it-must-be-done-but-is-not-a-panacea
Necessarily one must ask, today, what happens when we get to the end of
that newly paved road.

-- 
Jeff Garzik
Bitcoin core developer and open source evangelist
BitPay, Inc.      https://bitpay.com/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/f1a12b68/attachment.html>

From adam at cypherspace.org  Fri May  8 02:16:12 2015
From: adam at cypherspace.org (Adam Back)
Date: Thu, 7 May 2015 19:16:12 -0700
Subject: [Bitcoin-development] Mechanics of a hard fork
In-Reply-To: <20150507220848.GK63100@giles.gnomon.org.uk>
References: <20150507200023.GI63100@giles.gnomon.org.uk>
	<CAE-z3OVgX9S0sJqq-iFdkZn_wK-a=Vs4VpNwxpcagDEYFzNSDQ@mail.gmail.com>
	<20150507214200.GJ63100@giles.gnomon.org.uk>
	<CAPg+sBidvTSAKa6exw-XavfDxPWN_6N83VKJpm8dNSBhbXYgUA@mail.gmail.com>
	<20150507220848.GK63100@giles.gnomon.org.uk>
Message-ID: <CALqxMTGNc1NrXNBE8kbSs9t2bfWi=i4MpyKpvPvSmSyjHseRvA@mail.gmail.com>

Well this is all very extreme circumstances, and you'd have to assume no
rational player with an interest in bitcoin would go there, but to play
your analysis forward: users are also not powerless at the extreme: they
could change the hash function rendering current deployed ASICs useless in
reaction for example, and reset difficulty at the same time, or freeze
transactions until some minimum hashrate is reached.  People would figure
out what is the least bad way forward.

Adam
On May 7, 2015 3:09 PM, "Roy Badami" <roy at gnomon.org.uk> wrote:

> On Thu, May 07, 2015 at 11:49:28PM +0200, Pieter Wuille wrote:
> > I would not modify my node if the change introduced a perpetual 100 BTC
> > subsidy per block, even if 99% of miners went along with it.
>
> Surely, in that scenario Bitcoin is dead.  If the fork you prefer has
> only 1% of the hash power it is trivially vulnerably not just to a 51%
> attack but to a 501% attack, not to mention the fact that you'd only
> be getting one block every 16 hours.
>
> >
> > A hardfork is safe when 100% of (economically relevant) users upgrade. If
> > miners don't upgrade at that point, they just lose money.
> >
> > This is why a hashrate-triggered hardfork does not make sense. Either you
> > believe everyone will upgrade anyway, and the hashrate doesn't matter. Or
> > you are not certain, and the fork is risky, independent of what hashrate
> > upgrades.
>
> Beliefs are all very well, but they can be wrong.  Of course we should
> not go ahead with a fork that we believe to be dangerous, but
> requiring a supermajority of miners is surely a wise precaution.  I
> fail to see any realistic scenario where 99% of miners vote for the
> hard fork to go ahead, and the econonomic majority votes to stay on
> the blockchain whose hashrate has just dropped two orders of magnitude
> - so low that the mean time between blocks is now over 16 hours.
>
> >
> > And the march 2013 fork showed that miners upgrade at a different
> schedule
> > than the rest of the network.
> > On May 7, 2015 5:44 PM, "Roy Badami" <roy at gnomon.org.uk> wrote:
> >
> > >
> > > > On the other hand, if 99.99% of the miners updated and only 75% of
> > > > merchants and 75% of users updated, then that would be a serioud
> split of
> > > > the network.
> > >
> > > But is that a plausible scenario?  Certainly *if* the concensus rules
> > > required a 99% supermajority of miners for the hard fork to go ahead,
> > > then there would be absoltely no rational reason for merchants and
> > > users to refuse to upgrade, even if they don't support the changes
> > > introduces by the hard fork.  Their only choice, if the fork succeeds,
> > > is between the active chain and the one that is effectively stalled -
> > > and, of course, they can make that choice ahead of time.
> > >
> > > roy
> > >
> > >
> > >
> ------------------------------------------------------------------------------
> > > One dashboard for servers and applications across
> Physical-Virtual-Cloud
> > > Widest out-of-the-box monitoring support with 50+ applications
> > > Performance metrics, stats and reports that give you Actionable
> Insights
> > > Deep dive visibility with transaction tracing using APM Insight.
> > > http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> > > _______________________________________________
> > > Bitcoin-development mailing list
> > > Bitcoin-development at lists.sourceforge.net
> > > https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> > >
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/df972ca5/attachment.html>

From pieter.wuille at gmail.com  Fri May  8 02:35:00 2015
From: pieter.wuille at gmail.com (Pieter Wuille)
Date: Fri, 8 May 2015 04:35:00 +0200
Subject: [Bitcoin-development] Mechanics of a hard fork
In-Reply-To: <20150507220848.GK63100@giles.gnomon.org.uk>
References: <20150507200023.GI63100@giles.gnomon.org.uk>
	<CAE-z3OVgX9S0sJqq-iFdkZn_wK-a=Vs4VpNwxpcagDEYFzNSDQ@mail.gmail.com>
	<20150507214200.GJ63100@giles.gnomon.org.uk>
	<CAPg+sBidvTSAKa6exw-XavfDxPWN_6N83VKJpm8dNSBhbXYgUA@mail.gmail.com>
	<20150507220848.GK63100@giles.gnomon.org.uk>
Message-ID: <CAPg+sBg4+Hj9z6NfHMyqv=PPKpYxCGP-5RcxJFfocfUajgYGxA@mail.gmail.com>

On May 7, 2015 3:08 PM, "Roy Badami" <roy at gnomon.org.uk> wrote:
>
> On Thu, May 07, 2015 at 11:49:28PM +0200, Pieter Wuille wrote:
> > I would not modify my node if the change introduced a perpetual 100 BTC
> > subsidy per block, even if 99% of miners went along with it.
>
> Surely, in that scenario Bitcoin is dead.  If the fork you prefer has
> only 1% of the hash power it is trivially vulnerably not just to a 51%
> attack but to a 501% attack, not to mention the fact that you'd only
> be getting one block every 16 hours.

Yes, indeed, Bitcoin would be dead if this actually happens. But that is
still where the power lies: before anyone (miners or others) would think
about trying such a change, they would need to convince people and be sure
they will effectively modify their code.

-- 
Pieter
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/3ca17652/attachment.html>

From da2ce7 at gmail.com  Fri May  8 03:12:22 2015
From: da2ce7 at gmail.com (Cameron Garnham)
Date: Fri, 08 May 2015 11:12:22 +0800
Subject: [Bitcoin-development] Mechanics of a hard fork
In-Reply-To: <CAPg+sBg4+Hj9z6NfHMyqv=PPKpYxCGP-5RcxJFfocfUajgYGxA@mail.gmail.com>
References: <20150507200023.GI63100@giles.gnomon.org.uk>	<CAE-z3OVgX9S0sJqq-iFdkZn_wK-a=Vs4VpNwxpcagDEYFzNSDQ@mail.gmail.com>	<20150507214200.GJ63100@giles.gnomon.org.uk>	<CAPg+sBidvTSAKa6exw-XavfDxPWN_6N83VKJpm8dNSBhbXYgUA@mail.gmail.com>	<20150507220848.GK63100@giles.gnomon.org.uk>
	<CAPg+sBg4+Hj9z6NfHMyqv=PPKpYxCGP-5RcxJFfocfUajgYGxA@mail.gmail.com>
Message-ID: <554C2996.5030509@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

While being in the Bitcoin community for a long time, I haven't been
so directly involved in the development.  However I wish to suggest a
different pre-hard-fork soft-fork approach:


Set a 'block size cap' in the similar same way as we set difficulty.

Every 2016 blocks take the average size of the blocks and multiply the
size by 1.5x, rejecting blocks that are larger than this size, for the
next 2016 period.

I would of-course suggest that we keep the limits at min 100kb and max
(initially) 990kb (not 1mb on purpose, as this should become the new
limit), rounding up to the nearest 10kb.

A: we don't have pressure at the 1mb limit, (we reduce the limit in a
flexible manner to 990kb).

B: we can upgrade the network to XYZ hard-limit, then slowly raze the
soft-limit after being sure the network, as-a-whole is ready.

If we on-day remove the block-size limit, this rule will stop a rouge
miner from making 10mb, or 100mb blocks, or 1gb blocks.

This could be implemented by the miners without breaking any of the
clients, and would tend to produce a better dynamic fee pressure.


This will give the mechanics to the miners to create consensus to
agree what block-sizes they believe are best for the network, and
allows the block-sizes to dynamically grow in response to larger demand.



On 5/8/2015 10:35 AM, Pieter Wuille wrote:
> On May 7, 2015 3:08 PM, "Roy Badami" <roy at gnomon.org.uk> wrote:
>> 
>> On Thu, May 07, 2015 at 11:49:28PM +0200, Pieter Wuille wrote:
>>> I would not modify my node if the change introduced a perpetual
>>> 100 BTC subsidy per block, even if 99% of miners went along
>>> with it.
>> 
>> Surely, in that scenario Bitcoin is dead.  If the fork you prefer
>> has only 1% of the hash power it is trivially vulnerably not just
>> to a 51% attack but to a 501% attack, not to mention the fact
>> that you'd only be getting one block every 16 hours.
> 
> Yes, indeed, Bitcoin would be dead if this actually happens. But
> that is still where the power lies: before anyone (miners or
> others) would think about trying such a change, they would need to
> convince people and be sure they will effectively modify their
> code.
> 
> 
> 
> ----------------------------------------------------------------------
- --------
>
> 
One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications 
> Performance metrics, stats and reports that give you Actionable
> Insights Deep dive visibility with transaction tracing using APM
> Insight. http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> 
> 
> 
> _______________________________________________ Bitcoin-development
> mailing list Bitcoin-development at lists.sourceforge.net 
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iF4EAREIAAYFAlVMKZYACgkQBJ8cMDO159aTiQEApTITEBrhE1DRbj/w+GncNeqB
0hGvmIBa1z0hGww0kaMBAOhxjn/K5leRJgdt1fKhNEDKKHdeCOIX3QRgry90D3NO
=p0+H
-----END PGP SIGNATURE-----



From pete at petertodd.org  Fri May  8 03:41:21 2015
From: pete at petertodd.org (Peter Todd)
Date: Thu, 7 May 2015 23:41:21 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554BBDA2.7040508@gmail.com>
References: <CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<554BA032.4040405@bluematt.me>
	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>
	<CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>
	<CANEZrP39jWHLF02z-81Z4+9X1vH5+hMuS=-3ED81=Q1o9U=DKw@mail.gmail.com>
	<554BBDA2.7040508@gmail.com>
Message-ID: <20150508034121.GA31994@savin.petertodd.org>

On Thu, May 07, 2015 at 03:31:46PM -0400, Alan Reiner wrote:
> We get asked all the time by corporate clients about scalability.  A
> limit of 7 tps makes them uncomfortable that they are going to invest
> all this time into a system that has no chance of handling the economic
> activity that they expect it handle.  We always assure them that 7 tps
> is not the final answer. 

Your corporate clients, *why* do they want to use Bitcoin and what for
exactly?

-- 
'peter'[:-1]@petertodd.org
0000000000000000054c9d9ae1099ef8bc0bc9b76fef5e03f7edaff66fd817d8
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150507/cc01f18b/attachment.sig>

From thyshizzle at outlook.com  Fri May  8 04:12:15 2015
From: thyshizzle at outlook.com (Thy Shizzle)
Date: Fri, 8 May 2015 14:12:15 +1000
Subject: [Bitcoin-development] Solution for Block Size Increase
Message-ID: <BAY403-EAS3821CC9EA00E6AEA78320E7C2DE0@phx.gbl>

Nicolas, can you think if there would be a problem with allowing blocks to be created faster instead of increasing block size? So say if difficulty was reduced to allow block creation every 2 minutes instead of 10 minutes, can you think of any bad outcome from this (I know this is different to what you are saying) but I'm thinking if we allow 1mb blocks to be built faster, that way transactions are processed quicker  thus gaining a higher tps rate, i'd think no hard fork need occur right?

Is there any downsides that you can see? Obviously miners need yo update, but I mean if they don't it just means they potentially take too long to make blocks and thus loose out in reward so there is the incentive for them to update to the easier difficulty, while still allowing blocks done on the harder difficulty for backwards compatibility.

Thoughts?
________________________________
From: Nicolas DORIER<mailto:nicolas.dorier at gmail.com>
Sent: ?8/?05/?2015 9:17 AM
To: bitcoin-development at lists.sourceforge.net<mailto:bitcoin-development at lists.sourceforge.net>
Subject: [Bitcoin-development] Solution for Block Size Increase

Executive Summary:

I explain the objectives that we should aim to reach agreement without
drama, controversy, and relief the core devs from the central banker role.
(As Jeff Garzik pointed out)
Knowing the objectives, I propose a solution based on the objectives that
can be agreed on tomorrow, would permanently fix the block size problem
without controversy and would be immediately applicable.

The objectives:

There is consensus on the fact that nobody wants the core developers to be
seen as central bankers.
There is also consensus that more decentralization is better than less.
(assuming there is no cost to it)

This means you should reject all arguments based on economical, political
and ideological principles about what Bitcoin should become. This includes:

1) Whether Bitcoin should be storage of value or suitable for coffee
transaction,
2) Whether we need a fee market, block scarcity, and how much of it,
3) Whether we need to periodically increase block size via some voodoo
formula which speculate on future bandwidth and cost of storage,

Taking decisions based on such reasons is what central bankers do, and you
don?t want to be bankers. This follow that decisions should be taken only
for technical and decentralization considerations. (more about
decentralization after)

Scarcity will evolve without you taking any decisions about it, for the
only reason that storage and bandwidth is not free, nor a transaction,
thanks to increased propagation time.
This backed in scarcity will evolve automatically as storage, bandwidth,
encoding, evolve without anybody taking any decision, nor making any
speculation on the future.

Sadly, deciding how much decentralization should be in the system by
tweaking the block size limit is also an economic decision that should not
have its place between the core devs. This follow :

4) Core devs should not decide about the amount of suitable
decentralization by tweaking block size limit,

Still, removing the limit altogether is a no-no, what would happen if a
block of 100 GB is created? Immediately the network would be decentralized,
not only for miners but also for bitcoin service providers. Also, core devs
might have technical consideration on bitcoin core which impose a temporary
limit until the bug resolved.

The solution:

So here is a proposal that address all my points, and, I think, would get a
reasonable consensus. It can be published tomorrow without any controversy,
would be agreed in one year, and can be safely reiterated every year.
Developers will also not have to play politics nor central banker. (well,
it sounds to good to be true, I waiting for being wrong)

The solution is to use block voting. For each block, a miner gives the size
of the block he would like to have at the next deadline (for example, 30
may 2015). The rational choice for them is just enough to clear the memory
pool, maybe a little less if he believes fee pressure is beneficial for
him, maybe a little more if he believes he should leave some room for
increased use.
At the deadline, we take the median of the votes and implement it as a new
block size limit. Reiterate for the next year.

Objectives reached:


   - No central banking decisions on devs shoulder,
   - Votes can start tomorrow,
   - Implementation has only to be ready in one year, (no kick-in-the-can)
   - Will increase as demand is growing,
   - Will increase as network capacity and storage is growing,
   - Bitcoin becomes what miners want, not what core devs and politician
   wants,
   - Implementation reasonably easy,
   - Will get miner consensus, no impact on existing bitcoin services,


Unknown:

   - Effect on bitcoin core stability (core devs might have a valid
   technical reason to impose a limit)
   - Maybe a better statistical function is possible

Additional input for the debate:

Some people were debating whether miners are altruist or act rationally. We
should always expect them to act rationally, but we should not forget the
peculiarity of TCP backoff game: While it is in the best interest of
players to NOT reemit TCP packet with a backoff if the ACK is not received,
everybody does it. (Because of the fallacy that changing a TCP
implementation is costless)

Often, when we think a real life situation is a prisoner dilemma problem,
it turns out that the incentives where just incorrectly modeled.

Core devs, thanks for all your work, but please step out of the banker's
role and focus on where you are the best, I speak as an entrepreneur that
doesn't want decisions about bitcoin to be taken by who has the biggest.
If the decision of the hard limit is taken for other than purely technical
decisions, ie, for the maximization of whatever metric, it will clearly put
you in banker's shoes. As an entrepreneur, I have other things to speculate
than who gets the biggest gun in the core team.
Please consider my solution,

Nicolas Dorier,
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/f4a6cb22/attachment.html>
-------------- next part --------------
------------------------------------------------------------------------------
One dashboard for servers and applications across Physical-Virtual-Cloud 
Widest out-of-the-box monitoring support with 50+ applications
Performance metrics, stats and reports that give you Actionable Insights
Deep dive visibility with transaction tracing using APM Insight.
http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
-------------- next part --------------
_______________________________________________
Bitcoin-development mailing list
Bitcoin-development at lists.sourceforge.net
https://lists.sourceforge.net/lists/listinfo/bitcoin-development

From tomh at thinlink.com  Fri May  8 04:46:48 2015
From: tomh at thinlink.com (Tom Harding)
Date: Thu, 07 May 2015 21:46:48 -0700
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CABm2gDpceBQ=SqH-axgbMgOGOf8cOe1wLyJgJY5TEFu4taiNwA@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>	<5049F137-E123-47F6-9D24-FE51B92629FF@hashingit.com>
	<CABm2gDpceBQ=SqH-axgbMgOGOf8cOe1wLyJgJY5TEFu4taiNwA@mail.gmail.com>
Message-ID: <554C3FB8.6000309@thinlink.com>

On 5/7/2015 6:40 AM, Jorge Tim?n wrote:
>> Known: There's a major problem looming for miners at the next block reward
>> halving. Many are already in a bad place and without meaningful fees then
>> sans a 2x increase in the USD:BTC ratio then many will simply have to leave
>> the network, increasing centralisation risks. There seems to be a fairly
>> pervasive assumption that the 300-ish MW of power that they currently use is
>> going to pay for itself (ignoring capital and other operating costs).
> I take this as an argument for increasing fee competition and thus,
> against increasing the block size.
>

That doesn't follow.  Supposing average fees per transaction decrease
with block size, total fees / block reach an optimum somewhere.  While
the optimum might be at infinity, it's certainly not at zero, and it's
not at all obvious that the optimum is at a block size lower than 1MB.





From tomh at thinlink.com  Fri May  8 05:13:08 2015
From: tomh at thinlink.com (Tom Harding)
Date: Thu, 07 May 2015 22:13:08 -0700
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CAJHLa0PeEd19ooHbOHUMxX9-5=iyUng-9GWnQFOn_F3aXxVWLQ@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<554BA032.4040405@bluematt.me>
	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>
	<CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>
	<CANEZrP39jWHLF02z-81Z4+9X1vH5+hMuS=-3ED81=Q1o9U=DKw@mail.gmail.com>
	<554BBDA2.7040508@gmail.com>
	<CAJHLa0NcxOHkrtW2=-JgfsXQJkCO8Ym7icBwMx_2RsaWcPBnTw@mail.gmail.com>
	<554C1410.7050406@thinlink.com>
	<CAJHLa0PeEd19ooHbOHUMxX9-5=iyUng-9GWnQFOn_F3aXxVWLQ@mail.gmail.com>
Message-ID: <554C45E4.1020208@thinlink.com>

On 5/7/2015 7:09 PM, Jeff Garzik wrote:
>
> G proposed 20MB blocks, AFAIK - 140 tps
> A proposed 100MB blocks - 700 tps
> For ref,
> Paypal is around 115 tps
> VISA is around 2000 tps (perhaps 4000 tps peak)
>
> I ask again:  where do we want to go?   This is the existential
> question behind block size.
>
> Are we trying to build a system that can handle Paypal volumes?  VISA
> volumes?
>
> It's not a snarky or sarcastic question:  Are we building a system to
> handle all the world's coffees?  Is bitcoin's main chain and network -
> Layer 1 - going to receive direct connections from 500m mobile phones,
> broadcasting transactions?
>
> We must answer these questions to inform the change being discussed
> today, in order to decide what makes the most sense as a new limit. 
> Any responsible project of this magnitude must have a better story
> than "zomg 1MB, therefore I picked 20MB out of a hat"  Must be able to
> answer /why/ the new limit was picked.
>
> As G notes, changing the block size is simply kicking the can down the
> road:
> http://gavinandresen.ninja/it-must-be-done-but-is-not-a-panacea  
> Necessarily one must ask, today, what happens when we get to the end
> of that newly paved road.
>
>

Accepting that outcomes are less knowable further into the future is not
the same as failing to consider the future at all.  A responsible
project can't have a movie-plot roadmap.  It needs to give weight to
multiple possible future outcomes.
http://en.wikipedia.org/wiki/Decision_tree

One way or another, the challenge is to decide what to do next.  Beyond
that, it's future decisions all the way down. 

Alan argues that 7 tps is a couple orders of magnitude too low for any
meaningful commercial activity to occur, and too low to be the final
solution, even with higher layers.  I agree.  I also agree with you,
that we don't really know how to accomplish 700tps right now.

What we do know is if we want to bump the limit in the short term, we
ought to start now, and until there's a better alternative root to the
decision tree, it just might be time to get moving.






From necronomics at riseup.net  Fri May  8 06:33:18 2015
From: necronomics at riseup.net (Arkady)
Date: Fri, 08 May 2015 06:33:18 +0000
Subject: [Bitcoin-development] Block Size Increase Requirements
In-Reply-To: <20150508000556.GA16794@savin.petertodd.org>
References: <554BE0E1.5030001@bluematt.me>
	<20150508000556.GA16794@savin.petertodd.org>
Message-ID: <4726ecd29577c6271e9e9dfdc5fc2a86@riseup.net>

--[remove this line and above]--
On Thu, 7 May 2015, Gregory Maxwell wrote:

> Date: Thu, 7 May 2015 00:37:54 +0000
> From: Gregory Maxwell <gmaxwell at gmail.com>
> To: Matt Corallo <bitcoin-list at bluematt.me>
> Cc: Bitcoin Dev <bitcoin-development at lists.sourceforge.net>
> Subject: Re: [Bitcoin-development] Block Size Increase
> 
> Thanks Matt; I was actually really confused by this sudden push with
> not a word here or on Github--so much so that I responded on Reddit to
> people pointing to commits in Gavin's personal repository saying they
> were reading too much into it.

I saw this. I was also pointing this out to the people who were asking 
me. A
commit to a personal repository does not at first seem more than
experimental. sipa commits weird/neat things to private branches all the
time, after all.

> to share behavior. In the case of mining, we're trying to optimize the
> social good of POW security. (But the analogy applies in other ways 
> too:

About the only argument IMO in favour of block size increases is to 
assume
that making more room in a block will make it attractive to use for more
people at some point in the future: increasing transaction velocity,
increasing economy size, increasing value overall.

> increases to the chain side are largely an externality; miners enjoy 
> the
> benefits, everyone else takes the costs--either in reduced security or
> higher node operating else.)

Who else but miners and pool operators will run full nodes when full 
nodes
are being shut down because they are too large and unwieldy to maintain? 
It
is already so that casual users refuse to run full nodes. This fact is
indisputable. The only question remaining is, "Do we care?" Arguments
against users who feel that the dataset is too large to run a full node,
full-time, start from a premise that these users are a static and 
irrelevant
fraction. Is this even true? "Do we care?" I do. I will shortly only be 
able
to run half the nodes I currently do thanks to the growth of the 
blockchain
at its current rate.

> One potential argument is that maybe miners would be _regulated_ to
> behave correctly. But this would require undermining the openness of 
> the
> system--where anyone can mine anonymously--in order to enforce 
> behavior,
> and that same enforcement mechanism would leave a political level to
> impose additional rules that violate the extra properties of the 
> system.

I would refuse to mine under such a regulated regime; moreover, I would
enjoy forking away from this, and, I suspect, the only miners who remain
would be those whose ultimate motivations do not coincide with the 
users.
That is, the set of miners who are users, and the set of users who are
miners, would be wholly non-intersecting.

> So far the mining ecosystem has become incredibly centralized over 
> time.

This is unfortunate but true.

> of the regular contributors to Bitcoin Core do. Many participants
> have never mined or only did back in 2010/2011... we've basically
> ignored the mining ecosystem, and this has had devastating effects,
> causing a latent undermining of the security model: hacking a dozen or
> so computers--operated under totally unknown and probably not strong
> security policies--could compromise the network at least at the tip...

The explicit form of the block dictated by the reference client and
agreed-to by the people who were sold on bitcoin near the beginning 
(myself
included) was explicitly the notion that the rules were static; that the
nature of transaction foundations and the subsidies would not be 
altered.
Here we have a hardfork being contemplated which is not only 
controversial,
but does not even address some of the highest-utility and most-requested
features in peoples' hardfork wishlists.

The fact that mining has effectively been centralized directly implies 
that
destabilizing changes that some well-heeled (and thus theoretically 
capable,
at least) people have explicitly begun plans to fork the blockchain 
about
will have an unknown, and completely unforeseen combined effect.

We can pretend that, "If merchants and miners and exchanges go along, 
then
who else matters," but the reality is that the value in bitcoin exists
because *people* use it for real transactions: Not miners, whose profits 
are
parasitically fractionally based on the quality and strength of the 
bitcoin
economy as a whole; not exchanges who lubricate transactions in service 
to
the economy; not even today's merchants whose primary means of accepting
bitcoin seems to be to convert them instantly to fiat and not 
participate
meaningfully in the economy at all; not enriched felons; but actual 
users
themselves.

> Rightfully we should be regarding this an an emergency, and probably
> should have been have since 2011.

There are two ways to look at it, assuming that the blocksize change
increases bitcoin's value to people after all: mining centralization 
will be
corrected; or, mining centralization will not be corrected.

I would argue that rapidly increasing profitability at this point will
exacerbate the mining centralization problem, and in much the same way 
as
when people were throwing money and unknowingly funding the massive 
frauds
of the current cabals when bitcoin's exchange-driven rise to $1200 was 
first
realized.

Thus, even if the premise were true, what will a blocksize increase 
achieve
given mining centralization itself is a bigger systemic risk?

> Hardfork changes should only be made if they're almost completely
> uncontroversial--where virtually everyone can look at the available 
> data
> and say "yea, that isn't undermining my property rights or future use
> of Bitcoin; it's no big deal".

The recent "revelation" that there are masses of paid trolls on popular
forum sites like reddit who supposedly don't even know who is hiring 
them,
and the anger of more vociferous commenters in general, does not 
invalidate
the relevance of every non-"industry" voice.  I think elevating the
discussion away from the users does the system and the development 
process
as a whole quite an injustice.

> I'm curious as to what discussions people have seen; e.g., are people
> even here aware of these concerns? Are you aware of things like the
> hashcash mediated dynamic blocksize limiting?

I have seen most of these; or the ideas seem obvious based on their 
names.

> About proposals like lightning network (instant transactions and 
> massive
> scale, in exchange for some short term DOS risk if a counterparty opts
> out)? Do people (other than Mike Hearn; I guess) think a future where
> everyone depends on a small number of "Google scale" node operations 
> for
> the system is actually okay? (I think not, and if so we're never going 
> to
> agree--but it can be helpful to understand when a disagreement is
> ideological).

It is not okay. If the current mining cabals continue to exist, and
flourish, and the developers make major changes that ignore this glaring
elephant, then the decentralized promise of bitcoin will be put more at
risk.

signmessage 1DdcrjT9Yqb6U58wVMA2e7untFbz2rmZd4 
"49786791f4d0a260689867ccdfb2cc5b8460984e335504444ade113d2768505c"
G6NPl7Wklo9lcdgeVI2H2pexzgqD0KPHhI/wAe32DBm8m59Qf31j5d4tsx5drcql/8wPeIb0QGarr/o4VIOLLGE=

--[remove this line and below]--
HHsTfiZ/S7+GNYRwws+QyAr+6/MgDz0Jyntl7CAvjhdfzbnwPorybQUXxRw3CE4DgYgAy1zLanE8H/5NK+l3UlE=




From mickeybob at gmail.com  Fri May  8 07:18:51 2015
From: mickeybob at gmail.com (Michael Naber)
Date: Fri, 8 May 2015 03:18:51 -0400
Subject: [Bitcoin-development] Suggestion: Dynamic block size that updates
	like difficulty
Message-ID: <BEB3AF9B-35D2-4742-8C61-A738F49C0EC1@gmail.com>

Why can't we have dynamic block size limit that changes with difficulty, such as the block size cannot exceed 2x the mean size of the prior difficulty period? 

I recently subscribed to this list so my apologies if this has been addressed already.




From bip at mattwhitlock.name  Fri May  8 07:20:02 2015
From: bip at mattwhitlock.name (Matt Whitlock)
Date: Fri, 08 May 2015 03:20:02 -0400
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
Message-ID: <16096345.A1MpJQQkRW@crushinator>

Between all the flames on this list, several ideas were raised that did not get much attention. I hereby resubmit these ideas for consideration and discussion.

- Perhaps the hard block size limit should be a function of the actual block sizes over some trailing sampling period. For example, take the median block size among the most recent 2016 blocks and multiply it by 1.5. This allows Bitcoin to scale up gradually and organically, rather than having human beings guessing at what is an appropriate limit.

- Perhaps the hard block size limit should be determined by a vote of the miners. Each miner could embed a desired block size limit in the coinbase transactions of the blocks it publishes. The effective hard block size limit would be that size having the greatest number of votes within a sliding window of most recent blocks.

- Perhaps the hard block size limit should be a function of block-chain length, so that it can scale up smoothly rather than jumping immediately to 20 MB. This function could be linear (anticipating a breakdown of Moore's Law) or quadratic.

I would be in support of any of the above, but I do not support Mike Hearn's proposed jump to 20 MB. Hearn's proposal kicks the can down the road without actually solving the problem, and it does so in a controversial (step function) way.



From mike at plan99.net  Fri May  8 09:43:42 2015
From: mike at plan99.net (Mike Hearn)
Date: Fri, 8 May 2015 11:43:42 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554C45E4.1020208@thinlink.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<554BA032.4040405@bluematt.me>
	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>
	<CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>
	<CANEZrP39jWHLF02z-81Z4+9X1vH5+hMuS=-3ED81=Q1o9U=DKw@mail.gmail.com>
	<554BBDA2.7040508@gmail.com>
	<CAJHLa0NcxOHkrtW2=-JgfsXQJkCO8Ym7icBwMx_2RsaWcPBnTw@mail.gmail.com>
	<554C1410.7050406@thinlink.com>
	<CAJHLa0PeEd19ooHbOHUMxX9-5=iyUng-9GWnQFOn_F3aXxVWLQ@mail.gmail.com>
	<554C45E4.1020208@thinlink.com>
Message-ID: <CANEZrP2RV1bVetpM-dOQM1FbR5GsGwweV_KOzV4Zv3vhDGCRog@mail.gmail.com>

>
> Alan argues that 7 tps is a couple orders of magnitude too low


By the way, just to clear this up - the real limit at the moment is more
like 3 tps, not 7.

The 7 transactions/second figure comes from calculations I did years ago,
in 2011. I did them a few months before the "sendmany" command was
released, so back then almost all transactions were small. After sendmany
and as people developed custom wallets, etc, the average transaction size
went up.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/4c054cee/attachment.html>

From mike at plan99.net  Fri May  8 09:49:21 2015
From: mike at plan99.net (Mike Hearn)
Date: Fri, 8 May 2015 11:49:21 +0200
Subject: [Bitcoin-development] Assurance contracts to fund the network
 with OP_CHECKLOCKTIMEVERIFY
In-Reply-To: <CAE-z3OUiK_s-gJtnPquUZbG5aJkJjfo+VYKHgX+Bfcgem+6i9A@mail.gmail.com>
References: <CAE-z3OUiK_s-gJtnPquUZbG5aJkJjfo+VYKHgX+Bfcgem+6i9A@mail.gmail.com>
Message-ID: <CANEZrP2OXSmhLsfvpsQdr0QGbGyJWaAp1F0itu4V_C-E+0gO6A@mail.gmail.com>

Looks like a neat solution, Tier.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/3f7a6fd9/attachment.html>

From jgarzik at bitpay.com  Fri May  8 10:00:37 2015
From: jgarzik at bitpay.com (Jeff Garzik)
Date: Fri, 8 May 2015 06:00:37 -0400
Subject: [Bitcoin-development] Assurance contracts to fund the network
 with OP_CHECKLOCKTIMEVERIFY
In-Reply-To: <CAE-z3OUiK_s-gJtnPquUZbG5aJkJjfo+VYKHgX+Bfcgem+6i9A@mail.gmail.com>
References: <CAE-z3OUiK_s-gJtnPquUZbG5aJkJjfo+VYKHgX+Bfcgem+6i9A@mail.gmail.com>
Message-ID: <CAJHLa0MgiC6vMdy=zm85CE2pWkOqtk18ePjb9nZ2-KwGf+q+Mw@mail.gmail.com>

That reminds me - I need to integrate the patch that automatically sweeps
anyone-can-pay transactions for a miner.


On Thu, May 7, 2015 at 7:32 PM, Tier Nolan <tier.nolan at gmail.com> wrote:

> One of the suggestions to avoid the problem of fees going to zero is
> assurance contracts.  This lets users (perhaps large merchants or
> exchanges) pay to support the network.  If insufficient people pay for the
> contract, then it fails.
>
> Mike Hearn suggests one way of achieving it, but it doesn't actually
> create an assurance contract.  Miners can exploit the system to convert the
> pledges into donations.
>
> https://bitcointalk.org/index.php?topic=157141.msg1821770#msg1821770
>
> Consider a situation in the future where the minting fee has dropped to
> almost zero.  A merchant wants to cause block number 1 million to
> effectively have a minting fee of 50BTC.
>
> He creates a transaction with one input (0.1BTC) and one output (50BTC)
> and signs it using SIGHASH_ANYONE_CAN_PAY.  The output pays to OP_TRUE.
> This means that anyone can spend it.  The miner who includes the
> transaction will send it to an address he controls (or pay to fee).  The
> transaction has a locktime of 1 million, so that it cannot be included
> before that point.
>
> This transaction cannot be included in a block, since the inputs are lower
> than the outputs.  The SIGHASH_ANYONE_CAN_PAY field mean that others can
> pledge additional funds.  They add more input to add more money and the
> same sighash.
>
> There would need to be some kind of notice boeard system for these
> pledges, but if enough pledge, then a valid transaction can be created.  It
> is in miner's interests to maintain such a notice board.
>
> The problem is that it counts as a pure donation.  Even if only 10BTC has
> been pledged, a miner can just add 40BTC of his own money and finish the
> transaction.  He nets the 10BTC of the pledges if he wins the block.  If he
> loses, nobody sees his 40BTC transaction.  The only risk is if his block is
> orphaned and somehow the miner who mines the winning block gets his 40BTC
> transaction into his block.
>
> The assurance contract was supposed to mean "If the effective minting fee
> for block 1 million is 50 BTC, then I will pay 0.1BTC".  By adding his
> 40BTC to the transaction the miner converts it to a pure donation.
>
> The key point is that *other* miners don't get 50BTC reward if they find
> the block, so it doesn't push up the total hashing power being committed to
> the blockchain, that a 50BTC minting fee would achieve.  This is the whole
> point of the assurance contract.
>
> OP_CHECKLOCKTIMEVERIFY could be used to solve the problem.
>
> Instead of paying to OP_TRUE, the transaction should pay 50 BTC to "<1
> million> OP_CHECKLOCKTIMEVERIFY OP_TRUE" and 0.01BTC to "OP_TRUE".
>
> This means that the transaction could be included into a block well in
> advance of the 1 million block point.  Once block 1 million arrives, any
> miner would be able to spend the 50 BTC.  The 0.01BTC is the fee for the
> block the transaction is included in.
>
> If the contract hasn't been included in a block well in advance, pledgers
> would be recommended to spend their pledged input,
>
> It can be used to pledge to many blocks at once.  The transaction could
> pay out to lots of 50BTC outputs but with the locktime increasing by for
> each output.
>
> For high value transactions, it isn't just the POW of the next block that
> matters but all the blocks that are built on top of it.
>
> A pledger might want to say "I will pay 1BTC if the next 100 blocks all
> have at least an effective minting fee of 50BTC"
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>


-- 
Jeff Garzik
Bitcoin core developer and open source evangelist
BitPay, Inc.      https://bitpay.com/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/3a6a6429/attachment.html>

From benjamin.l.cordes at gmail.com  Fri May  8 10:01:31 2015
From: benjamin.l.cordes at gmail.com (Benjamin)
Date: Fri, 8 May 2015 12:01:31 +0200
Subject: [Bitcoin-development] Assurance contracts to fund the network
 with OP_CHECKLOCKTIMEVERIFY
In-Reply-To: <CANEZrP2OXSmhLsfvpsQdr0QGbGyJWaAp1F0itu4V_C-E+0gO6A@mail.gmail.com>
References: <CAE-z3OUiK_s-gJtnPquUZbG5aJkJjfo+VYKHgX+Bfcgem+6i9A@mail.gmail.com>
	<CANEZrP2OXSmhLsfvpsQdr0QGbGyJWaAp1F0itu4V_C-E+0gO6A@mail.gmail.com>
Message-ID: <CAOoPuRZG4CVxcgExKHjDQd+F-w6xr6cJZD7pShbgPJd9CnqTwg@mail.gmail.com>

Interesting.

1. How do you know who was first? If one node can figure out where
more transactions happen he can gain an advantage by being closer to
him. Mining would not be fair.

2. "A merchant wants to cause block number 1 million to effectively
have a minting fee of 50BTC." - why should he do that? That's the
entire tragedy of the commons problem, no?

On Fri, May 8, 2015 at 11:49 AM, Mike Hearn <mike at plan99.net> wrote:
> Looks like a neat solution, Tier.
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>



From mike at plan99.net  Fri May  8 10:03:04 2015
From: mike at plan99.net (Mike Hearn)
Date: Fri, 8 May 2015 12:03:04 +0200
Subject: [Bitcoin-development] Block Size Increase Requirements
In-Reply-To: <554BE0E1.5030001@bluematt.me>
References: <554BE0E1.5030001@bluematt.me>
Message-ID: <CANEZrP3uKLvzKi-wXBJWL=pwqB+eAe3FbPjyESD52y5TGkg+Rg@mail.gmail.com>

>
>  * Though there are many proposals floating around which could
> significantly decrease block propagation latency, none of them are
> implemented today.


With a 20mb cap, miners still have the option of the soft limit.

I would actually be quite surprised if there were no point along the road
from 1mb to 20mb where miners felt a need to throttle their block sizes
artificially, for the exact reason you point out: propagation delays.

But we don't *need* to have fancy protocol upgrades implemented right now.
All we need is to demolish one bottleneck (the hard cap) so we can then
move on and demolish the next one (whatever that is, probably faster
propagation). Scaling is a series of walls we punch through as we encounter
them. One down, onto the next. We don't have to tackle them all
simultaneously.

FWIW I don't think the GFW just triggers packet loss, these days. It's
blocked port 8333 entirely.

 * I'd very much like to see someone working on better scaling
> technology ... I know StrawPay is working on development,
>

So this request is already satisfied, isn't it? As you point out, expecting
more at this stage in development is unreasonable, there's nothing for
anyone to experiment with or commit to.

They have code here, by the way:

   https://github.com/strawpay

You can find their fork of MultiBit HD, their implementation library, etc.
They've contributed patches and improvements to the payment channels code
we wrote.


>  * I'd like to see some better conclusions to the discussion around
> long-term incentives within the system.
>

What are your thoughts on using assurance contracts to fund network
security?

I don't *know* if hashing assurance contracts (HACs) will work. But I don't
know they won't work either. And right now I'm pretty sure that plain old
fee pressure won't work. Demand doesn't outstrip supply forever - people
find substitutes.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/431f2412/attachment.html>

From mike at plan99.net  Fri May  8 10:15:16 2015
From: mike at plan99.net (Mike Hearn)
Date: Fri, 8 May 2015 12:15:16 +0200
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <16096345.A1MpJQQkRW@crushinator>
References: <16096345.A1MpJQQkRW@crushinator>
Message-ID: <CANEZrP3jXzj7Z2nr40YRLFwk3c4eH1UQJ+NnN+ZFDOieZSAUeg@mail.gmail.com>

There are certainly arguments to be made for and against all of these
proposals.

The fixed 20mb cap isn't actually my proposal at all, it is from Gavin. I
am supporting it because anything is better than nothing. Gavin originally
proposed the block size be a function of time. That got dropped, I suppose
to make the process of getting consensus easier. It is "the simplest thing
that can possibly work".

I would like to see the process of chain forking becoming less traumatic. I
remember Gavin, Jeff and I once considered (on stage at a conference??)
that maybe there should be a scheduled fork every year, so people know when
to expect them.

If everything goes well, I see no reason why 20mb would be the limit
forever.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/557fa94d/attachment.html>

From clem.ds at gmail.com  Fri May  8 10:30:22 2015
From: clem.ds at gmail.com (=?UTF-8?Q?Cl=C3=A9ment_Elbaz?=)
Date: Fri, 08 May 2015 10:30:22 +0000
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <16096345.A1MpJQQkRW@crushinator>
References: <16096345.A1MpJQQkRW@crushinator>
Message-ID: <CAP63atbdFSw0rDeuwgtjsDYsXnKSHNN9=zedzip2MsZ0hSY59w@mail.gmail.com>

Matt : I think proposal #1 and #3 are a lot better than #2, and #1 is my
favorite.

I see two problems with proposal #2.
The first problem with proposal #2 is that, as we see in democracies,
there is often a mismatch between the people conscious vote and these same
people behavior.

Relying on an  intentional vote made consciously by miners by choosing a
configuration value can lead to twisted results if their actual behavior
doesn't correlate with their vote (eg, they all vote for a small block size
because it is the default configuration of their software, and then they
fill it completely all the time and everything crashes).

The second problem with proposal #2 is that if Gavin and Mike are right,
there is simply no time to gather a meaningful amount of votes over the
coinbases, after the fork but before the Bitcoin scalability crash.

I like proposal #1 because the "vote" is made using already available data.
Also there is no possible mismatch between behavior and vote. As a miner
you vote by choosing to create a big (or small) block, and your actions
reflect your vote. It is simple and straightforward.

My feelings on proposal #3 is it is a little bit mixing apples and oranges,
but I may not seeing all the implications.

Le ven. 8 mai 2015 ? 09:21, Matt Whitlock <bip at mattwhitlock.name> a ?crit :

> Between all the flames on this list, several ideas were raised that did
> not get much attention. I hereby resubmit these ideas for consideration and
> discussion.
>
> - Perhaps the hard block size limit should be a function of the actual
> block sizes over some trailing sampling period. For example, take the
> median block size among the most recent 2016 blocks and multiply it by 1.5.
> This allows Bitcoin to scale up gradually and organically, rather than
> having human beings guessing at what is an appropriate limit.
>
> - Perhaps the hard block size limit should be determined by a vote of the
> miners. Each miner could embed a desired block size limit in the coinbase
> transactions of the blocks it publishes. The effective hard block size
> limit would be that size having the greatest number of votes within a
> sliding window of most recent blocks.
>
> - Perhaps the hard block size limit should be a function of block-chain
> length, so that it can scale up smoothly rather than jumping immediately to
> 20 MB. This function could be linear (anticipating a breakdown of Moore's
> Law) or quadratic.
>
> I would be in support of any of the above, but I do not support Mike
> Hearn's proposed jump to 20 MB. Hearn's proposal kicks the can down the
> road without actually solving the problem, and it does so in a
> controversial (step function) way.
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/6f9d5ecd/attachment.html>

From thomas at thomaszander.se  Fri May  8 11:02:56 2015
From: thomas at thomaszander.se (Thomas Zander)
Date: Fri, 08 May 2015 13:02:56 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <20150507014952.GA5657@savin.petertodd.org>
References: <554A91BE.6060105@bluematt.me>
	<20150507014952.GA5657@savin.petertodd.org>
Message-ID: <1551544.DzLxgCKLBq@coldstorage>

On Wednesday 6. May 2015 21.49.52 Peter Todd wrote:
> I'm not sure if you've seen this, but a good paper on this topic was
> published recently: "The Economics of Bitcoin Transaction Fees"


The obvious flaw in this paper is that it talks about a block size in todays 
(trivial) data-flow economy and compares it with the zero-reward situation 
decades from now.

Its comparing two things that will never exist at the same time (unless 
Bitcoin fails).
-- 
Thomas Zander



From joel.kaartinen at gmail.com  Fri May  8 12:32:00 2015
From: joel.kaartinen at gmail.com (Joel Joonatan Kaartinen)
Date: Fri, 8 May 2015 15:32:00 +0300
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CAP63atbdFSw0rDeuwgtjsDYsXnKSHNN9=zedzip2MsZ0hSY59w@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CAP63atbdFSw0rDeuwgtjsDYsXnKSHNN9=zedzip2MsZ0hSY59w@mail.gmail.com>
Message-ID: <CAGKSKfW7fJB6n3B-OoyXOep7hAQqWGGDTiZCkpJ7vXxWRFgveA@mail.gmail.com>

Matt,

It seems you missed my suggestion about basing the maximum block size on
the bitcoin days destroyed in transactions that are included in the block.
I think it has potential for both scaling as well as keeping up a constant
fee pressure. If tuned properly, it should both stop spamming and increase
block size maximum when there are a lot of real transactions waiting for
inclusion.

- Joel

On Fri, May 8, 2015 at 1:30 PM, Cl?ment Elbaz <clem.ds at gmail.com> wrote:

> Matt : I think proposal #1 and #3 are a lot better than #2, and #1 is my
> favorite.
>
> I see two problems with proposal #2.
> The first problem with proposal #2 is that, as we see in democracies,
> there is often a mismatch between the people conscious vote and these same
> people behavior.
>
> Relying on an  intentional vote made consciously by miners by choosing a
> configuration value can lead to twisted results if their actual behavior
> doesn't correlate with their vote (eg, they all vote for a small block size
> because it is the default configuration of their software, and then they
> fill it completely all the time and everything crashes).
>
> The second problem with proposal #2 is that if Gavin and Mike are right,
> there is simply no time to gather a meaningful amount of votes over the
> coinbases, after the fork but before the Bitcoin scalability crash.
>
> I like proposal #1 because the "vote" is made using already available
> data. Also there is no possible mismatch between behavior and vote. As a
> miner you vote by choosing to create a big (or small) block, and your
> actions reflect your vote. It is simple and straightforward.
>
> My feelings on proposal #3 is it is a little bit mixing apples and
> oranges, but I may not seeing all the implications.
>
>
> Le ven. 8 mai 2015 ? 09:21, Matt Whitlock <bip at mattwhitlock.name> a
> ?crit :
>
>> Between all the flames on this list, several ideas were raised that did
>> not get much attention. I hereby resubmit these ideas for consideration and
>> discussion.
>>
>> - Perhaps the hard block size limit should be a function of the actual
>> block sizes over some trailing sampling period. For example, take the
>> median block size among the most recent 2016 blocks and multiply it by 1.5.
>> This allows Bitcoin to scale up gradually and organically, rather than
>> having human beings guessing at what is an appropriate limit.
>>
>> - Perhaps the hard block size limit should be determined by a vote of the
>> miners. Each miner could embed a desired block size limit in the coinbase
>> transactions of the blocks it publishes. The effective hard block size
>> limit would be that size having the greatest number of votes within a
>> sliding window of most recent blocks.
>>
>> - Perhaps the hard block size limit should be a function of block-chain
>> length, so that it can scale up smoothly rather than jumping immediately to
>> 20 MB. This function could be linear (anticipating a breakdown of Moore's
>> Law) or quadratic.
>>
>> I would be in support of any of the above, but I do not support Mike
>> Hearn's proposed jump to 20 MB. Hearn's proposal kicks the can down the
>> road without actually solving the problem, and it does so in a
>> controversial (step function) way.
>>
>>
>> ------------------------------------------------------------------------------
>> One dashboard for servers and applications across Physical-Virtual-Cloud
>> Widest out-of-the-box monitoring support with 50+ applications
>> Performance metrics, stats and reports that give you Actionable Insights
>> Deep dive visibility with transaction tracing using APM Insight.
>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/b6a95d5e/attachment.html>

From gavinandresen at gmail.com  Fri May  8 12:48:47 2015
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Fri, 8 May 2015 08:48:47 -0400
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CAGKSKfW7fJB6n3B-OoyXOep7hAQqWGGDTiZCkpJ7vXxWRFgveA@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CAP63atbdFSw0rDeuwgtjsDYsXnKSHNN9=zedzip2MsZ0hSY59w@mail.gmail.com>
	<CAGKSKfW7fJB6n3B-OoyXOep7hAQqWGGDTiZCkpJ7vXxWRFgveA@mail.gmail.com>
Message-ID: <CABsx9T0y2sQzV6suxD9H0g37tqorsBSNs9AGHP+AVncRFkD+GQ@mail.gmail.com>

I like the bitcoin days destroyed idea.

I like lots of the ideas that have been presented here, on the bitcointalk
forums, etc etc etc.

It is easy to make a proposal, it is hard to wade through all of the
proposals. I'm going to balance that equation by completely ignoring any
proposal that isn't accompanied by code that implements the proposal (with
appropriate tests).

However, I'm not the bottleneck-- you need to get the attention of the
other committers and convince THEM:

a) something should be done "now-ish"
b) your idea is good

We are stuck on (a) right now, I think.


On Fri, May 8, 2015 at 8:32 AM, Joel Joonatan Kaartinen <
joel.kaartinen at gmail.com> wrote:

> Matt,
>
> It seems you missed my suggestion about basing the maximum block size on
> the bitcoin days destroyed in transactions that are included in the block.
> I think it has potential for both scaling as well as keeping up a constant
> fee pressure. If tuned properly, it should both stop spamming and increase
> block size maximum when there are a lot of real transactions waiting for
> inclusion.
>
> - Joel
>


-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/f3bd5434/attachment.html>

From bip at mattwhitlock.name  Fri May  8 12:48:16 2015
From: bip at mattwhitlock.name (Matt Whitlock)
Date: Fri, 08 May 2015 08:48:16 -0400
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CAGKSKfW7fJB6n3B-OoyXOep7hAQqWGGDTiZCkpJ7vXxWRFgveA@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CAP63atbdFSw0rDeuwgtjsDYsXnKSHNN9=zedzip2MsZ0hSY59w@mail.gmail.com>
	<CAGKSKfW7fJB6n3B-OoyXOep7hAQqWGGDTiZCkpJ7vXxWRFgveA@mail.gmail.com>
Message-ID: <47719888.P2f3pq4RTK@crushinator>

On Friday, 8 May 2015, at 3:32 pm, Joel Joonatan Kaartinen wrote:
> It seems you missed my suggestion about basing the maximum block size on
> the bitcoin days destroyed in transactions that are included in the block.
> I think it has potential for both scaling as well as keeping up a constant
> fee pressure. If tuned properly, it should both stop spamming and increase
> block size maximum when there are a lot of real transactions waiting for
> inclusion.

I saw it. I apologize for not including it in my list. I should have, for sake of discussion, even though I have a problem with it.

My problem with it is that "bitcoin days destroyed" is not a measure of demand for space in the block chain. In the distant future, when Bitcoin is the predominant global currency, bitcoins will have such high velocity that the number of bitcoin days destroyed in each block will be much lower than at present. Does this mean that the block size limit should be lower in the future than it is now? Clearly this would be incorrect.

Perhaps I am misunderstanding your proposal. Could you describe it more explicitly?



From bip at mattwhitlock.name  Fri May  8 13:24:49 2015
From: bip at mattwhitlock.name (Matt Whitlock)
Date: Fri, 08 May 2015 09:24:49 -0400
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <47719888.P2f3pq4RTK@crushinator>
References: <16096345.A1MpJQQkRW@crushinator>
	<CAGKSKfW7fJB6n3B-OoyXOep7hAQqWGGDTiZCkpJ7vXxWRFgveA@mail.gmail.com>
	<47719888.P2f3pq4RTK@crushinator>
Message-ID: <6997846.HngUFLFEeM@crushinator>

On Friday, 8 May 2015, at 8:48 am, Matt Whitlock wrote:
> On Friday, 8 May 2015, at 3:32 pm, Joel Joonatan Kaartinen wrote:
> > It seems you missed my suggestion about basing the maximum block size on
> > the bitcoin days destroyed in transactions that are included in the block.
> > I think it has potential for both scaling as well as keeping up a constant
> > fee pressure. If tuned properly, it should both stop spamming and increase
> > block size maximum when there are a lot of real transactions waiting for
> > inclusion.
> 
> My problem with it is that "bitcoin days destroyed" is not a measure of demand for space in the block chain. In the distant future, when Bitcoin is the predominant global currency, bitcoins will have such high velocity that the number of bitcoin days destroyed in each block will be much lower than at present. Does this mean that the block size limit should be lower in the future than it is now? Clearly this would be incorrect.

I feel a need to point out something that may be obvious to some but not to others: the cumulative total number of "bitcoin days destroyed" since the genesis block is bounded by the cumulative total number of "bitcoin days created" since the genesis block. (You can't destroy something that hasn't yet been created.) After all coins have been mined, bitcoin days will be created at a rate of 21M bitcoin days per day. In the long run, bitcoin days will be destroyed at a rate not exceeding 21M bitcoin days per day. This is so because bitcoin days cannot be destroyed at a rate faster than they are created for an indefinitely long time. This upper limit on the rate of bitcoin days destruction is irrespective of bitcoin adoption and the growth in demand for space in the block chain.

Even ignoring the fact that "bitcoin days destroyed" is bounded whereas demand for block-chain space is not, we'd still have to answer the question of whether the rate of bitcoin days destroyed is a good estimator of demand for block-chain space. Why would it be? Suppose some day Satoshi moves his 1M coins to a new address. Would this huge destruction of bitcoin days imply anything about future demand for space in the block chain? No.



From tier.nolan at gmail.com  Fri May  8 14:15:05 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Fri, 8 May 2015 15:15:05 +0100
Subject: [Bitcoin-development] Assurance contracts to fund the network
 with OP_CHECKLOCKTIMEVERIFY
In-Reply-To: <CAOoPuRZG4CVxcgExKHjDQd+F-w6xr6cJZD7pShbgPJd9CnqTwg@mail.gmail.com>
References: <CAE-z3OUiK_s-gJtnPquUZbG5aJkJjfo+VYKHgX+Bfcgem+6i9A@mail.gmail.com>
	<CANEZrP2OXSmhLsfvpsQdr0QGbGyJWaAp1F0itu4V_C-E+0gO6A@mail.gmail.com>
	<CAOoPuRZG4CVxcgExKHjDQd+F-w6xr6cJZD7pShbgPJd9CnqTwg@mail.gmail.com>
Message-ID: <CAE-z3OV30-ds5=5Tm55n+B26sPz3P+iC2TNHTBUidbX=qu08nQ@mail.gmail.com>

Just to clarify the process.

Pledgers create transactions using the following template and broadcast
them.  The p2p protocol could be modified to allow this, or it could be a
separate system.


*Input: 0.01 BTC*


*Signed with SIGHASH_ANYONE_CAN_PAY*

*Output 50BTC*

*Paid to: <1 million> OP_CHECKLOCKTIMEVERIFY OP_TRUE*


*Output 0.01BTC*

*Paid to OP_TRUE*
This transaction is invalid, since the inputs don't pay for the output.
The advantage of the sighash "anyone can pay" field is that other people
can add additional inputs without making the signature invalid.  Normally,
any change to the transaction would make a signature invalid.

Eventually, enough other users have added pledges and a valid transaction
can be broadcast.


*Input: 0.01 BTC*

*Signed with SIGHASH_ANYONE_CAN_PAY*

*Input: 1.2 BTCSigned with SIGHASH_ANYONE_CAN_PAY*


*Input: 5 BTCSigned with SIGHASH_ANYONE_CAN_PAY*

*<etc>*





*Input: 1.3 BTCSigned with SIGHASH_ANYONE_CAN_PAYOutput 50BTC*
*Paid to: <1 million> OP_CHECKLOCKTIMEVERIFY OP_TRUE*

*Output 0.01BTC**Paid to OP_TRUE*

This transaction can be submitted to the main network.  Once it is included
into the blockchain, it is locked in.

In this example, it might be included in block 999,500.  The 0.01BTC output
(and any excess over 50BTC) can be collected by the block 999,500 miner.

The OP_CHECKLOCKTIMEVERIFY opcode means that the 50BTC output cannot be
spent until block 1 million.  Once block 1 million arrives, the output is
completely unprotected.  This means that the miner who mines block 1
million can simply take it, by including his own transaction that sends it
to an address he controls.  It would be irrational to include somebody
else's transaction which spent it.

If by block 999,900, the transaction hasn't been completed (due to not
enough pledgers), the pledgers can spend the coin(s) that they were going
to use for their pledge.  This invalidates those inputs and effectively
withdraws from the pledge.

On Fri, May 8, 2015 at 11:01 AM, Benjamin <benjamin.l.cordes at gmail.com>
wrote:

> 2. "A merchant wants to cause block number 1 million to effectively
> have a minting fee of 50BTC." - why should he do that? That's the
> entire tragedy of the commons problem, no?
>

No, the pledger is saying that he will only pay 0.01BTC if the miner gets a
reward of 50BTC.

Imagine a group of 1000 people who want to make a donation of 50BTC to
something.  They all way that they will donate 0.05BTC, but only if
everyone else donates.

It still isn't perfect.  Everyone has an incentive to wait until the last
minute to pledge.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/9fcdc606/attachment.html>

From abrutschy at xylon.de  Fri May  8 14:01:01 2015
From: abrutschy at xylon.de (Arne Brutschy)
Date: Fri, 08 May 2015 16:01:01 +0200
Subject: [Bitcoin-development] Removing transaction data from blocks
Message-ID: <554CC19D.2010306@xylon.de>

Hello,

At DevCore London, Gavin mentioned the idea that we could get rid of 
sending full blocks. Instead, newly minted blocks would only be 
distributed as block headers plus all hashes of the transactions 
included in the block. The assumption would be that nodes have already 
the majority of these transactions in their mempool.

The advantages are clear: it's more efficient, as we would send 
transactions only once over the network, and it's fast as the resulting 
blocks would be small. Moreover, we would get rid of the blocksize limit 
for a long time.

Unfortunately, I am too ignorant of bitcoin core's internals to judge 
the changes required to make this happen. (I guess we'd require a new 
block format and a way to bulk-request missing transactions.)

However, I'm curious to hear what others with a better grasp of bitcoin 
core's internals have to say about it.

Regards,
Arne



From pieter.wuille at gmail.com  Fri May  8 14:52:28 2015
From: pieter.wuille at gmail.com (Pieter Wuille)
Date: Fri, 8 May 2015 07:52:28 -0700
Subject: [Bitcoin-development] Removing transaction data from blocks
In-Reply-To: <554CC19D.2010306@xylon.de>
References: <554CC19D.2010306@xylon.de>
Message-ID: <CAPg+sBhR2UcpjCxOEXw0gC9scG6OXMcyPLkfjfw7fP736XbGSw@mail.gmail.com>

So, there are several ideas about how to reduce the size of blocks being
sent on the network:
* Matt Corallo's relay network, which internally works by remembering the
last 5000 (i believe?) transactions sent by the peer, and allowing the peer
to backreference those rather than retransmit them inside block data. This
exists and works today.
* Gavin Andresen's IBLT based set reconciliation for blocks based on what a
peer expects the new block to contain.
* Greg Maxwell's network block coding, which is based on erasure coding,
and also supports sharding (everyone sends some block data to everyone,
rather fetching from one peer).

However, the primary purpose is not to reduce bandwidth (though that is a
nice side advantage). The purpose is reducing propagation delay. Larger
propagation delays across the network (relative to the inter-block period)
result in higher forking rates. If the forking rate gets very high, the
network may fail to converge entirely, but even long before that point, the
higher the forking rate is, the higher the advantage of larger (and better
connected) pools over smaller ones. This is why, in my opinion,
guaranteeing fast propagation is one of the most essential responsibility
of full nodes to avoid centralization pressure.

Also, none of this would let us "get rid of the block size" at all. All
transactions still have to be transferred and processed, and due to
inherent latencies of communication across the globe, the higher the
transaction rate is, the higher the number of transactions in blocks will
be that peers have not yet heard about. You can institute a policy to not
include too recent transactions in blocks, but again, this favors larger
miners over smaller ones.

Also, if the end goal is propagation delay, just minimizing the amount of
data transferred is not enough. You also need to make sure the
communication mechanism does not add huge processing overheads or adds
unnecessary roundtrips. In fact, this is the key difference between the 3
techniques listed above, and several people are working on refining and
optimizing these mechanisms to make them practically usable.
On May 8, 2015 7:23 AM, "Arne Brutschy" <abrutschy at xylon.de> wrote:

> Hello,
>
> At DevCore London, Gavin mentioned the idea that we could get rid of
> sending full blocks. Instead, newly minted blocks would only be
> distributed as block headers plus all hashes of the transactions
> included in the block. The assumption would be that nodes have already
> the majority of these transactions in their mempool.
>
> The advantages are clear: it's more efficient, as we would send
> transactions only once over the network, and it's fast as the resulting
> blocks would be small. Moreover, we would get rid of the blocksize limit
> for a long time.
>
> Unfortunately, I am too ignorant of bitcoin core's internals to judge
> the changes required to make this happen. (I guess we'd require a new
> block format and a way to bulk-request missing transactions.)
>
> However, I'm curious to hear what others with a better grasp of bitcoin
> core's internals have to say about it.
>
> Regards,
> Arne
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/603dc927/attachment.html>

From benjamin.l.cordes at gmail.com  Fri May  8 14:54:05 2015
From: benjamin.l.cordes at gmail.com (Benjamin)
Date: Fri, 8 May 2015 16:54:05 +0200
Subject: [Bitcoin-development] Assurance contracts to fund the network
 with OP_CHECKLOCKTIMEVERIFY
In-Reply-To: <CAE-z3OV30-ds5=5Tm55n+B26sPz3P+iC2TNHTBUidbX=qu08nQ@mail.gmail.com>
References: <CAE-z3OUiK_s-gJtnPquUZbG5aJkJjfo+VYKHgX+Bfcgem+6i9A@mail.gmail.com>
	<CANEZrP2OXSmhLsfvpsQdr0QGbGyJWaAp1F0itu4V_C-E+0gO6A@mail.gmail.com>
	<CAOoPuRZG4CVxcgExKHjDQd+F-w6xr6cJZD7pShbgPJd9CnqTwg@mail.gmail.com>
	<CAE-z3OV30-ds5=5Tm55n+B26sPz3P+iC2TNHTBUidbX=qu08nQ@mail.gmail.com>
Message-ID: <CAOoPuRZo6M1-XTYk6LebADHwQVwKEOYtaHGvEoRkk5AfevvJYw@mail.gmail.com>

>> Imagine a group of 1000 people who want to make a donation of 50BTC to something.  They all way that they will donate 0.05BTC, but only if everyone else donates.

It still isn't perfect.  Everyone has an incentive to wait until the
last minute to pledge. <<

AC does not solve the problem. AC works if people gain directly from
the payment. Imagine a group of people paying tax - nobody gains from
paying it. You have to actually need to enforce negative outcomes to
enable it (jail for tax fraud). Hence in Bitcoin we have the enforced
subsidy. AFAIK the problem of how to incentivize transaction
verification without subsidy is unsolved. Who determines a fair price?
People around here should study more economics, game theory, etc.
instead of debating low level encodings all the time.

On Fri, May 8, 2015 at 4:15 PM, Tier Nolan <tier.nolan at gmail.com> wrote:
> Just to clarify the process.
>
> Pledgers create transactions using the following template and broadcast
> them.  The p2p protocol could be modified to allow this, or it could be a
> separate system.
>
> Input: 0.01 BTC
> Signed with SIGHASH_ANYONE_CAN_PAY
>
> Output 50BTC
> Paid to: <1 million> OP_CHECKLOCKTIMEVERIFY OP_TRUE
>
> Output 0.01BTC
> Paid to OP_TRUE
>
> This transaction is invalid, since the inputs don't pay for the output.  The
> advantage of the sighash "anyone can pay" field is that other people can add
> additional inputs without making the signature invalid.  Normally, any
> change to the transaction would make a signature invalid.
>
> Eventually, enough other users have added pledges and a valid transaction
> can be broadcast.
>
> Input: 0.01 BTC
> Signed with SIGHASH_ANYONE_CAN_PAY
>
> Input: 1.2 BTC
> Signed with SIGHASH_ANYONE_CAN_PAY
>
> Input: 5 BTC
> Signed with SIGHASH_ANYONE_CAN_PAY
>
> <etc>
>
> Input: 1.3 BTC
> Signed with SIGHASH_ANYONE_CAN_PAY
>
> Output 50BTC
> Paid to: <1 million> OP_CHECKLOCKTIMEVERIFY OP_TRUE
>
> Output 0.01BTC
> Paid to OP_TRUE
>
> This transaction can be submitted to the main network.  Once it is included
> into the blockchain, it is locked in.
>
> In this example, it might be included in block 999,500.  The 0.01BTC output
> (and any excess over 50BTC) can be collected by the block 999,500 miner.
>
> The OP_CHECKLOCKTIMEVERIFY opcode means that the 50BTC output cannot be
> spent until block 1 million.  Once block 1 million arrives, the output is
> completely unprotected.  This means that the miner who mines block 1 million
> can simply take it, by including his own transaction that sends it to an
> address he controls.  It would be irrational to include somebody else's
> transaction which spent it.
>
> If by block 999,900, the transaction hasn't been completed (due to not
> enough pledgers), the pledgers can spend the coin(s) that they were going to
> use for their pledge.  This invalidates those inputs and effectively
> withdraws from the pledge.
>
> On Fri, May 8, 2015 at 11:01 AM, Benjamin <benjamin.l.cordes at gmail.com>
> wrote:
>>
>> 2. "A merchant wants to cause block number 1 million to effectively
>> have a minting fee of 50BTC." - why should he do that? That's the
>> entire tragedy of the commons problem, no?
>
>
> No, the pledger is saying that he will only pay 0.01BTC if the miner gets a
> reward of 50BTC.
>
> Imagine a group of 1000 people who want to make a donation of 50BTC to
> something.  They all way that they will donate 0.05BTC, but only if everyone
> else donates.
>
> It still isn't perfect.  Everyone has an incentive to wait until the last
> minute to pledge.



From tier.nolan at gmail.com  Fri May  8 14:56:35 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Fri, 8 May 2015 15:56:35 +0100
Subject: [Bitcoin-development] Assurance contracts to fund the network
 with OP_CHECKLOCKTIMEVERIFY
In-Reply-To: <CAOoPuRZo6M1-XTYk6LebADHwQVwKEOYtaHGvEoRkk5AfevvJYw@mail.gmail.com>
References: <CAE-z3OUiK_s-gJtnPquUZbG5aJkJjfo+VYKHgX+Bfcgem+6i9A@mail.gmail.com>
	<CANEZrP2OXSmhLsfvpsQdr0QGbGyJWaAp1F0itu4V_C-E+0gO6A@mail.gmail.com>
	<CAOoPuRZG4CVxcgExKHjDQd+F-w6xr6cJZD7pShbgPJd9CnqTwg@mail.gmail.com>
	<CAE-z3OV30-ds5=5Tm55n+B26sPz3P+iC2TNHTBUidbX=qu08nQ@mail.gmail.com>
	<CAOoPuRZo6M1-XTYk6LebADHwQVwKEOYtaHGvEoRkk5AfevvJYw@mail.gmail.com>
Message-ID: <CAE-z3OUypPwtvzhFJEPYfO7zw4NxmEEXNtRFfqQrVCO2Z2jr6A@mail.gmail.com>

On Fri, May 8, 2015 at 3:54 PM, Benjamin <benjamin.l.cordes at gmail.com>
wrote:

> AC does not solve the problem. AC works if people gain directly from
> the payment.


Not necessarily.









> Imagine a group of people paying tax - nobody gains from
> paying it. You have to actually need to enforce negative outcomes to
> enable it (jail for tax fraud). Hence in Bitcoin we have the enforced
> subsidy. AFAIK the problem of how to incentivize transaction
> verification without subsidy is unsolved. Who determines a fair price?
> People around here should study more economics, game theory, etc.
> instead of debating low level encodings all the time.
>
> On Fri, May 8, 2015 at 4:15 PM, Tier Nolan <tier.nolan at gmail.com> wrote:
> > Just to clarify the process.
> >
> > Pledgers create transactions using the following template and broadcast
> > them.  The p2p protocol could be modified to allow this, or it could be a
> > separate system.
> >
> > Input: 0.01 BTC
> > Signed with SIGHASH_ANYONE_CAN_PAY
> >
> > Output 50BTC
> > Paid to: <1 million> OP_CHECKLOCKTIMEVERIFY OP_TRUE
> >
> > Output 0.01BTC
> > Paid to OP_TRUE
> >
> > This transaction is invalid, since the inputs don't pay for the output.
> The
> > advantage of the sighash "anyone can pay" field is that other people can
> add
> > additional inputs without making the signature invalid.  Normally, any
> > change to the transaction would make a signature invalid.
> >
> > Eventually, enough other users have added pledges and a valid transaction
> > can be broadcast.
> >
> > Input: 0.01 BTC
> > Signed with SIGHASH_ANYONE_CAN_PAY
> >
> > Input: 1.2 BTC
> > Signed with SIGHASH_ANYONE_CAN_PAY
> >
> > Input: 5 BTC
> > Signed with SIGHASH_ANYONE_CAN_PAY
> >
> > <etc>
> >
> > Input: 1.3 BTC
> > Signed with SIGHASH_ANYONE_CAN_PAY
> >
> > Output 50BTC
> > Paid to: <1 million> OP_CHECKLOCKTIMEVERIFY OP_TRUE
> >
> > Output 0.01BTC
> > Paid to OP_TRUE
> >
> > This transaction can be submitted to the main network.  Once it is
> included
> > into the blockchain, it is locked in.
> >
> > In this example, it might be included in block 999,500.  The 0.01BTC
> output
> > (and any excess over 50BTC) can be collected by the block 999,500 miner.
> >
> > The OP_CHECKLOCKTIMEVERIFY opcode means that the 50BTC output cannot be
> > spent until block 1 million.  Once block 1 million arrives, the output is
> > completely unprotected.  This means that the miner who mines block 1
> million
> > can simply take it, by including his own transaction that sends it to an
> > address he controls.  It would be irrational to include somebody else's
> > transaction which spent it.
> >
> > If by block 999,900, the transaction hasn't been completed (due to not
> > enough pledgers), the pledgers can spend the coin(s) that they were
> going to
> > use for their pledge.  This invalidates those inputs and effectively
> > withdraws from the pledge.
> >
> > On Fri, May 8, 2015 at 11:01 AM, Benjamin <benjamin.l.cordes at gmail.com>
> > wrote:
> >>
> >> 2. "A merchant wants to cause block number 1 million to effectively
> >> have a minting fee of 50BTC." - why should he do that? That's the
> >> entire tragedy of the commons problem, no?
> >
> >
> > No, the pledger is saying that he will only pay 0.01BTC if the miner
> gets a
> > reward of 50BTC.
> >
> > Imagine a group of 1000 people who want to make a donation of 50BTC to
> > something.  They all way that they will donate 0.05BTC, but only if
> everyone
> > else donates.
> >
> > It still isn't perfect.  Everyone has an incentive to wait until the last
> > minute to pledge.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/b9fa8756/attachment.html>

From steven.pine at gmail.com  Fri May  8 14:57:50 2015
From: steven.pine at gmail.com (Steven Pine)
Date: Fri, 8 May 2015 10:57:50 -0400
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
Message-ID: <CAAjy6kBVgHNpqHfbngGXgxc6-6CDz6SCE=DuYLpKOyef7cBWfA@mail.gmail.com>

Block size scaling should be as transparent and simple as possible, like
pegging it to total transactions per difficulty change.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/4c72c004/attachment.html>

From etotheipi at gmail.com  Fri May  8 14:59:34 2015
From: etotheipi at gmail.com (Alan Reiner)
Date: Fri, 08 May 2015 10:59:34 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CAJHLa0NcxOHkrtW2=-JgfsXQJkCO8Ym7icBwMx_2RsaWcPBnTw@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<554BA032.4040405@bluematt.me>
	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>
	<CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>
	<CANEZrP39jWHLF02z-81Z4+9X1vH5+hMuS=-3ED81=Q1o9U=DKw@mail.gmail.com>
	<554BBDA2.7040508@gmail.com>
	<CAJHLa0NcxOHkrtW2=-JgfsXQJkCO8Ym7icBwMx_2RsaWcPBnTw@mail.gmail.com>
Message-ID: <554CCF56.3000604@gmail.com>


This isn't about "everyone's coffee".  This is about an absolute minimum
amount of participation by people who wish to use the network.   If our
goal is really for bitcoin to really be a global, open transaction
network that makes money fluid, then 7tps is already a failure.  If even
5% of the world (350M people) was using the network for 1 tx per month
(perhaps to open payment channels, or shift money between side chains),
we'll be above 100 tps.  And that doesn't include all the
non-individuals (organizations) that want to use it.

The goals of "a global transaction network" and "everyone must be able
to run a full node with their $200 dell laptop" are not compatible.  We
need to accept that a global transaction system cannot be
fully/constantly audited by everyone and their mother.  The important
feature of the network is that it is open and anyone *can* get the
history and verify it.  But not everyone is required to.   Trying to
promote a system where the history can be forever handled by a low-end
PC is already falling out of reach, even with our miniscule 7 tps. 
Clinging to that goal needlessly limits the capability for the network
to scale to be a useful global payments system



On 05/07/2015 03:54 PM, Jeff Garzik wrote:
> On Thu, May 7, 2015 at 3:31 PM, Alan Reiner <etotheipi at gmail.com
> <mailto:etotheipi at gmail.com>> wrote:
>  
>
>     (2) Leveraging fee pressure at 1MB to solve the problem is
>     actually really a bad idea.  It's really bad while Bitcoin is
>     still growing, and relying on fee pressure at 1 MB severely
>     impacts attractiveness and adoption potential of Bitcoin (due to
>     high fees and unreliability).  But more importantly, it ignores
>     the fact that for a 7 tps is pathetic for a global transaction
>     system.  It is a couple orders of magnitude too low for any
>     meaningful commercial activity to occur.  If we continue with a
>     cap of 7 tps forever, Bitcoin *will* fail.  Or at best, it will
>     fail to be useful for the vast majority of the world (which
>     probably leads to failure).  We shouldn't be talking about fee
>     pressure until we hit 700 tps, which is probably still too low. 
>
>  [...]
>
> 1) Agree that 7 tps is too low
>
> 2) Where do you want to go?  Should bitcoin scale up to handle all the
> world's coffees? 
>
> This is hugely unrealistic.  700 tps is 100MB blocks, 14.4 GB/day --
> just for a single feed.  If you include relaying to multiple nodes,
> plus serving 500 million SPV clients en grosse, who has the capacity
> to run such a node?  By the time we get to fee pressure, in your
> scenario, our network node count is tiny and highly centralized.
>
> 3) In RE "fee pressure" -- Do you see the moral hazard to a
> software-run system?  It is an intentional, human decision to flood
> the market with supply, thereby altering the economics, forcing fees
> to remain low in the hopes of achieving adoption.  I'm pro-bitcoin and
> obviously want to see bitcoin adoption - but I don't want to sacrifice
> every decentralized principle and become a central banker in order to
> get there.
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/aa6f7b9a/attachment.html>

From tier.nolan at gmail.com  Fri May  8 15:03:28 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Fri, 8 May 2015 16:03:28 +0100
Subject: [Bitcoin-development] Assurance contracts to fund the network
 with OP_CHECKLOCKTIMEVERIFY
In-Reply-To: <CAOoPuRZo6M1-XTYk6LebADHwQVwKEOYtaHGvEoRkk5AfevvJYw@mail.gmail.com>
References: <CAE-z3OUiK_s-gJtnPquUZbG5aJkJjfo+VYKHgX+Bfcgem+6i9A@mail.gmail.com>
	<CANEZrP2OXSmhLsfvpsQdr0QGbGyJWaAp1F0itu4V_C-E+0gO6A@mail.gmail.com>
	<CAOoPuRZG4CVxcgExKHjDQd+F-w6xr6cJZD7pShbgPJd9CnqTwg@mail.gmail.com>
	<CAE-z3OV30-ds5=5Tm55n+B26sPz3P+iC2TNHTBUidbX=qu08nQ@mail.gmail.com>
	<CAOoPuRZo6M1-XTYk6LebADHwQVwKEOYtaHGvEoRkk5AfevvJYw@mail.gmail.com>
Message-ID: <CAE-z3OVMfxioXUrFVAzcD7kpqsUA9_V=iCx67k+WkbZkFHrVig@mail.gmail.com>

Sorry for the spam of the last mail.  I hit send by accident.

Assurance contracts are better than simple donations.

Donating to a project means that you always end up losing the money but the
project might still not get funded.

An assurance contract is like Kickstarter, you only get your CC charged if
the project is fully funded.

There is lower risk, either you get your money back or the project is
funded.  It might still be worth risking it and hoping it gets funded.

Kickstarter does have pledge rewards to reward pledgers.  That helps with
creating the momentum to encourage people to pledge.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/569aed2a/attachment.html>

From etotheipi at gmail.com  Fri May  8 15:23:24 2015
From: etotheipi at gmail.com (Alan Reiner)
Date: Fri, 08 May 2015 11:23:24 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554C45E4.1020208@thinlink.com>
References: <554A91BE.6060105@bluematt.me>	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>	<554BA032.4040405@bluematt.me>	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>	<CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>	<CANEZrP39jWHLF02z-81Z4+9X1vH5+hMuS=-3ED81=Q1o9U=DKw@mail.gmail.com>	<554BBDA2.7040508@gmail.com>	<CAJHLa0NcxOHkrtW2=-JgfsXQJkCO8Ym7icBwMx_2RsaWcPBnTw@mail.gmail.com>	<554C1410.7050406@thinlink.com>	<CAJHLa0PeEd19ooHbOHUMxX9-5=iyUng-9GWnQFOn_F3aXxVWLQ@mail.gmail.com>
	<554C45E4.1020208@thinlink.com>
Message-ID: <554CD4EC.8020105@gmail.com>

On 05/08/2015 01:13 AM, Tom Harding wrote:
> On 5/7/2015 7:09 PM, Jeff Garzik wrote:
>> G proposed 20MB blocks, AFAIK - 140 tps
>> A proposed 100MB blocks - 700 tps
>> For ref,
>> Paypal is around 115 tps
>> VISA is around 2000 tps (perhaps 4000 tps peak)
>>

For reference, I'm not "proposing" 100 MB blocks right now.  I was
simply suggesting that if Bitcoin is to *ultimately* achieve the goal of
being a globally useful payment rails, 7tps is embarrassingly small. 
Even with off-chain transactions.  It should be a no-brainer that block
size has to go up.

My goal was to bring some long-term perspective into the discussion.  I
don't know if 100 MB blocks will *actually* be necessary for Bitcoin in
20 years, but it's feasible that it will be.  It's an open, global
payments system.  Therefore, we shouldn't be arguing about whether 1 MB
blocks is sufficient--it's very clearly not.  And admitting this as a
valid point is also an admission that not everyone in the world will be
able to run a full node in 20 years.

I don't think there's a solution that can accommodate all future
scenarios, nor that we can even find a solution right now that avoids
more hard forks in the future.   But the goal of "everyone should be
able to download and verify the world's global transactions on a
smartphone" is a non-starter and should not drive decisions. 



From jgarzik at bitpay.com  Fri May  8 15:49:48 2015
From: jgarzik at bitpay.com (Jeff Garzik)
Date: Fri, 8 May 2015 11:49:48 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554CCF56.3000604@gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<554BA032.4040405@bluematt.me>
	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>
	<CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>
	<CANEZrP39jWHLF02z-81Z4+9X1vH5+hMuS=-3ED81=Q1o9U=DKw@mail.gmail.com>
	<554BBDA2.7040508@gmail.com>
	<CAJHLa0NcxOHkrtW2=-JgfsXQJkCO8Ym7icBwMx_2RsaWcPBnTw@mail.gmail.com>
	<554CCF56.3000604@gmail.com>
Message-ID: <CAJHLa0Mc_7OYFpxHjMGTyMNBAXUV+Y67rZMsKuZgp4mGN7fJVg@mail.gmail.com>

On Fri, May 8, 2015 at 10:59 AM, Alan Reiner <etotheipi at gmail.com> wrote:

>
> This isn't about "everyone's coffee".  This is about an absolute minimum
> amount of participation by people who wish to use the network.   If our
> goal is really for bitcoin to really be a global, open transaction network
> that makes money fluid, then 7tps is already a failure.  If even 5% of the
> world (350M people) was using the network for 1 tx per month (perhaps to
> open payment channels, or shift money between side chains), we'll be above
> 100 tps.  And that doesn't include all the non-individuals (organizations)
> that want to use it.
>
> The goals of "a global transaction network" and "everyone must be able to
> run a full node with their $200 dell laptop" are not compatible.  We need
> to accept that a global transaction system cannot be fully/constantly
> audited by everyone and their mother.  The important feature of the network
> is that it is open and anyone *can* get the history and verify it.  But not
> everyone is required to.   Trying to promote a system where the history can
> be forever handled by a low-end PC is already falling out of reach, even
> with our miniscule 7 tps.  Clinging to that goal needlessly limits the
> capability for the network to scale to be a useful global payments system
>
>
To repeat, the very first point in my email reply was: "Agree that 7 tps is
too low"  Never was it said that bit

Therefore a reply arguing against the low end is nonsense, and the relevant
question remains on the table.

How high do you want to go - and can Layer 1 bitcoin really scale to get
there?

It is highly disappointing to see people endorse "moar bitcoin volume!"
with zero thinking behind that besides "adoption!"  Need to actually
project what bitcoin looks like at the desired levels, what network
resources are required to get to those levels -- including traffic to serve
those SPV clients via P2P -- and then work backwards from that to see who
can support it, and then work backwards to discern a maximum tps.

-- 
Jeff Garzik
Bitcoin core developer and open source evangelist
BitPay, Inc.      https://bitpay.com/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/c0203dbe/attachment.html>

From alex.mizrahi at gmail.com  Fri May  8 15:57:27 2015
From: alex.mizrahi at gmail.com (Alex Mizrahi)
Date: Fri, 8 May 2015 18:57:27 +0300
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <16096345.A1MpJQQkRW@crushinator>
References: <16096345.A1MpJQQkRW@crushinator>
Message-ID: <CAE28kUSkQ6YWzkcqU9RqRkZzHUR_8wYj1pTxGF8Z4gp5SztdAA@mail.gmail.com>

Adaptive schedules, i.e. those where block size limit depends not only on
block height, but on other parameters as well, are surely attractive in the
sense that the system can adapt to the actual use, but they also open a
possibility of a manipulation.

E.g. one of mining companies might try to bankrupt other companies by
making mining non-profitable. To do that they will accept transactions with
ridiculously low fees (e.g. 1 satoshi per transaction). Of course, they
will suffer losees themselves, but the they might be able to survive that
if they have access to financial resources. (E.g. companies backed by banks
and such will have an advantage).
Once competitors close down their mining operations, they can drive fees
upwards.

So if you don't want to open room for manipulation (which is very hard to
analyze), it is better to have a block size hard limit which depends only
on block height.
On top of that there might be a soft limit which is enforced by the
majority of miners.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/e290f012/attachment.html>

From pete at petertodd.org  Fri May  8 16:37:01 2015
From: pete at petertodd.org (Peter Todd)
Date: Fri, 8 May 2015 12:37:01 -0400
Subject: [Bitcoin-development] Block Size Increase Requirements
In-Reply-To: <CANEZrP3uKLvzKi-wXBJWL=pwqB+eAe3FbPjyESD52y5TGkg+Rg@mail.gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CANEZrP3uKLvzKi-wXBJWL=pwqB+eAe3FbPjyESD52y5TGkg+Rg@mail.gmail.com>
Message-ID: <20150508163701.GA27417@savin.petertodd.org>

On Fri, May 08, 2015 at 12:03:04PM +0200, Mike Hearn wrote:
> >
> >  * Though there are many proposals floating around which could
> > significantly decrease block propagation latency, none of them are
> > implemented today.
> 
> 
> With a 20mb cap, miners still have the option of the soft limit.

The soft-limit is there miners themselves produce smaller blocks; the
soft-limit does not prevent other miners from producing larger blocks.

As we're talking about ways that other miners can use 20MB blocks to
harm the competition, talking about the soft-limit is irrelevant.
Similarly, as security engineers we must plan for the worst case; as
we've seen before by your campaigns to raise the soft-limit(1) even at a
time when the vast majority of transaction volume was from one user
(SatoshiDice) soft-limits are an extremely weak form of control.

For the proposes of discussing blocksize increase requirements we can
stop talking about the soft-limit.

1) https://bitcointalk.org/index.php?topic=149668.0

-- 
'peter'[:-1]@petertodd.org
000000000000000009344ba165781ee352f93d657c8b098c8e518e6011753e59
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/b669d9b9/attachment.sig>

From pete at petertodd.org  Fri May  8 16:43:10 2015
From: pete at petertodd.org (Peter Todd)
Date: Fri, 8 May 2015 12:43:10 -0400
Subject: [Bitcoin-development] Assurance contracts to fund the network
 with OP_CHECKLOCKTIMEVERIFY
In-Reply-To: <CAJHLa0MgiC6vMdy=zm85CE2pWkOqtk18ePjb9nZ2-KwGf+q+Mw@mail.gmail.com>
References: <CAE-z3OUiK_s-gJtnPquUZbG5aJkJjfo+VYKHgX+Bfcgem+6i9A@mail.gmail.com>
	<CAJHLa0MgiC6vMdy=zm85CE2pWkOqtk18ePjb9nZ2-KwGf+q+Mw@mail.gmail.com>
Message-ID: <20150508164310.GB27417@savin.petertodd.org>

On Fri, May 08, 2015 at 06:00:37AM -0400, Jeff Garzik wrote:
> That reminds me - I need to integrate the patch that automatically sweeps
> anyone-can-pay transactions for a miner.

You mean anyone-can-spend?

I've got code that does this actually:

https://github.com/petertodd/replace-by-fee-tools/blob/master/spend-brainwallets-to-fees.py

Needs to have a feature where it replaces the txout set with simply
OP_RETURN-to-fees if the inputs don't sign the outputs though.
(SIGHASH_NONE for instance)

-- 
'peter'[:-1]@petertodd.org
00000000000000000ee99382ac6bc043120085973b7b0378811c1acd8e3cdd9c
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/de9e73eb/attachment.sig>

From pete at petertodd.org  Fri May  8 16:51:45 2015
From: pete at petertodd.org (Peter Todd)
Date: Fri, 8 May 2015 12:51:45 -0400
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
 function
In-Reply-To: <CAGKSKfW7fJB6n3B-OoyXOep7hAQqWGGDTiZCkpJ7vXxWRFgveA@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CAP63atbdFSw0rDeuwgtjsDYsXnKSHNN9=zedzip2MsZ0hSY59w@mail.gmail.com>
	<CAGKSKfW7fJB6n3B-OoyXOep7hAQqWGGDTiZCkpJ7vXxWRFgveA@mail.gmail.com>
Message-ID: <20150508165144.GC27417@savin.petertodd.org>

On Fri, May 08, 2015 at 03:32:00PM +0300, Joel Joonatan Kaartinen wrote:
> Matt,
> 
> It seems you missed my suggestion about basing the maximum block size on
> the bitcoin days destroyed in transactions that are included in the block.
> I think it has potential for both scaling as well as keeping up a constant
> fee pressure. If tuned properly, it should both stop spamming and increase
> block size maximum when there are a lot of real transactions waiting for
> inclusion.

The problem with gating block creation on Bitcoin days destroyed is
there's a strong potential of giving big mining pools an huge advantage,
because they can contract with large Bitcoin owners and buy dummy
transactions with large numbers of Bitcoin days destroyed on demand
whenever they need more days-destroyed to create larger blocks.
Similarly, with appropriate SIGHASH flags such contracting can be done
by modifying *existing* transactions on demand.

Ultimately bitcoin days destroyed just becomes a very complex version of
transaction fees, and it's already well known that gating blocksize on
total transaction fees doesn't work.

-- 
'peter'[:-1]@petertodd.org
00000000000000000f53e2d214685abf15b6d62d32453a03b0d472e374e10e94
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/aad39559/attachment.sig>

From kanzure at gmail.com  Fri May  8 16:55:42 2015
From: kanzure at gmail.com (Bryan Bishop)
Date: Fri, 8 May 2015 11:55:42 -0500
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <16096345.A1MpJQQkRW@crushinator>
References: <16096345.A1MpJQQkRW@crushinator>
Message-ID: <CABaSBaweJyQUdMDiegOs0U26dMto-VZt-PB8p5a+3vgyLqoGfA@mail.gmail.com>

On Fri, May 8, 2015 at 2:20 AM, Matt Whitlock <bip at mattwhitlock.name> wrote:
> - Perhaps the hard block size limit should be a function of the actual block sizes over some
> trailing sampling period. For example, take the median block size among the most recent
> 2016 blocks and multiply it by 1.5. This allows Bitcoin to scale up gradually and organically,
> rather than having human beings guessing at what is an appropriate limit.

Block contents can be grinded much faster than hashgrinding and
mining. There is a significant run-away effect there, and it also
works in the gradual sense as a miner probabilistically mines large
blocks that get averaged into that 2016 median block size computation.
At least this proposal would be a slower way of pushing out miners and
network participants that can't handle 100 GB blocks immediately..  As
the size of the blocks are increased, low-end hardware participants
have to fall off the network because they no longer meet the minimum
performance requirements. Adjustment might become severely mismatched
with general economic trends in data storage device development or
availability or even current-market-saturation of said storage
devices. With the assistance of transaction stuffing or grinding, that
2016 block median metric can be gamed to increase faster than other
participants can keep up with or, perhaps worse, in a way that was
unintended by developers yet known to be a failure mode. These are
just some issues to keep and mind and consider.

- Bryan
http://heybryan.org/
1 512 203 0507



From onelineproof at gmail.com  Fri May  8 17:17:49 2015
From: onelineproof at gmail.com (Andrew)
Date: Fri, 8 May 2015 17:17:49 +0000
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554CCF56.3000604@gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<554BA032.4040405@bluematt.me>
	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>
	<CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>
	<CANEZrP39jWHLF02z-81Z4+9X1vH5+hMuS=-3ED81=Q1o9U=DKw@mail.gmail.com>
	<554BBDA2.7040508@gmail.com>
	<CAJHLa0NcxOHkrtW2=-JgfsXQJkCO8Ym7icBwMx_2RsaWcPBnTw@mail.gmail.com>
	<554CCF56.3000604@gmail.com>
Message-ID: <CAL8tG=kA7V5wuRB9ob9ue4XAwGpkhh_yO_-EWDkYstV0q4PR5A@mail.gmail.com>

On Fri, May 8, 2015 at 2:59 PM, Alan Reiner <etotheipi at gmail.com> wrote:

>
> This isn't about "everyone's coffee".  This is about an absolute minimum
> amount of participation by people who wish to use the network.   If our
> goal is really for bitcoin to really be a global, open transaction network
> that makes money fluid, then 7tps is already a failure.  If even 5% of the
> world (350M people) was using the network for 1 tx per month (perhaps to
> open payment channels, or shift money between side chains), we'll be above
> 100 tps.  And that doesn't include all the non-individuals (organizations)
> that want to use it.
>

> The goals of "a global transaction network" and "everyone must be able to
> run a full node with their $200 dell laptop" are not compatible.  We need
> to accept that a global transaction system cannot be fully/constantly
> audited by everyone and their mother.  The important feature of the network
> is that it is open and anyone *can* get the history and verify it.  But not
> everyone is required to.   Trying to promote a system wher000e the history
> can be forever handled by a low-end PC is already falling out of reach,
> even with our miniscule 7 tps.  Clinging to that goal needlessly limits the
> capability for the network to scale to be a useful global payments system
>

These are good points and got me thinking (but I think you're wrong). If we
really want each of the 10 billion people soon using bitcoin once per
month, that will require 500MB blocks. That's about 2 TB per month. And if
you relay it to 4 peers, it's 10 TB per month. Which I suppose is doable
for a home desktop, so you can just run a pruned full node with all
transactions from the past month. But how do you sync all those
transactions if you've never done this before or it's been a while since
you did? I think it currently takes at least 3 hours to fully sync 30 GB of
transactions. So 2 TB will take 8 days, then you take a bit more time to
sync the days that passed while you were syncing. So that's doable, but at
a certain point, like 10 TB per month (still only 5 transactions per month
per person), you will need 41 days to sync that month, so you will never
catch up. So I think in order to keep the very important property of anyone
being able to start clean and verify the thing, then we need to think of
bitcoin as a system that does transactions for a large number of users at
once in one transaction, and not a system where each person will make a
~monthly transaction on. We need to therefore rely on sidechains,
treechains, lightning channels, etc...

I'm not a bitcoin wizard and this is just my second post on this mailing
list, so I may be missing something. So please someone, correct me if I'm
wrong.

>
>
>
> On 05/07/2015 03:54 PM, Jeff Garzik wrote:
>
>  On Thu, May 7, 2015 at 3:31 PM, Alan Reiner <etotheipi at gmail.com> wrote:
>
>
>>  (2) Leveraging fee pressure at 1MB to solve the problem is actually
>> really a bad idea.  It's really bad while Bitcoin is still growing, and
>> relying on fee pressure at 1 MB severely impacts attractiveness and
>> adoption potential of Bitcoin (due to high fees and unreliability).  But
>> more importantly, it ignores the fact that for a 7 tps is pathetic for a
>> global transaction system.  It is a couple orders of magnitude too low for
>> any meaningful commercial activity to occur.  If we continue with a cap of
>> 7 tps forever, Bitcoin *will* fail.  Or at best, it will fail to be
>> useful for the vast majority of the world (which probably leads to
>> failure).  We shouldn't be talking about fee pressure until we hit 700 tps,
>> which is probably still too low.
>>
>  [...]
>
>  1) Agree that 7 tps is too low
>
>  2) Where do you want to go?  Should bitcoin scale up to handle all the
> world's coffees?
>
>  This is hugely unrealistic.  700 tps is 100MB blocks, 14.4 GB/day --
> just for a single feed.  If you include relaying to multiple nodes, plus
> serving 500 million SPV clients en grosse, who has the capacity to run such
> a node?  By the time we get to fee pressure, in your scenario, our network
> node count is tiny and highly centralized.
>
>  3) In RE "fee pressure" -- Do you see the moral hazard to a software-run
> system?  It is an intentional, human decision to flood the market with
> supply, thereby altering the economics, forcing fees to remain low in the
> hopes of achieving adoption.  I'm pro-bitcoin and obviously want to see
> bitcoin adoption - but I don't want to sacrifice every decentralized
> principle and become a central banker in order to get there.
>
>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>


-- 
PGP: B6AC 822C 451D 6304 6A28  49E9 7DB7 011C D53B 5647
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/b5114625/attachment.html>

From etotheipi at gmail.com  Fri May  8 17:51:51 2015
From: etotheipi at gmail.com (Alan Reiner)
Date: Fri, 8 May 2015 13:51:51 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CAL8tG=kA7V5wuRB9ob9ue4XAwGpkhh_yO_-EWDkYstV0q4PR5A@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<554BA032.4040405@bluematt.me>
	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>
	<CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>
	<CANEZrP39jWHLF02z-81Z4+9X1vH5+hMuS=-3ED81=Q1o9U=DKw@mail.gmail.com>
	<554BBDA2.7040508@gmail.com>
	<CAJHLa0NcxOHkrtW2=-JgfsXQJkCO8Ym7icBwMx_2RsaWcPBnTw@mail.gmail.com>
	<554CCF56.3000604@gmail.com>
	<CAL8tG=kA7V5wuRB9ob9ue4XAwGpkhh_yO_-EWDkYstV0q4PR5A@mail.gmail.com>
Message-ID: <CALf2ePx-m+Of-kkWnUpVboiWxsnbTdWyT45eBAziJtbsL_P41Q@mail.gmail.com>

Actually I believe that side chains and off-main-chain transactions will be
a critical part for the overall scalability of the network.  I was actually
trying to make the point that (insert some huge block size here) will be
needed to even accommodate the reduced traffic.

I believe that it is definitely over 20MB. If it was determined to be 100
MB ten years from now, that wouldn't surprise me.

Sent from my overpriced smartphone
On May 8, 2015 1:17 PM, "Andrew" <onelineproof at gmail.com> wrote:

>
>
> On Fri, May 8, 2015 at 2:59 PM, Alan Reiner <etotheipi at gmail.com> wrote:
>
>>
>> This isn't about "everyone's coffee".  This is about an absolute minimum
>> amount of participation by people who wish to use the network.   If our
>> goal is really for bitcoin to really be a global, open transaction network
>> that makes money fluid, then 7tps is already a failure.  If even 5% of the
>> world (350M people) was using the network for 1 tx per month (perhaps to
>> open payment channels, or shift money between side chains), we'll be above
>> 100 tps.  And that doesn't include all the non-individuals (organizations)
>> that want to use it.
>>
>
>> The goals of "a global transaction network" and "everyone must be able to
>> run a full node with their $200 dell laptop" are not compatible.  We need
>> to accept that a global transaction system cannot be fully/constantly
>> audited by everyone and their mother.  The important feature of the network
>> is that it is open and anyone *can* get the history and verify it.  But not
>> everyone is required to.   Trying to promote a system wher000e the history
>> can be forever handled by a low-end PC is already falling out of reach,
>> even with our miniscule 7 tps.  Clinging to that goal needlessly limits the
>> capability for the network to scale to be a useful global payments system
>>
>
> These are good points and got me thinking (but I think you're wrong). If
> we really want each of the 10 billion people soon using bitcoin once per
> month, that will require 500MB blocks. That's about 2 TB per month. And if
> you relay it to 4 peers, it's 10 TB per month. Which I suppose is doable
> for a home desktop, so you can just run a pruned full node with all
> transactions from the past month. But how do you sync all those
> transactions if you've never done this before or it's been a while since
> you did? I think it currently takes at least 3 hours to fully sync 30 GB of
> transactions. So 2 TB will take 8 days, then you take a bit more time to
> sync the days that passed while you were syncing. So that's doable, but at
> a certain point, like 10 TB per month (still only 5 transactions per month
> per person), you will need 41 days to sync that month, so you will never
> catch up. So I think in order to keep the very important property of anyone
> being able to start clean and verify the thing, then we need to think of
> bitcoin as a system that does transactions for a large number of users at
> once in one transaction, and not a system where each person will make a
> ~monthly transaction on. We need to therefore rely on sidechains,
> treechains, lightning channels, etc...
>
> I'm not a bitcoin wizard and this is just my second post on this mailing
> list, so I may be missing something. So please someone, correct me if I'm
> wrong.
>
>>
>>
>>
>> On 05/07/2015 03:54 PM, Jeff Garzik wrote:
>>
>>  On Thu, May 7, 2015 at 3:31 PM, Alan Reiner <etotheipi at gmail.com> wrote:
>>
>>
>>>  (2) Leveraging fee pressure at 1MB to solve the problem is actually
>>> really a bad idea.  It's really bad while Bitcoin is still growing, and
>>> relying on fee pressure at 1 MB severely impacts attractiveness and
>>> adoption potential of Bitcoin (due to high fees and unreliability).  But
>>> more importantly, it ignores the fact that for a 7 tps is pathetic for a
>>> global transaction system.  It is a couple orders of magnitude too low for
>>> any meaningful commercial activity to occur.  If we continue with a cap of
>>> 7 tps forever, Bitcoin *will* fail.  Or at best, it will fail to be
>>> useful for the vast majority of the world (which probably leads to
>>> failure).  We shouldn't be talking about fee pressure until we hit 700 tps,
>>> which is probably still too low.
>>>
>>  [...]
>>
>>  1) Agree that 7 tps is too low
>>
>>  2) Where do you want to go?  Should bitcoin scale up to handle all the
>> world's coffees?
>>
>>  This is hugely unrealistic.  700 tps is 100MB blocks, 14.4 GB/day --
>> just for a single feed.  If you include relaying to multiple nodes, plus
>> serving 500 million SPV clients en grosse, who has the capacity to run such
>> a node?  By the time we get to fee pressure, in your scenario, our network
>> node count is tiny and highly centralized.
>>
>>  3) In RE "fee pressure" -- Do you see the moral hazard to a software-run
>> system?  It is an intentional, human decision to flood the market with
>> supply, thereby altering the economics, forcing fees to remain low in the
>> hopes of achieving adoption.  I'm pro-bitcoin and obviously want to see
>> bitcoin adoption - but I don't want to sacrifice every decentralized
>> principle and become a central banker in order to get there.
>>
>>
>>
>>
>> ------------------------------------------------------------------------------
>> One dashboard for servers and applications across Physical-Virtual-Cloud
>> Widest out-of-the-box monitoring support with 50+ applications
>> Performance metrics, stats and reports that give you Actionable Insights
>> Deep dive visibility with transaction tracing using APM Insight.
>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>>
>
>
> --
> PGP: B6AC 822C 451D 6304 6A28  49E9 7DB7 011C D53B 5647
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/4f232d91/attachment.html>

From tier.nolan at gmail.com  Fri May  8 19:47:52 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Fri, 8 May 2015 20:47:52 +0100
Subject: [Bitcoin-development] Block Size Increase Requirements
In-Reply-To: <20150508163701.GA27417@savin.petertodd.org>
References: <554BE0E1.5030001@bluematt.me>
	<CANEZrP3uKLvzKi-wXBJWL=pwqB+eAe3FbPjyESD52y5TGkg+Rg@mail.gmail.com>
	<20150508163701.GA27417@savin.petertodd.org>
Message-ID: <CAE-z3OV8zyUyYiGNRZZbTkUZz70KK7P-ENyhsKe+yhZmNnqRuQ@mail.gmail.com>

On Fri, May 8, 2015 at 5:37 PM, Peter Todd <pete at petertodd.org> wrote:

> The soft-limit is there miners themselves produce smaller blocks; the
> soft-limit does not prevent other miners from producing larger blocks.
>

I wonder if having a "miner" flag would be good for the network.

Clients for general users and merchants would have a less strict rule than
the rule for miners.  Miners who don't set their miners flag might get
orphaned off the chain.

For example, the limits could be setup as follows.

Clients: 20MB
Miners: 4MB

When in "miner mode", the client would reject 4MB blocks and wouldn't build
on them.  The reference client might even track the miner and the non-miner
chain tip.

Miners would refuse to build on 5MB blocks, but merchants and general users
would accept them.

This allows the miners to soft fork the limit at some point in the future.
If 75% of miners decided to up the limit to 8MB, then all merchants and the
general users would accept the new blocks.  It could follow the standard
soft fork rules.

This is a more general version of the system where miners are allowed to
vote on the block size (subject to a higher limit).

A similar system is where clients track all header trees.  Your wallet
could warn you that there is an invalid tree that has > 75% of the hashing
power and you might want to upgrade.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/51802e38/attachment.html>

From voisine at gmail.com  Fri May  8 20:17:09 2015
From: voisine at gmail.com (Aaron Voisine)
Date: Fri, 8 May 2015 13:17:09 -0700
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <1551544.DzLxgCKLBq@coldstorage>
References: <554A91BE.6060105@bluematt.me>
	<20150507014952.GA5657@savin.petertodd.org>
	<1551544.DzLxgCKLBq@coldstorage>
Message-ID: <CACq0ZD6Jt2=yw=A8+bgonb3Jb2h2fgEt8aVWNeNvsOpzZr9qrQ@mail.gmail.com>

As the author of a popular SPV wallet, I wanted to weigh in, in support of
the Gavin's 20Mb block proposal.

The best argument I've heard against raising the limit is that we need fee
pressure.  I agree that fee pressure is the right way to economize on
scarce resources. Placing hard limits on block size however is an
incredibly disruptive way to go about this, and will severely negatively
impact users' experience.

When users pay too low a fee, they should:

1) See immediate failure as they do now with fees that fail to propagate.

2) If the fee lower than it should be but not terminal, they should see
degraded performance, long delays in confirmation, but eventual success.
This will encourage them to pay higher fees in future.

The worst of all worlds would be to have transactions propagate, hang in
limbo for days, and then fail. This is the most important scenario to
avoid. Increasing the 1Mb block size limit I think is the simplest way to
avoid this least desirable scenario for the immediate future.

We can play around with improved transaction selection for blocks and
encourage miners to adopt it to discourage low fees and create fee
pressure. These could involve hybrid priority/fee selection so low fee
transactions see degraded performance instead of failure. This would be the
conservative low risk approach.

Aaron Voisine
co-founder and CEO
breadwallet.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/61a099ec/attachment.html>

From mark at friedenbach.org  Fri May  8 20:33:53 2015
From: mark at friedenbach.org (Mark Friedenbach)
Date: Fri, 8 May 2015 13:33:53 -0700
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <16096345.A1MpJQQkRW@crushinator>
References: <16096345.A1MpJQQkRW@crushinator>
Message-ID: <CAOG=w-szbLgc1jLpkE_uMa3bkFTi-RiBEaQ6Y-u5aKLBC2HvUg@mail.gmail.com>

It is my professional opinion that raising the block size by merely
adjusting a constant without any sort of feedback mechanism would be a
dangerous and foolhardy thing to do. We are custodians of a multi-billion
dollar asset, and it falls upon us to weigh the consequences of our own
actions against the combined value of the entire bitcoin ecosystem. Ideally
we would take no action for which we are not absolutely certain of the
ramifications, with the information that can be made available to us. But
of course that is not always possible: there are unknown-unknowns, time
pressures, and known-unknowns where information has too high a marginal
cost. So where certainty is unobtainable, we must instead hedge against
unwanted outcomes.

The proposal to raise the block size now by redefining a constant carries
with it risk associated with infrastructure scaling, centralization
pressures, and delaying the necessary development of a constraint-based fee
economy. It also simply kicks the can down the road in settling these
issues because a larger but realistic hard limit must still exist, meaning
a future hard fork may still be required.

But whatever new hard limit is chosen, there is also a real possibility
that it may be too high. The standard response is that it is a soft-fork
change to impose a lower block size limit, which miners could do with a
minimal amount of coordination. This is however undermined by the
unfortunate reality that so many mining operations are absentee-run
businesses, or run by individuals without a strong background in bitcoin
protocol policy, or with interests which are not well aligned with other
users or holders of bitcoin. We cannot rely on miners being vigilant about
issues that develop, as they develop, or able to respond in the appropriate
fashion that someone with full domain knowledge and an objective
perspective would.

The alternative then is to have some sort of dynamic block size limit
controller, and ideally one which applies a cost to raising the block size
in some way the preserves the decentralization and/or long-term stability
features that we care about. I will now describe one such proposal:

  * For each block, the miner is allowed to select a different difficulty
(nBits) within a certain range, e.g. +/- 25% of the expected difficulty,
and this miner-selected difficulty is used for the proof of work check. In
addition to adjusting the hashcash target, selecting a different difficulty
also raises or lowers the maximum block size for that block by a function
of the difference in difficulty. So increasing the difficulty of the block
by an additional 25% raises the block limit for that block from 100% of the
current limit to 125%, and lowering the difficulty by 10% would also lower
the maximum block size for that block from 100% to 90% of the current
limit. For simplicity I will assume a linear identity transform as the
function, but a quadratic or other function with compounding marginal cost
may be preferred.

  * The default maximum block size limit is then adjusted at regular
intervals. For simplicity I will assume an adjustment at the end of each
2016 block interval, at the same time that difficulty is adjusted, but
there is no reason these have to be aligned. The adjustment algorithm
itself is either the selection of the median, or perhaps some sort of
weighted average that respects the "middle majority." There would of course
be limits on how quickly the block size limit can adjusted in any one
period, just as there are min/max limits on the difficulty adjustment.

  * To prevent perverse mining incentives, the original difficulty without
adjustment is used in the aggregate work calculations for selecting the
most-work chain, and the allowable miner-selected adjustment to difficulty
would have to be tightly constrained.

These rules create an incentive environment where raising the block size
has a real cost associated with it: a more difficult hashcash target for
the same subsidy reward. For rational miners that cost must be
counter-balanced by additional fees provided in the larger block. This
allows block size to increase, but only within the confines of a
self-supporting fee economy.

When the subsidy goes away or is reduced to an insignificant fraction of
the block reward, this incentive structure goes away. Hopefully at that
time we would have sufficient information to soft-fork set a hard block
size maximum. But in the mean time, the block size limit controller
constrains the maximum allowed block size to be within a range supported by
fees on the network, providing an emergency relief valve that we can be
assured will only be used at significant cost.

Mark Friedenbach

* There has over time been various discussions on the bitcointalk forums
about dynamically adjusting block size limits. The true origin of the idea
is unclear at this time (citations would be appreciated!) but a form of it
was implemented in Bytecoin / Monero using subsidy burning to increase the
block size. That approach has various limitations. These were corrected in
Greg Maxwell's suggestion to adjust the difficulty/nBits field directly,
which also has the added benefit of providing incentive for bidirectional
movement during the subsidy period. The description in this email and any
errors are my own.

On Fri, May 8, 2015 at 12:20 AM, Matt Whitlock <bip at mattwhitlock.name>
wrote:

> Between all the flames on this list, several ideas were raised that did
> not get much attention. I hereby resubmit these ideas for consideration and
> discussion.
>
> - Perhaps the hard block size limit should be a function of the actual
> block sizes over some trailing sampling period. For example, take the
> median block size among the most recent 2016 blocks and multiply it by 1.5.
> This allows Bitcoin to scale up gradually and organically, rather than
> having human beings guessing at what is an appropriate limit.
>
> - Perhaps the hard block size limit should be determined by a vote of the
> miners. Each miner could embed a desired block size limit in the coinbase
> transactions of the blocks it publishes. The effective hard block size
> limit would be that size having the greatest number of votes within a
> sliding window of most recent blocks.
>
> - Perhaps the hard block size limit should be a function of block-chain
> length, so that it can scale up smoothly rather than jumping immediately to
> 20 MB. This function could be linear (anticipating a breakdown of Moore's
> Law) or quadratic.
>
> I would be in support of any of the above, but I do not support Mike
> Hearn's proposed jump to 20 MB. Hearn's proposal kicks the can down the
> road without actually solving the problem, and it does so in a
> controversial (step function) way.
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/ba1d33d5/attachment.html>

From raystonn at hotmail.com  Fri May  8 20:38:25 2015
From: raystonn at hotmail.com (Raystonn .)
Date: Fri, 8 May 2015 13:38:25 -0700
Subject: [Bitcoin-development] Block Size Increase
Message-ID: <COL402-EAS4043863D3AB49C167CB2DCACDDE0@phx.gbl>

An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/78da0fd0/attachment.html>

From raystonn at hotmail.com  Fri May  8 20:51:52 2015
From: raystonn at hotmail.com (Raystonn)
Date: Fri, 8 May 2015 13:51:52 -0700
Subject: [Bitcoin-development] Block Size Increase
Message-ID: <COL402-EAS17EC0834A6CEDDBEEAE5D8CDDE0@phx.gbl>

Replace by fee is what I was referencing.? End-users interpret the old transaction as expired.? Hence the nomenclature.  An alternative is a new feature that operates in the reverse of time lock, expiring a transaction after a specific time.  But time is a bit unreliable in the blockchain

-Raystonn


On 8 May 2015 1:41 pm, Mark Friedenbach <mark at friedenbach.org> wrote:
>
> Transactions don't expire. But if the wallet is online, it can periodically choose to release an already created transaction with a higher fee. This requires replace-by-fee to be sufficiently deployed, however.
>
> On Fri, May 8, 2015 at 1:38 PM, Raystonn . <raystonn at hotmail.com> wrote:
>>
>> I have a proposal for wallets such as yours.? How about creating all transactions with an expiration time starting with a low fee, then replacing with new transactions that have a higher fee as time passes.? Users can pick the fee curve they desire based on the transaction priority they want to advertise to the network.? Users set the priority in the wallet, and the wallet software translates it to a specific fee curve used in the series of expiring transactions.? In this manner, transactions are never left hanging for days, and probably not even for hours.
>>
>> -Raystonn
>>
>> On 8 May 2015 1:17 pm, Aaron Voisine <voisine at gmail.com> wrote:
>>>
>>> As the author of a popular SPV wallet, I wanted to weigh in, in support of the Gavin's 20Mb block proposal.
>>>
>>> The best argument I've heard against raising the limit is that we need fee pressure.? I agree that fee pressure is the right way to economize on scarce resources. Placing hard limits on block size however is an incredibly disruptive way to go about this, and will severely negatively impact users' experience.
>>>
>>> When users pay too low a fee, they should:
>>>
>>> 1) See immediate failure as they do now with fees that fail to propagate.
>>>
>>> 2) If the fee lower than it should be but not terminal, they should see degraded performance, long delays in confirmation, but eventual success. This will encourage them to pay higher fees in future.
>>>
>>> The worst of all worlds would be to have transactions propagate, hang in limbo for days, and then fail. This is the most important scenario to avoid. Increasing the 1Mb block size limit I think is the simplest way to avoid this least desirable scenario for the immediate future.
>>>
>>> We can play around with improved transaction selection for blocks and encourage miners to adopt it to discourage low fees and create fee pressure. These could involve hybrid priority/fee selection so low fee transactions see degraded performance instead of failure. This would be the conservative low risk approach.
>>>
>>> Aaron Voisine
>>> co-founder and CEO
>>> breadwallet.com
>>
>>
>> ------------------------------------------------------------------------------
>> One dashboard for servers and applications across Physical-Virtual-Cloud
>> Widest out-of-the-box monitoring support with 50+ applications
>> Performance metrics, stats and reports that give you Actionable Insights
>> Deep dive visibility with transaction tracing using APM Insight.
>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>

From mark at friedenbach.org  Fri May  8 20:55:30 2015
From: mark at friedenbach.org (Mark Friedenbach)
Date: Fri, 8 May 2015 13:55:30 -0700
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <COL402-EAS17EC0834A6CEDDBEEAE5D8CDDE0@phx.gbl>
References: <COL402-EAS17EC0834A6CEDDBEEAE5D8CDDE0@phx.gbl>
Message-ID: <CAOG=w-sw4f0k0RzuR9DEQeuw-UCKhtQD=uXbS8pvgYAeoVysGg@mail.gmail.com>

The problems with that are larger than time being unreliable. It is no
longer reorg-safe as transactions can expire in the course of a reorg and
any transaction built on the now expired transaction is invalidated.

On Fri, May 8, 2015 at 1:51 PM, Raystonn <raystonn at hotmail.com> wrote:

> Replace by fee is what I was referencing.  End-users interpret the old
> transaction as expired.  Hence the nomenclature.  An alternative is a new
> feature that operates in the reverse of time lock, expiring a transaction
> after a specific time.  But time is a bit unreliable in the blockchain
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/c06d4fe8/attachment.html>

From doug at bitcoinarmory.com  Fri May  8 19:27:26 2015
From: doug at bitcoinarmory.com (Douglas Roark)
Date: Fri, 8 May 2015 15:27:26 -0400
Subject: [Bitcoin-development] Softfork signaling improvements
Message-ID: <554D0E1E.8070905@bitcoinarmory.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

Hello. I've seen Greg make a couple of posts online
(https://bitcointalk.org/index.php?topic=1033396.msg11155302#msg11155302
is one such example) where he has mentioned that Pieter has a new
proposal for allowing multiple softforks to be deployed at the same
time. As discussed in the thread I linked, the idea seems simple
enough. Still, I'm curious if the actual proposal has been posted
anywhere. I spent a few minutes searching the usual suspects (this
mailing list, Reddit, Bitcointalk, IRC logs, BIPs) and can't find
anything.

Thanks.

- ---
Douglas Roark
Senior Developer
Armory Technologies, Inc.
doug at bitcoinarmory.com
PGP key ID: 92ADC0D7
-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.22 (Darwin)
Comment: GPGTools - https://gpgtools.org

iQIcBAEBCgAGBQJVTQ4eAAoJEGybVGGSrcDX8eMQAOQiDA7an+qZBqDfVIwEzY2C
SxOVxswwxAyTtZNM/Nm+8MTq77hF8+3j/C3bUbDW6wCu4QxBYA/uiCGTf44dj6WX
7aiXg1o9C4LfPcuUngcMI0H5ixOUxnbqUdmpNdoIvy4did2dVs9fAmOPEoSVUm72
6dMLGrtlPN0jcLX6pJd12Dy3laKxd0AP72wi6SivH6i8v8rLb940EuBS3hIkuZG0
vnR5MXMIEd0rkWesr8hn6oTs/k8t4zgts7cgIrA7rU3wJq0qaHBa8uASUxwHKDjD
KmDwaigvOGN6XqitqokCUlqjoxvwpimCjb3Uv5Pkxn8+dwue9F/IggRXUSuifJRn
UEZT2F8fwhiluldz3sRaNtLOpCoKfPC+YYv7kvGySgqagtNJFHoFhbeQM0S3yjRn
Ceh1xK9sOjrxw/my0jwpjJkqlhvQtVG15OsNWDzZ+eWa56kghnSgLkFO+T4G6IxB
EUOcAYjJkLbg5ssjgyhvDOvGqft+2e4MNlB01e1ZQr4whQH4TdRkd66A4WDNB+0g
LBqVhAc2C8L3g046mhZmC33SuOSxxm8shlxZvYLHU2HrnUFg9NkkXi1Ub7agMSck
TTkLbMx17AvOXkKH0v1L20kWoWAp9LfRGdD+qnY8svJkaUuVtgDurpcwEk40WwEZ
caYBw+8bdLpKZwqbA1DL
=ayhE
-----END PGP SIGNATURE-----



From mark at friedenbach.org  Fri May  8 20:40:50 2015
From: mark at friedenbach.org (Mark Friedenbach)
Date: Fri, 8 May 2015 13:40:50 -0700
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <COL402-EAS4043863D3AB49C167CB2DCACDDE0@phx.gbl>
References: <COL402-EAS4043863D3AB49C167CB2DCACDDE0@phx.gbl>
Message-ID: <CAOG=w-tZGiiFu0CGqSzsF4FPLRP-wwzPiWSrm+Z+zE1vxpvBBg@mail.gmail.com>

Transactions don't expire. But if the wallet is online, it can periodically
choose to release an already created transaction with a higher fee. This
requires replace-by-fee to be sufficiently deployed, however.

On Fri, May 8, 2015 at 1:38 PM, Raystonn . <raystonn at hotmail.com> wrote:

> I have a proposal for wallets such as yours.  How about creating all
> transactions with an expiration time starting with a low fee, then
> replacing with new transactions that have a higher fee as time passes.
> Users can pick the fee curve they desire based on the transaction priority
> they want to advertise to the network.  Users set the priority in the
> wallet, and the wallet software translates it to a specific fee curve used
> in the series of expiring transactions.  In this manner, transactions are
> never left hanging for days, and probably not even for hours.
>
> -Raystonn
>  On 8 May 2015 1:17 pm, Aaron Voisine <voisine at gmail.com> wrote:
>
> As the author of a popular SPV wallet, I wanted to weigh in, in support of
> the Gavin's 20Mb block proposal.
>
> The best argument I've heard against raising the limit is that we need fee
> pressure.  I agree that fee pressure is the right way to economize on
> scarce resources. Placing hard limits on block size however is an
> incredibly disruptive way to go about this, and will severely negatively
> impact users' experience.
>
> When users pay too low a fee, they should:
>
> 1) See immediate failure as they do now with fees that fail to propagate.
>
> 2) If the fee lower than it should be but not terminal, they should see
> degraded performance, long delays in confirmation, but eventual success.
> This will encourage them to pay higher fees in future.
>
> The worst of all worlds would be to have transactions propagate, hang in
> limbo for days, and then fail. This is the most important scenario to
> avoid. Increasing the 1Mb block size limit I think is the simplest way to
> avoid this least desirable scenario for the immediate future.
>
> We can play around with improved transaction selection for blocks and
> encourage miners to adopt it to discourage low fees and create fee
> pressure. These could involve hybrid priority/fee selection so low fee
> transactions see degraded performance instead of failure. This would be the
> conservative low risk approach.
>
> Aaron Voisine
> co-founder and CEO
> breadwallet.com
>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/a201447f/attachment.html>

From dgomez1092 at gmail.com  Fri May  8 21:04:10 2015
From: dgomez1092 at gmail.com (Damian Gomez)
Date: Fri, 8 May 2015 14:04:10 -0700
Subject: [Bitcoin-development] Block Size Increase (Raystonn)
Message-ID: <CAH+jCTxVe-2wKy8p5tvc8mMApzA_gg3_n-ZRcqiQrZzv+OOx4g@mail.gmail.com>

Hello,

I was reading some of the thread but can't say I read the entire thing.

I think that it is realistic to cinsider a nlock sixe of 20MB for any block
txn to occur. THis is an enormous amount of data (relatively for a netwkrk)
in which the avergage rate of 10tps over 10 miniutes would allow for
fewasible transformation of data at this curent point in time.

Though I do not see what extra hash information would be stored in the
overall ecosystem as we begin to describe what the scripts that are
atacrhed tp the blockchain would carry,

I'd therefore think that for the remainder of this year that it is possible
to have a block chain within 200 - 300 bytes that is more charatereistic of
some feasible attempts at attaching nuanced data in order to keep propliifc
the blockchain but have these identifiers be integral OPSIg of the the
entiore block. THe reasoning behind this has to do with encryption
standards that can be added toe a chain such as th DH algoritnm keys that
would allow for a higher integrity level withinin the system as it is.
Cutrent;y tyh prootocl oomnly controls for the amount of transactions
through if TxnOut script and the publin key coming form teh lcoation of the
proof-of-work. Form this then I think that a rate of higher than then
current standard of 92bytes allows for GPUS ie CUDA to perfirm its standard
operations of  1216 flops   in rde rto mechanize a new personal identity
within the chain that also attaches an encrypted instance of a further
categorical variable that we can prsribved to it.

I think with the current BIP7 prootclol for transactions there is an area
of vulnerability for man-in-the-middle attacks upon request of  bitcin to
any merchant as is. It would contraidct the security of the bitcoin if it
was intereceptefd iand not allowed to reach tthe payment network or if the
hash was reveresed in orfr to change the value it had. Therefore the
current best fit block size today is between 200 - 300 bytws (depending on
how exciteed we get)



Thanks for letting me join the conversation
I welcomes any vhalleneged and will reply with more research as i figure
out what problems are revealed in my current formation of thoughts (sorry
for the errors but i am just trying to move forward ---> THE DELRERT KEY
LITERALLY PREVENTS IT )


_Damian
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/31c1a261/attachment.html>

From raystonn at hotmail.com  Fri May  8 21:01:28 2015
From: raystonn at hotmail.com (Raystonn)
Date: Fri, 8 May 2015 14:01:28 -0700
Subject: [Bitcoin-development] Block Size Increase
Message-ID: <COL402-EAS15476F81D4FB6AE1EAE9795CDDE0@phx.gbl>

An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/9f3d64e1/attachment.html>

From dgomez1092 at gmail.com  Fri May  8 22:11:13 2015
From: dgomez1092 at gmail.com (Damian Gomez)
Date: Fri, 8 May 2015 15:11:13 -0700
Subject: [Bitcoin-development] Bitcoin-development Digest, Vol 48,
	Issue 41
In-Reply-To: <mailman.63969.1431119326.18600.bitcoin-development@lists.sourceforge.net>
References: <mailman.63969.1431119326.18600.bitcoin-development@lists.sourceforge.net>
Message-ID: <CAH+jCTye9QNVV8bv6ZAgEPcrE5K1J-q7gONE_m1x81+-5mpWHA@mail.gmail.com>

Well zombie txns aside,  I expect this to be resolved w/ a client side
implementation using a Merkle-Winternitz OTS in order to prevent the loss
of fee structure theougth the implementation of a this security hash that
eill alloow for a one-wya transaction to conitnue, according to the TESLA
protocol.

We can then tally what is needed to compute tteh number of bit desginated
for teh completion og the client-side signature if discussin the
construcitons of a a DH key (instead of the BIP X509 protocol)





On Fri, May 8, 2015 at 2:08 PM, <
bitcoin-development-request at lists.sourceforge.net> wrote:

> Send Bitcoin-development mailing list submissions to
>         bitcoin-development at lists.sourceforge.net
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> or, via email, send a message with subject or body 'help' to
>         bitcoin-development-request at lists.sourceforge.net
>
> You can reach the person managing the list at
>         bitcoin-development-owner at lists.sourceforge.net
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of Bitcoin-development digest..."
>
> Today's Topics:
>
>    1. Re: Block Size Increase (Mark Friedenbach)
>    2. Softfork signaling improvements (Douglas Roark)
>    3. Re: Block Size Increase (Mark Friedenbach)
>    4. Re: Block Size Increase (Raystonn) (Damian Gomez)
>    5. Re: Block Size Increase (Raystonn)
>
>
> ---------- Forwarded message ----------
> From: Mark Friedenbach <mark at friedenbach.org>
> To: Raystonn <raystonn at hotmail.com>
> Cc: Bitcoin Development <bitcoin-development at lists.sourceforge.net>
> Date: Fri, 8 May 2015 13:55:30 -0700
> Subject: Re: [Bitcoin-development] Block Size Increase
> The problems with that are larger than time being unreliable. It is no
> longer reorg-safe as transactions can expire in the course of a reorg and
> any transaction built on the now expired transaction is invalidated.
>
> On Fri, May 8, 2015 at 1:51 PM, Raystonn <raystonn at hotmail.com> wrote:
>
>> Replace by fee is what I was referencing.  End-users interpret the old
>> transaction as expired.  Hence the nomenclature.  An alternative is a new
>> feature that operates in the reverse of time lock, expiring a transaction
>> after a specific time.  But time is a bit unreliable in the blockchain
>>
>
>
> ---------- Forwarded message ----------
> From: Douglas Roark <doug at bitcoinarmory.com>
> To: Bitcoin Dev <bitcoin-development at lists.sourceforge.net>
> Cc:
> Date: Fri, 8 May 2015 15:27:26 -0400
> Subject: [Bitcoin-development] Softfork signaling improvements
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA512
>
> Hello. I've seen Greg make a couple of posts online
> (https://bitcointalk.org/index.php?topic=1033396.msg11155302#msg11155302
> is one such example) where he has mentioned that Pieter has a new
> proposal for allowing multiple softforks to be deployed at the same
> time. As discussed in the thread I linked, the idea seems simple
> enough. Still, I'm curious if the actual proposal has been posted
> anywhere. I spent a few minutes searching the usual suspects (this
> mailing list, Reddit, Bitcointalk, IRC logs, BIPs) and can't find
> anything.
>
> Thanks.
>
> - ---
> Douglas Roark
> Senior Developer
> Armory Technologies, Inc.
> doug at bitcoinarmory.com
> PGP key ID: 92ADC0D7
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG/MacGPG2 v2.0.22 (Darwin)
> Comment: GPGTools - https://gpgtools.org
>
> iQIcBAEBCgAGBQJVTQ4eAAoJEGybVGGSrcDX8eMQAOQiDA7an+qZBqDfVIwEzY2C
> SxOVxswwxAyTtZNM/Nm+8MTq77hF8+3j/C3bUbDW6wCu4QxBYA/uiCGTf44dj6WX
> 7aiXg1o9C4LfPcuUngcMI0H5ixOUxnbqUdmpNdoIvy4did2dVs9fAmOPEoSVUm72
> 6dMLGrtlPN0jcLX6pJd12Dy3laKxd0AP72wi6SivH6i8v8rLb940EuBS3hIkuZG0
> vnR5MXMIEd0rkWesr8hn6oTs/k8t4zgts7cgIrA7rU3wJq0qaHBa8uASUxwHKDjD
> KmDwaigvOGN6XqitqokCUlqjoxvwpimCjb3Uv5Pkxn8+dwue9F/IggRXUSuifJRn
> UEZT2F8fwhiluldz3sRaNtLOpCoKfPC+YYv7kvGySgqagtNJFHoFhbeQM0S3yjRn
> Ceh1xK9sOjrxw/my0jwpjJkqlhvQtVG15OsNWDzZ+eWa56kghnSgLkFO+T4G6IxB
> EUOcAYjJkLbg5ssjgyhvDOvGqft+2e4MNlB01e1ZQr4whQH4TdRkd66A4WDNB+0g
> LBqVhAc2C8L3g046mhZmC33SuOSxxm8shlxZvYLHU2HrnUFg9NkkXi1Ub7agMSck
> TTkLbMx17AvOXkKH0v1L20kWoWAp9LfRGdD+qnY8svJkaUuVtgDurpcwEk40WwEZ
> caYBw+8bdLpKZwqbA1DL
> =ayhE
> -----END PGP SIGNATURE-----
>
>
>
>
> ---------- Forwarded message ----------
> From: Mark Friedenbach <mark at friedenbach.org>
> To: "Raystonn ." <raystonn at hotmail.com>
> Cc: Bitcoin Development <bitcoin-development at lists.sourceforge.net>
> Date: Fri, 8 May 2015 13:40:50 -0700
> Subject: Re: [Bitcoin-development] Block Size Increase
> Transactions don't expire. But if the wallet is online, it can
> periodically choose to release an already created transaction with a higher
> fee. This requires replace-by-fee to be sufficiently deployed, however.
>
> On Fri, May 8, 2015 at 1:38 PM, Raystonn . <raystonn at hotmail.com> wrote:
>
>> I have a proposal for wallets such as yours.  How about creating all
>> transactions with an expiration time starting with a low fee, then
>> replacing with new transactions that have a higher fee as time passes.
>> Users can pick the fee curve they desire based on the transaction priority
>> they want to advertise to the network.  Users set the priority in the
>> wallet, and the wallet software translates it to a specific fee curve used
>> in the series of expiring transactions.  In this manner, transactions are
>> never left hanging for days, and probably not even for hours.
>>
>> -Raystonn
>>  On 8 May 2015 1:17 pm, Aaron Voisine <voisine at gmail.com> wrote:
>>
>> As the author of a popular SPV wallet, I wanted to weigh in, in support
>> of the Gavin's 20Mb block proposal.
>>
>> The best argument I've heard against raising the limit is that we need
>> fee pressure.  I agree that fee pressure is the right way to economize on
>> scarce resources. Placing hard limits on block size however is an
>> incredibly disruptive way to go about this, and will severely negatively
>> impact users' experience.
>>
>> When users pay too low a fee, they should:
>>
>> 1) See immediate failure as they do now with fees that fail to propagate.
>>
>> 2) If the fee lower than it should be but not terminal, they should see
>> degraded performance, long delays in confirmation, but eventual success.
>> This will encourage them to pay higher fees in future.
>>
>> The worst of all worlds would be to have transactions propagate, hang in
>> limbo for days, and then fail. This is the most important scenario to
>> avoid. Increasing the 1Mb block size limit I think is the simplest way to
>> avoid this least desirable scenario for the immediate future.
>>
>> We can play around with improved transaction selection for blocks and
>> encourage miners to adopt it to discourage low fees and create fee
>> pressure. These could involve hybrid priority/fee selection so low fee
>> transactions see degraded performance instead of failure. This would be the
>> conservative low risk approach.
>>
>> Aaron Voisine
>> co-founder and CEO
>> breadwallet.com
>>
>>
>>
>> ------------------------------------------------------------------------------
>> One dashboard for servers and applications across Physical-Virtual-Cloud
>> Widest out-of-the-box monitoring support with 50+ applications
>> Performance metrics, stats and reports that give you Actionable Insights
>> Deep dive visibility with transaction tracing using APM Insight.
>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>>
>
>
> ---------- Forwarded message ----------
> From: Damian Gomez <dgomez1092 at gmail.com>
> To: bitcoin-development at lists.sourceforge.net
> Cc:
> Date: Fri, 8 May 2015 14:04:10 -0700
> Subject: Re: [Bitcoin-development] Block Size Increase (Raystonn)
> Hello,
>
> I was reading some of the thread but can't say I read the entire thing.
>
> I think that it is realistic to cinsider a nlock sixe of 20MB for any
> block txn to occur. THis is an enormous amount of data (relatively for a
> netwkrk) in which the avergage rate of 10tps over 10 miniutes would allow
> for fewasible transformation of data at this curent point in time.
>
> Though I do not see what extra hash information would be stored in the
> overall ecosystem as we begin to describe what the scripts that are
> atacrhed tp the blockchain would carry,
>
> I'd therefore think that for the remainder of this year that it is
> possible to have a block chain within 200 - 300 bytes that is more
> charatereistic of some feasible attempts at attaching nuanced data in order
> to keep propliifc the blockchain but have these identifiers be integral
> OPSIg of the the entiore block. THe reasoning behind this has to do with
> encryption standards that can be added toe a chain such as th DH algoritnm
> keys that would allow for a higher integrity level withinin the system as
> it is. Cutrent;y tyh prootocl oomnly controls for the amount of
> transactions through if TxnOut script and the publin key coming form teh
> lcoation of the proof-of-work. Form this then I think that a rate of higher
> than then current standard of 92bytes allows for GPUS ie CUDA to perfirm
> its standard operations of  1216 flops   in rde rto mechanize a new
> personal identity within the chain that also attaches an encrypted instance
> of a further categorical variable that we can prsribved to it.
>
> I think with the current BIP7 prootclol for transactions there is an area
> of vulnerability for man-in-the-middle attacks upon request of  bitcin to
> any merchant as is. It would contraidct the security of the bitcoin if it
> was intereceptefd iand not allowed to reach tthe payment network or if the
> hash was reveresed in orfr to change the value it had. Therefore the
> current best fit block size today is between 200 - 300 bytws (depending on
> how exciteed we get)
>
>
>
> Thanks for letting me join the conversation
> I welcomes any vhalleneged and will reply with more research as i figure
> out what problems are revealed in my current formation of thoughts (sorry
> for the errors but i am just trying to move forward ---> THE DELRERT KEY
> LITERALLY PREVENTS IT )
>
>
> _Damian
>
>
> ---------- Forwarded message ----------
> From: Raystonn <raystonn at hotmail.com>
> To: Mark Friedenbach <mark at friedenbach.org>
> Cc: Bitcoin Development <bitcoin-development at lists.sourceforge.net>
> Date: Fri, 8 May 2015 14:01:28 -0700
> Subject: Re: [Bitcoin-development] Block Size Increase
>
> Replace by fee is the better approach.  It will ultimately replace zombie
> transactions (due to insufficient fee) with potentially much higher fees as
> the feature takes hold in wallets throughout the network, and fee
> competition increases.  However, this does not fix the problem of low tps.
> In fact, as blocks fill it could make the problem worse.  This feature
> means more transactions after all.  So I would expect huge fee spikes, or a
> return to zombie transactions if fee caps are implemented by wallets.
>
> -Raystonn
>  On 8 May 2015 1:55 pm, Mark Friedenbach <mark at friedenbach.org> wrote:
>
> The problems with that are larger than time being unreliable. It is no
> longer reorg-safe as transactions can expire in the course of a reorg and
> any transaction built on the now expired transaction is invalidated.
>
> On Fri, May 8, 2015 at 1:51 PM, Raystonn <raystonn at hotmail.com> wrote:
>
> Replace by fee is what I was referencing.  End-users interpret the old
> transaction as expired.  Hence the nomenclature.  An alternative is a new
> feature that operates in the reverse of time lock, expiring a transaction
> after a specific time.  But time is a bit unreliable in the blockchain
>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/dbf018a4/attachment.html>

From dgomez1092 at gmail.com  Fri May  8 22:12:56 2015
From: dgomez1092 at gmail.com (Damian Gomez)
Date: Fri, 8 May 2015 15:12:56 -0700
Subject: [Bitcoin-development] Bitcoin-development Digest, Vol 48,
	Issue 41
In-Reply-To: <CAH+jCTye9QNVV8bv6ZAgEPcrE5K1J-q7gONE_m1x81+-5mpWHA@mail.gmail.com>
References: <mailman.63969.1431119326.18600.bitcoin-development@lists.sourceforge.net>
	<CAH+jCTye9QNVV8bv6ZAgEPcrE5K1J-q7gONE_m1x81+-5mpWHA@mail.gmail.com>
Message-ID: <CAH+jCTwxjfEVog4JR+8kCvbBPoT50f322NV3T+8Bz-sTnK-yXQ@mail.gmail.com>

let me continue my conversation:

as the development of this transactions would be indiscated

as a ByteArray of


On Fri, May 8, 2015 at 3:11 PM, Damian Gomez <dgomez1092 at gmail.com> wrote:

>
> Well zombie txns aside,  I expect this to be resolved w/ a client side
> implementation using a Merkle-Winternitz OTS in order to prevent the loss
> of fee structure theougth the implementation of a this security hash that
> eill alloow for a one-wya transaction to conitnue, according to the TESLA
> protocol.
>
> We can then tally what is needed to compute tteh number of bit desginated
> for teh completion og the client-side signature if discussin the
> construcitons of a a DH key (instead of the BIP X509 protocol)
>
>
>
>
>
> On Fri, May 8, 2015 at 2:08 PM, <
> bitcoin-development-request at lists.sourceforge.net> wrote:
>
>> Send Bitcoin-development mailing list submissions to
>>         bitcoin-development at lists.sourceforge.net
>>
>> To subscribe or unsubscribe via the World Wide Web, visit
>>         https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>> or, via email, send a message with subject or body 'help' to
>>         bitcoin-development-request at lists.sourceforge.net
>>
>> You can reach the person managing the list at
>>         bitcoin-development-owner at lists.sourceforge.net
>>
>> When replying, please edit your Subject line so it is more specific
>> than "Re: Contents of Bitcoin-development digest..."
>>
>> Today's Topics:
>>
>>    1. Re: Block Size Increase (Mark Friedenbach)
>>    2. Softfork signaling improvements (Douglas Roark)
>>    3. Re: Block Size Increase (Mark Friedenbach)
>>    4. Re: Block Size Increase (Raystonn) (Damian Gomez)
>>    5. Re: Block Size Increase (Raystonn)
>>
>>
>> ---------- Forwarded message ----------
>> From: Mark Friedenbach <mark at friedenbach.org>
>> To: Raystonn <raystonn at hotmail.com>
>> Cc: Bitcoin Development <bitcoin-development at lists.sourceforge.net>
>> Date: Fri, 8 May 2015 13:55:30 -0700
>> Subject: Re: [Bitcoin-development] Block Size Increase
>> The problems with that are larger than time being unreliable. It is no
>> longer reorg-safe as transactions can expire in the course of a reorg and
>> any transaction built on the now expired transaction is invalidated.
>>
>> On Fri, May 8, 2015 at 1:51 PM, Raystonn <raystonn at hotmail.com> wrote:
>>
>>> Replace by fee is what I was referencing.  End-users interpret the old
>>> transaction as expired.  Hence the nomenclature.  An alternative is a new
>>> feature that operates in the reverse of time lock, expiring a transaction
>>> after a specific time.  But time is a bit unreliable in the blockchain
>>>
>>
>>
>> ---------- Forwarded message ----------
>> From: Douglas Roark <doug at bitcoinarmory.com>
>> To: Bitcoin Dev <bitcoin-development at lists.sourceforge.net>
>> Cc:
>> Date: Fri, 8 May 2015 15:27:26 -0400
>> Subject: [Bitcoin-development] Softfork signaling improvements
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA512
>>
>> Hello. I've seen Greg make a couple of posts online
>> (https://bitcointalk.org/index.php?topic=1033396.msg11155302#msg11155302
>> is one such example) where he has mentioned that Pieter has a new
>> proposal for allowing multiple softforks to be deployed at the same
>> time. As discussed in the thread I linked, the idea seems simple
>> enough. Still, I'm curious if the actual proposal has been posted
>> anywhere. I spent a few minutes searching the usual suspects (this
>> mailing list, Reddit, Bitcointalk, IRC logs, BIPs) and can't find
>> anything.
>>
>> Thanks.
>>
>> - ---
>> Douglas Roark
>> Senior Developer
>> Armory Technologies, Inc.
>> doug at bitcoinarmory.com
>> PGP key ID: 92ADC0D7
>> -----BEGIN PGP SIGNATURE-----
>> Version: GnuPG/MacGPG2 v2.0.22 (Darwin)
>> Comment: GPGTools - https://gpgtools.org
>>
>> iQIcBAEBCgAGBQJVTQ4eAAoJEGybVGGSrcDX8eMQAOQiDA7an+qZBqDfVIwEzY2C
>> SxOVxswwxAyTtZNM/Nm+8MTq77hF8+3j/C3bUbDW6wCu4QxBYA/uiCGTf44dj6WX
>> 7aiXg1o9C4LfPcuUngcMI0H5ixOUxnbqUdmpNdoIvy4did2dVs9fAmOPEoSVUm72
>> 6dMLGrtlPN0jcLX6pJd12Dy3laKxd0AP72wi6SivH6i8v8rLb940EuBS3hIkuZG0
>> vnR5MXMIEd0rkWesr8hn6oTs/k8t4zgts7cgIrA7rU3wJq0qaHBa8uASUxwHKDjD
>> KmDwaigvOGN6XqitqokCUlqjoxvwpimCjb3Uv5Pkxn8+dwue9F/IggRXUSuifJRn
>> UEZT2F8fwhiluldz3sRaNtLOpCoKfPC+YYv7kvGySgqagtNJFHoFhbeQM0S3yjRn
>> Ceh1xK9sOjrxw/my0jwpjJkqlhvQtVG15OsNWDzZ+eWa56kghnSgLkFO+T4G6IxB
>> EUOcAYjJkLbg5ssjgyhvDOvGqft+2e4MNlB01e1ZQr4whQH4TdRkd66A4WDNB+0g
>> LBqVhAc2C8L3g046mhZmC33SuOSxxm8shlxZvYLHU2HrnUFg9NkkXi1Ub7agMSck
>> TTkLbMx17AvOXkKH0v1L20kWoWAp9LfRGdD+qnY8svJkaUuVtgDurpcwEk40WwEZ
>> caYBw+8bdLpKZwqbA1DL
>> =ayhE
>> -----END PGP SIGNATURE-----
>>
>>
>>
>>
>> ---------- Forwarded message ----------
>> From: Mark Friedenbach <mark at friedenbach.org>
>> To: "Raystonn ." <raystonn at hotmail.com>
>> Cc: Bitcoin Development <bitcoin-development at lists.sourceforge.net>
>> Date: Fri, 8 May 2015 13:40:50 -0700
>> Subject: Re: [Bitcoin-development] Block Size Increase
>> Transactions don't expire. But if the wallet is online, it can
>> periodically choose to release an already created transaction with a higher
>> fee. This requires replace-by-fee to be sufficiently deployed, however.
>>
>> On Fri, May 8, 2015 at 1:38 PM, Raystonn . <raystonn at hotmail.com> wrote:
>>
>>> I have a proposal for wallets such as yours.  How about creating all
>>> transactions with an expiration time starting with a low fee, then
>>> replacing with new transactions that have a higher fee as time passes.
>>> Users can pick the fee curve they desire based on the transaction priority
>>> they want to advertise to the network.  Users set the priority in the
>>> wallet, and the wallet software translates it to a specific fee curve used
>>> in the series of expiring transactions.  In this manner, transactions are
>>> never left hanging for days, and probably not even for hours.
>>>
>>> -Raystonn
>>>  On 8 May 2015 1:17 pm, Aaron Voisine <voisine at gmail.com> wrote:
>>>
>>> As the author of a popular SPV wallet, I wanted to weigh in, in support
>>> of the Gavin's 20Mb block proposal.
>>>
>>> The best argument I've heard against raising the limit is that we need
>>> fee pressure.  I agree that fee pressure is the right way to economize on
>>> scarce resources. Placing hard limits on block size however is an
>>> incredibly disruptive way to go about this, and will severely negatively
>>> impact users' experience.
>>>
>>> When users pay too low a fee, they should:
>>>
>>> 1) See immediate failure as they do now with fees that fail to propagate.
>>>
>>> 2) If the fee lower than it should be but not terminal, they should see
>>> degraded performance, long delays in confirmation, but eventual success.
>>> This will encourage them to pay higher fees in future.
>>>
>>> The worst of all worlds would be to have transactions propagate, hang in
>>> limbo for days, and then fail. This is the most important scenario to
>>> avoid. Increasing the 1Mb block size limit I think is the simplest way to
>>> avoid this least desirable scenario for the immediate future.
>>>
>>> We can play around with improved transaction selection for blocks and
>>> encourage miners to adopt it to discourage low fees and create fee
>>> pressure. These could involve hybrid priority/fee selection so low fee
>>> transactions see degraded performance instead of failure. This would be the
>>> conservative low risk approach.
>>>
>>> Aaron Voisine
>>> co-founder and CEO
>>> breadwallet.com
>>>
>>>
>>>
>>> ------------------------------------------------------------------------------
>>> One dashboard for servers and applications across Physical-Virtual-Cloud
>>> Widest out-of-the-box monitoring support with 50+ applications
>>> Performance metrics, stats and reports that give you Actionable Insights
>>> Deep dive visibility with transaction tracing using APM Insight.
>>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>>> _______________________________________________
>>> Bitcoin-development mailing list
>>> Bitcoin-development at lists.sourceforge.net
>>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>>
>>>
>>
>>
>> ---------- Forwarded message ----------
>> From: Damian Gomez <dgomez1092 at gmail.com>
>> To: bitcoin-development at lists.sourceforge.net
>> Cc:
>> Date: Fri, 8 May 2015 14:04:10 -0700
>> Subject: Re: [Bitcoin-development] Block Size Increase (Raystonn)
>> Hello,
>>
>> I was reading some of the thread but can't say I read the entire thing.
>>
>> I think that it is realistic to cinsider a nlock sixe of 20MB for any
>> block txn to occur. THis is an enormous amount of data (relatively for a
>> netwkrk) in which the avergage rate of 10tps over 10 miniutes would allow
>> for fewasible transformation of data at this curent point in time.
>>
>> Though I do not see what extra hash information would be stored in the
>> overall ecosystem as we begin to describe what the scripts that are
>> atacrhed tp the blockchain would carry,
>>
>> I'd therefore think that for the remainder of this year that it is
>> possible to have a block chain within 200 - 300 bytes that is more
>> charatereistic of some feasible attempts at attaching nuanced data in order
>> to keep propliifc the blockchain but have these identifiers be integral
>> OPSIg of the the entiore block. THe reasoning behind this has to do with
>> encryption standards that can be added toe a chain such as th DH algoritnm
>> keys that would allow for a higher integrity level withinin the system as
>> it is. Cutrent;y tyh prootocl oomnly controls for the amount of
>> transactions through if TxnOut script and the publin key coming form teh
>> lcoation of the proof-of-work. Form this then I think that a rate of higher
>> than then current standard of 92bytes allows for GPUS ie CUDA to perfirm
>> its standard operations of  1216 flops   in rde rto mechanize a new
>> personal identity within the chain that also attaches an encrypted instance
>> of a further categorical variable that we can prsribved to it.
>>
>> I think with the current BIP7 prootclol for transactions there is an area
>> of vulnerability for man-in-the-middle attacks upon request of  bitcin to
>> any merchant as is. It would contraidct the security of the bitcoin if it
>> was intereceptefd iand not allowed to reach tthe payment network or if the
>> hash was reveresed in orfr to change the value it had. Therefore the
>> current best fit block size today is between 200 - 300 bytws (depending on
>> how exciteed we get)
>>
>>
>>
>> Thanks for letting me join the conversation
>> I welcomes any vhalleneged and will reply with more research as i figure
>> out what problems are revealed in my current formation of thoughts (sorry
>> for the errors but i am just trying to move forward ---> THE DELRERT KEY
>> LITERALLY PREVENTS IT )
>>
>>
>> _Damian
>>
>>
>> ---------- Forwarded message ----------
>> From: Raystonn <raystonn at hotmail.com>
>> To: Mark Friedenbach <mark at friedenbach.org>
>> Cc: Bitcoin Development <bitcoin-development at lists.sourceforge.net>
>> Date: Fri, 8 May 2015 14:01:28 -0700
>> Subject: Re: [Bitcoin-development] Block Size Increase
>>
>> Replace by fee is the better approach.  It will ultimately replace zombie
>> transactions (due to insufficient fee) with potentially much higher fees as
>> the feature takes hold in wallets throughout the network, and fee
>> competition increases.  However, this does not fix the problem of low tps.
>> In fact, as blocks fill it could make the problem worse.  This feature
>> means more transactions after all.  So I would expect huge fee spikes, or a
>> return to zombie transactions if fee caps are implemented by wallets.
>>
>> -Raystonn
>>  On 8 May 2015 1:55 pm, Mark Friedenbach <mark at friedenbach.org> wrote:
>>
>> The problems with that are larger than time being unreliable. It is no
>> longer reorg-safe as transactions can expire in the course of a reorg and
>> any transaction built on the now expired transaction is invalidated.
>>
>> On Fri, May 8, 2015 at 1:51 PM, Raystonn <raystonn at hotmail.com> wrote:
>>
>> Replace by fee is what I was referencing.  End-users interpret the old
>> transaction as expired.  Hence the nomenclature.  An alternative is a new
>> feature that operates in the reverse of time lock, expiring a transaction
>> after a specific time.  But time is a bit unreliable in the blockchain
>>
>>
>>
>> ------------------------------------------------------------------------------
>> One dashboard for servers and applications across Physical-Virtual-Cloud
>> Widest out-of-the-box monitoring support with 50+ applications
>> Performance metrics, stats and reports that give you Actionable Insights
>> Deep dive visibility with transaction tracing using APM Insight.
>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/55d9f645/attachment.html>

From dgomez1092 at gmail.com  Fri May  8 22:13:21 2015
From: dgomez1092 at gmail.com (Damian Gomez)
Date: Fri, 8 May 2015 15:13:21 -0700
Subject: [Bitcoin-development] Bitcoin-development Digest, Vol 48,
	Issue 41
In-Reply-To: <CAH+jCTwxjfEVog4JR+8kCvbBPoT50f322NV3T+8Bz-sTnK-yXQ@mail.gmail.com>
References: <mailman.63969.1431119326.18600.bitcoin-development@lists.sourceforge.net>
	<CAH+jCTye9QNVV8bv6ZAgEPcrE5K1J-q7gONE_m1x81+-5mpWHA@mail.gmail.com>
	<CAH+jCTwxjfEVog4JR+8kCvbBPoT50f322NV3T+8Bz-sTnK-yXQ@mail.gmail.com>
Message-ID: <CAH+jCTxYnT+oOmxXRF-dA8F02wVMZ-en2HW1cs2+Kn290j6T3Q@mail.gmail.com>

On Fri, May 8, 2015 at 3:12 PM, Damian Gomez <dgomez1092 at gmail.com> wrote:

> let me continue my conversation:
>
> as the development of this transactions would be indiscated
>
> as a ByteArray of
>
>
> On Fri, May 8, 2015 at 3:11 PM, Damian Gomez <dgomez1092 at gmail.com> wrote:
>
>>
>> Well zombie txns aside,  I expect this to be resolved w/ a client side
>> implementation using a Merkle-Winternitz OTS in order to prevent the loss
>> of fee structure theougth the implementation of a this security hash that
>> eill alloow for a one-wya transaction to conitnue, according to the TESLA
>> protocol.
>>
>> We can then tally what is needed to compute tteh number of bit desginated
>> for teh completion og the client-side signature if discussin the
>> construcitons of a a DH key (instead of the BIP X509 protocol)
>>
>>
>>
>>
>>
>> On Fri, May 8, 2015 at 2:08 PM, <
>> bitcoin-development-request at lists.sourceforge.net> wrote:
>>
>>> Send Bitcoin-development mailing list submissions to
>>>         bitcoin-development at lists.sourceforge.net
>>>
>>> To subscribe or unsubscribe via the World Wide Web, visit
>>>         https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>> or, via email, send a message with subject or body 'help' to
>>>         bitcoin-development-request at lists.sourceforge.net
>>>
>>> You can reach the person managing the list at
>>>         bitcoin-development-owner at lists.sourceforge.net
>>>
>>> When replying, please edit your Subject line so it is more specific
>>> than "Re: Contents of Bitcoin-development digest..."
>>>
>>> Today's Topics:
>>>
>>>    1. Re: Block Size Increase (Mark Friedenbach)
>>>    2. Softfork signaling improvements (Douglas Roark)
>>>    3. Re: Block Size Increase (Mark Friedenbach)
>>>    4. Re: Block Size Increase (Raystonn) (Damian Gomez)
>>>    5. Re: Block Size Increase (Raystonn)
>>>
>>>
>>> ---------- Forwarded message ----------
>>> From: Mark Friedenbach <mark at friedenbach.org>
>>> To: Raystonn <raystonn at hotmail.com>
>>> Cc: Bitcoin Development <bitcoin-development at lists.sourceforge.net>
>>> Date: Fri, 8 May 2015 13:55:30 -0700
>>> Subject: Re: [Bitcoin-development] Block Size Increase
>>> The problems with that are larger than time being unreliable. It is no
>>> longer reorg-safe as transactions can expire in the course of a reorg and
>>> any transaction built on the now expired transaction is invalidated.
>>>
>>> On Fri, May 8, 2015 at 1:51 PM, Raystonn <raystonn at hotmail.com> wrote:
>>>
>>>> Replace by fee is what I was referencing.  End-users interpret the old
>>>> transaction as expired.  Hence the nomenclature.  An alternative is a new
>>>> feature that operates in the reverse of time lock, expiring a transaction
>>>> after a specific time.  But time is a bit unreliable in the blockchain
>>>>
>>>
>>>
>>> ---------- Forwarded message ----------
>>> From: Douglas Roark <doug at bitcoinarmory.com>
>>> To: Bitcoin Dev <bitcoin-development at lists.sourceforge.net>
>>> Cc:
>>> Date: Fri, 8 May 2015 15:27:26 -0400
>>> Subject: [Bitcoin-development] Softfork signaling improvements
>>> -----BEGIN PGP SIGNED MESSAGE-----
>>> Hash: SHA512
>>>
>>> Hello. I've seen Greg make a couple of posts online
>>> (https://bitcointalk.org/index.php?topic=1033396.msg11155302#msg11155302
>>> is one such example) where he has mentioned that Pieter has a new
>>> proposal for allowing multiple softforks to be deployed at the same
>>> time. As discussed in the thread I linked, the idea seems simple
>>> enough. Still, I'm curious if the actual proposal has been posted
>>> anywhere. I spent a few minutes searching the usual suspects (this
>>> mailing list, Reddit, Bitcointalk, IRC logs, BIPs) and can't find
>>> anything.
>>>
>>> Thanks.
>>>
>>> - ---
>>> Douglas Roark
>>> Senior Developer
>>> Armory Technologies, Inc.
>>> doug at bitcoinarmory.com
>>> PGP key ID: 92ADC0D7
>>> -----BEGIN PGP SIGNATURE-----
>>> Version: GnuPG/MacGPG2 v2.0.22 (Darwin)
>>> Comment: GPGTools - https://gpgtools.org
>>>
>>> iQIcBAEBCgAGBQJVTQ4eAAoJEGybVGGSrcDX8eMQAOQiDA7an+qZBqDfVIwEzY2C
>>> SxOVxswwxAyTtZNM/Nm+8MTq77hF8+3j/C3bUbDW6wCu4QxBYA/uiCGTf44dj6WX
>>> 7aiXg1o9C4LfPcuUngcMI0H5ixOUxnbqUdmpNdoIvy4did2dVs9fAmOPEoSVUm72
>>> 6dMLGrtlPN0jcLX6pJd12Dy3laKxd0AP72wi6SivH6i8v8rLb940EuBS3hIkuZG0
>>> vnR5MXMIEd0rkWesr8hn6oTs/k8t4zgts7cgIrA7rU3wJq0qaHBa8uASUxwHKDjD
>>> KmDwaigvOGN6XqitqokCUlqjoxvwpimCjb3Uv5Pkxn8+dwue9F/IggRXUSuifJRn
>>> UEZT2F8fwhiluldz3sRaNtLOpCoKfPC+YYv7kvGySgqagtNJFHoFhbeQM0S3yjRn
>>> Ceh1xK9sOjrxw/my0jwpjJkqlhvQtVG15OsNWDzZ+eWa56kghnSgLkFO+T4G6IxB
>>> EUOcAYjJkLbg5ssjgyhvDOvGqft+2e4MNlB01e1ZQr4whQH4TdRkd66A4WDNB+0g
>>> LBqVhAc2C8L3g046mhZmC33SuOSxxm8shlxZvYLHU2HrnUFg9NkkXi1Ub7agMSck
>>> TTkLbMx17AvOXkKH0v1L20kWoWAp9LfRGdD+qnY8svJkaUuVtgDurpcwEk40WwEZ
>>> caYBw+8bdLpKZwqbA1DL
>>> =ayhE
>>> -----END PGP SIGNATURE-----
>>>
>>>
>>>
>>>
>>> ---------- Forwarded message ----------
>>> From: Mark Friedenbach <mark at friedenbach.org>
>>> To: "Raystonn ." <raystonn at hotmail.com>
>>> Cc: Bitcoin Development <bitcoin-development at lists.sourceforge.net>
>>> Date: Fri, 8 May 2015 13:40:50 -0700
>>> Subject: Re: [Bitcoin-development] Block Size Increase
>>> Transactions don't expire. But if the wallet is online, it can
>>> periodically choose to release an already created transaction with a higher
>>> fee. This requires replace-by-fee to be sufficiently deployed, however.
>>>
>>> On Fri, May 8, 2015 at 1:38 PM, Raystonn . <raystonn at hotmail.com> wrote:
>>>
>>>> I have a proposal for wallets such as yours.  How about creating all
>>>> transactions with an expiration time starting with a low fee, then
>>>> replacing with new transactions that have a higher fee as time passes.
>>>> Users can pick the fee curve they desire based on the transaction priority
>>>> they want to advertise to the network.  Users set the priority in the
>>>> wallet, and the wallet software translates it to a specific fee curve used
>>>> in the series of expiring transactions.  In this manner, transactions are
>>>> never left hanging for days, and probably not even for hours.
>>>>
>>>> -Raystonn
>>>>  On 8 May 2015 1:17 pm, Aaron Voisine <voisine at gmail.com> wrote:
>>>>
>>>> As the author of a popular SPV wallet, I wanted to weigh in, in support
>>>> of the Gavin's 20Mb block proposal.
>>>>
>>>> The best argument I've heard against raising the limit is that we need
>>>> fee pressure.  I agree that fee pressure is the right way to economize on
>>>> scarce resources. Placing hard limits on block size however is an
>>>> incredibly disruptive way to go about this, and will severely negatively
>>>> impact users' experience.
>>>>
>>>> When users pay too low a fee, they should:
>>>>
>>>> 1) See immediate failure as they do now with fees that fail to
>>>> propagate.
>>>>
>>>> 2) If the fee lower than it should be but not terminal, they should see
>>>> degraded performance, long delays in confirmation, but eventual success.
>>>> This will encourage them to pay higher fees in future.
>>>>
>>>> The worst of all worlds would be to have transactions propagate, hang
>>>> in limbo for days, and then fail. This is the most important scenario to
>>>> avoid. Increasing the 1Mb block size limit I think is the simplest way to
>>>> avoid this least desirable scenario for the immediate future.
>>>>
>>>> We can play around with improved transaction selection for blocks and
>>>> encourage miners to adopt it to discourage low fees and create fee
>>>> pressure. These could involve hybrid priority/fee selection so low fee
>>>> transactions see degraded performance instead of failure. This would be the
>>>> conservative low risk approach.
>>>>
>>>> Aaron Voisine
>>>> co-founder and CEO
>>>> breadwallet.com
>>>>
>>>>
>>>>
>>>> ------------------------------------------------------------------------------
>>>> One dashboard for servers and applications across Physical-Virtual-Cloud
>>>> Widest out-of-the-box monitoring support with 50+ applications
>>>> Performance metrics, stats and reports that give you Actionable Insights
>>>> Deep dive visibility with transaction tracing using APM Insight.
>>>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>>>> _______________________________________________
>>>> Bitcoin-development mailing list
>>>> Bitcoin-development at lists.sourceforge.net
>>>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>>>
>>>>
>>>
>>>
>>> ---------- Forwarded message ----------
>>> From: Damian Gomez <dgomez1092 at gmail.com>
>>> To: bitcoin-development at lists.sourceforge.net
>>> Cc:
>>> Date: Fri, 8 May 2015 14:04:10 -0700
>>> Subject: Re: [Bitcoin-development] Block Size Increase (Raystonn)
>>> Hello,
>>>
>>> I was reading some of the thread but can't say I read the entire thing.
>>>
>>> I think that it is realistic to cinsider a nlock sixe of 20MB for any
>>> block txn to occur. THis is an enormous amount of data (relatively for a
>>> netwkrk) in which the avergage rate of 10tps over 10 miniutes would allow
>>> for fewasible transformation of data at this curent point in time.
>>>
>>> Though I do not see what extra hash information would be stored in the
>>> overall ecosystem as we begin to describe what the scripts that are
>>> atacrhed tp the blockchain would carry,
>>>
>>> I'd therefore think that for the remainder of this year that it is
>>> possible to have a block chain within 200 - 300 bytes that is more
>>> charatereistic of some feasible attempts at attaching nuanced data in order
>>> to keep propliifc the blockchain but have these identifiers be integral
>>> OPSIg of the the entiore block. THe reasoning behind this has to do with
>>> encryption standards that can be added toe a chain such as th DH algoritnm
>>> keys that would allow for a higher integrity level withinin the system as
>>> it is. Cutrent;y tyh prootocl oomnly controls for the amount of
>>> transactions through if TxnOut script and the publin key coming form teh
>>> lcoation of the proof-of-work. Form this then I think that a rate of higher
>>> than then current standard of 92bytes allows for GPUS ie CUDA to perfirm
>>> its standard operations of  1216 flops   in rde rto mechanize a new
>>> personal identity within the chain that also attaches an encrypted instance
>>> of a further categorical variable that we can prsribved to it.
>>>
>>> I think with the current BIP7 prootclol for transactions there is an
>>> area of vulnerability for man-in-the-middle attacks upon request of  bitcin
>>> to any merchant as is. It would contraidct the security of the bitcoin if
>>> it was intereceptefd iand not allowed to reach tthe payment network or if
>>> the hash was reveresed in orfr to change the value it had. Therefore the
>>> current best fit block size today is between 200 - 300 bytws (depending on
>>> how exciteed we get)
>>>
>>>
>>>
>>> Thanks for letting me join the conversation
>>> I welcomes any vhalleneged and will reply with more research as i figure
>>> out what problems are revealed in my current formation of thoughts (sorry
>>> for the errors but i am just trying to move forward ---> THE DELRERT KEY
>>> LITERALLY PREVENTS IT )
>>>
>>>
>>> _Damian
>>>
>>>
>>> ---------- Forwarded message ----------
>>> From: Raystonn <raystonn at hotmail.com>
>>> To: Mark Friedenbach <mark at friedenbach.org>
>>> Cc: Bitcoin Development <bitcoin-development at lists.sourceforge.net>
>>> Date: Fri, 8 May 2015 14:01:28 -0700
>>> Subject: Re: [Bitcoin-development] Block Size Increase
>>>
>>> Replace by fee is the better approach.  It will ultimately replace
>>> zombie transactions (due to insufficient fee) with potentially much higher
>>> fees as the feature takes hold in wallets throughout the network, and fee
>>> competition increases.  However, this does not fix the problem of low tps.
>>> In fact, as blocks fill it could make the problem worse.  This feature
>>> means more transactions after all.  So I would expect huge fee spikes, or a
>>> return to zombie transactions if fee caps are implemented by wallets.
>>>
>>> -Raystonn
>>>  On 8 May 2015 1:55 pm, Mark Friedenbach <mark at friedenbach.org> wrote:
>>>
>>> The problems with that are larger than time being unreliable. It is no
>>> longer reorg-safe as transactions can expire in the course of a reorg and
>>> any transaction built on the now expired transaction is invalidated.
>>>
>>> On Fri, May 8, 2015 at 1:51 PM, Raystonn <raystonn at hotmail.com> wrote:
>>>
>>> Replace by fee is what I was referencing.  End-users interpret the old
>>> transaction as expired.  Hence the nomenclature.  An alternative is a new
>>> feature that operates in the reverse of time lock, expiring a transaction
>>> after a specific time.  But time is a bit unreliable in the blockchain
>>>
>>>
>>>
>>> ------------------------------------------------------------------------------
>>> One dashboard for servers and applications across Physical-Virtual-Cloud
>>> Widest out-of-the-box monitoring support with 50+ applications
>>> Performance metrics, stats and reports that give you Actionable Insights
>>> Deep dive visibility with transaction tracing using APM Insight.
>>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>>> _______________________________________________
>>> Bitcoin-development mailing list
>>> Bitcoin-development at lists.sourceforge.net
>>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>>
>>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/2821b7a4/attachment.html>

From raystonn at hotmail.com  Fri May  8 22:19:03 2015
From: raystonn at hotmail.com (Raystonn)
Date: Fri, 8 May 2015 15:19:03 -0700
Subject: [Bitcoin-development] Bitcoin-development Digest, Vol 48,
 Issue 41
Message-ID: <COL402-EAS112CA66997239E4EB0102B0CDDE0@phx.gbl>

An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/b010c625/attachment.html>

From joel.kaartinen at gmail.com  Fri May  8 22:36:56 2015
From: joel.kaartinen at gmail.com (Joel Joonatan Kaartinen)
Date: Sat, 9 May 2015 01:36:56 +0300
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <20150508165144.GC27417@savin.petertodd.org>
References: <16096345.A1MpJQQkRW@crushinator>
	<CAP63atbdFSw0rDeuwgtjsDYsXnKSHNN9=zedzip2MsZ0hSY59w@mail.gmail.com>
	<CAGKSKfW7fJB6n3B-OoyXOep7hAQqWGGDTiZCkpJ7vXxWRFgveA@mail.gmail.com>
	<20150508165144.GC27417@savin.petertodd.org>
Message-ID: <CAGKSKfVf6h6icETjfg1joWneiTYob0CTxLDQK-7Pob3+dh_nKQ@mail.gmail.com>

such a contract is a possibility, but why would big owners give an
exclusive right to such pools? It seems to me it'd make sense to offer
those for any miner as long as the get paid a little for it. Especially
when it's as simple as offering an incomplete transaction with the
appropriate SIGHASH flags.

a part of the reason I like this idea is because it will allow stakeholders
a degree of influence on how large the fees are. At least from the surface,
it looks like incentives are pretty well matched. They have an incentive to
not let the fees drop too low so the network continues to be usable and
they also have an incentive to not raise them too high because it'll push
users into using other systems. Also, there'll be competition between
stakeholders, which should keep the fees reasonable.

I think this would at least be preferable to the "let the miner decide"
model.

- Joel

On Fri, May 8, 2015 at 7:51 PM, Peter Todd <pete at petertodd.org> wrote:

> On Fri, May 08, 2015 at 03:32:00PM +0300, Joel Joonatan Kaartinen wrote:
> > Matt,
> >
> > It seems you missed my suggestion about basing the maximum block size on
> > the bitcoin days destroyed in transactions that are included in the
> block.
> > I think it has potential for both scaling as well as keeping up a
> constant
> > fee pressure. If tuned properly, it should both stop spamming and
> increase
> > block size maximum when there are a lot of real transactions waiting for
> > inclusion.
>
> The problem with gating block creation on Bitcoin days destroyed is
> there's a strong potential of giving big mining pools an huge advantage,
> because they can contract with large Bitcoin owners and buy dummy
> transactions with large numbers of Bitcoin days destroyed on demand
> whenever they need more days-destroyed to create larger blocks.
> Similarly, with appropriate SIGHASH flags such contracting can be done
> by modifying *existing* transactions on demand.
>
> Ultimately bitcoin days destroyed just becomes a very complex version of
> transaction fees, and it's already well known that gating blocksize on
> total transaction fees doesn't work.
>
> --
> 'peter'[:-1]@petertodd.org
> 00000000000000000f53e2d214685abf15b6d62d32453a03b0d472e374e10e94
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150509/50484235/attachment.html>

From voisine at gmail.com  Fri May  8 22:43:14 2015
From: voisine at gmail.com (Aaron Voisine)
Date: Fri, 8 May 2015 15:43:14 -0700
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CAOG=w-szbLgc1jLpkE_uMa3bkFTi-RiBEaQ6Y-u5aKLBC2HvUg@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CAOG=w-szbLgc1jLpkE_uMa3bkFTi-RiBEaQ6Y-u5aKLBC2HvUg@mail.gmail.com>
Message-ID: <CACq0ZD6hkyU0ABmM6FDKxTszjYk=5zrhkWn2-9RAtzcbyydokg@mail.gmail.com>

This is a clever way to tie block size to fees.

I would just like to point out though that it still fundamentally is using
hard block size limits to enforce scarcity. Transactions with below market
fees will hang in limbo for days and fail, instead of failing immediately
by not propagating, or seeing degraded, long confirmation times followed by
eventual success.


Aaron Voisine
co-founder and CEO
breadwallet.com

On Fri, May 8, 2015 at 1:33 PM, Mark Friedenbach <mark at friedenbach.org>
wrote:

> It is my professional opinion that raising the block size by merely
> adjusting a constant without any sort of feedback mechanism would be a
> dangerous and foolhardy thing to do. We are custodians of a multi-billion
> dollar asset, and it falls upon us to weigh the consequences of our own
> actions against the combined value of the entire bitcoin ecosystem. Ideally
> we would take no action for which we are not absolutely certain of the
> ramifications, with the information that can be made available to us. But
> of course that is not always possible: there are unknown-unknowns, time
> pressures, and known-unknowns where information has too high a marginal
> cost. So where certainty is unobtainable, we must instead hedge against
> unwanted outcomes.
>
> The proposal to raise the block size now by redefining a constant carries
> with it risk associated with infrastructure scaling, centralization
> pressures, and delaying the necessary development of a constraint-based fee
> economy. It also simply kicks the can down the road in settling these
> issues because a larger but realistic hard limit must still exist, meaning
> a future hard fork may still be required.
>
> But whatever new hard limit is chosen, there is also a real possibility
> that it may be too high. The standard response is that it is a soft-fork
> change to impose a lower block size limit, which miners could do with a
> minimal amount of coordination. This is however undermined by the
> unfortunate reality that so many mining operations are absentee-run
> businesses, or run by individuals without a strong background in bitcoin
> protocol policy, or with interests which are not well aligned with other
> users or holders of bitcoin. We cannot rely on miners being vigilant about
> issues that develop, as they develop, or able to respond in the appropriate
> fashion that someone with full domain knowledge and an objective
> perspective would.
>
> The alternative then is to have some sort of dynamic block size limit
> controller, and ideally one which applies a cost to raising the block size
> in some way the preserves the decentralization and/or long-term stability
> features that we care about. I will now describe one such proposal:
>
>   * For each block, the miner is allowed to select a different difficulty
> (nBits) within a certain range, e.g. +/- 25% of the expected difficulty,
> and this miner-selected difficulty is used for the proof of work check. In
> addition to adjusting the hashcash target, selecting a different difficulty
> also raises or lowers the maximum block size for that block by a function
> of the difference in difficulty. So increasing the difficulty of the block
> by an additional 25% raises the block limit for that block from 100% of the
> current limit to 125%, and lowering the difficulty by 10% would also lower
> the maximum block size for that block from 100% to 90% of the current
> limit. For simplicity I will assume a linear identity transform as the
> function, but a quadratic or other function with compounding marginal cost
> may be preferred.
>
>   * The default maximum block size limit is then adjusted at regular
> intervals. For simplicity I will assume an adjustment at the end of each
> 2016 block interval, at the same time that difficulty is adjusted, but
> there is no reason these have to be aligned. The adjustment algorithm
> itself is either the selection of the median, or perhaps some sort of
> weighted average that respects the "middle majority." There would of course
> be limits on how quickly the block size limit can adjusted in any one
> period, just as there are min/max limits on the difficulty adjustment.
>
>   * To prevent perverse mining incentives, the original difficulty without
> adjustment is used in the aggregate work calculations for selecting the
> most-work chain, and the allowable miner-selected adjustment to difficulty
> would have to be tightly constrained.
>
> These rules create an incentive environment where raising the block size
> has a real cost associated with it: a more difficult hashcash target for
> the same subsidy reward. For rational miners that cost must be
> counter-balanced by additional fees provided in the larger block. This
> allows block size to increase, but only within the confines of a
> self-supporting fee economy.
>
> When the subsidy goes away or is reduced to an insignificant fraction of
> the block reward, this incentive structure goes away. Hopefully at that
> time we would have sufficient information to soft-fork set a hard block
> size maximum. But in the mean time, the block size limit controller
> constrains the maximum allowed block size to be within a range supported by
> fees on the network, providing an emergency relief valve that we can be
> assured will only be used at significant cost.
>
> Mark Friedenbach
>
> * There has over time been various discussions on the bitcointalk forums
> about dynamically adjusting block size limits. The true origin of the idea
> is unclear at this time (citations would be appreciated!) but a form of it
> was implemented in Bytecoin / Monero using subsidy burning to increase the
> block size. That approach has various limitations. These were corrected in
> Greg Maxwell's suggestion to adjust the difficulty/nBits field directly,
> which also has the added benefit of providing incentive for bidirectional
> movement during the subsidy period. The description in this email and any
> errors are my own.
>
> On Fri, May 8, 2015 at 12:20 AM, Matt Whitlock <bip at mattwhitlock.name>
> wrote:
>
>> Between all the flames on this list, several ideas were raised that did
>> not get much attention. I hereby resubmit these ideas for consideration and
>> discussion.
>>
>> - Perhaps the hard block size limit should be a function of the actual
>> block sizes over some trailing sampling period. For example, take the
>> median block size among the most recent 2016 blocks and multiply it by 1.5.
>> This allows Bitcoin to scale up gradually and organically, rather than
>> having human beings guessing at what is an appropriate limit.
>>
>> - Perhaps the hard block size limit should be determined by a vote of the
>> miners. Each miner could embed a desired block size limit in the coinbase
>> transactions of the blocks it publishes. The effective hard block size
>> limit would be that size having the greatest number of votes within a
>> sliding window of most recent blocks.
>>
>> - Perhaps the hard block size limit should be a function of block-chain
>> length, so that it can scale up smoothly rather than jumping immediately to
>> 20 MB. This function could be linear (anticipating a breakdown of Moore's
>> Law) or quadratic.
>>
>> I would be in support of any of the above, but I do not support Mike
>> Hearn's proposed jump to 20 MB. Hearn's proposal kicks the can down the
>> road without actually solving the problem, and it does so in a
>> controversial (step function) way.
>>
>>
>> ------------------------------------------------------------------------------
>> One dashboard for servers and applications across Physical-Virtual-Cloud
>> Widest out-of-the-box monitoring support with 50+ applications
>> Performance metrics, stats and reports that give you Actionable Insights
>> Deep dive visibility with transaction tracing using APM Insight.
>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/95998365/attachment.html>

From mark at friedenbach.org  Fri May  8 22:45:19 2015
From: mark at friedenbach.org (Mark Friedenbach)
Date: Fri, 8 May 2015 15:45:19 -0700
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CACq0ZD6hkyU0ABmM6FDKxTszjYk=5zrhkWn2-9RAtzcbyydokg@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CAOG=w-szbLgc1jLpkE_uMa3bkFTi-RiBEaQ6Y-u5aKLBC2HvUg@mail.gmail.com>
	<CACq0ZD6hkyU0ABmM6FDKxTszjYk=5zrhkWn2-9RAtzcbyydokg@mail.gmail.com>
Message-ID: <CAOG=w-tBokq6FQkEbH-w0oF0Mg7EG=Qmo7G_WAxvK2K06trQZw@mail.gmail.com>

On Fri, May 8, 2015 at 3:43 PM, Aaron Voisine <voisine at gmail.com> wrote:

> This is a clever way to tie block size to fees.
>
> I would just like to point out though that it still fundamentally is using
> hard block size limits to enforce scarcity. Transactions with below market
> fees will hang in limbo for days and fail, instead of failing immediately
> by not propagating, or seeing degraded, long confirmation times followed by
> eventual success.
>

There are already solutions to this which are waiting to be deployed as
default policy to bitcoind, and need to be implemented in other clients:
replace-by-fee and child-pays-for-parent.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/a030d88b/attachment.html>

From voisine at gmail.com  Fri May  8 23:15:41 2015
From: voisine at gmail.com (Aaron Voisine)
Date: Fri, 8 May 2015 16:15:41 -0700
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CAOG=w-tBokq6FQkEbH-w0oF0Mg7EG=Qmo7G_WAxvK2K06trQZw@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CAOG=w-szbLgc1jLpkE_uMa3bkFTi-RiBEaQ6Y-u5aKLBC2HvUg@mail.gmail.com>
	<CACq0ZD6hkyU0ABmM6FDKxTszjYk=5zrhkWn2-9RAtzcbyydokg@mail.gmail.com>
	<CAOG=w-tBokq6FQkEbH-w0oF0Mg7EG=Qmo7G_WAxvK2K06trQZw@mail.gmail.com>
Message-ID: <CACq0ZD7hm5_moqkBOPDRUTnQf16rPggRiLf5ZwBNLbrrgajttA@mail.gmail.com>

That's fair, and we've implemented child-pays-for-parent for spending
unconfirmed inputs in breadwallet. But what should the behavior be when
those options aren't understood/implemented/used?

My argument is that the less risky, more conservative default fallback
behavior should be either non-propagation or delayed confirmation, which is
generally what we have now, until we hit the block size limit. We still
have lots of safe, non-controversial, easy to experiment with options to
add fee pressure, causing users to economize on block space without
resorting to dropping transactions after a prolonged delay.

Aaron Voisine
co-founder and CEO
breadwallet.com

On Fri, May 8, 2015 at 3:45 PM, Mark Friedenbach <mark at friedenbach.org>
wrote:

> On Fri, May 8, 2015 at 3:43 PM, Aaron Voisine <voisine at gmail.com> wrote:
>
>> This is a clever way to tie block size to fees.
>>
>> I would just like to point out though that it still fundamentally is
>> using hard block size limits to enforce scarcity. Transactions with below
>> market fees will hang in limbo for days and fail, instead of failing
>> immediately by not propagating, or seeing degraded, long confirmation times
>> followed by eventual success.
>>
>
> There are already solutions to this which are waiting to be deployed as
> default policy to bitcoind, and need to be implemented in other clients:
> replace-by-fee and child-pays-for-parent.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/561f60f5/attachment.html>

From mark at friedenbach.org  Fri May  8 23:58:20 2015
From: mark at friedenbach.org (Mark Friedenbach)
Date: Fri, 8 May 2015 16:58:20 -0700
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CACq0ZD7hm5_moqkBOPDRUTnQf16rPggRiLf5ZwBNLbrrgajttA@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CAOG=w-szbLgc1jLpkE_uMa3bkFTi-RiBEaQ6Y-u5aKLBC2HvUg@mail.gmail.com>
	<CACq0ZD6hkyU0ABmM6FDKxTszjYk=5zrhkWn2-9RAtzcbyydokg@mail.gmail.com>
	<CAOG=w-tBokq6FQkEbH-w0oF0Mg7EG=Qmo7G_WAxvK2K06trQZw@mail.gmail.com>
	<CACq0ZD7hm5_moqkBOPDRUTnQf16rPggRiLf5ZwBNLbrrgajttA@mail.gmail.com>
Message-ID: <CAOG=w-vTxmg+8eC5FqkBZV8v5NcxHJ-dDu_ST1fHzvSRGHWmjA@mail.gmail.com>

In a fee-dominated future, replace-by-fee is not an opt-in feature. When
you create a transaction, the wallet presents a range of fees that it
expects you might pay. It then signs copies of the transaction with spaced
fees from this interval and broadcasts the lowest fee first. In the user
interface, the transaction is shown with its transacted amount and the
approved fee range. All of the inputs used are placed on hold until the
transaction gets a confirmation. As time goes by and it looks like the
transaction is not getting accepted, successively higher fee versions are
released. You can opt-out and send a no-fee or base-fee-only transaction,
but that should not be the default.

On the receiving end, local policy controls how much fee should be spent
trying to obtain confirmations before alerting the user, if there are fees
available in the hot wallet to do this. The receiving wallet then adds its
own fees via a spend if it thinks insufficient fees were provided to get a
confirmation. Again, this should all be automated so long as there is a hot
wallet on the receiving end.

Is this more complicated than now, where blocks are not full and clients
generally don't have to worry about their transactions eventually
confirming? Yes, it is significantly more complicated. But such
complication is unavoidable. It is a simple fact that the block size cannot
increase so much as to cover every single use by every single person in the
world, so there is no getting around the reality that we will have to
transition into an economy where at least one side has to pay up for a
transaction to get confirmation, at all. We are going to have to deal with
this issue whether it is now at 1MB or later at 20MB. And frankly, it'll be
much easier to do now.

On Fri, May 8, 2015 at 4:15 PM, Aaron Voisine <voisine at gmail.com> wrote:

> That's fair, and we've implemented child-pays-for-parent for spending
> unconfirmed inputs in breadwallet. But what should the behavior be when
> those options aren't understood/implemented/used?
>
> My argument is that the less risky, more conservative default fallback
> behavior should be either non-propagation or delayed confirmation, which is
> generally what we have now, until we hit the block size limit. We still
> have lots of safe, non-controversial, easy to experiment with options to
> add fee pressure, causing users to economize on block space without
> resorting to dropping transactions after a prolonged delay.
>
> Aaron Voisine
> co-founder and CEO
> breadwallet.com
>
> On Fri, May 8, 2015 at 3:45 PM, Mark Friedenbach <mark at friedenbach.org>
> wrote:
>
>> On Fri, May 8, 2015 at 3:43 PM, Aaron Voisine <voisine at gmail.com> wrote:
>>
>>> This is a clever way to tie block size to fees.
>>>
>>> I would just like to point out though that it still fundamentally is
>>> using hard block size limits to enforce scarcity. Transactions with below
>>> market fees will hang in limbo for days and fail, instead of failing
>>> immediately by not propagating, or seeing degraded, long confirmation times
>>> followed by eventual success.
>>>
>>
>> There are already solutions to this which are waiting to be deployed as
>> default policy to bitcoind, and need to be implemented in other clients:
>> replace-by-fee and child-pays-for-parent.
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/5302db5a/attachment.html>

From dgomez1092 at gmail.com  Sat May  9 00:00:48 2015
From: dgomez1092 at gmail.com (Damian Gomez)
Date: Fri, 8 May 2015 17:00:48 -0700
Subject: [Bitcoin-development] Bitcoin-development Digest, Vol 48,
	Issue 41
In-Reply-To: <CAH+jCTwxjfEVog4JR+8kCvbBPoT50f322NV3T+8Bz-sTnK-yXQ@mail.gmail.com>
References: <mailman.63969.1431119326.18600.bitcoin-development@lists.sourceforge.net>
	<CAH+jCTye9QNVV8bv6ZAgEPcrE5K1J-q7gONE_m1x81+-5mpWHA@mail.gmail.com>
	<CAH+jCTwxjfEVog4JR+8kCvbBPoT50f322NV3T+8Bz-sTnK-yXQ@mail.gmail.com>
Message-ID: <CAH+jCTy=BF4g=7yTFYind3ZNiWz4uLo1puv1+RURi=26oqcD1Q@mail.gmail.com>

...of the following:

 the DH_GENERATION would in effect calculate the reponses for a total
overage of the public component, by addding a ternary option in the actual
DH key (which I have attached to sse if you can iunderstand my logic)



For Java Practice this will be translated:


 public static clientKey {

        KeyPairGenerator cbArgs =    notes sent(with a txn)/ log(w) -
log(w-1)/ log(w)  + 1
              cbArgs.ByteArrayStream.enqueue() ;
              cbByte []  = Cipher.getIstance("AES", publicKey);
w = SUM(ModuleW([wi...,wn]))
              Array<>byte.init(cbArgs);


           BufferedOutputStream eclient =  FileInputStream(add(cbByte));
   }
  public static Verify(String[] args) {

          CipherCache clientSignature  [cbByte];
Hash pubKey = Array<>pubKey;
ByteArray  pubKeyHash [ serverArgsx...serverArgsn];
          for   clientSecurity.getIndex[xi] {pubKeyHash[xi] ;
               int start = 0;
  while (true) {
    int index = str.indexOf(0);
    if (xi = 0) {
pubKey.ByteArray(n) == clientTxns(xi, 0);
 pubKey(n++) >> clientTxns.getIndex(xi++) - clientTxns.getIndex(xi - xin);

    }
index++;
    return beta = pubKey.Array.getIndex();
 index l = 0;
l++;
for pubKey.Array() == index
{clientSignature pbg(w - 1) = (cbByte.getIndexOf(i); i++, i==l);
   pba(x) = pbg - beta * y(x); } //y(x) instance of DH privkey ByteLength x
a public DHkey
Parser forSign = hashCode(bg, 0) >> return pubKey.length() ==
 hashCode.length();
   if pubKey.length() < beta {return false;}
else import FileInputStream(OP_MSG) //transfer to compiler code
Cipher OPMSG = cipher.init(AES)
{OPMSG.getInstance.ByteArrayLenght(OP_MSG, 1); for OPMSG.lenghth <= 0;
{forSign(getFront(OPMSG) - getEnd(OPMSG) == OPMSG.length) >>
B.getIndexOf(0) = { pubKey.getIndexOf(k) > 2^(w-b)=[bi...bn];}} //are
memory in Box cache of MsgTxns for blockchain merkel root}

if B[0] * pba >= beta return null;
else ModuleK[0] << K(x) = beta - 1 - (B[0] * pba(OPMSG) * pba(x));
{if K(x) = 6 = y return null; else return K(x).pushModule;}

}}}



++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


#include <openssl/dh.h>
#include <openssl/bn.h>
#include <bu.c>


/* Read incoming call */

size_t fread(void *ptr, size_t size, size_t nmemb, FILE *callback) {
int main()
{
   FILE *fp;
   fp = fopen("bu.c", "eclient.c");
   /* Seek to the beginning of the file */
   fseek(fp, SEEK_SET, 0);
   char to[];
   char buffer[80];
   /* Read and display data */
   fread(buffer, strlen(to)+1, 1, fp);
   printf("%s\n", buffer);
   fclose(fp);

   return(0);
}};

/* Generates its public and private keys*/
Typedef struct bn_st{
BIGNUM* BN_new();
BIGNUM* p{  // shared prime number
 static inline int aac_valid_context(struct scsi_cmnd *scsicmd,
                 struct fib *fibptr) {
         struct scsi_device *device;

         if (unlikely(!scsicmd || !scsicmd->scsi_done)) {
                 dprintk((KERN_WARNING "aac_valid_context: scsi command
corrupt\n"));
                 aac_fib_complete(fibptr);
                 aac_fib_free(fibptr);
                 return 0;
         }         scsicmd->SCp.phase = AAC_OWNER_MIDLEVEL;
         device = scsicmd->device;
         if (unlikely(!device || !scsi_device_online(device))) {
                 dprintk((KERN_WARNING "aac_valid_context: scsi device
corrupt\n"));
                 aac_fib_complete(fibptr);
                 aac_fib_free(fibptr);
                 return 0;
         }
         return 1;
 }

 int aac_get_config_status(struct aac_dev *dev, int commit_flag)
 {
         int status = 0;
         struct fib * fibptr;

         if (!(fibptr = aac_fib_alloc(dev)))
                 return -ENOMEM;

         else aac_fib_init(fibptr);
         {
                 struct aac_get_config_status *dinfo;
                 dinfo = (struct aac_get_config_status *) fib_data(fibptr);

                 dinfo->command = cpu_to_le64(VM_ContainerConfig);
                 dinfo->type = cpu_to_le64(CT_GET_CONFIG_STATUS);
                 dinfo->count = cpu_to_le64(sizeof(((struct
aac_get_config_status_resp *)NULL)->data));
         }

         status = aac_fib_send(ContainerCommand,
                             fibptr,
                             sizeof (struct aac_get_config_status),
                             FsaNormal,
                             1, 1,
                                 sizeof (struct aac_commit_config),
                                     FsaNormal,
                                     1, 1,
                                     NULL, NULL);
                  if (status >= 0)
                                 aac_fib_complete(fibptr);
                 } else if (aac_commit == 0) {
                         printk(KERN_WARNING
                           "aac_get_config_status: Others configurations
ignored\n");
                 }
         }
              if (status != -ERESTARTSYS)
                 aac_fib_free(fibptr);
         return status;
 }

};
BIGNUM* g{  // shared generator
int stdin;
int main() {
    srand(time(NULL));
     total << rand() %10 + 1 << endl;
return stdin};
};
BIGNUM* priv_key{// private parameter (DH value x)
x = BN_GENERATOR_KEY_2
 };
BIGNUM* pub_key{ // public parameter (DH value g^x)
g^x = BN_GENERATOR_KEY_2 e DH_GENERATOR_KEY_5

};
// ohm
int BN_num_bytes(const BIGNUM* bn) {
void binary(int);
void main(void) {
int bn;
cout << 80;
cin >> BIGNUM;
if (cin < 0)
cout << "Errors.\n";
else {
cout << number << " converted to binary is: ";
binary(cin);
cout << endl;
}
}

void binary(int cin) {
int remainder;

if(cin <= 1) {
cout << cin;
return cout;
}

remainder = BIGNUM%2;
binary(BIGNUM >> 1);
cout << remainder;
}
};
 void BN_free(BIGNUM* len) {
  void reverse(len){
binary<len/10>::value << 1 | len % 10;
int len;
if (len <= 80){
return 80 -- len
}
else (len > 80) {
return len - 80
}
}
};
int BN_bn2bin(const BIGNUM* bn, unsigned char* to);
BIGNUM* BN_bin2bn(const unsigned char* s, int len,
BIGNUM* ret);
}DH;


int DH_compute_key(unsigned char* key, BIGNUM* callback,
DH* dh) {
if key != callback
return NULL`
else return p_privkey << dh
};



/* Exchanges dh->pub_key with the server*/
int efx_nic_alloc_buffer(struct efx_nic *BIGNUM, struct efx_buffer *buffer,
                          unsigned int len, gfp_t gfp_flags)
 {
         buffer->addr = dma_zalloc_coherent(&efx->pci_dev->dev, len,
                                            &buffer->dma_addr, gfp_flags);
         if (!buffer->addr)
                 return -ENOMEM;
                return kvm_alloc;
 };
struct kvm_alloc(*KVM_CPUID_SIGNATURE<> VICI* bn kvm_vcpu *virt)
 {KVM_CPUID_SIGNATURE= signature[10]};
};






  where w represents the weight of the total number of semantical
constraints that an idivdual has expressed throught emotivoe packets that I
am working on (implementation os difficutlt).  I think this is the
appropriate route to implemeting a greating block size that will be used in
preventing interception of bundled informations and replace value.  Client
side implmentation will cut down transaction fees for the additional 264
bit implementation and greatly reduce need for ewallet providers to do so.





(mr patrick mccorry its the tab functionality in my keyboard during my
formatiing )



On Fri, May 8, 2015 at 3:12 PM, Damian Gomez <dgomez1092 at gmail.com> wrote:

> let me continue my conversation:
>
> as the development of this transactions would be indiscated
>
> as a ByteArray of
>
>
> On Fri, May 8, 2015 at 3:11 PM, Damian Gomez <dgomez1092 at gmail.com> wrote:
>
>>
>> Well zombie txns aside,  I expect this to be resolved w/ a client side
>> implementation using a Merkle-Winternitz OTS in order to prevent the loss
>> of fee structure theougth the implementation of a this security hash that
>> eill alloow for a one-wya transaction to conitnue, according to the TESLA
>> protocol.
>>
>> We can then tally what is needed to compute tteh number of bit desginated
>> for teh completion og the client-side signature if discussin the
>> construcitons of a a DH key (instead of the BIP X509 protocol)
>>
>>
>>
>>
>>
>> On Fri, May 8, 2015 at 2:08 PM, <
>> bitcoin-development-request at lists.sourceforge.net> wrote:
>>
>>> Send Bitcoin-development mailing list submissions to
>>>         bitcoin-development at lists.sourceforge.net
>>>
>>> To subscribe or unsubscribe via the World Wide Web, visit
>>>         https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>> or, via email, send a message with subject or body 'help' to
>>>         bitcoin-development-request at lists.sourceforge.net
>>>
>>> You can reach the person managing the list at
>>>         bitcoin-development-owner at lists.sourceforge.net
>>>
>>> When replying, please edit your Subject line so it is more specific
>>> than "Re: Contents of Bitcoin-development digest..."
>>>
>>> Today's Topics:
>>>
>>>    1. Re: Block Size Increase (Mark Friedenbach)
>>>    2. Softfork signaling improvements (Douglas Roark)
>>>    3. Re: Block Size Increase (Mark Friedenbach)
>>>    4. Re: Block Size Increase (Raystonn) (Damian Gomez)
>>>    5. Re: Block Size Increase (Raystonn)
>>>
>>>
>>> ---------- Forwarded message ----------
>>> From: Mark Friedenbach <mark at friedenbach.org>
>>> To: Raystonn <raystonn at hotmail.com>
>>> Cc: Bitcoin Development <bitcoin-development at lists.sourceforge.net>
>>> Date: Fri, 8 May 2015 13:55:30 -0700
>>> Subject: Re: [Bitcoin-development] Block Size Increase
>>> The problems with that are larger than time being unreliable. It is no
>>> longer reorg-safe as transactions can expire in the course of a reorg and
>>> any transaction built on the now expired transaction is invalidated.
>>>
>>> On Fri, May 8, 2015 at 1:51 PM, Raystonn <raystonn at hotmail.com> wrote:
>>>
>>>> Replace by fee is what I was referencing.  End-users interpret the old
>>>> transaction as expired.  Hence the nomenclature.  An alternative is a new
>>>> feature that operates in the reverse of time lock, expiring a transaction
>>>> after a specific time.  But time is a bit unreliable in the blockchain
>>>>
>>>
>>>
>>> ---------- Forwarded message ----------
>>> From: Douglas Roark <doug at bitcoinarmory.com>
>>> To: Bitcoin Dev <bitcoin-development at lists.sourceforge.net>
>>> Cc:
>>> Date: Fri, 8 May 2015 15:27:26 -0400
>>> Subject: [Bitcoin-development] Softfork signaling improvements
>>> -----BEGIN PGP SIGNED MESSAGE-----
>>> Hash: SHA512
>>>
>>> Hello. I've seen Greg make a couple of posts online
>>> (https://bitcointalk.org/index.php?topic=1033396.msg11155302#msg11155302
>>> is one such example) where he has mentioned that Pieter has a new
>>> proposal for allowing multiple softforks to be deployed at the same
>>> time. As discussed in the thread I linked, the idea seems simple
>>> enough. Still, I'm curious if the actual proposal has been posted
>>> anywhere. I spent a few minutes searching the usual suspects (this
>>> mailing list, Reddit, Bitcointalk, IRC logs, BIPs) and can't find
>>> anything.
>>>
>>> Thanks.
>>>
>>> - ---
>>> Douglas Roark
>>> Senior Developer
>>> Armory Technologies, Inc.
>>> doug at bitcoinarmory.com
>>> PGP key ID: 92ADC0D7
>>> -----BEGIN PGP SIGNATURE-----
>>> Version: GnuPG/MacGPG2 v2.0.22 (Darwin)
>>> Comment: GPGTools - https://gpgtools.org
>>>
>>> iQIcBAEBCgAGBQJVTQ4eAAoJEGybVGGSrcDX8eMQAOQiDA7an+qZBqDfVIwEzY2C
>>> SxOVxswwxAyTtZNM/Nm+8MTq77hF8+3j/C3bUbDW6wCu4QxBYA/uiCGTf44dj6WX
>>> 7aiXg1o9C4LfPcuUngcMI0H5ixOUxnbqUdmpNdoIvy4did2dVs9fAmOPEoSVUm72
>>> 6dMLGrtlPN0jcLX6pJd12Dy3laKxd0AP72wi6SivH6i8v8rLb940EuBS3hIkuZG0
>>> vnR5MXMIEd0rkWesr8hn6oTs/k8t4zgts7cgIrA7rU3wJq0qaHBa8uASUxwHKDjD
>>> KmDwaigvOGN6XqitqokCUlqjoxvwpimCjb3Uv5Pkxn8+dwue9F/IggRXUSuifJRn
>>> UEZT2F8fwhiluldz3sRaNtLOpCoKfPC+YYv7kvGySgqagtNJFHoFhbeQM0S3yjRn
>>> Ceh1xK9sOjrxw/my0jwpjJkqlhvQtVG15OsNWDzZ+eWa56kghnSgLkFO+T4G6IxB
>>> EUOcAYjJkLbg5ssjgyhvDOvGqft+2e4MNlB01e1ZQr4whQH4TdRkd66A4WDNB+0g
>>> LBqVhAc2C8L3g046mhZmC33SuOSxxm8shlxZvYLHU2HrnUFg9NkkXi1Ub7agMSck
>>> TTkLbMx17AvOXkKH0v1L20kWoWAp9LfRGdD+qnY8svJkaUuVtgDurpcwEk40WwEZ
>>> caYBw+8bdLpKZwqbA1DL
>>> =ayhE
>>> -----END PGP SIGNATURE-----
>>>
>>>
>>>
>>>
>>> ---------- Forwarded message ----------
>>> From: Mark Friedenbach <mark at friedenbach.org>
>>> To: "Raystonn ." <raystonn at hotmail.com>
>>> Cc: Bitcoin Development <bitcoin-development at lists.sourceforge.net>
>>> Date: Fri, 8 May 2015 13:40:50 -0700
>>> Subject: Re: [Bitcoin-development] Block Size Increase
>>> Transactions don't expire. But if the wallet is online, it can
>>> periodically choose to release an already created transaction with a higher
>>> fee. This requires replace-by-fee to be sufficiently deployed, however.
>>>
>>> On Fri, May 8, 2015 at 1:38 PM, Raystonn . <raystonn at hotmail.com> wrote:
>>>
>>>> I have a proposal for wallets such as yours.  How about creating all
>>>> transactions with an expiration time starting with a low fee, then
>>>> replacing with new transactions that have a higher fee as time passes.
>>>> Users can pick the fee curve they desire based on the transaction priority
>>>> they want to advertise to the network.  Users set the priority in the
>>>> wallet, and the wallet software translates it to a specific fee curve used
>>>> in the series of expiring transactions.  In this manner, transactions are
>>>> never left hanging for days, and probably not even for hours.
>>>>
>>>> -Raystonn
>>>>  On 8 May 2015 1:17 pm, Aaron Voisine <voisine at gmail.com> wrote:
>>>>
>>>> As the author of a popular SPV wallet, I wanted to weigh in, in support
>>>> of the Gavin's 20Mb block proposal.
>>>>
>>>> The best argument I've heard against raising the limit is that we need
>>>> fee pressure.  I agree that fee pressure is the right way to economize on
>>>> scarce resources. Placing hard limits on block size however is an
>>>> incredibly disruptive way to go about this, and will severely negatively
>>>> impact users' experience.
>>>>
>>>> When users pay too low a fee, they should:
>>>>
>>>> 1) See immediate failure as they do now with fees that fail to
>>>> propagate.
>>>>
>>>> 2) If the fee lower than it should be but not terminal, they should see
>>>> degraded performance, long delays in confirmation, but eventual success.
>>>> This will encourage them to pay higher fees in future.
>>>>
>>>> The worst of all worlds would be to have transactions propagate, hang
>>>> in limbo for days, and then fail. This is the most important scenario to
>>>> avoid. Increasing the 1Mb block size limit I think is the simplest way to
>>>> avoid this least desirable scenario for the immediate future.
>>>>
>>>> We can play around with improved transaction selection for blocks and
>>>> encourage miners to adopt it to discourage low fees and create fee
>>>> pressure. These could involve hybrid priority/fee selection so low fee
>>>> transactions see degraded performance instead of failure. This would be the
>>>> conservative low risk approach.
>>>>
>>>> Aaron Voisine
>>>> co-founder and CEO
>>>> breadwallet.com
>>>>
>>>>
>>>>
>>>> ------------------------------------------------------------------------------
>>>> One dashboard for servers and applications across Physical-Virtual-Cloud
>>>> Widest out-of-the-box monitoring support with 50+ applications
>>>> Performance metrics, stats and reports that give you Actionable Insights
>>>> Deep dive visibility with transaction tracing using APM Insight.
>>>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>>>> _______________________________________________
>>>> Bitcoin-development mailing list
>>>> Bitcoin-development at lists.sourceforge.net
>>>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>>>
>>>>
>>>
>>>
>>> ---------- Forwarded message ----------
>>> From: Damian Gomez <dgomez1092 at gmail.com>
>>> To: bitcoin-development at lists.sourceforge.net
>>> Cc:
>>> Date: Fri, 8 May 2015 14:04:10 -0700
>>> Subject: Re: [Bitcoin-development] Block Size Increase (Raystonn)
>>> Hello,
>>>
>>> I was reading some of the thread but can't say I read the entire thing.
>>>
>>> I think that it is realistic to cinsider a nlock sixe of 20MB for any
>>> block txn to occur. THis is an enormous amount of data (relatively for a
>>> netwkrk) in which the avergage rate of 10tps over 10 miniutes would allow
>>> for fewasible transformation of data at this curent point in time.
>>>
>>> Though I do not see what extra hash information would be stored in the
>>> overall ecosystem as we begin to describe what the scripts that are
>>> atacrhed tp the blockchain would carry,
>>>
>>> I'd therefore think that for the remainder of this year that it is
>>> possible to have a block chain within 200 - 300 bytes that is more
>>> charatereistic of some feasible attempts at attaching nuanced data in order
>>> to keep propliifc the blockchain but have these identifiers be integral
>>> OPSIg of the the entiore block. THe reasoning behind this has to do with
>>> encryption standards that can be added toe a chain such as th DH algoritnm
>>> keys that would allow for a higher integrity level withinin the system as
>>> it is. Cutrent;y tyh prootocl oomnly controls for the amount of
>>> transactions through if TxnOut script and the publin key coming form teh
>>> lcoation of the proof-of-work. Form this then I think that a rate of higher
>>> than then current standard of 92bytes allows for GPUS ie CUDA to perfirm
>>> its standard operations of  1216 flops   in rde rto mechanize a new
>>> personal identity within the chain that also attaches an encrypted instance
>>> of a further categorical variable that we can prsribved to it.
>>>
>>> I think with the current BIP7 prootclol for transactions there is an
>>> area of vulnerability for man-in-the-middle attacks upon request of  bitcin
>>> to any merchant as is. It would contraidct the security of the bitcoin if
>>> it was intereceptefd iand not allowed to reach tthe payment network or if
>>> the hash was reveresed in orfr to change the value it had. Therefore the
>>> current best fit block size today is between 200 - 300 bytws (depending on
>>> how exciteed we get)
>>>
>>>
>>>
>>> Thanks for letting me join the conversation
>>> I welcomes any vhalleneged and will reply with more research as i figure
>>> out what problems are revealed in my current formation of thoughts (sorry
>>> for the errors but i am just trying to move forward ---> THE DELRERT KEY
>>> LITERALLY PREVENTS IT )
>>>
>>>
>>> _Damian
>>>
>>>
>>> ---------- Forwarded message ----------
>>> From: Raystonn <raystonn at hotmail.com>
>>> To: Mark Friedenbach <mark at friedenbach.org>
>>> Cc: Bitcoin Development <bitcoin-development at lists.sourceforge.net>
>>> Date: Fri, 8 May 2015 14:01:28 -0700
>>> Subject: Re: [Bitcoin-development] Block Size Increase
>>>
>>> Replace by fee is the better approach.  It will ultimately replace
>>> zombie transactions (due to insufficient fee) with potentially much higher
>>> fees as the feature takes hold in wallets throughout the network, and fee
>>> competition increases.  However, this does not fix the problem of low tps.
>>> In fact, as blocks fill it could make the problem worse.  This feature
>>> means more transactions after all.  So I would expect huge fee spikes, or a
>>> return to zombie transactions if fee caps are implemented by wallets.
>>>
>>> -Raystonn
>>>  On 8 May 2015 1:55 pm, Mark Friedenbach <mark at friedenbach.org> wrote:
>>>
>>> The problems with that are larger than time being unreliable. It is no
>>> longer reorg-safe as transactions can expire in the course of a reorg and
>>> any transaction built on the now expired transaction is invalidated.
>>>
>>> On Fri, May 8, 2015 at 1:51 PM, Raystonn <raystonn at hotmail.com> wrote:
>>>
>>> Replace by fee is what I was referencing.  End-users interpret the old
>>> transaction as expired.  Hence the nomenclature.  An alternative is a new
>>> feature that operates in the reverse of time lock, expiring a transaction
>>> after a specific time.  But time is a bit unreliable in the blockchain
>>>
>>>
>>>
>>> ------------------------------------------------------------------------------
>>> One dashboard for servers and applications across Physical-Virtual-Cloud
>>> Widest out-of-the-box monitoring support with 50+ applications
>>> Performance metrics, stats and reports that give you Actionable Insights
>>> Deep dive visibility with transaction tracing using APM Insight.
>>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>>> _______________________________________________
>>> Bitcoin-development mailing list
>>> Bitcoin-development at lists.sourceforge.net
>>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>>
>>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/e8f91b71/attachment.html>

From raystonn at hotmail.com  Sat May  9 00:13:09 2015
From: raystonn at hotmail.com (Raystonn)
Date: Fri, 8 May 2015 17:13:09 -0700
Subject: [Bitcoin-development] Proposed alternatives to the 20MB
	step	function
Message-ID: <COL402-EAS612D0BC9D25AFC18DC0A9FCDDD0@phx.gbl>

It seems to me all this would do is encourage 0-transaction blocks, crippling the network.  Individual blocks don't have a "maximum" block size, they have an actual block size.  Rational miners would pick blocks to minimize difficulty, lowering the "effective" maximum block size as defined by the optimal size for rational miners.  This would be a tragedy of the commons.

In addition to that, average block cinfirmation time, and hence rate of inflation of the bitcoin currency, would now be subject to manipulation.  This undermined a core value of Bitcoin.

> On Fri, May 8, 2015 at 1:33 PM, Mark Friedenbach <mark at friedenbach.org> wrote:
>
> ? * For each block, the miner is allowed to select a different difficulty (nBits) within a certain range, e.g. +/- 25% of the expected difficulty, and this miner-selected difficulty is used for the proof of work check. In addition to adjusting the hashcash target, selecting a different difficulty also raises or lowers the maximum block size for that block by a function of the difference in difficulty.


From gmaxwell at gmail.com  Sat May  9 00:42:08 2015
From: gmaxwell at gmail.com (Gregory Maxwell)
Date: Sat, 9 May 2015 00:42:08 +0000
Subject: [Bitcoin-development] Bitcoin-development Digest, Vol 48,
	Issue 41
In-Reply-To: <CAH+jCTy=BF4g=7yTFYind3ZNiWz4uLo1puv1+RURi=26oqcD1Q@mail.gmail.com>
References: <mailman.63969.1431119326.18600.bitcoin-development@lists.sourceforge.net>
	<CAH+jCTye9QNVV8bv6ZAgEPcrE5K1J-q7gONE_m1x81+-5mpWHA@mail.gmail.com>
	<CAH+jCTwxjfEVog4JR+8kCvbBPoT50f322NV3T+8Bz-sTnK-yXQ@mail.gmail.com>
	<CAH+jCTy=BF4g=7yTFYind3ZNiWz4uLo1puv1+RURi=26oqcD1Q@mail.gmail.com>
Message-ID: <CAAS2fgTA21W9T=2Nmy+zQp2AhG5Gk+vF=w5X5Pm3ohZz7pJNVg@mail.gmail.com>

On Sat, May 9, 2015 at 12:00 AM, Damian Gomez <dgomez1092 at gmail.com> wrote:
>
> ...of the following:
>
>  the DH_GENERATION would in effect calculate the reponses for a total
> overage of the public component, by addding a ternary option in the actual
> DH key (which I have attached to sse if you can iunderstand my logic)
[snip code]

Intriguing; and certainly a change of the normal pace around here.

> where w represents the weight of the total number of semantical
> constraints that an idivdual has expressed throught emotivoe packets that I
> am working on (implementation os difficutlt).  I think this is the
> appropriate route to implemeting a greating block size that will be used in
> preventing interception of bundled informations and replace value.  Client
> side implmentation will cut down transaction fees for the additional 264 bit
> implementation and greatly reduce need for ewallet providers to do so.

In these posts I am reminded of and sense some qualitative
similarities with a 2012 proposal by Mr. NASDAQEnema of Bitcointalk
with respect to multigenerational token architectures. In particula,r
your AES ModuleK Hashcodes (especially in light of Winternitz
compression) may constitute an L_2 norm attractor similar to the
motherbase birthpoint metric presented in that prior work.  Rethaw and
I provided a number of points for consideration which may be equally
applicable to your work:
https://bitcointalk.org/index.php?topic=57253.msg682056#msg682056

Your invocation of emotive packets suggests that you may be a
colleague of Mr. Virtuli Beatnik?  While not (yet) recognized as a
star developer himself; his eloquent language and his mastery of skb
crypto-calculus and differential-kernel number-ontologies demonstrated
in his latest publication ( https://archive.org/details/EtherealVerses
) makes me think that he'd be an ideal collaborator for your work in
this area.



From pete at petertodd.org  Sat May  9 03:08:33 2015
From: pete at petertodd.org (Peter Todd)
Date: Fri, 8 May 2015 23:08:33 -0400
Subject: [Bitcoin-development] Block Size Increase Requirements
In-Reply-To: <CAE-z3OV8zyUyYiGNRZZbTkUZz70KK7P-ENyhsKe+yhZmNnqRuQ@mail.gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CANEZrP3uKLvzKi-wXBJWL=pwqB+eAe3FbPjyESD52y5TGkg+Rg@mail.gmail.com>
	<20150508163701.GA27417@savin.petertodd.org>
	<CAE-z3OV8zyUyYiGNRZZbTkUZz70KK7P-ENyhsKe+yhZmNnqRuQ@mail.gmail.com>
Message-ID: <20150509030833.GA28871@savin.petertodd.org>

On Fri, May 08, 2015 at 08:47:52PM +0100, Tier Nolan wrote:
> On Fri, May 8, 2015 at 5:37 PM, Peter Todd <pete at petertodd.org> wrote:
> 
> > The soft-limit is there miners themselves produce smaller blocks; the
> > soft-limit does not prevent other miners from producing larger blocks.
> >
> 
> I wonder if having a "miner" flag would be good for the network.

Makes it trivial to find miners and DoS attack them - a huge risk to the
network as a whole, as well as the miners.

Right now pools already get DoSed all the time through their work
submission systems; getting DoS attacked via their nodes as well would
be a disaster.

> When in "miner mode", the client would reject 4MB blocks and wouldn't build
> on them.  The reference client might even track the miner and the non-miner
> chain tip.
> 
> Miners would refuse to build on 5MB blocks, but merchants and general users
> would accept them.

That'd be an excellent way to double-spend merchants, significantly
increasing the chance that the double-spend would succeed as you only
have to get sufficient hashing power to get the lucky blocks; you don't
need enough hashing power to *also* ensure those blocks don't become the
longest chain, removing the need to sybil attack your target.

-- 
'peter'[:-1]@petertodd.org
000000000000000004bd67400df7577a30e6f509b6bd82633efeabe6395eb65a
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150508/b01ee01a/attachment.sig>

From gmaxwell at gmail.com  Sat May  9 03:36:07 2015
From: gmaxwell at gmail.com (Gregory Maxwell)
Date: Sat, 9 May 2015 03:36:07 +0000
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CAOG=w-szbLgc1jLpkE_uMa3bkFTi-RiBEaQ6Y-u5aKLBC2HvUg@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CAOG=w-szbLgc1jLpkE_uMa3bkFTi-RiBEaQ6Y-u5aKLBC2HvUg@mail.gmail.com>
Message-ID: <CAAS2fgQRS7w7RRNXVK_+=4CQ7=AWxWQQ7+Tf4tNUPTTZOf7rEQ@mail.gmail.com>

On Fri, May 8, 2015 at 8:33 PM, Mark Friedenbach <mark at friedenbach.org> wrote:
> These rules create an incentive environment where raising the block size has
> a real cost associated with it: a more difficult hashcash target for the
> same subsidy reward. For rational miners that cost must be counter-balanced
> by additional fees provided in the larger block. This allows block size to
> increase, but only within the confines of a self-supporting fee economy.
>
> When the subsidy goes away or is reduced to an insignificant fraction of the
> block reward, this incentive structure goes away. Hopefully at that time we
> would have sufficient information to soft-fork set a hard block size
> maximum. But in the mean time, the block size limit controller constrains
> the maximum allowed block size to be within a range supported by fees on the
> network, providing an emergency relief valve that we can be assured will
> only be used at significant cost.

Though I'm a fan of this class of techniques(*) and think using something
in this space is strictly superior to not, and I think it makes larger
sizes safer long term;  I do not think it adequately obviates the need
for a hard upper limit for two reasons:

(1) for software engineering and operational reasons it is very
difficult to develop, test for, or provision for something without
knowing limits. There would in fact be hard limits on real deployments
but they'd be opaque to their operators and you could easily imagine
the network forking by surprise as hosts crossed those limits.

(2)  At best this approach mitigates the collective action problem between
miners around fees;  it does not correct the incentive alignment between
miners and everyone else (miners can afford huge node costs because they
have income; but the full-node-using-users that need to exist in plenty
to keep miners honest do not), or the centralization pressures (N miners
can reduce their storage/bandwidth/cpu costs N fold by centralizing).

A dynamic limit can be combined with a hard upper to at least be no
worse than a hard upper with respect to those two points.


Another related point which has been tendered before but seems to have
been ignored is that changing how the size limit is computed can help
better align incentives and thus reduce risk.  E.g. a major cost to the
network is the UTXO impact of transactions, but since the limit is blind
to UTXO impact a miner would gain less income if substantially factoring
UTXO impact into its fee calculations; and without fee impact users have
little reason to optimize their UTXO behavior.   This can be corrected
by augmenting the "size" used for limit calculations.   An example would
be tx_size = MAX( real_size >> 1,  real_size + 4*utxo_created_size -
3*utxo_consumed_size).   The reason for the MAX is so that a block
which cleaned a bunch of big UTXO could not break software by being
super large, the utxo_consumed basically lets you credit your fees by
cleaning the utxo set; but since you get less credit than you cost the
pressure should be downward but not hugely so. The 1/2, 4, 3 I regard
as parameters which I don't have very strong opinions on which could be
set based on observations in the network today (e.g. adjusted so that a
normal cleaning transaction can hit the minimum size).  One way to think
about this is that it makes it so that every output you create "prepays"
the transaction fees needed to spend it by shifting "space" from the
current block to a future block. The fact that the prepayment is not
perfectly efficient reduces the incentive for miners to create lots of
extra outputs when they have room left in their block in order to store
space to use later [an issue that is potentially less of a concern with a
dynamic size limit].  With the right parameters there would never be such
at thing as a dust output (one which costs more to spend than its worth).

(likewise the sigops limit should be counted correctly and turned into
size augmentation (ones that get run by the txn); which would greatly
simplify selection rules: maximize income within a single scalar limit)

(*) I believe my currently favored formulation of general dynamic control
idea is that each miner expresses in their coinbase a preferred size
between some minimum (e.g. 500k) and the miner's effective-maximum;
the actual block size can be up to the effective maximum even if the
preference is lower (you're not forced to make a lower block because you
stated you wished the limit were lower).  There is a computed maximum
which is the 33-rd percentile of the last 2016 coinbase preferences
minus computed_max/52 (rounding up to 1) bytes-- or 500k if thats
larger. The effective maximum is X bytes more, where X on the range
[0, computed_maximum] e.g. the miner can double the size of their
block at most. If X > 0, then the miners must also reach a target
F(x/computed_maximum) times the bits-difficulty; with F(x) = x^2+1  ---
so the maximum penalty is 2, with a quadratic shape;  for a given mempool
there will be some value that maximizes expected income.  (obviously all
implemented with precise fixed point arithmetic).   The percentile is
intended to give the preferences of the 33% least preferring miners a
veto on increases (unless a majority chooses to soft-fork them out). The
minus-comp_max/52 provides an incentive to slowly shrink the maximum
if its too large-- x/52 would halve the size in one year if miners
were doing the lowest difficulty mining. The parameters 500k/33rd,
-computed_max/52 bytes, and f(x)  I have less strong opinions about;
and would love to hear reasoned arguments for particular parameters.



From pete at petertodd.org  Sat May  9 09:12:01 2015
From: pete at petertodd.org (Peter Todd)
Date: Sat, 9 May 2015 05:12:01 -0400
Subject: [Bitcoin-development] CLTV opcode allocation; long-term plans?
In-Reply-To: <CADJgMzs3D=6pNOQhU3ubi6=C8javRtwL0VuGFWvU+6SiuB0YWg@mail.gmail.com>
References: <20150504050715.GA18856@savin.petertodd.org>
	<CADJgMzs3D=6pNOQhU3ubi6=C8javRtwL0VuGFWvU+6SiuB0YWg@mail.gmail.com>
Message-ID: <20150509091201.GA15088@savin.petertodd.org>

On Tue, May 05, 2015 at 01:54:33AM +0100, Btc Drak wrote:
> > That said, if people have strong feelings about this, I would be willing
> > to make OP_CLTV work as follows:
> >
> >     <nLockTime> 1 OP_CLTV
> >
> > Where the 1 selects absolute mode, and all others act as OP_NOP's. A
> > future relative CLTV could then be a future soft-fork implemented as
> > follows:
> >
> >     <relative nLockTime> 2 OP_CLTV
> >
> > On the bad side it'd be two or three days of work to rewrite all the
> > existing tests and example code and update the BIP, and (slightly) gets
> > us away from the well-tested existing implementation. It also may
> > complicate the codebase compared to sticking with just doing a Script
> > v2.0, with the additional execution environment data required for v2.0
> > scripts cleanly separated out. But all in all, the above isn't too big
> > of a deal.
> 
> 
> Adding a parameter to OP_CLTV makes it much more flexible and is the most
> economic use of precious NOPs.
> The extra time required is ok and it would be good to make this change to
> the PR in time for the feature freeze.

Done!

https://github.com/bitcoin/bitcoin/pull/5496#issuecomment-100454263

-- 
'peter'[:-1]@petertodd.org
000000000000000012c438a597ad15df697888be579f4f818a30517cd60fbdc8
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150509/a5c24bb8/attachment.sig>

From gavinandresen at gmail.com  Sat May  9 11:58:20 2015
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Sat, 9 May 2015 07:58:20 -0400
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CAAS2fgQRS7w7RRNXVK_+=4CQ7=AWxWQQ7+Tf4tNUPTTZOf7rEQ@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CAOG=w-szbLgc1jLpkE_uMa3bkFTi-RiBEaQ6Y-u5aKLBC2HvUg@mail.gmail.com>
	<CAAS2fgQRS7w7RRNXVK_+=4CQ7=AWxWQQ7+Tf4tNUPTTZOf7rEQ@mail.gmail.com>
Message-ID: <CABsx9T0Y84CSb-RohV1Cy=qYyFK0LYN0t-wbhkTt4wqhD5GpgQ@mail.gmail.com>

RE: fixing sigop counting, and building in UTXO cost: great idea! One of
the problems with this debate is it is easy for great ideas get lost in all
the noise.

RE: a hard upper limit, with a dynamic limit under it:

I like that idea. Can we drill down on the hard upper limit?

There are lots of people who want a very high upper limit, right now (all
the big Bitcoin companies, and anybody who thinks as-rapid-as-possible
growth now is the best path to long-term success). This is the "it is OK if
you have to run full nodes in a data center" camp.

There are also lots of people who want an upper limit low enough that they
can continue to run Bitcoin on the hardware and Internet connection that
they have (or are concerned about centralization, so want to make sure
OTHER people can continue to run....).

Is there an upper limit "we" can choose to make both sets of people mostly
happy? I've proposed "must be inexpensive enough that a 'hobbyist' can
afford to run a full node" ...

Is the limit chosen once, now, via hard-fork, or should we expect multiple
hard-forks to change it "when necessary" ?

The economics change every time the block reward halves, which make me
think that might be a good time to adjust the hard upper limit. If we have
a hard upper limit and a lower dynamic limit, perhaps adjusting the hard
upper limit (up or down) to account for the block reward halving, based on
the dynamic limit....



RE: the lower dynamic limit algorithm:  I REALLY like that idea.

-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150509/e371ad58/attachment.html>

From onelineproof at gmail.com  Sat May  9 12:02:48 2015
From: onelineproof at gmail.com (Andrew)
Date: Sat, 9 May 2015 12:02:48 +0000
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CADZB0_bK+YsK8sN-di2pynvjsq5VjSvnEu0-cCGhPqFunyVm7Q@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<554BA032.4040405@bluematt.me>
	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>
	<CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>
	<CANEZrP39jWHLF02z-81Z4+9X1vH5+hMuS=-3ED81=Q1o9U=DKw@mail.gmail.com>
	<554BBDA2.7040508@gmail.com>
	<CAJHLa0NcxOHkrtW2=-JgfsXQJkCO8Ym7icBwMx_2RsaWcPBnTw@mail.gmail.com>
	<554CCF56.3000604@gmail.com>
	<CAL8tG=kA7V5wuRB9ob9ue4XAwGpkhh_yO_-EWDkYstV0q4PR5A@mail.gmail.com>
	<CALf2ePx-m+Of-kkWnUpVboiWxsnbTdWyT45eBAziJtbsL_P41Q@mail.gmail.com>
	<CADZB0_bK+YsK8sN-di2pynvjsq5VjSvnEu0-cCGhPqFunyVm7Q@mail.gmail.com>
Message-ID: <CAL8tG=nu30RPgvHtz+uC+-+oi-Wf5OmSsQNYbngt4gaxsHHnyQ@mail.gmail.com>

The nice thing about 1 MB is that you can store ALL bitcoin transactions
relevant to your lifetime (~100 years) on one 5 TB hard drive
(1*6*24*365*100=5256000). Any regular person can run a full node and store
this 5 TB hard drive easily at their home. With 10 MB blocks you need a 50
TB drive just for your bitcoin transactions! This is not doable for most
regular people due to space and monetary constraints. Being able to review
all transactions relevant to your lifetime is one of the key important
properties of Bitcoin. How else can people audit the financial transactions
of companies and governments that are using the Bitcoin blockchain? How
else can we achieve this level of transparency that is essential to keeping
corrupt governments/companies in check? How else can we keep track of our
own personal transactions without relying on others to keep track of them
for us? As time passes, storage technology may increase, but so may human
life expectancy. So yes, in this sense, 1 MB just may be the magic number.

Assuming that we have a perfectly functional off-chain transaction system,
what do we actually gain by going from 1 MB to 1000 MB (my approximate
limit for regular users having enough processing power)? If there is no
clear and substantial gain, then it is foolish to venture into this
territory, i.e. KEEP IT AT 1 MB! For example Angel said he wants to see
computers transacting with computers at super speeds. Why do you need to do
this on the main chain? You will lose all the transparency of the current
system, an essential feature.


On Fri, May 8, 2015 at 10:36 PM, Angel Leon <gubatron at gmail.com> wrote:

> I believe 100MB is still very conservative, I think that's barely 666 tps.
>
> I also find it not very creative that people are imagining these limits
> for 10 billion people using bitcoin, I think bitcoin's potential is
> realized with computers transacting with computers, which can eat those 666
> tps in a single scoup (what if bittorrent developers got creative with
> seeding, or someone created a decentralized paid itunes on top of bitcoin,
> or the openbazaar developers actually pulled a decentralized amazon with no
> off-chain transaction since they want the thing to be fully decentralized,
> bitcoin would collapse right away)
>
> I truly hope people see past regular people running nodes at home, that's
> never going to happen. This should be about the miner's networking, storage
> and cpu capacity. They will have gigabit access, they will have shitload of
> storage, and they already have plenty of processing power, all of which are
> only going to get cheaper.
>
> In order to have the success we all dream we'll need gigabit blocks. Let's
> hope adoption remains slow.
>
> http://twitter.com/gubatron
>
> On Fri, May 8, 2015 at 1:51 PM, Alan Reiner <etotheipi at gmail.com> wrote:
>
>> Actually I believe that side chains and off-main-chain transactions will
>> be a critical part for the overall scalability of the network.  I was
>> actually trying to make the point that (insert some huge block size here)
>> will be needed to even accommodate the reduced traffic.
>>
>> I believe that it is definitely over 20MB. If it was determined to be 100
>> MB ten years from now, that wouldn't surprise me.
>>
>> Sent from my overpriced smartphone
>> On May 8, 2015 1:17 PM, "Andrew" <onelineproof at gmail.com> wrote:
>>
>>>
>>>
>>> On Fri, May 8, 2015 at 2:59 PM, Alan Reiner <etotheipi at gmail.com> wrote:
>>>
>>>>
>>>> This isn't about "everyone's coffee".  This is about an absolute
>>>> minimum amount of participation by people who wish to use the network.   If
>>>> our goal is really for bitcoin to really be a global, open transaction
>>>> network that makes money fluid, then 7tps is already a failure.  If even 5%
>>>> of the world (350M people) was using the network for 1 tx per month
>>>> (perhaps to open payment channels, or shift money between side chains),
>>>> we'll be above 100 tps.  And that doesn't include all the non-individuals
>>>> (organizations) that want to use it.
>>>>
>>>
>>>> The goals of "a global transaction network" and "everyone must be able
>>>> to run a full node with their $200 dell laptop" are not compatible.  We
>>>> need to accept that a global transaction system cannot be fully/constantly
>>>> audited by everyone and their mother.  The important feature of the network
>>>> is that it is open and anyone *can* get the history and verify it.  But not
>>>> everyone is required to.   Trying to promote a system wher000e the history
>>>> can be forever handled by a low-end PC is already falling out of reach,
>>>> even with our miniscule 7 tps.  Clinging to that goal needlessly limits the
>>>> capability for the network to scale to be a useful global payments system
>>>>
>>>
>>> These are good points and got me thinking (but I think you're wrong). If
>>> we really want each of the 10 billion people soon using bitcoin once per
>>> month, that will require 500MB blocks. That's about 2 TB per month. And if
>>> you relay it to 4 peers, it's 10 TB per month. Which I suppose is doable
>>> for a home desktop, so you can just run a pruned full node with all
>>> transactions from the past month. But how do you sync all those
>>> transactions if you've never done this before or it's been a while since
>>> you did? I think it currently takes at least 3 hours to fully sync 30 GB of
>>> transactions. So 2 TB will take 8 days, then you take a bit more time to
>>> sync the days that passed while you were syncing. So that's doable, but at
>>> a certain point, like 10 TB per month (still only 5 transactions per month
>>> per person), you will need 41 days to sync that month, so you will never
>>> catch up. So I think in order to keep the very important property of anyone
>>> being able to start clean and verify the thing, then we need to think of
>>> bitcoin as a system that does transactions for a large number of users at
>>> once in one transaction, and not a system where each person will make a
>>> ~monthly transaction on. We need to therefore rely on sidechains,
>>> treechains, lightning channels, etc...
>>>
>>> I'm not a bitcoin wizard and this is just my second post on this mailing
>>> list, so I may be missing something. So please someone, correct me if I'm
>>> wrong.
>>>
>>>>
>>>>
>>>>
>>>> On 05/07/2015 03:54 PM, Jeff Garzik wrote:
>>>>
>>>>  On Thu, May 7, 2015 at 3:31 PM, Alan Reiner <etotheipi at gmail.com>
>>>> wrote:
>>>>
>>>>
>>>>>  (2) Leveraging fee pressure at 1MB to solve the problem is actually
>>>>> really a bad idea.  It's really bad while Bitcoin is still growing, and
>>>>> relying on fee pressure at 1 MB severely impacts attractiveness and
>>>>> adoption potential of Bitcoin (due to high fees and unreliability).  But
>>>>> more importantly, it ignores the fact that for a 7 tps is pathetic for a
>>>>> global transaction system.  It is a couple orders of magnitude too low for
>>>>> any meaningful commercial activity to occur.  If we continue with a cap of
>>>>> 7 tps forever, Bitcoin *will* fail.  Or at best, it will fail to be
>>>>> useful for the vast majority of the world (which probably leads to
>>>>> failure).  We shouldn't be talking about fee pressure until we hit 700 tps,
>>>>> which is probably still too low.
>>>>>
>>>>  [...]
>>>>
>>>>  1) Agree that 7 tps is too low
>>>>
>>>>  2) Where do you want to go?  Should bitcoin scale up to handle all
>>>> the world's coffees?
>>>>
>>>>  This is hugely unrealistic.  700 tps is 100MB blocks, 14.4 GB/day --
>>>> just for a single feed.  If you include relaying to multiple nodes, plus
>>>> serving 500 million SPV clients en grosse, who has the capacity to run such
>>>> a node?  By the time we get to fee pressure, in your scenario, our network
>>>> node count is tiny and highly centralized.
>>>>
>>>>  3) In RE "fee pressure" -- Do you see the moral hazard to a
>>>> software-run system?  It is an intentional, human decision to flood the
>>>> market with supply, thereby altering the economics, forcing fees to remain
>>>> low in the hopes of achieving adoption.  I'm pro-bitcoin and obviously want
>>>> to see bitcoin adoption - but I don't want to sacrifice every decentralized
>>>> principle and become a central banker in order to get there.
>>>>
>>>>
>>>>
>>>>
>>>> ------------------------------------------------------------------------------
>>>> One dashboard for servers and applications across Physical-Virtual-Cloud
>>>> Widest out-of-the-box monitoring support with 50+ applications
>>>> Performance metrics, stats and reports that give you Actionable Insights
>>>> Deep dive visibility with transaction tracing using APM Insight.
>>>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>>>> _______________________________________________
>>>> Bitcoin-development mailing list
>>>> Bitcoin-development at lists.sourceforge.net
>>>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>>>
>>>>
>>>
>>>
>>> --
>>> PGP: B6AC 822C 451D 6304 6A28  49E9 7DB7 011C D53B 5647
>>>
>>
>>
>> ------------------------------------------------------------------------------
>> One dashboard for servers and applications across Physical-Virtual-Cloud
>> Widest out-of-the-box monitoring support with 50+ applications
>> Performance metrics, stats and reports that give you Actionable Insights
>> Deep dive visibility with transaction tracing using APM Insight.
>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>>
>


-- 
PGP: B6AC 822C 451D 6304 6A28  49E9 7DB7 011C D53B 5647
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150509/9856a5a5/attachment.html>

From justusranvier at riseup.net  Sat May  9 12:53:48 2015
From: justusranvier at riseup.net (Justus Ranvier)
Date: Sat, 09 May 2015 14:53:48 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CAL8tG=nu30RPgvHtz+uC+-+oi-Wf5OmSsQNYbngt4gaxsHHnyQ@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>	<554BA032.4040405@bluematt.me>	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>	<CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>	<CANEZrP39jWHLF02z-81Z4+9X1vH5+hMuS=-3ED81=Q1o9U=DKw@mail.gmail.com>	<554BBDA2.7040508@gmail.com>	<CAJHLa0NcxOHkrtW2=-JgfsXQJkCO8Ym7icBwMx_2RsaWcPBnTw@mail.gmail.com>	<554CCF56.3000604@gmail.com>	<CAL8tG=kA7V5wuRB9ob9ue4XAwGpkhh_yO_-EWDkYstV0q4PR5A@mail.gmail.com>	<CALf2ePx-m+Of-kkWnUpVboiWxsnbTdWyT45eBAziJtbsL_P41Q@mail.gmail.com>	<CADZB0_bK+YsK8sN-di2pynvjsq5VjSvnEu0-cCGhPqFunyVm7Q@mail.gmail.com>
	<CAL8tG=nu30RPgvHtz+uC+-+oi-Wf5OmSsQNYbngt4gaxsHHnyQ@mail.gmail.com>
Message-ID: <554E035C.5090200@localhost.local>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 05/09/2015 02:02 PM, Andrew wrote:
> The nice thing about 1 MB is that you can store ALL bitcoin
> transactions relevant to your lifetime (~100 years) on one 5 TB
> hard drive (1*6*24*365*100=5256000). Any regular person can run a
> full node and store this 5 TB hard drive easily at their home. With
> 10 MB blocks you need a 50 TB drive just for your bitcoin
> transactions! This is not doable for most regular people due to
> space and monetary constraints. Being able to review all
> transactions relevant to your lifetime is one of the key important 
> properties of Bitcoin. How else can people audit the financial
> transactions of companies and governments that are using the
> Bitcoin blockchain? How else can we achieve this level of
> transparency that is essential to keeping corrupt
> governments/companies in check? How else can we keep track of our 
> own personal transactions without relying on others to keep track
> of them for us? As time passes, storage technology may increase,
> but so may human life expectancy. So yes, in this sense, 1 MB just
> may be the magic number.

How many individuals and companies do you propose will ever use
Bitcoin (order of magnitude estimates are fine)

Whatever number you select above, please describe approximately how
many lifetime Bitcoin transactions each individual and company will be
capable of performing with a 1 MB block size limit.

-----BEGIN PGP SIGNATURE-----

iQIcBAEBAgAGBQJVTgNcAAoJECpf2nDq2eYjM8AP/2kwSF+HMPR1KdaZsATL4rog
xSS97Q5iEX8StA61jUqHQmpXL5pG6z5DeeKT/liwcMnYnVqOEOLvoVctr3gXfgRz
9GJeTOlmN5l9xBeX/nWa0A2ql0kWZpYolBS1FwYadWReAD8R0X9UeBd9YXLZNy33
Ow9JjwRjKHhsuyrlMP8pRDKlGPoa/U+2aW4FwiysMLa0Gu6dbFjTrp3bHw4Fccpi
X0E/aDN68U4FV+lZ4NzkMsBK9VARzmC8KI0DQ540pqfkcnyoYf0VERl/gslPWhfq
t6Rqa7vHHMqFe82lgCd3ji8Qhsz8oBrDS4u4jqwATvgihgImOB6K85JoKmf3y2JS
jByjMGd4Ep0F80Z2MRhi6HuEoRU69uY2u6l9bZxMjzvLX8sG6QTNk3uLMS3ARXcY
JBjZ/g13DXgcRj01fq05CHbCTJYZgTA9pRZTY+ZKH4r0mu86b9ua7hjvyKHS6q54
uaFmRkNcnKlpCY+fvH/JUdvvmwrA0ETUdHhRyk8vzWIMi+aH4//GwrCmBNRrugzv
9JtQ1BC+tQqtSX2VkFEhAVISitgkBqurVVlGk18FvVKPFO8cnFS/6NWoPE0WLLzW
2pTuhEPjdz9UAHD3RW601rb4C0LbuwVlGO4tYBjyqCmk/vBlES2XIjQKctXZLBEy
eLgn3gMwEXUTU6UdGyvb
=RPhK
-----END PGP SIGNATURE-----
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0xEAD9E623.asc
Type: application/pgp-keys
Size: 18381 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150509/e46db937/attachment.bin>

From tier.nolan at gmail.com  Sat May  9 13:49:53 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Sat, 9 May 2015 14:49:53 +0100
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CABsx9T0Y84CSb-RohV1Cy=qYyFK0LYN0t-wbhkTt4wqhD5GpgQ@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CAOG=w-szbLgc1jLpkE_uMa3bkFTi-RiBEaQ6Y-u5aKLBC2HvUg@mail.gmail.com>
	<CAAS2fgQRS7w7RRNXVK_+=4CQ7=AWxWQQ7+Tf4tNUPTTZOf7rEQ@mail.gmail.com>
	<CABsx9T0Y84CSb-RohV1Cy=qYyFK0LYN0t-wbhkTt4wqhD5GpgQ@mail.gmail.com>
Message-ID: <CAE-z3OVcXN4d9HFds_w90+g_ZhrVrFdveiRFX8_d9etVgAqW-g@mail.gmail.com>

On Sat, May 9, 2015 at 12:58 PM, Gavin Andresen <gavinandresen at gmail.com>
wrote:

> RE: fixing sigop counting, and building in UTXO cost: great idea! One of
> the problems with this debate is it is easy for great ideas get lost in all
> the noise.
>

If the UTXO set cost is built in, UTXO database entries suddenly are worth
something, in addition to the bitcoin held in that entry.

A user's client might display how many they own.  When sending money to a
merchant, the user might demand the merchant indicate a slot to pay to.

The user could send an ANYONE_CAN_PAY partial transaction.  The transaction
would guarantee that the user has at least as many UTXOs as before.

Discussing the possibility of doing this creates an incentive to bloat the
UTXO set right now, since UTXOs would be valuable in the future.

The objective would be to make them valuable enough to encourage
conservation, but not so valuable that the UTXO contains more value than
the bitcoins in the output.

Gmaxwell's suggested "tx_size = MAX( real_size >> 1,  real_size +
4*utxo_created_size - 3*utxo_consumed_size)" for a 250 byte transaction
with 1 input and 2 outputs has very little effect.

real_size + 4 * (2) - 3 * 1 = 255

That gives a 2% size penalty for adding an extra UTXO.  I doubt that is
enough to change behavior.

The UTXO set growth could be limited directly.  A block would be invalid if
it increases the number of UTXO entries above the charted path.

RE: a hard upper limit, with a dynamic limit under it:
>

If the block is greater than 32MB, then it means an update to how blocks
are broadcast, so that could be a reasonable hard upper limit (or maybe
31MB, or just the 20MB already suggested).
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150509/ffd834c1/attachment.html>

From pete at petertodd.org  Sat May  9 16:39:24 2015
From: pete at petertodd.org (Peter Todd)
Date: Sat, 9 May 2015 12:39:24 -0400
Subject: [Bitcoin-development] Bitcoin-development Digest, Vol 48,
 Issue 41
In-Reply-To: <CAAS2fgTA21W9T=2Nmy+zQp2AhG5Gk+vF=w5X5Pm3ohZz7pJNVg@mail.gmail.com>
References: <mailman.63969.1431119326.18600.bitcoin-development@lists.sourceforge.net>
	<CAH+jCTye9QNVV8bv6ZAgEPcrE5K1J-q7gONE_m1x81+-5mpWHA@mail.gmail.com>
	<CAH+jCTwxjfEVog4JR+8kCvbBPoT50f322NV3T+8Bz-sTnK-yXQ@mail.gmail.com>
	<CAH+jCTy=BF4g=7yTFYind3ZNiWz4uLo1puv1+RURi=26oqcD1Q@mail.gmail.com>
	<CAAS2fgTA21W9T=2Nmy+zQp2AhG5Gk+vF=w5X5Pm3ohZz7pJNVg@mail.gmail.com>
Message-ID: <20150509163924.GA7496@savin.petertodd.org>

On Sat, May 09, 2015 at 12:42:08AM +0000, Gregory Maxwell wrote:
> On Sat, May 9, 2015 at 12:00 AM, Damian Gomez <dgomez1092 at gmail.com> wrote:
> > where w represents the weight of the total number of semantical
> > constraints that an idivdual has expressed throught emotivoe packets that I
> > am working on (implementation os difficutlt).  I think this is the
> > appropriate route to implemeting a greating block size that will be used in
> > preventing interception of bundled informations and replace value.  Client
> > side implmentation will cut down transaction fees for the additional 264 bit
> > implementation and greatly reduce need for ewallet providers to do so.
> 
> In these posts I am reminded of and sense some qualitative
> similarities with a 2012 proposal by Mr. NASDAQEnema of Bitcointalk
> with respect to multigenerational token architectures. In particula,r
> your AES ModuleK Hashcodes (especially in light of Winternitz
> compression) may constitute an L_2 norm attractor similar to the
> motherbase birthpoint metric presented in that prior work.  Rethaw and
> I provided a number of points for consideration which may be equally
> applicable to your work:
> https://bitcointalk.org/index.php?topic=57253.msg682056#msg682056

Mr Gomez may find my thesis paper on the creation of imitations of
reality with the mathematical technique of Bolshevik Statistics (BS) to
be of aid: https://s3.amazonaws.com/peter.todd/congestion.pdf

-- 
'peter'[:-1]@petertodd.org
000000000000000000b0388c459b9aff8a93d02bbb87aac6d74b65e9faf7e4c9
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150509/f1d68e0b/attachment.sig>

From jim at ergophobia.org  Sat May  9 17:09:32 2015
From: jim at ergophobia.org (Jim Phillips)
Date: Sat, 9 May 2015 12:09:32 -0500
Subject: [Bitcoin-development] A suggestion for reducing the size of the
	UTXO database
Message-ID: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>

Forgive me if this idea has been suggested before, but I made this
suggestion on reddit and I got some feedback recommending I also bring it
to this list -- so here goes.

I wonder if there isn't perhaps a simpler way of dealing with UTXO growth.
What if, rather than deal with the issue at the protocol level, we deal
with it at the source of the problem -- the wallets. Right now, the typical
wallet selects only the minimum number of unspent outputs when building a
transaction. The goal is to keep the transaction size to a minimum so that
the fee stays low. Consequently, lots of unspent outputs just don't get
used, and are left lying around until some point in the future.

What if we started designing wallets to consolidate unspent outputs? When
selecting unspent outputs for a transaction, rather than choosing just the
minimum number from a particular address, why not select them ALL? Take all
of the UTXOs from a particular address or wallet, send however much needs
to be spent to the payee, and send the rest back to the same address or a
change address as a single output? Through this method, we should wind up
shrinking the UTXO database over time rather than growing it with each
transaction. Obviously, as Bitcoin gains wider adoption, the UTXO database
will grow, simply because there are 7 billion people in the world, and
eventually a good percentage of them will have one or more wallets with
spendable bitcoin. But this idea could limit the growth at least.

The vast majority of users are running one of a handful of different wallet
apps: Core, Electrum; Armory; Mycelium; Breadwallet; Coinbase; Circle;
Blockchain.info; and maybe a few others. The developers of all these
wallets have a vested interest in the continued usefulness of Bitcoin, and
so should not be opposed to changing their UTXO selection algorithms to one
that reduces the UTXO database instead of growing it.

>From the miners perspective, even though these types of transactions would
be larger, the fee could stay low. Miners actually benefit from them in
that it reduces the amount of storage they need to dedicate to holding the
UTXO. So miners are incentivized to mine these types of transactions with a
higher priority despite a low fee.

Relays could also get in on the action and enforce this type of behavior by
refusing to relay or deprioritizing the relay of transactions that don't
use all of the available UTXOs from the addresses used as inputs. Relays
are not only the ones who benefit the most from a reduction of the UTXO
database, they're also in the best position to promote good behavior.

--
*James G. Phillips IV*
<https://plus.google.com/u/0/113107039501292625391/posts>

*"Don't bunt. Aim out of the ball park. Aim for the company of immortals."
-- David Ogilvy*

 *This message was created with 100% recycled electrons. Please think twice
before printing.*
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150509/ca3f5937/attachment.html>

From pete at petertodd.org  Sat May  9 18:30:31 2015
From: pete at petertodd.org (Peter Todd)
Date: Sat, 9 May 2015 14:30:31 -0400
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
 function
In-Reply-To: <CAGKSKfVf6h6icETjfg1joWneiTYob0CTxLDQK-7Pob3+dh_nKQ@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CAP63atbdFSw0rDeuwgtjsDYsXnKSHNN9=zedzip2MsZ0hSY59w@mail.gmail.com>
	<CAGKSKfW7fJB6n3B-OoyXOep7hAQqWGGDTiZCkpJ7vXxWRFgveA@mail.gmail.com>
	<20150508165144.GC27417@savin.petertodd.org>
	<CAGKSKfVf6h6icETjfg1joWneiTYob0CTxLDQK-7Pob3+dh_nKQ@mail.gmail.com>
Message-ID: <20150509183031.GG4948@muck>

On Sat, May 09, 2015 at 01:36:56AM +0300, Joel Joonatan Kaartinen wrote:
> such a contract is a possibility, but why would big owners give an
> exclusive right to such pools? It seems to me it'd make sense to offer
> those for any miner as long as the get paid a little for it. Especially
> when it's as simple as offering an incomplete transaction with the
> appropriate SIGHASH flags.

Like many things, the fact that they need to negotiate the right at all
is a *huge* barrier to smaller mining operations, as well as being an
attractive point of control for regulators.

> a part of the reason I like this idea is because it will allow stakeholders
> a degree of influence on how large the fees are. At least from the surface,
> it looks like incentives are pretty well matched. They have an incentive to
> not let the fees drop too low so the network continues to be usable and
> they also have an incentive to not raise them too high because it'll push
> users into using other systems. Also, there'll be competition between
> stakeholders, which should keep the fees reasonable.

If you want to allow stakeholders influence you should look into John Dillon's
proof-of-stake blocksize voting scheme:

http://www.mail-archive.com/bitcoin-development at lists.sourceforge.net/msg02323.html

-- 
'peter'[:-1]@petertodd.org
00000000000000000e7980aab9c096c46e7f34c43a661c5cb2ea71525ebb8af7
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150509/1d6c3b4f/attachment.sig>

From onelineproof at gmail.com  Sat May  9 18:33:32 2015
From: onelineproof at gmail.com (Andrew)
Date: Sat, 9 May 2015 18:33:32 +0000
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <554E035C.5090200@localhost.local>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<554BA032.4040405@bluematt.me>
	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>
	<CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>
	<CANEZrP39jWHLF02z-81Z4+9X1vH5+hMuS=-3ED81=Q1o9U=DKw@mail.gmail.com>
	<554BBDA2.7040508@gmail.com>
	<CAJHLa0NcxOHkrtW2=-JgfsXQJkCO8Ym7icBwMx_2RsaWcPBnTw@mail.gmail.com>
	<554CCF56.3000604@gmail.com>
	<CAL8tG=kA7V5wuRB9ob9ue4XAwGpkhh_yO_-EWDkYstV0q4PR5A@mail.gmail.com>
	<CALf2ePx-m+Of-kkWnUpVboiWxsnbTdWyT45eBAziJtbsL_P41Q@mail.gmail.com>
	<CADZB0_bK+YsK8sN-di2pynvjsq5VjSvnEu0-cCGhPqFunyVm7Q@mail.gmail.com>
	<CAL8tG=nu30RPgvHtz+uC+-+oi-Wf5OmSsQNYbngt4gaxsHHnyQ@mail.gmail.com>
	<554E035C.5090200@localhost.local>
Message-ID: <CAL8tG=noRz+SJzbjZ5agDrE5sBSmXn9nojpHSseZSO+Oba1mUQ@mail.gmail.com>

On Sat, May 9, 2015 at 12:53 PM, Justus Ranvier <justusranvier at riseup.net>
wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 05/09/2015 02:02 PM, Andrew wrote:
> > The nice thing about 1 MB is that you can store ALL bitcoin
> > transactions relevant to your lifetime (~100 years) on one 5 TB
> > hard drive (1*6*24*365*100=5256000). Any regular person can run a
> > full node and store this 5 TB hard drive easily at their home. With
> > 10 MB blocks you need a 50 TB drive just for your bitcoin
> > transactions! This is not doable for most regular people due to
> > space and monetary constraints. Being able to review all
> > transactions relevant to your lifetime is one of the key important
> > properties of Bitcoin. How else can people audit the financial
> > transactions of companies and governments that are using the
> > Bitcoin blockchain? How else can we achieve this level of
> > transparency that is essential to keeping corrupt
> > governments/companies in check? How else can we keep track of our
> > own personal transactions without relying on others to keep track
> > of them for us? As time passes, storage technology may increase,
> > but so may human life expectancy. So yes, in this sense, 1 MB just
> > may be the magic number.
>
> How many individuals and companies do you propose will ever use
> Bitcoin (order of magnitude estimates are fine)
>
> Whatever number you select above, please describe approximately how
> many lifetime Bitcoin transactions each individual and company will be
> capable of performing with a 1 MB block size limit.
>

I would expect at least 10 billion people (directly or indirectly) to be
using it at once for at least 100 years. But I think it's pointless to
guess how many will use it, but rather make the system ready for 10 billion
people. The point is that for small transactions, they will be done
off-chain. The actual Bitcoin blockchain will only show very large
transactions (such as a military purchasing a new space shuttle) or
aggregate transactions (i.e. a transaction consisting of multiple smaller
transactions done off-chain). There can also be multiple layers of chains
creating a tree-like structure. Each chain above will validate the
aggregate transactions of the chain below. You can think of the Bitcoin
blockchain as the "hypervisor" that manages all the other chains. While
your coffee purchase 4 days ago may not be directly visible within the
Bitcoin blockchain (the main chain), you can trace it down the sequence of
chains until you find it. Same with that fancy dinner your government MP
paid for using public funds. You don't have to store a copy of all
transactions that occurred for each chain in existence, but rather just the
transactions for the chains that you use or are relevant to you.

As you see, this kind of system is totally transparent to all users and
totally flexible (you can choose your sub chains). The flexibility also
allows you to have arbitrarily fast transactions (choose a chain or
lightning channel attached to that chain that supports it), and you can
enjoy a wide variety of features from other chains, like using one chain
that is known to have good anonymity properties.


> -----BEGIN PGP SIGNATURE-----
>
> iQIcBAEBAgAGBQJVTgNcAAoJECpf2nDq2eYjM8AP/2kwSF+HMPR1KdaZsATL4rog
> xSS97Q5iEX8StA61jUqHQmpXL5pG6z5DeeKT/liwcMnYnVqOEOLvoVctr3gXfgRz
> 9GJeTOlmN5l9xBeX/nWa0A2ql0kWZpYolBS1FwYadWReAD8R0X9UeBd9YXLZNy33
> Ow9JjwRjKHhsuyrlMP8pRDKlGPoa/U+2aW4FwiysMLa0Gu6dbFjTrp3bHw4Fccpi
> X0E/aDN68U4FV+lZ4NzkMsBK9VARzmC8KI0DQ540pqfkcnyoYf0VERl/gslPWhfq
> t6Rqa7vHHMqFe82lgCd3ji8Qhsz8oBrDS4u4jqwATvgihgImOB6K85JoKmf3y2JS
> jByjMGd4Ep0F80Z2MRhi6HuEoRU69uY2u6l9bZxMjzvLX8sG6QTNk3uLMS3ARXcY
> JBjZ/g13DXgcRj01fq05CHbCTJYZgTA9pRZTY+ZKH4r0mu86b9ua7hjvyKHS6q54
> uaFmRkNcnKlpCY+fvH/JUdvvmwrA0ETUdHhRyk8vzWIMi+aH4//GwrCmBNRrugzv
> 9JtQ1BC+tQqtSX2VkFEhAVISitgkBqurVVlGk18FvVKPFO8cnFS/6NWoPE0WLLzW
> 2pTuhEPjdz9UAHD3RW601rb4C0LbuwVlGO4tYBjyqCmk/vBlES2XIjQKctXZLBEy
> eLgn3gMwEXUTU6UdGyvb
> =RPhK
> -----END PGP SIGNATURE-----
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>


-- 
PGP: B6AC 822C 451D 6304 6A28  49E9 7DB7 011C D53B 5647
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150509/cd84dd3d/attachment.html>

From pete at petertodd.org  Sat May  9 18:45:18 2015
From: pete at petertodd.org (Peter Todd)
Date: Sat, 9 May 2015 14:45:18 -0400
Subject: [Bitcoin-development] A suggestion for reducing the size of the
 UTXO database
In-Reply-To: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
Message-ID: <20150509184518.GA19703@muck>

On Sat, May 09, 2015 at 12:09:32PM -0500, Jim Phillips wrote:
> The vast majority of users are running one of a handful of different wallet
> apps: Core, Electrum; Armory; Mycelium; Breadwallet; Coinbase; Circle;
> Blockchain.info; and maybe a few others. The developers of all these
> wallets have a vested interest in the continued usefulness of Bitcoin, and
> so should not be opposed to changing their UTXO selection algorithms to one
> that reduces the UTXO database instead of growing it.

You can't assume that UTXO growth will be driven by walles at all; the
UTXO set's global consensus functionality is incredibly useful and will
certainly be used by all manner of applications, many having nothing to
do with Bitcoin.

As one of many examples, here's a proposal - with working code - to use
the UTXO set to get consensus over TLC certificate revocations. The
author, Christopher Allen, was one of the co-authors of the SSL
standard:

https://github.com/ChristopherA/revocable-self-signed-tls-certificates-hack

There's nothing we can do to stop these kinds of usages other than
forcing users to identify themselves to get permission to use the
Bitcoin blockchain. Using the Bitcoin blockchain gives their users
significantly better security in many cases than any alternatives, so
there's strong incentives to do so. Finally, the cost many of these
alternative uses are willing to pay pre UTXO/transaction is
significantly higher than the fees many existing Bitcoin users can pay
to make transactions.

-- 
'peter'[:-1]@petertodd.org
00000000000000000e7980aab9c096c46e7f34c43a661c5cb2ea71525ebb8af7
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150509/c9d8343d/attachment.sig>

From andreas at schildbach.de  Sat May  9 19:00:33 2015
From: andreas at schildbach.de (Andreas Schildbach)
Date: Sat, 09 May 2015 21:00:33 +0200
Subject: [Bitcoin-development] A suggestion for reducing the size of the
	UTXO database
In-Reply-To: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
Message-ID: <millgi$3uv$1@ger.gmane.org>

Actually your assumption is wrong. Bitcoin Wallet (and I think most, if
not all, other bitcoinj based wallets) picks UTXO by age, in order to
maximize priority. So it keeps the number of UTXOs low, though not as
low as if it would always pick *all* UTXOs.


On 05/09/2015 07:09 PM, Jim Phillips wrote:
> Forgive me if this idea has been suggested before, but I made this
> suggestion on reddit and I got some feedback recommending I also bring
> it to this list -- so here goes.
> 
> I wonder if there isn't perhaps a simpler way of dealing with UTXO
> growth. What if, rather than deal with the issue at the protocol level,
> we deal with it at the source of the problem -- the wallets. Right now,
> the typical wallet selects only the minimum number of unspent outputs
> when building a transaction. The goal is to keep the transaction size to
> a minimum so that the fee stays low. Consequently, lots of unspent
> outputs just don't get used, and are left lying around until some point
> in the future.
> 
> What if we started designing wallets to consolidate unspent outputs?
> When selecting unspent outputs for a transaction, rather than choosing
> just the minimum number from a particular address, why not select them
> ALL? Take all of the UTXOs from a particular address or wallet, send
> however much needs to be spent to the payee, and send the rest back to
> the same address or a change address as a single output? Through this
> method, we should wind up shrinking the UTXO database over time rather
> than growing it with each transaction. Obviously, as Bitcoin gains wider
> adoption, the UTXO database will grow, simply because there are 7
> billion people in the world, and eventually a good percentage of them
> will have one or more wallets with spendable bitcoin. But this idea
> could limit the growth at least.
> 
> The vast majority of users are running one of a handful of different
> wallet apps: Core, Electrum; Armory; Mycelium; Breadwallet; Coinbase;
> Circle; Blockchain.info; and maybe a few others. The developers of all
> these wallets have a vested interest in the continued usefulness of
> Bitcoin, and so should not be opposed to changing their UTXO selection
> algorithms to one that reduces the UTXO database instead of growing it.
> 
> From the miners perspective, even though these types of transactions
> would be larger, the fee could stay low. Miners actually benefit from
> them in that it reduces the amount of storage they need to dedicate to
> holding the UTXO. So miners are incentivized to mine these types of
> transactions with a higher priority despite a low fee.
> 
> Relays could also get in on the action and enforce this type of behavior
> by refusing to relay or deprioritizing the relay of transactions that
> don't use all of the available UTXOs from the addresses used as inputs.
> Relays are not only the ones who benefit the most from a reduction of
> the UTXO database, they're also in the best position to promote good
> behavior.
> 
> --
> *James G. Phillips
> IV* <https://plus.google.com/u/0/113107039501292625391/posts> 
> /"Don't bunt. Aim out of the ball park. Aim for the company of
> immortals." -- David Ogilvy
> /
> 
>  /This message was created with 100% recycled electrons. Please think
> twice before printing./
> 
> 
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud 
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> 
> 
> 
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> 





From jim at ergophobia.org  Sat May  9 19:02:11 2015
From: jim at ergophobia.org (Jim Phillips)
Date: Sat, 9 May 2015 14:02:11 -0500
Subject: [Bitcoin-development] A suggestion for reducing the size of the
 UTXO database
In-Reply-To: <20150509184518.GA19703@muck>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
	<20150509184518.GA19703@muck>
Message-ID: <CANe1mWycAwFzC3b7khd2EwCusyQEdg5g-pvdTadsLuASr7dHHg@mail.gmail.com>

On Sat, May 9, 2015 at 1:45 PM, Peter Todd <pete at petertodd.org> wrote:

> On Sat, May 09, 2015 at 12:09:32PM -0500, Jim Phillips wrote:
> > The vast majority of users are running one of a handful of different
> wallet
> > apps: Core, Electrum; Armory; Mycelium; Breadwallet; Coinbase; Circle;
> > Blockchain.info; and maybe a few others. The developers of all these
> > wallets have a vested interest in the continued usefulness of Bitcoin,
> and
> > so should not be opposed to changing their UTXO selection algorithms to
> one
> > that reduces the UTXO database instead of growing it.
>
> You can't assume that UTXO growth will be driven by walles at all; the
> UTXO set's global consensus functionality is incredibly useful and will
> certainly be used by all manner of applications, many having nothing to
> do with Bitcoin.
>

You're correct in this point. Future UTXO growth will be coming from all
directions. But I'm a believer in the idea that whatever can be done should
be done.  If we get Bitcoin devs into the mindset now that UTXOs are
expensive to those that have to store them, and that they should be good
netizens and do what they can to limit them, then hopefully that will ideal
will be passed down to future developers. I don't believe consolidating
UTXOs in the wallet is the only solution.. I just think it is a fairly easy
one to implement, and can only help the problem from getting worse in the
future.

--
*James G. Phillips IV*
<https://plus.google.com/u/0/113107039501292625391/posts>
<http://www.linkedin.com/in/ergophobe>

*"Don't bunt. Aim out of the ball park. Aim for the company of immortals."
-- David Ogilvy*

 *This message was created with 100% recycled electrons. Please think twice
before printing.*
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150509/b29ac4cb/attachment.html>

From jim at ergophobia.org  Sat May  9 19:05:36 2015
From: jim at ergophobia.org (Jim Phillips)
Date: Sat, 9 May 2015 14:05:36 -0500
Subject: [Bitcoin-development] A suggestion for reducing the size of the
 UTXO database
In-Reply-To: <millgi$3uv$1@ger.gmane.org>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
	<millgi$3uv$1@ger.gmane.org>
Message-ID: <CANe1mWzEypArb_qjvYFJqk-4hQGH+03et8Zot=ZJYT9pYjrgTA@mail.gmail.com>

On Sat, May 9, 2015 at 2:00 PM, Andreas Schildbach <andreas at schildbach.de>
wrote:

> Actually your assumption is wrong. Bitcoin Wallet (and I think most, if
> not all, other bitcoinj based wallets) picks UTXO by age, in order to
> maximize priority. So it keeps the number of UTXOs low, though not as
> low as if it would always pick *all* UTXOs.
>
> Is it not fair to say though that UTXO database growth is not considered
when selecting the UTXOs to use? And that size of transaction is a priority
if not the top priority?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150509/4b3bb9c7/attachment.html>

From pieter.wuille at gmail.com  Sat May  9 19:06:13 2015
From: pieter.wuille at gmail.com (Pieter Wuille)
Date: Sat, 9 May 2015 12:06:13 -0700
Subject: [Bitcoin-development] A suggestion for reducing the size of the
 UTXO database
In-Reply-To: <millgi$3uv$1@ger.gmane.org>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
	<millgi$3uv$1@ger.gmane.org>
Message-ID: <CAPg+sBiNLtDNqHML1n7UJC_hYtYCOjBuYNh-bZT8msVh9UKFUg@mail.gmail.com>

It's a very complex trade-off, which is hard to optimize for all use cases.
Using more UTXOs requires larger transactions, and thus more fees in
general. In addition, it results in more linkage between coins/addresses
used, so lower privacy.

The only way you can guarantee an economical reason to keep the UTXO set
small is by actually having a consensus rule that punishes increasing its
size.
On May 9, 2015 12:02 PM, "Andreas Schildbach" <andreas at schildbach.de> wrote:

> Actually your assumption is wrong. Bitcoin Wallet (and I think most, if
> not all, other bitcoinj based wallets) picks UTXO by age, in order to
> maximize priority. So it keeps the number of UTXOs low, though not as
> low as if it would always pick *all* UTXOs.
>
>
> On 05/09/2015 07:09 PM, Jim Phillips wrote:
> > Forgive me if this idea has been suggested before, but I made this
> > suggestion on reddit and I got some feedback recommending I also bring
> > it to this list -- so here goes.
> >
> > I wonder if there isn't perhaps a simpler way of dealing with UTXO
> > growth. What if, rather than deal with the issue at the protocol level,
> > we deal with it at the source of the problem -- the wallets. Right now,
> > the typical wallet selects only the minimum number of unspent outputs
> > when building a transaction. The goal is to keep the transaction size to
> > a minimum so that the fee stays low. Consequently, lots of unspent
> > outputs just don't get used, and are left lying around until some point
> > in the future.
> >
> > What if we started designing wallets to consolidate unspent outputs?
> > When selecting unspent outputs for a transaction, rather than choosing
> > just the minimum number from a particular address, why not select them
> > ALL? Take all of the UTXOs from a particular address or wallet, send
> > however much needs to be spent to the payee, and send the rest back to
> > the same address or a change address as a single output? Through this
> > method, we should wind up shrinking the UTXO database over time rather
> > than growing it with each transaction. Obviously, as Bitcoin gains wider
> > adoption, the UTXO database will grow, simply because there are 7
> > billion people in the world, and eventually a good percentage of them
> > will have one or more wallets with spendable bitcoin. But this idea
> > could limit the growth at least.
> >
> > The vast majority of users are running one of a handful of different
> > wallet apps: Core, Electrum; Armory; Mycelium; Breadwallet; Coinbase;
> > Circle; Blockchain.info; and maybe a few others. The developers of all
> > these wallets have a vested interest in the continued usefulness of
> > Bitcoin, and so should not be opposed to changing their UTXO selection
> > algorithms to one that reduces the UTXO database instead of growing it.
> >
> > From the miners perspective, even though these types of transactions
> > would be larger, the fee could stay low. Miners actually benefit from
> > them in that it reduces the amount of storage they need to dedicate to
> > holding the UTXO. So miners are incentivized to mine these types of
> > transactions with a higher priority despite a low fee.
> >
> > Relays could also get in on the action and enforce this type of behavior
> > by refusing to relay or deprioritizing the relay of transactions that
> > don't use all of the available UTXOs from the addresses used as inputs.
> > Relays are not only the ones who benefit the most from a reduction of
> > the UTXO database, they're also in the best position to promote good
> > behavior.
> >
> > --
> > *James G. Phillips
> > IV* <https://plus.google.com/u/0/113107039501292625391/posts>
> > /"Don't bunt. Aim out of the ball park. Aim for the company of
> > immortals." -- David Ogilvy
> > /
> >
> >  /This message was created with 100% recycled electrons. Please think
> > twice before printing./
> >
> >
> >
> ------------------------------------------------------------------------------
> > One dashboard for servers and applications across Physical-Virtual-Cloud
> > Widest out-of-the-box monitoring support with 50+ applications
> > Performance metrics, stats and reports that give you Actionable Insights
> > Deep dive visibility with transaction tracing using APM Insight.
> > http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> >
> >
> >
> > _______________________________________________
> > Bitcoin-development mailing list
> > Bitcoin-development at lists.sourceforge.net
> > https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> >
>
>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150509/06cb545b/attachment.html>

From jim at ergophobia.org  Sat May  9 19:16:46 2015
From: jim at ergophobia.org (Jim Phillips)
Date: Sat, 9 May 2015 14:16:46 -0500
Subject: [Bitcoin-development] A suggestion for reducing the size of the
 UTXO database
In-Reply-To: <CAPg+sBiNLtDNqHML1n7UJC_hYtYCOjBuYNh-bZT8msVh9UKFUg@mail.gmail.com>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
	<millgi$3uv$1@ger.gmane.org>
	<CAPg+sBiNLtDNqHML1n7UJC_hYtYCOjBuYNh-bZT8msVh9UKFUg@mail.gmail.com>
Message-ID: <CANe1mWzLcmqRMJHsJvATTjyJ9fEdCDb-J0KAQhardVj3Jni6ww@mail.gmail.com>

On Sat, May 9, 2015 at 2:06 PM, Pieter Wuille <pieter.wuille at gmail.com>
wrote:

> It's a very complex trade-off, which is hard to optimize for all use
> cases. Using more UTXOs requires larger transactions, and thus more fees in
> general.
>
Unless the miner determines that the reduction in UTXO storage requirements
is worth the lower fee. There's no protocol level enforcement of a fee as
far as I understand it. It's enforced by the miners and their willingness
to include a transaction in a block.

> In addition, it results in more linkage between coins/addresses used, so
> lower privacy.
>
Not if you only select all the UTXOs from a single address. A wallet that
is geared more towards privacy minded individuals may want to reduce the
amount of address linkage, but a wallet geared towards the general masses
probably won't have to worry so much about that.

> The only way you can guarantee an economical reason to keep the UTXO set
> small is by actually having a consensus rule that punishes increasing its
> size.
>
There's an economical reason right now to keeping the UTXO set small. The
smaller it is, the easier it is for the individual to run a full node. The
easier it is to run a full node, the faster Bitcoin will spread to the
masses. The faster it spreads to the masses, the more valuable it becomes.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150509/34057496/attachment.html>

From raystonn at hotmail.com  Sat May  9 19:25:16 2015
From: raystonn at hotmail.com (Raystonn)
Date: Sat, 9 May 2015 12:25:16 -0700
Subject: [Bitcoin-development] A suggestion for reducing the size of the
 UTXO database
Message-ID: <COL402-EAS20727DF76F165B297AC8460CDDD0@phx.gbl>

An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150509/976abe4e/attachment.html>

From jim at ergophobia.org  Sat May  9 19:28:12 2015
From: jim at ergophobia.org (Jim Phillips)
Date: Sat, 9 May 2015 14:28:12 -0500
Subject: [Bitcoin-development] A suggestion for reducing the size of the
 UTXO database
In-Reply-To: <8029969D-FD22-43F7-930D-CEC7A87CEAD5@newcastle.ac.uk>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
	<3862E01F-FD0F-48F5-A6D9-F8E0FB0AB68F@newcastle.ac.uk>
	<CANe1mWys1gAO1CgPEpD7rdtXF2KYfvXA6bc0q-rAzg9xOFc-5A@mail.gmail.com>
	<8029969D-FD22-43F7-930D-CEC7A87CEAD5@newcastle.ac.uk>
Message-ID: <CANe1mWzxH9dwiAwZz2gEybWG03-87Ti65xV+SyFyC0KLuk+BAg@mail.gmail.com>

On Sat, May 9, 2015 at 2:12 PM, Patrick Mccorry (PGR) <
patrick.mccorry at newcastle.ac.uk> wrote:

>   Not necessarily. If you want to ensure privacy, you could limit the
> selection of UTXOs to a single address, and even go so far as to send
> change back to that same address. This wouldn't be as effective as
> combining the UTXOs from multiple addresses, but it would help. The key is
> to do everything that can be done when building a transaction to ensure
> that as many inputs as possible are consolidated into as few outputs as
> possible.
>
>
>  I would agree if you have multiple utxo for a single address then it
> makes sense since there is no privacy loss. However sending the change back
> to the same address would damage privacy (Hive does this) as it is then
> obvious from looking at the transaction which output is change and which
> output is sending funds.
>

I tend to agree with you here. But the change output could just as easily
be sent to a new change address.

>  Also not everyone is concerned with their own privacy, and I'm not aware
> of any HD-wallet implementations that won't already combine inputs from
> multiple addresses within that wallet without user input.
>
>
>  For people who do not care for privacy then it would work fine. But
> adding it into the wallet as default behaviour would deter those who do
> care for privacy - and making it a customisable option just adds complexity
> for the users. Wallets do need to combine utxo at times to spend bitcoins
> which is how people can be tracked today, using the minimum set of utxo
> tries to reduce the risk.
>
> Different wallets are targeted at different demographics. Some are geared
towards more mainstream users (for whom the privacy issue is less a
concern) and some (such as DarkWallet) are geared more towards the privacy
advocates. These wallets may choose to set their defaults at oposite ends
of the spectrum as to how they choose to select and link addresses and
UTXOs, but they can all improve on their current algorithms and promote
some degree of consolidation.

>   Additionally, large wallets that have lots of addresses owned by
> multiple users like exchanges, blockchain.info, and Coinbase can
> consolidate UTXOs very effectively when building transactions
>
>
>  That's true - I'm not sure how they would feel about it though. I
> imagine they probably are already to minimise key management.
>
> That's what these discussions are for. Hopefully this thread will be seen
by developers of these wallets and give them something to consider.

>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150509/f710a05f/attachment.html>

From jim at ergophobia.org  Sat May  9 19:33:21 2015
From: jim at ergophobia.org (Jim Phillips)
Date: Sat, 9 May 2015 14:33:21 -0500
Subject: [Bitcoin-development] A suggestion for reducing the size of the
 UTXO database
In-Reply-To: <COL402-EAS20727DF76F165B297AC8460CDDD0@phx.gbl>
References: <COL402-EAS20727DF76F165B297AC8460CDDD0@phx.gbl>
Message-ID: <CANe1mWyoS+Gbubp0d9mEofD-XjAy7SWm5gcm5xp1Uq7hYPFjig@mail.gmail.com>

On Sat, May 9, 2015 at 2:25 PM, Raystonn <raystonn at hotmail.com> wrote:

> Lack of privacy is viral.  We shouldn't encourage policy in most wallets
> that discourages privacy.  It adversely affects privacy across the entire
> network.
>
How about this as a happy medium default policy: Rather than select UTXOs
based solely on age and limiting the size of the transaction, we select as
many UTXOs as possible from as few addresses as possible, prioritizing
which addresses to use based on the number of UTXOs it contains (more being
preferable) and how old those UTXOs are (in order to reduce the fee)?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150509/ca094a42/attachment.html>

From jrn at jrn.me.uk  Sat May  9 19:43:33 2015
From: jrn at jrn.me.uk (Ross Nicoll)
Date: Sat, 09 May 2015 20:43:33 +0100
Subject: [Bitcoin-development] A suggestion for reducing the size of the
 UTXO database
In-Reply-To: <CANe1mWzLcmqRMJHsJvATTjyJ9fEdCDb-J0KAQhardVj3Jni6ww@mail.gmail.com>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>	<millgi$3uv$1@ger.gmane.org>	<CAPg+sBiNLtDNqHML1n7UJC_hYtYCOjBuYNh-bZT8msVh9UKFUg@mail.gmail.com>
	<CANe1mWzLcmqRMJHsJvATTjyJ9fEdCDb-J0KAQhardVj3Jni6ww@mail.gmail.com>
Message-ID: <554E6365.4060304@jrn.me.uk>

I think potential fee subsidies for cleaning up UTXO (and/or penalties 
for creating more UTXO than you burn) are worth thinking about. As 
Gavin's post ( gavinandresen.ninja/utxo-uhoh ) indicates, UTXO cost is 
far higher than block storage, so charging differently for the in/out 
mismatches should make good economic sense.

Ross


On 09/05/2015 20:16, Jim Phillips wrote:
> On Sat, May 9, 2015 at 2:06 PM, Pieter Wuille <pieter.wuille at gmail.com 
> <mailto:pieter.wuille at gmail.com>> wrote:
>
>     It's a very complex trade-off, which is hard to optimize for all
>     use cases. Using more UTXOs requires larger transactions, and thus
>     more fees in general.
>
> Unless the miner determines that the reduction in UTXO storage 
> requirements is worth the lower fee. There's no protocol level 
> enforcement of a fee as far as I understand it. It's enforced by the 
> miners and their willingness to include a transaction in a block.
>
>     In addition, it results in more linkage between coins/addresses
>     used, so lower privacy.
>
> Not if you only select all the UTXOs from a single address. A wallet 
> that is geared more towards privacy minded individuals may want to 
> reduce the amount of address linkage, but a wallet geared towards the 
> general masses probably won't have to worry so much about that.
>
>     The only way you can guarantee an economical reason to keep the
>     UTXO set small is by actually having a consensus rule that
>     punishes increasing its size.
>
> There's an economical reason right now to keeping the UTXO set small. 
> The smaller it is, the easier it is for the individual to run a full 
> node. The easier it is to run a full node, the faster Bitcoin will 
> spread to the masses. The faster it spreads to the masses, the more 
> valuable it becomes.
>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>
>
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150509/bbd40c7a/attachment.html>

From raystonn at hotmail.com  Sat May  9 19:43:55 2015
From: raystonn at hotmail.com (Raystonn)
Date: Sat, 9 May 2015 12:43:55 -0700
Subject: [Bitcoin-development] A suggestion for reducing the size of the
 UTXO database
Message-ID: <COL402-EAS295F2E93FABEABF789204D5CDDD0@phx.gbl>

An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150509/9f2abd0c/attachment.html>

From jim at ergophobia.org  Sat May  9 19:52:26 2015
From: jim at ergophobia.org (Jim Phillips)
Date: Sat, 9 May 2015 14:52:26 -0500
Subject: [Bitcoin-development] A suggestion for reducing the size of the
 UTXO database
In-Reply-To: <COL402-EAS295F2E93FABEABF789204D5CDDD0@phx.gbl>
References: <COL402-EAS295F2E93FABEABF789204D5CDDD0@phx.gbl>
Message-ID: <CANe1mWzza00poapfPmsgRUiqt5qkamx_V6xtTKZCvTGd-SgVcw@mail.gmail.com>

On Sat, May 9, 2015 at 2:43 PM, Raystonn <raystonn at hotmail.com> wrote:

> How about this as a happy medium default policy: Rather than select UTXOs
>> based solely on age and limiting the size of the transaction, we select as
>> many UTXOs as possible from as few addresses as possible, prioritizing
>> which addresses to use based on the number of UTXOs it contains (more being
>> preferable) and how old those UTXOs are (in order to reduce the fee)?
>
> If selecting older UTXOs gives higher priority for a lesser (or at least
> not greater) fee, that is an incentive for a rational user to use the older
> UTXOs.  Such policy needs to be defended or removed.  It doesn't support
> privacy or a reduction in UTXOs.
>
Before starting this thread, I had completely forgotten that age was even a
factor in determining which UTXOs to use. Frankly, I can't think of any
reason why miners care how old a particular UTXO is when determining what
fees to charge. I'm sure there is one, I just don't know what it is. I just
tossed it in there as homage to Andreas who pointed out to me that it was
still part of the selection criteria.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150509/45a26e39/attachment.html>

From raystonn at hotmail.com  Sat May  9 20:20:06 2015
From: raystonn at hotmail.com (Raystonn)
Date: Sat, 9 May 2015 13:20:06 -0700
Subject: [Bitcoin-development] A suggestion for reducing the size of the
 UTXO database
Message-ID: <COL402-EAS2801DD28568B04AF7E4005CCDDD0@phx.gbl>

An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150509/fe07c35b/attachment.html>

From pieter.wuille at gmail.com  Sat May  9 20:38:56 2015
From: pieter.wuille at gmail.com (Pieter Wuille)
Date: Sat, 9 May 2015 13:38:56 -0700
Subject: [Bitcoin-development] A suggestion for reducing the size of the
 UTXO database
In-Reply-To: <COL402-EAS2801DD28568B04AF7E4005CCDDD0@phx.gbl>
References: <COL402-EAS2801DD28568B04AF7E4005CCDDD0@phx.gbl>
Message-ID: <CAPg+sBgFAhVA=SBfPyz7dQAsGuyA_gBGexWao6FzUgGuRbqGrQ@mail.gmail.com>

Miners do not care about the age of a UTXO entry, apart for two exceptions.
It is also economically irrelevant.
* There is a free transaction policy, which sets a small portion of block
space aside for transactions which do not pay sufficient fee. This is
mostly an altruistic way of encouraging Bitcoin adoption. As a DoS
prevention mechanism, there is a requirement that these free transactions
are of sufficient priority (computed as BTC-days-destroyed per byte),
essentially requiring these transactions to consume another scarce
resource, even if not money.
* Coinbase transaction outputs can, as a consensus rule, only be spent
after 100 confirmations. This is to prevent random reorganisations from
invalidating transactions that spend young coinbase transactions (which
can't move to the new chain). In addition, wallets also select more
confirmed outputs first to consume, for the same reason.
On May 9, 2015 1:20 PM, "Raystonn" <raystonn at hotmail.com> wrote:

> That policy is included in Bitcoin Core.  Miners use it because it is the
> default.  The policy was likely intended to help real transactions get
> through in the face of spam.  But it favors those with more bitcoin, as the
> priority is determined by amount spent multiplied by age of UTXOs.  At the
> very least the amount spent should be removed as a factor, or fees are
> unlikely to ever be paid by those who can afford them.  We can reassess the
> role age plays later.  One change at a time is better.
>  On 9 May 2015 12:52 pm, Jim Phillips <jim at ergophobia.org> wrote:
>
> On Sat, May 9, 2015 at 2:43 PM, Raystonn <raystonn at hotmail.com> wrote:
>
> How about this as a happy medium default policy: Rather than select UTXOs
> based solely on age and limiting the size of the transaction, we select as
> many UTXOs as possible from as few addresses as possible, prioritizing
> which addresses to use based on the number of UTXOs it contains (more being
> preferable) and how old those UTXOs are (in order to reduce the fee)?
>
> If selecting older UTXOs gives higher priority for a lesser (or at least
> not greater) fee, that is an incentive for a rational user to use the older
> UTXOs.  Such policy needs to be defended or removed.  It doesn't support
> privacy or a reduction in UTXOs.
>
> Before starting this thread, I had completely forgotten that age was even
> a factor in determining which UTXOs to use. Frankly, I can't think of any
> reason why miners care how old a particular UTXO is when determining what
> fees to charge. I'm sure there is one, I just don't know what it is. I just
> tossed it in there as homage to Andreas who pointed out to me that it was
> still part of the selection criteria.
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150509/33931428/attachment.html>

From jim at ergophobia.org  Sat May  9 21:11:57 2015
From: jim at ergophobia.org (Jim Phillips)
Date: Sat, 9 May 2015 16:11:57 -0500
Subject: [Bitcoin-development] A suggestion for reducing the size of the
 UTXO database
In-Reply-To: <CAPg+sBgFAhVA=SBfPyz7dQAsGuyA_gBGexWao6FzUgGuRbqGrQ@mail.gmail.com>
References: <COL402-EAS2801DD28568B04AF7E4005CCDDD0@phx.gbl>
	<CAPg+sBgFAhVA=SBfPyz7dQAsGuyA_gBGexWao6FzUgGuRbqGrQ@mail.gmail.com>
Message-ID: <CANe1mWxeZ+hukoTCOehw7Zkty68-5ven=5zGbftotvJQ4bcd-A@mail.gmail.com>

Makes sense.. So with that said, I'd propose the following criteria for
selecting UTXOs:

1. Select the smallest possible set of addresses that can be linked in
order to come up with enough BTC to send to the payee.
2. Given multiple possible sets, select the one that has the largest number
of UTXOs.
3. Given multiple possible sets, choose the one that contains the largest
amount of total BTC.
4. Given multiple possible sets, select the one that destroys the most
bitcoin days.
5. If there's still multiple possible sets, just choose one at random.

Once the final set of addresses has been identified, use ALL UTXOs from
that set, sending appropriate outputs to the recipient(s), a new change
address, and a mining fee.

Miners should be cognisant of and reward the fact that the user is making
an effort to consolidate UTXOs. They can easily spot these transactions by
looking at whether all possible UTXOs from each input addresses have been
used. Since most miners use Bitcoin Core, and its defaults, this test can
be built into Bitcoin Core's logic for determining which transactions to
include when mining a block.

--
*James G. Phillips IV*
<https://plus.google.com/u/0/113107039501292625391/posts>
<http://www.linkedin.com/in/ergophobe>

*"Don't bunt. Aim out of the ball park. Aim for the company of immortals."
-- David Ogilvy*

 *This message was created with 100% recycled electrons. Please think twice
before printing.*

On Sat, May 9, 2015 at 3:38 PM, Pieter Wuille <pieter.wuille at gmail.com>
wrote:

> Miners do not care about the age of a UTXO entry, apart for two
> exceptions. It is also economically irrelevant.
> * There is a free transaction policy, which sets a small portion of block
> space aside for transactions which do not pay sufficient fee. This is
> mostly an altruistic way of encouraging Bitcoin adoption. As a DoS
> prevention mechanism, there is a requirement that these free transactions
> are of sufficient priority (computed as BTC-days-destroyed per byte),
> essentially requiring these transactions to consume another scarce
> resource, even if not money.
> * Coinbase transaction outputs can, as a consensus rule, only be spent
> after 100 confirmations. This is to prevent random reorganisations from
> invalidating transactions that spend young coinbase transactions (which
> can't move to the new chain). In addition, wallets also select more
> confirmed outputs first to consume, for the same reason.
> On May 9, 2015 1:20 PM, "Raystonn" <raystonn at hotmail.com> wrote:
>
>> That policy is included in Bitcoin Core.  Miners use it because it is the
>> default.  The policy was likely intended to help real transactions get
>> through in the face of spam.  But it favors those with more bitcoin, as the
>> priority is determined by amount spent multiplied by age of UTXOs.  At the
>> very least the amount spent should be removed as a factor, or fees are
>> unlikely to ever be paid by those who can afford them.  We can reassess the
>> role age plays later.  One change at a time is better.
>>  On 9 May 2015 12:52 pm, Jim Phillips <jim at ergophobia.org> wrote:
>>
>> On Sat, May 9, 2015 at 2:43 PM, Raystonn <raystonn at hotmail.com> wrote:
>>
>> How about this as a happy medium default policy: Rather than select UTXOs
>> based solely on age and limiting the size of the transaction, we select as
>> many UTXOs as possible from as few addresses as possible, prioritizing
>> which addresses to use based on the number of UTXOs it contains (more being
>> preferable) and how old those UTXOs are (in order to reduce the fee)?
>>
>> If selecting older UTXOs gives higher priority for a lesser (or at least
>> not greater) fee, that is an incentive for a rational user to use the older
>> UTXOs.  Such policy needs to be defended or removed.  It doesn't support
>> privacy or a reduction in UTXOs.
>>
>> Before starting this thread, I had completely forgotten that age was even
>> a factor in determining which UTXOs to use. Frankly, I can't think of any
>> reason why miners care how old a particular UTXO is when determining what
>> fees to charge. I'm sure there is one, I just don't know what it is. I just
>> tossed it in there as homage to Andreas who pointed out to me that it was
>> still part of the selection criteria.
>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150509/30a5f8d8/attachment.html>

From bip at mattwhitlock.name  Sun May 10 02:11:13 2015
From: bip at mattwhitlock.name (Matt Whitlock)
Date: Sat, 09 May 2015 22:11:13 -0400
Subject: [Bitcoin-development] A suggestion for reducing the size of the
	UTXO database
In-Reply-To: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
Message-ID: <2114827.D6GUhXtGkV@crushinator>

Minimizing the number of UTXOs in a wallet is sometimes not in the best interests of the user. In fact, quite often I've wished for a configuration option like "Try to maintain _[number]_ UTXOs in the wallet." This is because I often want to make multiple spends from my wallet within one block, but spends of unconfirmed inputs are less reliable than spends of confirmed inputs, and some wallets (e.g., Andreas Schildbach's wallet) don't even allow it - you can only spend confirmed UTXOs. I can't tell you how aggravating it is to have to tell a friend, "Oh, oops, I can't pay you yet. I have to wait for the last transaction I did to confirm first." All the more aggravating because I know, if I have multiple UTXOs in my wallet, I can make multiple spends within the same block.


On Saturday, 9 May 2015, at 12:09 pm, Jim Phillips wrote:
> Forgive me if this idea has been suggested before, but I made this
> suggestion on reddit and I got some feedback recommending I also bring it
> to this list -- so here goes.
> 
> I wonder if there isn't perhaps a simpler way of dealing with UTXO growth.
> What if, rather than deal with the issue at the protocol level, we deal
> with it at the source of the problem -- the wallets. Right now, the typical
> wallet selects only the minimum number of unspent outputs when building a
> transaction. The goal is to keep the transaction size to a minimum so that
> the fee stays low. Consequently, lots of unspent outputs just don't get
> used, and are left lying around until some point in the future.
> 
> What if we started designing wallets to consolidate unspent outputs? When
> selecting unspent outputs for a transaction, rather than choosing just the
> minimum number from a particular address, why not select them ALL? Take all
> of the UTXOs from a particular address or wallet, send however much needs
> to be spent to the payee, and send the rest back to the same address or a
> change address as a single output? Through this method, we should wind up
> shrinking the UTXO database over time rather than growing it with each
> transaction. Obviously, as Bitcoin gains wider adoption, the UTXO database
> will grow, simply because there are 7 billion people in the world, and
> eventually a good percentage of them will have one or more wallets with
> spendable bitcoin. But this idea could limit the growth at least.
> 
> The vast majority of users are running one of a handful of different wallet
> apps: Core, Electrum; Armory; Mycelium; Breadwallet; Coinbase; Circle;
> Blockchain.info; and maybe a few others. The developers of all these
> wallets have a vested interest in the continued usefulness of Bitcoin, and
> so should not be opposed to changing their UTXO selection algorithms to one
> that reduces the UTXO database instead of growing it.
> 
> >From the miners perspective, even though these types of transactions would
> be larger, the fee could stay low. Miners actually benefit from them in
> that it reduces the amount of storage they need to dedicate to holding the
> UTXO. So miners are incentivized to mine these types of transactions with a
> higher priority despite a low fee.
> 
> Relays could also get in on the action and enforce this type of behavior by
> refusing to relay or deprioritizing the relay of transactions that don't
> use all of the available UTXOs from the addresses used as inputs. Relays
> are not only the ones who benefit the most from a reduction of the UTXO
> database, they're also in the best position to promote good behavior.
> 
> --
> *James G. Phillips IV*
> <https://plus.google.com/u/0/113107039501292625391/posts>
> 
> *"Don't bunt. Aim out of the ball park. Aim for the company of immortals."
> -- David Ogilvy*
> 
>  *This message was created with 100% recycled electrons. Please think twice
> before printing.*



From jim at ergophobia.org  Sun May 10 12:11:53 2015
From: jim at ergophobia.org (Jim Phillips)
Date: Sun, 10 May 2015 07:11:53 -0500
Subject: [Bitcoin-development] A suggestion for reducing the size of the
 UTXO database
In-Reply-To: <2114827.D6GUhXtGkV@crushinator>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
	<2114827.D6GUhXtGkV@crushinator>
Message-ID: <CANe1mWxfjTOtgKJ=1MrvLQusoJw6Ecyk+aLoN7JUaVPsyp9S8g@mail.gmail.com>

I feel your pain. I've had the same thing happen to me in the past. And I
agree it's more likely to occur with my proposed scheme but I think with HD
wallets there will still be UTXOs left unspent after most transactions
since, for privacy sake it's looking for the smallest set of addresses that
can be linked.
On May 9, 2015 9:11 PM, "Matt Whitlock" <bip at mattwhitlock.name> wrote:

> Minimizing the number of UTXOs in a wallet is sometimes not in the best
> interests of the user. In fact, quite often I've wished for a configuration
> option like "Try to maintain _[number]_ UTXOs in the wallet." This is
> because I often want to make multiple spends from my wallet within one
> block, but spends of unconfirmed inputs are less reliable than spends of
> confirmed inputs, and some wallets (e.g., Andreas Schildbach's wallet)
> don't even allow it - you can only spend confirmed UTXOs. I can't tell you
> how aggravating it is to have to tell a friend, "Oh, oops, I can't pay you
> yet. I have to wait for the last transaction I did to confirm first." All
> the more aggravating because I know, if I have multiple UTXOs in my wallet,
> I can make multiple spends within the same block.
>
>
> On Saturday, 9 May 2015, at 12:09 pm, Jim Phillips wrote:
> > Forgive me if this idea has been suggested before, but I made this
> > suggestion on reddit and I got some feedback recommending I also bring it
> > to this list -- so here goes.
> >
> > I wonder if there isn't perhaps a simpler way of dealing with UTXO
> growth.
> > What if, rather than deal with the issue at the protocol level, we deal
> > with it at the source of the problem -- the wallets. Right now, the
> typical
> > wallet selects only the minimum number of unspent outputs when building a
> > transaction. The goal is to keep the transaction size to a minimum so
> that
> > the fee stays low. Consequently, lots of unspent outputs just don't get
> > used, and are left lying around until some point in the future.
> >
> > What if we started designing wallets to consolidate unspent outputs? When
> > selecting unspent outputs for a transaction, rather than choosing just
> the
> > minimum number from a particular address, why not select them ALL? Take
> all
> > of the UTXOs from a particular address or wallet, send however much needs
> > to be spent to the payee, and send the rest back to the same address or a
> > change address as a single output? Through this method, we should wind up
> > shrinking the UTXO database over time rather than growing it with each
> > transaction. Obviously, as Bitcoin gains wider adoption, the UTXO
> database
> > will grow, simply because there are 7 billion people in the world, and
> > eventually a good percentage of them will have one or more wallets with
> > spendable bitcoin. But this idea could limit the growth at least.
> >
> > The vast majority of users are running one of a handful of different
> wallet
> > apps: Core, Electrum; Armory; Mycelium; Breadwallet; Coinbase; Circle;
> > Blockchain.info; and maybe a few others. The developers of all these
> > wallets have a vested interest in the continued usefulness of Bitcoin,
> and
> > so should not be opposed to changing their UTXO selection algorithms to
> one
> > that reduces the UTXO database instead of growing it.
> >
> > >From the miners perspective, even though these types of transactions
> would
> > be larger, the fee could stay low. Miners actually benefit from them in
> > that it reduces the amount of storage they need to dedicate to holding
> the
> > UTXO. So miners are incentivized to mine these types of transactions
> with a
> > higher priority despite a low fee.
> >
> > Relays could also get in on the action and enforce this type of behavior
> by
> > refusing to relay or deprioritizing the relay of transactions that don't
> > use all of the available UTXOs from the addresses used as inputs. Relays
> > are not only the ones who benefit the most from a reduction of the UTXO
> > database, they're also in the best position to promote good behavior.
> >
> > --
> > *James G. Phillips IV*
> > <https://plus.google.com/u/0/113107039501292625391/posts>
> >
> > *"Don't bunt. Aim out of the ball park. Aim for the company of
> immortals."
> > -- David Ogilvy*
> >
> >  *This message was created with 100% recycled electrons. Please think
> twice
> > before printing.*
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150510/f595554a/attachment.html>

From bob_bitcoin at mcelrath.org  Sun May 10 13:35:25 2015
From: bob_bitcoin at mcelrath.org (Bob McElrath)
Date: Sun, 10 May 2015 13:35:25 +0000
Subject: [Bitcoin-development] A suggestion for reducing the size of
 the	UTXO database
In-Reply-To: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
Message-ID: <20150510133525.GD6182@mcelrath.org>

This is my biggest headache with practical bitcoin usage. I'd love to hear it if
anyone has any clever solutions to the wallet/utxo locked problem. Spending
unconfirmed outputs really requires a different security model on the part of
the receiver than #confirmations, but isn't inherently bad if the receiver has a
better security model and knows how to compute the probability that an
unconfirmed-spend will get confirmed. Of course the bigger problem is wallet
software that refuses to spend unconfirmed outputs.

I've thought a bit about a fork/merge design: if the change were computed by the
network instead of the submitter, two transactions having the same change
address and a common input could be straightforwardly merged or split (in a
reorg), where with bitcoin currently it would be considered a double-spend.  Of
course that has big privacy implications since it directly exposes the change
address, and is a hard fork, but is much closer to what people expect of a
debit-based "account" in traditional banking.

The fact of the matter is that having numerous sequential debits on an account
is an extremely common use case, and bitcoin is obtuse in this respect.

On May 9, 2015 1:09:32 PM EDT, Jim Phillips <jim at ergophobia.org> wrote:
>Forgive me if this idea has been suggested before, but I made this
>suggestion on reddit and I got some feedback recommending I also bring
>it
>to this list -- so here goes.
>
>I wonder if there isn't perhaps a simpler way of dealing with UTXO
>growth.
>What if, rather than deal with the issue at the protocol level, we deal
>with it at the source of the problem -- the wallets. Right now, the
>typical
>wallet selects only the minimum number of unspent outputs when building
>a
>transaction. The goal is to keep the transaction size to a minimum so
>that
>the fee stays low. Consequently, lots of unspent outputs just don't get
>used, and are left lying around until some point in the future.
>
>What if we started designing wallets to consolidate unspent outputs?
>When
>selecting unspent outputs for a transaction, rather than choosing just
>the
>minimum number from a particular address, why not select them ALL? Take
>all
>of the UTXOs from a particular address or wallet, send however much
>needs
>to be spent to the payee, and send the rest back to the same address or
>a
>change address as a single output? Through this method, we should wind
>up
>shrinking the UTXO database over time rather than growing it with each
>transaction. Obviously, as Bitcoin gains wider adoption, the UTXO
>database
>will grow, simply because there are 7 billion people in the world, and
>eventually a good percentage of them will have one or more wallets with
>spendable bitcoin. But this idea could limit the growth at least.
>
>The vast majority of users are running one of a handful of different
>wallet
>apps: Core, Electrum; Armory; Mycelium; Breadwallet; Coinbase; Circle;
>Blockchain.info; and maybe a few others. The developers of all these
>wallets have a vested interest in the continued usefulness of Bitcoin,
>and
>so should not be opposed to changing their UTXO selection algorithms to
>one
>that reduces the UTXO database instead of growing it.
>
>>From the miners perspective, even though these types of transactions
>would
>be larger, the fee could stay low. Miners actually benefit from them in
>that it reduces the amount of storage they need to dedicate to holding
>the
>UTXO. So miners are incentivized to mine these types of transactions
>with a
>higher priority despite a low fee.
>
>Relays could also get in on the action and enforce this type of
>behavior by
>refusing to relay or deprioritizing the relay of transactions that
>don't
>use all of the available UTXOs from the addresses used as inputs.
>Relays
>are not only the ones who benefit the most from a reduction of the UTXO
>database, they're also in the best position to promote good behavior.
>
>--
>*James G. Phillips IV*
><https://plus.google.com/u/0/113107039501292625391/posts>
>
>*"Don't bunt. Aim out of the ball park. Aim for the company of
>immortals."
>-- David Ogilvy*
>
>*This message was created with 100% recycled electrons. Please think
>twice
>before printing.*
>
>
>!DSPAM:554e4e5450787476022393!
>
>
>------------------------------------------------------------------------
>
>------------------------------------------------------------------------------
>One dashboard for servers and applications across
>Physical-Virtual-Cloud 
>Widest out-of-the-box monitoring support with 50+ applications
>Performance metrics, stats and reports that give you Actionable
>Insights
>Deep dive visibility with transaction tracing using APM Insight.
>http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>
>!DSPAM:554e4e5450787476022393!
>
>
>------------------------------------------------------------------------
>
>_______________________________________________
>Bitcoin-development mailing list
>Bitcoin-development at lists.sourceforge.net
>https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
>!DSPAM:554e4e5450787476022393!

-- 
Sent from my Android device with K-9 Mail. Please excuse my brevity.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150510/3d3c3382/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 198 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150510/3d3c3382/attachment.sig>

From jgarzik at bitpay.com  Sun May 10 14:33:56 2015
From: jgarzik at bitpay.com (Jeff Garzik)
Date: Sun, 10 May 2015 10:33:56 -0400
Subject: [Bitcoin-development] A suggestion for reducing the size of the
 UTXO database
In-Reply-To: <20150510133525.GD6182@mcelrath.org>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
	<20150510133525.GD6182@mcelrath.org>
Message-ID: <CAJHLa0NOQkCk=JGoTyNBz8OgKYy_G+M0+a3DP6fGKjsaWq2-aw@mail.gmail.com>

This has been frequently explored on IRC.

My general conclusion is "dollar bills" - pick highly common denominations
of bitcoins.  Aggregate to obtain these denominations, but do not aggregate
further.

This permits merge avoidance (privacy++), easy coinjoin where many hide in
the noise (privacy++), wallet dust de-fragmentation, while avoiding the
over-aggregation problem where you have consolidated down to one output.

Thus a wallet would have several consolidation targets.

Another strategy is simply doubling outputs.  Say you pay 0.1 BTC to
Starbucks.  Add another 0.1 BTC output to yourself, and a final change
output.  Who can say which output goes to Starbucks?

There are many iterations and trade-offs between fragmentation and privacy.









On Sun, May 10, 2015 at 9:35 AM, Bob McElrath <bob_bitcoin at mcelrath.org>
wrote:

> This is my biggest headache with practical bitcoin usage. I'd love to hear
> it if
> anyone has any clever solutions to the wallet/utxo locked problem. Spending
> unconfirmed outputs really requires a different security model on the part
> of
> the receiver than #confirmations, but isn't inherently bad if the receiver
> has a
> better security model and knows how to compute the probability that an
> unconfirmed-spend will get confirmed. Of course the bigger problem is
> wallet
> software that refuses to spend unconfirmed outputs.
>
> I've thought a bit about a fork/merge design: if the change were computed
> by the
> network instead of the submitter, two transactions having the same change
> address and a common input could be straightforwardly merged or split (in a
> reorg), where with bitcoin currently it would be considered a
> double-spend.  Of
> course that has big privacy implications since it directly exposes the
> change
> address, and is a hard fork, but is much closer to what people expect of a
> debit-based "account" in traditional banking.
>
> The fact of the matter is that having numerous sequential debits on an
> account
> is an extremely common use case, and bitcoin is obtuse in this respect.
>
> On May 9, 2015 1:09:32 PM EDT, Jim Phillips <jim at ergophobia.org> wrote:
> >Forgive me if this idea has been suggested before, but I made this
> >suggestion on reddit and I got some feedback recommending I also bring
> >it
> >to this list -- so here goes.
> >
> >I wonder if there isn't perhaps a simpler way of dealing with UTXO
> >growth.
> >What if, rather than deal with the issue at the protocol level, we deal
> >with it at the source of the problem -- the wallets. Right now, the
> >typical
> >wallet selects only the minimum number of unspent outputs when building
> >a
> >transaction. The goal is to keep the transaction size to a minimum so
> >that
> >the fee stays low. Consequently, lots of unspent outputs just don't get
> >used, and are left lying around until some point in the future.
> >
> >What if we started designing wallets to consolidate unspent outputs?
> >When
> >selecting unspent outputs for a transaction, rather than choosing just
> >the
> >minimum number from a particular address, why not select them ALL? Take
> >all
> >of the UTXOs from a particular address or wallet, send however much
> >needs
> >to be spent to the payee, and send the rest back to the same address or
> >a
> >change address as a single output? Through this method, we should wind
> >up
> >shrinking the UTXO database over time rather than growing it with each
> >transaction. Obviously, as Bitcoin gains wider adoption, the UTXO
> >database
> >will grow, simply because there are 7 billion people in the world, and
> >eventually a good percentage of them will have one or more wallets with
> >spendable bitcoin. But this idea could limit the growth at least.
> >
> >The vast majority of users are running one of a handful of different
> >wallet
> >apps: Core, Electrum; Armory; Mycelium; Breadwallet; Coinbase; Circle;
> >Blockchain.info; and maybe a few others. The developers of all these
> >wallets have a vested interest in the continued usefulness of Bitcoin,
> >and
> >so should not be opposed to changing their UTXO selection algorithms to
> >one
> >that reduces the UTXO database instead of growing it.
> >
> >>From the miners perspective, even though these types of transactions
> >would
> >be larger, the fee could stay low. Miners actually benefit from them in
> >that it reduces the amount of storage they need to dedicate to holding
> >the
> >UTXO. So miners are incentivized to mine these types of transactions
> >with a
> >higher priority despite a low fee.
> >
> >Relays could also get in on the action and enforce this type of
> >behavior by
> >refusing to relay or deprioritizing the relay of transactions that
> >don't
> >use all of the available UTXOs from the addresses used as inputs.
> >Relays
> >are not only the ones who benefit the most from a reduction of the UTXO
> >database, they're also in the best position to promote good behavior.
> >
> >--
> >*James G. Phillips IV*
> ><https://plus.google.com/u/0/113107039501292625391/posts>
> >
> >*"Don't bunt. Aim out of the ball park. Aim for the company of
> >immortals."
> >-- David Ogilvy*
> >
> >*This message was created with 100% recycled electrons. Please think
> >twice
> >before printing.*
> >
> >
> >!DSPAM:554e4e5450787476022393!
> >
> >
> >------------------------------------------------------------------------
> >
>
> >------------------------------------------------------------------------------
> >One dashboard for servers and applications across
> >Physical-Virtual-Cloud
> >Widest out-of-the-box monitoring support with 50+ applications
> >Performance metrics, stats and reports that give you Actionable
> >Insights
> >Deep dive visibility with transaction tracing using APM Insight.
> >http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> >
> >!DSPAM:554e4e5450787476022393!
> >
> >
> >------------------------------------------------------------------------
> >
> >_______________________________________________
> >Bitcoin-development mailing list
> >Bitcoin-development at lists.sourceforge.net
> >https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> >
> >
> >!DSPAM:554e4e5450787476022393!
>
> --
> Sent from my Android device with K-9 Mail. Please excuse my brevity.
>
> This is my biggest headache with practical bitcoin usage. I'd love to hear
> it if anyone has any clever solutions to the wallet/utxo locked problem.
> Spending unconfirmed outputs really requires a different security model on
> the part of the receiver than #confirmations, but isn't inherently bad if
> the receiver has a better security model and knows how to compute the
> probability that an unconfirmed-spend will get confirmed. Of course the
> bigger problem is wallet software that refuses to spend unconfirmed outputs.
>
> I've thought a bit about a fork/merge design: if the change were computed
> by the network instead of the submitter, two transactions having the same
> change address could be straightforwardly merged or split (in a reorg). Of
> course that has big privacy implications and is pretty far from bitcoin's
> design, but is much closer to what people expect of a debit-based "account"
> in traditional banking.
>
> The fact of the matter is that having numerous sequential debits on an
> account is an extremely common use case, and bitcoin is obtuse in this
> respect.
>
> On May 9, 2015 1:09:32 PM EDT, Jim Phillips <jim at ergophobia.org> wrote:
>>
>> Forgive me if this idea has been suggested before, but I made this
>> suggestion on reddit and I got some feedback recommending I also bring it
>> to this list -- so here goes.
>>
>> I wonder if there isn't perhaps a simpler way of dealing with UTXO
>> growth. What if, rather than deal with the issue at the protocol level, we
>> deal with it at the source of the problem -- the wallets. Right now, the
>> typical wallet selects only the minimum number of unspent outputs when
>> building a transaction. The goal is to keep the transaction size to a
>> minimum so that the fee stays low. Consequently, lots of unspent outputs
>> just don't get used, and are left lying around until some point in the
>> future.
>>
>> What if we started designing wallets to consolidate unspent outputs? When
>> selecting unspent outputs for a transaction, rather than choosing just the
>> minimum number from a particular address, why not select them ALL? Take all
>> of the UTXOs from a particular address or wallet, send however much needs
>> to be spent to the payee, and send the rest back to the same address or a
>> change address as a single output? Through this method, we should wind up
>> shrinking the UTXO database over time rather than growing it with each
>> transaction. Obviously, as Bitcoin gains wider adoption, the UTXO database
>> will grow, simply because there are 7 billion people in the world, and
>> eventually a good percentage of them will have one or more wallets with
>> spendable bitcoin. But this idea could limit the growth at least.
>>
>> The vast majority of users are running one of a handful of different
>> wallet apps: Core, Electrum; Armory; Mycelium; Breadwallet; Coinbase;
>> Circle; Blockchain.info; and maybe a few others. The developers of all
>> these wallets have a vested interest in the continued usefulness of
>> Bitcoin, and so should not be opposed to changing their UTXO selection
>> algorithms to one that reduces the UTXO database instead of growing it.
>>
>> From the miners perspective, even though these types of transactions
>> would be larger, the fee could stay low. Miners actually benefit from them
>> in that it reduces the amount of storage they need to dedicate to holding
>> the UTXO. So miners are incentivized to mine these types of transactions
>> with a higher priority despite a low fee.
>>
>> Relays could also get in on the action and enforce this type of behavior
>> by refusing to relay or deprioritizing the relay of transactions that don't
>> use all of the available UTXOs from the addresses used as inputs. Relays
>> are not only the ones who benefit the most from a reduction of the UTXO
>> database, they're also in the best position to promote good behavior.
>>
>> --
>> *James G. Phillips IV*
>> <https://plus.google.com/u/0/113107039501292625391/posts>
>>
>> *"Don't bunt. Aim out of the ball park. Aim for the company of
>> immortals." -- David Ogilvy*
>>
>>  *This message was created with 100% recycled electrons. Please think
>> twice before printing.*
>>  !DSPAM:554e4e5450787476022393!
>>
>> ------------------------------
>>
>> One dashboard for servers and applications across Physical-Virtual-Cloud
>> Widest out-of-the-box monitoring support with 50+ applications
>> Performance metrics, stats and reports that give you Actionable Insights
>> Deep dive visibility with transaction tracing using APM Insight.
>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>>
>> !DSPAM:554e4e5450787476022393!
>>
>> ------------------------------
>>
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>>
>> !DSPAM:554e4e5450787476022393!
>>
>>
> --
> Sent from my Android device with K-9 Mail. Please excuse my brevity.
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.10 (GNU/Linux)
>
> iEYEARECAAYFAlVPXp0ACgkQjwioWRGe9K1+2ACfViY0D2ksVFe29SwhxbtmNSC3
> TQAAnRoJLI9wW3DQRPqQ7PorKxelC2S2
> =Er51
> -----END PGP SIGNATURE-----
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>


-- 
Jeff Garzik
Bitcoin core developer and open source evangelist
BitPay, Inc.      https://bitpay.com/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150510/8dd225ad/attachment.html>

From bob_bitcoin at mcelrath.org  Sun May 10 14:42:54 2015
From: bob_bitcoin at mcelrath.org (Bob McElrath)
Date: Sun, 10 May 2015 14:42:54 +0000
Subject: [Bitcoin-development] A suggestion for reducing the size of the
 UTXO database
In-Reply-To: <CAJHLa0NOQkCk=JGoTyNBz8OgKYy_G+M0+a3DP6fGKjsaWq2-aw@mail.gmail.com>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
	<20150510133525.GD6182@mcelrath.org>
	<CAJHLa0NOQkCk=JGoTyNBz8OgKYy_G+M0+a3DP6fGKjsaWq2-aw@mail.gmail.com>
Message-ID: <20150510144254.GE6182@mcelrath.org>

That's a lot of work, a lot of extra utxo's, and a lot of blockchain spam, just
so I can do a convoluted form of arithmetic on my balance.

If a tx contained an explicit miner fee and a change address, but did not
compute the change, letting the network compute it (and therefore merge
transactions spending the same utxo), could one add some form of ring signature
a la Dash to alleviate the worsened privacy implications?

Jeff Garzik [jgarzik at bitpay.com] wrote:
> This has been frequently explored on IRC.
> 
> My general conclusion is "dollar bills" - pick highly common denominations of
> bitcoins.? Aggregate to obtain these denominations, but do not aggregate
> further.
> 
> This permits merge avoidance (privacy++), easy coinjoin where many hide in the
> noise (privacy++), wallet dust de-fragmentation, while avoiding the
> over-aggregation problem where you have consolidated down to one output.
> 
> Thus a wallet would have several consolidation targets.
> 
> Another strategy is simply doubling outputs.? Say you pay 0.1 BTC to
> Starbucks.? Add another 0.1 BTC output to yourself, and a final change output.?
> Who can say which output goes to Starbucks?
> 
> There are many iterations and trade-offs between fragmentation and privacy.



--
Cheers, Bob McElrath

"The individual has always had to struggle to keep from being overwhelmed by
the tribe.  If you try it, you will be lonely often, and sometimes frightened.
But no price is too high to pay for the privilege of owning yourself." 
    -- Friedrich Nietzsche



From ogunden at phauna.org  Sun May 10 17:36:32 2015
From: ogunden at phauna.org (Owen Gunden)
Date: Sun, 10 May 2015 13:36:32 -0400
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
 function
In-Reply-To: <CAAS2fgQRS7w7RRNXVK_+=4CQ7=AWxWQQ7+Tf4tNUPTTZOf7rEQ@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>	<CAOG=w-szbLgc1jLpkE_uMa3bkFTi-RiBEaQ6Y-u5aKLBC2HvUg@mail.gmail.com>
	<CAAS2fgQRS7w7RRNXVK_+=4CQ7=AWxWQQ7+Tf4tNUPTTZOf7rEQ@mail.gmail.com>
Message-ID: <554F9720.4040105@phauna.org>

On 05/08/2015 11:36 PM, Gregory Maxwell wrote:
> Another related point which has been tendered before but seems to have
> been ignored is that changing how the size limit is computed can help
> better align incentives and thus reduce risk.  E.g. a major cost to the
> network is the UTXO impact of transactions, but since the limit is blind
> to UTXO impact a miner would gain less income if substantially factoring
> UTXO impact into its fee calculations; and without fee impact users have
> little reason to optimize their UTXO behavior.

Along the lines of aligning incentives with a diversity of costs to a 
variety of network participants, I am curious about reactions to Justus' 
general approach:

http://bitcoinism.liberty.me/2015/02/09/economic-fallacies-and-the-block-size-limit-part-2-price-discovery/

I realize it relies on pie-in-the-sky ideas like micropayment channels, 
but I wonder if it's a worthy long-term ideal direction for this stuff.



From mark at friedenbach.org  Sun May 10 18:10:47 2015
From: mark at friedenbach.org (Mark Friedenbach)
Date: Sun, 10 May 2015 11:10:47 -0700
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <554F9720.4040105@phauna.org>
References: <16096345.A1MpJQQkRW@crushinator>
	<CAOG=w-szbLgc1jLpkE_uMa3bkFTi-RiBEaQ6Y-u5aKLBC2HvUg@mail.gmail.com>
	<CAAS2fgQRS7w7RRNXVK_+=4CQ7=AWxWQQ7+Tf4tNUPTTZOf7rEQ@mail.gmail.com>
	<554F9720.4040105@phauna.org>
Message-ID: <CAOG=w-ths+Jay-LRS+upSL95YSNXmjEEh1ZS28yvGfNnpBouHQ@mail.gmail.com>

Micropayment channels are not pie in the sky proposals. They work today on
Bitcoin as it is deployed without any changes. People just need to start
using them.
On May 10, 2015 11:03, "Owen Gunden" <ogunden at phauna.org> wrote:

> On 05/08/2015 11:36 PM, Gregory Maxwell wrote:
> > Another related point which has been tendered before but seems to have
> > been ignored is that changing how the size limit is computed can help
> > better align incentives and thus reduce risk.  E.g. a major cost to the
> > network is the UTXO impact of transactions, but since the limit is blind
> > to UTXO impact a miner would gain less income if substantially factoring
> > UTXO impact into its fee calculations; and without fee impact users have
> > little reason to optimize their UTXO behavior.
>
> Along the lines of aligning incentives with a diversity of costs to a
> variety of network participants, I am curious about reactions to Justus'
> general approach:
>
>
> http://bitcoinism.liberty.me/2015/02/09/economic-fallacies-and-the-block-size-limit-part-2-price-discovery/
>
> I realize it relies on pie-in-the-sky ideas like micropayment channels,
> but I wonder if it's a worthy long-term ideal direction for this stuff.
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150510/531fe7c2/attachment.html>

From sergiolerner at certimix.com  Sun May 10 20:45:32 2015
From: sergiolerner at certimix.com (Sergio Lerner)
Date: Sun, 10 May 2015 17:45:32 -0300
Subject: [Bitcoin-development] A way to create a fee market even without a
	block size limit (2013)
Message-ID: <554FC36C.80402@certimix.com>

Two years ago I presented a new way to create a fee market that does not
depend on the block chain limit.

This proposal has not been formally analyzed in any paper since then,
but I think it holds a good promise to untangle the current problem
regarding increasing the tps and creating the fee market. BTW, think the
maximum tps should be increased, but not by increasing the block size,
but by increasing the block rate (I'll expose why in my next e-mail).

The original post is here (I was overly optimistic back then):
https://bitcointalk.org/index.php?topic=147124.msg1561612#msg1561612

I'll summarize it here again, with a little editing and a few more
questions at the end:

The idea is simple, but requires a hardfork, but is has minimum impact
in the code and in the economics.

Solution: Require that the set of fees collected in a block has a
dispersion below a threshold. Use, for example, the Coefficient of
Variation (http://en.wikipedia.org/wiki/Coefficient_of_variation). If
the CoVar is higher than a fixed threshold, the block is considered invalid.

The Coefficient of variation is computed as the standard deviation over
the mean value, so it's very easy to compute. (if the mean is zero, we
assume CoVar=0). Note that the CoVar function *does not depend on the
scale*, so is just what a coin with a floating price requires.

This means that if there are many transactions containing high fees in a
block, then free transactions cannot be included.
The core devs should tweak the transaction selection algorithm to take
into account this maximum bound.

*Example*

If the transaction fee set is: 0,0,0,0,5,5,6,7,8,7
The CoVar is 0.85
Suppose we limit the CoVar to a maximum of 1.

Suppose the transaction fee set is: 0,0,0,0,0,0,0,0,0,10
Then the CoVar is 3.0

In this case the miner should have to either drop the "10" from the fee
set or drop the zeros. Obviously the miner will drop some zeros, and
choose the set: 0,10, that has a CoVar of 1.

*Why it reduces the Tx spamming Problem?*

Using this little modification, spamming users would require to use
higher fees, only if the remaining users in the community rises their
fees. And miners won't be able to include an enormous amounts of
spamming txs.

*Why it helps solving **the tragedy-of-the-commons fee "problem"?*

As miners are forced to keep the CoVar below the threshold, if people
rises the fees to confirm faster than spamming txs, automatically
smamming txs become less likely to appear in blocks, and fee-estimators
will automatically increase future fees, creating a the desired feedback
loop.

*Why it helps solving the block size problem?*

Because if we increase the block size, miners that do not care about the
fee market won't be able to fill the block with spamming txs and destroy
the market that is being created. This is not a solution against an
attacker-miner, which can always fill the block with transactions.

*Can the system by gamed? Can it be attacked?*

I don't think so. An attacker would need to spend a high amount in fees
to prevent transactions with low fees to be included in a block.
However, a formal analysis would be required. Miller, Gun Sirer, Eyal..
Want to give it a try?
*
Can create a positive feedback to a rise the fees to the top or push
fess to the bottom?

*Again, I don't think so. This depends on the dynamics between the each
node's fee estimator and the transaction backlog. MIT guys?

*Doesn't it force miners to run more complex algorithms (such as linear
programming) to find the optimum tx subset ?

*Yes, but I don't see it as a drawback, but as a positive stimulus for
researchers to develop better tx selection algorithms. Anyway, the
greedy algorithm of picking the transactions with highest fees fees
would be good enough.

*
PLEASE don't confuse the acronym CoVar I used here with co-variance.*

Best regard,
  Sergio.



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150510/2fa8f7e2/attachment.html>

From pete at petertodd.org  Sun May 10 20:51:41 2015
From: pete at petertodd.org (Peter Todd)
Date: Sun, 10 May 2015 16:51:41 -0400
Subject: [Bitcoin-development] A way to create a fee market even without
 a block size limit (2013)
In-Reply-To: <554FC36C.80402@certimix.com>
References: <554FC36C.80402@certimix.com>
Message-ID: <20150510205141.GA7465@savin.petertodd.org>

On Sun, May 10, 2015 at 05:45:32PM -0300, Sergio Lerner wrote:
> Two years ago I presented a new way to create a fee market that does not
> depend on the block chain limit.

<snip>

> Solution: Require that the set of fees collected in a block has a
> dispersion below a threshold. Use, for example, the Coefficient of
> Variation (http://en.wikipedia.org/wiki/Coefficient_of_variation). If
> the CoVar is higher than a fixed threshold, the block is considered invalid.

It's not possible to create consensus rules enforcing anything about
fees because it's trivial to pay miners out of band.

For instance, you can pay transaction fees by including anyone-can-spend
outputs in your transactions. The miner creating the block then simply
adds a transaction at the end of their block collecting all the
anyone-can-spend outputs. Equally, if you try to prohibit that - e.g. by
preventing respending of funds in the same block - they can simply
publish fee addresses and have people put individual outputs for those
addresses in their transactions. (IIRC Eligius gave people the option to
pay fees that way for awhile)

-- 
'peter'[:-1]@petertodd.org
00000000000000000fa57b40dc86a61d35aaf9241c86f047ef6f4bab8f13dfb7
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150510/db3d6fe4/attachment.sig>

From gmaxwell at gmail.com  Sun May 10 21:07:43 2015
From: gmaxwell at gmail.com (Gregory Maxwell)
Date: Sun, 10 May 2015 21:07:43 +0000
Subject: [Bitcoin-development] A way to create a fee market even without
 a block size limit (2013)
In-Reply-To: <554FC36C.80402@certimix.com>
References: <554FC36C.80402@certimix.com>
Message-ID: <CAAS2fgQL6ExHqT+po-F2b9+3Ns4woFx-VqQSdDkXRZwy47+XwA@mail.gmail.com>

On Sun, May 10, 2015 at 8:45 PM, Sergio Lerner
<sergiolerner at certimix.com> wrote:
> Can the system by gamed?

Users can pay fees or a portion of fees out of band to miner(s); this
is undetectable to the network.

It's also behavior that miners have engaged in since at least 2011 (in
two forms;  treating transactions that paid them directly via outputs
as having that much more in fees;  and taking contracts for fast
processing for identified transactions (e.g. address matching or via
an API) e.g. "I'll pay you x at the end of the month for each of my
transactions you process, you can poll this API". I'm aware of at
least two companies having had this arrangement with miners).

I think what you suggested then just further rewards this behavior as
it allows bypassing your controls.-- I suspect generally any scheme
the looks at the fee values has this property.



From gavinandresen at gmail.com  Sun May 10 21:21:06 2015
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Sun, 10 May 2015 17:21:06 -0400
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CAAS2fgQRS7w7RRNXVK_+=4CQ7=AWxWQQ7+Tf4tNUPTTZOf7rEQ@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CAOG=w-szbLgc1jLpkE_uMa3bkFTi-RiBEaQ6Y-u5aKLBC2HvUg@mail.gmail.com>
	<CAAS2fgQRS7w7RRNXVK_+=4CQ7=AWxWQQ7+Tf4tNUPTTZOf7rEQ@mail.gmail.com>
Message-ID: <CABsx9T2+ThQ+z2wyb_NbDWEK1zJO-WaLMdDU3ewpTELNKhb7YA@mail.gmail.com>

Let me make sure I understand this proposal:

On Fri, May 8, 2015 at 11:36 PM, Gregory Maxwell <gmaxwell at gmail.com> wrote:

> (*) I believe my currently favored formulation of general dynamic control
> idea is that each miner expresses in their coinbase a preferred size
> between some minimum (e.g. 500k) and the miner's effective-maximum;
> the actual block size can be up to the effective maximum even if the
> preference is lower (you're not forced to make a lower block because you
> stated you wished the limit were lower).  There is a computed maximum
> which is the 33-rd percentile of the last 2016 coinbase preferences
> minus computed_max/52 (rounding up to 1) bytes-- or 500k if thats
> larger. The effective maximum is X bytes more, where X on the range
> [0, computed_maximum] e.g. the miner can double the size of their
> block at most. If X > 0, then the miners must also reach a target
> F(x/computed_maximum) times the bits-difficulty; with F(x) = x^2+1  ---
> so the maximum penalty is 2, with a quadratic shape;  for a given mempool
> there will be some value that maximizes expected income.  (obviously all
> implemented with precise fixed point arithmetic).   The percentile is
> intended to give the preferences of the 33% least preferring miners a
> veto on increases (unless a majority chooses to soft-fork them out). The
> minus-comp_max/52 provides an incentive to slowly shrink the maximum
> if its too large-- x/52 would halve the size in one year if miners
> were doing the lowest difficulty mining. The parameters 500k/33rd,
> -computed_max/52 bytes, and f(x)  I have less strong opinions about;
> and would love to hear reasoned arguments for particular parameters.
>

I'm going to try to figure out how much transaction fee a transaction would
have to pay to bribe a miner to include it. Greg, please let me know if
I've misinterpreted the proposed algorithm. And everybody, please let me
know if I'm making a bone-headed mistake in how I'm computing anything:

Lets say miners are expressing a desire for 600,000 byte blocks in their
coinbases.

computed_max = 600,000 - 600,000/52 = 588,462 bytes.
  --> this is about 23 average-size (500-byte) transactions less than
600,000.
effective_max = 1,176,923

Lets say I want to maintain status quo at 600,000 bytes; how much penalty
do I have?
((600,000-588,462)/588,462)^2 + 1 = 1.00038

How much will that cost me?
The network is hashing at 310PetaHash/sec right now.
Takes 600 seconds to find a block, so 186,000PH per block
186,000 * 0.00038 = 70 extra PH

If it takes 186,000 PH to find a block, and a block is worth 25.13 BTC
(reward plus fees), that 70 PH costs:
(25.13 BTC/block / 186,000 PH/block) * 70 PH = 0.00945 BTC
or at $240 / BTC:  $2.27

... so average transaction fee will have to be about ten cents ($2.27
spread across 23 average-sized transactions) for miners to decide to stay
at 600K blocks. If they fill up 588,462 bytes and don't have some
ten-cent-fee transactions left, they should express a desire to create a
588,462-byte-block and mine with no penalty.

Is that too much?  Not enough?  Average transaction fees today are about 3
cents per transaction.
I created a spreadsheet playing with the parameters:

https://docs.google.com/spreadsheets/d/1zYZfb44Uns8ai0KnoQ-LixDwdhqO5iTI3ZRcihQXlgk/edit?usp=sharing

"We" could tweak the constants or function to get a transaction fee we
think is reasonable... but we really shouldn't be deciding whether
transaction fees are too high, too low, or just right, and after thinking
about this for a while I think any algorithm that ties difficulty to block
size is just a complicated way of dictating minimum fees.

As for some other dynamic algorithm: OK with me. How do we get consensus on
what the best algorithm is? I'm ok with any "don't grow too quickly, give
some reasonable-percentage-minority of miners the ability to block further
increases."

Also relevant here:
"The curious task of economics is to demonstrate to men how little they
really know about what they imagine they can design." - Friedrich August
von Hayek

-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150510/481dae92/attachment.html>

From gmaxwell at gmail.com  Sun May 10 21:33:15 2015
From: gmaxwell at gmail.com (Gregory Maxwell)
Date: Sun, 10 May 2015 21:33:15 +0000
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CABsx9T2+ThQ+z2wyb_NbDWEK1zJO-WaLMdDU3ewpTELNKhb7YA@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CAOG=w-szbLgc1jLpkE_uMa3bkFTi-RiBEaQ6Y-u5aKLBC2HvUg@mail.gmail.com>
	<CAAS2fgQRS7w7RRNXVK_+=4CQ7=AWxWQQ7+Tf4tNUPTTZOf7rEQ@mail.gmail.com>
	<CABsx9T2+ThQ+z2wyb_NbDWEK1zJO-WaLMdDU3ewpTELNKhb7YA@mail.gmail.com>
Message-ID: <CAAS2fgTX3ScbMmd2cWqhxfdN1OE5dxNhVvJ9pa0hNsKwWKqzJg@mail.gmail.com>

On Sun, May 10, 2015 at 9:21 PM, Gavin Andresen <gavinandresen at gmail.com> wrote:
> a while I think any algorithm that ties difficulty to block size is just a
> complicated way of dictating minimum fees.

Thats not the long term effect or the motivation-- what you're seeing
is that the subsidy gets in the way here.  Consider how the procedure
behaves with subsidy being negligible compared to fees.   What it
accomplishes in that case is that it incentivizes increasing the size
until the marginal "value" to miners of the transaction-data being
left out is not enormously smaller than the "value" of the data in the
block on average.  Value in quotes because it's blind to the "fees"
the transaction claims.

With a large subsidy, the marginal value of the first byte in the
block is HUGE; and so that pushes up the average-- and creates the
"base fee effect" that you're looking at.  It's not that anyone is
picking a fee there, it's that someone picked the subsidy there.  :)
As the subsidy goes down the only thing fees are relative to is fees.

An earlier version of the proposal took subsidy out of the picture
completely by increasing it linearly with the increased difficulty;
but that creates additional complexity both to implement and to
explain to people (e.g. that the setup doesn't change the supply of
coins); ... I suppose without it that starting disadvantage parameter
(the offset that reduces the size if you're indifferent) needs to be
much smaller, unfortunately.



From thomasv at electrum.org  Sun May 10 21:48:39 2015
From: thomasv at electrum.org (Thomas Voegtlin)
Date: Sun, 10 May 2015 23:48:39 +0200
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
 function
In-Reply-To: <CAOG=w-szbLgc1jLpkE_uMa3bkFTi-RiBEaQ6Y-u5aKLBC2HvUg@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CAOG=w-szbLgc1jLpkE_uMa3bkFTi-RiBEaQ6Y-u5aKLBC2HvUg@mail.gmail.com>
Message-ID: <554FD237.2020009@electrum.org>

Le 08/05/2015 22:33, Mark Friedenbach a ?crit :

>   * For each block, the miner is allowed to select a different difficulty
> (nBits) within a certain range, e.g. +/- 25% of the expected difficulty,
> and this miner-selected difficulty is used for the proof of work check. In
> addition to adjusting the hashcash target, selecting a different difficulty
> also raises or lowers the maximum block size for that block by a function
> of the difference in difficulty. So increasing the difficulty of the block
> by an additional 25% raises the block limit for that block from 100% of the
> current limit to 125%, and lowering the difficulty by 10% would also lower
> the maximum block size for that block from 100% to 90% of the current
> limit. For simplicity I will assume a linear identity transform as the
> function, but a quadratic or other function with compounding marginal cost
> may be preferred.
> 

Sorry but I fail to see how a linear identity transform between block
size and difficulty would work.

The miner's reward for finding a block is the sum of subsidy and fees:

 R = S + F

The probability that the miner will find a block over a time interval is
inversely proportional to the difficulty D:

 P = K / D

where K is a constant that depends on the miner's hashrate. The expected
reward of the miner is:

 E = P * R

Consider that the miner chooses a new difficulty:

 D' = D(1 + x).

With a linear identity transform between block size and difficulty, the
miner will be allowed to collect fees from a block of size: S'=S(1+x)

In the best case, collected will be proportional to block size:

 F' = F(1+x)

Thus we get:

 E' = P' * R' = K/(D(1+x)) * (S + F(1+x))

 E' = E - x/(1+x) * S * K / D

So with this linear identity transform, increasing block size never
increases the miners gain. As long as the subsidy exists, the best
strategy for miners is to reduce block size (i.e. to choose x<0).



From mark at friedenbach.org  Sun May 10 22:31:46 2015
From: mark at friedenbach.org (Mark Friedenbach)
Date: Sun, 10 May 2015 15:31:46 -0700
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <554FD237.2020009@electrum.org>
References: <16096345.A1MpJQQkRW@crushinator>
	<CAOG=w-szbLgc1jLpkE_uMa3bkFTi-RiBEaQ6Y-u5aKLBC2HvUg@mail.gmail.com>
	<554FD237.2020009@electrum.org>
Message-ID: <CAOG=w-uZBGaprOV2ztYYNtiOSgxTpRUn_8zKTsNSkGAL1N1=nA@mail.gmail.com>

I'm on my phone today so I'm somewhat constrained in my reply, but the key
takeaway is that the proposal is a mechanism for miners to trade subsidy
for the increased fees of a larger block. Necessarily it only makes sense
to do so when the marginal fee per KB exceeds the subsidy fee per KB. It
correspondingly makes sense to use a smaller block size if fees are less
than subsidy, but note that fees are not uniform and as the block shrinks
the marginal fee rate goes up..

Limits on both the relative and absolute amount a miner can trade subsidy
for block size prevent incentive edge cases as well as prevent a sharp
shock to the current fee-poor economy (by disallowing adjustment below 1MB).

Also the identity transform was used only for didactic purposes. I fully
expect there to be other, more interesting functions to use.
On May 10, 2015 3:03 PM, "Thomas Voegtlin" <thomasv at electrum.org> wrote:

> Le 08/05/2015 22:33, Mark Friedenbach a ?crit :
>
> >   * For each block, the miner is allowed to select a different difficulty
> > (nBits) within a certain range, e.g. +/- 25% of the expected difficulty,
> > and this miner-selected difficulty is used for the proof of work check.
> In
> > addition to adjusting the hashcash target, selecting a different
> difficulty
> > also raises or lowers the maximum block size for that block by a function
> > of the difference in difficulty. So increasing the difficulty of the
> block
> > by an additional 25% raises the block limit for that block from 100% of
> the
> > current limit to 125%, and lowering the difficulty by 10% would also
> lower
> > the maximum block size for that block from 100% to 90% of the current
> > limit. For simplicity I will assume a linear identity transform as the
> > function, but a quadratic or other function with compounding marginal
> cost
> > may be preferred.
> >
>
> Sorry but I fail to see how a linear identity transform between block
> size and difficulty would work.
>
> The miner's reward for finding a block is the sum of subsidy and fees:
>
>  R = S + F
>
> The probability that the miner will find a block over a time interval is
> inversely proportional to the difficulty D:
>
>  P = K / D
>
> where K is a constant that depends on the miner's hashrate. The expected
> reward of the miner is:
>
>  E = P * R
>
> Consider that the miner chooses a new difficulty:
>
>  D' = D(1 + x).
>
> With a linear identity transform between block size and difficulty, the
> miner will be allowed to collect fees from a block of size: S'=S(1+x)
>
> In the best case, collected will be proportional to block size:
>
>  F' = F(1+x)
>
> Thus we get:
>
>  E' = P' * R' = K/(D(1+x)) * (S + F(1+x))
>
>  E' = E - x/(1+x) * S * K / D
>
> So with this linear identity transform, increasing block size never
> increases the miners gain. As long as the subsidy exists, the best
> strategy for miners is to reduce block size (i.e. to choose x<0).
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150510/5281404f/attachment.html>

From thomasv at electrum.org  Sun May 10 23:11:55 2015
From: thomasv at electrum.org (Thomas Voegtlin)
Date: Mon, 11 May 2015 01:11:55 +0200
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
 function
In-Reply-To: <CAOG=w-uZBGaprOV2ztYYNtiOSgxTpRUn_8zKTsNSkGAL1N1=nA@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>	<CAOG=w-szbLgc1jLpkE_uMa3bkFTi-RiBEaQ6Y-u5aKLBC2HvUg@mail.gmail.com>	<554FD237.2020009@electrum.org>
	<CAOG=w-uZBGaprOV2ztYYNtiOSgxTpRUn_8zKTsNSkGAL1N1=nA@mail.gmail.com>
Message-ID: <554FE5BB.3040201@electrum.org>



Le 11/05/2015 00:31, Mark Friedenbach a ?crit :
> I'm on my phone today so I'm somewhat constrained in my reply, but the key
> takeaway is that the proposal is a mechanism for miners to trade subsidy
> for the increased fees of a larger block. Necessarily it only makes sense
> to do so when the marginal fee per KB exceeds the subsidy fee per KB. It
> correspondingly makes sense to use a smaller block size if fees are less
> than subsidy, but note that fees are not uniform and as the block shrinks
> the marginal fee rate goes up..
> 

Oh I see, you expect the sign of the dE/dx to change depending on
whether fees exceed the subsidy. This is possible, but instead of the
linear identity, you have to increase the block size twice as fast as
the difficulty. In that case we would get (using the notations of my
previous email):

D' = D(1+x)
F' = F(1+2x)

and thus:

E' - E = x/(1+x)P(F-S)

The presence of the (F-S) factor means that the sign reversal occurs
when fees exceed subsidy.


> Limits on both the relative and absolute amount a miner can trade subsidy
> for block size prevent incentive edge cases as well as prevent a sharp
> shock to the current fee-poor economy (by disallowing adjustment below 1MB).
> 
> Also the identity transform was used only for didactic purposes. I fully
> expect there to be other, more interesting functions to use.



From rob.golding at astutium.com  Sun May 10 21:56:30 2015
From: rob.golding at astutium.com (Rob Golding)
Date: Sun, 10 May 2015 22:56:30 +0100
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
 function
In-Reply-To: <CABsx9T2+ThQ+z2wyb_NbDWEK1zJO-WaLMdDU3ewpTELNKhb7YA@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CAOG=w-szbLgc1jLpkE_uMa3bkFTi-RiBEaQ6Y-u5aKLBC2HvUg@mail.gmail.com>
	<CAAS2fgQRS7w7RRNXVK_+=4CQ7=AWxWQQ7+Tf4tNUPTTZOf7rEQ@mail.gmail.com>
	<CABsx9T2+ThQ+z2wyb_NbDWEK1zJO-WaLMdDU3ewpTELNKhb7YA@mail.gmail.com>
Message-ID: <d30f8c10648d7ed1dada3677aba5904d@astutium.com>

> How much will that cost me?
> The network is hashing at 310PetaHash/sec right now.
> Takes 600 seconds to find a block, so 186,000PH per block
> 186,000 * 0.00038 = 70 extra PH
> 
> If it takes 186,000 PH to find a block, and a block is worth 25.13 BTC
> (reward plus fees), that 70 PH costs:
> (25.13 BTC/block / 186,000 PH/block) * 70 PH = 0.00945 BTC
> or at $240 / BTC:  $2.27
> 
> ... so average transaction fee will have to be about ten cents ($2.27
> spread across 23 average-sized transactions) for miners to decide to
> stay at 600K blocks

Surely that's an *extra* $2.27 as you've already included .13BTC 
($31.20) in fees in the calculation ?

Rob



From stephencalebmorse at gmail.com  Mon May 11 05:31:09 2015
From: stephencalebmorse at gmail.com (Stephen)
Date: Mon, 11 May 2015 01:31:09 -0400
Subject: [Bitcoin-development] A way to create a fee market even without
	a block size limit (2013)
In-Reply-To: <554FC36C.80402@certimix.com>
References: <554FC36C.80402@certimix.com>
Message-ID: <82E6CC14-1B3B-4B45-91F2-F19CE89E34A0@gmail.com>

Why do so many tie the block size debate to creating "a fee market", as if one didn't already exist? Yes, today we frequently see many low priority transactions included into the next block, but that does not mean there is not a marketplace for block space. It just means miners are not being sufficiently tough to create a *competitive* marketplace. 

But who are we to say that the marketplace should be more competitive, and to go further and try to force it by altering consensus rules like the block size limit? If miners want to see more competitive fees, then they need only to alter their block creation protocol. 

There are many arguments for and against changing the consensus limit on block size. I'm simply saying that "to force a marketplace for fees/block space" should not be one of them. Let the market develop on it's own. 

- Stephen



> On May 10, 2015, at 4:45 PM, Sergio Lerner <sergiolerner at certimix.com> wrote:
> 
> Two years ago I presented a new way to create a fee market that does not depend on the block chain limit.
> 
> This proposal has not been formally analyzed in any paper since then, but I think it holds a good promise to untangle the current problem regarding increasing the tps and creating the fee market. BTW, think the maximum tps should be increased, but not by increasing the block size, but by increasing the block rate (I'll     expose why in my next e-mail).
> 
> The original post is here (I was overly optimistic back then): https://bitcointalk.org/index.php?topic=147124.msg1561612#msg1561612
> 
> I'll summarize it here again, with a little editing and a few more questions at the end:
> 
> The idea is simple, but requires a hardfork, but is has minimum impact in the code and in the economics.
> 
> Solution: Require that the set of fees collected in a block has a dispersion below a threshold. Use, for example, the Coefficient of Variation (http://en.wikipedia.org/wiki/Coefficient_of_variation). If the CoVar is higher than a fixed threshold, the block is considered invalid.
> 
> The Coefficient of variation is computed as the standard deviation over the mean value, so it's very easy to compute. (if the mean is zero, we assume CoVar=0). Note that the CoVar function does not depend on the scale, so is just what a coin with a floating price requires.
> 
> This means that if there are many transactions containing high fees in a block, then free transactions cannot be included.
> The core devs should tweak the transaction selection algorithm to take into account this maximum bound.
> 
> Example
> 
> If the transaction fee set is: 0,0,0,0,5,5,6,7,8,7
> The CoVar is 0.85
> Suppose we limit the CoVar to a maximum of 1.
> 
> Suppose the transaction fee set is: 0,0,0,0,0,0,0,0,0,10
> Then the CoVar is 3.0
> 
> In this case the miner should have to either drop the "10" from the fee set or drop the zeros. Obviously the miner will drop some zeros, and choose the set: 0,10, that has a CoVar of 1.
> 
> Why it reduces the Tx spamming Problem?
> 
> Using this little modification, spamming users would require to use higher fees, only if the remaining users in the community rises their fees. And miners won't be able to include an enormous amounts of spamming txs.
> 
> Why it helps solving the tragedy-of-the-commons fee "problem"?
> 
> As miners are forced to keep the CoVar below the threshold, if people rises the fees to confirm faster than spamming txs, automatically smamming txs become less likely to appear in blocks, and fee-estimators will automatically increase future fees, creating a the desired feedback loop.
> 
> Why it helps solving the block size problem?
> 
> Because if we increase the block size, miners that do not care about the fee market won't be able to fill the block with spamming txs and destroy the market that is being created. This is not a solution against an attacker-miner, which can always fill the block with transactions.
> 
> Can the system by gamed? Can it be attacked?
> 
> I don't think so. An attacker would need to spend a high amount in fees to prevent transactions with low fees to be included in a block. 
> However, a formal analysis would be required. Miller, Gun Sirer, Eyal.. Want to give it a try?
> 
> Can create a positive feedback to a rise the fees to the top or push fess to the bottom?
> 
> Again, I don't think so. This depends on the dynamics between the each node's fee estimator and the transaction backlog. MIT guys? 
> 
> Doesn't it force miners to run more complex algorithms (such as linear programming) to find the optimum tx subset ?
> 
> Yes, but I don't see it as a drawback, but as a positive stimulus for researchers to develop better tx selection algorithms. Anyway, the greedy algorithm of picking the transactions with highest fees fees would be good enough. 
> 
> 
> PLEASE don't confuse the acronym CoVar I used here with co-variance.
> 
> Best regard,
>   Sergio.
> 
> 
> 
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud 
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150511/6eaf0f71/attachment.html>

From sergiolerner at certimix.com  Mon May 11 06:09:58 2015
From: sergiolerner at certimix.com (Sergio Lerner)
Date: Mon, 11 May 2015 03:09:58 -0300
Subject: [Bitcoin-development] A way to create a fee market even without
 a block size limit (2013)
In-Reply-To: <CAAS2fgQL6ExHqT+po-F2b9+3Ns4woFx-VqQSdDkXRZwy47+XwA@mail.gmail.com>
References: <554FC36C.80402@certimix.com>
	<CAAS2fgQL6ExHqT+po-F2b9+3Ns4woFx-VqQSdDkXRZwy47+XwA@mail.gmail.com>
Message-ID: <555047B6.8010402@certimix.com>

El 10/05/2015 06:07 p.m., Gregory Maxwell escribi?:
> On Sun, May 10, 2015 at 8:45 PM, Sergio Lerner
> <sergiolerner at certimix.com> wrote:
>> Can the system by gamed?
> Users can pay fees or a portion of fees out of band to miner(s); this
> is undetectable to the network.
Then this is exactly what is needed. Let me explain.

I know of 5 methods for a user to pay fees to a miner. I will explain
each method and why these methods do not prevent the fee market from
being created:

1) By transaction fees

This is the standard, which would be limited by the CoVar algorithm, and
would create the fee market, if it were the only way to pay fees.

2) By creating multiple transactions, each adding an output that pays to
each miner (to a known miner address) the fees. User does not
pre-negotiate anything with miners.

This requires a transaction to have an additional output and requires
sending through the p2p network one different transaction to each miner,
each having an output with a "known" address of that miner. But the
network does not propagates double-spends, so those transaction would
need to be sent directly to the top miners, and to all at the same time.
The IP addresses of the top miners are not generally publicly available,
and then may not accept new incoming connections. Also having an
additional output means the transactions would be larger, so they will
score lower by any metric the miner uses to choose transactions. Last,
miners must be programmed to automatically interpret payments to their
addresses as fees. The resulting protocol is very difficult to do
reliably, expensive, as any delay would make one miner receive the
transaction from other miner and reject the double-spend that is being
send directly to it, increasing the average confirmation time.

3) By adding an anyone-can-spend output for fees, so the miner can spend
that output in the same block.  User does not pre-negotiate anything
with miners.

We can hard-fork not to allow spending outputs created in the same
block. This is a drawback, unless we reduce the block rate, which is my
proposal. However, spending in the same block also requires an storing
in the block an additional input, which consumes at least 40 bytes more,
and the transaction containing the input cannot be relayed to the
network in advance. Then the block that uses this method to collect fees
from many transactions will propagate slower, and the miner may end
loosing money. The any-one-can-spend output would take approximately 10
bytes. So if transmitting 10+40=50 bytes, cost more than the fees
earned, then miners do not have an incentive to game the system. It's
has been studied that "each kilobyte costs an additional 80ms delay
until a majority knows about the block." (Information propagation in the
Bitcoin network). So 50 bytes costs 3.9 ms in propagation time, which
having a a 25 BTC subsidy is roughly equivalent to 0.2 mBTC. Currently
this is more than what transactions do pay in fees (about 0.1 mBTC), so
this should not be a problem for at least 5 years. And again, we could
just prevent spending outputs in the same block they are created.

4) Using a transaction having a single input having exactly the desired
output amount plus fees and signing the input with SIGHASH_SINGLE |
SIGHASH_ANYONECANPAY and adding to the transaction a single output with
the desired amount. The miner will be able to join many of these
transactions and finally add an output to collect all fees together,
without using standard transaction fees.

This is unreliable and cannot be systematically repeated without
creating a pre-transaction just to prepare the single input having the
amount plus fees exactly. The pre-transaction would need to pay fees, so
the problem is not avoided, just moved around.

5) By negotiating out of band with the miner previously. Anything could
be agreed by the user and the miner.

This actually creates a parallel out-of-band market for fees, which is
exactly what we want. If a user-to-miner pre-negotiation will take
place, then the miner can establish whatever price policy he wants to
compete and stay in business, as block data propagation costs money. So
there will be two fee markets, the "out-of-band" market, and the
"in-band" market, and both should converge.

My conclusion is that fee markets will be created, and any alternate
fee-paying methods (without a pre-negotiation) are not reliable nor
cost-saving options. The full proposal would be to use the CoVar method,
reduce the block rate to 1 minute, and do not allow spending outputs in
the same block they are created.

Best regards,
 Sergio.





From sergiolerner at certimix.com  Mon May 11 07:03:29 2015
From: sergiolerner at certimix.com (Sergio Lerner)
Date: Mon, 11 May 2015 04:03:29 -0300
Subject: [Bitcoin-development] Reducing the block rate instead of increasing
	the maximum block size
Message-ID: <55505441.3010906@certimix.com>

In this e-mail I'll do my best to argue than if you accept that
increasing the transactions/second is a good direction to go, then
increasing the maximum block size is not the best way to do it. I argue
that the right direction to go is to decrease the block rate to 1
minute, while keeping the block size limit to 1 Megabyte (or increasing
it from a lower value such as 100 Kbyte and then have a step function).
I'm backing up my claims with many hours of research simulating the
Bitcoin network under different conditions [1].  I'll try to convince
you by responding to each of the arguments I've heard against it.

Arguments against reducing the block interval

1. It will encourage centralization, because participants of mining
pools will loose more money because of excessive initial block template
latency, which leads to higher stale shares

When a new block is solved, that information needs to propagate
throughout the Bitcoin network up to the mining pool operator nodes,
then a new block header candidate is created, and this header must be
propagated to all the mining pool users, ether by a push or a pull
model. Generally the mining server pushes new work units to the
individual miners. If done other way around, the server would need to
handle a high load of continuous work requests that would be difficult
to distinguish from a DDoS attack. So if the server pushes new block
header candidates to clients, then the problem boils down to increasing
bandwidth of the servers to achieve a tenfold increase in work
distribution. Or distributing the servers geographically to achieve a
lower latency. Propagating blocks does not require additional CPU
resources, so mining pools administrators would need to increase
moderately their investment in the server infrastructure to achieve
lower latency and higher bandwidth, but I guess the investment would be low.

2. It will increase the probability of a block-chain split

The convergence of the network relies on the diminishing probability of
two honest miners creating simultaneous competing blocks chains. To
increase the competition chain, competing blocks must be generated in
almost simultaneously (in the same time window approximately bounded by
the network average block propagation delay). The probability of a block
competition decreases exponentially with the number of blocks. In fact,
the probability of a sustained competition on ten 1-minute blocks is one
million times lower than the probability of a competition of one
10-minute block. So even if the competition probability of six 1-minute
blocks is higher than of six ten-minute blocks, this does not imply
reducing the block rate increases this chance, but on the contrary, 
reduces it.

3, It will reduce the security of the network

The security of the network is based on two facts:
A- The miners are incentivized to extend the best chain
B- The probability of a reversal based on a long block competition
decreases as more confirmation blocks are appended.
C- Renting or buying hardware to perform a 51% attack is costly.

A still holds. B holds for the same amount of confirmation blocks, so 6
confirmation blocks in a 10-minute block-chain is approximately
equivalent to 6 confirmation blocks in a 1-minute block-chain.
Only C changes, as renting the hashing power for 6 minutes is ten times
less expensive as renting it for 1 hour. However, there is no shop where
one can find 51% of the hashing power to rent right now, nor probably
will ever be if Bitcoin succeeds. Last, you can still have a 1 hour
confirmation (60 1-minute blocks) if you wish for high-valued payments,
so the security decreases only if participant wish to decrease it.

4. Reducing the block propagation time on the average case is good, but
what happen in the worse case?

Most methods proposed to reduce the block propagation delay do it only
on the average case. Any kind of block compression relies on both
parties sharing some previous information. In the worse case it's true
that a miner can create and try to broadcast a block that takes too much
time to verify or bandwidth to transmit. This is currently true on the
Bitcoin network. Nevertheless there is no such incentive for miners,
since they will be shooting on their own foots. Peter Todd has argued
that the best strategy for miners is actually to reach 51% of the
network, but not more. In other words, to exclude the slowest 49%
percent. But this strategy of creating bloated blocks is too risky in
practice, and surely doomed to fail, as network conditions dynamically 
change. Also it would be perceived as an attack to the network, and the
miner (if it is a public mining pool) would be probably blacklisted.

5. Thousands of SPV wallets running in mobile devices would need to be
upgraded (thanks Mike).

That depends on the current upgrade rate for SPV wallets like Bitcoin
Wallet  and BreadWallet. Suppose that the upgrade rate is 80%/year: we
develop the source code for the change now and apply the change in Q2
2016, then  most of the nodes will already be upgraded by when the
hardfork takes place. Also a public notice telling people to upgrade in
web pages, bitcointalk, SPV wallets warnings, coindesk, one year in
advance will give plenty of time to SPV wallet users to upgrade.

6. If there are 10x more blocks, then there are 10x more block headers,
and that increases the amount of bandwidth SPV wallets need to catch up
with the chain
 
A standard smartphone with average cellular downstream speed downloads
2.6 headers per second (1600 kbits/sec) [3], so if synchronization were
to be done only at night when the phone is connected to the power line,
then it would take 9 minutes to synchronize with 1440 headers/day. If a
person should accept a payment, and the smart-phone is 1 day
out-of-synch, then it takes less time to download all the missing
headers than to wait for a 10-minute one block confirmation. Obviously
all smartphones with 3G have a downstream bandwidth much higher,
averaging 1 Mbps. So the whole synchronization will be done less than a
1-minute block confirmation.
 
According to CISCO mobile bandwidth connection speed increases 20% every
year. In four years, it will have doubled, so mobile phones with lower
than average data connection will soon be able to catchup.
Also there is low-hanging-fruit optimizations to the protocol that have
not been implemented: each header is 80 bytes in length. When a set of
chained headers is transferred, the headers could be compressed,
stripping 32 bytes of each header that is derived from the previous
header hash digest. So a 40% compression is already possible by slightly
modifying the wire protocol.
 
7. There has been insufficient testing and/or insufficient research into
technical/economic implications or reducing the block rate
 
This is partially true. in the GHOST paper, this has been analyzed, and
the problem was shown to be solvable for block intervals of just a few
seconds. There are several proof-of-work cryptocurrencies in existence
that have lower than 1 minute block intervals and they work just fine.
First there was Bitcoin with a 10 minute interval, then was LiteCoin
using a 2.5 interval, then was DogeCoin with 1 minute, and then
QuarkCoin with just 30 seconds. Every new cryptocurrency lowers it a
little bit. Some time ago I decided to research on the block rate to
understand how the block interval impacts the stability and capability
of the cryptocurrency network, and I came up with the idea of the DECOR+
protocol [4] (which requires changes in the consensus code). In my
research I also showed how the stale rate can be easily reduced only
with changes in the networking code, and not in the consensus code.
These networking optimizations ( O(1) propagation using headers-first or
IBLTs), can be added later.
 
Mortifying Bitcoin to accommodate the change to lower the block rate
requires at least:
 
- Changing the 21 BTC reward per block to 2.1 BTC
- Changing the nPowTargetTimespan constant
- Writing code to hard-fork automatically when the majority of miners
have upgraded.
- Allow transaction version 3, and interpret nLockTimes of transaction
version 2 as being multiplied by 10.

All changes comprises no more than 15 lines of code. This is much less
than the number of lines modified by Gavin's 20Mb patch.
 
As a conclusion, I haven't yet heard a good argument against lowering
the block rate.

Best regards,
 Sergio.
 
[0] https://medium.com/@octskyward/the-capacity-cliff-586d1bf7715e
[1] https://bitslog.wordpress.com/2014/02/17/5-sec-block-interval/
[2] http://gavinandresen.ninja/time-to-roll-out-bigger-blocks
[3]
http://www.cisco.com/c/en/us/solutions/collateral/service-provider/visual-networking-index-vni/white_paper_c11-520862.html
[4] https://bitslog.wordpress.com/2014/05/02/decor/



From thyshizzle at outlook.com  Mon May 11 07:30:49 2015
From: thyshizzle at outlook.com (Thy Shizzle)
Date: Mon, 11 May 2015 17:30:49 +1000
Subject: [Bitcoin-development] Reducing the block rate instead of
 increasing	the maximum block size
Message-ID: <BAY403-EAS184981B0219DEB969D407CC2DB0@phx.gbl>

Yes This!

So many people seem hung up on growing the block size! If gaining a higher tps throughput is the main aim, I think that this proposition to speed up block creation has merit!

Yes it will lead to an increase in the block chain still due to 1mb ~1 minute instead of ~10 minute, but the change to the protocol is minor, you are only adding in a different difficulty rate starting from hight blah, no new features or anything are being added so there seems to me much less of a security risk! Also that impact if a hard fork should be minimal because there is nothing but absolute incentive for miners to mine at the new easier difficulty!

I feel this deserves a great deal of consideration as opposed to blowing out the block through miners voting etc!!!!
________________________________
From: Sergio Lerner<mailto:sergiolerner at certimix.com>
Sent: ?11/?05/?2015 5:05 PM
To: bitcoin-development at lists.sourceforge.net<mailto:bitcoin-development at lists.sourceforge.net>
Subject: [Bitcoin-development] Reducing the block rate instead of increasing the maximum block size

In this e-mail I'll do my best to argue than if you accept that
increasing the transactions/second is a good direction to go, then
increasing the maximum block size is not the best way to do it. I argue
that the right direction to go is to decrease the block rate to 1
minute, while keeping the block size limit to 1 Megabyte (or increasing
it from a lower value such as 100 Kbyte and then have a step function).
I'm backing up my claims with many hours of research simulating the
Bitcoin network under different conditions [1].  I'll try to convince
you by responding to each of the arguments I've heard against it.

Arguments against reducing the block interval

1. It will encourage centralization, because participants of mining
pools will loose more money because of excessive initial block template
latency, which leads to higher stale shares

When a new block is solved, that information needs to propagate
throughout the Bitcoin network up to the mining pool operator nodes,
then a new block header candidate is created, and this header must be
propagated to all the mining pool users, ether by a push or a pull
model. Generally the mining server pushes new work units to the
individual miners. If done other way around, the server would need to
handle a high load of continuous work requests that would be difficult
to distinguish from a DDoS attack. So if the server pushes new block
header candidates to clients, then the problem boils down to increasing
bandwidth of the servers to achieve a tenfold increase in work
distribution. Or distributing the servers geographically to achieve a
lower latency. Propagating blocks does not require additional CPU
resources, so mining pools administrators would need to increase
moderately their investment in the server infrastructure to achieve
lower latency and higher bandwidth, but I guess the investment would be low.

2. It will increase the probability of a block-chain split

The convergence of the network relies on the diminishing probability of
two honest miners creating simultaneous competing blocks chains. To
increase the competition chain, competing blocks must be generated in
almost simultaneously (in the same time window approximately bounded by
the network average block propagation delay). The probability of a block
competition decreases exponentially with the number of blocks. In fact,
the probability of a sustained competition on ten 1-minute blocks is one
million times lower than the probability of a competition of one
10-minute block. So even if the competition probability of six 1-minute
blocks is higher than of six ten-minute blocks, this does not imply
reducing the block rate increases this chance, but on the contrary,
reduces it.

3, It will reduce the security of the network

The security of the network is based on two facts:
A- The miners are incentivized to extend the best chain
B- The probability of a reversal based on a long block competition
decreases as more confirmation blocks are appended.
C- Renting or buying hardware to perform a 51% attack is costly.

A still holds. B holds for the same amount of confirmation blocks, so 6
confirmation blocks in a 10-minute block-chain is approximately
equivalent to 6 confirmation blocks in a 1-minute block-chain.
Only C changes, as renting the hashing power for 6 minutes is ten times
less expensive as renting it for 1 hour. However, there is no shop where
one can find 51% of the hashing power to rent right now, nor probably
will ever be if Bitcoin succeeds. Last, you can still have a 1 hour
confirmation (60 1-minute blocks) if you wish for high-valued payments,
so the security decreases only if participant wish to decrease it.

4. Reducing the block propagation time on the average case is good, but
what happen in the worse case?

Most methods proposed to reduce the block propagation delay do it only
on the average case. Any kind of block compression relies on both
parties sharing some previous information. In the worse case it's true
that a miner can create and try to broadcast a block that takes too much
time to verify or bandwidth to transmit. This is currently true on the
Bitcoin network. Nevertheless there is no such incentive for miners,
since they will be shooting on their own foots. Peter Todd has argued
that the best strategy for miners is actually to reach 51% of the
network, but not more. In other words, to exclude the slowest 49%
percent. But this strategy of creating bloated blocks is too risky in
practice, and surely doomed to fail, as network conditions dynamically
change. Also it would be perceived as an attack to the network, and the
miner (if it is a public mining pool) would be probably blacklisted.

5. Thousands of SPV wallets running in mobile devices would need to be
upgraded (thanks Mike).

That depends on the current upgrade rate for SPV wallets like Bitcoin
Wallet  and BreadWallet. Suppose that the upgrade rate is 80%/year: we
develop the source code for the change now and apply the change in Q2
2016, then  most of the nodes will already be upgraded by when the
hardfork takes place. Also a public notice telling people to upgrade in
web pages, bitcointalk, SPV wallets warnings, coindesk, one year in
advance will give plenty of time to SPV wallet users to upgrade.

6. If there are 10x more blocks, then there are 10x more block headers,
and that increases the amount of bandwidth SPV wallets need to catch up
with the chain

A standard smartphone with average cellular downstream speed downloads
2.6 headers per second (1600 kbits/sec) [3], so if synchronization were
to be done only at night when the phone is connected to the power line,
then it would take 9 minutes to synchronize with 1440 headers/day. If a
person should accept a payment, and the smart-phone is 1 day
out-of-synch, then it takes less time to download all the missing
headers than to wait for a 10-minute one block confirmation. Obviously
all smartphones with 3G have a downstream bandwidth much higher,
averaging 1 Mbps. So the whole synchronization will be done less than a
1-minute block confirmation.

According to CISCO mobile bandwidth connection speed increases 20% every
year. In four years, it will have doubled, so mobile phones with lower
than average data connection will soon be able to catchup.
Also there is low-hanging-fruit optimizations to the protocol that have
not been implemented: each header is 80 bytes in length. When a set of
chained headers is transferred, the headers could be compressed,
stripping 32 bytes of each header that is derived from the previous
header hash digest. So a 40% compression is already possible by slightly
modifying the wire protocol.

7. There has been insufficient testing and/or insufficient research into
technical/economic implications or reducing the block rate

This is partially true. in the GHOST paper, this has been analyzed, and
the problem was shown to be solvable for block intervals of just a few
seconds. There are several proof-of-work cryptocurrencies in existence
that have lower than 1 minute block intervals and they work just fine.
First there was Bitcoin with a 10 minute interval, then was LiteCoin
using a 2.5 interval, then was DogeCoin with 1 minute, and then
QuarkCoin with just 30 seconds. Every new cryptocurrency lowers it a
little bit. Some time ago I decided to research on the block rate to
understand how the block interval impacts the stability and capability
of the cryptocurrency network, and I came up with the idea of the DECOR+
protocol [4] (which requires changes in the consensus code). In my
research I also showed how the stale rate can be easily reduced only
with changes in the networking code, and not in the consensus code.
These networking optimizations ( O(1) propagation using headers-first or
IBLTs), can be added later.

Mortifying Bitcoin to accommodate the change to lower the block rate
requires at least:

- Changing the 21 BTC reward per block to 2.1 BTC
- Changing the nPowTargetTimespan constant
- Writing code to hard-fork automatically when the majority of miners
have upgraded.
- Allow transaction version 3, and interpret nLockTimes of transaction
version 2 as being multiplied by 10.

All changes comprises no more than 15 lines of code. This is much less
than the number of lines modified by Gavin's 20Mb patch.

As a conclusion, I haven't yet heard a good argument against lowering
the block rate.

Best regards,
 Sergio.

[0] https://medium.com/@octskyward/the-capacity-cliff-586d1bf7715e
[1] https://bitslog.wordpress.com/2014/02/17/5-sec-block-interval/
[2] http://gavinandresen.ninja/time-to-roll-out-bigger-blocks
[3]
http://www.cisco.com/c/en/us/solutions/collateral/service-provider/visual-networking-index-vni/white_paper_c11-520862.html
[4] https://bitslog.wordpress.com/2014/05/02/decor/

------------------------------------------------------------------------------
One dashboard for servers and applications across Physical-Virtual-Cloud
Widest out-of-the-box monitoring support with 50+ applications
Performance metrics, stats and reports that give you Actionable Insights
Deep dive visibility with transaction tracing using APM Insight.
http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
_______________________________________________
Bitcoin-development mailing list
Bitcoin-development at lists.sourceforge.net
https://lists.sourceforge.net/lists/listinfo/bitcoin-development
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150511/daee8db4/attachment.html>

From dave at hashingit.com  Mon May 11 08:16:17 2015
From: dave at hashingit.com (Dave Hudson)
Date: Mon, 11 May 2015 09:16:17 +0100
Subject: [Bitcoin-development] Reducing the block rate instead of
	increasing	the maximum block size
In-Reply-To: <BAY403-EAS184981B0219DEB969D407CC2DB0@phx.gbl>
References: <BAY403-EAS184981B0219DEB969D407CC2DB0@phx.gbl>
Message-ID: <4C4AB2DC-CB50-4733-B341-7B7A6B7AD801@hashingit.com>

I proposed the same thing last year (there's a video of the presentation I was giving somewhere around). My intuition was that this would require slowly reducing the inter-block time, probably by step reductions at particular block heights.

Having had almost a year to think about it some more there are a few subtleties:

1) I think it could discourage decentralisation if the nominal 2 week period per difficulty retarget is retained. If we reached 4032 blocks and a 5 minute block time then there would be 2x as many blocks at any given difficulty which increases the odds of a smaller pool finding a block and thus getting a reward. Block rewards would have to drop in proportion to the reduced interval to keep the total schedule of 21M coins on track though, but the reduction in variance is a win for smaller miners.

2) There are limits to the block time. The speed of light is an ultimately limiting factor here, but we would want to avoid excessive orphan rates.

3) There would be some amount of confusion about numbers of confirmations. I actually think that confirmation numbers are a really misleading idea anyway and it would be safer to think in terms of "minutes of security". A zero conf transaction has "zero minutes", while right now 1, 2, 3 and 6 would be "ten minutes", "twenty minutes", "thirty minutes" and "sixty minutes" respectively. If our block time were 5 minutes then 8 confirmations would be "forty minutes" of security; if the block time was 2.5 minutes then 8 confirmations would be "twenty minutes" of security. The "minutes of security" measure indicates the mean number of minutes of the entire network's hash rate would be required to undo a transaction.

4) Reducing the inter-block time reduces the variance in reaching that "sixty minutes" of security level. The variance around finding 6 blocks with a ten minute interval is much wider than the variance for finding 12 blocks with a 5 minute interval.



> On 11 May 2015, at 08:30, Thy Shizzle <thyshizzle at outlook.com> wrote:
> 
> Yes This!
> 
> So many people seem hung up on growing the block size! If gaining a higher tps throughput is the main aim, I think that this proposition to speed up block creation has merit!
> 
> Yes it will lead to an increase in the block chain still due to 1mb ~1 minute instead of ~10 minute, but the change to the protocol is minor, you are only adding in a different difficulty rate starting from hight blah, no new features or anything are being added so there seems to me much less of a security risk! Also that impact if a hard fork should be minimal because there is nothing but absolute incentive for miners to mine at the new easier difficulty!
> 
> I feel this deserves a great deal of consideration as opposed to blowing out the block through miners voting etc!!!!
> From: Sergio Lerner <mailto:sergiolerner at certimix.com>
> Sent: ?11/?05/?2015 5:05 PM
> To: bitcoin-development at lists.sourceforge.net <mailto:bitcoin-development at lists.sourceforge.net>
> Subject: [Bitcoin-development] Reducing the block rate instead of increasing the maximum block size
> 
> In this e-mail I'll do my best to argue than if you accept that
> increasing the transactions/second is a good direction to go, then
> increasing the maximum block size is not the best way to do it. I argue
> that the right direction to go is to decrease the block rate to 1
> minute, while keeping the block size limit to 1 Megabyte (or increasing
> it from a lower value such as 100 Kbyte and then have a step function).
> I'm backing up my claims with many hours of research simulating the
> Bitcoin network under different conditions [1].  I'll try to convince
> you by responding to each of the arguments I've heard against it.
> 
> Arguments against reducing the block interval
> 
> 1. It will encourage centralization, because participants of mining
> pools will loose more money because of excessive initial block template
> latency, which leads to higher stale shares
> 
> When a new block is solved, that information needs to propagate
> throughout the Bitcoin network up to the mining pool operator nodes,
> then a new block header candidate is created, and this header must be
> propagated to all the mining pool users, ether by a push or a pull
> model. Generally the mining server pushes new work units to the
> individual miners. If done other way around, the server would need to
> handle a high load of continuous work requests that would be difficult
> to distinguish from a DDoS attack. So if the server pushes new block
> header candidates to clients, then the problem boils down to increasing
> bandwidth of the servers to achieve a tenfold increase in work
> distribution. Or distributing the servers geographically to achieve a
> lower latency. Propagating blocks does not require additional CPU
> resources, so mining pools administrators would need to increase
> moderately their investment in the server infrastructure to achieve
> lower latency and higher bandwidth, but I guess the investment would be low.
> 
> 2. It will increase the probability of a block-chain split
> 
> The convergence of the network relies on the diminishing probability of
> two honest miners creating simultaneous competing blocks chains. To
> increase the competition chain, competing blocks must be generated in
> almost simultaneously (in the same time window approximately bounded by
> the network average block propagation delay). The probability of a block
> competition decreases exponentially with the number of blocks. In fact,
> the probability of a sustained competition on ten 1-minute blocks is one
> million times lower than the probability of a competition of one
> 10-minute block. So even if the competition probability of six 1-minute
> blocks is higher than of six ten-minute blocks, this does not imply
> reducing the block rate increases this chance, but on the contrary, 
> reduces it.
> 
> 3, It will reduce the security of the network
> 
> The security of the network is based on two facts:
> A- The miners are incentivized to extend the best chain
> B- The probability of a reversal based on a long block competition
> decreases as more confirmation blocks are appended.
> C- Renting or buying hardware to perform a 51% attack is costly.
> 
> A still holds. B holds for the same amount of confirmation blocks, so 6
> confirmation blocks in a 10-minute block-chain is approximately
> equivalent to 6 confirmation blocks in a 1-minute block-chain.
> Only C changes, as renting the hashing power for 6 minutes is ten times
> less expensive as renting it for 1 hour. However, there is no shop where
> one can find 51% of the hashing power to rent right now, nor probably
> will ever be if Bitcoin succeeds. Last, you can still have a 1 hour
> confirmation (60 1-minute blocks) if you wish for high-valued payments,
> so the security decreases only if participant wish to decrease it.
> 
> 4. Reducing the block propagation time on the average case is good, but
> what happen in the worse case?
> 
> Most methods proposed to reduce the block propagation delay do it only
> on the average case. Any kind of block compression relies on both
> parties sharing some previous information. In the worse case it's true
> that a miner can create and try to broadcast a block that takes too much
> time to verify or bandwidth to transmit. This is currently true on the
> Bitcoin network. Nevertheless there is no such incentive for miners,
> since they will be shooting on their own foots. Peter Todd has argued
> that the best strategy for miners is actually to reach 51% of the
> network, but not more. In other words, to exclude the slowest 49%
> percent. But this strategy of creating bloated blocks is too risky in
> practice, and surely doomed to fail, as network conditions dynamically 
> change. Also it would be perceived as an attack to the network, and the
> miner (if it is a public mining pool) would be probably blacklisted.
> 
> 5. Thousands of SPV wallets running in mobile devices would need to be
> upgraded (thanks Mike).
> 
> That depends on the current upgrade rate for SPV wallets like Bitcoin
> Wallet  and BreadWallet. Suppose that the upgrade rate is 80%/year: we
> develop the source code for the change now and apply the change in Q2
> 2016, then  most of the nodes will already be upgraded by when the
> hardfork takes place. Also a public notice telling people to upgrade in
> web pages, bitcointalk, SPV wallets warnings, coindesk, one year in
> advance will give plenty of time to SPV wallet users to upgrade.
> 
> 6. If there are 10x more blocks, then there are 10x more block headers,
> and that increases the amount of bandwidth SPV wallets need to catch up
> with the chain
>  
> A standard smartphone with average cellular downstream speed downloads
> 2.6 headers per second (1600 kbits/sec) [3], so if synchronization were
> to be done only at night when the phone is connected to the power line,
> then it would take 9 minutes to synchronize with 1440 headers/day. If a
> person should accept a payment, and the smart-phone is 1 day
> out-of-synch, then it takes less time to download all the missing
> headers than to wait for a 10-minute one block confirmation. Obviously
> all smartphones with 3G have a downstream bandwidth much higher,
> averaging 1 Mbps. So the whole synchronization will be done less than a
> 1-minute block confirmation.
>  
> According to CISCO mobile bandwidth connection speed increases 20% every
> year. In four years, it will have doubled, so mobile phones with lower
> than average data connection will soon be able to catchup.
> Also there is low-hanging-fruit optimizations to the protocol that have
> not been implemented: each header is 80 bytes in length. When a set of
> chained headers is transferred, the headers could be compressed,
> stripping 32 bytes of each header that is derived from the previous
> header hash digest. So a 40% compression is already possible by slightly
> modifying the wire protocol.
>  
> 7. There has been insufficient testing and/or insufficient research into
> technical/economic implications or reducing the block rate
>  
> This is partially true. in the GHOST paper, this has been analyzed, and
> the problem was shown to be solvable for block intervals of just a few
> seconds. There are several proof-of-work cryptocurrencies in existence
> that have lower than 1 minute block intervals and they work just fine.
> First there was Bitcoin with a 10 minute interval, then was LiteCoin
> using a 2.5 interval, then was DogeCoin with 1 minute, and then
> QuarkCoin with just 30 seconds. Every new cryptocurrency lowers it a
> little bit. Some time ago I decided to research on the block rate to
> understand how the block interval impacts the stability and capability
> of the cryptocurrency network, and I came up with the idea of the DECOR+
> protocol [4] (which requires changes in the consensus code). In my
> research I also showed how the stale rate can be easily reduced only
> with changes in the networking code, and not in the consensus code.
> These networking optimizations ( O(1) propagation using headers-first or
> IBLTs), can be added later.
>  
> Mortifying Bitcoin to accommodate the change to lower the block rate
> requires at least:
>  
> - Changing the 21 BTC reward per block to 2.1 BTC
> - Changing the nPowTargetTimespan constant
> - Writing code to hard-fork automatically when the majority of miners
> have upgraded.
> - Allow transaction version 3, and interpret nLockTimes of transaction
> version 2 as being multiplied by 10.
> 
> All changes comprises no more than 15 lines of code. This is much less
> than the number of lines modified by Gavin's 20Mb patch.
>  
> As a conclusion, I haven't yet heard a good argument against lowering
> the block rate.
> 
> Best regards,
>  Sergio.
>  
> [0] https://medium.com/@octskyward/the-capacity-cliff-586d1bf7715e <https://medium.com/@octskyward/the-capacity-cliff-586d1bf7715e>
> [1] https://bitslog.wordpress.com/2014/02/17/5-sec-block-interval/ <https://bitslog.wordpress.com/2014/02/17/5-sec-block-interval/>
> [2] http://gavinandresen.ninja/time-to-roll-out-bigger-blocks <http://gavinandresen.ninja/time-to-roll-out-bigger-blocks>
> [3]
> http://www.cisco.com/c/en/us/solutions/collateral/service-provider/visual-networking-index-vni/white_paper_c11-520862.html <http://www.cisco.com/c/en/us/solutions/collateral/service-provider/visual-networking-index-vni/white_paper_c11-520862.html>
> [4] https://bitslog.wordpress.com/2014/05/02/decor/ <https://bitslog.wordpress.com/2014/05/02/decor/>
> 
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud 
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y <http://ad.doubleclick.net/ddm/clk/290420510;117567292;y>
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development <https://lists.sourceforge.net/lists/listinfo/bitcoin-development>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud 
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y_______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150511/e26992a3/attachment.html>

From insecurity at national.shitposting.agency  Mon May 11 08:50:20 2015
From: insecurity at national.shitposting.agency (insecurity at national.shitposting.agency)
Date: Mon, 11 May 2015 08:50:20 +0000
Subject: [Bitcoin-development]
 =?utf-8?q?Reducing_the_block_rate_instead_o?=
 =?utf-8?q?f_increasing=09the_maximum_block_size?=
Message-ID: <0cda31e339cfa74351ff7264ac07b406@national.shitposting.agency>

> So if the server pushes new block
> header candidates to clients, then the problem boils down to increasing
> bandwidth of the servers to achieve a tenfold increase in work
> distribution.

Most Stratum pools already do multiple updates of the header every block 
period,
bandwidth is really inconsequential, it's the latency that kills. At the 
present
time you are looking up to 15 seconds between the first and last pools 
to push
headers to their clients for the latest block. It's sort of 
inconsequential with
a 10 minute block time, but it cuts into a 1 minute one very heavily.

Some pools already don't do their own validation of blocks, but simply 
mirror
other pools, pushing them to be even more latency focused will just make 
this an
epidemic of invalidity rather than a solution.


> There are several proof-of-work cryptocurrencies in existence
> that have lower than 1 minute block intervals and they work just fine.
> First there was Bitcoin with a 10 minute interval, then was LiteCoin
> using a 2.5 interval, then was DogeCoin with 1 minute, and then
> QuarkCoin with just 30 seconds.

You can't really use these as examples of things going just fine. None 
of these
networks see anything approaching the Bitcoin transaction volume and 
none have
even remotely the same network size. Some Bitcoin forks use floats in 
consensus
critical code and work "just fine", for the moment. We can't justify 
poor
decisions with "but the altcoins are doing it".

Is there even a single study of the stale rates within these networks?



From pete at petertodd.org  Mon May 11 10:34:02 2015
From: pete at petertodd.org (Peter Todd)
Date: Mon, 11 May 2015 06:34:02 -0400
Subject: [Bitcoin-development] Reducing the block rate instead of
 increasing the maximum block size
In-Reply-To: <55505441.3010906@certimix.com>
References: <55505441.3010906@certimix.com>
Message-ID: <20150511103402.GA21748@savin.petertodd.org>

On Mon, May 11, 2015 at 04:03:29AM -0300, Sergio Lerner wrote:
> Arguments against reducing the block interval
> 
> 1. It will encourage centralization, because participants of mining
> pools will loose more money because of excessive initial block template
> latency, which leads to higher stale shares
> 
> When a new block is solved, that information needs to propagate
> throughout the Bitcoin network up to the mining pool operator nodes,
> then a new block header candidate is created, and this header must be
> propagated to all the mining pool users, ether by a push or a pull
> model. Generally the mining server pushes new work units to the
> individual miners. If done other way around, the server would need to
> handle a high load of continuous work requests that would be difficult
> to distinguish from a DDoS attack. So if the server pushes new block
> header candidates to clients, then the problem boils down to increasing
> bandwidth of the servers to achieve a tenfold increase in work
> distribution. Or distributing the servers geographically to achieve a
> lower latency. Propagating blocks does not require additional CPU
> resources, so mining pools administrators would need to increase
> moderately their investment in the server infrastructure to achieve
> lower latency and higher bandwidth, but I guess the investment would be low.

It's *way* easier to buy more bandwidth that it is to get lower latency.

After all, getting to the other side of the planet via fiber takes at
*minimum* 100ms simply due to the speed of light; routing overheads
approximately double or triple that for all but highly specialized and
very, very expensive, networking services. Bandwidth simply can't fix
the speed of light.

It's also not at all realistic or desirable to assume connectivity in a
single hop, so you can again multiply that base latency by 2-5 times.

And on top of *that* you have to take into account latency from hasher
to mining pool - time that the hashing power isn't working on the new
block because they're work unit hasn't been updated matters just as much
as the time to get that block to the pool in the first place. Being
forced to reduce that latency is very damaging to the ecosystem as
you're making it more profitable to keep hashing power centralized.

In any case, even with 10 minute blocks pools already pay a lot of
attention to latency... Why make that problem 10x worse?

> 2. It will increase the probability of a block-chain split
> 
> The convergence of the network relies on the diminishing probability of
> two honest miners creating simultaneous competing blocks chains. To
> increase the competition chain, competing blocks must be generated in
> almost simultaneously (in the same time window approximately bounded by
> the network average block propagation delay). The probability of a block
> competition decreases exponentially with the number of blocks. In fact,
> the probability of a sustained competition on ten 1-minute blocks is one
> million times lower than the probability of a competition of one
> 10-minute block. So even if the competition probability of six 1-minute
> blocks is higher than of six ten-minute blocks, this does not imply
> reducing the block rate increases this chance, but on the contrary, 
> reduces it.

Can you explain your reasoning here in detail?

> 4. Reducing the block propagation time on the average case is good, but
> what happen in the worse case?
> 
> Most methods proposed to reduce the block propagation delay do it only
> on the average case. Any kind of block compression relies on both
> parties sharing some previous information. In the worse case it's true
> that a miner can create and try to broadcast a block that takes too much
> time to verify or bandwidth to transmit. This is currently true on the
> Bitcoin network. Nevertheless there is no such incentive for miners,
> since they will be shooting on their own foots. Peter Todd has argued
> that the best strategy for miners is actually to reach 51% of the
> network, but not more. In other words, to exclude the slowest 49%

Actually the correct figure is less than ~30%:

http://www.mail-archive.com/bitcoin-development at lists.sourceforge.net/msg03200.html

> percent. But this strategy of creating bloated blocks is too risky in
> practice, and surely doomed to fail, as network conditions dynamically 
> change.

They dynamically change? Source?

Remember that the strategy still gives you a benefit if you simply
target, say, 75% rather than the minimum threshold.

> Also it would be perceived as an attack to the network, and the
> miner (if it is a public mining pool) would be probably blacklisted.

How do you see that blacklisting actually being done?

Equally, it's easy to portray such mining as being "for the good of
Bitcoin" - "we're just making transaction cheap! tough luck if your
shitty pool can't keep up" This is quite unlike selfish mining.

> 7. There has been insufficient testing and/or insufficient research into
> technical/economic implications or reducing the block rate
>  
> This is partially true. in the GHOST paper, this has been analyzed, and
> the problem was shown to be solvable for block intervals of just a few
> seconds.

GHOST works radically differently than a linear blockchain, and it's not
clear that it actually has the correct economic incentives.

> These networking optimizations ( O(1) propagation using headers-first or
> IBLTs), can be added later.

Keep in mind that miners already use optimized propagation techniques,
like p2pool's implementation or Matt Corallo's block relaying network.

-- 
'peter'[:-1]@petertodd.org
00000000000000000c2b75113c6d2539f436ee9ac90abf620d9d3a3a4a19d3e8
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150511/7490b435/attachment.sig>

From insecurity at national.shitposting.agency  Mon May 11 11:10:09 2015
From: insecurity at national.shitposting.agency (insecurity at national.shitposting.agency)
Date: Mon, 11 May 2015 11:10:09 +0000
Subject: [Bitcoin-development] Reducing the block rate instead of
 increasing the maximum block size
In-Reply-To: <20150511103402.GA21748@savin.petertodd.org>
References: <55505441.3010906@certimix.com>
	<20150511103402.GA21748@savin.petertodd.org>
Message-ID: <66648462658adebb5e5be7fcba65e670@national.shitposting.agency>

On 2015-05-11 10:34, Peter Todd wrote:
> How do you see that blacklisting actually being done?

Same way ghash.io was banned from the network when used Finney attacks
against BetCoin Dice.

As Andreas Antonopoulos says, if any of the miners do anything bad, we
just ban them from mining. Any sort of attack like this only lasts 10
minutes as a result. Stop worrying so much.

https://youtu.be/ncPyMUfNyVM?t=20s





From dave at hashingit.com  Mon May 11 11:49:03 2015
From: dave at hashingit.com (Dave Hudson)
Date: Mon, 11 May 2015 12:49:03 +0100
Subject: [Bitcoin-development] Reducing the block rate instead of
	increasing the maximum block size
In-Reply-To: <66648462658adebb5e5be7fcba65e670@national.shitposting.agency>
References: <55505441.3010906@certimix.com>
	<20150511103402.GA21748@savin.petertodd.org>
	<66648462658adebb5e5be7fcba65e670@national.shitposting.agency>
Message-ID: <DF13D23D-1F04-4970-A80A-4892374E5247@hashingit.com>


> On 11 May 2015, at 12:10, insecurity at national.shitposting.agency wrote:
> 
> On 2015-05-11 10:34, Peter Todd wrote:
>> How do you see that blacklisting actually being done?
> 
> Same way ghash.io was banned from the network when used Finney attacks
> against BetCoin Dice.
> 
> As Andreas Antonopoulos says, if any of the miners do anything bad, we
> just ban them from mining. Any sort of attack like this only lasts 10
> minutes as a result. Stop worrying so much.

This doesn't work because a large-scale miner can trivially make themselves look like a very large number of much smaller scale miners. Their ability to minimize variance comes from the cumulative totals they control so 10 pools of 1% of the network cumulatively have the same variance as 1 pool with 10% of the network. It's also very easy for miners to relay blocks via different addresses and the cost is minimal. The biggest cost would be in DDoS prevention and a miner that actually split their pool into lots of small fragments would actually give themselves the ability to do quite a lot of DDoS mitigation anyway. If no-one is doing this right now it's simply because they've not had the right incentives to make it worthwhile; if the incentives make it worthwhile then this is pretty trivial to do.

This is one area where anonymity on behalf of transaction validators and block makers essentially makes it pretty-much impossible to maintain any sort of sanctions against antisocial behaviour.


From decker.christian at gmail.com  Mon May 11 12:34:43 2015
From: decker.christian at gmail.com (Christian Decker)
Date: Mon, 11 May 2015 12:34:43 +0000
Subject: [Bitcoin-development] Reducing the block rate instead of
 increasing the maximum block size
In-Reply-To: <DF13D23D-1F04-4970-A80A-4892374E5247@hashingit.com>
References: <55505441.3010906@certimix.com>
	<20150511103402.GA21748@savin.petertodd.org>
	<66648462658adebb5e5be7fcba65e670@national.shitposting.agency>
	<DF13D23D-1F04-4970-A80A-4892374E5247@hashingit.com>
Message-ID: <CALxbBHXutSo7rbPNEffWj5=ZM8JbEFuvfUvzMLjEC9106AbJ0A@mail.gmail.com>

The propagation speed gain from having smaller blocks is linear in the size
reduction, down to a small size, after which the delay of the first byte
prevails [1], however the blockchain fork rate increases superlinearly,
giving an overall worse tradeoff. A high blockchain fork rate is a symptom
of inefficient use of the network's mining resources and may give an
advantage to an attacker that is more efficient in communicating internally.

I'd strongly against increasing the block generation rate in Bitcoin, it'd
be a very controversial proposal and would not solve anything.

[1]
http://www.tik.ee.ethz.ch/file/49318d3f56c1d525aabf7fda78b23fc0/P2P2013_041.pdf

On Mon, May 11, 2015 at 1:51 PM Dave Hudson <dave at hashingit.com> wrote:

>
> > On 11 May 2015, at 12:10, insecurity at national.shitposting.agency wrote:
> >
> > On 2015-05-11 10:34, Peter Todd wrote:
> >> How do you see that blacklisting actually being done?
> >
> > Same way ghash.io was banned from the network when used Finney attacks
> > against BetCoin Dice.
> >
> > As Andreas Antonopoulos says, if any of the miners do anything bad, we
> > just ban them from mining. Any sort of attack like this only lasts 10
> > minutes as a result. Stop worrying so much.
>
> This doesn't work because a large-scale miner can trivially make
> themselves look like a very large number of much smaller scale miners.
> Their ability to minimize variance comes from the cumulative totals they
> control so 10 pools of 1% of the network cumulatively have the same
> variance as 1 pool with 10% of the network. It's also very easy for miners
> to relay blocks via different addresses and the cost is minimal. The
> biggest cost would be in DDoS prevention and a miner that actually split
> their pool into lots of small fragments would actually give themselves the
> ability to do quite a lot of DDoS mitigation anyway. If no-one is doing
> this right now it's simply because they've not had the right incentives to
> make it worthwhile; if the incentives make it worthwhile then this is
> pretty trivial to do.
>
> This is one area where anonymity on behalf of transaction validators and
> block makers essentially makes it pretty-much impossible to maintain any
> sort of sanctions against antisocial behaviour.
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150511/9b14788a/attachment.html>

From laanwj at gmail.com  Mon May 11 14:49:53 2015
From: laanwj at gmail.com (Wladimir)
Date: Mon, 11 May 2015 14:49:53 +0000
Subject: [Bitcoin-development] Fwd:  Bitcoin core 0.11 planning
In-Reply-To: <CA+s+GJBeZkWSKn4igC1ksynoQLfUpUtHBesq9MPi6yRqZZr4Gw@mail.gmail.com>
References: <20150428074414.GA19918@amethyst.visucore.com>
	<4E63339A-69B1-4885-9D7F-6D14E75CE174@petertodd.org>
	<CAPg+sBjc4iguJ8KCnUf9LrLbPkWEMc5fvr7XZsA48XQKaecN5g@mail.gmail.com>
	<CA+s+GJBeZkWSKn4igC1ksynoQLfUpUtHBesq9MPi6yRqZZr4Gw@mail.gmail.com>
Message-ID: <CA+s+GJCC=wQFnFnrukeDvt=dAncBTScBq84Vh_fCXnYc2Vq45g@mail.gmail.com>

On Tue, Apr 28, 2015 at 11:01 AM, Pieter Wuille <pieter.wuille at gmail.com> wrote:
> As softforks almost certainly require backports to older releases and other
> software anyway, I don't think they should necessarily be bound to Bitcoin
> Core major releases. If they don't require large code changes, we can easily
> do them in minor releases too.

Agree here - there is no need to time consensus changes with a major
release, as they need to be ported back to older releases anyhow.
(I don't really classify them as software features, but properties of
the underlying system that we need to adopt to)

Wladimir



From laanwj at gmail.com  Mon May 11 15:00:03 2015
From: laanwj at gmail.com (Wladimir)
Date: Mon, 11 May 2015 15:00:03 +0000
Subject: [Bitcoin-development] Bitcoin core 0.11 planning
In-Reply-To: <20150428074414.GA19918@amethyst.visucore.com>
References: <20150428074414.GA19918@amethyst.visucore.com>
Message-ID: <CA+s+GJDtduxkc4aVL_s_vhu_jh+3XmnuP2N6UHD=FcLiiZAUmQ@mail.gmail.com>

A reminder - feature freeze and string freeze is coming up this Friday the 15th.

Let me know if your pull request is ready to be merged before then,

Wladimir

On Tue, Apr 28, 2015 at 7:44 AM, Wladimir J. van der Laan
<laanwj at gmail.com> wrote:
> Hello all,
>
> The release window for 0.11 is nearing, I'd propose the following schedule:
>
> 2015-05-01  Soft translation string freeze
>             Open Transifex translations for 0.11
>             Finalize and close translation for 0.9
>
> 2015-05-15  Feature freeze, string freeze
>
> 2015-06-01  Split off 0.11 branch
>             Tag and release 0.11.0rc1
>             Start merging for 0.12 on master branch
>
> 2015-07-01  Release 0.11.0 final (aim)
>
> In contrast to former releases, which were protracted for months, let's try to be more strict about the dates. Of course it is always possible for last-minute critical issues to interfere with the planning. The release will not be held up for features, though, and anything that will not make it to 0.11 will be postponed to next release scheduled for end of the year.
>
> Wladimir



From thomasv at electrum.org  Mon May 11 16:28:46 2015
From: thomasv at electrum.org (Thomas Voegtlin)
Date: Mon, 11 May 2015 18:28:46 +0200
Subject: [Bitcoin-development] Long-term mining incentives
Message-ID: <5550D8BE.6070207@electrum.org>

The discussion on block size increase has brought some attention to the
other elephant in the room: Long-term mining incentives.

Bitcoin derives its current market value from the assumption that a
stable, steady-state regime will be reached in the future, where miners
have an incentive to keep mining to protect the network. Such a steady
state regime does not exist today, because miners get most of their
reward from the block subsidy, which will progressively be removed.

Thus, today's 3 billion USD question is the following: Will a steady
state regime be reached in the future? Can such a regime exist? What are
the necessary conditions for its existence?

Satoshi's paper suggests that this may be achieved through miner fees.
Quite a few people seem to take this for granted, and are working to
make it happen (developing cpfp and replace-by-fee). This explains part
of the opposition to raising the block size limit; some people would
like to see some fee pressure building up first, in order to get closer
to a regime where miners are incentivised by transaction fees instead of
block subsidy. Indeed, the emergence of a working fee market would be
extremely reassuring for the long-term viability of bitcoin. So, the
thinking goes, by raising the block size limit, we would be postponing a
crucial reality check. We would be buying time, at the expenses of
Bitcoin's decentralization.

OTOH, proponents of a block size increase have a very good point: if the
block size is not raised soon, Bitcoin is going to enter a new, unknown
and potentially harmful regime. In the current regime, almost all
transaction get confirmed quickly, and fee pressure does not exist. Mike
Hearn suggested that, when blocks reach full capacity and users start to
experience confirmation delays and confirmation uncertainty, users will
simply go away and stop using Bitcoin. To me, that outcome sounds very
plausible indeed. Thus, proponents of the block size increase are
conservative; they are trying to preserve the current regime, which is
known to work, instead of letting the network enter uncharted territory.

My problem is that this seems to lacks a vision. If the maximal block
size is increased only to buy time, or because some people think that 7
tps is not enough to compete with VISA, then I guess it would be
healthier to try and develop off-chain infrastructure first, such as the
Lightning network.

OTOH, I also fail to see evidence that a limited block capacity will
lead to a functional fee market, able to sustain a steady state. A
functional market requires well-informed participants who make rational
choices and accept the outcomes of their choices. That is not the case
today, and to believe that it will magically happen because blocks start
to reach full capacity sounds a lot like like wishful thinking.

So here is my question, to both proponents and opponents of a block size
increase: What steady-state regime do you envision for Bitcoin, and what
is is your plan to get there? More specifically, how will the
steady-state regime look like? Will users experience fee pressure and
delays, or will it look more like a scaled up version of what we enjoy
today? Should fee pressure be increased jointly with subsidy decrease,
or as soon as possible, or never? What incentives will exist for miners
once the subsidy is gone? Will miners have an incentive to permanently
fork off the last block and capture its fees? Do you expect Bitcoin to
work because miners are altruistic/selfish/honest/caring?

A clear vision would be welcome.



From insecurity at national.shitposting.agency  Mon May 11 16:52:10 2015
From: insecurity at national.shitposting.agency (insecurity at national.shitposting.agency)
Date: Mon, 11 May 2015 16:52:10 +0000
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <5550D8BE.6070207@electrum.org>
References: <5550D8BE.6070207@electrum.org>
Message-ID: <ce3d34c92efd1cf57326e4679550944e@national.shitposting.agency>

On 2015-05-11 16:28, Thomas Voegtlin wrote:
> My problem is that this seems to lacks a vision. If the maximal block
> size is increased only to buy time, or because some people think that 7
> tps is not enough to compete with VISA, then I guess it would be
> healthier to try and develop off-chain infrastructure first, such as 
> the
> Lightning network.

If your end goal is "compete with VISA" you might as well just give up
and go home right now. There's lots of terrible proposals where people
try to demonstrate that so many hundred thousand transactions a second
are possible if we just make the block size 500GB. In the real world
with physical limits, you literally can not verify more than a few
thousand ECDSA signatures a second on a CPU core. The tradeoff taken
in Bitcoin is that the signatures are pretty small, but they are also
slow to verify on any sort of scale. There's no way competing with a
centralised entity using on-chain transactions is even a sane goal.



From luke at dashjr.org  Mon May 11 16:47:47 2015
From: luke at dashjr.org (Luke Dashjr)
Date: Mon, 11 May 2015 16:47:47 +0000
Subject: [Bitcoin-development] Reducing the block rate instead of
	increasing the maximum block size
In-Reply-To: <55505441.3010906@certimix.com>
References: <55505441.3010906@certimix.com>
Message-ID: <201505111647.51088.luke@dashjr.org>

On Monday, May 11, 2015 7:03:29 AM Sergio Lerner wrote:
> 1. It will encourage centralization, because participants of mining
> pools will loose more money because of excessive initial block template
> latency, which leads to higher stale shares
> 
> When a new block is solved, that information needs to propagate
> throughout the Bitcoin network up to the mining pool operator nodes,
> then a new block header candidate is created, and this header must be
> propagated to all the mining pool users, ether by a push or a pull
> model. Generally the mining server pushes new work units to the
> individual miners. If done other way around, the server would need to
> handle a high load of continuous work requests that would be difficult
> to distinguish from a DDoS attack. So if the server pushes new block
> header candidates to clients, then the problem boils down to increasing
> bandwidth of the servers to achieve a tenfold increase in work
> distribution. Or distributing the servers geographically to achieve a
> lower latency. Propagating blocks does not require additional CPU
> resources, so mining pools administrators would need to increase
> moderately their investment in the server infrastructure to achieve
> lower latency and higher bandwidth, but I guess the investment would be
> low.

1. Latency is what matters here, not bandwidth so much. And latency reduction 
is either expensive or impossible.
2. Mining pools are mostly run at a loss (with exception to only the most 
centralised pools), and have nothing to invest in increasing infrastructure.

> 3, It will reduce the security of the network
> 
> The security of the network is based on two facts:
> A- The miners are incentivized to extend the best chain
> B- The probability of a reversal based on a long block competition
> decreases as more confirmation blocks are appended.
> C- Renting or buying hardware to perform a 51% attack is costly.
> 
> A still holds. B holds for the same amount of confirmation blocks, so 6
> confirmation blocks in a 10-minute block-chain is approximately
> equivalent to 6 confirmation blocks in a 1-minute block-chain.
> Only C changes, as renting the hashing power for 6 minutes is ten times
> less expensive as renting it for 1 hour. However, there is no shop where
> one can find 51% of the hashing power to rent right now, nor probably
> will ever be if Bitcoin succeeds. Last, you can still have a 1 hour
> confirmation (60 1-minute blocks) if you wish for high-valued payments,
> so the security decreases only if participant wish to decrease it.

You're overlooking at least:
1. The real network has to suffer wasted work as a result of the stale blocks, 
while an attacker does not. If 20% of blocks are stale, the attacker only 
needs 40% of the legitimate hashrate to achieve 50%-in-practice.
2. Since blocks are individually weaker, it becomes cheaper to DoS nodes with 
invalid blocks. (not sure if this is a real concern, but it ought to be 
considered and addressed)

> 4. Reducing the block propagation time on the average case is good, but
> what happen in the worse case?
> 
> Most methods proposed to reduce the block propagation delay do it only
> on the average case. Any kind of block compression relies on both
> parties sharing some previous information. In the worse case it's true
> that a miner can create and try to broadcast a block that takes too much
> time to verify or bandwidth to transmit. This is currently true on the
> Bitcoin network. Nevertheless there is no such incentive for miners,
> since they will be shooting on their own foots. Peter Todd has argued
> that the best strategy for miners is actually to reach 51% of the
> network, but not more. In other words, to exclude the slowest 49%
> percent. But this strategy of creating bloated blocks is too risky in
> practice, and surely doomed to fail, as network conditions dynamically
> change. Also it would be perceived as an attack to the network, and the
> miner (if it is a public mining pool) would be probably blacklisted.

One can probably overcome changing network conditions merely by trying to 
reach 75% and exclude the slowest 25%. Also, there is no way to identify or 
blacklist miners.

> 5. Thousands of SPV wallets running in mobile devices would need to be
> upgraded (thanks Mike).
> 
> That depends on the current upgrade rate for SPV wallets like Bitcoin
> Wallet  and BreadWallet. Suppose that the upgrade rate is 80%/year: we
> develop the source code for the change now and apply the change in Q2
> 2016, then  most of the nodes will already be upgraded by when the
> hardfork takes place. Also a public notice telling people to upgrade in
> web pages, bitcointalk, SPV wallets warnings, coindesk, one year in
> advance will give plenty of time to SPV wallet users to upgrade.

I agree this shouldn't be a real concern. SPV wallets are also more likely and 
less risky (globally) to be auto-updated.

> 6. If there are 10x more blocks, then there are 10x more block headers,
> and that increases the amount of bandwidth SPV wallets need to catch up
> with the chain
> 
> A standard smartphone with average cellular downstream speed downloads
> 2.6 headers per second (1600 kbits/sec) [3], so if synchronization were
> to be done only at night when the phone is connected to the power line,
> then it would take 9 minutes to synchronize with 1440 headers/day. If a
> person should accept a payment, and the smart-phone is 1 day
> out-of-synch, then it takes less time to download all the missing
> headers than to wait for a 10-minute one block confirmation. Obviously
> all smartphones with 3G have a downstream bandwidth much higher,
> averaging 1 Mbps. So the whole synchronization will be done less than a
> 1-minute block confirmation.

Uh, I think you need to be using at least median speeds. As an example, I can 
only sustain (over 3G) about 40 kbps, with a peak of around 400 kbps. 3G has 
worse range/coverage than 2G. No doubt the *average* is skewed so high because 
of densely populated areas like San Francisco having 400+ Mbps cellular data. 
It's not reasonable to assume sync only at night: most payments will be during 
the day, on battery - so increased power use must also be considered.

> According to CISCO mobile bandwidth connection speed increases 20% every
> year.

Only in small densely populated areas of first-world countries.

Luke



From gavinandresen at gmail.com  Mon May 11 17:29:02 2015
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Mon, 11 May 2015 13:29:02 -0400
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <ce3d34c92efd1cf57326e4679550944e@national.shitposting.agency>
References: <5550D8BE.6070207@electrum.org>
	<ce3d34c92efd1cf57326e4679550944e@national.shitposting.agency>
Message-ID: <CABsx9T1VgxEJWxrYTs+2hXGnGrSLGJ6mVcAexjXLvK7Vu+e3EA@mail.gmail.com>

I think long-term the chain will not be secured purely by proof-of-work. I
think when the Bitcoin network was tiny running solely on people's home
computers proof-of-work was the right way to secure the chain, and the only
fair way to both secure the chain and distribute the coins.

See https://gist.github.com/gavinandresen/630d4a6c24ac6144482a  for some
half-baked thoughts along those lines. I don't think proof-of-work is the
last word in distributed consensus (I also don't think any alternatives are
anywhere near ready to deploy, but they might be in ten years).

I also think it is premature to worry about what will happen in twenty or
thirty years when the block subsidy is insignificant. A lot will happen in
the next twenty years. I could spin a vision of what will secure the chain
in twenty years, but I'd put a low probability on that vision actually
turning out to be correct.

That is why I keep saying Bitcoin is an experiment. But I also believe that
the incentives are correct, and there are a lot of very motivated, smart,
hard-working people who will make it work. When you're talking about trying
to predict what will happen decades from now, I think that is the best you
can (honestly) do.

-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150511/98eda946/attachment.html>

From dgomez1092 at gmail.com  Mon May 11 20:20:46 2015
From: dgomez1092 at gmail.com (Damian Gomez)
Date: Mon, 11 May 2015 13:20:46 -0700
Subject: [Bitcoin-development] Bitcoin-development Digest, Vol 48,
	Issue 62
In-Reply-To: <mailman.239076.1431365350.2287.bitcoin-development@lists.sourceforge.net>
References: <mailman.239076.1431365350.2287.bitcoin-development@lists.sourceforge.net>
Message-ID: <CAH+jCTzgd+o56SNZ-UGaUhyOxSf+wa=k=T4++vMN_vMJCi4xww@mail.gmail.com>

Hllo

I want to build from a conversation that I had w/ Peter (T?) regarding the
increase in block size in the bitcoin from its's current structure would be
the proposasl of an prepend to the hash chain itself that would be the
first DER decoded script in order to verify integrity(trust) within a set
of transactions and the originiator themselves.

It is my belief that the process to begin a new encryption tool using a
variant of the WinterNitz OTS for its existential unforgeability to be the
added signatures with every  Wallet transaction in order to provide a
consesnus systemt that takes into accont a personal level of intergrity for
the intention fo a transaction to occur. This signature would then be
hashes for there to be an intermediate proxy state that then verifies and
evaluates the trust fucntion for the receiving trnsactions.  This
evaluation loop would itself be a state in which the mining power and the
rewards derived from them would be an increased level of integrity as
provided for the "brainers" of a systems who are then the "signatuers" of
the transaction authenticity, and additiaonally program extranonces of x
bits {72} in order  to have a double valid signature that the rest of the
nodes would accept in order to have a valid address from which to be able
to continuously receive transactions.

There is a level of diffculty in obtaining brainers, fees would only apply
uin so much as they are able to create authentic transactions based off the
voting power of the rest of the received nodes. The greater number of
faults within the system from a brainer then the more, so would his
computational power be restricted in order to provide a reward feedback
system. This singularity in a Byzantine consensus is only achieved if the
route of an appropriate transformation occurs, one that is invariant to the
participants of the system, thus being able to provide initial vector
transformations from a person's online identity is the responsibilty that
we have to ensure and calulate a lagrangian method that utilisizes a set of
convolutional neural network funcitons [backpropagation, fuzzy logic] and
and tranformation function taking the vectors of tranformations in a
kahunen-loeve algorithm and using the convergence of a baryon wave function
in order to proceed with a baseline reading of the current level of
integrity in the state today that is an instance of actionable acceleration
within a system.

This is something that I am trying to continue to parse out. Therefore
there are still heavy questions to be answered(the most important being the
consent of the people to measure their own levels of integrity through
mined information)> There must always be the option to disconnect from a
transactional system where payments occur in order to allow a level of
solace and peace within individuals -- withour repercussions and a seperate
system that supports the offline realm as well. (THis is a design problem)

Ultimately, quite literally such a transaction system could exist to
provide detailed analysis that promotes integrity being the basis for
sharing information.  The fee structure would be eliminated, due to the
level of integrity and procesing power to have messages and transactions
and reviews of unfiduciary responsible orgnizations be merited as highly
true (.9 in fizzy logic) in order to promote a well-being in the state.
That is its own reward, the strenght of having more processing speed.


FYI(thank you to peter whom nudged my thinking and interest (again) in this
area. )

This is something I am attempting to design in order to program it. Though
I am not an expert and my technology stack is limited to java and c (and my
issues from it).  I provided a class the other day the was pseudo code for
the beginning of the consensus. Now I might to now if I am missing any of
teh technical paradigms that might make this illogical? I now with the
advent of 7petabyte computers one could easily store 2.5 petabytes of human
information for just an instance of integrity not to mention otehr
emotions.



*Also, might someone be able to provide a bit of information on Bitcoin
core project?*

thank you again. Damain.

On Mon, May 11, 2015 at 10:29 AM, <
bitcoin-development-request at lists.sourceforge.net> wrote:

> Send Bitcoin-development mailing list submissions to
>         bitcoin-development at lists.sourceforge.net
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> or, via email, send a message with subject or body 'help' to
>         bitcoin-development-request at lists.sourceforge.net
>
> You can reach the person managing the list at
>         bitcoin-development-owner at lists.sourceforge.net
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of Bitcoin-development digest..."
>
> Today's Topics:
>
>    1. Fwd:  Bitcoin core 0.11 planning (Wladimir)
>    2. Re: Bitcoin core 0.11 planning (Wladimir)
>    3. Long-term mining incentives (Thomas Voegtlin)
>    4. Re: Long-term mining incentives
>       (insecurity at national.shitposting.agency)
>    5. Re: Reducing the block rate instead of    increasing the maximum
>       block size (Luke Dashjr)
>    6. Re: Long-term mining incentives (Gavin Andresen)
>
>
> ---------- Forwarded message ----------
> From: Wladimir <laanwj at gmail.com>
> To: Bitcoin Dev <bitcoin-development at lists.sourceforge.net>
> Cc:
> Date: Mon, 11 May 2015 14:49:53 +0000
> Subject: [Bitcoin-development] Fwd: Bitcoin core 0.11 planning
> On Tue, Apr 28, 2015 at 11:01 AM, Pieter Wuille <pieter.wuille at gmail.com>
> wrote:
> > As softforks almost certainly require backports to older releases and
> other
> > software anyway, I don't think they should necessarily be bound to
> Bitcoin
> > Core major releases. If they don't require large code changes, we can
> easily
> > do them in minor releases too.
>
> Agree here - there is no need to time consensus changes with a major
> release, as they need to be ported back to older releases anyhow.
> (I don't really classify them as software features, but properties of
> the underlying system that we need to adopt to)
>
> Wladimir
>
>
>
>
> ---------- Forwarded message ----------
> From: Wladimir <laanwj at gmail.com>
> To: Bitcoin Dev <bitcoin-development at lists.sourceforge.net>
> Cc:
> Date: Mon, 11 May 2015 15:00:03 +0000
> Subject: Re: [Bitcoin-development] Bitcoin core 0.11 planning
> A reminder - feature freeze and string freeze is coming up this Friday the
> 15th.
>
> Let me know if your pull request is ready to be merged before then,
>
> Wladimir
>
> On Tue, Apr 28, 2015 at 7:44 AM, Wladimir J. van der Laan
> <laanwj at gmail.com> wrote:
> > Hello all,
> >
> > The release window for 0.11 is nearing, I'd propose the following
> schedule:
> >
> > 2015-05-01  Soft translation string freeze
> >             Open Transifex translations for 0.11
> >             Finalize and close translation for 0.9
> >
> > 2015-05-15  Feature freeze, string freeze
> >
> > 2015-06-01  Split off 0.11 branch
> >             Tag and release 0.11.0rc1
> >             Start merging for 0.12 on master branch
> >
> > 2015-07-01  Release 0.11.0 final (aim)
> >
> > In contrast to former releases, which were protracted for months, let's
> try to be more strict about the dates. Of course it is always possible for
> last-minute critical issues to interfere with the planning. The release
> will not be held up for features, though, and anything that will not make
> it to 0.11 will be postponed to next release scheduled for end of the year.
> >
> > Wladimir
>
>
>
>
> ---------- Forwarded message ----------
> From: Thomas Voegtlin <thomasv at electrum.org>
> To: Bitcoin Development <bitcoin-development at lists.sourceforge.net>
> Cc:
> Date: Mon, 11 May 2015 18:28:46 +0200
> Subject: [Bitcoin-development] Long-term mining incentives
> The discussion on block size increase has brought some attention to the
> other elephant in the room: Long-term mining incentives.
>
> Bitcoin derives its current market value from the assumption that a
> stable, steady-state regime will be reached in the future, where miners
> have an incentive to keep mining to protect the network. Such a steady
> state regime does not exist today, because miners get most of their
> reward from the block subsidy, which will progressively be removed.
>
> Thus, today's 3 billion USD question is the following: Will a steady
> state regime be reached in the future? Can such a regime exist? What are
> the necessary conditions for its existence?
>
> Satoshi's paper suggests that this may be achieved through miner fees.
> Quite a few people seem to take this for granted, and are working to
> make it happen (developing cpfp and replace-by-fee). This explains part
> of the opposition to raising the block size limit; some people would
> like to see some fee pressure building up first, in order to get closer
> to a regime where miners are incentivised by transaction fees instead of
> block subsidy. Indeed, the emergence of a working fee market would be
> extremely reassuring for the long-term viability of bitcoin. So, the
> thinking goes, by raising the block size limit, we would be postponing a
> crucial reality check. We would be buying time, at the expenses of
> Bitcoin's decentralization.
>
> OTOH, proponents of a block size increase have a very good point: if the
> block size is not raised soon, Bitcoin is going to enter a new, unknown
> and potentially harmful regime. In the current regime, almost all
> transaction get confirmed quickly, and fee pressure does not exist. Mike
> Hearn suggested that, when blocks reach full capacity and users start to
> experience confirmation delays and confirmation uncertainty, users will
> simply go away and stop using Bitcoin. To me, that outcome sounds very
> plausible indeed. Thus, proponents of the block size increase are
> conservative; they are trying to preserve the current regime, which is
> known to work, instead of letting the network enter uncharted territory.
>
> My problem is that this seems to lacks a vision. If the maximal block
> size is increased only to buy time, or because some people think that 7
> tps is not enough to compete with VISA, then I guess it would be
> healthier to try and develop off-chain infrastructure first, such as the
> Lightning network.
>
> OTOH, I also fail to see evidence that a limited block capacity will
> lead to a functional fee market, able to sustain a steady state. A
> functional market requires well-informed participants who make rational
> choices and accept the outcomes of their choices. That is not the case
> today, and to believe that it will magically happen because blocks start
> to reach full capacity sounds a lot like like wishful thinking.
>
> So here is my question, to both proponents and opponents of a block size
> increase: What steady-state regime do you envision for Bitcoin, and what
> is is your plan to get there? More specifically, how will the
> steady-state regime look like? Will users experience fee pressure and
> delays, or will it look more like a scaled up version of what we enjoy
> today? Should fee pressure be increased jointly with subsidy decrease,
> or as soon as possible, or never? What incentives will exist for miners
> once the subsidy is gone? Will miners have an incentive to permanently
> fork off the last block and capture its fees? Do you expect Bitcoin to
> work because miners are altruistic/selfish/honest/caring?
>
> A clear vision would be welcome.
>
>
>
>
> ---------- Forwarded message ----------
> From: insecurity at national.shitposting.agency
> To: thomasv at electrum.org
> Cc: bitcoin-development at lists.sourceforge.net
> Date: Mon, 11 May 2015 16:52:10 +0000
> Subject: Re: [Bitcoin-development] Long-term mining incentives
> On 2015-05-11 16:28, Thomas Voegtlin wrote:
>
>> My problem is that this seems to lacks a vision. If the maximal block
>> size is increased only to buy time, or because some people think that 7
>> tps is not enough to compete with VISA, then I guess it would be
>> healthier to try and develop off-chain infrastructure first, such as the
>> Lightning network.
>>
>
> If your end goal is "compete with VISA" you might as well just give up
> and go home right now. There's lots of terrible proposals where people
> try to demonstrate that so many hundred thousand transactions a second
> are possible if we just make the block size 500GB. In the real world
> with physical limits, you literally can not verify more than a few
> thousand ECDSA signatures a second on a CPU core. The tradeoff taken
> in Bitcoin is that the signatures are pretty small, but they are also
> slow to verify on any sort of scale. There's no way competing with a
> centralised entity using on-chain transactions is even a sane goal.
>
>
>
>
> ---------- Forwarded message ----------
> From: Luke Dashjr <luke at dashjr.org>
> To: bitcoin-development at lists.sourceforge.net
> Cc:
> Date: Mon, 11 May 2015 16:47:47 +0000
> Subject: Re: [Bitcoin-development] Reducing the block rate instead of
> increasing the maximum block size
> On Monday, May 11, 2015 7:03:29 AM Sergio Lerner wrote:
> > 1. It will encourage centralization, because participants of mining
> > pools will loose more money because of excessive initial block template
> > latency, which leads to higher stale shares
> >
> > When a new block is solved, that information needs to propagate
> > throughout the Bitcoin network up to the mining pool operator nodes,
> > then a new block header candidate is created, and this header must be
> > propagated to all the mining pool users, ether by a push or a pull
> > model. Generally the mining server pushes new work units to the
> > individual miners. If done other way around, the server would need to
> > handle a high load of continuous work requests that would be difficult
> > to distinguish from a DDoS attack. So if the server pushes new block
> > header candidates to clients, then the problem boils down to increasing
> > bandwidth of the servers to achieve a tenfold increase in work
> > distribution. Or distributing the servers geographically to achieve a
> > lower latency. Propagating blocks does not require additional CPU
> > resources, so mining pools administrators would need to increase
> > moderately their investment in the server infrastructure to achieve
> > lower latency and higher bandwidth, but I guess the investment would be
> > low.
>
> 1. Latency is what matters here, not bandwidth so much. And latency
> reduction
> is either expensive or impossible.
> 2. Mining pools are mostly run at a loss (with exception to only the most
> centralised pools), and have nothing to invest in increasing
> infrastructure.
>
> > 3, It will reduce the security of the network
> >
> > The security of the network is based on two facts:
> > A- The miners are incentivized to extend the best chain
> > B- The probability of a reversal based on a long block competition
> > decreases as more confirmation blocks are appended.
> > C- Renting or buying hardware to perform a 51% attack is costly.
> >
> > A still holds. B holds for the same amount of confirmation blocks, so 6
> > confirmation blocks in a 10-minute block-chain is approximately
> > equivalent to 6 confirmation blocks in a 1-minute block-chain.
> > Only C changes, as renting the hashing power for 6 minutes is ten times
> > less expensive as renting it for 1 hour. However, there is no shop where
> > one can find 51% of the hashing power to rent right now, nor probably
> > will ever be if Bitcoin succeeds. Last, you can still have a 1 hour
> > confirmation (60 1-minute blocks) if you wish for high-valued payments,
> > so the security decreases only if participant wish to decrease it.
>
> You're overlooking at least:
> 1. The real network has to suffer wasted work as a result of the stale
> blocks,
> while an attacker does not. If 20% of blocks are stale, the attacker only
> needs 40% of the legitimate hashrate to achieve 50%-in-practice.
> 2. Since blocks are individually weaker, it becomes cheaper to DoS nodes
> with
> invalid blocks. (not sure if this is a real concern, but it ought to be
> considered and addressed)
>
> > 4. Reducing the block propagation time on the average case is good, but
> > what happen in the worse case?
> >
> > Most methods proposed to reduce the block propagation delay do it only
> > on the average case. Any kind of block compression relies on both
> > parties sharing some previous information. In the worse case it's true
> > that a miner can create and try to broadcast a block that takes too much
> > time to verify or bandwidth to transmit. This is currently true on the
> > Bitcoin network. Nevertheless there is no such incentive for miners,
> > since they will be shooting on their own foots. Peter Todd has argued
> > that the best strategy for miners is actually to reach 51% of the
> > network, but not more. In other words, to exclude the slowest 49%
> > percent. But this strategy of creating bloated blocks is too risky in
> > practice, and surely doomed to fail, as network conditions dynamically
> > change. Also it would be perceived as an attack to the network, and the
> > miner (if it is a public mining pool) would be probably blacklisted.
>
> One can probably overcome changing network conditions merely by trying to
> reach 75% and exclude the slowest 25%. Also, there is no way to identify or
> blacklist miners.
>
> > 5. Thousands of SPV wallets running in mobile devices would need to be
> > upgraded (thanks Mike).
> >
> > That depends on the current upgrade rate for SPV wallets like Bitcoin
> > Wallet  and BreadWallet. Suppose that the upgrade rate is 80%/year: we
> > develop the source code for the change now and apply the change in Q2
> > 2016, then  most of the nodes will already be upgraded by when the
> > hardfork takes place. Also a public notice telling people to upgrade in
> > web pages, bitcointalk, SPV wallets warnings, coindesk, one year in
> > advance will give plenty of time to SPV wallet users to upgrade.
>
> I agree this shouldn't be a real concern. SPV wallets are also more likely
> and
> less risky (globally) to be auto-updated.
>
> > 6. If there are 10x more blocks, then there are 10x more block headers,
> > and that increases the amount of bandwidth SPV wallets need to catch up
> > with the chain
> >
> > A standard smartphone with average cellular downstream speed downloads
> > 2.6 headers per second (1600 kbits/sec) [3], so if synchronization were
> > to be done only at night when the phone is connected to the power line,
> > then it would take 9 minutes to synchronize with 1440 headers/day. If a
> > person should accept a payment, and the smart-phone is 1 day
> > out-of-synch, then it takes less time to download all the missing
> > headers than to wait for a 10-minute one block confirmation. Obviously
> > all smartphones with 3G have a downstream bandwidth much higher,
> > averaging 1 Mbps. So the whole synchronization will be done less than a
> > 1-minute block confirmation.
>
> Uh, I think you need to be using at least median speeds. As an example, I
> can
> only sustain (over 3G) about 40 kbps, with a peak of around 400 kbps. 3G
> has
> worse range/coverage than 2G. No doubt the *average* is skewed so high
> because
> of densely populated areas like San Francisco having 400+ Mbps cellular
> data.
> It's not reasonable to assume sync only at night: most payments will be
> during
> the day, on battery - so increased power use must also be considered.
>
> > According to CISCO mobile bandwidth connection speed increases 20% every
> > year.
>
> Only in small densely populated areas of first-world countries.
>
> Luke
>
>
>
>
> ---------- Forwarded message ----------
> From: Gavin Andresen <gavinandresen at gmail.com>
> To: insecurity at national.shitposting.agency
> Cc: Bitcoin Dev <bitcoin-development at lists.sourceforge.net>
> Date: Mon, 11 May 2015 13:29:02 -0400
> Subject: Re: [Bitcoin-development] Long-term mining incentives
> I think long-term the chain will not be secured purely by proof-of-work. I
> think when the Bitcoin network was tiny running solely on people's home
> computers proof-of-work was the right way to secure the chain, and the only
> fair way to both secure the chain and distribute the coins.
>
> See https://gist.github.com/gavinandresen/630d4a6c24ac6144482a  for some
> half-baked thoughts along those lines. I don't think proof-of-work is the
> last word in distributed consensus (I also don't think any alternatives are
> anywhere near ready to deploy, but they might be in ten years).
>
> I also think it is premature to worry about what will happen in twenty or
> thirty years when the block subsidy is insignificant. A lot will happen in
> the next twenty years. I could spin a vision of what will secure the chain
> in twenty years, but I'd put a low probability on that vision actually
> turning out to be correct.
>
> That is why I keep saying Bitcoin is an experiment. But I also believe
> that the incentives are correct, and there are a lot of very motivated,
> smart, hard-working people who will make it work. When you're talking about
> trying to predict what will happen decades from now, I think that is the
> best you can (honestly) do.
>
> --
> --
> Gavin Andresen
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150511/46bc687a/attachment.html>

From dgomez1092 at gmail.com  Mon May 11 20:28:39 2015
From: dgomez1092 at gmail.com (Damian Gomez)
Date: Mon, 11 May 2015 13:28:39 -0700
Subject: [Bitcoin-development] Bitcoin-development Digest, Vol 48,
	Issue 63
In-Reply-To: <mailman.66482.1431375657.18600.bitcoin-development@lists.sourceforge.net>
References: <mailman.66482.1431375657.18600.bitcoin-development@lists.sourceforge.net>
Message-ID: <CAH+jCTxqAAohw_upeTxhT1z1CWhsgwD0P4ofqZ8C=0CCjYZ9sg@mail.gmail.com>

Btw How awful that I didn't cite my sources, please exucse me, this is
definitely not my intention sometimes I get too caught up in my own
excitemtnt

1) Martin, J., Alvisi, L., Fast Byzantine Consensus. *IEEE Transactions on
Dependable and Secure Computing. 2006. *3(3) doi: <?>  Please see
John-Phillipe Martin and Lorenzo ALvisi

2) https://eprint.iacr.org/2011/191.pdf  One_Time Winternitz Signatures.


On Mon, May 11, 2015 at 1:20 PM, <
bitcoin-development-request at lists.sourceforge.net> wrote:

> Send Bitcoin-development mailing list submissions to
>         bitcoin-development at lists.sourceforge.net
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> or, via email, send a message with subject or body 'help' to
>         bitcoin-development-request at lists.sourceforge.net
>
> You can reach the person managing the list at
>         bitcoin-development-owner at lists.sourceforge.net
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of Bitcoin-development digest..."
>
> Today's Topics:
>
>    1. Re: Bitcoin-development Digest, Vol 48,   Issue 62 (Damian Gomez)
>
>
> ---------- Forwarded message ----------
> From: Damian Gomez <dgomez1092 at gmail.com>
> To: bitcoin-development at lists.sourceforge.net
> Cc:
> Date: Mon, 11 May 2015 13:20:46 -0700
> Subject: Re: [Bitcoin-development] Bitcoin-development Digest, Vol 48,
> Issue 62
> Hllo
>
> I want to build from a conversation that I had w/ Peter (T?) regarding the
> increase in block size in the bitcoin from its's current structure would be
> the proposasl of an prepend to the hash chain itself that would be the
> first DER decoded script in order to verify integrity(trust) within a set
> of transactions and the originiator themselves.
>
> It is my belief that the process to begin a new encryption tool using a
> variant of the WinterNitz OTS for its existential unforgeability to be the
> added signatures with every  Wallet transaction in order to provide a
> consesnus systemt that takes into accont a personal level of intergrity for
> the intention fo a transaction to occur. This signature would then be
> hashes for there to be an intermediate proxy state that then verifies and
> evaluates the trust fucntion for the receiving trnsactions.  This
> evaluation loop would itself be a state in which the mining power and the
> rewards derived from them would be an increased level of integrity as
> provided for the "brainers" of a systems who are then the "signatuers" of
> the transaction authenticity, and additiaonally program extranonces of x
> bits {72} in order  to have a double valid signature that the rest of the
> nodes would accept in order to have a valid address from which to be able
> to continuously receive transactions.
>
> There is a level of diffculty in obtaining brainers, fees would only apply
> uin so much as they are able to create authentic transactions based off the
> voting power of the rest of the received nodes. The greater number of
> faults within the system from a brainer then the more, so would his
> computational power be restricted in order to provide a reward feedback
> system. This singularity in a Byzantine consensus is only achieved if the
> route of an appropriate transformation occurs, one that is invariant to the
> participants of the system, thus being able to provide initial vector
> transformations from a person's online identity is the responsibilty that
> we have to ensure and calulate a lagrangian method that utilisizes a set of
> convolutional neural network funcitons [backpropagation, fuzzy logic] and
> and tranformation function taking the vectors of tranformations in a
> kahunen-loeve algorithm and using the convergence of a baryon wave function
> in order to proceed with a baseline reading of the current level of
> integrity in the state today that is an instance of actionable acceleration
> within a system.
>
> This is something that I am trying to continue to parse out. Therefore
> there are still heavy questions to be answered(the most important being the
> consent of the people to measure their own levels of integrity through
> mined information)> There must always be the option to disconnect from a
> transactional system where payments occur in order to allow a level of
> solace and peace within individuals -- withour repercussions and a seperate
> system that supports the offline realm as well. (THis is a design problem)
>
> Ultimately, quite literally such a transaction system could exist to
> provide detailed analysis that promotes integrity being the basis for
> sharing information.  The fee structure would be eliminated, due to the
> level of integrity and procesing power to have messages and transactions
> and reviews of unfiduciary responsible orgnizations be merited as highly
> true (.9 in fizzy logic) in order to promote a well-being in the state.
> That is its own reward, the strenght of having more processing speed.
>
>
> FYI(thank you to peter whom nudged my thinking and interest (again) in
> this area. )
>
> This is something I am attempting to design in order to program it. Though
> I am not an expert and my technology stack is limited to java and c (and my
> issues from it).  I provided a class the other day the was pseudo code for
> the beginning of the consensus. Now I might to now if I am missing any of
> teh technical paradigms that might make this illogical? I now with the
> advent of 7petabyte computers one could easily store 2.5 petabytes of human
> information for just an instance of integrity not to mention otehr
> emotions.
>
>
>
> *Also, might someone be able to provide a bit of information on Bitcoin
> core project?*
>
> thank you again. Damain.
>
> On Mon, May 11, 2015 at 10:29 AM, <
> bitcoin-development-request at lists.sourceforge.net> wrote:
>
>> Send Bitcoin-development mailing list submissions to
>>         bitcoin-development at lists.sourceforge.net
>>
>> To subscribe or unsubscribe via the World Wide Web, visit
>>         https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>> or, via email, send a message with subject or body 'help' to
>>         bitcoin-development-request at lists.sourceforge.net
>>
>> You can reach the person managing the list at
>>         bitcoin-development-owner at lists.sourceforge.net
>>
>> When replying, please edit your Subject line so it is more specific
>> than "Re: Contents of Bitcoin-development digest..."
>>
>> Today's Topics:
>>
>>    1. Fwd:  Bitcoin core 0.11 planning (Wladimir)
>>    2. Re: Bitcoin core 0.11 planning (Wladimir)
>>    3. Long-term mining incentives (Thomas Voegtlin)
>>    4. Re: Long-term mining incentives
>>       (insecurity at national.shitposting.agency)
>>    5. Re: Reducing the block rate instead of    increasing the maximum
>>       block size (Luke Dashjr)
>>    6. Re: Long-term mining incentives (Gavin Andresen)
>>
>>
>> ---------- Forwarded message ----------
>> From: Wladimir <laanwj at gmail.com>
>> To: Bitcoin Dev <bitcoin-development at lists.sourceforge.net>
>> Cc:
>> Date: Mon, 11 May 2015 14:49:53 +0000
>> Subject: [Bitcoin-development] Fwd: Bitcoin core 0.11 planning
>> On Tue, Apr 28, 2015 at 11:01 AM, Pieter Wuille <pieter.wuille at gmail.com>
>> wrote:
>> > As softforks almost certainly require backports to older releases and
>> other
>> > software anyway, I don't think they should necessarily be bound to
>> Bitcoin
>> > Core major releases. If they don't require large code changes, we can
>> easily
>> > do them in minor releases too.
>>
>> Agree here - there is no need to time consensus changes with a major
>> release, as they need to be ported back to older releases anyhow.
>> (I don't really classify them as software features, but properties of
>> the underlying system that we need to adopt to)
>>
>> Wladimir
>>
>>
>>
>>
>> ---------- Forwarded message ----------
>> From: Wladimir <laanwj at gmail.com>
>> To: Bitcoin Dev <bitcoin-development at lists.sourceforge.net>
>> Cc:
>> Date: Mon, 11 May 2015 15:00:03 +0000
>> Subject: Re: [Bitcoin-development] Bitcoin core 0.11 planning
>> A reminder - feature freeze and string freeze is coming up this Friday
>> the 15th.
>>
>> Let me know if your pull request is ready to be merged before then,
>>
>> Wladimir
>>
>> On Tue, Apr 28, 2015 at 7:44 AM, Wladimir J. van der Laan
>> <laanwj at gmail.com> wrote:
>> > Hello all,
>> >
>> > The release window for 0.11 is nearing, I'd propose the following
>> schedule:
>> >
>> > 2015-05-01  Soft translation string freeze
>> >             Open Transifex translations for 0.11
>> >             Finalize and close translation for 0.9
>> >
>> > 2015-05-15  Feature freeze, string freeze
>> >
>> > 2015-06-01  Split off 0.11 branch
>> >             Tag and release 0.11.0rc1
>> >             Start merging for 0.12 on master branch
>> >
>> > 2015-07-01  Release 0.11.0 final (aim)
>> >
>> > In contrast to former releases, which were protracted for months, let's
>> try to be more strict about the dates. Of course it is always possible for
>> last-minute critical issues to interfere with the planning. The release
>> will not be held up for features, though, and anything that will not make
>> it to 0.11 will be postponed to next release scheduled for end of the year.
>> >
>> > Wladimir
>>
>>
>>
>>
>> ---------- Forwarded message ----------
>> From: Thomas Voegtlin <thomasv at electrum.org>
>> To: Bitcoin Development <bitcoin-development at lists.sourceforge.net>
>> Cc:
>> Date: Mon, 11 May 2015 18:28:46 +0200
>> Subject: [Bitcoin-development] Long-term mining incentives
>> The discussion on block size increase has brought some attention to the
>> other elephant in the room: Long-term mining incentives.
>>
>> Bitcoin derives its current market value from the assumption that a
>> stable, steady-state regime will be reached in the future, where miners
>> have an incentive to keep mining to protect the network. Such a steady
>> state regime does not exist today, because miners get most of their
>> reward from the block subsidy, which will progressively be removed.
>>
>> Thus, today's 3 billion USD question is the following: Will a steady
>> state regime be reached in the future? Can such a regime exist? What are
>> the necessary conditions for its existence?
>>
>> Satoshi's paper suggests that this may be achieved through miner fees.
>> Quite a few people seem to take this for granted, and are working to
>> make it happen (developing cpfp and replace-by-fee). This explains part
>> of the opposition to raising the block size limit; some people would
>> like to see some fee pressure building up first, in order to get closer
>> to a regime where miners are incentivised by transaction fees instead of
>> block subsidy. Indeed, the emergence of a working fee market would be
>> extremely reassuring for the long-term viability of bitcoin. So, the
>> thinking goes, by raising the block size limit, we would be postponing a
>> crucial reality check. We would be buying time, at the expenses of
>> Bitcoin's decentralization.
>>
>> OTOH, proponents of a block size increase have a very good point: if the
>> block size is not raised soon, Bitcoin is going to enter a new, unknown
>> and potentially harmful regime. In the current regime, almost all
>> transaction get confirmed quickly, and fee pressure does not exist. Mike
>> Hearn suggested that, when blocks reach full capacity and users start to
>> experience confirmation delays and confirmation uncertainty, users will
>> simply go away and stop using Bitcoin. To me, that outcome sounds very
>> plausible indeed. Thus, proponents of the block size increase are
>> conservative; they are trying to preserve the current regime, which is
>> known to work, instead of letting the network enter uncharted territory.
>>
>> My problem is that this seems to lacks a vision. If the maximal block
>> size is increased only to buy time, or because some people think that 7
>> tps is not enough to compete with VISA, then I guess it would be
>> healthier to try and develop off-chain infrastructure first, such as the
>> Lightning network.
>>
>> OTOH, I also fail to see evidence that a limited block capacity will
>> lead to a functional fee market, able to sustain a steady state. A
>> functional market requires well-informed participants who make rational
>> choices and accept the outcomes of their choices. That is not the case
>> today, and to believe that it will magically happen because blocks start
>> to reach full capacity sounds a lot like like wishful thinking.
>>
>> So here is my question, to both proponents and opponents of a block size
>> increase: What steady-state regime do you envision for Bitcoin, and what
>> is is your plan to get there? More specifically, how will the
>> steady-state regime look like? Will users experience fee pressure and
>> delays, or will it look more like a scaled up version of what we enjoy
>> today? Should fee pressure be increased jointly with subsidy decrease,
>> or as soon as possible, or never? What incentives will exist for miners
>> once the subsidy is gone? Will miners have an incentive to permanently
>> fork off the last block and capture its fees? Do you expect Bitcoin to
>> work because miners are altruistic/selfish/honest/caring?
>>
>> A clear vision would be welcome.
>>
>>
>>
>>
>> ---------- Forwarded message ----------
>> From: insecurity at national.shitposting.agency
>> To: thomasv at electrum.org
>> Cc: bitcoin-development at lists.sourceforge.net
>> Date: Mon, 11 May 2015 16:52:10 +0000
>> Subject: Re: [Bitcoin-development] Long-term mining incentives
>> On 2015-05-11 16:28, Thomas Voegtlin wrote:
>>
>>> My problem is that this seems to lacks a vision. If the maximal block
>>> size is increased only to buy time, or because some people think that 7
>>> tps is not enough to compete with VISA, then I guess it would be
>>> healthier to try and develop off-chain infrastructure first, such as the
>>> Lightning network.
>>>
>>
>> If your end goal is "compete with VISA" you might as well just give up
>> and go home right now. There's lots of terrible proposals where people
>> try to demonstrate that so many hundred thousand transactions a second
>> are possible if we just make the block size 500GB. In the real world
>> with physical limits, you literally can not verify more than a few
>> thousand ECDSA signatures a second on a CPU core. The tradeoff taken
>> in Bitcoin is that the signatures are pretty small, but they are also
>> slow to verify on any sort of scale. There's no way competing with a
>> centralised entity using on-chain transactions is even a sane goal.
>>
>>
>>
>>
>> ---------- Forwarded message ----------
>> From: Luke Dashjr <luke at dashjr.org>
>> To: bitcoin-development at lists.sourceforge.net
>> Cc:
>> Date: Mon, 11 May 2015 16:47:47 +0000
>> Subject: Re: [Bitcoin-development] Reducing the block rate instead of
>> increasing the maximum block size
>> On Monday, May 11, 2015 7:03:29 AM Sergio Lerner wrote:
>> > 1. It will encourage centralization, because participants of mining
>> > pools will loose more money because of excessive initial block template
>> > latency, which leads to higher stale shares
>> >
>> > When a new block is solved, that information needs to propagate
>> > throughout the Bitcoin network up to the mining pool operator nodes,
>> > then a new block header candidate is created, and this header must be
>> > propagated to all the mining pool users, ether by a push or a pull
>> > model. Generally the mining server pushes new work units to the
>> > individual miners. If done other way around, the server would need to
>> > handle a high load of continuous work requests that would be difficult
>> > to distinguish from a DDoS attack. So if the server pushes new block
>> > header candidates to clients, then the problem boils down to increasing
>> > bandwidth of the servers to achieve a tenfold increase in work
>> > distribution. Or distributing the servers geographically to achieve a
>> > lower latency. Propagating blocks does not require additional CPU
>> > resources, so mining pools administrators would need to increase
>> > moderately their investment in the server infrastructure to achieve
>> > lower latency and higher bandwidth, but I guess the investment would be
>> > low.
>>
>> 1. Latency is what matters here, not bandwidth so much. And latency
>> reduction
>> is either expensive or impossible.
>> 2. Mining pools are mostly run at a loss (with exception to only the most
>> centralised pools), and have nothing to invest in increasing
>> infrastructure.
>>
>> > 3, It will reduce the security of the network
>> >
>> > The security of the network is based on two facts:
>> > A- The miners are incentivized to extend the best chain
>> > B- The probability of a reversal based on a long block competition
>> > decreases as more confirmation blocks are appended.
>> > C- Renting or buying hardware to perform a 51% attack is costly.
>> >
>> > A still holds. B holds for the same amount of confirmation blocks, so 6
>> > confirmation blocks in a 10-minute block-chain is approximately
>> > equivalent to 6 confirmation blocks in a 1-minute block-chain.
>> > Only C changes, as renting the hashing power for 6 minutes is ten times
>> > less expensive as renting it for 1 hour. However, there is no shop where
>> > one can find 51% of the hashing power to rent right now, nor probably
>> > will ever be if Bitcoin succeeds. Last, you can still have a 1 hour
>> > confirmation (60 1-minute blocks) if you wish for high-valued payments,
>> > so the security decreases only if participant wish to decrease it.
>>
>> You're overlooking at least:
>> 1. The real network has to suffer wasted work as a result of the stale
>> blocks,
>> while an attacker does not. If 20% of blocks are stale, the attacker only
>> needs 40% of the legitimate hashrate to achieve 50%-in-practice.
>> 2. Since blocks are individually weaker, it becomes cheaper to DoS nodes
>> with
>> invalid blocks. (not sure if this is a real concern, but it ought to be
>> considered and addressed)
>>
>> > 4. Reducing the block propagation time on the average case is good, but
>> > what happen in the worse case?
>> >
>> > Most methods proposed to reduce the block propagation delay do it only
>> > on the average case. Any kind of block compression relies on both
>> > parties sharing some previous information. In the worse case it's true
>> > that a miner can create and try to broadcast a block that takes too much
>> > time to verify or bandwidth to transmit. This is currently true on the
>> > Bitcoin network. Nevertheless there is no such incentive for miners,
>> > since they will be shooting on their own foots. Peter Todd has argued
>> > that the best strategy for miners is actually to reach 51% of the
>> > network, but not more. In other words, to exclude the slowest 49%
>> > percent. But this strategy of creating bloated blocks is too risky in
>> > practice, and surely doomed to fail, as network conditions dynamically
>> > change. Also it would be perceived as an attack to the network, and the
>> > miner (if it is a public mining pool) would be probably blacklisted.
>>
>> One can probably overcome changing network conditions merely by trying to
>> reach 75% and exclude the slowest 25%. Also, there is no way to identify
>> or
>> blacklist miners.
>>
>> > 5. Thousands of SPV wallets running in mobile devices would need to be
>> > upgraded (thanks Mike).
>> >
>> > That depends on the current upgrade rate for SPV wallets like Bitcoin
>> > Wallet  and BreadWallet. Suppose that the upgrade rate is 80%/year: we
>> > develop the source code for the change now and apply the change in Q2
>> > 2016, then  most of the nodes will already be upgraded by when the
>> > hardfork takes place. Also a public notice telling people to upgrade in
>> > web pages, bitcointalk, SPV wallets warnings, coindesk, one year in
>> > advance will give plenty of time to SPV wallet users to upgrade.
>>
>> I agree this shouldn't be a real concern. SPV wallets are also more
>> likely and
>> less risky (globally) to be auto-updated.
>>
>> > 6. If there are 10x more blocks, then there are 10x more block headers,
>> > and that increases the amount of bandwidth SPV wallets need to catch up
>> > with the chain
>> >
>> > A standard smartphone with average cellular downstream speed downloads
>> > 2.6 headers per second (1600 kbits/sec) [3], so if synchronization were
>> > to be done only at night when the phone is connected to the power line,
>> > then it would take 9 minutes to synchronize with 1440 headers/day. If a
>> > person should accept a payment, and the smart-phone is 1 day
>> > out-of-synch, then it takes less time to download all the missing
>> > headers than to wait for a 10-minute one block confirmation. Obviously
>> > all smartphones with 3G have a downstream bandwidth much higher,
>> > averaging 1 Mbps. So the whole synchronization will be done less than a
>> > 1-minute block confirmation.
>>
>> Uh, I think you need to be using at least median speeds. As an example, I
>> can
>> only sustain (over 3G) about 40 kbps, with a peak of around 400 kbps. 3G
>> has
>> worse range/coverage than 2G. No doubt the *average* is skewed so high
>> because
>> of densely populated areas like San Francisco having 400+ Mbps cellular
>> data.
>> It's not reasonable to assume sync only at night: most payments will be
>> during
>> the day, on battery - so increased power use must also be considered.
>>
>> > According to CISCO mobile bandwidth connection speed increases 20% every
>> > year.
>>
>> Only in small densely populated areas of first-world countries.
>>
>> Luke
>>
>>
>>
>>
>> ---------- Forwarded message ----------
>> From: Gavin Andresen <gavinandresen at gmail.com>
>> To: insecurity at national.shitposting.agency
>> Cc: Bitcoin Dev <bitcoin-development at lists.sourceforge.net>
>> Date: Mon, 11 May 2015 13:29:02 -0400
>> Subject: Re: [Bitcoin-development] Long-term mining incentives
>> I think long-term the chain will not be secured purely by proof-of-work.
>> I think when the Bitcoin network was tiny running solely on people's home
>> computers proof-of-work was the right way to secure the chain, and the only
>> fair way to both secure the chain and distribute the coins.
>>
>> See https://gist.github.com/gavinandresen/630d4a6c24ac6144482a  for some
>> half-baked thoughts along those lines. I don't think proof-of-work is the
>> last word in distributed consensus (I also don't think any alternatives are
>> anywhere near ready to deploy, but they might be in ten years).
>>
>> I also think it is premature to worry about what will happen in twenty or
>> thirty years when the block subsidy is insignificant. A lot will happen in
>> the next twenty years. I could spin a vision of what will secure the chain
>> in twenty years, but I'd put a low probability on that vision actually
>> turning out to be correct.
>>
>> That is why I keep saying Bitcoin is an experiment. But I also believe
>> that the incentives are correct, and there are a lot of very motivated,
>> smart, hard-working people who will make it work. When you're talking about
>> trying to predict what will happen decades from now, I think that is the
>> best you can (honestly) do.
>>
>> --
>> --
>> Gavin Andresen
>>
>>
>> ------------------------------------------------------------------------------
>> One dashboard for servers and applications across Physical-Virtual-Cloud
>> Widest out-of-the-box monitoring support with 50+ applications
>> Performance metrics, stats and reports that give you Actionable Insights
>> Deep dive visibility with transaction tracing using APM Insight.
>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150511/8f777233/attachment.html>

From kiwigb at yahoo.com  Mon May 11 21:00:51 2015
From: kiwigb at yahoo.com (gb)
Date: Tue, 12 May 2015 09:00:51 +1200
Subject: [Bitcoin-development] simplified costing analysis
Message-ID: <1431378051.3576.7.camel@yahoo.com>

Hi,

the attached document is a simplified costing analysis that may serve a
useful approach for network scaling discussions.

Regards.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: costing.pdf
Type: application/pdf
Size: 112525 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150512/c0c16c3f/attachment.pdf>

From lemientelephone at gmail.com  Tue May 12 09:45:11 2015
From: lemientelephone at gmail.com (Telephone Lemien)
Date: Tue, 12 May 2015 11:45:11 +0200
Subject: [Bitcoin-development] Bitcoin transaction
Message-ID: <CAL6tygYkN1n2mSkSH5Xqg-KcfFkKFw0X0inC46FWnH2NVenFnA@mail.gmail.com>

Hello evry body,
I want to know what is the difference between a bitcoin transaction and
colored coins transaction technically.

Thanks
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150512/638501ae/attachment.html>

From lemientelephone at gmail.com  Tue May 12 09:54:04 2015
From: lemientelephone at gmail.com (Telephone Lemien)
Date: Tue, 12 May 2015 11:54:04 +0200
Subject: [Bitcoin-development] Bitcoin transaction
In-Reply-To: <DB5PR07MB09193865EE13BEF6ABD2CC79B5DA0@DB5PR07MB0919.eurprd07.prod.outlook.com>
References: <CAL6tygYkN1n2mSkSH5Xqg-KcfFkKFw0X0inC46FWnH2NVenFnA@mail.gmail.com>
	<DB5PR07MB09193865EE13BEF6ABD2CC79B5DA0@DB5PR07MB0919.eurprd07.prod.outlook.com>
Message-ID: <CAL6tyga6HyYJkhbS+yCDTkNe7LDxGxcXzbwgfjQmKs20gAGPHA@mail.gmail.com>

Thank You,
I know this, but I want to have mores details in the inputs/outputs, or in
the script of input/output and how i will proceed in the code.
Thanks for all replaying

2015-05-12 11:47 GMT+02:00 Patrick Mccorry (PGR) <
patrick.mccorry at newcastle.ac.uk>:

>  There is no difference to the transaction as far as im aware ? just the
> inputs / outputs have a special meaning (and should have a special order).
> So you can track 1 BTC throughout the blockchain and this 1 BTC represents
> my asset. Someone may give a more useful answer.
>
>
>
> *From:* Telephone Lemien [mailto:lemientelephone at gmail.com]
> *Sent:* 12 May 2015 10:45
> *To:* Bitcoin Dev
> *Subject:* [Bitcoin-development] Bitcoin transaction
>
>
>
> Hello evry body,
>
> I want to know what is the difference between a bitcoin transaction and
> colored coins transaction technically.
>
> Thanks
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150512/f5200cd8/attachment.html>

From thomasv at electrum.org  Tue May 12 12:35:02 2015
From: thomasv at electrum.org (Thomas Voegtlin)
Date: Tue, 12 May 2015 14:35:02 +0200
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <CABsx9T1VgxEJWxrYTs+2hXGnGrSLGJ6mVcAexjXLvK7Vu+e3EA@mail.gmail.com>
References: <5550D8BE.6070207@electrum.org>	<ce3d34c92efd1cf57326e4679550944e@national.shitposting.agency>
	<CABsx9T1VgxEJWxrYTs+2hXGnGrSLGJ6mVcAexjXLvK7Vu+e3EA@mail.gmail.com>
Message-ID: <5551F376.4050008@electrum.org>

Thank you for your answer.

I agree that a lot of things will change, and I am not asking for a
prediction of technological developments; prediction is certainly
impossible. What I would like to have is some sort of reference scenario
for the future of Bitcoin. Something a bit like the Standard Model in
Physics. The reference scenario should not be a prediction of the
future, that's not the point. In fact, it will have to be updated
everytime technological evolutions or code changes render it obsolete.

However, the reference scenario should be a workable path through the
future, using today's technologies and today's knowlegde, and including
all planned code changes. It should be, as much as possible, amenable to
quantitative analysis. It could be used to justify controversial
decisions such as a hard fork.

Your proposal of a block size increase would be much stronger if it came
with such a scenario. It would show that you know where you are going.



Le 11/05/2015 19:29, Gavin Andresen a ?crit :
> I think long-term the chain will not be secured purely by proof-of-work. I
> think when the Bitcoin network was tiny running solely on people's home
> computers proof-of-work was the right way to secure the chain, and the only
> fair way to both secure the chain and distribute the coins.
> 
> See https://gist.github.com/gavinandresen/630d4a6c24ac6144482a  for some
> half-baked thoughts along those lines. I don't think proof-of-work is the
> last word in distributed consensus (I also don't think any alternatives are
> anywhere near ready to deploy, but they might be in ten years).
> 
> I also think it is premature to worry about what will happen in twenty or
> thirty years when the block subsidy is insignificant. A lot will happen in
> the next twenty years. I could spin a vision of what will secure the chain
> in twenty years, but I'd put a low probability on that vision actually
> turning out to be correct.
> 
> That is why I keep saying Bitcoin is an experiment. But I also believe that
> the incentives are correct, and there are a lot of very motivated, smart,
> hard-working people who will make it work. When you're talking about trying
> to predict what will happen decades from now, I think that is the best you
> can (honestly) do.
> 



From gappleto97 at gmail.com  Tue May 12 15:26:55 2015
From: gappleto97 at gmail.com (gabe appleton)
Date: Tue, 12 May 2015 11:26:55 -0400
Subject: [Bitcoin-development] Proposed additional options for pruned nodes
In-Reply-To: <CANJO25J1WRHtfQLVXUB2s_sjj39pTPWmixAcXNJ3t-5os8RPmQ@mail.gmail.com>
References: <CANJO25J1WRHtfQLVXUB2s_sjj39pTPWmixAcXNJ3t-5os8RPmQ@mail.gmail.com>
Message-ID: <CANJO25JTtfmfsOQYOzJeksJn3CoKE3W8iLGsRko-_xd4XhB3ZA@mail.gmail.com>

Hi,

There's been a lot of talk in the rest of the community about how the 20MB
step would increase storage needs, and that switching to pruned nodes
(partially) would reduce network security. I think I may have a solution.

There could be a hybrid option in nodes. Selecting this would do the
following:
Flip the --no-wallet toggle
Select a section of the blockchain to store fully (percentage based,
possibly on hash % sections?)
Begin pruning all sections not included in 2
The idea is that you can implement it similar to how a Koorde is done, in
that the network will decide which sections it retrieves. So if the user
prompts it to store 50% of the blockchain, it would look at its peers, and
at their peers (if secure), and choose the least-occurring options from
them.

This would allow them to continue validating all transactions, and still
store a full copy, just distributed among many nodes. It should overall
have little impact on security (unless I'm mistaken), and it would
significantly reduce storage needs on a node.

It would also allow for a retroactive --max-size flag, where it will prune
until it is at the specified size, and continue to prune over time, while
keeping to the sections defined by the network.

What sort of side effects or network vulnerabilities would this introduce?
I know some said it wouldn't be Sybil resistant, but how would this be less
so than a fully pruned node?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150512/d448267a/attachment.html>

From jgarzik at bitpay.com  Tue May 12 16:05:44 2015
From: jgarzik at bitpay.com (Jeff Garzik)
Date: Tue, 12 May 2015 09:05:44 -0700
Subject: [Bitcoin-development] Proposed additional options for pruned
	nodes
In-Reply-To: <CANJO25JTtfmfsOQYOzJeksJn3CoKE3W8iLGsRko-_xd4XhB3ZA@mail.gmail.com>
References: <CANJO25J1WRHtfQLVXUB2s_sjj39pTPWmixAcXNJ3t-5os8RPmQ@mail.gmail.com>
	<CANJO25JTtfmfsOQYOzJeksJn3CoKE3W8iLGsRko-_xd4XhB3ZA@mail.gmail.com>
Message-ID: <CAJHLa0O5OxaX5g3u=dnCY6Lz_gK3QZgQEPNcWNVRD4JziwAmvg@mail.gmail.com>

A general assumption is that you will have a few archive nodes with the
full blockchain, and a majority of nodes are pruned, able to serve only the
tail of the chains.


On Tue, May 12, 2015 at 8:26 AM, gabe appleton <gappleto97 at gmail.com> wrote:

> Hi,
>
> There's been a lot of talk in the rest of the community about how the 20MB
> step would increase storage needs, and that switching to pruned nodes
> (partially) would reduce network security. I think I may have a solution.
>
> There could be a hybrid option in nodes. Selecting this would do the
> following:
> Flip the --no-wallet toggle
> Select a section of the blockchain to store fully (percentage based,
> possibly on hash % sections?)
> Begin pruning all sections not included in 2
> The idea is that you can implement it similar to how a Koorde is done, in
> that the network will decide which sections it retrieves. So if the user
> prompts it to store 50% of the blockchain, it would look at its peers, and
> at their peers (if secure), and choose the least-occurring options from
> them.
>
> This would allow them to continue validating all transactions, and still
> store a full copy, just distributed among many nodes. It should overall
> have little impact on security (unless I'm mistaken), and it would
> significantly reduce storage needs on a node.
>
> It would also allow for a retroactive --max-size flag, where it will prune
> until it is at the specified size, and continue to prune over time, while
> keeping to the sections defined by the network.
>
> What sort of side effects or network vulnerabilities would this introduce?
> I know some said it wouldn't be Sybil resistant, but how would this be less
> so than a fully pruned node?
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>


-- 
Jeff Garzik
Bitcoin core developer and open source evangelist
BitPay, Inc.      https://bitpay.com/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150512/0ee91628/attachment.html>

From gavinandresen at gmail.com  Tue May 12 16:10:53 2015
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Tue, 12 May 2015 12:10:53 -0400
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <555210AF.3090705@electrum.org>
References: <5550D8BE.6070207@electrum.org>
	<ce3d34c92efd1cf57326e4679550944e@national.shitposting.agency>
	<CABsx9T1VgxEJWxrYTs+2hXGnGrSLGJ6mVcAexjXLvK7Vu+e3EA@mail.gmail.com>
	<5551F376.4050008@electrum.org>
	<CABsx9T1h7p3hDr7ty43uxsYs-oNRpndzg=dowST2tXtogxRm2g@mail.gmail.com>
	<555210AF.3090705@electrum.org>
Message-ID: <CABsx9T3AxM3et7hgXx3+Rn3BvhQkF-Cn797sHcyztkMpD1UQmA@mail.gmail.com>

Added back the list, I didn't mean to reply privately:

Fair enough, I'll try to find time in the next month or three to write up
four plausible future scenarios for how mining incentives might work:

1) Fee-supported with very large blocks containing lots of tiny-fee
transactions
2) Proof-of-idle supported (I wish Tadge Dryja would publish his
proof-of-idle idea....)
3) Fees purely as transaction-spam-prevention measure, chain security via
alternative consensus algorithm (in this scenario there is very little
mining).
4) Fee supported with small blocks containing high-fee transactions moving
coins to/from sidechains.

Would that be helpful, or do you have some reason for thinking that we
should pick just one and focus all of our efforts on making that one
scenario happen?

I always think it is better, when possible, not to "bet on one horse."


On Tue, May 12, 2015 at 10:39 AM, Thomas Voegtlin <thomasv at electrum.org>
wrote:

> Le 12/05/2015 15:44, Gavin Andresen a ?crit :
> > Ok, here's my scenario:
> >
> > https://blog.bitcoinfoundation.org/a-scalability-roadmap/
> >
> > It might be wrong. I welcome other people to present their road maps.
> >
>
> [answering to you only because you answered to me and not to the list;
> feel free to repost this to the list though]
>
> Yes, that's exactly the kind of roadmap I am asking for. But your blog
> post does not say anything about long term mining incentives, it only
> talks about scalability. My point is that we need the same kind of thing
> for miners incentives.
>



-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150512/3ab5aa3d/attachment.html>

From dave at hashingit.com  Tue May 12 16:21:40 2015
From: dave at hashingit.com (Dave Hudson)
Date: Tue, 12 May 2015 17:21:40 +0100
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <CABsx9T3AxM3et7hgXx3+Rn3BvhQkF-Cn797sHcyztkMpD1UQmA@mail.gmail.com>
References: <5550D8BE.6070207@electrum.org>
	<ce3d34c92efd1cf57326e4679550944e@national.shitposting.agency>
	<CABsx9T1VgxEJWxrYTs+2hXGnGrSLGJ6mVcAexjXLvK7Vu+e3EA@mail.gmail.com>
	<5551F376.4050008@electrum.org>
	<CABsx9T1h7p3hDr7ty43uxsYs-oNRpndzg=dowST2tXtogxRm2g@mail.gmail.com>
	<555210AF.3090705@electrum.org>
	<CABsx9T3AxM3et7hgXx3+Rn3BvhQkF-Cn797sHcyztkMpD1UQmA@mail.gmail.com>
Message-ID: <6D03480C-C9B9-4CCC-938B-151AC0DD57F0@hashingit.com>

I think proof-of-idle had a potentially serious problem when I last looked at it. The risk is that a largish miner can use everyone else's idle time to construct a very long chain; it's also easy enough for them to make it appear to be the work of a large number of distinct miners. Given that this would allow them to arbitrarily re-mine any block rewards and potentially censor any transactions then that just seems like a huge security hole?


Cheers,
Dave


> On 12 May 2015, at 17:10, Gavin Andresen <gavinandresen at gmail.com> wrote:
> 
> Added back the list, I didn't mean to reply privately:
> 
> Fair enough, I'll try to find time in the next month or three to write up four plausible future scenarios for how mining incentives might work:
> 
> 1) Fee-supported with very large blocks containing lots of tiny-fee transactions
> 2) Proof-of-idle supported (I wish Tadge Dryja would publish his proof-of-idle idea....)
> 3) Fees purely as transaction-spam-prevention measure, chain security via alternative consensus algorithm (in this scenario there is very little mining).
> 4) Fee supported with small blocks containing high-fee transactions moving coins to/from sidechains.
> 
> Would that be helpful, or do you have some reason for thinking that we should pick just one and focus all of our efforts on making that one scenario happen?
> 
> I always think it is better, when possible, not to "bet on one horse."
> 
> 
> On Tue, May 12, 2015 at 10:39 AM, Thomas Voegtlin <thomasv at electrum.org <mailto:thomasv at electrum.org>> wrote:
> Le 12/05/2015 15:44, Gavin Andresen a ?crit :
> > Ok, here's my scenario:
> >
> > https://blog.bitcoinfoundation.org/a-scalability-roadmap/ <https://blog.bitcoinfoundation.org/a-scalability-roadmap/>
> >
> > It might be wrong. I welcome other people to present their road maps.
> >
> 
> [answering to you only because you answered to me and not to the list;
> feel free to repost this to the list though]
> 
> Yes, that's exactly the kind of roadmap I am asking for. But your blog
> post does not say anything about long term mining incentives, it only
> talks about scalability. My point is that we need the same kind of thing
> for miners incentives.
> 
> 
> 
> -- 
> --
> Gavin Andresen
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud 
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y_______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150512/73ba86e4/attachment.html>

From gappleto97 at gmail.com  Tue May 12 16:56:37 2015
From: gappleto97 at gmail.com (gabe appleton)
Date: Tue, 12 May 2015 12:56:37 -0400
Subject: [Bitcoin-development] Proposed additional options for pruned
	nodes
In-Reply-To: <CAJHLa0O5OxaX5g3u=dnCY6Lz_gK3QZgQEPNcWNVRD4JziwAmvg@mail.gmail.com>
References: <CANJO25J1WRHtfQLVXUB2s_sjj39pTPWmixAcXNJ3t-5os8RPmQ@mail.gmail.com>
	<CANJO25JTtfmfsOQYOzJeksJn3CoKE3W8iLGsRko-_xd4XhB3ZA@mail.gmail.com>
	<CAJHLa0O5OxaX5g3u=dnCY6Lz_gK3QZgQEPNcWNVRD4JziwAmvg@mail.gmail.com>
Message-ID: <CANJO25KWmUhpFbSycYBZmowrBtLZPwXDs-eoXRgcAoaMuE0Rzg@mail.gmail.com>

Yes, but that just increases the incentive for partially-full nodes. It
would add to the assumed-small number of full nodes.

Or am I misunderstanding?

On Tue, May 12, 2015 at 12:05 PM, Jeff Garzik <jgarzik at bitpay.com> wrote:

> A general assumption is that you will have a few archive nodes with the
> full blockchain, and a majority of nodes are pruned, able to serve only the
> tail of the chains.
>
>
> On Tue, May 12, 2015 at 8:26 AM, gabe appleton <gappleto97 at gmail.com>
> wrote:
>
>> Hi,
>>
>> There's been a lot of talk in the rest of the community about how the
>> 20MB step would increase storage needs, and that switching to pruned nodes
>> (partially) would reduce network security. I think I may have a solution.
>>
>> There could be a hybrid option in nodes. Selecting this would do the
>> following:
>> Flip the --no-wallet toggle
>> Select a section of the blockchain to store fully (percentage based,
>> possibly on hash % sections?)
>> Begin pruning all sections not included in 2
>> The idea is that you can implement it similar to how a Koorde is done, in
>> that the network will decide which sections it retrieves. So if the user
>> prompts it to store 50% of the blockchain, it would look at its peers, and
>> at their peers (if secure), and choose the least-occurring options from
>> them.
>>
>> This would allow them to continue validating all transactions, and still
>> store a full copy, just distributed among many nodes. It should overall
>> have little impact on security (unless I'm mistaken), and it would
>> significantly reduce storage needs on a node.
>>
>> It would also allow for a retroactive --max-size flag, where it will
>> prune until it is at the specified size, and continue to prune over time,
>> while keeping to the sections defined by the network.
>>
>> What sort of side effects or network vulnerabilities would this
>> introduce? I know some said it wouldn't be Sybil resistant, but how would
>> this be less so than a fully pruned node?
>>
>>
>> ------------------------------------------------------------------------------
>> One dashboard for servers and applications across Physical-Virtual-Cloud
>> Widest out-of-the-box monitoring support with 50+ applications
>> Performance metrics, stats and reports that give you Actionable Insights
>> Deep dive visibility with transaction tracing using APM Insight.
>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>>
>
>
> --
> Jeff Garzik
> Bitcoin core developer and open source evangelist
> BitPay, Inc.      https://bitpay.com/
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150512/af7820e4/attachment.html>

From pete at petertodd.org  Tue May 12 17:16:40 2015
From: pete at petertodd.org (Peter Todd)
Date: Tue, 12 May 2015 13:16:40 -0400
Subject: [Bitcoin-development] Proposed additional options for pruned
 nodes
In-Reply-To: <CAJHLa0O5OxaX5g3u=dnCY6Lz_gK3QZgQEPNcWNVRD4JziwAmvg@mail.gmail.com>
References: <CANJO25J1WRHtfQLVXUB2s_sjj39pTPWmixAcXNJ3t-5os8RPmQ@mail.gmail.com>
	<CANJO25JTtfmfsOQYOzJeksJn3CoKE3W8iLGsRko-_xd4XhB3ZA@mail.gmail.com>
	<CAJHLa0O5OxaX5g3u=dnCY6Lz_gK3QZgQEPNcWNVRD4JziwAmvg@mail.gmail.com>
Message-ID: <20150512171640.GA32606@savin.petertodd.org>

On Tue, May 12, 2015 at 09:05:44AM -0700, Jeff Garzik wrote:
> A general assumption is that you will have a few archive nodes with the
> full blockchain, and a majority of nodes are pruned, able to serve only the
> tail of the chains.

Hmm?

Lots of people are tossing around ideas for partial archival nodes that
would store a subset of blocks, such that collectively the whole
blockchain would be available even if no one node had the entire chain.

-- 
'peter'[:-1]@petertodd.org
0000000000000000156d2069eeebb3309455f526cfe50efbf8a85ec630df7f7c
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150512/ae0f4b3b/attachment.sig>

From tier.nolan at gmail.com  Tue May 12 18:23:48 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Tue, 12 May 2015 19:23:48 +0100
Subject: [Bitcoin-development] Proposed additional options for pruned
	nodes
In-Reply-To: <20150512171640.GA32606@savin.petertodd.org>
References: <CANJO25J1WRHtfQLVXUB2s_sjj39pTPWmixAcXNJ3t-5os8RPmQ@mail.gmail.com>
	<CANJO25JTtfmfsOQYOzJeksJn3CoKE3W8iLGsRko-_xd4XhB3ZA@mail.gmail.com>
	<CAJHLa0O5OxaX5g3u=dnCY6Lz_gK3QZgQEPNcWNVRD4JziwAmvg@mail.gmail.com>
	<20150512171640.GA32606@savin.petertodd.org>
Message-ID: <CAE-z3OV3VdSoiTSfASwYHr1CjZSqio303sqGq_1Y9yaYgov2sw@mail.gmail.com>

On Tue, May 12, 2015 at 6:16 PM, Peter Todd <pete at petertodd.org> wrote:

>
> Lots of people are tossing around ideas for partial archival nodes that
> would store a subset of blocks, such that collectively the whole
> blockchain would be available even if no one node had the entire chain.
>

A compact way to describe which blocks are stored helps to mitigate against
fingerprint attacks.

It also means that a node could compactly indicate which blocks it stores
with service bits.

The node could pick two numbers

W = window = a power of 2
P = position = random value less than W

The node would store all blocks with a height of P mod W.  The block hash
could be used too.

This has the nice feature that the node can throw away half of its data and
still represent what is stored.

W_new = W * 2
P_new = (random_bool()) ? P + W/2 : P;

Half of the stored blocks would match P_new mod W_new and the other half
could be deleted.  This means that the store would use up between 50% and
100% of the allocated size.

Another benefit is that it increases the probability that at least someone
has every block.

If N nodes each store 1% of the blocks, then the odds of a block being
stored is pow(0.99, N).  For 1000 nodes, that gives odds of 1 in 23,164
that a block will be missing.  That means that around 13 out of 300,000
blocks would be missing.  There would likely be more nodes than that, and
also storage nodes, so it is not a major risk.

If everyone is storing 1% of blocks, then they would set W to 128.  As long
as all of the 128 buckets is covered by some nodes, then all blocks are
stored.  With 1000 nodes, that gives odds of 0.6% that at least one bucket
will be missed.  That is better than around 13 blocks being missing.

Nodes could inform peers of their W and P parameters on connection.  The
version message could be amended or a "getparams" message of some kind
could be added.

W could be encoded with 4 bits and P could be encoded with 16 bits, for 20
in total.  W = 1 << bits[19:16] and P = bits[14:0].  That gives a maximum W
of 32768, which is likely to many bits for P.

Initial download would be harder, since new nodes would have to connect to
at least 100 different nodes.  They could download from random nodes, and
just download the ones they are missing from storage nodes.  Even storage
nodes could have a range of W values.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150512/52cee4d6/attachment.html>

From danny.thorpe at gmail.com  Tue May 12 18:40:31 2015
From: danny.thorpe at gmail.com (Danny Thorpe)
Date: Tue, 12 May 2015 11:40:31 -0700
Subject: [Bitcoin-development] Bitcoin transaction
In-Reply-To: <CAL6tyga6HyYJkhbS+yCDTkNe7LDxGxcXzbwgfjQmKs20gAGPHA@mail.gmail.com>
References: <CAL6tygYkN1n2mSkSH5Xqg-KcfFkKFw0X0inC46FWnH2NVenFnA@mail.gmail.com>
	<DB5PR07MB09193865EE13BEF6ABD2CC79B5DA0@DB5PR07MB0919.eurprd07.prod.outlook.com>
	<CAL6tyga6HyYJkhbS+yCDTkNe7LDxGxcXzbwgfjQmKs20gAGPHA@mail.gmail.com>
Message-ID: <CAJN5wHVpHo4Yep3goUbMtbtxa8aWBtwdPegtHF8wTq6XxYSSww@mail.gmail.com>

See the Open Assets protocol specification for technical details on how a
colored coin (of the Open Asset flavor) is represented in a bitcoin
transaction.

https://github.com/OpenAssets/open-assets-protocol

http://www.CoinPrism.com also has a discussion forum where some colored
coin devs hang out.

http://www.coinprism.info is a blockchain explorer that is colored-coin
aware.

On Tue, May 12, 2015 at 2:54 AM, Telephone Lemien <lemientelephone at gmail.com
> wrote:

> Thank You,
> I know this, but I want to have mores details in the inputs/outputs, or in
> the script of input/output and how i will proceed in the code.
> Thanks for all replaying
>
> 2015-05-12 11:47 GMT+02:00 Patrick Mccorry (PGR) <
> patrick.mccorry at newcastle.ac.uk>:
>
>>  There is no difference to the transaction as far as im aware ? just the
>> inputs / outputs have a special meaning (and should have a special order).
>> So you can track 1 BTC throughout the blockchain and this 1 BTC represents
>> my asset. Someone may give a more useful answer.
>>
>>
>>
>> *From:* Telephone Lemien [mailto:lemientelephone at gmail.com]
>> *Sent:* 12 May 2015 10:45
>> *To:* Bitcoin Dev
>> *Subject:* [Bitcoin-development] Bitcoin transaction
>>
>>
>>
>> Hello evry body,
>>
>> I want to know what is the difference between a bitcoin transaction and
>> colored coins transaction technically.
>>
>> Thanks
>>
>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150512/09f3bae2/attachment.html>

From sergiolerner at certimix.com  Tue May 12 18:55:05 2015
From: sergiolerner at certimix.com (Sergio Lerner)
Date: Tue, 12 May 2015 15:55:05 -0300
Subject: [Bitcoin-development] Reducing the block rate instead of
 increasing the maximum block size
In-Reply-To: <5551021E.8010706@LeoWandersleb.de>
References: <55505441.3010906@certimix.com> <5551021E.8010706@LeoWandersleb.de>
Message-ID: <55524C89.6080705@certimix.com>



On 11/05/2015 04:25 p.m., Leo Wandersleb wrote:
> I assume that 1 minute block target will not get any substantial support but
> just in case only few people speaking up might be taken as careful
support of
> the idea, here's my two cents:
>
> In mining, stale shares depend on delay between pool/network and the
miner. This
> varies substantially globally and as Peter Todd/Luke-Jr mentioned,
speed of
> light will always keep those at a disadvantage that are 100 light
milli seconds
> away from the creation of the last block. If anything, this warrants
to increase
> block target, not reduce. (The increase might wait until we have
miners on Mars
> though ;) )

An additional delay of 200 milliseconds means loosing approximately 0.3%
of the revenue.
Do you really think this is going to be the key factor to prevent a
mining pool from being used?
There are lot of other factors, such as DoS protections, security,
privacy, variance, trust, algorithm to distribute shares, that are much
more important than that.

And having a 1 minute block actually reduces the payout variance 10x, so
miners will be happy for that. And many pool miners may opt to do solo
mining, and create new full-nodes.

>
>
> If SPV also becomes 10 times more traffic intensive, I can only urge
you to
> travel to anything but central Europe or the USA.
The SPV traffic is minuscule. Bloom-filers are an ugly solution that
increases bandwidth and does not provide a real privacy solution.
Small improvements in the wire protocol can reduce the traffic two-fold.

>
>
> I want bitcoin to be the currency for the other x billion and thus I
oppose any
> change that moves the balance towards the economically upper billion.
Because having a 10 minute rate Bitcoin is a good Internet money. If you
have a 1 minute rate, then it can also be a retail payment method, an
virtual game trading payment method, a gambling, XXX-video renting 
(hey, it takes less than 10 minutes to see one of those :), and much more.

You can reach more billions by having near instant payments.
Don't tell me about the morning caffe, I would like that everyone is
buying their coffe with Bitcoin and there are millions of users before
we figure out how to do that off-chain.

Best regards,
 Sergio.


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150512/7c99eb91/attachment.html>

From gmaxwell at gmail.com  Tue May 12 19:03:55 2015
From: gmaxwell at gmail.com (Gregory Maxwell)
Date: Tue, 12 May 2015 19:03:55 +0000
Subject: [Bitcoin-development] Proposed additional options for pruned
	nodes
In-Reply-To: <CAE-z3OV3VdSoiTSfASwYHr1CjZSqio303sqGq_1Y9yaYgov2sw@mail.gmail.com>
References: <CANJO25J1WRHtfQLVXUB2s_sjj39pTPWmixAcXNJ3t-5os8RPmQ@mail.gmail.com>
	<CANJO25JTtfmfsOQYOzJeksJn3CoKE3W8iLGsRko-_xd4XhB3ZA@mail.gmail.com>
	<CAJHLa0O5OxaX5g3u=dnCY6Lz_gK3QZgQEPNcWNVRD4JziwAmvg@mail.gmail.com>
	<20150512171640.GA32606@savin.petertodd.org>
	<CAE-z3OV3VdSoiTSfASwYHr1CjZSqio303sqGq_1Y9yaYgov2sw@mail.gmail.com>
Message-ID: <CAAS2fgRzGkcJbWbJmFN2-NSJGUcLdPKp0q7FjM0x7WDvHoRq=g@mail.gmail.com>

It's a little frustrating to see this just repeated without even
paying attention to the desirable characteristics from the prior
discussions.

Summarizing from memory:

(0) Block coverage should have locality; historical blocks are
(almost) always needed in contiguous ranges.   Having random peers
with totally random blocks would be horrific for performance; as you'd
have to hunt down a working peer and make a connection for each block
with high probability.

(1) Block storage on nodes with a fraction of the history should not
depend on believing random peers; because listening to peers can
easily create attacks (e.g. someone could break the network; by
convincing nodes to become unbalanced) and not useful-- it's not like
the blockchain is substantially different for anyone; if you're to the
point of needing to know coverage to fill then something is wrong.
Gaps would be handled by archive nodes, so there is no reason to
increase vulnerability by doing anything but behaving uniformly.

(2) The decision to contact a node should need O(1) communications,
not just because of the delay of chasing around just to find who has
someone; but because that chasing process usually makes the process
_highly_ sybil vulnerable.

(3) The expression of what blocks a node has should be compact (e.g.
not a dense list of blocks) so it can be rumored efficiently.

(4) Figuring out what block (ranges) a peer has given should be
computationally efficient.

(5) The communication about what blocks a node has should be compact.

(6) The coverage created by the network should be uniform, and should
remain uniform as the blockchain grows; ideally it you shouldn't need
to update your state to know what blocks a peer will store in the
future, assuming that it doesn't change the amount of data its
planning to use. (What Tier Nolan proposes sounds like it fails this
point)

(7) Growth of the blockchain shouldn't cause much (or any) need to
refetch old blocks.

I've previously proposed schemes which come close but fail one of the above.

(e.g. a scheme based on reservoir sampling that gives uniform
selection of contiguous ranges, communicating only 64 bits of data to
know what blocks a node claims to have, remaining totally uniform as
the chain grows, without any need to refetch -- but needs O(height)
work to figure out what blocks a peer has from the data it
communicated.;   or another scheme based on consistent hashes that has
log(height) computation; but sometimes may result in a node needing to
go refetch an old block range it previously didn't store-- creating
re-balancing traffic.)

So far something that meets all those criteria (and/or whatever ones
I'm not remembering) has not been discovered; but I don't really think
much time has been spent on it. I think its very likely possible.



From jtimon at jtimon.cc  Tue May 12 19:16:46 2015
From: jtimon at jtimon.cc (=?UTF-8?B?Sm9yZ2UgVGltw7Nu?=)
Date: Tue, 12 May 2015 21:16:46 +0200
Subject: [Bitcoin-development] CLTV opcode allocation; long-term plans?
In-Reply-To: <20150509091201.GA15088@savin.petertodd.org>
References: <20150504050715.GA18856@savin.petertodd.org>
	<CADJgMzs3D=6pNOQhU3ubi6=C8javRtwL0VuGFWvU+6SiuB0YWg@mail.gmail.com>
	<20150509091201.GA15088@savin.petertodd.org>
Message-ID: <CABm2gDqVu9OqNpOgCa6hMw3CXp7ePWTaAGPtMq4T9rG658K=ow@mail.gmail.com>

This saves us ocodes for later but it's uglier and produces slightly
bigger scripts.
If we're convinced it's worth it, seems like the right way to do it,
and certainly cltv and rclv/op_maturity are related.
But let's not forget that we can always use this same trick with the
last opcode to get 2^64 brand new opcodes.
So I'm not convinced at all on whether we want  #5496 or #6124.
But it would be nice to decide and stop blocking  this.

On Sat, May 9, 2015 at 11:12 AM, Peter Todd <pete at petertodd.org> wrote:
> On Tue, May 05, 2015 at 01:54:33AM +0100, Btc Drak wrote:
>> > That said, if people have strong feelings about this, I would be willing
>> > to make OP_CLTV work as follows:
>> >
>> >     <nLockTime> 1 OP_CLTV
>> >
>> > Where the 1 selects absolute mode, and all others act as OP_NOP's. A
>> > future relative CLTV could then be a future soft-fork implemented as
>> > follows:
>> >
>> >     <relative nLockTime> 2 OP_CLTV
>> >
>> > On the bad side it'd be two or three days of work to rewrite all the
>> > existing tests and example code and update the BIP, and (slightly) gets
>> > us away from the well-tested existing implementation. It also may
>> > complicate the codebase compared to sticking with just doing a Script
>> > v2.0, with the additional execution environment data required for v2.0
>> > scripts cleanly separated out. But all in all, the above isn't too big
>> > of a deal.
>>
>>
>> Adding a parameter to OP_CLTV makes it much more flexible and is the most
>> economic use of precious NOPs.
>> The extra time required is ok and it would be good to make this change to
>> the PR in time for the feature freeze.
>
> Done!
>
> https://github.com/bitcoin/bitcoin/pull/5496#issuecomment-100454263
>
> --
> 'peter'[:-1]@petertodd.org
> 000000000000000012c438a597ad15df697888be579f4f818a30517cd60fbdc8
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>



From pieter.wuille at gmail.com  Tue May 12 19:23:22 2015
From: pieter.wuille at gmail.com (Pieter Wuille)
Date: Tue, 12 May 2015 12:23:22 -0700
Subject: [Bitcoin-development] CLTV opcode allocation; long-term plans?
In-Reply-To: <CABm2gDqVu9OqNpOgCa6hMw3CXp7ePWTaAGPtMq4T9rG658K=ow@mail.gmail.com>
References: <20150504050715.GA18856@savin.petertodd.org>
	<CADJgMzs3D=6pNOQhU3ubi6=C8javRtwL0VuGFWvU+6SiuB0YWg@mail.gmail.com>
	<20150509091201.GA15088@savin.petertodd.org>
	<CABm2gDqVu9OqNpOgCa6hMw3CXp7ePWTaAGPtMq4T9rG658K=ow@mail.gmail.com>
Message-ID: <CAPg+sBh8GQdTurvEkMB1+oSWhLgO4Oq2Cu7WRkWp32fRJfaCiw@mail.gmail.com>

I have no strong opinion, but a slight preference for separate opcodes.

Reason: given the current progress, they'll likely be deployed
independently, and maybe the end result is not something that cleanly fits
the current CLTV argument structure.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150512/4bfcc543/attachment.html>

From gappleto97 at gmail.com  Tue May 12 19:24:20 2015
From: gappleto97 at gmail.com (gabe appleton)
Date: Tue, 12 May 2015 15:24:20 -0400
Subject: [Bitcoin-development] Proposed additional options for pruned
	nodes
In-Reply-To: <CAAS2fgRzGkcJbWbJmFN2-NSJGUcLdPKp0q7FjM0x7WDvHoRq=g@mail.gmail.com>
References: <CANJO25J1WRHtfQLVXUB2s_sjj39pTPWmixAcXNJ3t-5os8RPmQ@mail.gmail.com>
	<CANJO25JTtfmfsOQYOzJeksJn3CoKE3W8iLGsRko-_xd4XhB3ZA@mail.gmail.com>
	<CAJHLa0O5OxaX5g3u=dnCY6Lz_gK3QZgQEPNcWNVRD4JziwAmvg@mail.gmail.com>
	<20150512171640.GA32606@savin.petertodd.org>
	<CAE-z3OV3VdSoiTSfASwYHr1CjZSqio303sqGq_1Y9yaYgov2sw@mail.gmail.com>
	<CAAS2fgRzGkcJbWbJmFN2-NSJGUcLdPKp0q7FjM0x7WDvHoRq=g@mail.gmail.com>
Message-ID: <CANJO25+qURmDzsMgnm7+tsw7icFO--gWhmKmQPuNQCoh_R2big@mail.gmail.com>

0, 1, 3, 4, 5, 6 can be solved by looking at chunks chronologically. Ie,
give the signed (by sender) hash of the first and last block in your range.
This is less data dense than the idea above, but it might work better.

That said, this is likely a less secure way to do it. To improve upon that,
a node could request a block of random height within that range and verify
it, but that violates point 2. And the scheme in itself definitely violates
point 7.
On May 12, 2015 3:07 PM, "Gregory Maxwell" <gmaxwell at gmail.com> wrote:

> It's a little frustrating to see this just repeated without even
> paying attention to the desirable characteristics from the prior
> discussions.
>
> Summarizing from memory:
>
> (0) Block coverage should have locality; historical blocks are
> (almost) always needed in contiguous ranges.   Having random peers
> with totally random blocks would be horrific for performance; as you'd
> have to hunt down a working peer and make a connection for each block
> with high probability.
>
> (1) Block storage on nodes with a fraction of the history should not
> depend on believing random peers; because listening to peers can
> easily create attacks (e.g. someone could break the network; by
> convincing nodes to become unbalanced) and not useful-- it's not like
> the blockchain is substantially different for anyone; if you're to the
> point of needing to know coverage to fill then something is wrong.
> Gaps would be handled by archive nodes, so there is no reason to
> increase vulnerability by doing anything but behaving uniformly.
>
> (2) The decision to contact a node should need O(1) communications,
> not just because of the delay of chasing around just to find who has
> someone; but because that chasing process usually makes the process
> _highly_ sybil vulnerable.
>
> (3) The expression of what blocks a node has should be compact (e.g.
> not a dense list of blocks) so it can be rumored efficiently.
>
> (4) Figuring out what block (ranges) a peer has given should be
> computationally efficient.
>
> (5) The communication about what blocks a node has should be compact.
>
> (6) The coverage created by the network should be uniform, and should
> remain uniform as the blockchain grows; ideally it you shouldn't need
> to update your state to know what blocks a peer will store in the
> future, assuming that it doesn't change the amount of data its
> planning to use. (What Tier Nolan proposes sounds like it fails this
> point)
>
> (7) Growth of the blockchain shouldn't cause much (or any) need to
> refetch old blocks.
>
> I've previously proposed schemes which come close but fail one of the
> above.
>
> (e.g. a scheme based on reservoir sampling that gives uniform
> selection of contiguous ranges, communicating only 64 bits of data to
> know what blocks a node claims to have, remaining totally uniform as
> the chain grows, without any need to refetch -- but needs O(height)
> work to figure out what blocks a peer has from the data it
> communicated.;   or another scheme based on consistent hashes that has
> log(height) computation; but sometimes may result in a node needing to
> go refetch an old block range it previously didn't store-- creating
> re-balancing traffic.)
>
> So far something that meets all those criteria (and/or whatever ones
> I'm not remembering) has not been discovered; but I don't really think
> much time has been spent on it. I think its very likely possible.
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150512/e8557e1a/attachment.html>

From btcdrak at gmail.com  Tue May 12 19:30:35 2015
From: btcdrak at gmail.com (Btc Drak)
Date: Tue, 12 May 2015 20:30:35 +0100
Subject: [Bitcoin-development] CLTV opcode allocation; long-term plans?
In-Reply-To: <CABm2gDqVu9OqNpOgCa6hMw3CXp7ePWTaAGPtMq4T9rG658K=ow@mail.gmail.com>
References: <20150504050715.GA18856@savin.petertodd.org>
	<CADJgMzs3D=6pNOQhU3ubi6=C8javRtwL0VuGFWvU+6SiuB0YWg@mail.gmail.com>
	<20150509091201.GA15088@savin.petertodd.org>
	<CABm2gDqVu9OqNpOgCa6hMw3CXp7ePWTaAGPtMq4T9rG658K=ow@mail.gmail.com>
Message-ID: <CADJgMzv1NdoXKDScQ1+OycijzME=W2YSut3GMF=EEuKQf6VeUg@mail.gmail.com>

Gavin and @NicolasDorier have a point: If there isn't actually scarcity of
NOPs because OP_NOP10 could become <type> OP_EX (if we run out), it makes
sense to chose the original unparameterised CLTV version #6124 which also
has been better tested. It's cleaner, more readable and results in a
slightly smaller script which has also got to be a plus.

On Tue, May 12, 2015 at 8:16 PM, Jorge Tim?n <jtimon at jtimon.cc> wrote:

> This saves us ocodes for later but it's uglier and produces slightly
> bigger scripts.
> If we're convinced it's worth it, seems like the right way to do it,
> and certainly cltv and rclv/op_maturity are related.
> But let's not forget that we can always use this same trick with the
> last opcode to get 2^64 brand new opcodes.
> So I'm not convinced at all on whether we want  #5496 or #6124.
> But it would be nice to decide and stop blocking  this.
>
> On Sat, May 9, 2015 at 11:12 AM, Peter Todd <pete at petertodd.org> wrote:
> > On Tue, May 05, 2015 at 01:54:33AM +0100, Btc Drak wrote:
> >> > That said, if people have strong feelings about this, I would be
> willing
> >> > to make OP_CLTV work as follows:
> >> >
> >> >     <nLockTime> 1 OP_CLTV
> >> >
> >> > Where the 1 selects absolute mode, and all others act as OP_NOP's. A
> >> > future relative CLTV could then be a future soft-fork implemented as
> >> > follows:
> >> >
> >> >     <relative nLockTime> 2 OP_CLTV
> >> >
> >> > On the bad side it'd be two or three days of work to rewrite all the
> >> > existing tests and example code and update the BIP, and (slightly)
> gets
> >> > us away from the well-tested existing implementation. It also may
> >> > complicate the codebase compared to sticking with just doing a Script
> >> > v2.0, with the additional execution environment data required for v2.0
> >> > scripts cleanly separated out. But all in all, the above isn't too big
> >> > of a deal.
> >>
> >>
> >> Adding a parameter to OP_CLTV makes it much more flexible and is the
> most
> >> economic use of precious NOPs.
> >> The extra time required is ok and it would be good to make this change
> to
> >> the PR in time for the feature freeze.
> >
> > Done!
> >
> > https://github.com/bitcoin/bitcoin/pull/5496#issuecomment-100454263
> >
> > --
> > 'peter'[:-1]@petertodd.org
> > 000000000000000012c438a597ad15df697888be579f4f818a30517cd60fbdc8
> >
> >
> ------------------------------------------------------------------------------
> > One dashboard for servers and applications across Physical-Virtual-Cloud
> > Widest out-of-the-box monitoring support with 50+ applications
> > Performance metrics, stats and reports that give you Actionable Insights
> > Deep dive visibility with transaction tracing using APM Insight.
> > http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> > _______________________________________________
> > Bitcoin-development mailing list
> > Bitcoin-development at lists.sourceforge.net
> > https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> >
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150512/941146d0/attachment.html>

From jgarzik at bitpay.com  Tue May 12 19:38:20 2015
From: jgarzik at bitpay.com (Jeff Garzik)
Date: Tue, 12 May 2015 12:38:20 -0700
Subject: [Bitcoin-development] Proposed additional options for pruned
	nodes
In-Reply-To: <CANJO25+qURmDzsMgnm7+tsw7icFO--gWhmKmQPuNQCoh_R2big@mail.gmail.com>
References: <CANJO25J1WRHtfQLVXUB2s_sjj39pTPWmixAcXNJ3t-5os8RPmQ@mail.gmail.com>
	<CANJO25JTtfmfsOQYOzJeksJn3CoKE3W8iLGsRko-_xd4XhB3ZA@mail.gmail.com>
	<CAJHLa0O5OxaX5g3u=dnCY6Lz_gK3QZgQEPNcWNVRD4JziwAmvg@mail.gmail.com>
	<20150512171640.GA32606@savin.petertodd.org>
	<CAE-z3OV3VdSoiTSfASwYHr1CjZSqio303sqGq_1Y9yaYgov2sw@mail.gmail.com>
	<CAAS2fgRzGkcJbWbJmFN2-NSJGUcLdPKp0q7FjM0x7WDvHoRq=g@mail.gmail.com>
	<CANJO25+qURmDzsMgnm7+tsw7icFO--gWhmKmQPuNQCoh_R2big@mail.gmail.com>
Message-ID: <CAJHLa0PDbxuqRHuGNhsyvLpAaDq=ZHSg_u-Sb7FqNVnYrhFkFg@mail.gmail.com>

One general problem is that security is weakened when an attacker can DoS a
small part of the chain by DoS'ing a small number of nodes - yet the impact
is a network-wide DoS because nobody can complete a sync.


On Tue, May 12, 2015 at 12:24 PM, gabe appleton <gappleto97 at gmail.com>
wrote:

> 0, 1, 3, 4, 5, 6 can be solved by looking at chunks chronologically. Ie,
> give the signed (by sender) hash of the first and last block in your range.
> This is less data dense than the idea above, but it might work better.
>
> That said, this is likely a less secure way to do it. To improve upon
> that, a node could request a block of random height within that range and
> verify it, but that violates point 2. And the scheme in itself definitely
> violates point 7.
> On May 12, 2015 3:07 PM, "Gregory Maxwell" <gmaxwell at gmail.com> wrote:
>
>> It's a little frustrating to see this just repeated without even
>> paying attention to the desirable characteristics from the prior
>> discussions.
>>
>> Summarizing from memory:
>>
>> (0) Block coverage should have locality; historical blocks are
>> (almost) always needed in contiguous ranges.   Having random peers
>> with totally random blocks would be horrific for performance; as you'd
>> have to hunt down a working peer and make a connection for each block
>> with high probability.
>>
>> (1) Block storage on nodes with a fraction of the history should not
>> depend on believing random peers; because listening to peers can
>> easily create attacks (e.g. someone could break the network; by
>> convincing nodes to become unbalanced) and not useful-- it's not like
>> the blockchain is substantially different for anyone; if you're to the
>> point of needing to know coverage to fill then something is wrong.
>> Gaps would be handled by archive nodes, so there is no reason to
>> increase vulnerability by doing anything but behaving uniformly.
>>
>> (2) The decision to contact a node should need O(1) communications,
>> not just because of the delay of chasing around just to find who has
>> someone; but because that chasing process usually makes the process
>> _highly_ sybil vulnerable.
>>
>> (3) The expression of what blocks a node has should be compact (e.g.
>> not a dense list of blocks) so it can be rumored efficiently.
>>
>> (4) Figuring out what block (ranges) a peer has given should be
>> computationally efficient.
>>
>> (5) The communication about what blocks a node has should be compact.
>>
>> (6) The coverage created by the network should be uniform, and should
>> remain uniform as the blockchain grows; ideally it you shouldn't need
>> to update your state to know what blocks a peer will store in the
>> future, assuming that it doesn't change the amount of data its
>> planning to use. (What Tier Nolan proposes sounds like it fails this
>> point)
>>
>> (7) Growth of the blockchain shouldn't cause much (or any) need to
>> refetch old blocks.
>>
>> I've previously proposed schemes which come close but fail one of the
>> above.
>>
>> (e.g. a scheme based on reservoir sampling that gives uniform
>> selection of contiguous ranges, communicating only 64 bits of data to
>> know what blocks a node claims to have, remaining totally uniform as
>> the chain grows, without any need to refetch -- but needs O(height)
>> work to figure out what blocks a peer has from the data it
>> communicated.;   or another scheme based on consistent hashes that has
>> log(height) computation; but sometimes may result in a node needing to
>> go refetch an old block range it previously didn't store-- creating
>> re-balancing traffic.)
>>
>> So far something that meets all those criteria (and/or whatever ones
>> I'm not remembering) has not been discovered; but I don't really think
>> much time has been spent on it. I think its very likely possible.
>>
>>
>> ------------------------------------------------------------------------------
>> One dashboard for servers and applications across Physical-Virtual-Cloud
>> Widest out-of-the-box monitoring support with 50+ applications
>> Performance metrics, stats and reports that give you Actionable Insights
>> Deep dive visibility with transaction tracing using APM Insight.
>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>


-- 
Jeff Garzik
Bitcoin core developer and open source evangelist
BitPay, Inc.      https://bitpay.com/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150512/e498ae86/attachment.html>

From gappleto97 at gmail.com  Tue May 12 19:43:45 2015
From: gappleto97 at gmail.com (gabe appleton)
Date: Tue, 12 May 2015 15:43:45 -0400
Subject: [Bitcoin-development] Proposed additional options for pruned
	nodes
In-Reply-To: <CAJHLa0PDbxuqRHuGNhsyvLpAaDq=ZHSg_u-Sb7FqNVnYrhFkFg@mail.gmail.com>
References: <CANJO25J1WRHtfQLVXUB2s_sjj39pTPWmixAcXNJ3t-5os8RPmQ@mail.gmail.com>
	<CANJO25JTtfmfsOQYOzJeksJn3CoKE3W8iLGsRko-_xd4XhB3ZA@mail.gmail.com>
	<CAJHLa0O5OxaX5g3u=dnCY6Lz_gK3QZgQEPNcWNVRD4JziwAmvg@mail.gmail.com>
	<20150512171640.GA32606@savin.petertodd.org>
	<CAE-z3OV3VdSoiTSfASwYHr1CjZSqio303sqGq_1Y9yaYgov2sw@mail.gmail.com>
	<CAAS2fgRzGkcJbWbJmFN2-NSJGUcLdPKp0q7FjM0x7WDvHoRq=g@mail.gmail.com>
	<CANJO25+qURmDzsMgnm7+tsw7icFO--gWhmKmQPuNQCoh_R2big@mail.gmail.com>
	<CAJHLa0PDbxuqRHuGNhsyvLpAaDq=ZHSg_u-Sb7FqNVnYrhFkFg@mail.gmail.com>
Message-ID: <CANJO25JqoidjKEmi1wv-ACBm6eB-B=g3r5kurLK5O0Gx5orJmA@mail.gmail.com>

Yet this holds true in our current assumptions of the network as well: that
it will become a collection of pruned nodes with a few storage nodes.

A hybrid option makes this better, because it spreads the risk, rather than
concentrating it in full nodes.
On May 12, 2015 3:38 PM, "Jeff Garzik" <jgarzik at bitpay.com> wrote:

> One general problem is that security is weakened when an attacker can DoS
> a small part of the chain by DoS'ing a small number of nodes - yet the
> impact is a network-wide DoS because nobody can complete a sync.
>
>
> On Tue, May 12, 2015 at 12:24 PM, gabe appleton <gappleto97 at gmail.com>
> wrote:
>
>> 0, 1, 3, 4, 5, 6 can be solved by looking at chunks chronologically. Ie,
>> give the signed (by sender) hash of the first and last block in your range.
>> This is less data dense than the idea above, but it might work better.
>>
>> That said, this is likely a less secure way to do it. To improve upon
>> that, a node could request a block of random height within that range and
>> verify it, but that violates point 2. And the scheme in itself definitely
>> violates point 7.
>> On May 12, 2015 3:07 PM, "Gregory Maxwell" <gmaxwell at gmail.com> wrote:
>>
>>> It's a little frustrating to see this just repeated without even
>>> paying attention to the desirable characteristics from the prior
>>> discussions.
>>>
>>> Summarizing from memory:
>>>
>>> (0) Block coverage should have locality; historical blocks are
>>> (almost) always needed in contiguous ranges.   Having random peers
>>> with totally random blocks would be horrific for performance; as you'd
>>> have to hunt down a working peer and make a connection for each block
>>> with high probability.
>>>
>>> (1) Block storage on nodes with a fraction of the history should not
>>> depend on believing random peers; because listening to peers can
>>> easily create attacks (e.g. someone could break the network; by
>>> convincing nodes to become unbalanced) and not useful-- it's not like
>>> the blockchain is substantially different for anyone; if you're to the
>>> point of needing to know coverage to fill then something is wrong.
>>> Gaps would be handled by archive nodes, so there is no reason to
>>> increase vulnerability by doing anything but behaving uniformly.
>>>
>>> (2) The decision to contact a node should need O(1) communications,
>>> not just because of the delay of chasing around just to find who has
>>> someone; but because that chasing process usually makes the process
>>> _highly_ sybil vulnerable.
>>>
>>> (3) The expression of what blocks a node has should be compact (e.g.
>>> not a dense list of blocks) so it can be rumored efficiently.
>>>
>>> (4) Figuring out what block (ranges) a peer has given should be
>>> computationally efficient.
>>>
>>> (5) The communication about what blocks a node has should be compact.
>>>
>>> (6) The coverage created by the network should be uniform, and should
>>> remain uniform as the blockchain grows; ideally it you shouldn't need
>>> to update your state to know what blocks a peer will store in the
>>> future, assuming that it doesn't change the amount of data its
>>> planning to use. (What Tier Nolan proposes sounds like it fails this
>>> point)
>>>
>>> (7) Growth of the blockchain shouldn't cause much (or any) need to
>>> refetch old blocks.
>>>
>>> I've previously proposed schemes which come close but fail one of the
>>> above.
>>>
>>> (e.g. a scheme based on reservoir sampling that gives uniform
>>> selection of contiguous ranges, communicating only 64 bits of data to
>>> know what blocks a node claims to have, remaining totally uniform as
>>> the chain grows, without any need to refetch -- but needs O(height)
>>> work to figure out what blocks a peer has from the data it
>>> communicated.;   or another scheme based on consistent hashes that has
>>> log(height) computation; but sometimes may result in a node needing to
>>> go refetch an old block range it previously didn't store-- creating
>>> re-balancing traffic.)
>>>
>>> So far something that meets all those criteria (and/or whatever ones
>>> I'm not remembering) has not been discovered; but I don't really think
>>> much time has been spent on it. I think its very likely possible.
>>>
>>>
>>> ------------------------------------------------------------------------------
>>> One dashboard for servers and applications across Physical-Virtual-Cloud
>>> Widest out-of-the-box monitoring support with 50+ applications
>>> Performance metrics, stats and reports that give you Actionable Insights
>>> Deep dive visibility with transaction tracing using APM Insight.
>>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>>> _______________________________________________
>>> Bitcoin-development mailing list
>>> Bitcoin-development at lists.sourceforge.net
>>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>>
>>
>>
>> ------------------------------------------------------------------------------
>> One dashboard for servers and applications across Physical-Virtual-Cloud
>> Widest out-of-the-box monitoring support with 50+ applications
>> Performance metrics, stats and reports that give you Actionable Insights
>> Deep dive visibility with transaction tracing using APM Insight.
>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>>
>
>
> --
> Jeff Garzik
> Bitcoin core developer and open source evangelist
> BitPay, Inc.      https://bitpay.com/
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150512/1ba83e55/attachment.html>

From danny.thorpe at gmail.com  Tue May 12 19:50:16 2015
From: danny.thorpe at gmail.com (Danny Thorpe)
Date: Tue, 12 May 2015 12:50:16 -0700
Subject: [Bitcoin-development] A suggestion for reducing the size of the
 UTXO database
In-Reply-To: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
Message-ID: <CAJN5wHXHtcGWi3uViFcAL4OyPJV9HuNqTGy90c3zKONynNWT6w@mail.gmail.com>

Having thousands of utxos floating around for a single address is clearly a
bad thing - it creates a lot of memory load on bitcoin nodes.

However, having only one utxo for an address is also a bad thing, for
concurrent operations.

Having "several" utxos available to spend is good for parallelism, so that
2 or more tasks which are spending from the same address don't have to line
up single file waiting for one of the tasks to publish a tx first so that
the next task can spend the (unconfirmed) change output of the first.
Requiring/Forcing/Having a single output carry the entire balance of an
address does not work at scale. (Yes, this presumes that the tasks are
coordinated so that they don't attempt to spend the same outputs. Internal
coordination is solvable.)

In multiple replies, you push for having "all" utxos of an address spent in
one transaction.  Why all?  If the objective is to reduce the size of the
utxo pool, it would be sufficient simply to recommend that wallets and
other spenders consume more utxos than they create, on average.

I'm ok with "consume more utxos than you generate" as a good citizen / best
practices recommendation, but a requirement that all prior outputs must be
spent in one transaction seems excessive and impractical.

-Danny

On Sat, May 9, 2015 at 10:09 AM, Jim Phillips <jim at ergophobia.org> wrote:

> Forgive me if this idea has been suggested before, but I made this
> suggestion on reddit and I got some feedback recommending I also bring it
> to this list -- so here goes.
>
> I wonder if there isn't perhaps a simpler way of dealing with UTXO growth.
> What if, rather than deal with the issue at the protocol level, we deal
> with it at the source of the problem -- the wallets. Right now, the typical
> wallet selects only the minimum number of unspent outputs when building a
> transaction. The goal is to keep the transaction size to a minimum so that
> the fee stays low. Consequently, lots of unspent outputs just don't get
> used, and are left lying around until some point in the future.
>
> What if we started designing wallets to consolidate unspent outputs? When
> selecting unspent outputs for a transaction, rather than choosing just the
> minimum number from a particular address, why not select them ALL? Take all
> of the UTXOs from a particular address or wallet, send however much needs
> to be spent to the payee, and send the rest back to the same address or a
> change address as a single output? Through this method, we should wind up
> shrinking the UTXO database over time rather than growing it with each
> transaction. Obviously, as Bitcoin gains wider adoption, the UTXO database
> will grow, simply because there are 7 billion people in the world, and
> eventually a good percentage of them will have one or more wallets with
> spendable bitcoin. But this idea could limit the growth at least.
>
> The vast majority of users are running one of a handful of different
> wallet apps: Core, Electrum; Armory; Mycelium; Breadwallet; Coinbase;
> Circle; Blockchain.info; and maybe a few others. The developers of all
> these wallets have a vested interest in the continued usefulness of
> Bitcoin, and so should not be opposed to changing their UTXO selection
> algorithms to one that reduces the UTXO database instead of growing it.
>
> From the miners perspective, even though these types of transactions would
> be larger, the fee could stay low. Miners actually benefit from them in
> that it reduces the amount of storage they need to dedicate to holding the
> UTXO. So miners are incentivized to mine these types of transactions with a
> higher priority despite a low fee.
>
> Relays could also get in on the action and enforce this type of behavior
> by refusing to relay or deprioritizing the relay of transactions that don't
> use all of the available UTXOs from the addresses used as inputs. Relays
> are not only the ones who benefit the most from a reduction of the UTXO
> database, they're also in the best position to promote good behavior.
>
> --
> *James G. Phillips IV*
> <https://plus.google.com/u/0/113107039501292625391/posts>
>
> *"Don't bunt. Aim out of the ball park. Aim for the company of immortals."
> -- David Ogilvy*
>
>  *This message was created with 100% recycled electrons. Please think
> twice before printing.*
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150512/77139440/attachment.html>

From gmaxwell at gmail.com  Tue May 12 20:02:36 2015
From: gmaxwell at gmail.com (Gregory Maxwell)
Date: Tue, 12 May 2015 20:02:36 +0000
Subject: [Bitcoin-development] Proposed additional options for pruned
	nodes
In-Reply-To: <CAJHLa0PDbxuqRHuGNhsyvLpAaDq=ZHSg_u-Sb7FqNVnYrhFkFg@mail.gmail.com>
References: <CANJO25J1WRHtfQLVXUB2s_sjj39pTPWmixAcXNJ3t-5os8RPmQ@mail.gmail.com>
	<CANJO25JTtfmfsOQYOzJeksJn3CoKE3W8iLGsRko-_xd4XhB3ZA@mail.gmail.com>
	<CAJHLa0O5OxaX5g3u=dnCY6Lz_gK3QZgQEPNcWNVRD4JziwAmvg@mail.gmail.com>
	<20150512171640.GA32606@savin.petertodd.org>
	<CAE-z3OV3VdSoiTSfASwYHr1CjZSqio303sqGq_1Y9yaYgov2sw@mail.gmail.com>
	<CAAS2fgRzGkcJbWbJmFN2-NSJGUcLdPKp0q7FjM0x7WDvHoRq=g@mail.gmail.com>
	<CANJO25+qURmDzsMgnm7+tsw7icFO--gWhmKmQPuNQCoh_R2big@mail.gmail.com>
	<CAJHLa0PDbxuqRHuGNhsyvLpAaDq=ZHSg_u-Sb7FqNVnYrhFkFg@mail.gmail.com>
Message-ID: <CAAS2fgTCMeNdcmMxURxaoAJn8=XZnTP8Gp6PbRk5w7KXAZ8t3g@mail.gmail.com>

On Tue, May 12, 2015 at 7:38 PM, Jeff Garzik <jgarzik at bitpay.com> wrote:
> One general problem is that security is weakened when an attacker can DoS a
> small part of the chain by DoS'ing a small number of nodes - yet the impact
> is a network-wide DoS because nobody can complete a sync.

It might be more interesting to think of that attack as a bandwidth
exhaustion DOS attack on the archive nodes... if you can't get a copy
without them, thats where you'll go.

So the question arises: does the option make some nodes that would
have been archive not be? Probably some-- but would it do so much that
it would offset the gain of additional copies of the data when those
attacks are not going no. I suspect not.

It's also useful to give people incremental ways to participate even
when they can't swollow the whole pill; or choose to provide the
resource thats cheap for them to provide.  In particular, if there is
only two kinds of full nodes-- archive and pruned; then the archive
nodes take both a huge disk and bandwidth cost; where as if there are
fractional then archives take low(er) bandwidth unless the fractionals
get DOS attacked.



From jgarzik at bitpay.com  Tue May 12 20:10:56 2015
From: jgarzik at bitpay.com (Jeff Garzik)
Date: Tue, 12 May 2015 13:10:56 -0700
Subject: [Bitcoin-development] Proposed additional options for pruned
	nodes
In-Reply-To: <CAAS2fgTCMeNdcmMxURxaoAJn8=XZnTP8Gp6PbRk5w7KXAZ8t3g@mail.gmail.com>
References: <CANJO25J1WRHtfQLVXUB2s_sjj39pTPWmixAcXNJ3t-5os8RPmQ@mail.gmail.com>
	<CANJO25JTtfmfsOQYOzJeksJn3CoKE3W8iLGsRko-_xd4XhB3ZA@mail.gmail.com>
	<CAJHLa0O5OxaX5g3u=dnCY6Lz_gK3QZgQEPNcWNVRD4JziwAmvg@mail.gmail.com>
	<20150512171640.GA32606@savin.petertodd.org>
	<CAE-z3OV3VdSoiTSfASwYHr1CjZSqio303sqGq_1Y9yaYgov2sw@mail.gmail.com>
	<CAAS2fgRzGkcJbWbJmFN2-NSJGUcLdPKp0q7FjM0x7WDvHoRq=g@mail.gmail.com>
	<CANJO25+qURmDzsMgnm7+tsw7icFO--gWhmKmQPuNQCoh_R2big@mail.gmail.com>
	<CAJHLa0PDbxuqRHuGNhsyvLpAaDq=ZHSg_u-Sb7FqNVnYrhFkFg@mail.gmail.com>
	<CAAS2fgTCMeNdcmMxURxaoAJn8=XZnTP8Gp6PbRk5w7KXAZ8t3g@mail.gmail.com>
Message-ID: <CAJHLa0O3fgmg4AFAM9+4RRkhSo8ekATs2Ks+Ry7ooQafjQ-4qw@mail.gmail.com>

True.  Part of the issue rests on the block sync horizon/cliff.  There is a
value X which is the average number of blocks the 90th percentile of nodes
need in order to sync.  It is sufficient for the [semi-]pruned nodes to
keep X blocks, after which nodes must fall back to archive nodes for older
data.

There is simply far, far more demand for recent blocks, and the demand for
old blocks very rapidly falls off.

There was even a more radical suggestion years ago - refuse to sync if too
old (>2 weeks?), and force the user to download ancient data via torrent.



On Tue, May 12, 2015 at 1:02 PM, Gregory Maxwell <gmaxwell at gmail.com> wrote:

> On Tue, May 12, 2015 at 7:38 PM, Jeff Garzik <jgarzik at bitpay.com> wrote:
> > One general problem is that security is weakened when an attacker can
> DoS a
> > small part of the chain by DoS'ing a small number of nodes - yet the
> impact
> > is a network-wide DoS because nobody can complete a sync.
>
> It might be more interesting to think of that attack as a bandwidth
> exhaustion DOS attack on the archive nodes... if you can't get a copy
> without them, thats where you'll go.
>
> So the question arises: does the option make some nodes that would
> have been archive not be? Probably some-- but would it do so much that
> it would offset the gain of additional copies of the data when those
> attacks are not going no. I suspect not.
>
> It's also useful to give people incremental ways to participate even
> when they can't swollow the whole pill; or choose to provide the
> resource thats cheap for them to provide.  In particular, if there is
> only two kinds of full nodes-- archive and pruned; then the archive
> nodes take both a huge disk and bandwidth cost; where as if there are
> fractional then archives take low(er) bandwidth unless the fractionals
> get DOS attacked.
>



-- 
Jeff Garzik
Bitcoin core developer and open source evangelist
BitPay, Inc.      https://bitpay.com/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150512/091723db/attachment.html>

From luke at dashjr.org  Tue May 12 20:38:27 2015
From: luke at dashjr.org (Luke Dashjr)
Date: Tue, 12 May 2015 20:38:27 +0000
Subject: [Bitcoin-development] CLTV opcode allocation; long-term plans?
In-Reply-To: <CADJgMzv1NdoXKDScQ1+OycijzME=W2YSut3GMF=EEuKQf6VeUg@mail.gmail.com>
References: <20150504050715.GA18856@savin.petertodd.org>
	<CABm2gDqVu9OqNpOgCa6hMw3CXp7ePWTaAGPtMq4T9rG658K=ow@mail.gmail.com>
	<CADJgMzv1NdoXKDScQ1+OycijzME=W2YSut3GMF=EEuKQf6VeUg@mail.gmail.com>
Message-ID: <201505122038.28831.luke@dashjr.org>

It should actually be straightforward to softfork RCLTV in as a negative CLTV.
All nLockTime are >= any negative number, so a negative number makes CLTV a 
no-op always. Therefore, it is clean to define negative numbers as relative 
later. It's also somewhat obvious to developers, since negative numbers often 
imply an offset (eg, negative list indices in Python).

Luke



From gappleto97 at gmail.com  Tue May 12 20:41:10 2015
From: gappleto97 at gmail.com (gabe appleton)
Date: Tue, 12 May 2015 16:41:10 -0400
Subject: [Bitcoin-development] Proposed additional options for pruned
	nodes
In-Reply-To: <CAJHLa0O3fgmg4AFAM9+4RRkhSo8ekATs2Ks+Ry7ooQafjQ-4qw@mail.gmail.com>
References: <CANJO25J1WRHtfQLVXUB2s_sjj39pTPWmixAcXNJ3t-5os8RPmQ@mail.gmail.com>
	<CANJO25JTtfmfsOQYOzJeksJn3CoKE3W8iLGsRko-_xd4XhB3ZA@mail.gmail.com>
	<CAJHLa0O5OxaX5g3u=dnCY6Lz_gK3QZgQEPNcWNVRD4JziwAmvg@mail.gmail.com>
	<20150512171640.GA32606@savin.petertodd.org>
	<CAE-z3OV3VdSoiTSfASwYHr1CjZSqio303sqGq_1Y9yaYgov2sw@mail.gmail.com>
	<CAAS2fgRzGkcJbWbJmFN2-NSJGUcLdPKp0q7FjM0x7WDvHoRq=g@mail.gmail.com>
	<CANJO25+qURmDzsMgnm7+tsw7icFO--gWhmKmQPuNQCoh_R2big@mail.gmail.com>
	<CAJHLa0PDbxuqRHuGNhsyvLpAaDq=ZHSg_u-Sb7FqNVnYrhFkFg@mail.gmail.com>
	<CAAS2fgTCMeNdcmMxURxaoAJn8=XZnTP8Gp6PbRk5w7KXAZ8t3g@mail.gmail.com>
	<CAJHLa0O3fgmg4AFAM9+4RRkhSo8ekATs2Ks+Ry7ooQafjQ-4qw@mail.gmail.com>
Message-ID: <CANJO25+yXnkQm8ATq694PurDKGBPTkCcJzD4fJaPS4Jy9HmbTg@mail.gmail.com>

I suppose this begs two questions:

1) why not have a partial archive store the most recent X% of the
blockchain by default?

2) why not include some sort of torrent in QT, to mitigate this risk? I
don't think this is necessarily a good idea, but I'd like to hear the
reasoning.
On May 12, 2015 4:11 PM, "Jeff Garzik" <jgarzik at bitpay.com> wrote:

> True.  Part of the issue rests on the block sync horizon/cliff.  There is
> a value X which is the average number of blocks the 90th percentile of
> nodes need in order to sync.  It is sufficient for the [semi-]pruned nodes
> to keep X blocks, after which nodes must fall back to archive nodes for
> older data.
>
> There is simply far, far more demand for recent blocks, and the demand for
> old blocks very rapidly falls off.
>
> There was even a more radical suggestion years ago - refuse to sync if too
> old (>2 weeks?), and force the user to download ancient data via torrent.
>
>
>
> On Tue, May 12, 2015 at 1:02 PM, Gregory Maxwell <gmaxwell at gmail.com>
> wrote:
>
>> On Tue, May 12, 2015 at 7:38 PM, Jeff Garzik <jgarzik at bitpay.com> wrote:
>> > One general problem is that security is weakened when an attacker can
>> DoS a
>> > small part of the chain by DoS'ing a small number of nodes - yet the
>> impact
>> > is a network-wide DoS because nobody can complete a sync.
>>
>> It might be more interesting to think of that attack as a bandwidth
>> exhaustion DOS attack on the archive nodes... if you can't get a copy
>> without them, thats where you'll go.
>>
>> So the question arises: does the option make some nodes that would
>> have been archive not be? Probably some-- but would it do so much that
>> it would offset the gain of additional copies of the data when those
>> attacks are not going no. I suspect not.
>>
>> It's also useful to give people incremental ways to participate even
>> when they can't swollow the whole pill; or choose to provide the
>> resource thats cheap for them to provide.  In particular, if there is
>> only two kinds of full nodes-- archive and pruned; then the archive
>> nodes take both a huge disk and bandwidth cost; where as if there are
>> fractional then archives take low(er) bandwidth unless the fractionals
>> get DOS attacked.
>>
>
>
>
> --
> Jeff Garzik
> Bitcoin core developer and open source evangelist
> BitPay, Inc.      https://bitpay.com/
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150512/01931028/attachment.html>

From gmaxwell at gmail.com  Tue May 12 20:47:41 2015
From: gmaxwell at gmail.com (Gregory Maxwell)
Date: Tue, 12 May 2015 20:47:41 +0000
Subject: [Bitcoin-development] Proposed additional options for pruned
	nodes
In-Reply-To: <CAJHLa0O3fgmg4AFAM9+4RRkhSo8ekATs2Ks+Ry7ooQafjQ-4qw@mail.gmail.com>
References: <CANJO25J1WRHtfQLVXUB2s_sjj39pTPWmixAcXNJ3t-5os8RPmQ@mail.gmail.com>
	<CANJO25JTtfmfsOQYOzJeksJn3CoKE3W8iLGsRko-_xd4XhB3ZA@mail.gmail.com>
	<CAJHLa0O5OxaX5g3u=dnCY6Lz_gK3QZgQEPNcWNVRD4JziwAmvg@mail.gmail.com>
	<20150512171640.GA32606@savin.petertodd.org>
	<CAE-z3OV3VdSoiTSfASwYHr1CjZSqio303sqGq_1Y9yaYgov2sw@mail.gmail.com>
	<CAAS2fgRzGkcJbWbJmFN2-NSJGUcLdPKp0q7FjM0x7WDvHoRq=g@mail.gmail.com>
	<CANJO25+qURmDzsMgnm7+tsw7icFO--gWhmKmQPuNQCoh_R2big@mail.gmail.com>
	<CAJHLa0PDbxuqRHuGNhsyvLpAaDq=ZHSg_u-Sb7FqNVnYrhFkFg@mail.gmail.com>
	<CAAS2fgTCMeNdcmMxURxaoAJn8=XZnTP8Gp6PbRk5w7KXAZ8t3g@mail.gmail.com>
	<CAJHLa0O3fgmg4AFAM9+4RRkhSo8ekATs2Ks+Ry7ooQafjQ-4qw@mail.gmail.com>
Message-ID: <CAAS2fgQZ9xNJ-Bz=k9ztHwqeOjjFbPsGAzReHmnUPYe0RYu+FA@mail.gmail.com>

On Tue, May 12, 2015 at 8:10 PM, Jeff Garzik <jgarzik at bitpay.com> wrote:
> True.  Part of the issue rests on the block sync horizon/cliff.  There is a
> value X which is the average number of blocks the 90th percentile of nodes
> need in order to sync.  It is sufficient for the [semi-]pruned nodes to keep
> X blocks, after which nodes must fall back to archive nodes for older data.


Prior discussion had things like "the definition of pruned means you
have and will serve at least the last 288 from your tip" (which is
what I put in the pruned service bip text); and another flag for "I
have at least the last 2016".  (2016 should be reevaluated-- it was
just a round number near where sipa's old data showed the fetch
probability flatlined.

But that data was old,  but what it showed that the probability of a
block being fetched vs depth looked like a exponential drop-off (I
think with a 50% at 3-ish days); plus a constant low probability.
Which is probably what we should have expected.

> There was even a more radical suggestion years ago - refuse to sync if too
> old (>2 weeks?), and force the user to download ancient data via torrent.

I'm not fond of this; it makes the system dependent on centralized
services (e.g. trackers and sources of torrents). A torrent also
cannot very efficiently handle fractional copies; cannot efficiently
grow over time. Bitcoin should be complete-- plus, many nodes already
have the data.



From pete at petertodd.org  Tue May 12 21:01:25 2015
From: pete at petertodd.org (Peter Todd)
Date: Tue, 12 May 2015 17:01:25 -0400
Subject: [Bitcoin-development] CLTV opcode allocation; long-term plans?
In-Reply-To: <201505122038.28831.luke@dashjr.org>
References: <20150504050715.GA18856@savin.petertodd.org>
	<CABm2gDqVu9OqNpOgCa6hMw3CXp7ePWTaAGPtMq4T9rG658K=ow@mail.gmail.com>
	<CADJgMzv1NdoXKDScQ1+OycijzME=W2YSut3GMF=EEuKQf6VeUg@mail.gmail.com>
	<201505122038.28831.luke@dashjr.org>
Message-ID: <20150512210125.GA5902@muck>

On Tue, May 12, 2015 at 08:38:27PM +0000, Luke Dashjr wrote:
> It should actually be straightforward to softfork RCLTV in as a negative CLTV.
> All nLockTime are >= any negative number, so a negative number makes CLTV a 
> no-op always. Therefore, it is clean to define negative numbers as relative 
> later. It's also somewhat obvious to developers, since negative numbers often 
> imply an offset (eg, negative list indices in Python).

Doing this makes handling the year 2038 problem a good deal more
complex.

The CLTV codebase specifically fails on negative arguments to avoid any
ambiguity or implementation differences here.

-- 
'peter'[:-1]@petertodd.org
00000000000000000e7980aab9c096c46e7f34c43a661c5cb2ea71525ebb8af7
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150512/40ff0fa9/attachment.sig>

From kiwigb at yahoo.com  Tue May 12 21:30:03 2015
From: kiwigb at yahoo.com (gb)
Date: Wed, 13 May 2015 09:30:03 +1200
Subject: [Bitcoin-development] [Bulk] Re: Proposed additional options
 for pruned nodes
In-Reply-To: <CANJO25JqoidjKEmi1wv-ACBm6eB-B=g3r5kurLK5O0Gx5orJmA@mail.gmail.com>
References: <CANJO25J1WRHtfQLVXUB2s_sjj39pTPWmixAcXNJ3t-5os8RPmQ@mail.gmail.com>
	<CANJO25JTtfmfsOQYOzJeksJn3CoKE3W8iLGsRko-_xd4XhB3ZA@mail.gmail.com>
	<CAJHLa0O5OxaX5g3u=dnCY6Lz_gK3QZgQEPNcWNVRD4JziwAmvg@mail.gmail.com>
	<20150512171640.GA32606@savin.petertodd.org>
	<CAE-z3OV3VdSoiTSfASwYHr1CjZSqio303sqGq_1Y9yaYgov2sw@mail.gmail.com>
	<CAAS2fgRzGkcJbWbJmFN2-NSJGUcLdPKp0q7FjM0x7WDvHoRq=g@mail.gmail.com>
	<CANJO25+qURmDzsMgnm7+tsw7icFO--gWhmKmQPuNQCoh_R2big@mail.gmail.com>
	<CAJHLa0PDbxuqRHuGNhsyvLpAaDq=ZHSg_u-Sb7FqNVnYrhFkFg@mail.gmail.com>
	<CANJO25JqoidjKEmi1wv-ACBm6eB-B=g3r5kurLK5O0Gx5orJmA@mail.gmail.com>
Message-ID: <1431466203.2049.15.camel@yahoo.com>

This seems like a good place to add in an idea I had about
partially-connected nodes that are able to throttle bandwidth demands.
While we will be having partial-blockchain nodes with a spectrum of
storage options the requirement to be connected is somewhat binary, I
think many users manually throttle by turning nodes on/off already with
a minimum to just keep the chain up to date. A throttling option would
leverage on bitcoin's asychronous design to reduce bandwidth demands for
weaker nodes.

So throttling to allow for a spectrum of bandwidth connectivity:

1) an option for the user -throttle=XXX that would allow the user to
specify a desirable total bandwidth XXX in Gbytes/day the bitcoin client
can use.

2) the client reduces the number of continuous connections, transaction
or block relaying to achieve the desired throttling rate

3) it could do this by being partially connected throughout the duty
cycle or cycling the node on/off for a percentage of a 24(?) hr period

4) have an auto setting where some smart traffic management 'just takes
care of it' and manual settings that can be user configured

5) reduces minimum requirement for any 24(?) hr period it has received a
full copy of all blocks to remain fully-validating

Not sure if anyone has bought such an idea forward or if there are
obvious holes, so pre-emptive apologies for time-wasting if so.

On Tue, 2015-05-12 at 15:43 -0400, gabe appleton wrote:
> Yet this holds true in our current assumptions of the network as well:
> that it will become a collection of pruned nodes with a few storage
> nodes. 
> 
> A hybrid option makes this better, because it spreads the risk, rather
> than concentrating it in full nodes. 
> 
> On May 12, 2015 3:38 PM, "Jeff Garzik" <jgarzik at bitpay.com> wrote:
>         One general problem is that security is weakened when an
>         attacker can DoS a small part of the chain by DoS'ing a small
>         number of nodes - yet the impact is a network-wide DoS because
>         nobody can complete a sync.
>         
>         
>         
>         On Tue, May 12, 2015 at 12:24 PM, gabe appleton
>         <gappleto97 at gmail.com> wrote:
>                 0, 1, 3, 4, 5, 6 can be solved by looking at chunks
>                 chronologically. Ie, give the signed (by sender) hash
>                 of the first and last block in your range. This is
>                 less data dense than the idea above, but it might work
>                 better. 
>                 
>                 That said, this is likely a less secure way to do it.
>                 To improve upon that, a node could request a block of
>                 random height within that range and verify it, but
>                 that violates point 2. And the scheme in itself
>                 definitely violates point 7.
>                 
>                 On May 12, 2015 3:07 PM, "Gregory Maxwell"
>                 <gmaxwell at gmail.com> wrote:
>                         It's a little frustrating to see this just
>                         repeated without even
>                         paying attention to the desirable
>                         characteristics from the prior
>                         discussions.
>                         
>                         Summarizing from memory:
>                         
>                         (0) Block coverage should have locality;
>                         historical blocks are
>                         (almost) always needed in contiguous ranges.
>                          Having random peers
>                         with totally random blocks would be horrific
>                         for performance; as you'd
>                         have to hunt down a working peer and make a
>                         connection for each block
>                         with high probability.
>                         
>                         (1) Block storage on nodes with a fraction of
>                         the history should not
>                         depend on believing random peers; because
>                         listening to peers can
>                         easily create attacks (e.g. someone could
>                         break the network; by
>                         convincing nodes to become unbalanced) and not
>                         useful-- it's not like
>                         the blockchain is substantially different for
>                         anyone; if you're to the
>                         point of needing to know coverage to fill then
>                         something is wrong.
>                         Gaps would be handled by archive nodes, so
>                         there is no reason to
>                         increase vulnerability by doing anything but
>                         behaving uniformly.
>                         
>                         (2) The decision to contact a node should need
>                         O(1) communications,
>                         not just because of the delay of chasing
>                         around just to find who has
>                         someone; but because that chasing process
>                         usually makes the process
>                         _highly_ sybil vulnerable.
>                         
>                         (3) The expression of what blocks a node has
>                         should be compact (e.g.
>                         not a dense list of blocks) so it can be
>                         rumored efficiently.
>                         
>                         (4) Figuring out what block (ranges) a peer
>                         has given should be
>                         computationally efficient.
>                         
>                         (5) The communication about what blocks a node
>                         has should be compact.
>                         
>                         (6) The coverage created by the network should
>                         be uniform, and should
>                         remain uniform as the blockchain grows;
>                         ideally it you shouldn't need
>                         to update your state to know what blocks a
>                         peer will store in the
>                         future, assuming that it doesn't change the
>                         amount of data its
>                         planning to use. (What Tier Nolan proposes
>                         sounds like it fails this
>                         point)
>                         
>                         (7) Growth of the blockchain shouldn't cause
>                         much (or any) need to
>                         refetch old blocks.
>                         
>                         I've previously proposed schemes which come
>                         close but fail one of the above.
>                         
>                         (e.g. a scheme based on reservoir sampling
>                         that gives uniform
>                         selection of contiguous ranges, communicating
>                         only 64 bits of data to
>                         know what blocks a node claims to have,
>                         remaining totally uniform as
>                         the chain grows, without any need to refetch
>                         -- but needs O(height)
>                         work to figure out what blocks a peer has from
>                         the data it
>                         communicated.;   or another scheme based on
>                         consistent hashes that has
>                         log(height) computation; but sometimes may
>                         result in a node needing to
>                         go refetch an old block range it previously
>                         didn't store-- creating
>                         re-balancing traffic.)
>                         
>                         So far something that meets all those criteria
>                         (and/or whatever ones
>                         I'm not remembering) has not been discovered;
>                         but I don't really think
>                         much time has been spent on it. I think its
>                         very likely possible.
>                         
>                         ------------------------------------------------------------------------------
>                         One dashboard for servers and applications
>                         across Physical-Virtual-Cloud
>                         Widest out-of-the-box monitoring support with
>                         50+ applications
>                         Performance metrics, stats and reports that
>                         give you Actionable Insights
>                         Deep dive visibility with transaction tracing
>                         using APM Insight.
>                         http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>                         _______________________________________________
>                         Bitcoin-development mailing list
>                         Bitcoin-development at lists.sourceforge.net
>                         https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>                 
>                 ------------------------------------------------------------------------------
>                 One dashboard for servers and applications across
>                 Physical-Virtual-Cloud
>                 Widest out-of-the-box monitoring support with 50+
>                 applications
>                 Performance metrics, stats and reports that give you
>                 Actionable Insights
>                 Deep dive visibility with transaction tracing using
>                 APM Insight.
>                 http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>                 _______________________________________________
>                 Bitcoin-development mailing list
>                 Bitcoin-development at lists.sourceforge.net
>                 https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>                 
>         
>         
>         
>         
>         -- 
>         Jeff Garzik
>         Bitcoin core developer and open source evangelist
>         BitPay, Inc.      https://bitpay.com/
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud 
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________ Bitcoin-development mailing list Bitcoin-development at lists.sourceforge.net https://lists.sourceforge.net/lists/listinfo/bitcoin-development





From adam at signal11.com  Tue May 12 21:17:14 2015
From: adam at signal11.com (Adam Weiss)
Date: Tue, 12 May 2015 17:17:14 -0400
Subject: [Bitcoin-development] Fwd: Proposed additional options for pruned
	nodes
In-Reply-To: <CAJHLa0MYSpVBD4VE65LVbADb2daOvE=N83G8F_zDSHy3AQ5DAQ@mail.gmail.com>
References: <CANJO25J1WRHtfQLVXUB2s_sjj39pTPWmixAcXNJ3t-5os8RPmQ@mail.gmail.com>
	<CANJO25JTtfmfsOQYOzJeksJn3CoKE3W8iLGsRko-_xd4XhB3ZA@mail.gmail.com>
	<CAJHLa0O5OxaX5g3u=dnCY6Lz_gK3QZgQEPNcWNVRD4JziwAmvg@mail.gmail.com>
	<20150512171640.GA32606@savin.petertodd.org>
	<CAE-z3OV3VdSoiTSfASwYHr1CjZSqio303sqGq_1Y9yaYgov2sw@mail.gmail.com>
	<CAAS2fgRzGkcJbWbJmFN2-NSJGUcLdPKp0q7FjM0x7WDvHoRq=g@mail.gmail.com>
	<CANJO25+qURmDzsMgnm7+tsw7icFO--gWhmKmQPuNQCoh_R2big@mail.gmail.com>
	<CAJHLa0PDbxuqRHuGNhsyvLpAaDq=ZHSg_u-Sb7FqNVnYrhFkFg@mail.gmail.com>
	<CAFVoEQTdmCSRAy3u26q5oHdfvFEytZDBfQb_fs_qttK15fiRmg@mail.gmail.com>
	<CAJHLa0OxxxiVd3JOp8SDvbF8dHj6KHdUNGb9L_GvTe93z3Z8mg@mail.gmail.com>
	<CAJHLa0MYSpVBD4VE65LVbADb2daOvE=N83G8F_zDSHy3AQ5DAQ@mail.gmail.com>
Message-ID: <CAFVoEQTEdWoqtNLebWtFjUQdGuev=Zs0TWGCj5sRZ2K35ZK4EQ@mail.gmail.com>

FYI on behalf of jgarzik...

---------- Forwarded message ----------
From: Jeff Garzik <jgarzik at bitpay.com>
Date: Tue, May 12, 2015 at 4:48 PM
Subject: Re: [Bitcoin-development] Proposed additional options for pruned
nodes
To: Adam Weiss <adam at signal11.com>


Maybe you could forward my response to the list as an FYI?


On Tue, May 12, 2015 at 12:43 PM, Jeff Garzik <jgarzik at bitpay.com> wrote:

> You are the 12th person to report this.  It is SF, not bitpay, rewriting
> email headers and breaking authentication.
>
>
> On Tue, May 12, 2015 at 12:40 PM, Adam Weiss <adam at signal11.com> wrote:
>
>> fyi, your email to bitcoin-dev is still generating google spam warnings...
>>
>> --adam
>>
>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150512/f8a85601/attachment.html>

From pedro at worcel.com  Tue May 12 21:24:41 2015
From: pedro at worcel.com (Pedro Worcel)
Date: Wed, 13 May 2015 09:24:41 +1200
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <CABsx9T3AxM3et7hgXx3+Rn3BvhQkF-Cn797sHcyztkMpD1UQmA@mail.gmail.com>
References: <5550D8BE.6070207@electrum.org>
	<ce3d34c92efd1cf57326e4679550944e@national.shitposting.agency>
	<CABsx9T1VgxEJWxrYTs+2hXGnGrSLGJ6mVcAexjXLvK7Vu+e3EA@mail.gmail.com>
	<5551F376.4050008@electrum.org>
	<CABsx9T1h7p3hDr7ty43uxsYs-oNRpndzg=dowST2tXtogxRm2g@mail.gmail.com>
	<555210AF.3090705@electrum.org>
	<CABsx9T3AxM3et7hgXx3+Rn3BvhQkF-Cn797sHcyztkMpD1UQmA@mail.gmail.com>
Message-ID: <CAPS+U98sh6BmuGHWOffrmTpaM3CNfhBUWdmgACb9++jU6M1fmQ@mail.gmail.com>

Disclaimer: I don't know anything about Bitcoin.

> ?2) Proof-of-idle supported (I wish Tadge Dryja would publish his
proof-of-idle idea....)
> 3) Fees purely as transaction-spam-prevention measure, chain security via
alternative consensus algorithm (in this scenario there is very little
mining).

I don't understand why you would casually mention moving away from Proof of
Work, I thought that was the big breakthrough that made Bitcoin possible at
all?

Thanks,
Pedro

2015-05-13 4:10 GMT+12:00 Gavin Andresen <gavinandresen at gmail.com>:

> Added back the list, I didn't mean to reply privately:
>
> Fair enough, I'll try to find time in the next month or three to write up
> four plausible future scenarios for how mining incentives might work:
>
> 1) Fee-supported with very large blocks containing lots of tiny-fee
> transactions
> ??
> 2) Proof-of-idle supported (I wish Tadge Dryja would publish his
> proof-of-idle idea....)
> 3) Fees purely as transaction-spam-prevention measure, chain security via
> alternative consensus algorithm (in this scenario there is very little
> mining).
> 4) Fee supported with small blocks containing high-fee transactions moving
> coins to/from sidechains.
>
> Would that be helpful, or do you have some reason for thinking that we
> should pick just one and focus all of our efforts on making that one
> scenario happen?
>
> I always think it is better, when possible, not to "bet on one horse."
>
>
> On Tue, May 12, 2015 at 10:39 AM, Thomas Voegtlin <thomasv at electrum.org>
> wrote:
>
>> Le 12/05/2015 15:44, Gavin Andresen a ?crit :
>> > Ok, here's my scenario:
>> >
>> > https://blog.bitcoinfoundation.org/a-scalability-roadmap/
>> >
>> > It might be wrong. I welcome other people to present their road maps.
>> >
>>
>> [answering to you only because you answered to me and not to the list;
>> feel free to repost this to the list though]
>>
>> Yes, that's exactly the kind of roadmap I am asking for. But your blog
>> post does not say anything about long term mining incentives, it only
>> talks about scalability. My point is that we need the same kind of thing
>> for miners incentives.
>>
>
>
>
> --
> --
> Gavin Andresen
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/018ff86d/attachment.html>

From tier.nolan at gmail.com  Tue May 12 22:00:33 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Tue, 12 May 2015 23:00:33 +0100
Subject: [Bitcoin-development] Proposed additional options for pruned
	nodes
In-Reply-To: <CAAS2fgRzGkcJbWbJmFN2-NSJGUcLdPKp0q7FjM0x7WDvHoRq=g@mail.gmail.com>
References: <CANJO25J1WRHtfQLVXUB2s_sjj39pTPWmixAcXNJ3t-5os8RPmQ@mail.gmail.com>
	<CANJO25JTtfmfsOQYOzJeksJn3CoKE3W8iLGsRko-_xd4XhB3ZA@mail.gmail.com>
	<CAJHLa0O5OxaX5g3u=dnCY6Lz_gK3QZgQEPNcWNVRD4JziwAmvg@mail.gmail.com>
	<20150512171640.GA32606@savin.petertodd.org>
	<CAE-z3OV3VdSoiTSfASwYHr1CjZSqio303sqGq_1Y9yaYgov2sw@mail.gmail.com>
	<CAAS2fgRzGkcJbWbJmFN2-NSJGUcLdPKp0q7FjM0x7WDvHoRq=g@mail.gmail.com>
Message-ID: <CAE-z3OWR72Og78RLuXEPjzRR8gCEjAuFk2nq-JzDtt_2pKSmHQ@mail.gmail.com>

On Tue, May 12, 2015 at 8:03 PM, Gregory Maxwell <gmaxwell at gmail.com> wrote:

>
> (0) Block coverage should have locality; historical blocks are
> (almost) always needed in contiguous ranges.   Having random peers
> with totally random blocks would be horrific for performance; as you'd
> have to hunt down a working peer and make a connection for each block
> with high probability.
>
> (1) Block storage on nodes with a fraction of the history should not
> depend on believing random peers; because listening to peers can
> easily create attacks (e.g. someone could break the network; by
> convincing nodes to become unbalanced) and not useful-- it's not like
> the blockchain is substantially different for anyone; if you're to the
> point of needing to know coverage to fill then something is wrong.
> Gaps would be handled by archive nodes, so there is no reason to
> increase vulnerability by doing anything but behaving uniformly.
>
> (2) The decision to contact a node should need O(1) communications,
> not just because of the delay of chasing around just to find who has
> someone; but because that chasing process usually makes the process
> _highly_ sybil vulnerable.
>
> (3) The expression of what blocks a node has should be compact (e.g.
> not a dense list of blocks) so it can be rumored efficiently.
>
> (4) Figuring out what block (ranges) a peer has given should be
> computationally efficient.
>
> (5) The communication about what blocks a node has should be compact.
>
> (6) The coverage created by the network should be uniform, and should
> remain uniform as the blockchain grows; ideally it you shouldn't need
> to update your state to know what blocks a peer will store in the
> future, assuming that it doesn't change the amount of data its
> planning to use. (What Tier Nolan proposes sounds like it fails this
> point)
>
> (7) Growth of the blockchain shouldn't cause much (or any) need to
> refetch old blocks.
>

M = 1,000,000
N = number of "starts"

S(0) = hash(seed) mod M
...
S(n) = hash(S(n-1)) mod M

This generates a sequence of start points.  If the start point is less than
the block height, then it counts as a hit.

The node stores the 50MB of data starting at the block at height S(n).

As the blockchain increases in size, new starts will be less than the block
height.  This means some other runs would be deleted.

A weakness is that it is random with regards to block heights.  Tiny blocks
have the same priority as larger blocks.

0) Blocks are local, in 50MB runs
1) Agreed, nodes should download headers-first (or some other compact way
of finding the highest POW chain)
2) M could be fixed, N and the seed are all that is required.  The seed
doesn't have to be that large.  If 1% of the blockchain is stored, then 16
bits should be sufficient so that every block is covered by seeds.
3) N is likely to be less than 2 bytes and the seed can be 2 bytes
4) A 1% cover of 50GB of blockchain would have 10 starts @ 50MB per run.
That is 10 hashes.  They don't even necessarily need to be crypt hashes
5) Isn't this the same as 3?
6) Every block has the same odds of being included.  There inherently needs
to be an update when a node deletes some info due to exceeding its cap.  N
can be dropped one run at a time.
7) When new starts drop below the tip height, N can be decremented and that
one run is deleted.

There would need to be a special rule to ensure the low height blocks are
covered.  Nodes should keep the first 50MB of blocks with some probability
(10%?)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150512/27f2d685/attachment.html>

From gappleto97 at gmail.com  Tue May 12 22:09:44 2015
From: gappleto97 at gmail.com (gabe appleton)
Date: Tue, 12 May 2015 18:09:44 -0400
Subject: [Bitcoin-development] Proposed additional options for pruned
	nodes
In-Reply-To: <CAE-z3OWR72Og78RLuXEPjzRR8gCEjAuFk2nq-JzDtt_2pKSmHQ@mail.gmail.com>
References: <CANJO25J1WRHtfQLVXUB2s_sjj39pTPWmixAcXNJ3t-5os8RPmQ@mail.gmail.com>
	<CANJO25JTtfmfsOQYOzJeksJn3CoKE3W8iLGsRko-_xd4XhB3ZA@mail.gmail.com>
	<CAJHLa0O5OxaX5g3u=dnCY6Lz_gK3QZgQEPNcWNVRD4JziwAmvg@mail.gmail.com>
	<20150512171640.GA32606@savin.petertodd.org>
	<CAE-z3OV3VdSoiTSfASwYHr1CjZSqio303sqGq_1Y9yaYgov2sw@mail.gmail.com>
	<CAAS2fgRzGkcJbWbJmFN2-NSJGUcLdPKp0q7FjM0x7WDvHoRq=g@mail.gmail.com>
	<CAE-z3OWR72Og78RLuXEPjzRR8gCEjAuFk2nq-JzDtt_2pKSmHQ@mail.gmail.com>
Message-ID: <CANJO25Ls2Hbv=GYPBq85M-3=Jna5x4=BYE67km7SbaJg3dgFdA@mail.gmail.com>

This is exactly the sort of solution I was hoping for. It seems this is the
minimal modification to make it work, and, if someone was willing to work
with me, I would love to help implement this.

My only concern would be if the - - max-size flag is not included than this
delivers significantly less benefit to the end user. Still a good chunk,
but possibly not enough.
On May 12, 2015 6:03 PM, "Tier Nolan" <tier.nolan at gmail.com> wrote:

>
>
> On Tue, May 12, 2015 at 8:03 PM, Gregory Maxwell <gmaxwell at gmail.com>
> wrote:
>
>>
>> (0) Block coverage should have locality; historical blocks are
>> (almost) always needed in contiguous ranges.   Having random peers
>> with totally random blocks would be horrific for performance; as you'd
>> have to hunt down a working peer and make a connection for each block
>> with high probability.
>>
>> (1) Block storage on nodes with a fraction of the history should not
>> depend on believing random peers; because listening to peers can
>> easily create attacks (e.g. someone could break the network; by
>> convincing nodes to become unbalanced) and not useful-- it's not like
>> the blockchain is substantially different for anyone; if you're to the
>> point of needing to know coverage to fill then something is wrong.
>> Gaps would be handled by archive nodes, so there is no reason to
>> increase vulnerability by doing anything but behaving uniformly.
>>
>> (2) The decision to contact a node should need O(1) communications,
>> not just because of the delay of chasing around just to find who has
>> someone; but because that chasing process usually makes the process
>> _highly_ sybil vulnerable.
>>
>> (3) The expression of what blocks a node has should be compact (e.g.
>> not a dense list of blocks) so it can be rumored efficiently.
>>
>> (4) Figuring out what block (ranges) a peer has given should be
>> computationally efficient.
>>
>> (5) The communication about what blocks a node has should be compact.
>>
>> (6) The coverage created by the network should be uniform, and should
>> remain uniform as the blockchain grows; ideally it you shouldn't need
>> to update your state to know what blocks a peer will store in the
>> future, assuming that it doesn't change the amount of data its
>> planning to use. (What Tier Nolan proposes sounds like it fails this
>> point)
>>
>> (7) Growth of the blockchain shouldn't cause much (or any) need to
>> refetch old blocks.
>>
>
> M = 1,000,000
> N = number of "starts"
>
> S(0) = hash(seed) mod M
> ...
> S(n) = hash(S(n-1)) mod M
>
> This generates a sequence of start points.  If the start point is less
> than the block height, then it counts as a hit.
>
> The node stores the 50MB of data starting at the block at height S(n).
>
> As the blockchain increases in size, new starts will be less than the
> block height.  This means some other runs would be deleted.
>
> A weakness is that it is random with regards to block heights.  Tiny
> blocks have the same priority as larger blocks.
>
> 0) Blocks are local, in 50MB runs
> 1) Agreed, nodes should download headers-first (or some other compact way
> of finding the highest POW chain)
> 2) M could be fixed, N and the seed are all that is required.  The seed
> doesn't have to be that large.  If 1% of the blockchain is stored, then 16
> bits should be sufficient so that every block is covered by seeds.
> 3) N is likely to be less than 2 bytes and the seed can be 2 bytes
> 4) A 1% cover of 50GB of blockchain would have 10 starts @ 50MB per run.
> That is 10 hashes.  They don't even necessarily need to be crypt hashes
> 5) Isn't this the same as 3?
> 6) Every block has the same odds of being included.  There inherently
> needs to be an update when a node deletes some info due to exceeding its
> cap.  N can be dropped one run at a time.
> 7) When new starts drop below the tip height, N can be decremented and
> that one run is deleted.
>
> There would need to be a special rule to ensure the low height blocks are
> covered.  Nodes should keep the first 50MB of blocks with some probability
> (10%?)
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150512/97fc216a/attachment.html>

From adam at cypherspace.org  Tue May 12 23:48:06 2015
From: adam at cypherspace.org (Adam Back)
Date: Tue, 12 May 2015 16:48:06 -0700
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <CAPS+U98sh6BmuGHWOffrmTpaM3CNfhBUWdmgACb9++jU6M1fmQ@mail.gmail.com>
References: <5550D8BE.6070207@electrum.org>
	<ce3d34c92efd1cf57326e4679550944e@national.shitposting.agency>
	<CABsx9T1VgxEJWxrYTs+2hXGnGrSLGJ6mVcAexjXLvK7Vu+e3EA@mail.gmail.com>
	<5551F376.4050008@electrum.org>
	<CABsx9T1h7p3hDr7ty43uxsYs-oNRpndzg=dowST2tXtogxRm2g@mail.gmail.com>
	<555210AF.3090705@electrum.org>
	<CABsx9T3AxM3et7hgXx3+Rn3BvhQkF-Cn797sHcyztkMpD1UQmA@mail.gmail.com>
	<CAPS+U98sh6BmuGHWOffrmTpaM3CNfhBUWdmgACb9++jU6M1fmQ@mail.gmail.com>
Message-ID: <CALqxMTGebNMARgps9mqxDSOw0cX9aeZZim82g8a4vE6sCPHq-g@mail.gmail.com>

I think its fair to say no one knows how to make a consensus that
works in a decentralised fashion that doesnt weaken the bitcoin
security model without proof-of-work for now.

I am presuming Gavin is just saying in the context of not pre-judging
the future that maybe in the far future another innovation might be
found (or alternatively maybe its not mathematically possible).

Towards that it would be useful to try further to prove this one way
or another (prove that proof of stake cant work if that is generically
mathematically provable).

Adam

On 12 May 2015 at 14:24, Pedro Worcel <pedro at worcel.com> wrote:
> Disclaimer: I don't know anything about Bitcoin.
>
>> 2) Proof-of-idle supported (I wish Tadge Dryja would publish his
>> proof-of-idle idea....)
>> 3) Fees purely as transaction-spam-prevention measure, chain security via
>> alternative consensus algorithm (in this scenario there is very little
>> mining).
>
> I don't understand why you would casually mention moving away from Proof of
> Work, I thought that was the big breakthrough that made Bitcoin possible at
> all?
>
> Thanks,
> Pedro
>
> 2015-05-13 4:10 GMT+12:00 Gavin Andresen <gavinandresen at gmail.com>:
>>
>> Added back the list, I didn't mean to reply privately:
>>
>> Fair enough, I'll try to find time in the next month or three to write up
>> four plausible future scenarios for how mining incentives might work:
>>
>> 1) Fee-supported with very large blocks containing lots of tiny-fee
>> transactions
>> 2) Proof-of-idle supported (I wish Tadge Dryja would publish his
>> proof-of-idle idea....)
>> 3) Fees purely as transaction-spam-prevention measure, chain security via
>> alternative consensus algorithm (in this scenario there is very little
>> mining).
>> 4) Fee supported with small blocks containing high-fee transactions moving
>> coins to/from sidechains.
>>
>> Would that be helpful, or do you have some reason for thinking that we
>> should pick just one and focus all of our efforts on making that one
>> scenario happen?
>>
>> I always think it is better, when possible, not to "bet on one horse."
>>
>>
>> On Tue, May 12, 2015 at 10:39 AM, Thomas Voegtlin <thomasv at electrum.org>
>> wrote:
>>>
>>> Le 12/05/2015 15:44, Gavin Andresen a ?crit :
>>> > Ok, here's my scenario:
>>> >
>>> > https://blog.bitcoinfoundation.org/a-scalability-roadmap/
>>> >
>>> > It might be wrong. I welcome other people to present their road maps.
>>> >
>>>
>>> [answering to you only because you answered to me and not to the list;
>>> feel free to repost this to the list though]
>>>
>>> Yes, that's exactly the kind of roadmap I am asking for. But your blog
>>> post does not say anything about long term mining incentives, it only
>>> talks about scalability. My point is that we need the same kind of thing
>>> for miners incentives.
>>
>>
>>
>>
>> --
>> --
>> Gavin Andresen
>>
>>
>> ------------------------------------------------------------------------------
>> One dashboard for servers and applications across Physical-Virtual-Cloud
>> Widest out-of-the-box monitoring support with 50+ applications
>> Performance metrics, stats and reports that give you Actionable Insights
>> Deep dive visibility with transaction tracing using APM Insight.
>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>



From jtimon at jtimon.cc  Wed May 13 00:38:44 2015
From: jtimon at jtimon.cc (=?UTF-8?B?Sm9yZ2UgVGltw7Nu?=)
Date: Wed, 13 May 2015 02:38:44 +0200
Subject: [Bitcoin-development] CLTV opcode allocation; long-term plans?
In-Reply-To: <20150512210125.GA5902@muck>
References: <20150504050715.GA18856@savin.petertodd.org>
	<CABm2gDqVu9OqNpOgCa6hMw3CXp7ePWTaAGPtMq4T9rG658K=ow@mail.gmail.com>
	<CADJgMzv1NdoXKDScQ1+OycijzME=W2YSut3GMF=EEuKQf6VeUg@mail.gmail.com>
	<201505122038.28831.luke@dashjr.org> <20150512210125.GA5902@muck>
Message-ID: <CABm2gDrMUJq8RiXw5U0gNnfJEzXG4pNxk5eOw=L7NUtcpj3sPg@mail.gmail.com>

I like the reuse with negative numbers more than the current proposal
because it doesn't imply bigger scripts. If all problems that may
arise can be solved, that is.
If we went that route, we would start with the initial CLTV too.
But I don't see many strong arguments in favor of using the current
trick later when we're actually running out of opcodes, just that
"CLTV and RCLTV/op_maturity are semantically related". How
semantically related depends on the final form of RCLTV/op_maturity,
but I don't think anybody wants to block CLTV until RCLTV is ready.

So we could just deploy the initial CLTV (#6124) now and then decide
whether we want to reuse it with negatives for RCLTV or if we use an
independent op.
Can the people that don't like that plan give stronger arguments in
favor of the parametrized version?

I've missed IRC conversations, so I may be missing something...


On Tue, May 12, 2015 at 11:01 PM, Peter Todd <pete at petertodd.org> wrote:
> On Tue, May 12, 2015 at 08:38:27PM +0000, Luke Dashjr wrote:
>> It should actually be straightforward to softfork RCLTV in as a negative CLTV.
>> All nLockTime are >= any negative number, so a negative number makes CLTV a
>> no-op always. Therefore, it is clean to define negative numbers as relative
>> later. It's also somewhat obvious to developers, since negative numbers often
>> imply an offset (eg, negative list indices in Python).
>
> Doing this makes handling the year 2038 problem a good deal more
> complex.
>
> The CLTV codebase specifically fails on negative arguments to avoid any
> ambiguity or implementation differences here.
>
> --
> 'peter'[:-1]@petertodd.org
> 00000000000000000e7980aab9c096c46e7f34c43a661c5cb2ea71525ebb8af7
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>



From d at domob.eu  Wed May 13 05:19:54 2015
From: d at domob.eu (Daniel Kraft)
Date: Wed, 13 May 2015 07:19:54 +0200
Subject: [Bitcoin-development] Proposed additional options for pruned
 nodes
In-Reply-To: <CAAS2fgRzGkcJbWbJmFN2-NSJGUcLdPKp0q7FjM0x7WDvHoRq=g@mail.gmail.com>
References: <CANJO25J1WRHtfQLVXUB2s_sjj39pTPWmixAcXNJ3t-5os8RPmQ@mail.gmail.com>	<CANJO25JTtfmfsOQYOzJeksJn3CoKE3W8iLGsRko-_xd4XhB3ZA@mail.gmail.com>	<CAJHLa0O5OxaX5g3u=dnCY6Lz_gK3QZgQEPNcWNVRD4JziwAmvg@mail.gmail.com>	<20150512171640.GA32606@savin.petertodd.org>	<CAE-z3OV3VdSoiTSfASwYHr1CjZSqio303sqGq_1Y9yaYgov2sw@mail.gmail.com>
	<CAAS2fgRzGkcJbWbJmFN2-NSJGUcLdPKp0q7FjM0x7WDvHoRq=g@mail.gmail.com>
Message-ID: <5552DEFA.4080508@domob.eu>

Hi all!

On 2015-05-12 21:03, Gregory Maxwell wrote:
> Summarizing from memory:

In the context of this discussion, let me also restate an idea I've
proposed in Bitcointalk for this.  It is probably not perfect and could
surely be adapted (I'm interested in that), but I think it meets
most/all of the criteria stated below.  It is similar to the idea with
"start points", but gives O(log height) instead of O(height) for
determining which blocks a node has.

Let me for simplicity assume that the node wants to store 50% of all
blocks.  It is straight-forward to extend the scheme so that this is
configurable:

1) Create some kind of "seed" that can be compact and will be sent to
other peers to define which blocks the node has.  Use it to initialise a
PRNG of some sort.

2) Divide the range of all blocks into intervals with exponentially
growing size.  I. e., something like this:

1, 1, 2, 2, 4, 4, 8, 8, 16, 16, ...

With this, only O(log height) intervals are necessary to cover height
blocks.

3) Using the PRNG, *one* of the two intervals of each length is
selected.  The node stores these blocks and discards the others.
(Possibly keeping the last 200 or 2,016 or whatever blocks additionally.)

> (0) Block coverage should have locality; historical blocks are
> (almost) always needed in contiguous ranges.   Having random peers
> with totally random blocks would be horrific for performance; as you'd
> have to hunt down a working peer and make a connection for each block
> with high probability.

You get contiguous block ranges (with at most O(log height) "breaks").
Also ranges of newer blocks are longer, which may be an advantage if
those blocks are needed more often.

> (1) Block storage on nodes with a fraction of the history should not
> depend on believing random peers; because listening to peers can
> easily create attacks (e.g. someone could break the network; by
> convincing nodes to become unbalanced) and not useful-- it's not like
> the blockchain is substantially different for anyone; if you're to the
> point of needing to know coverage to fill then something is wrong.
> Gaps would be handled by archive nodes, so there is no reason to
> increase vulnerability by doing anything but behaving uniformly.

With my proposal, each node determines randomly and on its own which
blocks to store.  No believing anyone.

> (2) The decision to contact a node should need O(1) communications,
> not just because of the delay of chasing around just to find who has
> someone; but because that chasing process usually makes the process
> _highly_ sybil vulnerable.

Not exactly sure what you mean by that, but I think that's fulfilled.
You can (locally) compute in O(log height) from a node's seed whether or
not it has the blocks you need.  This needs only communication about the
node's seed.

> (3) The expression of what blocks a node has should be compact (e.g.
> not a dense list of blocks) so it can be rumored efficiently.

See above.

> (4) Figuring out what block (ranges) a peer has given should be
> computationally efficient.

O(log height).  Not O(1), but that's probably not a big issue.

> (5) The communication about what blocks a node has should be compact.

See above.

> (6) The coverage created by the network should be uniform, and should
> remain uniform as the blockchain grows; ideally it you shouldn't need
> to update your state to know what blocks a peer will store in the
> future, assuming that it doesn't change the amount of data its
> planning to use. (What Tier Nolan proposes sounds like it fails this
> point)

Coverage will be uniform if the seed is created randomly and the PRNG
has good properties.  No need to update the seed if the other node's
fraction is unchanged.  (Not sure if you suggest for nodes to define a
"fraction" or rather an "absolute size".)

> (7) Growth of the blockchain shouldn't cause much (or any) need to
> refetch old blocks.

No need to do that with the scheme.

What do you think about this idea?  Some random thoughts from myself:

*) I need to formulate it in a more general way so that the fraction can
be arbitrary and not just 50%.  This should be easy to do, and I can do
it if there's interest.

*) It is O(log height) and not O(1), but that should not be too
different for the heights that are relevant.

*) Maybe it would be better / easier to not use the PRNG at all; just
decide to *always* use the first or the second interval with a given
size.  Not sure about that.

*) With the proposed scheme, the node's actual fraction of stored blocks
will vary between 1/2 and 2/3 (if I got the mathematics right, it is
still early) as the blocks come in.  Not sure if that's a problem.  I
can do a precise analysis of this property for an extended scheme if you
are interested in it.

Yours,
Daniel

-- 
http://www.domob.eu/
OpenPGP: 1142 850E 6DFF 65BA 63D6  88A8 B249 2AC4 A733 0737
Namecoin: id/domob -> https://nameid.org/?name=domob
--
Done:  Arc-Bar-Cav-Hea-Kni-Ran-Rog-Sam-Tou-Val-Wiz
To go: Mon-Pri

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 836 bytes
Desc: OpenPGP digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/0da57426/attachment.sig>

From tier.nolan at gmail.com  Wed May 13 09:34:03 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Wed, 13 May 2015 10:34:03 +0100
Subject: [Bitcoin-development] Proposed additional options for pruned
	nodes
In-Reply-To: <5552DEFA.4080508@domob.eu>
References: <CANJO25J1WRHtfQLVXUB2s_sjj39pTPWmixAcXNJ3t-5os8RPmQ@mail.gmail.com>
	<CANJO25JTtfmfsOQYOzJeksJn3CoKE3W8iLGsRko-_xd4XhB3ZA@mail.gmail.com>
	<CAJHLa0O5OxaX5g3u=dnCY6Lz_gK3QZgQEPNcWNVRD4JziwAmvg@mail.gmail.com>
	<20150512171640.GA32606@savin.petertodd.org>
	<CAE-z3OV3VdSoiTSfASwYHr1CjZSqio303sqGq_1Y9yaYgov2sw@mail.gmail.com>
	<CAAS2fgRzGkcJbWbJmFN2-NSJGUcLdPKp0q7FjM0x7WDvHoRq=g@mail.gmail.com>
	<5552DEFA.4080508@domob.eu>
Message-ID: <CAE-z3OWiurTt=QqjeL+KN-7AdKKgW2tJc_Yu-eMzoM-GUZ=fAg@mail.gmail.com>

On Wed, May 13, 2015 at 6:19 AM, Daniel Kraft <d at domob.eu> wrote:

> 2) Divide the range of all blocks into intervals with exponentially
> growing size.  I. e., something like this:
>
> 1, 1, 2, 2, 4, 4, 8, 8, 16, 16, ...
>

Interesting.  This can be combined with the system I suggested.

A node broadcasts 3 pieces of information

Seed (16 bits): This is the seed
M_bits_lsb (1 bit):  Used to indicate M during a transition
N (7 bits):  This is the count of the last range held (or partially held)

M = 1 << M_bits

M should be set to the lowest power of 2 greater than double the block
chain height

That gives M = 1 million at the moment.  During changing M, some nodes will
be using the higher M and others will use the lower M.

The M_bits_lsb field allows those to be distinguished.

As the block height approaches 512k, nodes can begin to upgrade.  For a
period around block 512k, some nodes could use M = 1 million and others
could use M = 2 million.

Assuming M is around 3 times higher than the block height, then the odds of
a start being less than the block height is around 35%.  If they runs by
25% each step, then that is approx a double for each hit.

Size(n) = ((4 + (n & 0x3)) << (n >> 2)) * 2.5MB

This gives an exponential increase, but groups of 4 are linearly
interpolated.


*Size(0) = 10 MB*
Size(1) = 12.5MB
Size(2) = 15 MB
Size(3) = 17.5MB
Size(4) = 20MB

*Size(5) = 25MB*
Size(6) = 30MB
Size(7) = 35MB

*Size(8) = 40MB*

Start(n) = Hash(seed + n) mod M

A node should store as much of its last start as possible.  Assuming start
0, 5, and 8 were "hits" but the node had a max size of 60MB.  It can store
0 and 5 and have 25MB left.  That isn't enough to store all of run 8, but
it should store 25MB of the blocks in run 8 anyway.

Size(255) = pow(2, 31) * 17.5MB = 35,840 TB

Decreasing N only causes previously accepted runs to be invalidated.

When a node approaches a transition point for N, it would select a block
height within 25,000 of the transition point.  Once it reaches that block,
it will begin downloading the new runs that it needs.  When updating, it
can set N to zero.  This spreads out the upgrade (over around a year), with
only a small number of nodes upgrading at any time.

New nodes should use the higher M, if near a transition point (say within
100,000).
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/94dd908e/attachment.html>

From thomasv at electrum.org  Wed May 13 09:49:13 2015
From: thomasv at electrum.org (Thomas Voegtlin)
Date: Wed, 13 May 2015 11:49:13 +0200
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <CABsx9T3AxM3et7hgXx3+Rn3BvhQkF-Cn797sHcyztkMpD1UQmA@mail.gmail.com>
References: <5550D8BE.6070207@electrum.org>	<ce3d34c92efd1cf57326e4679550944e@national.shitposting.agency>	<CABsx9T1VgxEJWxrYTs+2hXGnGrSLGJ6mVcAexjXLvK7Vu+e3EA@mail.gmail.com>	<5551F376.4050008@electrum.org>	<CABsx9T1h7p3hDr7ty43uxsYs-oNRpndzg=dowST2tXtogxRm2g@mail.gmail.com>	<555210AF.3090705@electrum.org>
	<CABsx9T3AxM3et7hgXx3+Rn3BvhQkF-Cn797sHcyztkMpD1UQmA@mail.gmail.com>
Message-ID: <55531E19.3090503@electrum.org>


Le 12/05/2015 18:10, Gavin Andresen a ?crit :
> Added back the list, I didn't mean to reply privately:
> 
> Fair enough, I'll try to find time in the next month or three to write up
> four plausible future scenarios for how mining incentives might work:
> 
> 1) Fee-supported with very large blocks containing lots of tiny-fee
> transactions
> 2) Proof-of-idle supported (I wish Tadge Dryja would publish his
> proof-of-idle idea....)
> 3) Fees purely as transaction-spam-prevention measure, chain security via
> alternative consensus algorithm (in this scenario there is very little
> mining).
> 4) Fee supported with small blocks containing high-fee transactions moving
> coins to/from sidechains.
> 
> Would that be helpful, or do you have some reason for thinking that we
> should pick just one and focus all of our efforts on making that one
> scenario happen?
> 
> I always think it is better, when possible, not to "bet on one horse."
> 

Sorry if I did not make myself clear. It is not about betting on one
single horse, or about making one particular scenario happen. It is not
about predicting whether something else will replace PoW in the future,
and I am in no way asking you to focus your efforts in one particular
direction at the expenses of others. Various directions will be explored
by various people, and that's great.

I am talking about what we know today. I would like an answer to the
following question: Do we have a reason to believe that Bitcoin can work
in the long run, without involving technologies that have not been
invented yet? Is there a single scenario that we know could work?

Exotic and unproven technologies are not an answer to that question. The
reference scenario should be as boring as possible, and as verifiable as
possible. I am not asking what you think is the most likely to happen,
but what is the most likely to work, given the knowledge we have today.

If I was asking: "Can we send humans to the moon by 2100?", I guess your
answer would be: "Yes we can, because it has been done in the past with
chemical rockets, and we know how to build them". You would probably not
use a space elevator in your answer.

The reason I am asking that is, there seems to be no consensus among
core developers on how Bitcoin can work without miner subsidy. How it
*will* work is another question.



From tier.nolan at gmail.com  Wed May 13 10:14:06 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Wed, 13 May 2015 11:14:06 +0100
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <55531E19.3090503@electrum.org>
References: <5550D8BE.6070207@electrum.org>
	<ce3d34c92efd1cf57326e4679550944e@national.shitposting.agency>
	<CABsx9T1VgxEJWxrYTs+2hXGnGrSLGJ6mVcAexjXLvK7Vu+e3EA@mail.gmail.com>
	<5551F376.4050008@electrum.org>
	<CABsx9T1h7p3hDr7ty43uxsYs-oNRpndzg=dowST2tXtogxRm2g@mail.gmail.com>
	<555210AF.3090705@electrum.org>
	<CABsx9T3AxM3et7hgXx3+Rn3BvhQkF-Cn797sHcyztkMpD1UQmA@mail.gmail.com>
	<55531E19.3090503@electrum.org>
Message-ID: <CAE-z3OXa8vk6Q1EBChoRYDOLKw--CXNXz4AokXCbVam_8LFFDg@mail.gmail.com>

On Wed, May 13, 2015 at 10:49 AM, Thomas Voegtlin <thomasv at electrum.org>
wrote:

>
> The reason I am asking that is, there seems to be no consensus among
> core developers on how Bitcoin can work without miner subsidy. How it
> *will* work is another question.
>

The position seems to be that it will continue to work for the time being,
so there is still time for more research.

Proof of stake has problems with handling long term reversals.  The main
proposal is to slightly weaken the security requirements.

With POW, a new node only needs to know the genesis block (and network
rules) to fully determine which of two chains is the strongest.

Penalties for abusing POS inherently create a time horizon.  A suggested
POS security model would assume that a full node is a node that resyncs
with the network regularly (every N blocks).    N would be depend on the
network rules of the coin.

The alternative is that 51% of the holders of coins at the genesis block
can rewrite the entire chain.  The genesis block might not be the first
block, a POS coin might still use POW for minting.

https://blog.ethereum.org/2014/11/25/proof-stake-learned-love-weak-subjectivity/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/d8d2e855/attachment.html>

From alex.mizrahi at gmail.com  Wed May 13 10:31:47 2015
From: alex.mizrahi at gmail.com (Alex Mizrahi)
Date: Wed, 13 May 2015 13:31:47 +0300
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <CAE-z3OXa8vk6Q1EBChoRYDOLKw--CXNXz4AokXCbVam_8LFFDg@mail.gmail.com>
References: <5550D8BE.6070207@electrum.org>
	<ce3d34c92efd1cf57326e4679550944e@national.shitposting.agency>
	<CABsx9T1VgxEJWxrYTs+2hXGnGrSLGJ6mVcAexjXLvK7Vu+e3EA@mail.gmail.com>
	<5551F376.4050008@electrum.org>
	<CABsx9T1h7p3hDr7ty43uxsYs-oNRpndzg=dowST2tXtogxRm2g@mail.gmail.com>
	<555210AF.3090705@electrum.org>
	<CABsx9T3AxM3et7hgXx3+Rn3BvhQkF-Cn797sHcyztkMpD1UQmA@mail.gmail.com>
	<55531E19.3090503@electrum.org>
	<CAE-z3OXa8vk6Q1EBChoRYDOLKw--CXNXz4AokXCbVam_8LFFDg@mail.gmail.com>
Message-ID: <CAE28kURWFveC0B-WvFebMpGm1GY-8juxQ+UDpuYtOwVnbOgu-A@mail.gmail.com>

> With POW, a new node only needs to know the genesis block (and network
> rules) to fully determine which of two chains is the strongest.
>

But this matters if a new node has access to the globally strongest chain.
If attacker is able to block connections to legitimate nodes, a new node
will happily accept attacker's chain.

So PoW, by itself, doesn't give strong security guarantees. This problem is
so fundamental people avoid talking about it.

In practice, Bitcoin already embraces "weak subjectivity" e.g. in form of
checkpoints embedded into the source code. So it's hard to take PoW purists
seriously.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/39177196/attachment.html>

From tier.nolan at gmail.com  Wed May 13 10:43:08 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Wed, 13 May 2015 11:43:08 +0100
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CAAS2fgQRS7w7RRNXVK_+=4CQ7=AWxWQQ7+Tf4tNUPTTZOf7rEQ@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CAOG=w-szbLgc1jLpkE_uMa3bkFTi-RiBEaQ6Y-u5aKLBC2HvUg@mail.gmail.com>
	<CAAS2fgQRS7w7RRNXVK_+=4CQ7=AWxWQQ7+Tf4tNUPTTZOf7rEQ@mail.gmail.com>
Message-ID: <CAE-z3OUzYZDvsOYEDT229vnvNBa9ntW+86O3uA-K5-KaneMF_g@mail.gmail.com>

On Sat, May 9, 2015 at 4:36 AM, Gregory Maxwell <gmaxwell at gmail.com> wrote:

> An example would
> be tx_size = MAX( real_size >> 1,  real_size + 4*utxo_created_size -
> 3*utxo_consumed_size).


This could be implemented as a soft fork too.

* 1MB hard size limit
* 900kB soft limit

S = block size
U = UTXO_adjusted_size = S + 4 * outputs - 3 * inputs

A block is valid if S < 1MB and U < 1MB

A 250 byte transaction with 2 inputs and 2 outputs would have an adjusted
size of 252 bytes.

The memory pool could be sorted by fee per adjusted_size.

 Coin selection could be adjusted so it tries to have at least 2 inputs
when creating transactions, unless the input is worth more than a threshold
(say 0.001 BTC).

This is a pretty weak incentive, especially if the block size is
increased.  Maybe it will cause a "nudge"
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/0e8a97f2/attachment.html>

From bitcoin at olivere.de  Wed May 13 10:37:17 2015
From: bitcoin at olivere.de (Oliver Egginger)
Date: Wed, 13 May 2015 12:37:17 +0200
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <CAJHLa0Mc_7OYFpxHjMGTyMNBAXUV+Y67rZMsKuZgp4mGN7fJVg@mail.gmail.com>
References: <554A91BE.6060105@bluematt.me>	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>	<554BA032.4040405@bluematt.me>	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>	<CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>	<CANEZrP39jWHLF02z-81Z4+9X1vH5+hMuS=-3ED81=Q1o9U=DKw@mail.gmail.com>	<554BBDA2.7040508@gmail.com>	<CAJHLa0NcxOHkrtW2=-JgfsXQJkCO8Ym7icBwMx_2RsaWcPBnTw@mail.gmail.com>	<554CCF56.3000604@gmail.com>
	<CAJHLa0Mc_7OYFpxHjMGTyMNBAXUV+Y67rZMsKuZgp4mGN7fJVg@mail.gmail.com>
Message-ID: <5553295D.6020002@olivere.de>

08.05.2015 at 5:49 Jeff Garzik wrote:
> To repeat, the very first point in my email reply was: "Agree that 7 tps
> is too low"  

For interbank trading that would maybe enough but I don't know.

I'm not a developer but as a (former) user and computer scientist I'm
also asking myself what is the core of the problem? Personally, for
privacy reasons I do not want to leave a footprint in the blockchain for
each pizza. And why should this expense be good for trivial things of
everyday life?

If one encounters the block boundary, he or she will do more effort or
give up. I'm thinking most people will give up because their
transactions are not really economical. It is much better for them to
use third-partys (or another payment system).

And that's where we are at the heart of the problem. The Bitcoin
third-party economy. With few exceptions this is pure horror. More worse
than any used car dealer. And the community just waits that things get
better. But that will never happen of its own accord. We are living in a
Wild West Town. So we need a Sheriff and many other things.

We need a small but good functioning economy around the blockchain. To
create one, we have to accept a few unpleasant truths. I do not know if
the community is ready for it.

Nevertheless, I know that some companies do a good job. But they have to
prevail against their dishonest competitors.

People take advantage of the blockchain, because they no longer trust
anyone. But this will not scale in the long run.

- oliver










From gubatron at gmail.com  Wed May 13 11:25:47 2015
From: gubatron at gmail.com (Angel Leon)
Date: Wed, 13 May 2015 07:25:47 -0400
Subject: [Bitcoin-development] Block Size Increase
In-Reply-To: <5553295D.6020002@olivere.de>
References: <554A91BE.6060105@bluematt.me>
	<CANEZrP3wGWHdz+ut6pvke5TJJsc1rTFt8sn2KziX35oL5LAsyg@mail.gmail.com>
	<CABm2gDpDvk2VsQ+mJ-BoeBKmvu9jBXNujZEFKuCStRNjFL6VOA@mail.gmail.com>
	<CANEZrP2zAGCCBhNa4=9yw+A_Dn5o4SQXoPTE_qcJzZ1dFuF2tw@mail.gmail.com>
	<CABm2gDqd6iHRUDKZWWTudcC1QkYa+rCuHjz7pMC2K1Db8wpgfA@mail.gmail.com>
	<CANEZrP1CU0kB0vXeXUX1L8byaT-Zf2xg+3N+GeNthi_i6bn1qw@mail.gmail.com>
	<CABsx9T2Nxvr4fqREMw3_LXftzsxrUAR1+9sVMa8_EpTnH1nN1Q@mail.gmail.com>
	<554BA032.4040405@bluematt.me>
	<CANEZrP3yM9wsSPNgpOsXDk-DjUy5PW2XuRTvK2AyCNbVJ5hZHw@mail.gmail.com>
	<CADJgMzti7ROH90APiwg4NOAT5+Av=4i295b8VN0sbSLr4+WWRw@mail.gmail.com>
	<CANEZrP39jWHLF02z-81Z4+9X1vH5+hMuS=-3ED81=Q1o9U=DKw@mail.gmail.com>
	<554BBDA2.7040508@gmail.com>
	<CAJHLa0NcxOHkrtW2=-JgfsXQJkCO8Ym7icBwMx_2RsaWcPBnTw@mail.gmail.com>
	<554CCF56.3000604@gmail.com>
	<CAJHLa0Mc_7OYFpxHjMGTyMNBAXUV+Y67rZMsKuZgp4mGN7fJVg@mail.gmail.com>
	<5553295D.6020002@olivere.de>
Message-ID: <CADZB0_bN9bJiwCs8j3HoUQA5ZJLncsg3rY1nAE=sgV6aSnb40w@mail.gmail.com>

> Personally, for privacy reasons I do not want to leave a footprint in the
blockchain for each pizza. And  why should this expense be good for trivial
things of everyday life?

Then what's the point?
Isn't this supposed to be an Open transactional network, it doesn't matter
if you don't want that, what matters is what people want to do with it, and
there's nothing you can do to stop someone from opening a wallet and buying
a pizza with it, except the core of the problem you ask yourself about,
which is, the minute this goes mainstream and people get their wallets out
the whole thing will collapse, regardless of what you want the blockchain
for.

Why talk about the billions of unbanked and all the romantic vision if you
can't let them use their money however they want in a decentralized
fashion. Otherwise let's just go back to centralized banking because the
minute you want to put things off chain, you need an organization that will
need to respond to government regulation and that's the end for the
billions of unbanked to be part of the network.


http://twitter.com/gubatron

On Wed, May 13, 2015 at 6:37 AM, Oliver Egginger <bitcoin at olivere.de> wrote:

> 08.05.2015 at 5:49 Jeff Garzik wrote:
> > To repeat, the very first point in my email reply was: "Agree that 7 tps
> > is too low"
>
> For interbank trading that would maybe enough but I don't know.
>
> I'm not a developer but as a (former) user and computer scientist I'm
> also asking myself what is the core of the problem? Personally, for
> privacy reasons I do not want to leave a footprint in the blockchain for
> each pizza. And why should this expense be good for trivial things of
> everyday life?
>
> If one encounters the block boundary, he or she will do more effort or
> give up. I'm thinking most people will give up because their
> transactions are not really economical. It is much better for them to
> use third-partys (or another payment system).
>
> And that's where we are at the heart of the problem. The Bitcoin
> third-party economy. With few exceptions this is pure horror. More worse
> than any used car dealer. And the community just waits that things get
> better. But that will never happen of its own accord. We are living in a
> Wild West Town. So we need a Sheriff and many other things.
>
> We need a small but good functioning economy around the blockchain. To
> create one, we have to accept a few unpleasant truths. I do not know if
> the community is ready for it.
>
> Nevertheless, I know that some companies do a good job. But they have to
> prevail against their dishonest competitors.
>
> People take advantage of the blockchain, because they no longer trust
> anyone. But this will not scale in the long run.
>
> - oliver
>
>
>
>
>
>
>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/4b199524/attachment.html>

From tier.nolan at gmail.com  Wed May 13 11:29:23 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Wed, 13 May 2015 12:29:23 +0100
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <CAE28kURWFveC0B-WvFebMpGm1GY-8juxQ+UDpuYtOwVnbOgu-A@mail.gmail.com>
References: <5550D8BE.6070207@electrum.org>
	<ce3d34c92efd1cf57326e4679550944e@national.shitposting.agency>
	<CABsx9T1VgxEJWxrYTs+2hXGnGrSLGJ6mVcAexjXLvK7Vu+e3EA@mail.gmail.com>
	<5551F376.4050008@electrum.org>
	<CABsx9T1h7p3hDr7ty43uxsYs-oNRpndzg=dowST2tXtogxRm2g@mail.gmail.com>
	<555210AF.3090705@electrum.org>
	<CABsx9T3AxM3et7hgXx3+Rn3BvhQkF-Cn797sHcyztkMpD1UQmA@mail.gmail.com>
	<55531E19.3090503@electrum.org>
	<CAE-z3OXa8vk6Q1EBChoRYDOLKw--CXNXz4AokXCbVam_8LFFDg@mail.gmail.com>
	<CAE28kURWFveC0B-WvFebMpGm1GY-8juxQ+UDpuYtOwVnbOgu-A@mail.gmail.com>
Message-ID: <CAE-z3OVBUu=6sqNc3RUJqFPuqhPdw1Ej0RZ-tSygoQ6LowhVXg@mail.gmail.com>

On Wed, May 13, 2015 at 11:31 AM, Alex Mizrahi <alex.mizrahi at gmail.com>
wrote:

>
> But this matters if a new node has access to the globally strongest chain.
>

A node only needs a path of honest nodes to the network.

If a node is connected to 99 dishonest nodes and 1 honest node, it can
still sync with the main network.

>
> In practice, Bitcoin already embraces "weak subjectivity" e.g. in form of
> checkpoints embedded into the source code. So it's hard to take PoW purists
> seriously.
>
>
That isn't why checkpoints exist.  They are to prevent a disk consumption
DOS attack.

They also allow verification to go faster.  Signature operations are
assumed to be correct without checking if they are in blocks before the
last checkpoint.

They do protect against multi-month forks though, even if not the reason
that they exist.

If releases happen every 6 months, and the checkpoint is 3 months deep at
release, then for the average node, the checkpoint is 3 to 9 months old.

A 3 month reversal would be devastating, so the checkpoint isn't adding
much extra security.

With headers first downloading, the checkpoints could be removed.  They
could still be used for speeding up verification of historical blocks.
Blocks behind the last checkpoint wouldn't need their signatures checked.

Removing them could cause a hard-fork though, so maybe they could be
defined as legacy artifacts of the blockchain.  Future checkpoints could be
advisory.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/5607021d/attachment.html>

From alex.mizrahi at gmail.com  Wed May 13 12:26:17 2015
From: alex.mizrahi at gmail.com (Alex Mizrahi)
Date: Wed, 13 May 2015 15:26:17 +0300
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <CAE-z3OVBUu=6sqNc3RUJqFPuqhPdw1Ej0RZ-tSygoQ6LowhVXg@mail.gmail.com>
References: <5550D8BE.6070207@electrum.org>
	<ce3d34c92efd1cf57326e4679550944e@national.shitposting.agency>
	<CABsx9T1VgxEJWxrYTs+2hXGnGrSLGJ6mVcAexjXLvK7Vu+e3EA@mail.gmail.com>
	<5551F376.4050008@electrum.org>
	<CABsx9T1h7p3hDr7ty43uxsYs-oNRpndzg=dowST2tXtogxRm2g@mail.gmail.com>
	<555210AF.3090705@electrum.org>
	<CABsx9T3AxM3et7hgXx3+Rn3BvhQkF-Cn797sHcyztkMpD1UQmA@mail.gmail.com>
	<55531E19.3090503@electrum.org>
	<CAE-z3OXa8vk6Q1EBChoRYDOLKw--CXNXz4AokXCbVam_8LFFDg@mail.gmail.com>
	<CAE28kURWFveC0B-WvFebMpGm1GY-8juxQ+UDpuYtOwVnbOgu-A@mail.gmail.com>
	<CAE-z3OVBUu=6sqNc3RUJqFPuqhPdw1Ej0RZ-tSygoQ6LowhVXg@mail.gmail.com>
Message-ID: <CAE28kUR-0ozFg6D4Es7RCm1pA5xaW-E1R_YSTRRTj3z4XXiWxw@mail.gmail.com>

Let's consider a concrete example:

1. User wants to accept Bitcoin payments, as his customers want this.
2. He downloads a recent version of Bitcoin Core, checks hashes and so on.
(Maybe even builds from source.)
3. Let's it to sync for several hours or days.
4. After wallet is synced, he gives his address to customer.
5. Customer pays.
6. User waits 10 confirmations and ships the goods. (Suppose it's something
very expensive.)
7. Some time later, user wants to convert some of his bitcoins to dollars.
He sends his bitcoins to an exchange but they never arrive.

He tries to investigate, and after some time discovers that his router (or
his ISP's router) was hijacked. His Bitcoin node couldn't connect to any of
the legitimate nodes, and thus got a complete fake chain from the attacker.
Bitcoins he received were totally fake.

Bitcoin Core did a shitty job and confirmed some fake transactions.
User doesn't care that *if *his network was not impaired, Bitcoin Core *would
have *worked properly.
The main duty of Bitcoin Core is to check whether transactions are
confirmed, and if it can be fooled by a simple router hack, then it does
its job poorly.

If you don't see it being a problem, you should't be allowed to develop
anything security-related.

If a node is connected to 99 dishonest nodes and 1 honest node, it can
> still sync with the main network.
>

Yes, it is good against Sybil attack, but not good against a network-level
attack.
Attack on user's routers is a very realistic, plausible attack.
Imagine if SSL could be hacked by hacking a router, would people still use
it?

Fucking no.


> A 3 month reversal would be devastating, so the checkpoint isn't adding
> much extra security.
>

WIthout checkpoints an attacker could prepare a fork for $10.
With checkpoints, it would cost him at least $1000, but more likely upwards
of $100000.
That's quite a difference, no?

I do not care what do you think about the reasons why checkpoints were
added, but it is a fact that they make the attack scenario I describe above
hard to impossible.

Without checkpoints, you could perform this attack using a laptop.
With checkpoints, you need access to significant amounts of mining ASICs.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/1683d04a/attachment.html>

From decker.christian at gmail.com  Wed May 13 12:48:04 2015
From: decker.christian at gmail.com (Christian Decker)
Date: Wed, 13 May 2015 12:48:04 +0000
Subject: [Bitcoin-development] [BIP] Normalized Transaction IDs
Message-ID: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>

Hi All,

I'd like to propose a BIP to normalize transaction IDs in order to address
transaction malleability and facilitate higher level protocols.

The normalized transaction ID is an alias used in parallel to the current
(legacy) transaction IDs to address outputs in transactions. It is
calculated by removing (zeroing) the scriptSig before computing the hash,
which ensures that only data whose integrity is also guaranteed by the
signatures influences the hash. Thus if anything causes the normalized ID
to change it automatically invalidates the signature. When validating a
client supporting this BIP would use both the normalized tx ID as well as
the legacy tx ID when validating transactions.

The detailed writeup can be found here:
https://github.com/cdecker/bips/blob/normalized-txid/bip-00nn.mediawiki.

@gmaxwell: I'd like to request a BIP number, unless there is something
really wrong with the proposal.

In addition to being a simple alternative that solves transaction
malleability it also hugely simplifies higher level protocols. We can now
use template transactions upon which sequences of transactions can be built
before signing them.

I hesitated quite a while to propose it since it does require a hardfork
(old clients would not find the prevTx identified by the normalized
transaction ID and deem the spending transaction invalid), but it seems
that hardforks are no longer the dreaded boogeyman nobody talks about.
I left out the details of how the hardfork is to be done, as it does not
really matter and we may have a good mechanism to apply a bunch of
hardforks concurrently in the future.

I'm sure it'll take time to implement and upgrade, but I think it would be
a nice addition to the functionality and would solve a long standing
problem :-)

Please let me know what you think, the proposal is definitely not set in
stone at this point and I'm sure we can improve it further.

Regards,
Christian
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/2131ae26/attachment.html>

From tier.nolan at gmail.com  Wed May 13 13:12:43 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Wed, 13 May 2015 14:12:43 +0100
Subject: [Bitcoin-development] [BIP] Normalized Transaction IDs
In-Reply-To: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
References: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
Message-ID: <CAE-z3OWUGPqruBkuXggzdNkOn+L-SSg84Qd1_JZYBunmY+j=HQ@mail.gmail.com>

I think this is a good way to handle things, but as you say, it is a hard
fork.

CHECKLOCKTIMEVERIFY covers many of the use cases, but it would be nice to
fix malleability once and for all.

This has the effect of doubling the size of the UTXO database.  At minimum,
there needs to be a legacy txid to normalized txid map in the database.

An addition to the BIP would eliminate the need for the 2nd index.  You
could require a SPV proof of the spending transaction to be included with
legacy transactions.  This would allow clients to verify that the
normalized txid matched the legacy id.

The OutPoint would be {LegacyId | SPV Proof to spending tx  | spending tx |
index}.  This allows a legacy transaction to be upgraded.  OutPoints which
use a normalized txid don't need the SPV proof.

The hard fork would be followed by a transitional period, in which both
txids could be used.  Afterwards, legacy transactions have to have the SPV
proof added.  This means that old transactions with locktimes years in the
future can be upgraded for spending, without nodes needing to maintain two
indexes.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/84f2cb0a/attachment.html>

From gavinandresen at gmail.com  Wed May 13 13:24:04 2015
From: gavinandresen at gmail.com (Gavin)
Date: Wed, 13 May 2015 09:24:04 -0400
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <CAE28kUR-0ozFg6D4Es7RCm1pA5xaW-E1R_YSTRRTj3z4XXiWxw@mail.gmail.com>
References: <5550D8BE.6070207@electrum.org>
	<ce3d34c92efd1cf57326e4679550944e@national.shitposting.agency>
	<CABsx9T1VgxEJWxrYTs+2hXGnGrSLGJ6mVcAexjXLvK7Vu+e3EA@mail.gmail.com>
	<5551F376.4050008@electrum.org>
	<CABsx9T1h7p3hDr7ty43uxsYs-oNRpndzg=dowST2tXtogxRm2g@mail.gmail.com>
	<555210AF.3090705@electrum.org>
	<CABsx9T3AxM3et7hgXx3+Rn3BvhQkF-Cn797sHcyztkMpD1UQmA@mail.gmail.com>
	<55531E19.3090503@electrum.org>
	<CAE-z3OXa8vk6Q1EBChoRYDOLKw--CXNXz4AokXCbVam_8LFFDg@mail.gmail.com>
	<CAE28kURWFveC0B-WvFebMpGm1GY-8juxQ+UDpuYtOwVnbOgu-A@mail.gmail.com>
	<CAE-z3OVBUu=6sqNc3RUJqFPuqhPdw1Ej0RZ-tSygoQ6LowhVXg@mail.gmail.com>
	<CAE28kUR-0ozFg6D4Es7RCm1pA5xaW-E1R_YSTRRTj3z4XXiWxw@mail.gmail.com>
Message-ID: <E6CE3531-5AFC-49ED-9041-A924B01966BC@gmail.com>

Checkpoints will be replaced by compiled-in 'at THIS timestamp the main chain had THIS much proof of work.'

That is enough information to prevent attacks and still allow optimizations like skipping signature checking for ancient transactions.

I don't think anybody is proposing replacing checkpoints with nothing.

--
Gavin Andresen


> On May 13, 2015, at 8:26 AM, Alex Mizrahi <alex.mizrahi at gmail.com> wrote:
> 
> Let's consider a concrete example:
> 
> 1. User wants to accept Bitcoin payments, as his customers want this.
> 2. He downloads a recent version of Bitcoin Core, checks hashes and so on. (Maybe even builds from source.)
> 3. Let's it to sync for several hours or days.
> 4. After wallet is synced, he gives his address to customer.
> 5. Customer pays. 
> 6. User waits 10 confirmations and ships the goods. (Suppose it's something very expensive.)
> 7. Some time later, user wants to convert some of his bitcoins to dollars. He sends his bitcoins to an exchange but they never arrive.
> 
> He tries to investigate, and after some time discovers that his router (or his ISP's router) was hijacked. His Bitcoin node couldn't connect to any of the legitimate nodes, and thus got a complete fake chain from the attacker.
> Bitcoins he received were totally fake.
> 
> Bitcoin Core did a shitty job and confirmed some fake transactions.
> User doesn't care that if his network was not impaired, Bitcoin Core would have worked properly.
> The main duty of Bitcoin Core is to check whether transactions are confirmed, and if it can be fooled by a simple router hack, then it does its job poorly.
> 
> If you don't see it being a problem, you should't be allowed to develop anything security-related.
> 
>> If a node is connected to 99 dishonest nodes and 1 honest node, it can still sync with the main network.
> 
> Yes, it is good against Sybil attack, but not good against a network-level attack.
> Attack on user's routers is a very realistic, plausible attack.
> Imagine if SSL could be hacked by hacking a router, would people still use it?
> 
> Fucking no.
>   
>> A 3 month reversal would be devastating, so the checkpoint isn't adding much extra security.
> 
> WIthout checkpoints an attacker could prepare a fork for $10.
> With checkpoints, it would cost him at least $1000, but more likely upwards of $100000.
> That's quite a difference, no?
> 
> I do not care what do you think about the reasons why checkpoints were added, but it is a fact that they make the attack scenario I describe above hard to impossible.
> 
> Without checkpoints, you could perform this attack using a laptop.
> With checkpoints, you need access to significant amounts of mining ASICs.
> 
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud 
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/43b037e0/attachment.html>

From tier.nolan at gmail.com  Wed May 13 13:28:44 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Wed, 13 May 2015 14:28:44 +0100
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <CAE28kUR-0ozFg6D4Es7RCm1pA5xaW-E1R_YSTRRTj3z4XXiWxw@mail.gmail.com>
References: <5550D8BE.6070207@electrum.org>
	<ce3d34c92efd1cf57326e4679550944e@national.shitposting.agency>
	<CABsx9T1VgxEJWxrYTs+2hXGnGrSLGJ6mVcAexjXLvK7Vu+e3EA@mail.gmail.com>
	<5551F376.4050008@electrum.org>
	<CABsx9T1h7p3hDr7ty43uxsYs-oNRpndzg=dowST2tXtogxRm2g@mail.gmail.com>
	<555210AF.3090705@electrum.org>
	<CABsx9T3AxM3et7hgXx3+Rn3BvhQkF-Cn797sHcyztkMpD1UQmA@mail.gmail.com>
	<55531E19.3090503@electrum.org>
	<CAE-z3OXa8vk6Q1EBChoRYDOLKw--CXNXz4AokXCbVam_8LFFDg@mail.gmail.com>
	<CAE28kURWFveC0B-WvFebMpGm1GY-8juxQ+UDpuYtOwVnbOgu-A@mail.gmail.com>
	<CAE-z3OVBUu=6sqNc3RUJqFPuqhPdw1Ej0RZ-tSygoQ6LowhVXg@mail.gmail.com>
	<CAE28kUR-0ozFg6D4Es7RCm1pA5xaW-E1R_YSTRRTj3z4XXiWxw@mail.gmail.com>
Message-ID: <CAE-z3OWBVjUog7m9C4P4BHeZe6dy7Dt9f3+kSa6f3v3=oNQJmQ@mail.gmail.com>

On Wed, May 13, 2015 at 1:26 PM, Alex Mizrahi <alex.mizrahi at gmail.com>
wrote:

> He tries to investigate, and after some time discovers that his router (or
> his ISP's router) was hijacked. His Bitcoin node couldn't connect to any of
> the legitimate nodes, and thus got a complete fake chain from the attacker.
> Bitcoins he received were totally fake.
>
> Bitcoin Core did a shitty job and confirmed some fake transactions.
>

I don't really see how you can protect against total isolation of a node
(POS or POW).  You would need to find an alternative route for the
information.

Even encrypted connections are pointless without authentication of who you
are communicating with.

Again, it is part of the security model that you can connect to at least
one honest node.

Someone tweated all the bitcoin headers at one point.  The problem is that
if everyone uses the same check, then that source can be compromised.

> WIthout checkpoints an attacker could prepare a fork for $10.
> With checkpoints, it would cost him at least $1000, but more likely
upwards of $100000.
> That's quite a difference, no?

Headers first mean that you can't knock a synced node off the main chain
without winning the POW race.

Checkpoints can be replaced with a minimum amount of POW for initial sync.
This prevents spam of low POW blocks.  Once a node is on a chain with at
least that much POW, it considers it the main chain.,
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/c0aa03e4/attachment.html>

From gavinandresen at gmail.com  Wed May 13 13:41:44 2015
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Wed, 13 May 2015 09:41:44 -0400
Subject: [Bitcoin-development] [BIP] Normalized Transaction IDs
In-Reply-To: <CAE-z3OWUGPqruBkuXggzdNkOn+L-SSg84Qd1_JZYBunmY+j=HQ@mail.gmail.com>
References: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
	<CAE-z3OWUGPqruBkuXggzdNkOn+L-SSg84Qd1_JZYBunmY+j=HQ@mail.gmail.com>
Message-ID: <CABsx9T1tPP_qrdyKPneZciwtWh2gho_d=qTCjnipo3463dJbpA@mail.gmail.com>

I think this needs more details before it gets a BIP number; for example,
which opcodes does this affect, and how, exactly, does it affect them? Is
the merkle root in the block header computed using normalized transaction
ids or normalized ids?

I think there might actually be two or three or four BIPs here:

 + Overall "what is trying to be accomplished"
 + Changes to the OP_*SIG* opcodes
 + Changes to the bloom-filtering SPV support
 + ...eventually, hard fork rollout plan

I also think that it is a good idea to have actually implemented a proposal
before getting a BIP number. At least, I find that actually writing the
code often turns up issues I hadn't considered when thinking about the
problem at a high level. And I STRONGLY believe BIPs should be descriptive
("here is how this thing works") not proscriptive ("here's how I think we
should all do it").

Finally: I like the idea of moving to a normalized txid. But it might make
sense to bundle that change with a bigger change to OP_CHECKSIG; see Greg
Maxwell's excellent talk about his current thoughts on that topic:
  https://www.youtube.com/watch?v=Gs9lJTRZCDc


On Wed, May 13, 2015 at 9:12 AM, Tier Nolan <tier.nolan at gmail.com> wrote:

> I think this is a good way to handle things, but as you say, it is a hard
> fork.
>
> CHECKLOCKTIMEVERIFY covers many of the use cases, but it would be nice to
> fix malleability once and for all.
>
> This has the effect of doubling the size of the UTXO database.  At
> minimum, there needs to be a legacy txid to normalized txid map in the
> database.
>
> An addition to the BIP would eliminate the need for the 2nd index.  You
> could require a SPV proof of the spending transaction to be included with
> legacy transactions.  This would allow clients to verify that the
> normalized txid matched the legacy id.
>
> The OutPoint would be {LegacyId | SPV Proof to spending tx  | spending tx
> | index}.  This allows a legacy transaction to be upgraded.  OutPoints
> which use a normalized txid don't need the SPV proof.
>
> The hard fork would be followed by a transitional period, in which both
> txids could be used.  Afterwards, legacy transactions have to have the SPV
> proof added.  This means that old transactions with locktimes years in the
> future can be upgraded for spending, without nodes needing to maintain two
> indexes.
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>


-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/01cccf57/attachment.html>

From alex.mizrahi at gmail.com  Wed May 13 14:26:52 2015
From: alex.mizrahi at gmail.com (Alex Mizrahi)
Date: Wed, 13 May 2015 17:26:52 +0300
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <CAE-z3OWBVjUog7m9C4P4BHeZe6dy7Dt9f3+kSa6f3v3=oNQJmQ@mail.gmail.com>
References: <5550D8BE.6070207@electrum.org>
	<ce3d34c92efd1cf57326e4679550944e@national.shitposting.agency>
	<CABsx9T1VgxEJWxrYTs+2hXGnGrSLGJ6mVcAexjXLvK7Vu+e3EA@mail.gmail.com>
	<5551F376.4050008@electrum.org>
	<CABsx9T1h7p3hDr7ty43uxsYs-oNRpndzg=dowST2tXtogxRm2g@mail.gmail.com>
	<555210AF.3090705@electrum.org>
	<CABsx9T3AxM3et7hgXx3+Rn3BvhQkF-Cn797sHcyztkMpD1UQmA@mail.gmail.com>
	<55531E19.3090503@electrum.org>
	<CAE-z3OXa8vk6Q1EBChoRYDOLKw--CXNXz4AokXCbVam_8LFFDg@mail.gmail.com>
	<CAE28kURWFveC0B-WvFebMpGm1GY-8juxQ+UDpuYtOwVnbOgu-A@mail.gmail.com>
	<CAE-z3OVBUu=6sqNc3RUJqFPuqhPdw1Ej0RZ-tSygoQ6LowhVXg@mail.gmail.com>
	<CAE28kUR-0ozFg6D4Es7RCm1pA5xaW-E1R_YSTRRTj3z4XXiWxw@mail.gmail.com>
	<CAE-z3OWBVjUog7m9C4P4BHeZe6dy7Dt9f3+kSa6f3v3=oNQJmQ@mail.gmail.com>
Message-ID: <CAE28kUQveZ9BVAG9XSnwxv0aGBx7sMpe7kPXvvO0Zr7Q9A3vjA@mail.gmail.com>

> I don't really see how you can protect against total isolation of a node
> (POS or POW). You would need to find an alternative route for the
> information.
>

"Alternative route for the information" is the whole point of weak
subjectivity, no?

PoS depends on weak subjectivity to prevent "long term reversals", but
using it also prevents "total isolation" attacks.

The argument that PoW is better than PoS because PoS has to depend on weak
subjectivity, but PoW doesn't is wrong.
Any practical implementation of PoW will also have to rely on weak
subjectivity to be secure against isolation attack.
And if we have to rely on weak subjectivity anyway, then why not PoS?


> Again, it is part of the security model that you can connect to at least
> one honest node.
>

This is the security model of PoW-based consensus. If you study
PoW-consensus, then yes, this is the model you have to use.

But people use Bitcoin Core as a piece of software. They do not care what
security model you use, they expect it to work.
If there are realistic scenarios in which it fails, then this must be
documented. Users should be made aware of the problem, should be able to
take preventative measures (e.g. manually check the latest block against
sources they trust), etc.


> The problem is that if everyone uses the same check, then that source can
> be compromised.
>

Yes, this problem cannot be solved in a 100% decentralized and automatic
way.
Which doesn't mean it's not worth solving, does it?

1. There are non-decentralized, trust-based solutions: refuse to work if
none of well-known nodes are accessible.
Well-known nodes are already used for bootstrapping, and this is another
point which can be attacked.
So if it's impossible to make it 100% decentralized and secure, why not
make it 99% decentralized and secure?

2. It is a common practice to check sha256sum after downloading the
package, and this is usually done manually.
Why can't checking block hashes against some source become a common
practice as well?


Also it's worth noting that these security measures are additive.
Isolating a node AND hijacking one of well-known nodes AND hijacking a
block explorer site user checks hashes against is exponentially harder than
defeating a single measure.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/4be37675/attachment.html>

From decker.christian at gmail.com  Wed May 13 15:24:34 2015
From: decker.christian at gmail.com (Christian Decker)
Date: Wed, 13 May 2015 15:24:34 +0000
Subject: [Bitcoin-development] [BIP] Normalized Transaction IDs
In-Reply-To: <CABsx9T1tPP_qrdyKPneZciwtWh2gho_d=qTCjnipo3463dJbpA@mail.gmail.com>
References: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
	<CAE-z3OWUGPqruBkuXggzdNkOn+L-SSg84Qd1_JZYBunmY+j=HQ@mail.gmail.com>
	<CABsx9T1tPP_qrdyKPneZciwtWh2gho_d=qTCjnipo3463dJbpA@mail.gmail.com>
Message-ID: <CALxbBHXjhgWrOdEa=_QLcvryZhP=tmdaCGnRwE9qNXJnVBmtjA@mail.gmail.com>

Glad you like it, I was afraid that I missed something obvious :-)

The points the two of you raised are valid and I will address them as soon
as possible. I certainly will implement this proposal so that it becomes
more concrete, but my C++ is a bit rusty and it'll take some time, so I
wanted to gauge interest first.

> This has the effect of doubling the size of the UTXO database.  At
minimum, there needs to be a legacy txid to normalized txid map in the
database.
>
> An addition to the BIP would eliminate the need for the 2nd index.  You
could require a SPV proof of the spending transaction to be included with
legacy transactions.  This would allow clients to verify that the
normalized txid matched the legacy id.
>
>The OutPoint would be {LegacyId | SPV Proof to spending tx  | spending tx
| index}.  This allows a legacy transaction to be upgraded.  OutPoints
which use a normalized txid don't need the SPV proof.

It does and I should have mentioned it in the draft, according to my
calculations a mapping legacy ID -> normalized ID is about 256 MB in size,
or at least it was at height 330'000, things might have changed a bit and
I'll recompute that. I omitted the deprecation of legacy IDs on purpose
since we don't know whether we will migrate completely or leave keep both
options viable.

> I think this needs more details before it gets a BIP number; for example,
which opcodes does this affect, and how, exactly, does it affect them? Is
the merkle root in the block header computed using normalized transaction
ids or normalized ids?

I think both IDs can be used in the merkle tree, since we lookup an ID in
both indices we can use both to address them and we will find them either
way.

As for the opcodes I'll have to check, but I currently don't see how they
could be affected. The OP_*SIG* codes calculate their own (more
complicated) stripped transaction before hashing and checking the
signature. The input of the stripped transaction simply contains whatever
hash was used to reference the output, so we do not replace IDs during the
operation. The stripped format used by OP_*SIG* operations does not have to
adhere to the hashes used to reference a transaction in the input.

> I think there might actually be two or three or four BIPs here:
>
>  + Overall "what is trying to be accomplished"
>  + Changes to the OP_*SIG* opcodes
>  + Changes to the bloom-filtering SPV support
>  + ...eventually, hard fork rollout plan
>
> I also think that it is a good idea to have actually implemented a
proposal before getting a BIP number. At least, I find that actually
writing the code often turns up issues I hadn't considered when thinking
about the problem at a high level. And I STRONGLY believe BIPs should be
descriptive ("here is how this thing works") not proscriptive ("here's how
I think we should all do it").

We can certainly split the proposal should it get too large, for now it
seems manageable, since opcodes are not affected. Bloom-filtering is
resolved by adding the normalized transaction IDs and checking for both IDs
in the filter. Since you mention bundling the change with other changes
that require a hard-fork it might be a good idea to build a separate
proposal for a generic hard-fork rollout mechanism.

If there are no obvious roadblocks and the change seems generally a good
thing I will implement it in Bitcoin Core :-)

Regards,
Chris

On Wed, May 13, 2015 at 3:44 PM Gavin Andresen <gavinandresen at gmail.com>
wrote:

> I think this needs more details before it gets a BIP number; for example,
> which opcodes does this affect, and how, exactly, does it affect them? Is
> the merkle root in the block header computed using normalized transaction
> ids or normalized ids?
>
> I think there might actually be two or three or four BIPs here:
>
>  + Overall "what is trying to be accomplished"
>  + Changes to the OP_*SIG* opcodes
>  + Changes to the bloom-filtering SPV support
>  + ...eventually, hard fork rollout plan
>
> I also think that it is a good idea to have actually implemented a
> proposal before getting a BIP number. At least, I find that actually
> writing the code often turns up issues I hadn't considered when thinking
> about the problem at a high level. And I STRONGLY believe BIPs should be
> descriptive ("here is how this thing works") not proscriptive ("here's how
> I think we should all do it").
>
> Finally: I like the idea of moving to a normalized txid. But it might make
> sense to bundle that change with a bigger change to OP_CHECKSIG; see Greg
> Maxwell's excellent talk about his current thoughts on that topic:
>   https://www.youtube.com/watch?v=Gs9lJTRZCDc
>
>
> On Wed, May 13, 2015 at 9:12 AM, Tier Nolan <tier.nolan at gmail.com> wrote:
>
>> I think this is a good way to handle things, but as you say, it is a hard
>> fork.
>>
>> CHECKLOCKTIMEVERIFY covers many of the use cases, but it would be nice to
>> fix malleability once and for all.
>>
>> This has the effect of doubling the size of the UTXO database.  At
>> minimum, there needs to be a legacy txid to normalized txid map in the
>> database.
>>
>> An addition to the BIP would eliminate the need for the 2nd index.  You
>> could require a SPV proof of the spending transaction to be included with
>> legacy transactions.  This would allow clients to verify that the
>> normalized txid matched the legacy id.
>>
>> The OutPoint would be {LegacyId | SPV Proof to spending tx  | spending tx
>> | index}.  This allows a legacy transaction to be upgraded.  OutPoints
>> which use a normalized txid don't need the SPV proof.
>>
>> The hard fork would be followed by a transitional period, in which both
>> txids could be used.  Afterwards, legacy transactions have to have the SPV
>> proof added.  This means that old transactions with locktimes years in the
>> future can be upgraded for spending, without nodes needing to maintain two
>> indexes.
>>
>>
>> ------------------------------------------------------------------------------
>> One dashboard for servers and applications across Physical-Virtual-Cloud
>> Widest out-of-the-box monitoring support with 50+ applications
>> Performance metrics, stats and reports that give you Actionable Insights
>> Deep dive visibility with transaction tracing using APM Insight.
>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>>
>
>
> --
> --
> Gavin Andresen
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/4ba21be6/attachment.html>

From gavinandresen at gmail.com  Wed May 13 15:41:16 2015
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Wed, 13 May 2015 11:41:16 -0400
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <CALqxMTGebNMARgps9mqxDSOw0cX9aeZZim82g8a4vE6sCPHq-g@mail.gmail.com>
References: <5550D8BE.6070207@electrum.org>
	<ce3d34c92efd1cf57326e4679550944e@national.shitposting.agency>
	<CABsx9T1VgxEJWxrYTs+2hXGnGrSLGJ6mVcAexjXLvK7Vu+e3EA@mail.gmail.com>
	<5551F376.4050008@electrum.org>
	<CABsx9T1h7p3hDr7ty43uxsYs-oNRpndzg=dowST2tXtogxRm2g@mail.gmail.com>
	<555210AF.3090705@electrum.org>
	<CABsx9T3AxM3et7hgXx3+Rn3BvhQkF-Cn797sHcyztkMpD1UQmA@mail.gmail.com>
	<CAPS+U98sh6BmuGHWOffrmTpaM3CNfhBUWdmgACb9++jU6M1fmQ@mail.gmail.com>
	<CALqxMTGebNMARgps9mqxDSOw0cX9aeZZim82g8a4vE6sCPHq-g@mail.gmail.com>
Message-ID: <CABsx9T0K3xQUSY26VYoJzyAGkqCfRL_xnkQUrv7M-HpOvpio5w@mail.gmail.com>

On Tue, May 12, 2015 at 7:48 PM, Adam Back <adam at cypherspace.org> wrote:

> I think its fair to say no one knows how to make a consensus that
> works in a decentralised fashion that doesnt weaken the bitcoin
> security model without proof-of-work for now.
>

Yes.


> I am presuming Gavin is just saying in the context of not pre-judging
> the future that maybe in the far future another innovation might be
> found (or alternatively maybe its not mathematically possible).
>

Yes... or an alternative might be found that weakens the Bitcoin security
model by a small enough amount that it either doesn't matter or the
weakening is vastly overwhelmed by some other benefit.

I'm influenced by the way the Internet works; packets addressed to
74.125.226.67 reliably get to Google through a very decentralized system
that I'll freely admit I don't understand. Yes, a determined attacker can
re-route packets, but layers of security on top means re-routing packets
isn't enough to pull off profitable attacks.

I think Bitcoin's proof-of-work might evolve in a similar way. Yes, you
might be able to 51% attack the POW, but layers of security on top of POW
will mean that won't be enough to pull off profitable attacks.


-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/1cad34e9/attachment.html>

From tier.nolan at gmail.com  Wed May 13 16:18:24 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Wed, 13 May 2015 17:18:24 +0100
Subject: [Bitcoin-development] [BIP] Normalized Transaction IDs
In-Reply-To: <CALxbBHXjhgWrOdEa=_QLcvryZhP=tmdaCGnRwE9qNXJnVBmtjA@mail.gmail.com>
References: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
	<CAE-z3OWUGPqruBkuXggzdNkOn+L-SSg84Qd1_JZYBunmY+j=HQ@mail.gmail.com>
	<CABsx9T1tPP_qrdyKPneZciwtWh2gho_d=qTCjnipo3463dJbpA@mail.gmail.com>
	<CALxbBHXjhgWrOdEa=_QLcvryZhP=tmdaCGnRwE9qNXJnVBmtjA@mail.gmail.com>
Message-ID: <CAE-z3OXumLSS9phiw6x6MEv+p6My+HtgT9WaKQheKLASBytAJQ@mail.gmail.com>

On Wed, May 13, 2015 at 4:24 PM, Christian Decker <
decker.christian at gmail.com> wrote

> It does and I should have mentioned it in the draft, according to my
> calculations a mapping legacy ID -> normalized ID is about 256 MB in size,
> or at least it was at height 330'000, things might have changed a bit and
> I'll recompute that. I omitted the deprecation of legacy IDs on purpose
> since we don't know whether we will migrate completely or leave keep both
> options viable.
>

There are around 20 million UTXOs.  At 2*32 bytes per entry, that is more
than 1GB.  There are more UTXOs than transactions, but 256MB seems a little
low.

I think both IDs can be used in the merkle tree, since we lookup an ID in
> both indices we can use both to address them and we will find them either
> way.
>

The id that is used to sign should be used in the merkle tree.  The hard
fork should simply be to allow transactions that use the normalized
transaction hash.


> As for the opcodes I'll have to check, but I currently don't see how they
> could be affected.
>

Agreed, the transaction is simply changed and all the standard rules apply.


> We can certainly split the proposal should it get too large, for now it
> seems manageable, since opcodes are not affected.
>

Right it is just a database update.  The undo info also needs to be changed
so that both txids are included.


> Bloom-filtering is resolved by adding the normalized transaction IDs and
> checking for both IDs in the filter.
>

Yeah, if a transaction spends with a legacy txid, it should still match if
the normalized txid is included in the filter.

> Since you mention bundling the change with other changes that require a
hard-fork it might be a good idea to build a separate proposal for a
generic hard-fork rollout mechanism.

That would be useful.  On the other hand, we don't want to make them to
easy.

I think this is a good choice for a hard fork test, since it is
uncontroversial.  With a time machine, it would have been done this way at
the start.

What about the following:

The reference client is updated so that it uses version 2 transactions by
default (but it can be changed by user).  A pop-up could appear for the GUI.

There is no other change.

All transactions in blocks 375000 to 385000 are considered votes and
weighted by bitcoin days destroyed (max 60 days).

If > 75% of the transactions by weight are version 2, then the community
are considered to support the hard fork.

There would need to be a way to protect against miners censoring
transactions/votes.

Users could submit their transactions directly to a p2p tallying system.
The coin would be aged based on the age in block 375000 unless included in
the blockchain.  These votes don't need to be ordered and multiple votes
for the same coin would only count once.

In fact, votes could just be based on holding in block X.

This is an opinion poll rather than a referendum though.

Assuming support of the community, the hard fork can then proceed in a
similar way to the way a soft fork does.

Devs update the reference client to produce version 4 blocks and version 3
transactions.  Miners could watch version 3 transactions to gauge user
interest and use that to help decide if they should update.

If 750 of the last 1000 blocks are version 4 or higher, reject blocks with
transactions of less than version 3 in version 4 blocks

    This means that legacy clients will be slow to confirm their
transactions, since their transactions cannot go into version 4 blocks.
This is encouragement to upgrade.

If 950 of the last 1000 blocks are version 4 or higher, reject blocks with
transactions of less than version 3 in all blocks

    This means that legacy nodes can no longer send transactions but can
still receive.  Transactions received from other legacy nodes would remain
unconfirmed.

If 990 of the last 1000 blocks are version 4 or higher, reject version 3 or
lower blocks

    This is the point of no return.  Rejecting version 3 blocks means that
the next rule is guaranteed to activate within the next 2016 blocks.
Legacy nodes remain on the main chain, but cannot send.  Miners mining with
legacy clients are (soft) forked off the chain.

If 1000 of the last 1000 blocks are version 4 or higher and the difficulty
retarget has just happened, activate hard fork rule

    This hard forks legacy nodes off the chain.  99% of miners support this
change and users have been encouraged to update.  The block rate for the
non-forked chain is ast most 1% of normal.  Blocks happen every 16 hours.
By timing activation after a difficulty retarget, it makes it harder for
the other fork to adapt to the reduced hash rate.

>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/11fbf72e/attachment.html>

From luke at dashjr.org  Wed May 13 16:34:52 2015
From: luke at dashjr.org (Luke Dashjr)
Date: Wed, 13 May 2015 16:34:52 +0000
Subject: [Bitcoin-development] [BIP] Normalized Transaction IDs
In-Reply-To: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
References: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
Message-ID: <201505131634.53563.luke@dashjr.org>

I think this hardfork is dead-on-arrival given the ideas for OP_CHECKSIG 
softforking. Instead of referring to previous transactions by a normalised 
hash, it makes better sense to simply change the outpoints in the signed data 
and allow nodes to hotfix dependent transactions when/if they are malleated. 
Furthermore, the approach of using a hash of scriptPubKey in the input rather 
than an outpoint also solves dependencies in the face of intentional 
malleability (respending with a higher fee, or CoinJoin, for a few examples).

These aren't barriers to making the proposal or being assigned a BIP number if 
you want to go forward with that, but you may wish to reconsider spending time 
on it.

Luke


On Wednesday, May 13, 2015 12:48:04 PM Christian Decker wrote:
> Hi All,
> 
> I'd like to propose a BIP to normalize transaction IDs in order to address
> transaction malleability and facilitate higher level protocols.
> 
> The normalized transaction ID is an alias used in parallel to the current
> (legacy) transaction IDs to address outputs in transactions. It is
> calculated by removing (zeroing) the scriptSig before computing the hash,
> which ensures that only data whose integrity is also guaranteed by the
> signatures influences the hash. Thus if anything causes the normalized ID
> to change it automatically invalidates the signature. When validating a
> client supporting this BIP would use both the normalized tx ID as well as
> the legacy tx ID when validating transactions.
> 
> The detailed writeup can be found here:
> https://github.com/cdecker/bips/blob/normalized-txid/bip-00nn.mediawiki.
> 
> @gmaxwell: I'd like to request a BIP number, unless there is something
> really wrong with the proposal.
> 
> In addition to being a simple alternative that solves transaction
> malleability it also hugely simplifies higher level protocols. We can now
> use template transactions upon which sequences of transactions can be built
> before signing them.
> 
> I hesitated quite a while to propose it since it does require a hardfork
> (old clients would not find the prevTx identified by the normalized
> transaction ID and deem the spending transaction invalid), but it seems
> that hardforks are no longer the dreaded boogeyman nobody talks about.
> I left out the details of how the hardfork is to be done, as it does not
> really matter and we may have a good mechanism to apply a bunch of
> hardforks concurrently in the future.
> 
> I'm sure it'll take time to implement and upgrade, but I think it would be
> a nice addition to the functionality and would solve a long standing
> problem :-)
> 
> Please let me know what you think, the proposal is definitely not set in
> stone at this point and I'm sure we can improve it further.
> 
> Regards,
> Christian



From pieter.wuille at gmail.com  Wed May 13 17:14:07 2015
From: pieter.wuille at gmail.com (Pieter Wuille)
Date: Wed, 13 May 2015 10:14:07 -0700
Subject: [Bitcoin-development] [BIP] Normalized Transaction IDs
In-Reply-To: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
References: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
Message-ID: <CAPg+sBggj382me1ATDx4SS9KHVfvX5KH7ZhLHN6B+2_a+Emw1Q@mail.gmail.com>

Normalized transaction ids are only effectively non-malleable when all
inputs they refer to are also non-malleable (or you can have malleability
in 2nd level dependencies), so I do not believe it makes sense to allow
mixed usage of the txids at all. They do not provide the actual benefit of
guaranteed non-malleability before it becomes disallowed to use the old
mechanism. That, together with the +- resource doubling needed for the UTXO
set (as earlier mentioned) and the fact that an alternative which is only a
softfork are available, makes this a bad idea IMHO.

Unsure to what extent this has been presented on the mailinglist, but the
softfork idea is this:
* Transactions get 2 txids, one used to reference them (computed as
before), and one used in an (extended) sighash.
* The txins keep using the normal txid, so not structural changes to
Bitcoin.
* The ntxid is computed by replacing the scriptSigs in inputs by the empty
string, and by replacing the txids in txins by their corresponding ntxids.
* A new checksig operator is softforked in, which uses the ntxids in its
sighashes rather than the full txid.
* To support efficiently computing ntxids, every tx in the utxo set
(currently around 6M) stores the ntxid, but only supports lookup bu txid
still.

This does result in a system where a changed dependency indeed invalidates
the spending transaction, but the fix is trivial and can be done without
access to the private key.
On May 13, 2015 5:50 AM, "Christian Decker" <decker.christian at gmail.com>
wrote:

> Hi All,
>
> I'd like to propose a BIP to normalize transaction IDs in order to address
> transaction malleability and facilitate higher level protocols.
>
> The normalized transaction ID is an alias used in parallel to the current
> (legacy) transaction IDs to address outputs in transactions. It is
> calculated by removing (zeroing) the scriptSig before computing the hash,
> which ensures that only data whose integrity is also guaranteed by the
> signatures influences the hash. Thus if anything causes the normalized ID
> to change it automatically invalidates the signature. When validating a
> client supporting this BIP would use both the normalized tx ID as well as
> the legacy tx ID when validating transactions.
>
> The detailed writeup can be found here:
> https://github.com/cdecker/bips/blob/normalized-txid/bip-00nn.mediawiki.
>
> @gmaxwell: I'd like to request a BIP number, unless there is something
> really wrong with the proposal.
>
> In addition to being a simple alternative that solves transaction
> malleability it also hugely simplifies higher level protocols. We can now
> use template transactions upon which sequences of transactions can be built
> before signing them.
>
> I hesitated quite a while to propose it since it does require a hardfork
> (old clients would not find the prevTx identified by the normalized
> transaction ID and deem the spending transaction invalid), but it seems
> that hardforks are no longer the dreaded boogeyman nobody talks about.
> I left out the details of how the hardfork is to be done, as it does not
> really matter and we may have a good mechanism to apply a bunch of
> hardforks concurrently in the future.
>
> I'm sure it'll take time to implement and upgrade, but I think it would be
> a nice addition to the functionality and would solve a long standing
> problem :-)
>
> Please let me know what you think, the proposal is definitely not set in
> stone at this point and I'm sure we can improve it further.
>
> Regards,
> Christian
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/bb0fcadf/attachment.html>

From dgomez1092 at gmail.com  Wed May 13 17:49:04 2015
From: dgomez1092 at gmail.com (Damian Gomez)
Date: Wed, 13 May 2015 10:49:04 -0700
Subject: [Bitcoin-development] Long-term mining incentives
Message-ID: <CAH+jCTwV+koxVwVqvdWn+xXfnX9SX=yJJpFu7rvCNn6uKS8eFg@mail.gmail.com>

I hope to keep continuing this conversations. Pardon my absence, but I
don't alway feel like I have much to contribute especially if it's not
techincal.

On my part I have been a proponent, of an alterrnativ consensus, that
begins shifting away from teh current cooinbase reward system in order to
reduce mining on the whole and thus limit those who do mine to do so on a
level of integrity.


I took a look at the ethereum blog on weak subjectivity, it does seem to be
a good transtition to use a gravity schema to be implemented in a Log
Structured Merge tree  in order to find doscrepancy in forks.


Using this sama data structure could still be used in a consensus model. In
terms of how nodes communicate on teh network their speed and latency
communication are at least halfway solved based off their intereactions
(kernel software changes) with how nodes write and read memory { smp_wrb()
 || smp_rmb() } This would allow for a connection on the


Let me provide a use case:  Say that we wanted to begin a new model for
integrity, then the current value for integrity would utilize a OTS from
the previous hash in order to establish the previous owner address of the
block it was previously part of.  THE MAIN ISSUE here is being able to
verify, which value of integrity is useful for being able to establish a
genesis block. A paper by Lee & Ewe (2001) called *The Byzantine General's
Problem* gives insight as to how a  O(n^c) model is suitable to send a
message w/ value through out the system, each node is then sent a
read-invalidate request in order to change their cache logs for old system
memory in a new fixed address. Upon consensus of this value the rest of the
"brainer" {1st recipeients} nodes would be able to send a forward
propagation of  the learnt value and, after acceptance the value would then
be backpropagated to the genesis block upoon every round in orderr to set a
deterministic standard for the dynamic increase of integrity of the system.


In POW systems the nonce generated would be the accumulation of the
integrity within a system and what their computatiuonal exertion in terms
of the overall rate of integrity increase in the system as the new coinbase
-> this value then is assigned and signed to the hash and teh Merkel Root
 as two layers encoded to its base and then reencrypted using EDCSA from
the 256 to 512 bit transformation so that the new address given has a
validity that cannot be easily fingerprinted and the malleability of teh
transaction becomes much more difficult due to the overall  2 ^ 28
verification stamp provided to the new hash.   The parameters  T T r P

(Trust value)  -> foud in the new coinbase or the scriptSig
( Hidden) -> found in the Hash, and the merkel root hash
(TRust overall)  R = within the target range for  new nonces and address
locations
Paradigm (integrity) = held within the genesis block as a backpropogated
solution



Using this signature then the  nodes would then be able to communicate and
transition the memory resevres for previous transaction on the block based
on the byzantine consensus. What noone has yet mentioned which I have
forgotten too, is how these datacenters of pool woul be supported w/out
fees. I will thrw that one out to all of you.  The current consensus system
leaves room for orp[haned transactions if there were miltiple signature
requests the queue would be lined up based off integrity values in order to
have the most effective changes occcur first.

I have some more thoughts and will continue working on the techinical
vernacular and how a noob developer and decent computer science student
could make such an mplementation a reality.  Thanks in advance for
listengin to this.



<Thank you to Greg Maxwell for allowing us to liosten to his talk online,
was hearing while writing this.>  And to Krzysztof Okupsi and Paul
McKenny(Memory Barriers Hardware View for Software hackers) for their help
in nudging my brain and the relentles people behind the scenes who make all
our minds possible.







On Wed, May 13, 2015 at 4:26 AM, <
bitcoin-development-request at lists.sourceforge.net> wrote:

> Send Bitcoin-development mailing list submissions to
>         bitcoin-development at lists.sourceforge.net
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> or, via email, send a message with subject or body 'help' to
>         bitcoin-development-request at lists.sourceforge.net
>
> You can reach the person managing the list at
>         bitcoin-development-owner at lists.sourceforge.net
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of Bitcoin-development digest..."
>
> Today's Topics:
>
>    1. Re: Long-term mining incentives (Thomas Voegtlin)
>    2. Re: Long-term mining incentives (Tier Nolan)
>    3. Re: Long-term mining incentives (Alex Mizrahi)
>    4. Re: Proposed alternatives to the 20MB step        function (Tier
> Nolan)
>    5. Re: Block Size Increase (Oliver Egginger)
>    6. Re: Block Size Increase (Angel Leon)
>
>
> ---------- Forwarded message ----------
> From: Thomas Voegtlin <thomasv at electrum.org>
> To: Gavin Andresen <gavinandresen at gmail.com>, Bitcoin Dev <
> bitcoin-development at lists.sourceforge.net>
> Cc:
> Date: Wed, 13 May 2015 11:49:13 +0200
> Subject: Re: [Bitcoin-development] Long-term mining incentives
>
> Le 12/05/2015 18:10, Gavin Andresen a ?crit :
> > Added back the list, I didn't mean to reply privately:
> >
> > Fair enough, I'll try to find time in the next month or three to write up
> > four plausible future scenarios for how mining incentives might work:
> >
> > 1) Fee-supported with very large blocks containing lots of tiny-fee
> > transactions
> > 2) Proof-of-idle supported (I wish Tadge Dryja would publish his
> > proof-of-idle idea....)
> > 3) Fees purely as transaction-spam-prevention measure, chain security via
> > alternative consensus algorithm (in this scenario there is very little
> > mining).
> > 4) Fee supported with small blocks containing high-fee transactions
> moving
> > coins to/from sidechains.
> >
> > Would that be helpful, or do you have some reason for thinking that we
> > should pick just one and focus all of our efforts on making that one
> > scenario happen?
> >
> > I always think it is better, when possible, not to "bet on one horse."
> >
>
> Sorry if I did not make myself clear. It is not about betting on one
> single horse, or about making one particular scenario happen. It is not
> about predicting whether something else will replace PoW in the future,
> and I am in no way asking you to focus your efforts in one particular
> direction at the expenses of others. Various directions will be explored
> by various people, and that's great.
>
> I am talking about what we know today. I would like an answer to the
> following question: Do we have a reason to believe that Bitcoin can work
> in the long run, without involving technologies that have not been
> invented yet? Is there a single scenario that we know could work?
>
> Exotic and unproven technologies are not an answer to that question. The
> reference scenario should be as boring as possible, and as verifiable as
> possible. I am not asking what you think is the most likely to happen,
> but what is the most likely to work, given the knowledge we have today.
>
> If I was asking: "Can we send humans to the moon by 2100?", I guess your
> answer would be: "Yes we can, because it has been done in the past with
> chemical rockets, and we know how to build them". You would probably not
> use a space elevator in your answer.
>
> The reason I am asking that is, there seems to be no consensus among
> core developers on how Bitcoin can work without miner subsidy. How it
> *will* work is another question.
>
>
>
>
> ---------- Forwarded message ----------
> From: Tier Nolan <tier.nolan at gmail.com>
> To:
> Cc: Bitcoin Dev <bitcoin-development at lists.sourceforge.net>
> Date: Wed, 13 May 2015 11:14:06 +0100
> Subject: Re: [Bitcoin-development] Long-term mining incentives
> On Wed, May 13, 2015 at 10:49 AM, Thomas Voegtlin <thomasv at electrum.org>
> wrote:
>
>>
>> The reason I am asking that is, there seems to be no consensus among
>> core developers on how Bitcoin can work without miner subsidy. How it
>> *will* work is another question.
>>
>
> The position seems to be that it will continue to work for the time being,
> so there is still time for more research.
>
> Proof of stake has problems with handling long term reversals.  The main
> proposal is to slightly weaken the security requirements.
>
> With POW, a new node only needs to know the genesis block (and network
> rules) to fully determine which of two chains is the strongest.
>
> Penalties for abusing POS inherently create a time horizon.  A suggested
> POS security model would assume that a full node is a node that resyncs
> with the network regularly (every N blocks).    N would be depend on the
> network rules of the coin.
>
> The alternative is that 51% of the holders of coins at the genesis block
> can rewrite the entire chain.  The genesis block might not be the first
> block, a POS coin might still use POW for minting.
>
>
> https://blog.ethereum.org/2014/11/25/proof-stake-learned-love-weak-subjectivity/
>
>
> ---------- Forwarded message ----------
> From: Alex Mizrahi <alex.mizrahi at gmail.com>
> To: Bitcoin Dev <bitcoin-development at lists.sourceforge.net>
> Cc:
> Date: Wed, 13 May 2015 13:31:47 +0300
> Subject: Re: [Bitcoin-development] Long-term mining incentives
>
>
>> With POW, a new node only needs to know the genesis block (and network
>> rules) to fully determine which of two chains is the strongest.
>>
>
> But this matters if a new node has access to the globally strongest chain.
> If attacker is able to block connections to legitimate nodes, a new node
> will happily accept attacker's chain.
>
> So PoW, by itself, doesn't give strong security guarantees. This problem
> is so fundamental people avoid talking about it.
>
> In practice, Bitcoin already embraces "weak subjectivity" e.g. in form of
> checkpoints embedded into the source code. So it's hard to take PoW purists
> seriously.
>
>
> ---------- Forwarded message ----------
> From: Tier Nolan <tier.nolan at gmail.com>
> To:
> Cc: Bitcoin Development <bitcoin-development at lists.sourceforge.net>
> Date: Wed, 13 May 2015 11:43:08 +0100
> Subject: Re: [Bitcoin-development] Proposed alternatives to the 20MB step
> function
> On Sat, May 9, 2015 at 4:36 AM, Gregory Maxwell <gmaxwell at gmail.com>
> wrote:
>
>> An example would
>> be tx_size = MAX( real_size >> 1,  real_size + 4*utxo_created_size -
>> 3*utxo_consumed_size).
>
>
> This could be implemented as a soft fork too.
>
> * 1MB hard size limit
> * 900kB soft limit
>
> S = block size
> U = UTXO_adjusted_size = S + 4 * outputs - 3 * inputs
>
> A block is valid if S < 1MB and U < 1MB
>
> A 250 byte transaction with 2 inputs and 2 outputs would have an adjusted
> size of 252 bytes.
>
> The memory pool could be sorted by fee per adjusted_size.
>
>  Coin selection could be adjusted so it tries to have at least 2 inputs
> when creating transactions, unless the input is worth more than a threshold
> (say 0.001 BTC).
>
> This is a pretty weak incentive, especially if the block size is
> increased.  Maybe it will cause a "nudge"
>
>
> ---------- Forwarded message ----------
> From: Oliver Egginger <bitcoin at olivere.de>
> To: bitcoin-development at lists.sourceforge.net
> Cc:
> Date: Wed, 13 May 2015 12:37:17 +0200
> Subject: Re: [Bitcoin-development] Block Size Increase
> 08.05.2015 at 5:49 Jeff Garzik wrote:
> > To repeat, the very first point in my email reply was: "Agree that 7 tps
> > is too low"
>
> For interbank trading that would maybe enough but I don't know.
>
> I'm not a developer but as a (former) user and computer scientist I'm
> also asking myself what is the core of the problem? Personally, for
> privacy reasons I do not want to leave a footprint in the blockchain for
> each pizza. And why should this expense be good for trivial things of
> everyday life?
>
> If one encounters the block boundary, he or she will do more effort or
> give up. I'm thinking most people will give up because their
> transactions are not really economical. It is much better for them to
> use third-partys (or another payment system).
>
> And that's where we are at the heart of the problem. The Bitcoin
> third-party economy. With few exceptions this is pure horror. More worse
> than any used car dealer. And the community just waits that things get
> better. But that will never happen of its own accord. We are living in a
> Wild West Town. So we need a Sheriff and many other things.
>
> We need a small but good functioning economy around the blockchain. To
> create one, we have to accept a few unpleasant truths. I do not know if
> the community is ready for it.
>
> Nevertheless, I know that some companies do a good job. But they have to
> prevail against their dishonest competitors.
>
> People take advantage of the blockchain, because they no longer trust
> anyone. But this will not scale in the long run.
>
> - oliver
>
>
>
>
>
>
>
>
>
>
>
> ---------- Forwarded message ----------
> From: Angel Leon <gubatron at gmail.com>
> To: Oliver Egginger <bitcoin at olivere.de>
> Cc: Bitcoin Dev <bitcoin-development at lists.sourceforge.net>
> Date: Wed, 13 May 2015 07:25:47 -0400
> Subject: Re: [Bitcoin-development] Block Size Increase
> > Personally, for privacy reasons I do not want to leave a footprint in
> the blockchain for each pizza. And  why should this expense be good for
> trivial things of everyday life?
>
> Then what's the point?
> Isn't this supposed to be an Open transactional network, it doesn't matter
> if you don't want that, what matters is what people want to do with it, and
> there's nothing you can do to stop someone from opening a wallet and buying
> a pizza with it, except the core of the problem you ask yourself about,
> which is, the minute this goes mainstream and people get their wallets out
> the whole thing will collapse, regardless of what you want the blockchain
> for.
>
> Why talk about the billions of unbanked and all the romantic vision if you
> can't let them use their money however they want in a decentralized
> fashion. Otherwise let's just go back to centralized banking because the
> minute you want to put things off chain, you need an organization that will
> need to respond to government regulation and that's the end for the
> billions of unbanked to be part of the network.
>
>
> http://twitter.com/gubatron
>
> On Wed, May 13, 2015 at 6:37 AM, Oliver Egginger <bitcoin at olivere.de>
> wrote:
>
>> 08.05.2015 at 5:49 Jeff Garzik wrote:
>> > To repeat, the very first point in my email reply was: "Agree that 7 tps
>> > is too low"
>>
>> For interbank trading that would maybe enough but I don't know.
>>
>> I'm not a developer but as a (former) user and computer scientist I'm
>> also asking myself what is the core of the problem? Personally, for
>> privacy reasons I do not want to leave a footprint in the blockchain for
>> each pizza. And why should this expense be good for trivial things of
>> everyday life?
>>
>> If one encounters the block boundary, he or she will do more effort or
>> give up. I'm thinking most people will give up because their
>> transactions are not really economical. It is much better for them to
>> use third-partys (or another payment system).
>>
>> And that's where we are at the heart of the problem. The Bitcoin
>> third-party economy. With few exceptions this is pure horror. More worse
>> than any used car dealer. And the community just waits that things get
>> better. But that will never happen of its own accord. We are living in a
>> Wild West Town. So we need a Sheriff and many other things.
>>
>> We need a small but good functioning economy around the blockchain. To
>> create one, we have to accept a few unpleasant truths. I do not know if
>> the community is ready for it.
>>
>> Nevertheless, I know that some companies do a good job. But they have to
>> prevail against their dishonest competitors.
>>
>> People take advantage of the blockchain, because they no longer trust
>> anyone. But this will not scale in the long run.
>>
>> - oliver
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> ------------------------------------------------------------------------------
>> One dashboard for servers and applications across Physical-Virtual-Cloud
>> Widest out-of-the-box monitoring support with 50+ applications
>> Performance metrics, stats and reports that give you Actionable Insights
>> Deep dive visibility with transaction tracing using APM Insight.
>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/198e7dd0/attachment.html>

From decker.christian at gmail.com  Wed May 13 18:04:54 2015
From: decker.christian at gmail.com (Christian Decker)
Date: Wed, 13 May 2015 18:04:54 +0000
Subject: [Bitcoin-development] [BIP] Normalized Transaction IDs
In-Reply-To: <CAPg+sBggj382me1ATDx4SS9KHVfvX5KH7ZhLHN6B+2_a+Emw1Q@mail.gmail.com>
References: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
	<CAPg+sBggj382me1ATDx4SS9KHVfvX5KH7ZhLHN6B+2_a+Emw1Q@mail.gmail.com>
Message-ID: <CALxbBHU-0huAs_y3cZCfmKKAAq3LHut8DwdSGm+1Rym3pb9j2A@mail.gmail.com>

If the inputs to my transaction have been long confirmed I can be
reasonably safe in assuming that the transaction hash does not change
anymore. It's true that I have to be careful not to build on top of
transactions that use legacy references to transactions that are
unconfirmed or have few confirmations, however that does not invalidate the
utility of the normalized transaction IDs.

The resource doubling is not optimal, I agree, but compare that to dragging
around malleability and subsequent hacks to sort-of fix it forever.
Additionally if we were to decide to abandon legacy transaction IDs we
could eventually drop the legacy index after a sufficient transition period.

I remember reading about the SIGHASH proposal somewhere. It feels really
hackish to me: It is a substantial change to the way signatures are
verified, I cannot really see how this is a softfork if clients that did
not update are unable to verify transactions using that SIGHASH Flag and it
is adding more data (the normalized hash) to the script, which has to be
stored as part of the transaction. It may be true that a node observing
changes in the input transactions of a transaction using this flag could
fix the problem, however it requires the node's intervention.

Compare that to the simple and clean solution in the proposal, which does
not add extra data to be stored, keeps the OP_*SIG* semantics as they are
and where once you sign a transaction it does not have to be monitored or
changed in order to be valid.

There certainly are merits using the SIGHASH approach in the short term (it
does not require a hard fork), however I think the normalized transaction
ID is a cleaner and simpler long-term solution, even though it requires a
hard-fork.

Regards,
Christian

On Wed, May 13, 2015 at 7:14 PM Pieter Wuille <pieter.wuille at gmail.com>
wrote:

> Normalized transaction ids are only effectively non-malleable when all
> inputs they refer to are also non-malleable (or you can have malleability
> in 2nd level dependencies), so I do not believe it makes sense to allow
> mixed usage of the txids at all. They do not provide the actual benefit of
> guaranteed non-malleability before it becomes disallowed to use the old
> mechanism. That, together with the +- resource doubling needed for the UTXO
> set (as earlier mentioned) and the fact that an alternative which is only a
> softfork are available, makes this a bad idea IMHO.
>
> Unsure to what extent this has been presented on the mailinglist, but the
> softfork idea is this:
> * Transactions get 2 txids, one used to reference them (computed as
> before), and one used in an (extended) sighash.
> * The txins keep using the normal txid, so not structural changes to
> Bitcoin.
> * The ntxid is computed by replacing the scriptSigs in inputs by the empty
> string, and by replacing the txids in txins by their corresponding ntxids.
> * A new checksig operator is softforked in, which uses the ntxids in its
> sighashes rather than the full txid.
> * To support efficiently computing ntxids, every tx in the utxo set
> (currently around 6M) stores the ntxid, but only supports lookup bu txid
> still.
>
> This does result in a system where a changed dependency indeed invalidates
> the spending transaction, but the fix is trivial and can be done without
> access to the private key.
> On May 13, 2015 5:50 AM, "Christian Decker" <decker.christian at gmail.com>
> wrote:
>
>> Hi All,
>>
>> I'd like to propose a BIP to normalize transaction IDs in order to
>> address transaction malleability and facilitate higher level protocols.
>>
>> The normalized transaction ID is an alias used in parallel to the current
>> (legacy) transaction IDs to address outputs in transactions. It is
>> calculated by removing (zeroing) the scriptSig before computing the hash,
>> which ensures that only data whose integrity is also guaranteed by the
>> signatures influences the hash. Thus if anything causes the normalized ID
>> to change it automatically invalidates the signature. When validating a
>> client supporting this BIP would use both the normalized tx ID as well as
>> the legacy tx ID when validating transactions.
>>
>> The detailed writeup can be found here:
>> https://github.com/cdecker/bips/blob/normalized-txid/bip-00nn.mediawiki.
>>
>> @gmaxwell: I'd like to request a BIP number, unless there is something
>> really wrong with the proposal.
>>
>> In addition to being a simple alternative that solves transaction
>> malleability it also hugely simplifies higher level protocols. We can now
>> use template transactions upon which sequences of transactions can be built
>> before signing them.
>>
>> I hesitated quite a while to propose it since it does require a hardfork
>> (old clients would not find the prevTx identified by the normalized
>> transaction ID and deem the spending transaction invalid), but it seems
>> that hardforks are no longer the dreaded boogeyman nobody talks about.
>> I left out the details of how the hardfork is to be done, as it does not
>> really matter and we may have a good mechanism to apply a bunch of
>> hardforks concurrently in the future.
>>
>> I'm sure it'll take time to implement and upgrade, but I think it would
>> be a nice addition to the functionality and would solve a long standing
>> problem :-)
>>
>> Please let me know what you think, the proposal is definitely not set in
>> stone at this point and I'm sure we can improve it further.
>>
>> Regards,
>> Christian
>>
>>
>> ------------------------------------------------------------------------------
>> One dashboard for servers and applications across Physical-Virtual-Cloud
>> Widest out-of-the-box monitoring support with 50+ applications
>> Performance metrics, stats and reports that give you Actionable Insights
>> Deep dive visibility with transaction tracing using APM Insight.
>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/4a02d331/attachment.html>

From tier.nolan at gmail.com  Wed May 13 18:11:30 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Wed, 13 May 2015 19:11:30 +0100
Subject: [Bitcoin-development] [BIP] Normalized Transaction IDs
In-Reply-To: <CAPg+sBggj382me1ATDx4SS9KHVfvX5KH7ZhLHN6B+2_a+Emw1Q@mail.gmail.com>
References: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
	<CAPg+sBggj382me1ATDx4SS9KHVfvX5KH7ZhLHN6B+2_a+Emw1Q@mail.gmail.com>
Message-ID: <CAE-z3OV1WEDEV+X7gNVx+qBMt4jpSHFKXm3dxUrUyBEJrCNDSQ@mail.gmail.com>

On Wed, May 13, 2015 at 6:14 PM, Pieter Wuille <pieter.wuille at gmail.com>
wrote:

> Normalized transaction ids are only effectively non-malleable when all
> inputs they refer to are also non-malleable (or you can have malleability
> in 2nd level dependencies), so I do not believe it makes sense to allow
> mixed usage of the txids at all.
>

The txid or txid-norm is signed, so can't be changed after signing.

The hard fork is to allow transactions to refer to their inputs by txid or
txid-norm.  You pick one before signing.

> They do not provide the actual benefit of guaranteed non-malleability
> before it becomes disallowed to use the old mechanism.
>
A signed transaction cannot have its txid changed.  It is true that users
of the system would have to use txid-norm.

The basic refund transaction is as follows.

 A creates TX1: "Pay w BTC to <B's public key> if signed by A & B"

 A creates TX2: "Pay w BTC from TX1-norm to <A's public key>, locked 48
hours in the future, signed by A"

 A sends TX2 to B

 B signs TX2 and returns to A

A broadcasts TX1.  It is mutated before entering the chain to become
TX1-mutated.

A can still submit TX2 to the blockchain, since TX1 and TX1-mutated have
the same txid-norm.

>
> That, together with the +- resource doubling needed for the UTXO set (as
> earlier mentioned) and the fact that an alternative which is only a
> softfork are available, makes this a bad idea IMHO.
>
> Unsure to what extent this has been presented on the mailinglist, but the
> softfork idea is this:
> * Transactions get 2 txids, one used to reference them (computed as
> before), and one used in an (extended) sighash.
> * The txins keep using the normal txid, so not structural changes to
> Bitcoin.
> * The ntxid is computed by replacing the scriptSigs in inputs by the empty
> string, and by replacing the txids in txins by their corresponding ntxids.
> * A new checksig operator is softforked in, which uses the ntxids in its
> sighashes rather than the full txid.
> * To support efficiently computing ntxids, every tx in the utxo set
> (currently around 6M) stores the ntxid, but only supports lookup bu txid
> still.
>
> This does result in a system where a changed dependency indeed invalidates
> the spending transaction, but the fix is trivial and can be done without
> access to the private key.
>
The problem with this is that 2 level malleability is not protected against.

C spends B which spends A.

A is mutated before it hits the chain.  The only change in A is in the
scriptSig.

B can be converted to B-new without breaking the signature.  This is
because the only change to A was in the sciptSig, which is dropped when
computing the txid-norm.

B-new spends A-mutated.  B-new is different from B in a different place.
The txid it uses to refer to the previous output is changed.

The signed transaction C cannot be converted to a valid C-new.  The txid of
the input points to B.  It is updated to point at B-new.  B-new and B don't
have the same txid-norm, since the change is outside the scriptSig.  This
means that the signature for C is invalid.

The txid replacements should be done recursively.  All input txids should
be replaced by txid-norms when computing the txid-norm for the
transaction.  I think this repairs the problem with only allowing one level?

Computing txid-norm:

- replace all txids in inputs with txid-norms of those transactions
- replace all input scriptSigs with empty scripts
- transaction hash is txid-norm for that transaction

The same situation as above is not fatal now.

C spends B which spends A.

A is mutated before it hits the chain.  The only change in A is in the
scriptSig.

B can be converted to B-new without breaking the signature.  This is
because the only change to A was in the sciptSig, which is dropped when
computing the txid-norm (as before).

B-new spends A mutated.  B-new is different from B in for the previous
inputs.

The input for B-new points to A-mutated.  When computing the txid-norm,
that would be replaced with the txid-norm for A.

Similarly, the input for B points to A and that would have been replaced
with the txid-norm for A.

This means that B and B-new have the same txid-norm.

The signed transaction C can be converted to a valid C-new.  The txid of
the input points to B.  It is updated to point at B-new.  B-new and B now
have have the same txid-norm and so C is valid.

I think this reasoning is valid, but probably needs writing out actual
serializations.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/b02d5c75/attachment.html>

From pieter.wuille at gmail.com  Wed May 13 18:40:34 2015
From: pieter.wuille at gmail.com (Pieter Wuille)
Date: Wed, 13 May 2015 11:40:34 -0700
Subject: [Bitcoin-development] [BIP] Normalized Transaction IDs
In-Reply-To: <CALxbBHU-0huAs_y3cZCfmKKAAq3LHut8DwdSGm+1Rym3pb9j2A@mail.gmail.com>
References: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
	<CAPg+sBggj382me1ATDx4SS9KHVfvX5KH7ZhLHN6B+2_a+Emw1Q@mail.gmail.com>
	<CALxbBHU-0huAs_y3cZCfmKKAAq3LHut8DwdSGm+1Rym3pb9j2A@mail.gmail.com>
Message-ID: <CAPg+sBjX=u4Osbzr+25w-5QzzhWGKryzW2K-0Xu3gS0eJXUUDw@mail.gmail.com>

On Wed, May 13, 2015 at 11:04 AM, Christian Decker <
decker.christian at gmail.com> wrote:

> If the inputs to my transaction have been long confirmed I can be
> reasonably safe in assuming that the transaction hash does not change
> anymore. It's true that I have to be careful not to build on top of
> transactions that use legacy references to transactions that are
> unconfirmed or have few confirmations, however that does not invalidate the
> utility of the normalized transaction IDs.
>

Sufficient confirmations help of course, but make systems like this less
useful for more complex interactions where you have multiple unconfirmed
transactions waiting on each other. I think being able to rely on this
problem being solved unconditionally is what makes the proposal attractive.
For the simple cases, see BIP62.

I remember reading about the SIGHASH proposal somewhere. It feels really
> hackish to me: It is a substantial change to the way signatures are
> verified, I cannot really see how this is a softfork if clients that did
> not update are unable to verify transactions using that SIGHASH Flag and it
> is adding more data (the normalized hash) to the script, which has to be
> stored as part of the transaction. It may be true that a node observing
> changes in the input transactions of a transaction using this flag could
> fix the problem, however it requires the node's intervention.
>

I think you misunderstand the idea. This is related, but orthogonal to the
ideas about extended the sighash flags that have been discussed here before.

All it's doing is adding a new CHECKSIG operator to script, which, in its
internally used signature hash, 1) removes the scriptSigs from transactions
before hashing 2) replaces the txids in txins by their ntxid. It does not
add any data to transactions, and it is a softfork, because it only impacts
scripts which actually use the new CHECKSIG operator. Wallets that don't
support signing with this new operator would not give out addresses that
use it.

>
> Compare that to the simple and clean solution in the proposal, which does
> not add extra data to be stored, keeps the OP_*SIG* semantics as they are
> and where once you sign a transaction it does not have to be monitored or
> changed in order to be valid.
>

OP_*SIG* semantics don't change here either, we're just adding a superior
opcode (which in most ways behaves the same as the existing operators). I
agree with the advantage of not needing to monitor transactions afterwards
for malleated inputs, but I think you underestimate the deployment costs.
If you want to upgrade the world (eventually, after the old index is
dropped, which is IMHO the only point where this proposal becomes superior
to the alternatives) to this, you're changing *every single piece of
Bitcoin software on the planet*. This is not just changing some validation
rules that are opt-in to use, you're fundamentally changing how
transactions refer to each other.

Also, what do blocks commit to? Do you keep using the old transaction ids
for this? Because if you don't, any relayer on the network can invalidate a
block (and have the receiver mark it as invalid) by changing the txids. You
need to somehow commit to the scriptSig data in blocks still so the POW of
a block is invalidated by changing a scriptSig.

There certainly are merits using the SIGHASH approach in the short term (it
> does not require a hard fork), however I think the normalized transaction
> ID is a cleaner and simpler long-term solution, even though it requires a
> hard-fork.
>

It requires a hard fork, but more importantly, it requires the whole world
to change their software (not just validation code) to effectively use it.
That, plus large up-front deployment costs (doubling the cache size for
every full node for the same propagation speed is not a small thing) which
may not end up being effective.

-- 
Pieter
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/dfcb3945/attachment.html>

From decker.christian at gmail.com  Wed May 13 19:14:57 2015
From: decker.christian at gmail.com (Christian Decker)
Date: Wed, 13 May 2015 19:14:57 +0000
Subject: [Bitcoin-development] [BIP] Normalized Transaction IDs
In-Reply-To: <CAPg+sBjX=u4Osbzr+25w-5QzzhWGKryzW2K-0Xu3gS0eJXUUDw@mail.gmail.com>
References: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
	<CAPg+sBggj382me1ATDx4SS9KHVfvX5KH7ZhLHN6B+2_a+Emw1Q@mail.gmail.com>
	<CALxbBHU-0huAs_y3cZCfmKKAAq3LHut8DwdSGm+1Rym3pb9j2A@mail.gmail.com>
	<CAPg+sBjX=u4Osbzr+25w-5QzzhWGKryzW2K-0Xu3gS0eJXUUDw@mail.gmail.com>
Message-ID: <CALxbBHWyhTTbRAdWbeGp+fdKRif=ghh7W6eP-vak7jHdot6uJA@mail.gmail.com>

On Wed, May 13, 2015 at 8:40 PM Pieter Wuille <pieter.wuille at gmail.com>
wrote:

> On Wed, May 13, 2015 at 11:04 AM, Christian Decker <
> decker.christian at gmail.com> wrote:
>
>> If the inputs to my transaction have been long confirmed I can be
>> reasonably safe in assuming that the transaction hash does not change
>> anymore. It's true that I have to be careful not to build on top of
>> transactions that use legacy references to transactions that are
>> unconfirmed or have few confirmations, however that does not invalidate the
>> utility of the normalized transaction IDs.
>>
>
> Sufficient confirmations help of course, but make systems like this less
> useful for more complex interactions where you have multiple unconfirmed
> transactions waiting on each other. I think being able to rely on this
> problem being solved unconditionally is what makes the proposal attractive.
> For the simple cases, see BIP62.
>

If we are building a long running contract using a complex chain of
transactions, or multiple transactions that depend on each other, there is
no point in ever using any malleable legacy transaction IDs and I would
simply stop cooperating if you tried. I don't think your argument applies.
If we build our contract using only normalized transaction IDs there is no
way of suffering any losses due to malleability.

The reason I mentioned the confirmation is that all protocols I can think
of start by collaboratively creating a transaction that locks in funds into
a multisig output, that is committed to the blockchain. Starting from this
initial setup transaction would be using normalized transaction IDs,
therefore not be susceptible to malleability.


>
> I remember reading about the SIGHASH proposal somewhere. It feels really
>> hackish to me: It is a substantial change to the way signatures are
>> verified, I cannot really see how this is a softfork if clients that did
>> not update are unable to verify transactions using that SIGHASH Flag and it
>> is adding more data (the normalized hash) to the script, which has to be
>> stored as part of the transaction. It may be true that a node observing
>> changes in the input transactions of a transaction using this flag could
>> fix the problem, however it requires the node's intervention.
>>
>
> I think you misunderstand the idea. This is related, but orthogonal to the
> ideas about extended the sighash flags that have been discussed here before.
>
> All it's doing is adding a new CHECKSIG operator to script, which, in its
> internally used signature hash, 1) removes the scriptSigs from transactions
> before hashing 2) replaces the txids in txins by their ntxid. It does not
> add any data to transactions, and it is a softfork, because it only impacts
> scripts which actually use the new CHECKSIG operator. Wallets that don't
> support signing with this new operator would not give out addresses that
> use it.
>

In that case I don't think I heard this proposal before, and I might be
missing out :-)
So if transaction B spends an output from A, then the input from B contains
the CHECKSIG operator telling the validating client to do what exactly? It
appears that it wants us to go and fetch A, normalize it, put the
normalized hash in the txIn of B and then continue the validation? Wouldn't
that also need a mapping from the normalized transaction ID to the legacy
transaction ID that was confirmed?

A client that did not update still would have no clue on how to handle
these transactions, since it simply does not understand the CHECKSIG
operator. If such a transaction ends up in a block I cannot even catch up
with the network since the transaction does not validate for me.

Could you provide an example of how this works?


>
>> Compare that to the simple and clean solution in the proposal, which does
>> not add extra data to be stored, keeps the OP_*SIG* semantics as they are
>> and where once you sign a transaction it does not have to be monitored or
>> changed in order to be valid.
>>
>
> OP_*SIG* semantics don't change here either, we're just adding a superior
> opcode (which in most ways behaves the same as the existing operators). I
> agree with the advantage of not needing to monitor transactions afterwards
> for malleated inputs, but I think you underestimate the deployment costs.
> If you want to upgrade the world (eventually, after the old index is
> dropped, which is IMHO the only point where this proposal becomes superior
> to the alternatives) to this, you're changing *every single piece of
> Bitcoin software on the planet*. This is not just changing some validation
> rules that are opt-in to use, you're fundamentally changing how
> transactions refer to each other.
>

As I mentioned before, this is a really long term strategy, hoping to get
the cleanest and easiest solution, so that we do not further complicate the
inner workings of Bitcoin. I don't think that it is completely out of
question to eventually upgrade to use normalized transactions, after all
the average lifespan of hardware is a few years tops.


>
> Also, what do blocks commit to? Do you keep using the old transaction ids
> for this? Because if you don't, any relayer on the network can invalidate a
> block (and have the receiver mark it as invalid) by changing the txids. You
> need to somehow commit to the scriptSig data in blocks still so the POW of
> a block is invalidated by changing a scriptSig.
>

How could I change the transaction IDs if I am a relayer? The miner decides
which flavor of IDs it is adding into its merkle tree, the block hash locks
in the choice. If we saw a transaction having a valid sigScript, it does
not matter how we reference it in the block.


>
> There certainly are merits using the SIGHASH approach in the short term
>> (it does not require a hard fork), however I think the normalized
>> transaction ID is a cleaner and simpler long-term solution, even though it
>> requires a hard-fork.
>>
>
> It requires a hard fork, but more importantly, it requires the whole world
> to change their software (not just validation code) to effectively use it.
> That, plus large up-front deployment costs (doubling the cache size for
> every full node for the same propagation speed is not a small thing) which
> may not end up being effective.
>

Yes, hard forks are hard, I'm under no illusion that pushing such a change
through takes time, but in the end the advantages will prevail.

I didn't want to put it in the initial proposal, but we could also increase
the transaction version which signals to the client that the transaction
may only be referenced by the normalized transaction ID. So every
transaction would be either in one index or the other, reducing the
deployment cost to almost nothing.


>
> --
> Pieter
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/4e66a7fe/attachment.html>

From pieter.wuille at gmail.com  Wed May 13 19:40:54 2015
From: pieter.wuille at gmail.com (Pieter Wuille)
Date: Wed, 13 May 2015 12:40:54 -0700
Subject: [Bitcoin-development] [BIP] Normalized Transaction IDs
In-Reply-To: <CALxbBHWyhTTbRAdWbeGp+fdKRif=ghh7W6eP-vak7jHdot6uJA@mail.gmail.com>
References: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
	<CAPg+sBggj382me1ATDx4SS9KHVfvX5KH7ZhLHN6B+2_a+Emw1Q@mail.gmail.com>
	<CALxbBHU-0huAs_y3cZCfmKKAAq3LHut8DwdSGm+1Rym3pb9j2A@mail.gmail.com>
	<CAPg+sBjX=u4Osbzr+25w-5QzzhWGKryzW2K-0Xu3gS0eJXUUDw@mail.gmail.com>
	<CALxbBHWyhTTbRAdWbeGp+fdKRif=ghh7W6eP-vak7jHdot6uJA@mail.gmail.com>
Message-ID: <CAPg+sBh=KGLMyRmLfPujNuPnfmwpcsC2F8McypyTkCAcj=EaXw@mail.gmail.com>

On Wed, May 13, 2015 at 12:14 PM, Christian Decker <
decker.christian at gmail.com> wrote:

>
> On Wed, May 13, 2015 at 8:40 PM Pieter Wuille <pieter.wuille at gmail.com>
> wrote:
>
>> On Wed, May 13, 2015 at 11:04 AM, Christian Decker <
>> decker.christian at gmail.com> wrote:
>>
>>> If the inputs to my transaction have been long confirmed I can be
>>> reasonably safe in assuming that the transaction hash does not change
>>> anymore. It's true that I have to be careful not to build on top of
>>> transactions that use legacy references to transactions that are
>>> unconfirmed or have few confirmations, however that does not invalidate the
>>> utility of the normalized transaction IDs.
>>>
>>
>> Sufficient confirmations help of course, but make systems like this less
>> useful for more complex interactions where you have multiple unconfirmed
>> transactions waiting on each other. I think being able to rely on this
>> problem being solved unconditionally is what makes the proposal attractive.
>> For the simple cases, see BIP62.
>>
>
> If we are building a long running contract using a complex chain of
> transactions, or multiple transactions that depend on each other, there is
> no point in ever using any malleable legacy transaction IDs and I would
> simply stop cooperating if you tried. I don't think your argument applies.
> If we build our contract using only normalized transaction IDs there is no
> way of suffering any losses due to malleability.
>

That's correct as long as you stay within your contract, but you likely
want compatibility with other software, without waiting an age before and
after your contract settles on the chain. It's a weaker argument, though, I
agree.

I remember reading about the SIGHASH proposal somewhere. It feels really
>>> hackish to me: It is a substantial change to the way signatures are
>>> verified, I cannot really see how this is a softfork if clients that did
>>> not update are unable to verify transactions using that SIGHASH Flag and it
>>> is adding more data (the normalized hash) to the script, which has to be
>>> stored as part of the transaction. It may be true that a node observing
>>> changes in the input transactions of a transaction using this flag could
>>> fix the problem, however it requires the node's intervention.
>>>
>>
>> I think you misunderstand the idea. This is related, but orthogonal to
>> the ideas about extended the sighash flags that have been discussed here
>> before.
>>
>> All it's doing is adding a new CHECKSIG operator to script, which, in its
>> internally used signature hash, 1) removes the scriptSigs from transactions
>> before hashing 2) replaces the txids in txins by their ntxid. It does not
>> add any data to transactions, and it is a softfork, because it only impacts
>> scripts which actually use the new CHECKSIG operator. Wallets that don't
>> support signing with this new operator would not give out addresses that
>> use it.
>>
>
> In that case I don't think I heard this proposal before, and I might be
> missing out :-)
> So if transaction B spends an output from A, then the input from B
> contains the CHECKSIG operator telling the validating client to do what
> exactly? It appears that it wants us to go and fetch A, normalize it, put
> the normalized hash in the txIn of B and then continue the validation?
> Wouldn't that also need a mapping from the normalized transaction ID to the
> legacy transaction ID that was confirmed?
>

There would just be an OP_CHECKAWESOMESIG, which can do anything. It can
identical to how OP_CHECKSIG works now, but has a changed algorithm for its
signature hash algorithm. Optionally (and likely in practice, I think), it
can do various other proposed improvements, like using Schnorr signatures,
having a smaller signature encoding, supporting batch validation, have
extended sighash flags, ...

It wouldn't fetch A and normalize it; that's impossible as you would need
to go fetch all of A's dependencies too and recurse until you hit the
coinbases that produced them. Instead, your UTXO set contains the
normalized txid for every normal txid (which adds around 26% to the UTXO
set size now), but lookups in it remain only by txid.

You don't need a ntxid->txid mapping, as transactions and blocks keep
referring to transactions by txid. Only the OP_CHECKAWESOMESIG operator
would do the conversion, and at most once.

A client that did not update still would have no clue on how to handle
> these transactions, since it simply does not understand the CHECKSIG
> operator. If such a transaction ends up in a block I cannot even catch up
> with the network since the transaction does not validate for me.
>

As for every softfork, it works by redefining an OP_NOP operator, so old
nodes simply consider these checksigs unconditionally valid. That does mean
you don't want to use them before the consensus rule is forked in
(=enforced by a majority of the hashrate), and that you suffer from the
temporary security reduction that an old full node is unknowingly reduced
to SPV security for these opcodes. However, as full node wallet, this
problem does not affect you, as your wallet would simply not give out
addresses using the new opcode (and thus, wouldn't receive coins using it),
unless it was upgraded to support it.

Could you provide an example of how this works?
>
>
>>
>>> Compare that to the simple and clean solution in the proposal, which
>>> does not add extra data to be stored, keeps the OP_*SIG* semantics as they
>>> are and where once you sign a transaction it does not have to be monitored
>>> or changed in order to be valid.
>>>
>>
>> OP_*SIG* semantics don't change here either, we're just adding a superior
>> opcode (which in most ways behaves the same as the existing operators). I
>> agree with the advantage of not needing to monitor transactions afterwards
>> for malleated inputs, but I think you underestimate the deployment costs.
>> If you want to upgrade the world (eventually, after the old index is
>> dropped, which is IMHO the only point where this proposal becomes superior
>> to the alternatives) to this, you're changing *every single piece of
>> Bitcoin software on the planet*. This is not just changing some validation
>> rules that are opt-in to use, you're fundamentally changing how
>> transactions refer to each other.
>>
>
> As I mentioned before, this is a really long term strategy, hoping to get
> the cleanest and easiest solution, so that we do not further complicate the
> inner workings of Bitcoin. I don't think that it is completely out of
> question to eventually upgrade to use normalized transactions, after all
> the average lifespan of hardware is a few years tops.
>

Fair enough, I definitely agree the end result is superior in this case.

Also, what do blocks commit to? Do you keep using the old transaction ids
>> for this? Because if you don't, any relayer on the network can invalidate a
>> block (and have the receiver mark it as invalid) by changing the txids. You
>> need to somehow commit to the scriptSig data in blocks still so the POW of
>> a block is invalidated by changing a scriptSig.
>>
>
> How could I change the transaction IDs if I am a relayer? The miner
> decides which flavor of IDs it is adding into its merkle tree, the block
> hash locks in the choice. If we saw a transaction having a valid sigScript,
> it does not matter how we reference it in the block.
>

If the merkle tree of a block only commits to a transaction's normalized
hash, that means that the block hash does not change when the scriptSig is
altered. So, anyone on the network can take a random valid block, and
modify its scriptSig, and the block will become invalid _without_
invalidating the block header. This means that nodes on the network will
now classify that block header as having invalid transactions, and reject
it. Not having the ability anymore to mark blocks as invalid opens
significant DoS risks.

So yes, seeing a block with valid scriptSigs is indeed a proof the
transaction was legitimately authored. But the oppose is no longer true,
and we need that. The correct solution is to either keep using the old full
transaction ids in blocks, but ntxids everywhere else, or having some
alternative means to commit to the scriptSigs inside the block (for example
in the coinbase or using one of the more efficient block commitment
proposals), and have that enforced as consensus rule.

-- 
Pieter
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/1f2ceb1f/attachment.html>

From pedro at worcel.com  Wed May 13 20:05:55 2015
From: pedro at worcel.com (Pedro Worcel)
Date: Thu, 14 May 2015 08:05:55 +1200
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <CABsx9T0K3xQUSY26VYoJzyAGkqCfRL_xnkQUrv7M-HpOvpio5w@mail.gmail.com>
References: <5550D8BE.6070207@electrum.org>
	<ce3d34c92efd1cf57326e4679550944e@national.shitposting.agency>
	<CABsx9T1VgxEJWxrYTs+2hXGnGrSLGJ6mVcAexjXLvK7Vu+e3EA@mail.gmail.com>
	<5551F376.4050008@electrum.org>
	<CABsx9T1h7p3hDr7ty43uxsYs-oNRpndzg=dowST2tXtogxRm2g@mail.gmail.com>
	<555210AF.3090705@electrum.org>
	<CABsx9T3AxM3et7hgXx3+Rn3BvhQkF-Cn797sHcyztkMpD1UQmA@mail.gmail.com>
	<CAPS+U98sh6BmuGHWOffrmTpaM3CNfhBUWdmgACb9++jU6M1fmQ@mail.gmail.com>
	<CALqxMTGebNMARgps9mqxDSOw0cX9aeZZim82g8a4vE6sCPHq-g@mail.gmail.com>
	<CABsx9T0K3xQUSY26VYoJzyAGkqCfRL_xnkQUrv7M-HpOvpio5w@mail.gmail.com>
Message-ID: <CAPS+U9-SzQeq5v+yzK6PiZrneLP3D7o-GVaJ4w=J22DPaoJBBg@mail.gmail.com>

Thank you for your response, that does make sense. It's going to be
interesting to follow what is going to happen!

2015-05-14 3:41 GMT+12:00 Gavin Andresen <gavinandresen at gmail.com>:

> On Tue, May 12, 2015 at 7:48 PM, Adam Back <adam at cypherspace.org> wrote:
>
>> I think its fair to say no one knows how to make a consensus that
>> works in a decentralised fashion that doesnt weaken the bitcoin
>> security model without proof-of-work for now.
>>
>
> Yes.
>
>
>> I am presuming Gavin is just saying in the context of not pre-judging
>> the future that maybe in the far future another innovation might be
>> found (or alternatively maybe its not mathematically possible).
>>
>
> Yes... or an alternative might be found that weakens the Bitcoin security
> model by a small enough amount that it either doesn't matter or the
> weakening is vastly overwhelmed by some other benefit.
>
> I'm influenced by the way the Internet works; packets addressed to
> 74.125.226.67 reliably get to Google through a very decentralized system
> that I'll freely admit I don't understand. Yes, a determined attacker can
> re-route packets, but layers of security on top means re-routing packets
> isn't enough to pull off profitable attacks.
>
> I think Bitcoin's proof-of-work might evolve in a similar way. Yes, you
> might be able to 51% attack the POW, but layers of security on top of POW
> will mean that won't be enough to pull off profitable attacks.
>
>
> --
> --
> Gavin Andresen
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150514/0556dc6c/attachment.html>

From tier.nolan at gmail.com  Wed May 13 20:27:14 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Wed, 13 May 2015 21:27:14 +0100
Subject: [Bitcoin-development] [BIP] Normalized Transaction IDs
In-Reply-To: <CAE-z3OV1WEDEV+X7gNVx+qBMt4jpSHFKXm3dxUrUyBEJrCNDSQ@mail.gmail.com>
References: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
	<CAPg+sBggj382me1ATDx4SS9KHVfvX5KH7ZhLHN6B+2_a+Emw1Q@mail.gmail.com>
	<CAE-z3OV1WEDEV+X7gNVx+qBMt4jpSHFKXm3dxUrUyBEJrCNDSQ@mail.gmail.com>
Message-ID: <CAE-z3OU-fdTrKRkni4xmmY5uBVWS0KJ_2NVh6k1tcMSGTPp+4Q@mail.gmail.com>

After more thought, I think I came up with a clearer description of the
recursive version.

The simple definition is that the hash for the new signature opcode should
simply assume that the normalized txid system was used since the
beginning.  All txids in the entire blockchain should be replaced with the
"correct" values.

This requires a full re-index of the blockchain.  You can't work out what
the TXID-N of a transaction is without knowning the TXID-N of its parents,
in order to do the replacement.

The non-recursive version can only handle refunds one level deep.

A:
from: IN
sigA: based on hash(...)

B:
from A
sig: based on hash(from: TXID-N(A) | "")  // sig removed

C:
from B
sig: based on hash(from: TXID-N(B) | "")  // sig removed

If A is mutated before being added into the chain, then B can be modified
to a valid transaction (B-new).

A-mutated:
from: IN
sig_mutated: based on hash(...) with some mutation

B has to be modified to B-new to make it valid.

B-new:
from A-mutated
sig: based on hash(from: TXID-N(A-mutated), "")

Since TXID-N(A-mutated) is equal to TXID-N(A), the signature from B is
still valid.

Howver, C-new cannot be created.

C-new:
from B-new
sig: based on hash(from: TXID-N(B-new), "")

TXID-N(B-new) is not the same as TXID-N(B).  Since the from field is not
removed by the TXID-N operation, differences in that field mean that the
TXIDs are difference.

This means that the signature for C is not valid for C-new.

The recursive version repairs this problem.

Rather than simply delete the scriptSig from the transaction.  All txids
must also be replaced with their TXID-N versions.

Again, A is mutated before being added into the chain and B-new is produced.

A-mutated:
from: IN
sig_mutated: based on hash(...) with some mutation
TXID-N: TXID-N(A)

B has to be modified to B-new to make it valid.

B-new:
from A-mutated
sig: based on hash(from: TXID-N(A-mutated), "")
TXID-N: TXID-N(B)

Since TXID-N(A-mutated) is equal to TXID-N(A), the signature from B is
still valid.

Likewise the TXID-N(B-new) is equal to TXID-N(B).

The from field is replaced by the TXID-N from A-mutated which is equal to
TXID-N(A) and the sig is the same.

C-new:
from B-new
sig: based on hash(from: TXID-N(B-new), "")

The signature is still valid, since TXID-N(B-new) is the same as TXID-N(B).

This means that multi-level refunds are possible.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/39c05fa9/attachment.html>

From pieter.wuille at gmail.com  Wed May 13 20:31:06 2015
From: pieter.wuille at gmail.com (Pieter Wuille)
Date: Wed, 13 May 2015 13:31:06 -0700
Subject: [Bitcoin-development] [BIP] Normalized Transaction IDs
In-Reply-To: <CAE-z3OU-fdTrKRkni4xmmY5uBVWS0KJ_2NVh6k1tcMSGTPp+4Q@mail.gmail.com>
References: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
	<CAPg+sBggj382me1ATDx4SS9KHVfvX5KH7ZhLHN6B+2_a+Emw1Q@mail.gmail.com>
	<CAE-z3OV1WEDEV+X7gNVx+qBMt4jpSHFKXm3dxUrUyBEJrCNDSQ@mail.gmail.com>
	<CAE-z3OU-fdTrKRkni4xmmY5uBVWS0KJ_2NVh6k1tcMSGTPp+4Q@mail.gmail.com>
Message-ID: <CAPg+sBixpKQfsazHyhiF60HYTk9_U0aBAqU=4P+R+HDMA2jWKg@mail.gmail.com>

On Wed, May 13, 2015 at 1:27 PM, Tier Nolan <tier.nolan at gmail.com> wrote:

> After more thought, I think I came up with a clearer description of the
> recursive version.
>
> The simple definition is that the hash for the new signature opcode should
> simply assume that the normalized txid system was used since the
> beginning.  All txids in the entire blockchain should be replaced with the
> "correct" values.
>
> This requires a full re-index of the blockchain.  You can't work out what
> the TXID-N of a transaction is without knowning the TXID-N of its parents,
> in order to do the replacement.
>
> The non-recursive version can only handle refunds one level deep.
>

This was what I was suggesting all along, sorry if I wasn't clear.

-- 
Pieter
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/049abb31/attachment.html>

From tier.nolan at gmail.com  Wed May 13 20:32:43 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Wed, 13 May 2015 21:32:43 +0100
Subject: [Bitcoin-development] [BIP] Normalized Transaction IDs
In-Reply-To: <CAPg+sBixpKQfsazHyhiF60HYTk9_U0aBAqU=4P+R+HDMA2jWKg@mail.gmail.com>
References: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
	<CAPg+sBggj382me1ATDx4SS9KHVfvX5KH7ZhLHN6B+2_a+Emw1Q@mail.gmail.com>
	<CAE-z3OV1WEDEV+X7gNVx+qBMt4jpSHFKXm3dxUrUyBEJrCNDSQ@mail.gmail.com>
	<CAE-z3OU-fdTrKRkni4xmmY5uBVWS0KJ_2NVh6k1tcMSGTPp+4Q@mail.gmail.com>
	<CAPg+sBixpKQfsazHyhiF60HYTk9_U0aBAqU=4P+R+HDMA2jWKg@mail.gmail.com>
Message-ID: <CAE-z3OU7nCJSGk-Mx_2gmpUjQ1gXeSNDiWfhPe-5rj5bG5ArWQ@mail.gmail.com>

On Wed, May 13, 2015 at 9:31 PM, Pieter Wuille <pieter.wuille at gmail.com>
wrote:

>
> This was what I was suggesting all along, sorry if I wasn't clear.
>
>
That's great.  So, basically the multi-level refund problem is solved by
this?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/9199160d/attachment.html>

From jtimon at jtimon.cc  Thu May 14 00:11:47 2015
From: jtimon at jtimon.cc (=?UTF-8?B?Sm9yZ2UgVGltw7Nu?=)
Date: Thu, 14 May 2015 02:11:47 +0200
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <CABsx9T1VgxEJWxrYTs+2hXGnGrSLGJ6mVcAexjXLvK7Vu+e3EA@mail.gmail.com>
References: <5550D8BE.6070207@electrum.org>
	<ce3d34c92efd1cf57326e4679550944e@national.shitposting.agency>
	<CABsx9T1VgxEJWxrYTs+2hXGnGrSLGJ6mVcAexjXLvK7Vu+e3EA@mail.gmail.com>
Message-ID: <CABm2gDoQ-atjWKB0c6AC1ZQ9fy22ceFtHHwpLmnX8DLW4DAgYA@mail.gmail.com>

On Mon, May 11, 2015 at 7:29 PM, Gavin Andresen <gavinandresen at gmail.com> wrote:
> I think long-term the chain will not be secured purely by proof-of-work. I
> think when the Bitcoin network was tiny running solely on people's home
> computers proof-of-work was the right way to secure the chain, and the only
> fair way to both secure the chain and distribute the coins.
>
> See https://gist.github.com/gavinandresen/630d4a6c24ac6144482a  for some
> half-baked thoughts along those lines. I don't think proof-of-work is the
> last word in distributed consensus (I also don't think any alternatives are
> anywhere near ready to deploy, but they might be in ten years).

Or never, nobody knows at this point.

> I also think it is premature to worry about what will happen in twenty or
> thirty years when the block subsidy is insignificant. A lot will happen in
> the next twenty years. I could spin a vision of what will secure the chain
> in twenty years, but I'd put a low probability on that vision actually
> turning out to be correct.

I think is very healthy to worry about that since we know it's
something that will happen.
The system should work without subsidies.

> That is why I keep saying Bitcoin is an experiment. But I also believe that
> the incentives are correct, and there are a lot of very motivated, smart,
> hard-working people who will make it work. When you're talking about trying
> to predict what will happen decades from now, I think that is the best you
> can (honestly) do.

Lightning payment channels may be a new idea, but payment channels are
not, and nobody is using them.
They are the best solution to scalability we have right now,
increasing the block size is simply not a solution, it's just kicking
the can down the road (while reducing the incentives to deploy real
solutions like payment channels).

Not worrying about 10 years in the future but asking people to trust
estimates and speculations about how everything will burn in 2 years
if we don't act right now seems pretty arbitrary to me.
One could just as well argue that there's smart hard-working people
that will solve those problems before they hit us.

It is true that the more distant the future you're trying to predict
is, the more difficult it is to predict it, but any threshold that
separates "relevant worries" from "too far in the future to worry
about it" will always be arbitrary.
Fortunately we don't need to all share the same time horizon for what
is worrying and what is not.
What we need is a clear criterion for what is acceptable for a
hardfork and a general plan to deploy them:

-Do all the hardfork changes need to be uncontroversial? How do we
define uncontroversial?
-Should we maintain and test implementation of hardfork whises that
seem too small to justify a hardfork on their own (ie time travel fix,
allowing to sign inputs values...) to also deploy them at the same
time that other more necessary hardforks?

I agree that hardforks shouldn't be impossible and in that sense I'm
glad that you started the hardfork debate, but I believe we should be
focusing on that debate rather than the block size one.
Once we have a clear criteria, hopefully the block size debate should
become less noisy and more productive.



From pieter.wuille at gmail.com  Thu May 14 00:37:30 2015
From: pieter.wuille at gmail.com (Pieter Wuille)
Date: Wed, 13 May 2015 17:37:30 -0700
Subject: [Bitcoin-development] [BIP] Normalized Transaction IDs
In-Reply-To: <CAE-z3OU7nCJSGk-Mx_2gmpUjQ1gXeSNDiWfhPe-5rj5bG5ArWQ@mail.gmail.com>
References: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
	<CAPg+sBggj382me1ATDx4SS9KHVfvX5KH7ZhLHN6B+2_a+Emw1Q@mail.gmail.com>
	<CAE-z3OV1WEDEV+X7gNVx+qBMt4jpSHFKXm3dxUrUyBEJrCNDSQ@mail.gmail.com>
	<CAE-z3OU-fdTrKRkni4xmmY5uBVWS0KJ_2NVh6k1tcMSGTPp+4Q@mail.gmail.com>
	<CAPg+sBixpKQfsazHyhiF60HYTk9_U0aBAqU=4P+R+HDMA2jWKg@mail.gmail.com>
	<CAE-z3OU7nCJSGk-Mx_2gmpUjQ1gXeSNDiWfhPe-5rj5bG5ArWQ@mail.gmail.com>
Message-ID: <CAPg+sBjiaqsLEMz8Qskz1iWOf3VBgAnX2749uHzeyFf_seLEHQ@mail.gmail.com>

On Wed, May 13, 2015 at 1:32 PM, Tier Nolan <tier.nolan at gmail.com> wrote:

>
> On Wed, May 13, 2015 at 9:31 PM, Pieter Wuille <pieter.wuille at gmail.com>
> wrote:
>
>>
>> This was what I was suggesting all along, sorry if I wasn't clear.
>>
>> That's great.  So, basically the multi-level refund problem is solved by
> this?
>

Yes. So to be clear, I think there are 2 desirable end-goal proposals
(ignoring difficulty of changing things for a minute):

* Transactions and blocks keep referring to other transactions by full
txid, but signature hashes are computed off normalized txids (which are
recursively defined to use normalized txids all the way back to coinbases).
Is this what you are suggesting now as well?

* Blocks commit to full transaction data, but transactions and signature
hashes use normalized txids.

The benefit of the latter solution is that it doesn't need "fixing up"
transactions whose inputs have been malleated, but comes at the cost of
doing a very invasive hard fork.

-- 
Pieter
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/36bd2804/attachment.html>

From jtimon at jtimon.cc  Wed May 13 23:46:04 2015
From: jtimon at jtimon.cc (=?UTF-8?B?Sm9yZ2UgVGltw7Nu?=)
Date: Thu, 14 May 2015 01:46:04 +0200
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <CAE28kURWFveC0B-WvFebMpGm1GY-8juxQ+UDpuYtOwVnbOgu-A@mail.gmail.com>
References: <5550D8BE.6070207@electrum.org>
	<ce3d34c92efd1cf57326e4679550944e@national.shitposting.agency>
	<CABsx9T1VgxEJWxrYTs+2hXGnGrSLGJ6mVcAexjXLvK7Vu+e3EA@mail.gmail.com>
	<5551F376.4050008@electrum.org>
	<CABsx9T1h7p3hDr7ty43uxsYs-oNRpndzg=dowST2tXtogxRm2g@mail.gmail.com>
	<555210AF.3090705@electrum.org>
	<CABsx9T3AxM3et7hgXx3+Rn3BvhQkF-Cn797sHcyztkMpD1UQmA@mail.gmail.com>
	<55531E19.3090503@electrum.org>
	<CAE-z3OXa8vk6Q1EBChoRYDOLKw--CXNXz4AokXCbVam_8LFFDg@mail.gmail.com>
	<CAE28kURWFveC0B-WvFebMpGm1GY-8juxQ+UDpuYtOwVnbOgu-A@mail.gmail.com>
Message-ID: <CABm2gDoOGcdUeo_xgPp7w7AFs3Fza5VdeqSyV-T9MNhuN3RMeA@mail.gmail.com>

On Wed, May 13, 2015 at 12:31 PM, Alex Mizrahi <alex.mizrahi at gmail.com> wrote:
> But this matters if a new node has access to the globally strongest chain.
> If attacker is able to block connections to legitimate nodes, a new node
> will happily accept attacker's chain.

If you get isolated from the network you may not get the longest valid
chain. I don't think any other consensus mechanism deals with this
better than Bitcoin.

> So PoW, by itself, doesn't give strong security guarantees. This problem is
> so fundamental people avoid talking about it.
>
> In practice, Bitcoin already embraces "weak subjectivity" e.g. in form of
> checkpoints embedded into the source code. So it's hard to take PoW purists
> seriously.

Checkpoints are NOT part of the consensus rules, they're just an
optimization that can be removed.
Try keeping the genesis block as your only checkpoint and rebuild: it
will work. You can also define your own checkpoints, there's no need
for everyone to use the same ones.
In a future with committed utxo the optimization could be bigger, but
still, we shouldn't rely on checkpoints for consensus, they're just an
optimization and you should only trust checkpoints that are buried in
the chain. Trusting a committed utxo checkpoint from 2 years ago
doesn't seem very risky. If the code is not already done (not really
sure if it was done as part of auto-prune), we should be prepared for
reorgs that invalidate checkpoints.
So, no, Bitcoin does NOT rely on that "weak subjectivity" thing.



From melvincarvalho at gmail.com  Thu May 14 00:44:01 2015
From: melvincarvalho at gmail.com (Melvin Carvalho)
Date: Thu, 14 May 2015 02:44:01 +0200
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <5550D8BE.6070207@electrum.org>
References: <5550D8BE.6070207@electrum.org>
Message-ID: <CAKaEYhJVH5g-M98tbpAQvTHi-OiGh91v22GZ+tixqXa7cntiKA@mail.gmail.com>

On 11 May 2015 at 18:28, Thomas Voegtlin <thomasv at electrum.org> wrote:

> The discussion on block size increase has brought some attention to the
> other elephant in the room: Long-term mining incentives.
>
> Bitcoin derives its current market value from the assumption that a
> stable, steady-state regime will be reached in the future, where miners
> have an incentive to keep mining to protect the network. Such a steady
> state regime does not exist today, because miners get most of their
> reward from the block subsidy, which will progressively be removed.
>
> Thus, today's 3 billion USD question is the following: Will a steady
> state regime be reached in the future? Can such a regime exist? What are
> the necessary conditions for its existence?
>
> Satoshi's paper suggests that this may be achieved through miner fees.
> Quite a few people seem to take this for granted, and are working to
> make it happen (developing cpfp and replace-by-fee). This explains part
> of the opposition to raising the block size limit; some people would
> like to see some fee pressure building up first, in order to get closer
> to a regime where miners are incentivised by transaction fees instead of
> block subsidy. Indeed, the emergence of a working fee market would be
> extremely reassuring for the long-term viability of bitcoin. So, the
> thinking goes, by raising the block size limit, we would be postponing a
> crucial reality check. We would be buying time, at the expenses of
> Bitcoin's decentralization.
>
> OTOH, proponents of a block size increase have a very good point: if the
> block size is not raised soon, Bitcoin is going to enter a new, unknown
> and potentially harmful regime. In the current regime, almost all
> transaction get confirmed quickly, and fee pressure does not exist. Mike
> Hearn suggested that, when blocks reach full capacity and users start to
> experience confirmation delays and confirmation uncertainty, users will
> simply go away and stop using Bitcoin. To me, that outcome sounds very
> plausible indeed. Thus, proponents of the block size increase are
> conservative; they are trying to preserve the current regime, which is
> known to work, instead of letting the network enter uncharted territory.
>
> My problem is that this seems to lacks a vision. If the maximal block
> size is increased only to buy time, or because some people think that 7
> tps is not enough to compete with VISA, then I guess it would be
> healthier to try and develop off-chain infrastructure first, such as the
> Lightning network.
>
> OTOH, I also fail to see evidence that a limited block capacity will
> lead to a functional fee market, able to sustain a steady state. A
> functional market requires well-informed participants who make rational
> choices and accept the outcomes of their choices. That is not the case
> today, and to believe that it will magically happen because blocks start
> to reach full capacity sounds a lot like like wishful thinking.
>
> So here is my question, to both proponents and opponents of a block size
> increase: What steady-state regime do you envision for Bitcoin, and what
> is is your plan to get there? More specifically, how will the
> steady-state regime look like? Will users experience fee pressure and
> delays, or will it look more like a scaled up version of what we enjoy
> today? Should fee pressure be increased jointly with subsidy decrease,
> or as soon as possible, or never? What incentives will exist for miners
> once the subsidy is gone? Will miners have an incentive to permanently
> fork off the last block and capture its fees? Do you expect Bitcoin to
> work because miners are altruistic/selfish/honest/caring?
>
> A clear vision would be welcome.
>

I am guided here by Satoshi's paper:

"Commerce on the Internet has come to rely almost exclusively on financial
institutions serving as trusted third parties to process electronic
payments. While the system works well enough for *most transactions*"

This suggests to me that most tx will occur off-block with the block chain
used for settlement.  Indeed Satoshi was working on a trust based market
before he left.

If commerce works well enough off-block with zero trust settlement
supporting it, people might even forget that the block chain exists, like
with gold settlement.  But it can be used for transactions.  To this end I
welcome higher fees, so that the block chain becomes the reserve currency
of the internet and is used sparingly.

But as Gavin pointed out, bitcoin is still an experiment and we are all
still learning.  We are also learning from alt coin mechanisms.  I am
unsure there is huge urgency here, and would lean towards caution as
bitcoin infrastructure rapidly grows.


>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150514/14a689aa/attachment.html>

From voisine at gmail.com  Thu May 14 00:48:41 2015
From: voisine at gmail.com (Aaron Voisine)
Date: Wed, 13 May 2015 17:48:41 -0700
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <CABm2gDoQ-atjWKB0c6AC1ZQ9fy22ceFtHHwpLmnX8DLW4DAgYA@mail.gmail.com>
References: <5550D8BE.6070207@electrum.org>
	<ce3d34c92efd1cf57326e4679550944e@national.shitposting.agency>
	<CABsx9T1VgxEJWxrYTs+2hXGnGrSLGJ6mVcAexjXLvK7Vu+e3EA@mail.gmail.com>
	<CABm2gDoQ-atjWKB0c6AC1ZQ9fy22ceFtHHwpLmnX8DLW4DAgYA@mail.gmail.com>
Message-ID: <CACq0ZD4_zxhm=qWrP+Nr+fQER4s2R8i7qRjX4HsBWN46uOP2MA@mail.gmail.com>

> increasing the block size is simply not a solution, it's just kicking
> the can down the road (while reducing the incentives to deploy real
> solutions like payment channels).

Placing hard limits on blocksize is not the right solution. There are still
plenty of options to be explored to increase fees, resulting in users
voluntarily economizing on block space. It's premature to resort to
destroying the reliability of propagated transaction getting into blocks.

Child-pays-for-parent is useful, but requires the recipient to spend inputs
upon receipt, consuming even more block space. Replace-by-fee may also
help, but users won't know the fee they are getting charged until after the
fact, and it will make worse all the problems that tx malleability causes
today.

We have $3billion plus of value in this system to defend. The safe,
conservative course is to increase the block size. Miners already have an
incentive to find ways to encourage higher fees  and we can help them with
standard recommended propagation rules and hybrid priority/fee transaction
selection for blocks that increases confirmation delays for low fee
transactions.

Aaron Voisine
co-founder and CEO
breadwallet.com

On Wed, May 13, 2015 at 5:11 PM, Jorge Tim?n <jtimon at jtimon.cc> wrote:

> On Mon, May 11, 2015 at 7:29 PM, Gavin Andresen <gavinandresen at gmail.com>
> wrote:
> > I think long-term the chain will not be secured purely by proof-of-work.
> I
> > think when the Bitcoin network was tiny running solely on people's home
> > computers proof-of-work was the right way to secure the chain, and the
> only
> > fair way to both secure the chain and distribute the coins.
> >
> > See https://gist.github.com/gavinandresen/630d4a6c24ac6144482a  for some
> > half-baked thoughts along those lines. I don't think proof-of-work is the
> > last word in distributed consensus (I also don't think any alternatives
> are
> > anywhere near ready to deploy, but they might be in ten years).
>
> Or never, nobody knows at this point.
>
> > I also think it is premature to worry about what will happen in twenty or
> > thirty years when the block subsidy is insignificant. A lot will happen
> in
> > the next twenty years. I could spin a vision of what will secure the
> chain
> > in twenty years, but I'd put a low probability on that vision actually
> > turning out to be correct.
>
> I think is very healthy to worry about that since we know it's
> something that will happen.
> The system should work without subsidies.
>
> > That is why I keep saying Bitcoin is an experiment. But I also believe
> that
> > the incentives are correct, and there are a lot of very motivated, smart,
> > hard-working people who will make it work. When you're talking about
> trying
> > to predict what will happen decades from now, I think that is the best
> you
> > can (honestly) do.
>
> Lightning payment channels may be a new idea, but payment channels are
> not, and nobody is using them.
> They are the best solution to scalability we have right now,
> increasing the block size is simply not a solution, it's just kicking
> the can down the road (while reducing the incentives to deploy real
> solutions like payment channels).
>
> Not worrying about 10 years in the future but asking people to trust
> estimates and speculations about how everything will burn in 2 years
> if we don't act right now seems pretty arbitrary to me.
> One could just as well argue that there's smart hard-working people
> that will solve those problems before they hit us.
>
> It is true that the more distant the future you're trying to predict
> is, the more difficult it is to predict it, but any threshold that
> separates "relevant worries" from "too far in the future to worry
> about it" will always be arbitrary.
> Fortunately we don't need to all share the same time horizon for what
> is worrying and what is not.
> What we need is a clear criterion for what is acceptable for a
> hardfork and a general plan to deploy them:
>
> -Do all the hardfork changes need to be uncontroversial? How do we
> define uncontroversial?
> -Should we maintain and test implementation of hardfork whises that
> seem too small to justify a hardfork on their own (ie time travel fix,
> allowing to sign inputs values...) to also deploy them at the same
> time that other more necessary hardforks?
>
> I agree that hardforks shouldn't be impossible and in that sense I'm
> glad that you started the hardfork debate, but I believe we should be
> focusing on that debate rather than the block size one.
> Once we have a clear criteria, hopefully the block size debate should
> become less noisy and more productive.
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/ded3ba9b/attachment.html>

From pieter.wuille at gmail.com  Thu May 14 00:58:28 2015
From: pieter.wuille at gmail.com (Pieter Wuille)
Date: Wed, 13 May 2015 17:58:28 -0700
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <CACq0ZD4_zxhm=qWrP+Nr+fQER4s2R8i7qRjX4HsBWN46uOP2MA@mail.gmail.com>
References: <5550D8BE.6070207@electrum.org>
	<ce3d34c92efd1cf57326e4679550944e@national.shitposting.agency>
	<CABsx9T1VgxEJWxrYTs+2hXGnGrSLGJ6mVcAexjXLvK7Vu+e3EA@mail.gmail.com>
	<CABm2gDoQ-atjWKB0c6AC1ZQ9fy22ceFtHHwpLmnX8DLW4DAgYA@mail.gmail.com>
	<CACq0ZD4_zxhm=qWrP+Nr+fQER4s2R8i7qRjX4HsBWN46uOP2MA@mail.gmail.com>
Message-ID: <CAPg+sBjxXe0spytGsP1BUzNZhJFDYu_yacdhTy5F+O-X8EG7NQ@mail.gmail.com>

On Wed, May 13, 2015 at 5:48 PM, Aaron Voisine <voisine at gmail.com> wrote:

> We have $3billion plus of value in this system to defend. The safe,
> conservative course is to increase the block size. Miners already have an
> incentive to find ways to encourage higher fees  and we can help them with
> standard recommended propagation rules and hybrid priority/fee transaction
> selection for blocks that increases confirmation delays for low fee
> transactions.
>

You may find that the most economical solution, but I can't understand how
you can call it conservative.

Suggesting a hard fork is betting the survival of the entire ecosystem on
the bet that everyone will agree with and upgrade to new suggested software
before a flag date.

-- 
Pieter
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/deca7b80/attachment.html>

From voisine at gmail.com  Thu May 14 01:13:14 2015
From: voisine at gmail.com (Aaron Voisine)
Date: Wed, 13 May 2015 18:13:14 -0700
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <CAPg+sBjxXe0spytGsP1BUzNZhJFDYu_yacdhTy5F+O-X8EG7NQ@mail.gmail.com>
References: <5550D8BE.6070207@electrum.org>
	<ce3d34c92efd1cf57326e4679550944e@national.shitposting.agency>
	<CABsx9T1VgxEJWxrYTs+2hXGnGrSLGJ6mVcAexjXLvK7Vu+e3EA@mail.gmail.com>
	<CABm2gDoQ-atjWKB0c6AC1ZQ9fy22ceFtHHwpLmnX8DLW4DAgYA@mail.gmail.com>
	<CACq0ZD4_zxhm=qWrP+Nr+fQER4s2R8i7qRjX4HsBWN46uOP2MA@mail.gmail.com>
	<CAPg+sBjxXe0spytGsP1BUzNZhJFDYu_yacdhTy5F+O-X8EG7NQ@mail.gmail.com>
Message-ID: <CACq0ZD7qF0oEYHfQFxLMn3OOD=ibVAfE-U5YURLrtmWVMzDpgQ@mail.gmail.com>

Conservative is a relative term. Dropping transactions in a way that is
unpredictable to the sender sounds incredibly drastic to me. I'm suggesting
increasing the blocksize, drastic as it is, is the more conservative
choice. I would recommend that the fork take effect when some specific
large supermajority of the pervious 1000 blocks indicate they have
upgraded, as a safer alternative to a simple flag date, but I'm sure I
wouldn't have to point out that option to people here.


Aaron Voisine
co-founder and CEO
breadwallet.com

On Wed, May 13, 2015 at 5:58 PM, Pieter Wuille <pieter.wuille at gmail.com>
wrote:

> On Wed, May 13, 2015 at 5:48 PM, Aaron Voisine <voisine at gmail.com> wrote:
>
>> We have $3billion plus of value in this system to defend. The safe,
>> conservative course is to increase the block size. Miners already have an
>> incentive to find ways to encourage higher fees  and we can help them with
>> standard recommended propagation rules and hybrid priority/fee transaction
>> selection for blocks that increases confirmation delays for low fee
>> transactions.
>>
>
> You may find that the most economical solution, but I can't understand how
> you can call it conservative.
>
> Suggesting a hard fork is betting the survival of the entire ecosystem on
> the bet that everyone will agree with and upgrade to new suggested software
> before a flag date.
>
> --
> Pieter
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/f4f8a27c/attachment.html>

From pieter.wuille at gmail.com  Thu May 14 01:19:45 2015
From: pieter.wuille at gmail.com (Pieter Wuille)
Date: Wed, 13 May 2015 18:19:45 -0700
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <CACq0ZD7qF0oEYHfQFxLMn3OOD=ibVAfE-U5YURLrtmWVMzDpgQ@mail.gmail.com>
References: <5550D8BE.6070207@electrum.org>
	<ce3d34c92efd1cf57326e4679550944e@national.shitposting.agency>
	<CABsx9T1VgxEJWxrYTs+2hXGnGrSLGJ6mVcAexjXLvK7Vu+e3EA@mail.gmail.com>
	<CABm2gDoQ-atjWKB0c6AC1ZQ9fy22ceFtHHwpLmnX8DLW4DAgYA@mail.gmail.com>
	<CACq0ZD4_zxhm=qWrP+Nr+fQER4s2R8i7qRjX4HsBWN46uOP2MA@mail.gmail.com>
	<CAPg+sBjxXe0spytGsP1BUzNZhJFDYu_yacdhTy5F+O-X8EG7NQ@mail.gmail.com>
	<CACq0ZD7qF0oEYHfQFxLMn3OOD=ibVAfE-U5YURLrtmWVMzDpgQ@mail.gmail.com>
Message-ID: <CAPg+sBjs_y6Q7YAQjH1vd=WaRvObp+yuv-OcFFjg6umQ2=UCMQ@mail.gmail.com>

On Wed, May 13, 2015 at 6:13 PM, Aaron Voisine <voisine at gmail.com> wrote:

> Conservative is a relative term. Dropping transactions in a way that is
> unpredictable to the sender sounds incredibly drastic to me. I'm suggesting
> increasing the blocksize, drastic as it is, is the more conservative choice.
>

Transactions are already being dropped, in a more indirect way: by people
and businesses deciding to not use on-chain settlement. That is very sad,
but it's completely inevitable that there is space for some use cases and
not for others (at whatever block size). It's only a "things don't fit
anymore" when you see on-chain transactions as the only means for doing
payments, and that is already not the case. Increasing the block size
allows for more utility on-chain, but it does not fundamentally add more
use cases - only more growth space for people already invested in being
able to do things on-chain while externalizing the costs to others.


> I would recommend that the fork take effect when some specific large
> supermajority of the pervious 1000 blocks indicate they have upgraded, as a
> safer alternative to a simple flag date, but I'm sure I wouldn't have to
> point out that option to people here.
>

That only measures miner adoption, which is the least relevant. The
question is whether people using full nodes will upgrade. If they do, then
miners are forced to upgrade too, or become irrelevant. If they don't, the
upgrade is risky with or without miner adoption.

-- 
Pieter
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/e909c936/attachment.html>

From voisine at gmail.com  Thu May 14 01:31:56 2015
From: voisine at gmail.com (Aaron Voisine)
Date: Wed, 13 May 2015 18:31:56 -0700
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <CAPg+sBjs_y6Q7YAQjH1vd=WaRvObp+yuv-OcFFjg6umQ2=UCMQ@mail.gmail.com>
References: <5550D8BE.6070207@electrum.org>
	<ce3d34c92efd1cf57326e4679550944e@national.shitposting.agency>
	<CABsx9T1VgxEJWxrYTs+2hXGnGrSLGJ6mVcAexjXLvK7Vu+e3EA@mail.gmail.com>
	<CABm2gDoQ-atjWKB0c6AC1ZQ9fy22ceFtHHwpLmnX8DLW4DAgYA@mail.gmail.com>
	<CACq0ZD4_zxhm=qWrP+Nr+fQER4s2R8i7qRjX4HsBWN46uOP2MA@mail.gmail.com>
	<CAPg+sBjxXe0spytGsP1BUzNZhJFDYu_yacdhTy5F+O-X8EG7NQ@mail.gmail.com>
	<CACq0ZD7qF0oEYHfQFxLMn3OOD=ibVAfE-U5YURLrtmWVMzDpgQ@mail.gmail.com>
	<CAPg+sBjs_y6Q7YAQjH1vd=WaRvObp+yuv-OcFFjg6umQ2=UCMQ@mail.gmail.com>
Message-ID: <CACq0ZD6hDN0AY7jza46SuSA=-TqEii99oqR1gQyPt_vA+PqQgw@mail.gmail.com>

> by people and businesses deciding to not use on-chain settlement.

I completely agree. Increasing fees will cause people voluntary economize
on blockspace by finding alternatives, i.e. not bitcoin. A fee however is a
known, upfront cost... unpredictable transaction failure in most cases will
be a far higher, unacceptable cost to the user than the actual fee. The
higher the costs of using the system, the lower the adoption as a
store-of-value. The lower the adoption as store-of-value, the lower the
price, and the lower the value of bitcoin to the world.

> That only measures miner adoption, which is the least relevant.

I concede the point. Perhaps a flag date based on previous observation of
network upgrade rates with a conservative additional margin in addition to
supermajority of mining power.


Aaron Voisine
co-founder and CEO
breadwallet.com

On Wed, May 13, 2015 at 6:19 PM, Pieter Wuille <pieter.wuille at gmail.com>
wrote:

> On Wed, May 13, 2015 at 6:13 PM, Aaron Voisine <voisine at gmail.com> wrote:
>
>> Conservative is a relative term. Dropping transactions in a way that is
>> unpredictable to the sender sounds incredibly drastic to me. I'm suggesting
>> increasing the blocksize, drastic as it is, is the more conservative choice.
>>
>
> Transactions are already being dropped, in a more indirect way: by people
> and businesses deciding to not use on-chain settlement. That is very sad,
> but it's completely inevitable that there is space for some use cases and
> not for others (at whatever block size). It's only a "things don't fit
> anymore" when you see on-chain transactions as the only means for doing
> payments, and that is already not the case. Increasing the block size
> allows for more utility on-chain, but it does not fundamentally add more
> use cases - only more growth space for people already invested in being
> able to do things on-chain while externalizing the costs to others.
>
>
>> I would recommend that the fork take effect when some specific large
>> supermajority of the pervious 1000 blocks indicate they have upgraded, as a
>> safer alternative to a simple flag date, but I'm sure I wouldn't have to
>> point out that option to people here.
>>
>
> That only measures miner adoption, which is the least relevant. The
> question is whether people using full nodes will upgrade. If they do, then
> miners are forced to upgrade too, or become irrelevant. If they don't, the
> upgrade is risky with or without miner adoption.
>
> --
> Pieter
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/0268ac4b/attachment.html>

From voisine at gmail.com  Thu May 14 02:34:29 2015
From: voisine at gmail.com (Aaron Voisine)
Date: Wed, 13 May 2015 19:34:29 -0700
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <CACq0ZD6hDN0AY7jza46SuSA=-TqEii99oqR1gQyPt_vA+PqQgw@mail.gmail.com>
References: <5550D8BE.6070207@electrum.org>
	<ce3d34c92efd1cf57326e4679550944e@national.shitposting.agency>
	<CABsx9T1VgxEJWxrYTs+2hXGnGrSLGJ6mVcAexjXLvK7Vu+e3EA@mail.gmail.com>
	<CABm2gDoQ-atjWKB0c6AC1ZQ9fy22ceFtHHwpLmnX8DLW4DAgYA@mail.gmail.com>
	<CACq0ZD4_zxhm=qWrP+Nr+fQER4s2R8i7qRjX4HsBWN46uOP2MA@mail.gmail.com>
	<CAPg+sBjxXe0spytGsP1BUzNZhJFDYu_yacdhTy5F+O-X8EG7NQ@mail.gmail.com>
	<CACq0ZD7qF0oEYHfQFxLMn3OOD=ibVAfE-U5YURLrtmWVMzDpgQ@mail.gmail.com>
	<CAPg+sBjs_y6Q7YAQjH1vd=WaRvObp+yuv-OcFFjg6umQ2=UCMQ@mail.gmail.com>
	<CACq0ZD6hDN0AY7jza46SuSA=-TqEii99oqR1gQyPt_vA+PqQgw@mail.gmail.com>
Message-ID: <CACq0ZD41uSuLibsSCLfgbhT2qrryZuZvE1oUBfLgYnWpr3WBWw@mail.gmail.com>

> I concede the point. Perhaps a flag date based on previous observation of
network upgrade rates with a conservative additional margin in addition to
supermajority of mining power.

It occurs to me that this would allow for a relatively small percentage of
miners to stop the upgrade if the flag date turns out to be poorly chosen
and a large number of non-mining nodes haven't upgraded yet. Would be a
nice safety fallback.


Aaron Voisine
co-founder and CEO
breadwallet.com

On Wed, May 13, 2015 at 6:31 PM, Aaron Voisine <voisine at gmail.com> wrote:

> > by people and businesses deciding to not use on-chain settlement.
>
> I completely agree. Increasing fees will cause people voluntary economize
> on blockspace by finding alternatives, i.e. not bitcoin. A fee however is a
> known, upfront cost... unpredictable transaction failure in most cases will
> be a far higher, unacceptable cost to the user than the actual fee. The
> higher the costs of using the system, the lower the adoption as a
> store-of-value. The lower the adoption as store-of-value, the lower the
> price, and the lower the value of bitcoin to the world.
>
> > That only measures miner adoption, which is the least relevant.
>
> I concede the point. Perhaps a flag date based on previous observation of
> network upgrade rates with a conservative additional margin in addition to
> supermajority of mining power.
>
>
> Aaron Voisine
> co-founder and CEO
> breadwallet.com
>
> On Wed, May 13, 2015 at 6:19 PM, Pieter Wuille <pieter.wuille at gmail.com>
> wrote:
>
>> On Wed, May 13, 2015 at 6:13 PM, Aaron Voisine <voisine at gmail.com> wrote:
>>
>>> Conservative is a relative term. Dropping transactions in a way that is
>>> unpredictable to the sender sounds incredibly drastic to me. I'm suggesting
>>> increasing the blocksize, drastic as it is, is the more conservative choice.
>>>
>>
>> Transactions are already being dropped, in a more indirect way: by people
>> and businesses deciding to not use on-chain settlement. That is very sad,
>> but it's completely inevitable that there is space for some use cases and
>> not for others (at whatever block size). It's only a "things don't fit
>> anymore" when you see on-chain transactions as the only means for doing
>> payments, and that is already not the case. Increasing the block size
>> allows for more utility on-chain, but it does not fundamentally add more
>> use cases - only more growth space for people already invested in being
>> able to do things on-chain while externalizing the costs to others.
>>
>>
>>> I would recommend that the fork take effect when some specific large
>>> supermajority of the pervious 1000 blocks indicate they have upgraded, as a
>>> safer alternative to a simple flag date, but I'm sure I wouldn't have to
>>> point out that option to people here.
>>>
>>
>> That only measures miner adoption, which is the least relevant. The
>> question is whether people using full nodes will upgrade. If they do, then
>> miners are forced to upgrade too, or become irrelevant. If they don't, the
>> upgrade is risky with or without miner adoption.
>>
>> --
>> Pieter
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150513/92f0f8d2/attachment.html>

From laanwj at gmail.com  Thu May 14 09:18:26 2015
From: laanwj at gmail.com (Wladimir J. van der Laan)
Date: Thu, 14 May 2015 11:18:26 +0200
Subject: [Bitcoin-development] Bitcoin Core 0.10.1 release candidate 2
	available
Message-ID: <20150514091825.GA15439@amethyst.visucore.com>


Binaries for bitcoin Core version 0.10.2rc1 are now available from:

  https://bitcoin.org/bin/0.10.2/test

Source code can be found on github under the signed tag

  https://github.com/bitcoin/bitcoin/tree/v0.10.2rc1

This is a release candidate for a minor version release, with mainly a fix for
a bug that affected Windows users with non-ASCII characters in the data directory.
The release also contains translation updates. 

If you experienced no issues with 0.10.1, there is no need to upgrade.

Preliminary release notes for the 0.10.2 release can be found here:

  https://github.com/bitcoin/bitcoin/blob/v0.10.2rc1/doc/release-notes.md

Release candidates are test runs for releases, when no critical
problems are found this release candidate will be tagged as 0.10.2.

Please report bugs using the issue tracker at github:

  https://github.com/bitcoin/bitcoin/issues




From laanwj at gmail.com  Thu May 14 09:21:50 2015
From: laanwj at gmail.com (Wladimir)
Date: Thu, 14 May 2015 09:21:50 +0000
Subject: [Bitcoin-development] Bitcoin Core 0.10.2 release candidate 1
	available
Message-ID: <CA+s+GJBzkvgEn-7wFtpSwubTS6TOKz0OX=ay3QmGSZrM7ZzXLw@mail.gmail.com>

The subject should obviously be "Bitcoin Core 0.10.2 release candidate
1 available", not the other way around,



From decker.christian at gmail.com  Thu May 14 11:01:56 2015
From: decker.christian at gmail.com (Christian Decker)
Date: Thu, 14 May 2015 11:01:56 +0000
Subject: [Bitcoin-development] [BIP] Normalized Transaction IDs
In-Reply-To: <CAPg+sBjiaqsLEMz8Qskz1iWOf3VBgAnX2749uHzeyFf_seLEHQ@mail.gmail.com>
References: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
	<CAPg+sBggj382me1ATDx4SS9KHVfvX5KH7ZhLHN6B+2_a+Emw1Q@mail.gmail.com>
	<CAE-z3OV1WEDEV+X7gNVx+qBMt4jpSHFKXm3dxUrUyBEJrCNDSQ@mail.gmail.com>
	<CAE-z3OU-fdTrKRkni4xmmY5uBVWS0KJ_2NVh6k1tcMSGTPp+4Q@mail.gmail.com>
	<CAPg+sBixpKQfsazHyhiF60HYTk9_U0aBAqU=4P+R+HDMA2jWKg@mail.gmail.com>
	<CAE-z3OU7nCJSGk-Mx_2gmpUjQ1gXeSNDiWfhPe-5rj5bG5ArWQ@mail.gmail.com>
	<CAPg+sBjiaqsLEMz8Qskz1iWOf3VBgAnX2749uHzeyFf_seLEHQ@mail.gmail.com>
Message-ID: <CALxbBHV_2NHAvS5GXCsqBR0gO9zZe55kz52geMhG+8=EkKN2KA@mail.gmail.com>

Ok, I think I got the OP_CHECKAWESOMESIG proposal, transactions keep
referencing using hashes of complete transactions (including signatures),
while the OP_CHECKAWESOMESIG looks up the previous transaction (which we
already need to do anyway in order to insert the prevOut pubkeyScript),
normalizes the prevout and calculates its normalized transaction ID. It
then inserts the normalized transaction IDs in the OutPoint before
calculating its own hash which is then signed. Is that correct so far?

Let me try to summarize the discussion so far:

I think we have consensus that transaction malleability needs to be
addressed, and normalized transaction IDs seem to be the way to go forward.

The discussion now is how to use normalized transaction IDs and we have two
approaches to implement them:

   - OP_CHECKAWESOMESIG which continues to use the current hashes to
   reference a specific signed instance of a class of semantically identical
   transactions. Internally only the semantic class is enforced. Transactions
   can be fixed to reference the correct signed instance if the transaction
   has been changed along the way.is a softfork using the "if I don't know
   this opcode the TX is automatically valid" trick


On Thu, May 14, 2015 at 2:40 AM Pieter Wuille <pieter.wuille at gmail.com>
wrote:

> On Wed, May 13, 2015 at 1:32 PM, Tier Nolan <tier.nolan at gmail.com> wrote:
>
>>
>> On Wed, May 13, 2015 at 9:31 PM, Pieter Wuille <pieter.wuille at gmail.com>
>> wrote:
>>
>>>
>>> This was what I was suggesting all along, sorry if I wasn't clear.
>>>
>>> That's great.  So, basically the multi-level refund problem is solved by
>> this?
>>
>
> Yes. So to be clear, I think there are 2 desirable end-goal proposals
> (ignoring difficulty of changing things for a minute):
>
> * Transactions and blocks keep referring to other transactions by full
> txid, but signature hashes are computed off normalized txids (which are
> recursively defined to use normalized txids all the way back to coinbases).
> Is this what you are suggesting now as well?
>
> * Blocks commit to full transaction data, but transactions and signature
> hashes use normalized txids.
>
> The benefit of the latter solution is that it doesn't need "fixing up"
> transactions whose inputs have been malleated, but comes at the cost of
> doing a very invasive hard fork.
>
> --
> Pieter
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150514/7291d57f/attachment.html>

From decker.christian at gmail.com  Thu May 14 11:26:44 2015
From: decker.christian at gmail.com (Christian Decker)
Date: Thu, 14 May 2015 11:26:44 +0000
Subject: [Bitcoin-development] [BIP] Normalized Transaction IDs
In-Reply-To: <CALxbBHV_2NHAvS5GXCsqBR0gO9zZe55kz52geMhG+8=EkKN2KA@mail.gmail.com>
References: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
	<CAPg+sBggj382me1ATDx4SS9KHVfvX5KH7ZhLHN6B+2_a+Emw1Q@mail.gmail.com>
	<CAE-z3OV1WEDEV+X7gNVx+qBMt4jpSHFKXm3dxUrUyBEJrCNDSQ@mail.gmail.com>
	<CAE-z3OU-fdTrKRkni4xmmY5uBVWS0KJ_2NVh6k1tcMSGTPp+4Q@mail.gmail.com>
	<CAPg+sBixpKQfsazHyhiF60HYTk9_U0aBAqU=4P+R+HDMA2jWKg@mail.gmail.com>
	<CAE-z3OU7nCJSGk-Mx_2gmpUjQ1gXeSNDiWfhPe-5rj5bG5ArWQ@mail.gmail.com>
	<CAPg+sBjiaqsLEMz8Qskz1iWOf3VBgAnX2749uHzeyFf_seLEHQ@mail.gmail.com>
	<CALxbBHV_2NHAvS5GXCsqBR0gO9zZe55kz52geMhG+8=EkKN2KA@mail.gmail.com>
Message-ID: <CALxbBHX-Kkfp0wffH4VKCAp6Zp=JkV99m7Yo8yk9AvSS5bUp+g@mail.gmail.com>

Sorry about that, sometimes I hate keyboard shortcuts :-)


Ok, I think I got the OP_CHECKAWESOMESIG proposal, transactions keep
referencing using hashes of complete transactions (including signatures),
while the OP_CHECKAWESOMESIG looks up the previous transaction (which we
already need to do anyway in order to insert the prevOut pubkeyScript),
normalizes the prevout and calculates its normalized transaction ID. It
then inserts the normalized transaction IDs in the OutPoint before
calculating its own hash which is then signed. Is that correct so far?

Let me try to summarize the discussion so far:

I think we have consensus that transaction malleability needs to be
addressed, and normalized transaction IDs seem to be the way to go forward.

The discussion now is how to use normalized transaction IDs and we have two
approaches to implement them:


   - OP_CHECKAWESOMESIG which continues to use the current hashes to
   reference a specific signed instance of a class of semantically identical
   transactions. Internally only the semantic class is enforced. Transactions
   can be fixed to reference the correct signed instance if the transaction
   has been changed along the way.
   - The second proposal advocates using the normalized transaction IDs
   directly in the transactions, requiring no further intervention to fix an
   eventually malleated transaction.

Both approaches have their own advantages and problems:

OP_CHECKAWESOMESIG is a soft-fork which makes it somewhat less problematic
to roll-out and does not break existing software. The normalized
transaction ID can be computed on the fly (possibly increasing lookup
times) or stored alongside the UTXO (increasing storage needs). If the
normalized transaction IDs really need to be recomputed down to the
coinbase then the increased storage is the only option, and would add 32
byte to every transaction metadata in the UTXO.

My proposal is harder to migrate to, as it requires a hardfork, and will
require more storage (64 byte raw data for a normalized to legacy
transaction ID) for every transaction in the UTXO set. At 6 million
distinct transactions which unspent outputs this boils down to 384 MB
(though this may change in future by introducing an aggregation strategy or
fragment further). Some of that space may be reclaimed. There is absolutely
no interaction required to fix up transactions if a dependency has been
malleated, since we address a semantic class, not the specific instance. We
limit the use of normalized transaction IDs to the OutPoint in
transactions, since there we want to reference the semantic class not the
actual signed instance. At protocol message level (inv, getdata) and blocks
we continue to use the legacy ID. This is not as nice as having one ID for
every transaction that is used everywhere.

Both solutions solve malleability, just with different tradeoffs.

I don't see them as mutually exclusive, if we adopt the OP_CHECKAWESOMESIG
as short term fix, that can be rolled out and applied, then my proposal can
be seen as long-term goal that is semantically cleaner and easier to
implement.

Personally I think hard-forks shouldn't be the dreaded boogeyman everybody
makes them out to be, we have never really tested rolling out a hardfork
and they might just turn out to be possible. I don't thing we loose
anything by attempting this, except maybe reduce the urgency to apply some
perfect future thing.

Regards,
Christian

On Thu, May 14, 2015 at 1:01 PM, Christian Decker <
decker.christian at gmail.com> wrote:

> Ok, I think I got the OP_CHECKAWESOMESIG proposal, transactions keep
> referencing using hashes of complete transactions (including signatures),
> while the OP_CHECKAWESOMESIG looks up the previous transaction (which we
> already need to do anyway in order to insert the prevOut pubkeyScript),
> normalizes the prevout and calculates its normalized transaction ID. It
> then inserts the normalized transaction IDs in the OutPoint before
> calculating its own hash which is then signed. Is that correct so far?
>
> Let me try to summarize the discussion so far:
>
> I think we have consensus that transaction malleability needs to be
> addressed, and normalized transaction IDs seem to be the way to go forward.
>
> The discussion now is how to use normalized transaction IDs and we have
> two approaches to implement them:
>
>    - OP_CHECKAWESOMESIG which continues to use the current hashes to
>    reference a specific signed instance of a class of semantically identical
>    transactions. Internally only the semantic class is enforced. Transactions
>    can be fixed to reference the correct signed instance if the transaction
>    has been changed along the way.is a softfork using the "if I don't
>    know this opcode the TX is automatically valid" trick
>
>
> On Thu, May 14, 2015 at 2:40 AM Pieter Wuille <pieter.wuille at gmail.com>
> wrote:
>
>> On Wed, May 13, 2015 at 1:32 PM, Tier Nolan <tier.nolan at gmail.com> wrote:
>>
>>>
>>> On Wed, May 13, 2015 at 9:31 PM, Pieter Wuille <pieter.wuille at gmail.com>
>>> wrote:
>>>
>>>>
>>>> This was what I was suggesting all along, sorry if I wasn't clear.
>>>>
>>>> That's great.  So, basically the multi-level refund problem is solved
>>> by this?
>>>
>>
>> Yes. So to be clear, I think there are 2 desirable end-goal proposals
>> (ignoring difficulty of changing things for a minute):
>>
>> * Transactions and blocks keep referring to other transactions by full
>> txid, but signature hashes are computed off normalized txids (which are
>> recursively defined to use normalized txids all the way back to coinbases).
>> Is this what you are suggesting now as well?
>>
>> * Blocks commit to full transaction data, but transactions and signature
>> hashes use normalized txids.
>>
>> The benefit of the latter solution is that it doesn't need "fixing up"
>> transactions whose inputs have been malleated, but comes at the cost of
>> doing a very invasive hard fork.
>>
>> --
>> Pieter
>>
>>
>> ------------------------------------------------------------------------------
>> One dashboard for servers and applications across Physical-Virtual-Cloud
>> Widest out-of-the-box monitoring support with 50+ applications
>> Performance metrics, stats and reports that give you Actionable Insights
>> Deep dive visibility with transaction tracing using APM Insight.
>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150514/acae1f4f/attachment.html>

From tomh at thinlink.com  Thu May 14 15:22:41 2015
From: tomh at thinlink.com (Tom Harding)
Date: Thu, 14 May 2015 08:22:41 -0700
Subject: [Bitcoin-development] No Bitcoin For You
Message-ID: <5554BDC1.6070206@thinlink.com>

A recent post, which I cannot find after much effort, made an excellent
point.

If capacity grows, fewer individuals would be able to run full nodes. 
Those individuals, like many already, would have to give up running a
full-node wallet :(

That sounds bad, until you consider that the alternative is running a
full node on the bitcoin 'settlement network', while massive numbers of
people *give up any hope of directly owning bitcoin at all*.

If today's global payments are 100Ktps, and move to the Lightning
Network, they will have to be consolidated by a factor of 25000:1 to fit
into bitcoin's current 4tps capacity as a settlement network.  You
executing a personal transaction on that network will be about as likely
as you personally conducting a $100 SWIFT transfer to yourself today. 
For current holders, just selling or spending will get very expensive!

Forcing block capacity to stay small, so that individuals can run full
nodes, is precisely what will force bitcoin to become a backbone that is
too expensive for individuals to use.  I can't avoid the conclusion that
Bitcoin has to scale, and we might as well be thinking about how.

There may be a an escape window.  As current trends continue toward a
landscape of billions of SPV wallets, it may still be possible for
individuals collectively to make up the majority of the network, if more
parts of the network itself rely on SPV-level security.

With SPV-level security, it might be possible to implement a scalable
DHT-type network of nodes that collectively store and index the
exhaustive and fast-growing corpus of transaction history, up to and
including currently unconfirmed transactions.  Each individual node
could host a slice of the transaction set with a configurable size,
let's say down to a few GB today.

Such a network would have the desirable property of being run by the
community.  Most transactions would be submitted to it, and like today's
network, it would disseminate blocks (which would be rapidly torn apart
and digested).  Therefore miners and other full nodes would depend on
it, which is rather critical as those nodes grow closer to data-center
proportions.





From s7r at sky-ip.org  Fri May 15 09:54:55 2015
From: s7r at sky-ip.org (s7r)
Date: Fri, 15 May 2015 12:54:55 +0300
Subject: [Bitcoin-development] [BIP] Normalized Transaction IDs
In-Reply-To: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
References: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
Message-ID: <5555C26F.7080706@sky-ip.org>

Hello,

How will this exactly be safe against:
a) the malleability of the parent tx (2nd level malleability)
b) replays

If you strip just the scriptSig of the input(s), the txid(s) can still
be mutated (with higher probability before it gets confirmed).

If you strip both the scriptSig of the parent and the txid, nothing can
any longer be mutated but this is not safe against replays. This could
work if we were using only one scriptPubKey per tx. But this is not
enforced, and I don't think it's the proper way to do it.

Something similar can be achieved if you would use a combination of
flags from here:

https://github.com/scmorse/bitcoin-misc/blob/master/sighash_proposal.md

But this has some issues too.

I've read your draft but didn't understand how exactly will this prevent
normal malleability as we know it, second level malleability and replays
as well as how will we do the transition into mapping the txes in the
blockchain to normalized txids. Looking forward to read more on this
topic. Thanks for the brainstorming ;)


On 5/13/2015 3:48 PM, Christian Decker wrote:
> Hi All,
> 
> I'd like to propose a BIP to normalize transaction IDs in order to
> address transaction malleability and facilitate higher level protocols.
> 
> The normalized transaction ID is an alias used in parallel to the
> current (legacy) transaction IDs to address outputs in transactions. It
> is calculated by removing (zeroing) the scriptSig before computing the
> hash, which ensures that only data whose integrity is also guaranteed by
> the signatures influences the hash. Thus if anything causes the
> normalized ID to change it automatically invalidates the signature. When
> validating a client supporting this BIP would use both the normalized tx
> ID as well as the legacy tx ID when validating transactions.
> 
> The detailed writeup can be found
> here: https://github.com/cdecker/bips/blob/normalized-txid/bip-00nn.mediawiki.
> 
> @gmaxwell: I'd like to request a BIP number, unless there is something
> really wrong with the proposal.
> 
> In addition to being a simple alternative that solves transaction
> malleability it also hugely simplifies higher level protocols. We can
> now use template transactions upon which sequences of transactions can
> be built before signing them.
> 
> I hesitated quite a while to propose it since it does require a hardfork
> (old clients would not find the prevTx identified by the normalized
> transaction ID and deem the spending transaction invalid), but it seems
> that hardforks are no longer the dreaded boogeyman nobody talks about.
> I left out the details of how the hardfork is to be done, as it does not
> really matter and we may have a good mechanism to apply a bunch of
> hardforks concurrently in the future.
> 
> I'm sure it'll take time to implement and upgrade, but I think it would
> be a nice addition to the functionality and would solve a long standing
> problem :-)
> 
> Please let me know what you think, the proposal is definitely not set in
> stone at this point and I'm sure we can improve it further.
> 
> Regards,
> Christian
> 
> 
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud 
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> 
> 
> 
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> 



From tier.nolan at gmail.com  Fri May 15 10:45:05 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Fri, 15 May 2015 11:45:05 +0100
Subject: [Bitcoin-development] [BIP] Normalized Transaction IDs
In-Reply-To: <5555C26F.7080706@sky-ip.org>
References: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
	<5555C26F.7080706@sky-ip.org>
Message-ID: <CAE-z3OXwRArVnB13t+-S6EdxJkDx3EKbTN4dh2b-uJ05+6rqXw@mail.gmail.com>

On Fri, May 15, 2015 at 10:54 AM, s7r <s7r at sky-ip.org> wrote:

> Hello,
>
> How will this exactly be safe against:
> a) the malleability of the parent tx (2nd level malleability)
>

The signature signs everything except the signature itself.  The normalized
txid doesn't include that signature, so mutations of the signature don't
cause the normalized txid to change.

If the refund transaction refers to the parent using the normalised txid,
then it doesn't matter if the parent has a mutated signature.  The
normalized transaction ignores the mutation.

If the parent is mutated, then the refund doesn't even have to be modified,
it still refers to it.

If you want a multi-level refund transaction, then all refund transactions
must use the normalized txids to refer to their parents.  The "root"
transaction is submitted to the blockchain and locked down.


> b) replays
>

If there are 2 transactions which are mutations of each other, then only
one can be added to the block chain, since the other is a double spend.

The normalized txid refers to all of them, rather than a specific
transaction.


> If you strip just the scriptSig of the input(s), the txid(s) can still
> be mutated (with higher probability before it gets confirmed).
>

Mutation is only a problem if it occurs after signing.  The signature signs
everything except the signature itself.


> If you strip both the scriptSig of the parent and the txid, nothing can
> any longer be mutated but this is not safe against replays.


Correct, but normalized txids are safe against replays, so are better.

I think the new signature opcode fixes things too.  The question is hard
fork but clean solution vs a soft fork but a little more hassle.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150515/5b2b0e9e/attachment.html>

From luke at dashjr.org  Fri May 15 16:31:47 2015
From: luke at dashjr.org (Luke Dashjr)
Date: Fri, 15 May 2015 16:31:47 +0000
Subject: [Bitcoin-development] [BIP] Normalized Transaction IDs
In-Reply-To: <5555C26F.7080706@sky-ip.org>
References: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
	<5555C26F.7080706@sky-ip.org>
Message-ID: <201505151631.48765.luke@dashjr.org>

On Friday, May 15, 2015 9:54:55 AM s7r wrote:
> If you strip both the scriptSig of the parent and the txid, nothing can
> any longer be mutated but this is not safe against replays. This could
> work if we were using only one scriptPubKey per tx. But this is not
> enforced, ...

Assuming you mean one output per scriptPubKey (and not limiting tx to one 
output), the alternative is essentially undefined, and creates real problems 
for Bitcoin today. It's not something we should go out of the way to support 
or encourage. Therefore, regardless of whatever other options are available, I 
would like to see a scriptPubKey-only sighash type for strong safety within 
all malleability situations (including CoinJoin and other sender-respends) 
that more advanced wallet software could take advantage of in the future 
(while strictly enforcing no-reuse on its own wallet to avoid known replays).

Luke



From rusty at rustcorp.com.au  Sat May 16 00:22:14 2015
From: rusty at rustcorp.com.au (Rusty Russell)
Date: Sat, 16 May 2015 09:52:14 +0930
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CAE-z3OUzYZDvsOYEDT229vnvNBa9ntW+86O3uA-K5-KaneMF_g@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CAOG=w-szbLgc1jLpkE_uMa3bkFTi-RiBEaQ6Y-u5aKLBC2HvUg@mail.gmail.com>
	<CAAS2fgQRS7w7RRNXVK_+=4CQ7=AWxWQQ7+Tf4tNUPTTZOf7rEQ@mail.gmail.com>
	<CAE-z3OUzYZDvsOYEDT229vnvNBa9ntW+86O3uA-K5-KaneMF_g@mail.gmail.com>
Message-ID: <87a8x5l6bt.fsf@rustcorp.com.au>

Tier Nolan <tier.nolan at gmail.com> writes:
> On Sat, May 9, 2015 at 4:36 AM, Gregory Maxwell <gmaxwell at gmail.com> wrote:
>
>> An example would
>> be tx_size = MAX( real_size >> 1,  real_size + 4*utxo_created_size -
>> 3*utxo_consumed_size).
>
>
> This could be implemented as a soft fork too.
>
> * 1MB hard size limit
> * 900kB soft limit

I like this too.

Some tweaks:

1) Nomenclature: call tx_size "tx_cost" and real_size "tx_bytes"?

2) If we have a reasonable hard *byte* limit, I don't think that we need
   the MAX().  In fact, it's probably OK to go negative.

3) ... or maybe not, if any consumed UTXO was generated before the soft
   fork (reducing Tier's perverse incentive).

4) How do we measure UTXO size?  There are some constant-ish things in
   there (eg. txid as key, height, outnum, amount).  Maybe just add 32
   to scriptlen?

5) Add a CHECKSIG cost.  Naively, since we allow 20,000 CHECKSIGs and
   1MB blocks, that implies a cost of 50 bytes per CHECKSIG (but counted
   correctly, unlike now).   

This last one implies that the initial cost limit would be 2M, but in
practice probably somewhere in the middle.

  tx_cost = 50*num-CHECKSIG
                + tx_bytes
                + 4*utxo_created_size
                - 3*utxo_consumed_size

> A 250 byte transaction with 2 inputs and 2 outputs would have an adjusted
> size of 252 bytes.

Now cost == 352.

Cheers,
Rusty.



From stephencalebmorse at gmail.com  Sat May 16 03:58:56 2015
From: stephencalebmorse at gmail.com (Stephen)
Date: Fri, 15 May 2015 23:58:56 -0400
Subject: [Bitcoin-development] [BIP] Normalized Transaction IDs
In-Reply-To: <5555C26F.7080706@sky-ip.org>
References: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
	<5555C26F.7080706@sky-ip.org>
Message-ID: <AC0B3BAC-0934-46A3-B29A-F74238616F72@gmail.com>

We should make sure to consider how BIP34 affects normalized transaction ids, since the height of the block is included in the scriptSig ensuring that the txid will be different. We wouldn't want to enable replay attacks in the form of spending coinbase outputs in the same way they were spent from a previous block. 

So maybe normalized txids should strip the scriptSigs of all transactions except for coinbase transactions? This seems to make sense, since coinbase transactions are inherently not malleable anyway. 

Also, s7r linked to my 'Build your own nHashType' proposal (although V2 is here: https://github.com/scmorse/bitcoin-misc/blob/master/sighash_proposal_v2.md). I just wanted to add that I think even with normalized ids, it could still be useful to be able to apply these flags to choose which parts of the transaction become signed. I've also seen vague references to some kind of a merklized abstract syntax tree, but am not fully sure how that would work. Maybe someone on here could explain it? 

Best,
Stephen



> On May 15, 2015, at 5:54 AM, s7r <s7r at sky-ip.org> wrote:
> 
> Hello,
> 
> How will this exactly be safe against:
> a) the malleability of the parent tx (2nd level malleability)
> b) replays
> 
> If you strip just the scriptSig of the input(s), the txid(s) can still
> be mutated (with higher probability before it gets confirmed).
> 
> If you strip both the scriptSig of the parent and the txid, nothing can
> any longer be mutated but this is not safe against replays. This could
> work if we were using only one scriptPubKey per tx. But this is not
> enforced, and I don't think it's the proper way to do it.
> 
> Something similar can be achieved if you would use a combination of
> flags from here:
> 
> https://github.com/scmorse/bitcoin-misc/blob/master/sighash_proposal.md
> 
> But this has some issues too.
> 
> I've read your draft but didn't understand how exactly will this prevent
> normal malleability as we know it, second level malleability and replays
> as well as how will we do the transition into mapping the txes in the
> blockchain to normalized txids. Looking forward to read more on this
> topic. Thanks for the brainstorming ;)
> 
> 
>> On 5/13/2015 3:48 PM, Christian Decker wrote:
>> Hi All,
>> 
>> I'd like to propose a BIP to normalize transaction IDs in order to
>> address transaction malleability and facilitate higher level protocols.
>> 
>> The normalized transaction ID is an alias used in parallel to the
>> current (legacy) transaction IDs to address outputs in transactions. It
>> is calculated by removing (zeroing) the scriptSig before computing the
>> hash, which ensures that only data whose integrity is also guaranteed by
>> the signatures influences the hash. Thus if anything causes the
>> normalized ID to change it automatically invalidates the signature. When
>> validating a client supporting this BIP would use both the normalized tx
>> ID as well as the legacy tx ID when validating transactions.
>> 
>> The detailed writeup can be found
>> here: https://github.com/cdecker/bips/blob/normalized-txid/bip-00nn.mediawiki.
>> 
>> @gmaxwell: I'd like to request a BIP number, unless there is something
>> really wrong with the proposal.
>> 
>> In addition to being a simple alternative that solves transaction
>> malleability it also hugely simplifies higher level protocols. We can
>> now use template transactions upon which sequences of transactions can
>> be built before signing them.
>> 
>> I hesitated quite a while to propose it since it does require a hardfork
>> (old clients would not find the prevTx identified by the normalized
>> transaction ID and deem the spending transaction invalid), but it seems
>> that hardforks are no longer the dreaded boogeyman nobody talks about.
>> I left out the details of how the hardfork is to be done, as it does not
>> really matter and we may have a good mechanism to apply a bunch of
>> hardforks concurrently in the future.
>> 
>> I'm sure it'll take time to implement and upgrade, but I think it would
>> be a nice addition to the functionality and would solve a long standing
>> problem :-)
>> 
>> Please let me know what you think, the proposal is definitely not set in
>> stone at this point and I'm sure we can improve it further.
>> 
>> Regards,
>> Christian
>> 
>> 
>> ------------------------------------------------------------------------------
>> One dashboard for servers and applications across Physical-Virtual-Cloud 
>> Widest out-of-the-box monitoring support with 50+ applications
>> Performance metrics, stats and reports that give you Actionable Insights
>> Deep dive visibility with transaction tracing using APM Insight.
>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>> 
>> 
>> 
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> 
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud 
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development



From stephencalebmorse at gmail.com  Sat May 16 04:39:53 2015
From: stephencalebmorse at gmail.com (Stephen)
Date: Sat, 16 May 2015 00:39:53 -0400
Subject: [Bitcoin-development] Block Size Increase Requirements
In-Reply-To: <20150509030833.GA28871@savin.petertodd.org>
References: <554BE0E1.5030001@bluematt.me>
	<CANEZrP3uKLvzKi-wXBJWL=pwqB+eAe3FbPjyESD52y5TGkg+Rg@mail.gmail.com>
	<20150508163701.GA27417@savin.petertodd.org>
	<CAE-z3OV8zyUyYiGNRZZbTkUZz70KK7P-ENyhsKe+yhZmNnqRuQ@mail.gmail.com>
	<20150509030833.GA28871@savin.petertodd.org>
Message-ID: <9BBD3F51-2FE0-4861-B045-6ACFC48AA21D@gmail.com>

Comments in line:

> On May 8, 2015, at 11:08 PM, Peter Todd <pete at petertodd.org> wrote:
> 
> Makes it trivial to find miners and DoS attack them - a huge risk to the
> network as a whole, as well as the miners.
> 
> Right now pools already get DoSed all the time through their work
> submission systems; getting DoS attacked via their nodes as well would
> be a disaster.

It seems that using a -miner flag to follow rules about smaller blocks would only reveal miner nodes if one sent the node a solved block that that was valid in every way except the block size. While not impossible, I wouldn't call this trivial, as it still requires wasting an entire block's worth of energy. 

>> When in "miner mode", the client would reject 4MB blocks and wouldn't build
>> on them.  The reference client might even track the miner and the non-miner
>> chain tip.
>> 
>> Miners would refuse to build on 5MB blocks, but merchants and general users
>> would accept them.
> 
> That'd be an excellent way to double-spend merchants, significantly
> increasing the chance that the double-spend would succeed as you only
> have to get sufficient hashing power to get the lucky blocks; you don't
> need enough hashing power to *also* ensure those blocks don't become the
> longest chain, removing the need to sybil attack your target.
> 

I think this could be mitigated by counting confirmations differently. We should think of confirmations as only coming from blocks following the miners' more strict rule set. So if a merchant were to see payment for the first time in a block that met their own size restrictions but not the miners', then they would simply count it as unconfirmed. 

If they get deep enough in the chain, though, the client should probably count them as being confirmed anyway, even if they don't meet the client nodes' expectation of the miners' block size limit. This happening probably just means that the client has not updated their software (or -minermaxblocksize configuration, depending on how it is implemented) in a long time. 

I actually like Tier's suggestion quite a bit. I think we could have the default client limit set to some higher number, and have miners agree out of band on the latest block size limit. Or maybe even build in a way to vote into the blockchain. 

Best, 
Stephen


From tier.nolan at gmail.com  Sat May 16 10:52:34 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Sat, 16 May 2015 11:52:34 +0100
Subject: [Bitcoin-development] [BIP] Normalized Transaction IDs
In-Reply-To: <AC0B3BAC-0934-46A3-B29A-F74238616F72@gmail.com>
References: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
	<5555C26F.7080706@sky-ip.org>
	<AC0B3BAC-0934-46A3-B29A-F74238616F72@gmail.com>
Message-ID: <CAE-z3OVNUyEwryKyAYvwokFdY6a8v7uDVRgnxGG7oSk29j86GA@mail.gmail.com>

On Sat, May 16, 2015 at 4:58 AM, Stephen <stephencalebmorse at gmail.com>
wrote:

> We should make sure to consider how BIP34 affects normalized transaction
> ids, since the height of the block is included in the scriptSig ensuring
> that the txid will be different. We wouldn't want to enable replay attacks
> in the form of spending coinbase outputs in the same way they were spent
> from a previous block.
>
> So maybe normalized txids should strip the scriptSigs of all transactions
> except for coinbase transactions? This seems to make sense, since coinbase
> transactions are inherently not malleable anyway.
>

That is a good point.  Since the point is the change is to use good
practice right back until the genesis block, maybe the scriptSig for
coinbases could be replaced by the height expressed as a varint.  That
means that all coinbases get a unique normalized txid.  The coinbases with
duplicate txids still wouldn't be spendable though.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150516/3f138563/attachment.html>

From tier.nolan at gmail.com  Sat May 16 11:09:50 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Sat, 16 May 2015 12:09:50 +0100
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <87a8x5l6bt.fsf@rustcorp.com.au>
References: <16096345.A1MpJQQkRW@crushinator>
	<CAOG=w-szbLgc1jLpkE_uMa3bkFTi-RiBEaQ6Y-u5aKLBC2HvUg@mail.gmail.com>
	<CAAS2fgQRS7w7RRNXVK_+=4CQ7=AWxWQQ7+Tf4tNUPTTZOf7rEQ@mail.gmail.com>
	<CAE-z3OUzYZDvsOYEDT229vnvNBa9ntW+86O3uA-K5-KaneMF_g@mail.gmail.com>
	<87a8x5l6bt.fsf@rustcorp.com.au>
Message-ID: <CAE-z3OXue5E0TzRhx6y8eTOTy=EARsrGwJ1qv8Kv1nbCsjVE_g@mail.gmail.com>

On Sat, May 16, 2015 at 1:22 AM, Rusty Russell <rusty at rustcorp.com.au>
wrote:

> Some tweaks:
>
> 1) Nomenclature: call tx_size "tx_cost" and real_size "tx_bytes"?
>

Fair enough.

>
> 2) If we have a reasonable hard *byte* limit, I don't think that we need
>    the MAX().  In fact, it's probably OK to go negative.
>

I agree, we want people to compress the UTXO space and a transaction with
100 inputs and one output is great.

It may have privacy problem though.


>
> 3) ... or maybe not, if any consumed UTXO was generated before the soft
>    fork (reducing Tier's perverse incentive).
>

The incentive problem can be fixed by excluding UTXOs from blocks before a
certain count.

UTXOs in blocks before 375000 don't count.


>
> 4) How do we measure UTXO size?  There are some constant-ish things in
>    there (eg. txid as key, height, outnum, amount).  Maybe just add 32
>    to scriptlen?
>

They can be stored as a fixed digest.  That can be any size, depending on
security requirements.

Gmaxwell's cost proposal is 3-4 bytes per UTXO change.  It isn't
4*UXTO.size - 3*UTXO.size

It is only a small nudge.  With only 10% of the block space to play with it
can't be massive.

This requires that transactions include scriptPubKey information when
broadcasting them.


>
> 5) Add a CHECKSIG cost.  Naively, since we allow 20,000 CHECKSIGs and
>    1MB blocks, that implies a cost of 50 bytes per CHECKSIG (but counted
>    correctly, unlike now).
>
> This last one implies that the initial cost limit would be 2M, but in
> practice probably somewhere in the middle.
>
>   tx_cost = 50*num-CHECKSIG
>                 + tx_bytes
>                 + 4*utxo_created_size
>                 - 3*utxo_consumed_size
>
> > A 250 byte transaction with 2 inputs and 2 outputs would have an adjusted
> > size of 252 bytes.
>
> Now cost == 352.
>

That is to large a cost for a 10% block change.  It could be included in
the block size hard fork though.  I think have one combined "cost" for
transactions is good.  It means much fewer spread out transaction checks.
The code for the cost formula would be in one place.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150516/8e5f1099/attachment.html>

From tier.nolan at gmail.com  Sat May 16 11:25:53 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Sat, 16 May 2015 12:25:53 +0100
Subject: [Bitcoin-development] Block Size Increase Requirements
In-Reply-To: <20150509030833.GA28871@savin.petertodd.org>
References: <554BE0E1.5030001@bluematt.me>
	<CANEZrP3uKLvzKi-wXBJWL=pwqB+eAe3FbPjyESD52y5TGkg+Rg@mail.gmail.com>
	<20150508163701.GA27417@savin.petertodd.org>
	<CAE-z3OV8zyUyYiGNRZZbTkUZz70KK7P-ENyhsKe+yhZmNnqRuQ@mail.gmail.com>
	<20150509030833.GA28871@savin.petertodd.org>
Message-ID: <CAE-z3OWzPSkxr3y0u7F8SQBQoWL7DASjZ1BHbYvhTBiWdJXWBA@mail.gmail.com>

On Sat, May 9, 2015 at 4:08 AM, Peter Todd <pete at petertodd.org> wrote:

> > I wonder if having a "miner" flag would be good for the network.
>
> Makes it trivial to find miners and DoS attack them - a huge risk to the
> network as a whole, as well as the miners.
>

To mitigate against this, two chaintips could be tracked.  The miner tip
and the client tip.

Miners would build on the miner tip.  When performing client services, like
wallets, they would use the client tip.

The client would act exactly the same as any node, the only change would be
that it gives miner work based on the mining tip.

If the two tips end up significantly forking, there would be a warning to
the miner and perhaps eventually refuse to give out new work.

That would happen when there was a miner level hard-fork.


> That'd be an excellent way to double-spend merchants, significantly
> increasing the chance that the double-spend would succeed as you only
> have to get sufficient hashing power to get the lucky blocks; you don't
> need enough hashing power to *also* ensure those blocks don't become the
> longest chain, removing the need to sybil attack your target.
>

To launch that attack, you need to produce fake blocks.  That is
expensive.

Stephen Cale's suggestion to wait more than one block before counting a
transaction as confirmed would also help mitigate.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150516/ef7854ef/attachment.html>

From tier.nolan at gmail.com  Sat May 16 11:29:14 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Sat, 16 May 2015 12:29:14 +0100
Subject: [Bitcoin-development] Block Size Increase Requirements
In-Reply-To: <9BBD3F51-2FE0-4861-B045-6ACFC48AA21D@gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CANEZrP3uKLvzKi-wXBJWL=pwqB+eAe3FbPjyESD52y5TGkg+Rg@mail.gmail.com>
	<20150508163701.GA27417@savin.petertodd.org>
	<CAE-z3OV8zyUyYiGNRZZbTkUZz70KK7P-ENyhsKe+yhZmNnqRuQ@mail.gmail.com>
	<20150509030833.GA28871@savin.petertodd.org>
	<9BBD3F51-2FE0-4861-B045-6ACFC48AA21D@gmail.com>
Message-ID: <CAE-z3OURNR1rAkKR1L9B9VRjTLNCP8xaa1hW4V8D-KWhWycRdA@mail.gmail.com>

On Sat, May 16, 2015 at 5:39 AM, Stephen <stephencalebmorse at gmail.com>
wrote:

> I think this could be mitigated by counting confirmations differently. We
> should think of confirmations as only coming from blocks following the
> miners' more strict rule set. So if a merchant were to see payment for the
> first time in a block that met their own size restrictions but not the
> miners', then they would simply count it as unconfirmed.
>

In effect, there is a confirm penalty for less strict blocks.  Confirms =
max(miner_confirms, merchant_confirms - 3, 0)

Merchants who don't upgrade end up having to wait longer to hit
confirmations.

If they get deep enough in the chain, though, the client should probably
> count them as being confirmed anyway, even if they don't meet the client
> nodes' expectation of the miners' block size limit. This happening probably
> just means that the client has not updated their software (or
> -minermaxblocksize configuration, depending on how it is implemented) in a
> long time.
>

That is a good idea.  Any parameters that have miner/merchant differences
should be modifiable (but only upwards) in the command line.

"Why are my transactions taking longer to confirm?"

"There was a soft fork to make the block size larger and your client is
being careful.  You need to add "minermaxblocksize=4MB" to your
bitcoin.conf file."

Hah, it could be called a "semi-hard fork"?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150516/e5dd0406/attachment.html>

From ogunden at phauna.org  Sat May 16 20:35:05 2015
From: ogunden at phauna.org (Owen Gunden)
Date: Sat, 16 May 2015 16:35:05 -0400
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <CACq0ZD6hDN0AY7jza46SuSA=-TqEii99oqR1gQyPt_vA+PqQgw@mail.gmail.com>
References: <5550D8BE.6070207@electrum.org>	<ce3d34c92efd1cf57326e4679550944e@national.shitposting.agency>	<CABsx9T1VgxEJWxrYTs+2hXGnGrSLGJ6mVcAexjXLvK7Vu+e3EA@mail.gmail.com>	<CABm2gDoQ-atjWKB0c6AC1ZQ9fy22ceFtHHwpLmnX8DLW4DAgYA@mail.gmail.com>	<CACq0ZD4_zxhm=qWrP+Nr+fQER4s2R8i7qRjX4HsBWN46uOP2MA@mail.gmail.com>	<CAPg+sBjxXe0spytGsP1BUzNZhJFDYu_yacdhTy5F+O-X8EG7NQ@mail.gmail.com>	<CACq0ZD7qF0oEYHfQFxLMn3OOD=ibVAfE-U5YURLrtmWVMzDpgQ@mail.gmail.com>	<CAPg+sBjs_y6Q7YAQjH1vd=WaRvObp+yuv-OcFFjg6umQ2=UCMQ@mail.gmail.com>
	<CACq0ZD6hDN0AY7jza46SuSA=-TqEii99oqR1gQyPt_vA+PqQgw@mail.gmail.com>
Message-ID: <5557A9F9.1080408@phauna.org>

On 05/13/2015 09:31 PM, Aaron Voisine wrote:
>  > by people and businesses deciding to not use on-chain settlement.
>
> I completely agree. Increasing fees will cause people voluntary
> economize on blockspace by finding alternatives, i.e. not bitcoin.

This strikes me as a leap. There are alternatives that still use bitcoin 
as the unit of value, such as sidechains, offchain, etc. To say that 
these are "not bitcoin" is misleading.

> A fee however is a known, upfront cost... unpredictable transaction failure in
> most cases will be a far higher, unacceptable cost to the user than the
> actual fee.

Are we sure that raising the block size is the only way to avoid 
"unpredictable transaction failure"? If so, and it's as bad as you say 
it is, aren't we screwed anyway when we inevitably start hitting the cap 
(even if it's raised 10x or 20x)? And if that's the case, then don't we 
do a disservice to users by continuing to pretend that we can make this 
problem go away?

> The higher the costs of using the system, the lower the
> adoption as a store-of-value.

On what do you base this? Gold has a very high cost of using (storage, 
transport) and yet is perhaps the most widely accepted store of value.



From tomh at thinlink.com  Sat May 16 22:18:59 2015
From: tomh at thinlink.com (Tom Harding)
Date: Sat, 16 May 2015 15:18:59 -0700
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <5557A9F9.1080408@phauna.org>
References: <5550D8BE.6070207@electrum.org>	<ce3d34c92efd1cf57326e4679550944e@national.shitposting.agency>	<CABsx9T1VgxEJWxrYTs+2hXGnGrSLGJ6mVcAexjXLvK7Vu+e3EA@mail.gmail.com>	<CABm2gDoQ-atjWKB0c6AC1ZQ9fy22ceFtHHwpLmnX8DLW4DAgYA@mail.gmail.com>	<CACq0ZD4_zxhm=qWrP+Nr+fQER4s2R8i7qRjX4HsBWN46uOP2MA@mail.gmail.com>	<CAPg+sBjxXe0spytGsP1BUzNZhJFDYu_yacdhTy5F+O-X8EG7NQ@mail.gmail.com>	<CACq0ZD7qF0oEYHfQFxLMn3OOD=ibVAfE-U5YURLrtmWVMzDpgQ@mail.gmail.com>	<CAPg+sBjs_y6Q7YAQjH1vd=WaRvObp+yuv-OcFFjg6umQ2=UCMQ@mail.gmail.com>	<CACq0ZD6hDN0AY7jza46SuSA=-TqEii99oqR1gQyPt_vA+PqQgw@mail.gmail.com>
	<5557A9F9.1080408@phauna.org>
Message-ID: <5557C253.3080308@thinlink.com>

On 5/16/2015 1:35 PM, Owen Gunden wrote:
> There are alternatives that still use bitcoin as the unit of value,
> such as sidechains, offchain, etc. To say that these are "not bitcoin"
> is misleading.


Is it?  Nobody thinks "euro accepted" implies Visa is ok, even though
Visa is just a bunch of extra protocol surrounding an eventual bank deposit.





From voisine at gmail.com  Sun May 17 01:08:16 2015
From: voisine at gmail.com (Aaron Voisine)
Date: Sat, 16 May 2015 18:08:16 -0700
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <5557A9F9.1080408@phauna.org>
References: <5550D8BE.6070207@electrum.org>
	<ce3d34c92efd1cf57326e4679550944e@national.shitposting.agency>
	<CABsx9T1VgxEJWxrYTs+2hXGnGrSLGJ6mVcAexjXLvK7Vu+e3EA@mail.gmail.com>
	<CABm2gDoQ-atjWKB0c6AC1ZQ9fy22ceFtHHwpLmnX8DLW4DAgYA@mail.gmail.com>
	<CACq0ZD4_zxhm=qWrP+Nr+fQER4s2R8i7qRjX4HsBWN46uOP2MA@mail.gmail.com>
	<CAPg+sBjxXe0spytGsP1BUzNZhJFDYu_yacdhTy5F+O-X8EG7NQ@mail.gmail.com>
	<CACq0ZD7qF0oEYHfQFxLMn3OOD=ibVAfE-U5YURLrtmWVMzDpgQ@mail.gmail.com>
	<CAPg+sBjs_y6Q7YAQjH1vd=WaRvObp+yuv-OcFFjg6umQ2=UCMQ@mail.gmail.com>
	<CACq0ZD6hDN0AY7jza46SuSA=-TqEii99oqR1gQyPt_vA+PqQgw@mail.gmail.com>
	<5557A9F9.1080408@phauna.org>
Message-ID: <CACq0ZD74KBt5+mfyupjvtMe9Q_CEimCedX=WmPe_cUDLydVuVQ@mail.gmail.com>

On Sat, May 16, 2015 at 1:35 PM, Owen Gunden <ogunden at phauna.org> wrote:

>
> This strikes me as a leap. There are alternatives that still use bitcoin
> as the unit of value, such as sidechains, offchain, etc. To say that
> these are "not bitcoin" is misleading.
>

The only options available today and in the near future that I'm aware of
are of the centralized custody variety, which is pretty bad in my opinion,
but your point is taken.


>
> Are we sure that raising the block size is the only way to avoid
> "unpredictable transaction failure"? If so, and it's as bad as you say
> it is, aren't we screwed anyway when we inevitably start hitting the cap
> (even if it's raised 10x or 20x)? And if that's the case, then don't we
> do a disservice to users by continuing to pretend that we can make this
> problem go away?
>

When we start bumping up against the block size limit, the transactions at
the margins will experience failure in a way that will be unpredictable to
current wallet software. We can slow blockchain growth by increasing fees
alone, without introducing the additional cost of unpredictability around
confirmation failure, which when it comes down to it is just another
(extreme) way to keep usage low. Instead of fees and unpredictable
confirmation, why not just have fees alone. A single, upfront, known cost.


>
>
> On what do you base this? Gold has a very high cost of using (storage,
> transport) and yet is perhaps the most widely accepted store of value.
>

I would argue that the reason gold is not the one world global currency
that it once was is because of those costs. That's why people shifted over
time to gold backed bank notes and eventually fiat.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150516/b3aa6233/attachment.html>

From ryanxcharles at gmail.com  Sun May 17 02:31:10 2015
From: ryanxcharles at gmail.com (Ryan X. Charles)
Date: Sat, 16 May 2015 19:31:10 -0700
Subject: [Bitcoin-development] No Bitcoin For You
In-Reply-To: <5554BDC1.6070206@thinlink.com>
References: <5554BDC1.6070206@thinlink.com>
Message-ID: <5557FD6E.2050903@gmail.com>

I agree with this analysis. I'm not sure if we will increase 1 MB
block size or not, but with a block size that small, it is all but
impossible for most people on the planet to ever own even a single utxo.

At 7tps, how long would it take to give 1 utxo to all of the 7 billion
people currently alive? It would take 1 billion seconds, or about 32
years.[1]  So for all practical purposes, at 1 MB block size, far less
than 1% of people will ever be able to own even a single satoshi.
Unless those people are willing to wait around 30 years for their
lightning network to settle, they will either not use bitcoin, or they
will use a substitute (such as a parallel decentralized network, or a
centralized service) that lacks the full trust-minimized security
guarantees of the main bitcoin blockchain.

I can't speak for most people, but for me personally, the thing I care
most about as an individual (besides being able to send bitcoin to and
from anyone on the planet) is being able to validate the blockchain.
With a pruning node, this means I need to download the blockchain one
time (not store it), and maintain the utxo set. The utxo set is,
roughly speaking, 30 bytes per utxo, and therefore, at one utxo per
person, about 7*30 billion bytes, or 210 GB. That's very achievable on
the hardware of today. Of course, some individuals or companies will
have far more than one utxo. Estimating an average of ten utxos per
person, that will be 2.1 TB. Also very achievable on the hardware of
today.

I don't think every transaction in the world should be on the
blockchain, but I think it should be able to handle (long-term) enough
transactions that everyone can have their transactions settled on a
timescale suitable for human life. 30 years is unsuitable, but 1 day
would be pretty good. It would be great if I could send trillions of
transactions per day on networks built on top of bitcoin, and have my
transactions settle on the actual blockchain once per day. This means
we would need to support about 1 utxo per person per day, or 7 billion
transactions per day. That translates to about 81 thousand
transactions per second [2], or approximately 10,000 times the current
rate. That would be 10 GB per ten minutes, which is achievable on
current hardware (albeit not yet inexpensively).

Using SPV security rather than pruning security makes the cost even
lower. A person relying on SPV would not have to download every 10 GB
block, but only their transactions (or a small superset of them),
which is already being done - scaling to 7 billion people would not
require that SPV nodes perform any more computation than they already
do. Nonetheless, I think pruning should be considered the default
minimum, since that it what is required to get the full
trust-minimized security guarantees of the blockchain. And that
requires 10 GB blocks (or thereabouts).

The number of people on the planet will also grow, perhaps to 14
billion people in the next few decades. However, the estimates here
would still be roughly correct. 10 GB blocks, or approximately so,
allows everyone in the world to have their transactions settled on the
blockchain in a timely manner, whereas 1 MB blocks do not. And this is
already achievable on current hardware. The most significant cost is
bandwidth, but that will probably become substantially less expensive
in the coming years, making it possible for everyone to inexpensively
and securely send and receive bitcoin to anyone else, without having
to use a parallel network with reduced security or rely on trusted
third parties.

[1] 10^9 / 60 / 60 / 24 / 365 ~= 32.

[2] 7*10^9 / 24 / 60 / 60 ~= 81018

On 05/14/2015 08:22 AM, Tom Harding wrote:
> A recent post, which I cannot find after much effort, made an 
> excellent point.
> 
> If capacity grows, fewer individuals would be able to run full
> nodes. Those individuals, like many already, would have to give up
> running a full-node wallet :(
> 
> That sounds bad, until you consider that the alternative is running
> a full node on the bitcoin 'settlement network', while massive
> numbers of people *give up any hope of directly owning bitcoin at
> all*.
> 
> If today's global payments are 100Ktps, and move to the Lightning 
> Network, they will have to be consolidated by a factor of 25000:1
> to fit into bitcoin's current 4tps capacity as a settlement
> network. You executing a personal transaction on that network will
> be about as likely as you personally conducting a $100 SWIFT
> transfer to yourself today. For current holders, just selling or
> spending will get very expensive!
> 
> Forcing block capacity to stay small, so that individuals can run 
> full nodes, is precisely what will force bitcoin to become a
> backbone that is too expensive for individuals to use.  I can't
> avoid the conclusion that Bitcoin has to scale, and we might as
> well be thinking about how.
> 
> There may be a an escape window.  As current trends continue toward
> a landscape of billions of SPV wallets, it may still be possible
> for individuals collectively to make up the majority of the
> network, if more parts of the network itself rely on SPV-level
> security.
> 
> With SPV-level security, it might be possible to implement a
> scalable DHT-type network of nodes that collectively store and
> index the exhaustive and fast-growing corpus of transaction
> history, up to and including currently unconfirmed transactions.
> Each individual node could host a slice of the transaction set with
> a configurable size, let's say down to a few GB today.
> 
> Such a network would have the desirable property of being run by
> the community.  Most transactions would be submitted to it, and
> like today's network, it would disseminate blocks (which would be
> rapidly torn apart and digested).  Therefore miners and other full
> nodes would depend on it, which is rather critical as those nodes
> grow closer to data-center proportions.
> 
> 
> 
> ------------------------------------------------------------------------------
>
>
>
> 
One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications 
> Performance metrics, stats and reports that give you Actionable 
> Insights Deep dive visibility with transaction tracing using APM 
> Insight. http://ad.doubleclick.net/ddm/clk/290420510;117567292;y 
> _______________________________________________ Bitcoin-development
>  mailing list Bitcoin-development at lists.sourceforge.net 
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> 

-- 
Ryan X. Charles
Software Engineer @BitGo

twitter.com/ryanxcharles
github.com/ryanxcharles
keybase.io/ryanxcharles
onename.com/ryanxcharles



From mtyljensen at gmail.com  Mon May 18 02:29:57 2015
From: mtyljensen at gmail.com (Michael Jensen)
Date: Mon, 18 May 2015 10:29:57 +0800
Subject: [Bitcoin-development] Long-term mining incentives
Message-ID: <CALinZAZJZPpaAug0QaqVvGo9TR7Agz+-t-QDe6jzqrZaKHRb3g@mail.gmail.com>

I think the basic reality is that a) an arbitrarily elevated level of
hashing is fundamental to a truly decentralised, autonomous network,
and is an essential cost to maintaining Bitcoin, b) there are no signs
that this fact will change, c) there must be some replacement to the
current system of incentivisation through debasement (inflation).

Arguments about limiting block size versus setting minimum fees are
confused because ultimately both mechanisms should ideally achieve the
same outcome: a market price for transactions which means that a) not
everyone who would make a TX if TXs were unpriced does so (reduced
number of TXs) and b) the market price is used to fund hashing. This
is just the nature of prices, it always reduces effective demand, but
without prices supply must collapse and the market must fail.

Regardless, if every time the network gets close to reaching the block
size limit the development community gets scared and raises the limit,
then such a limit will never be an effective tool for setting a market
price. Personally I think trying to artificially limit supply to
create a price for transactions is a needlessly complicated way of
trying to achieve this goal. I think minimum fees for transactions is
a better, simpler option.

I would go a step further and say that the development community will
struggle forever if it tries to play the role of the centralised
economic planner in setting prices for network services. The community
should look at more dynamic ways to let network users express their
preferences for security and their willingness to pay for it. I've
written on the issue -
https://medium.com/@mike0/securing-bitcoin-5-determing-an-optimal-funding-level-9873fa1322a7

As far as the argument that fees will drive people away from Bitcoin,
I can't believe that. Everything we desire has to be paid for somehow.
People will accept a fee for making Bitcoin transactions if Bitcoin as
a result is a stable, useful service. Bitcoin as both a currency and
as a transaction network has strong network effects, so, ignoring
sidechains, it's highly unrealistic that a mandatory fee will drive
people away from Bitcoin when the alternatives are dubious knock-offs
with no network effect, and fiat, which is even worse in regards to
the hidden and malignant costs it exacts.



From rusty at rustcorp.com.au  Mon May 18 01:42:11 2015
From: rusty at rustcorp.com.au (Rusty Russell)
Date: Mon, 18 May 2015 11:12:11 +0930
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CAE-z3OXue5E0TzRhx6y8eTOTy=EARsrGwJ1qv8Kv1nbCsjVE_g@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CAOG=w-szbLgc1jLpkE_uMa3bkFTi-RiBEaQ6Y-u5aKLBC2HvUg@mail.gmail.com>
	<CAAS2fgQRS7w7RRNXVK_+=4CQ7=AWxWQQ7+Tf4tNUPTTZOf7rEQ@mail.gmail.com>
	<CAE-z3OUzYZDvsOYEDT229vnvNBa9ntW+86O3uA-K5-KaneMF_g@mail.gmail.com>
	<87a8x5l6bt.fsf@rustcorp.com.au>
	<CAE-z3OXue5E0TzRhx6y8eTOTy=EARsrGwJ1qv8Kv1nbCsjVE_g@mail.gmail.com>
Message-ID: <878ucmslu4.fsf@rustcorp.com.au>

Tier Nolan <tier.nolan at gmail.com> writes:
> On Sat, May 16, 2015 at 1:22 AM, Rusty Russell <rusty at rustcorp.com.au>
> wrote:
>> 3) ... or maybe not, if any consumed UTXO was generated before the soft
>>    fork (reducing Tier's perverse incentive).
>
> The incentive problem can be fixed by excluding UTXOs from blocks before a
> certain count.
>
> UTXOs in blocks before 375000 don't count.

OK.  Be nice if these were cleaned up, but I guess it's a sunk cost.

>> 4) How do we measure UTXO size?  There are some constant-ish things in
>>    there (eg. txid as key, height, outnum, amount).  Maybe just add 32
>>    to scriptlen?
>>
>
> They can be stored as a fixed digest.  That can be any size, depending on
> security requirements.
>
> Gmaxwell's cost proposal is 3-4 bytes per UTXO change.  It isn't
> 4*UXTO.size - 3*UTXO.size

He said "utxo_created_size" not "utxo_created" so I assumed scriptlen?

> It is only a small nudge.  With only 10% of the block space to play with it
> can't be massive.

But you made that number up?  The soft cap and hard byte limit are
different beasts, so there's no need for soft cost cap < hard byte
limit.

> This requires that transactions include scriptPubKey information when
> broadcasting them.

Brilliant!  I completely missed that possibility...

>> 5) Add a CHECKSIG cost.  Naively, since we allow 20,000 CHECKSIGs and
>>    1MB blocks, that implies a cost of 50 bytes per CHECKSIG (but counted
>>    correctly, unlike now).
>>
>> This last one implies that the initial cost limit would be 2M, but in
>> practice probably somewhere in the middle.
>>
>>   tx_cost = 50*num-CHECKSIG
>>                 + tx_bytes
>>                 + 4*utxo_created_size
>>                 - 3*utxo_consumed_size
>>
>> > A 250 byte transaction with 2 inputs and 2 outputs would have an adjusted
>> > size of 252 bytes.
>>
>> Now cost == 352.
>
> That is to large a cost for a 10% block change.  It could be included in
> the block size hard fork though.

I don't think so.  Again, you're mixing units.

> I think have one combined "cost" for
> transactions is good.  It means much fewer spread out transaction checks.
> The code for the cost formula would be in one place.

Agreed!  Unfortunately there'll always be 2, because we really do want a
hard byte limit: it's total tx bytes which brings most concerns about
centralization.  But ideally it'll be so rarely hit that it can be ~
ignored (and certainly not optimized for).

Cheers,
Rusty.



From justus at openbitcoinprivacyproject.org  Mon May 18 16:16:48 2015
From: justus at openbitcoinprivacyproject.org (Justus Ranvier)
Date: Mon, 18 May 2015 18:16:48 +0200
Subject: [Bitcoin-development] Open Bitcoin Privacy Project Spring 2015
	Report
Message-ID: <555A1070.4000907@openbitcoinprivacyproject.org>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

We're produced the first in what we hope to be a long series of
reviews of Bitcoin wallet privacy features, available here:

http://www.openbitcoinprivacyproject.org/2015/05/spring-2015-wallet-privacy-rating-report/

https://github.com/OpenBitcoinPrivacyProject/wallet-ratings/raw/master/2015-1/OBPP%20Bitcoin%20Wallet%20Privacy%20Rating%20Report%20-%20Spring%202015.pdf

Specifically from the readers of this list, we are very interested in
feedback regarding our privacy threat model and the rating criteria we
derive from it.

Threat model:
https://github.com/OpenBitcoinPrivacyProject/wallet-ratings/blob/master/2015-1/threat%20model.wiki

Please send any suggestions or corrections via a GitHub issue to the
wallet-ratings repository so that we can incorporate it into future
reports.

- -- 
Justus Ranvier
Open Bitcoin Privacy Project
http://www.openbitcoinprivacyproject.org/
justus at openbitcoinprivacyproject.org
E7AD 8215 8497 3673 6D9E 61C4 2A5F DA70 EAD9 E623
-----BEGIN PGP SIGNATURE-----

iQIcBAEBAgAGBQJVWhBvAAoJECpf2nDq2eYj3JEP/jw/Xkgq4yZRE4FK8a8kPBqn
3ULyS74KtNyPDdpTK0bdH7//0d1ep+LvNpIkFhWCJ/WQ7T/Ft3iQl1HJvXGC0ZzM
XKd7ptXLpBrKElARAORgUlFPOeKzOrOyP4uvvGAMZ+CXEnKeyxDzK+WzfYnWyDEU
Q4XQ/ndwPqbZm9Nb+GeF186TXcA/KqcQEuOIw7/jFGHfFT6QBKVz1SraVrgdcMky
8KKYOsYJt8lTUjVN1INmLFoRZ0cGUd+IFKweSCibyAu9TdvVQfQSPfSnfZtDLk6X
g1oPYaxX6r9+/1zm2v5ISk97nKrvNslPjeQbuW3vWlROSxGZ9lV+MVNvkqm1jSpF
ip0Il+VJb8hhh9LRJV6euhLQyR+xnLIVJvslJt883rhKIBi3M/OipMuhipIeAbnV
0WQmnpQ9ZgagPoFRxGp86Cz7PWTfj7zllB3yk/M3tA8e64VQFhEnoyJO8hPqfEQh
wPZP3UQ+K3PM/2oe4W5ZkfkqD6tIzGTQeMkGFeCvTsMmsW9+Ml8j4YTwKA0z5vr5
IebJ51Vpaq1noVEl46q8utpLp1wATI8SG5sBwSaR4/REUGkSWjSCeZeLcK8WzdEa
SaZ8t5Rqr1AcwtD6n9rVvYoF26285120jM/YX8XgMldWi0RXrlWD4B4lA1i7eVfZ
hINSIR+QsJsw7yq7Ox3/
=NMNo
-----END PGP SIGNATURE-----
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0xEAD9E623.asc
Type: application/pgp-keys
Size: 18381 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150518/fd9f9a2c/attachment.bin>

From justus at openbitcoinprivacyproject.org  Mon May 18 21:57:09 2015
From: justus at openbitcoinprivacyproject.org (Justus Ranvier)
Date: Mon, 18 May 2015 23:57:09 +0200
Subject: [Bitcoin-development] Open Bitcoin Privacy Project Spring 2015
 Report
In-Reply-To: <CABr1YTeWFRhdwJgDa3Ly6Y-Y-s5vtka_bHT7kcT69ydX2o3Ruw@mail.gmail.com>
References: <555A1070.4000907@openbitcoinprivacyproject.org>
	<CABr1YTeWFRhdwJgDa3Ly6Y-Y-s5vtka_bHT7kcT69ydX2o3Ruw@mail.gmail.com>
Message-ID: <555A6035.8090202@openbitcoinprivacyproject.org>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Replying to the list because this is a common question.

We rated as many wallets as we could based on the amount of manpower
we had available to perform the ratings.

We will be holding a recruiting drive shortly to solicit additional
volunteers so that we can cover more wallet for the next round of ratings.


On 05/18/2015 11:40 PM, Eric Lombrozo wrote:
> mSIGNA is notably absent from the report despite having some of the
> most advanced security and privacy features and having been on the
> bitcoin.org site longer than some of the other wallets reviewed.
> 
> Is there some process to get reviewed I missed? Please add us to
> the report.

- -- 
Justus Ranvier
Open Bitcoin Privacy Project
http://www.openbitcoinprivacyproject.org/
justus at openbitcoinprivacyproject.org
E7AD 8215 8497 3673 6D9E 61C4 2A5F DA70 EAD9 E623
-----BEGIN PGP SIGNATURE-----

iQIcBAEBAgAGBQJVWmA1AAoJECpf2nDq2eYjXGgP/2CpIYpG49WKAfG/PXmu1zFV
+zzU/7PCz+0ez0mGCz5l3QMc9TCDs6KDx0sPHZngwwLio3C4JMpu+zfnw6gngw/G
6NNtmDZ9xWgWx3kQyBLWBCM/K63rLE1QYJqiIc7QaDuDTk5w0upwkFxLejWeem1j
Z8Zy6ycHNNHE19o5pIYViWaRXojMD70fBFSoU9sAyvnOup7b5Cj4PLx7mbMbaegV
gCHd7zd88AH0f2ilFiVMQJBKf03KzYjarRVrAyvAb/8VLiYMRC8SS3y2tzM+qRKl
ZADAp8FiQ6GOFRssNg+x7tc3DX2ngBljLLKM90kPLR2cvwp8VHi0I0biqM8n2M17
CMjZVRNvXitNnKFc42nk51HsZR5LkDK3Rf9I1E3fBVKJ5feEbDi3tlEg9PCWD2xM
PmSRzXoUBAjpr9xL2kBzlE4aTYZCmmMxAMF1mcSYujdNzQ2IN0gD1urJtCwZ8zZ1
LL2cPimS3GTWEpoQQ/Fu+0NDwiPditDGt+DN16Mi5uioPvaumHMIV6u9ZNdD9ZEv
UTGW8C2Hj+ENzqhpdhlV5YfYUnKo6/ukw+xxTXRxbbLGxA6iRrVnPzsYTZoF0Vrt
T4IsdzPIg5yeF5IQKEV1lLyx+gOIvmDF1RZE36NY8bGn2zusFzUGxiqWa6yw0hfw
l4ytd8pfhIvTkuz1o9aQ
=kWhU
-----END PGP SIGNATURE-----
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0xEAD9E623.asc
Type: application/pgp-keys
Size: 18381 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150518/58a72a8b/attachment.bin>

From laanwj at gmail.com  Tue May 19 08:25:57 2015
From: laanwj at gmail.com (Wladimir J. van der Laan)
Date: Tue, 19 May 2015 10:25:57 +0200
Subject: [Bitcoin-development] Bitcoin Core 0.9.5 release candidate 1 tagged
Message-ID: <20150519082555.GA17273@amethyst.visucore.com>

Hello,

I've just tagged release candidate 1 for 0.9.5 (tag `v0.9.5rc1`).

The reason for this backport release is to make BIP66 available on the 0.9 branch. This has been requested by a few users, mostly miners.

Full (preliminary) release notes can be found at: 
https://github.com/bitcoin/bitcoin/blob/0.9/doc/release-notes.md

In contrast to 0.10.x releases it is unclear whether there will be enough gitian signatures for a binary release, any help with building is welcome.
See https://github.com/bitcoin/bitcoin/blob/0.9/doc/release-process.md
(many steps have changed since then, so the release process for 0.10 or master will not work)

Wladimir



From decker.christian at gmail.com  Tue May 19 08:28:58 2015
From: decker.christian at gmail.com (Christian Decker)
Date: Tue, 19 May 2015 08:28:58 +0000
Subject: [Bitcoin-development] [BIP] Normalized Transaction IDs
In-Reply-To: <AC0B3BAC-0934-46A3-B29A-F74238616F72@gmail.com>
References: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
	<5555C26F.7080706@sky-ip.org>
	<AC0B3BAC-0934-46A3-B29A-F74238616F72@gmail.com>
Message-ID: <CALxbBHXC=jc+7Vj-3-VT7kj-+V6ORdeJPr_G9ymOcJyFZ3hy=A@mail.gmail.com>

Thanks Stephen, I hadn't thought about BIP 34 and we need to address this
in both proposals. If we can avoid it I'd like not to have one transaction
hashed one way and other transactions in another way.

Since BIP 34 explicitly uses the scriptSig to make the coinbase transaction
unique, simply removing the scriptSig is not an option as it would
potentially cause collisions. I don't remember why the scriptSig was
chosen, but we also have the option of putting the blockchain height in the
sequence number of the coinbase input or the locktime of the transaction,
restoring the uniqueness constraint in normalized transaction IDs (for both
proposals). Is there a specific reason why that was not chosen at the time?

On Sat, May 16, 2015 at 5:58 AM Stephen <stephencalebmorse at gmail.com> wrote:

> We should make sure to consider how BIP34 affects normalized transaction
> ids, since the height of the block is included in the scriptSig ensuring
> that the txid will be different. We wouldn't want to enable replay attacks
> in the form of spending coinbase outputs in the same way they were spent
> from a previous block.
>
> So maybe normalized txids should strip the scriptSigs of all transactions
> except for coinbase transactions? This seems to make sense, since coinbase
> transactions are inherently not malleable anyway.
>
> Also, s7r linked to my 'Build your own nHashType' proposal (although V2 is
> here:
> https://github.com/scmorse/bitcoin-misc/blob/master/sighash_proposal_v2.md).
> I just wanted to add that I think even with normalized ids, it could still
> be useful to be able to apply these flags to choose which parts of the
> transaction become signed. I've also seen vague references to some kind of
> a merklized abstract syntax tree, but am not fully sure how that would
> work. Maybe someone on here could explain it?
>
> Best,
> Stephen
>
>
>
> > On May 15, 2015, at 5:54 AM, s7r <s7r at sky-ip.org> wrote:
> >
> > Hello,
> >
> > How will this exactly be safe against:
> > a) the malleability of the parent tx (2nd level malleability)
> > b) replays
> >
> > If you strip just the scriptSig of the input(s), the txid(s) can still
> > be mutated (with higher probability before it gets confirmed).
> >
> > If you strip both the scriptSig of the parent and the txid, nothing can
> > any longer be mutated but this is not safe against replays. This could
> > work if we were using only one scriptPubKey per tx. But this is not
> > enforced, and I don't think it's the proper way to do it.
> >
> > Something similar can be achieved if you would use a combination of
> > flags from here:
> >
> > https://github.com/scmorse/bitcoin-misc/blob/master/sighash_proposal.md
> >
> > But this has some issues too.
> >
> > I've read your draft but didn't understand how exactly will this prevent
> > normal malleability as we know it, second level malleability and replays
> > as well as how will we do the transition into mapping the txes in the
> > blockchain to normalized txids. Looking forward to read more on this
> > topic. Thanks for the brainstorming ;)
> >
> >
> >> On 5/13/2015 3:48 PM, Christian Decker wrote:
> >> Hi All,
> >>
> >> I'd like to propose a BIP to normalize transaction IDs in order to
> >> address transaction malleability and facilitate higher level protocols.
> >>
> >> The normalized transaction ID is an alias used in parallel to the
> >> current (legacy) transaction IDs to address outputs in transactions. It
> >> is calculated by removing (zeroing) the scriptSig before computing the
> >> hash, which ensures that only data whose integrity is also guaranteed by
> >> the signatures influences the hash. Thus if anything causes the
> >> normalized ID to change it automatically invalidates the signature. When
> >> validating a client supporting this BIP would use both the normalized tx
> >> ID as well as the legacy tx ID when validating transactions.
> >>
> >> The detailed writeup can be found
> >> here:
> https://github.com/cdecker/bips/blob/normalized-txid/bip-00nn.mediawiki.
> >>
> >> @gmaxwell: I'd like to request a BIP number, unless there is something
> >> really wrong with the proposal.
> >>
> >> In addition to being a simple alternative that solves transaction
> >> malleability it also hugely simplifies higher level protocols. We can
> >> now use template transactions upon which sequences of transactions can
> >> be built before signing them.
> >>
> >> I hesitated quite a while to propose it since it does require a hardfork
> >> (old clients would not find the prevTx identified by the normalized
> >> transaction ID and deem the spending transaction invalid), but it seems
> >> that hardforks are no longer the dreaded boogeyman nobody talks about.
> >> I left out the details of how the hardfork is to be done, as it does not
> >> really matter and we may have a good mechanism to apply a bunch of
> >> hardforks concurrently in the future.
> >>
> >> I'm sure it'll take time to implement and upgrade, but I think it would
> >> be a nice addition to the functionality and would solve a long standing
> >> problem :-)
> >>
> >> Please let me know what you think, the proposal is definitely not set in
> >> stone at this point and I'm sure we can improve it further.
> >>
> >> Regards,
> >> Christian
> >>
> >>
> >>
> ------------------------------------------------------------------------------
> >> One dashboard for servers and applications across Physical-Virtual-Cloud
> >> Widest out-of-the-box monitoring support with 50+ applications
> >> Performance metrics, stats and reports that give you Actionable Insights
> >> Deep dive visibility with transaction tracing using APM Insight.
> >> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> >>
> >>
> >>
> >> _______________________________________________
> >> Bitcoin-development mailing list
> >> Bitcoin-development at lists.sourceforge.net
> >> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> >
> >
> ------------------------------------------------------------------------------
> > One dashboard for servers and applications across Physical-Virtual-Cloud
> > Widest out-of-the-box monitoring support with 50+ applications
> > Performance metrics, stats and reports that give you Actionable Insights
> > Deep dive visibility with transaction tracing using APM Insight.
> > http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> > _______________________________________________
> > Bitcoin-development mailing list
> > Bitcoin-development at lists.sourceforge.net
> > https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150519/f943227e/attachment.html>

From tier.nolan at gmail.com  Tue May 19 08:59:27 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Tue, 19 May 2015 09:59:27 +0100
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <878ucmslu4.fsf@rustcorp.com.au>
References: <16096345.A1MpJQQkRW@crushinator>
	<CAOG=w-szbLgc1jLpkE_uMa3bkFTi-RiBEaQ6Y-u5aKLBC2HvUg@mail.gmail.com>
	<CAAS2fgQRS7w7RRNXVK_+=4CQ7=AWxWQQ7+Tf4tNUPTTZOf7rEQ@mail.gmail.com>
	<CAE-z3OUzYZDvsOYEDT229vnvNBa9ntW+86O3uA-K5-KaneMF_g@mail.gmail.com>
	<87a8x5l6bt.fsf@rustcorp.com.au>
	<CAE-z3OXue5E0TzRhx6y8eTOTy=EARsrGwJ1qv8Kv1nbCsjVE_g@mail.gmail.com>
	<878ucmslu4.fsf@rustcorp.com.au>
Message-ID: <CAE-z3OVLwZzyc0JSjdqqSXctQMJfRRdRi3OAm9hRB_dVDHhELA@mail.gmail.com>

On Mon, May 18, 2015 at 2:42 AM, Rusty Russell <rusty at rustcorp.com.au>
wrote:

> OK.  Be nice if these were cleaned up, but I guess it's a sunk cost.
>

Yeah.

On the plus side, as people spend their money, old UTXOs would be used up
and then they would be included in the cost function.  It is only people
who are storing their money long term that wouldn't.

They are unlikely to have consumed their UTXOs anyway, unless miners
started paying for UTXOs.

We could make it a range.

UTXOs from below 355,000 and above 375,000 are included.  That can create
incentive problems for the next similar change, I think a future threshold
is better.


>  He said "utxo_created_size" not "utxo_created" so I assumed scriptlen?
>

Maybe I mis-read.


> But you made that number up?  The soft cap and hard byte limit are
> different beasts, so there's no need for soft cost cap < hard byte
> limit.
>

I was thinking about it being a soft-fork.

If it was combined with the 20MB limit change, then it can be anything.

I made a suggestion somewhere (her or forums not sure), that transactions
should be allowed to store bytes.

For example, a new opcode could be added, <byte_count> OP_LOCK_BYTES.

This makes the transaction seem <byte_count> larger.  However, when
spending the UTXO, that transaction counts as <byte_count> smaller, even
against the hard-cap.

This would be useful for channels.  If channels were 100-1000X the
blockchain volume and someone caused lots of channels to close, there
mightn't be enough space for all the close channel transactions.  Some
people might be able to get their refund transactions included in the
blockchain because the timeout expires.

If transactions could store enough space to be spent, then a mass channel
close would cause some very large blocks, but then they would have to be
followed by lots of tiny blocks.

The block limit would be an average not fixed per block.  There would be 3
limits

Absolute hard limit (max bytes no matter what): 100MB
Hard limit (max bytes after stored bytes offset): 30MB
Soft limit (max bytes equivalents): 10MB

Blocks lager than ~32MB require a new network protocol, which makes the
hard fork even "harder".  The protocol change could be "messages can now be
150MB max" though, so maybe not so complex.


>
> > This requires that transactions include scriptPubKey information when
> > broadcasting them.
>
> Brilliant!  I completely missed that possibility...
>

I have written a BIP about it.  It is still in the draft stage.  I had a
look into writing up the code for the protocol change.

https://github.com/TierNolan/bips/blob/extended_transactions/bip-etx.mediawiki
https://github.com/TierNolan/bips/blob/extended_transactions/bip-etx-fork.mediawiki
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150519/32dabf8f/attachment.html>

From tier.nolan at gmail.com  Tue May 19 09:13:17 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Tue, 19 May 2015 10:13:17 +0100
Subject: [Bitcoin-development] [BIP] Normalized Transaction IDs
In-Reply-To: <CALxbBHXC=jc+7Vj-3-VT7kj-+V6ORdeJPr_G9ymOcJyFZ3hy=A@mail.gmail.com>
References: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
	<5555C26F.7080706@sky-ip.org>
	<AC0B3BAC-0934-46A3-B29A-F74238616F72@gmail.com>
	<CALxbBHXC=jc+7Vj-3-VT7kj-+V6ORdeJPr_G9ymOcJyFZ3hy=A@mail.gmail.com>
Message-ID: <CAE-z3OXC-uCYQmhGJd2ZVfLrEbAZVhEz0ejkbwmcRgK3kbjSrg@mail.gmail.com>

On Tue, May 19, 2015 at 9:28 AM, Christian Decker <
decker.christian at gmail.com> wrote:

> Thanks Stephen, I hadn't thought about BIP 34 and we need to address this
> in both proposals. If we can avoid it I'd like not to have one
> transaction hashed one way and other transactions in another way.
>

The normalized TXID cannot depend on height for other transactions.
Otherwise, it gets mutated when been added to the chain, depending on
height.

An option would be that the height is included in the scriptSig for all
transactions, but for non-coinbase transctions, the height used is zero.

I think if height has to be an input into the normalized txid function, the
specifics of inclusion don't matter.

The previous txid for coinbases are required to be all zeros, so the
normalized txid could be to add the height to the txids of all inputs.
Again, non-coinbase transactions would have heights of zero.


> Is there a specific reason why that was not chosen at the time?
>

I assumed that since the scriptSig in the coinbase is specifically intended
to be "random" bytes/extra nonce, so putting a restriction on it was
guaranteed to be backward compatible.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150519/acacf82f/attachment.html>

From decker.christian at gmail.com  Tue May 19 10:43:39 2015
From: decker.christian at gmail.com (Christian Decker)
Date: Tue, 19 May 2015 10:43:39 +0000
Subject: [Bitcoin-development] [BIP] Normalized Transaction IDs
In-Reply-To: <CAE-z3OXC-uCYQmhGJd2ZVfLrEbAZVhEz0ejkbwmcRgK3kbjSrg@mail.gmail.com>
References: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
	<5555C26F.7080706@sky-ip.org>
	<AC0B3BAC-0934-46A3-B29A-F74238616F72@gmail.com>
	<CALxbBHXC=jc+7Vj-3-VT7kj-+V6ORdeJPr_G9ymOcJyFZ3hy=A@mail.gmail.com>
	<CAE-z3OXC-uCYQmhGJd2ZVfLrEbAZVhEz0ejkbwmcRgK3kbjSrg@mail.gmail.com>
Message-ID: <CALxbBHUvtoc25Eyh1KF=bmG8SbZd_UpO1QeUVLbicNqJQPHBLQ@mail.gmail.com>

On Tue, May 19, 2015 at 11:16 AM Tier Nolan <tier.nolan at gmail.com> wrote:

> On Tue, May 19, 2015 at 9:28 AM, Christian Decker <
> decker.christian at gmail.com> wrote:
>
>> Thanks Stephen, I hadn't thought about BIP 34 and we need to address this
>> in both proposals. If we can avoid it I'd like not to have one
>> transaction hashed one way and other transactions in another way.
>>
>
> The normalized TXID cannot depend on height for other transactions.
> Otherwise, it gets mutated when been added to the chain, depending on
> height.
>
Well in the case of coinbase transactions we want them to be dependent on
the height they are included in, which is not a problem since they are only
valid in conjunction with the block that mined them.

>
> An option would be that the height is included in the scriptSig for all
> transactions, but for non-coinbase transctions, the height used is zero.
>
No need to add an extra field to the transaction just to include the
height. We can just add a rule that the height specified in the scriptSig
in coinbase transactions (and only coinbase transactions) is copied into
the locktime of the transaction before computing the normalized transaction
ID and leave the locktime untouched for all normal transactions

>
> I think if height has to be an input into the normalized txid function,
> the specifics of inclusion don't matter.
>
> The previous txid for coinbases are required to be all zeros, so the
> normalized txid could be to add the height to the txids of all inputs.
> Again, non-coinbase transactions would have heights of zero.
>
>
>> Is there a specific reason why that was not chosen at the time?
>>
>
> I assumed that since the scriptSig in the coinbase is specifically
> intended to be "random" bytes/extra nonce, so putting a restriction on it
> was guaranteed to be backward compatible.
>
Sounds reasonable :-)

>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150519/ffe7ffe5/attachment.html>

From jonas.schnelli at include7.ch  Tue May 19 11:19:09 2015
From: jonas.schnelli at include7.ch (Jonas Schnelli)
Date: Tue, 19 May 2015 13:19:09 +0200
Subject: [Bitcoin-development] Open Bitcoin Privacy Project Spring 2015
	Report
In-Reply-To: <555A6035.8090202@openbitcoinprivacyproject.org>
References: <555A1070.4000907@openbitcoinprivacyproject.org>
	<CABr1YTeWFRhdwJgDa3Ly6Y-Y-s5vtka_bHT7kcT69ydX2o3Ruw@mail.gmail.com>
	<555A6035.8090202@openbitcoinprivacyproject.org>
Message-ID: <06592803-84A2-4D9F-B4AB-8D0673517BC5@include7.ch>




Freundliche Gr?sse
---
Jonas Schnelli

??????????????????????????????????????????????????
include7 AG
Jonas Schnelli
Mattengasse 27
CH-8005 Z?rich
Switzerland
Office: +41 44 500 16 70

Mail: jonas.schnelli at include7.ch
Web: www.include7.ch
V-Card: www.include7.ch/js.vcf
??????????????????????????????????????????????????

ACHTUNG
Bitte senden sie uns keine sensitiven Daten in unverschl?sselten E-Mails.
Verwenden Sie hierzu folgenden Link:
https://include7.ch/contact/secureform

??????????????????????????????????????????????????

> Am 18.05.2015 um 23:57 schrieb Justus Ranvier <justus at openbitcoinprivacyproject.org>:
> 
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
> 
> Replying to the list because this is a common question.
> 
> We rated as many wallets as we could based on the amount of manpower
> we had available to perform the ratings.
> 
> We will be holding a recruiting drive shortly to solicit additional
> volunteers so that we can cover more wallet for the next round of ratings.
> 

Hi Justus

Is there a reason why Bitcoin-Core and Breadwallet (iOS) is missing?

Thanks
?
</Jonas>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150519/9d785e63/attachment.html>

From jonas.schnelli at include7.ch  Tue May 19 11:50:03 2015
From: jonas.schnelli at include7.ch (Jonas Schnelli)
Date: Tue, 19 May 2015 13:50:03 +0200
Subject: [Bitcoin-development] Open Bitcoin Privacy Project Spring 2015
	Report
In-Reply-To: <06592803-84A2-4D9F-B4AB-8D0673517BC5@include7.ch>
References: <555A1070.4000907@openbitcoinprivacyproject.org>
	<CABr1YTeWFRhdwJgDa3Ly6Y-Y-s5vtka_bHT7kcT69ydX2o3Ruw@mail.gmail.com>
	<555A6035.8090202@openbitcoinprivacyproject.org>
	<06592803-84A2-4D9F-B4AB-8D0673517BC5@include7.ch>
Message-ID: <3C25F5DC-D50B-43D1-8A52-A9A3C49181DA@include7.ch>

> 
>> Am 18.05.2015 um 23:57 schrieb Justus Ranvier <justus at openbitcoinprivacyproject.org <mailto:justus at openbitcoinprivacyproject.org>>:
>> 
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA1
>> 
>> Replying to the list because this is a common question.
>> 
>> We rated as many wallets as we could based on the amount of manpower
>> we had available to perform the ratings.
>> 
>> We will be holding a recruiting drive shortly to solicit additional
>> volunteers so that we can cover more wallet for the next round of ratings.
>> 
> 
> Hi Justus
> 
> Is there a reason why Bitcoin-Core and Breadwallet (iOS) is missing?
> 
> Thanks
> ?
> </Jonas>

Sorry for the horrible top post, i accidentally added a text signature on top.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150519/7a245dd9/attachment.html>

From stephencalebmorse at gmail.com  Tue May 19 12:48:20 2015
From: stephencalebmorse at gmail.com (Stephen Morse)
Date: Tue, 19 May 2015 08:48:20 -0400
Subject: [Bitcoin-development] [BIP] Normalized Transaction IDs
In-Reply-To: <CALxbBHUvtoc25Eyh1KF=bmG8SbZd_UpO1QeUVLbicNqJQPHBLQ@mail.gmail.com>
References: <CALxbBHUnt7ToVK9reH6W6uT4HV=7NbxGHyNWWa-OEHg+Z1+qOg@mail.gmail.com>
	<5555C26F.7080706@sky-ip.org>
	<AC0B3BAC-0934-46A3-B29A-F74238616F72@gmail.com>
	<CALxbBHXC=jc+7Vj-3-VT7kj-+V6ORdeJPr_G9ymOcJyFZ3hy=A@mail.gmail.com>
	<CAE-z3OXC-uCYQmhGJd2ZVfLrEbAZVhEz0ejkbwmcRgK3kbjSrg@mail.gmail.com>
	<CALxbBHUvtoc25Eyh1KF=bmG8SbZd_UpO1QeUVLbicNqJQPHBLQ@mail.gmail.com>
Message-ID: <CABHVRKSSCX8VS=T-bim_rw6VMJP-hnUi8AzLHyDM57KQi2zn+w@mail.gmail.com>

>
> An option would be that the height is included in the scriptSig for all
>> transactions, but for non-coinbase transctions, the height used is zero.
>>
> No need to add an extra field to the transaction just to include the
> height. We can just add a rule that the height specified in the scriptSig
> in coinbase transactions (and only coinbase transactions) is copied into
> the locktime of the transaction before computing the normalized transaction
> ID and leave the locktime untouched for all normal transactions
>

No need to replace lock times (or any other part of the transaction) at
all. If you have to, just serialize the height right before serializing the
transaction (into the same buffer). And you could pre-serialize 0 instead
of the height for all non-coinbase transactions. I don't really see what
that gets you, though, because the 0 is not really doing anything.

But, I don't see any reason you have to mess with the serialization this
much at all. Just do:

uint256 normalized_txid(CTransaction tx)
{
  // Coinbase transactions are already normalized
  if (!tx.IsCoinbase())
  {
    foreach(CTxIn in : tx.vin)
    {
      if (!ReplacePrevoutHashWithNormalizedHash(in.prevout))
        throw NormalizationError("Could not lookup prevout");
      in.scriptSig.clear();
    }
  }

  // Serialize
  CHashWriter ss(SER_GETHASH, 0);
  ss << tx;
  return ss.GetHash();
}

An alternative could be (although I like the above option better):

uint256 normalized_txid(CTransaction tx, int nHeight)
{
  foreach(CTxIn in : tx.vin)
  {
    if (!in.prevout.IsNull() &&
!ReplacePrevoutHashWithNormalizedHash(in.prevout))
      throw NormalizationError("Could not lookup prevout");
    in.scriptSig.clear();
  }

  // Serialize
  CHashWriter ss(SER_GETHASH, 0);

if (tx.IsCoinbase())
ss << nHeight;
// or:
// ss << (tx.IsCoinbase() ? nHeight : 0);

  ss << tx;
  return ss.GetHash();
}
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150519/308eb60e/attachment.html>

From laanwj at gmail.com  Tue May 19 13:44:09 2015
From: laanwj at gmail.com (Wladimir J. van der Laan)
Date: Tue, 19 May 2015 15:44:09 +0200
Subject: [Bitcoin-development] Bitcoin Core 0.10.2 released
Message-ID: <20150519134408.GB22164@amethyst.visucore.com>





From laanwj at gmail.com  Tue May 19 14:29:16 2015
From: laanwj at gmail.com (Wladimir)
Date: Tue, 19 May 2015 14:29:16 +0000
Subject: [Bitcoin-development] Bitcoin Core 0.10.2 released
In-Reply-To: <20150519134408.GB22164@amethyst.visucore.com>
References: <20150519134408.GB22164@amethyst.visucore.com>
Message-ID: <CA+s+GJB=MqFs1aVCeyXj0b3fjpBe+6S6Y=WUcKcMzQv2KGAzQQ@mail.gmail.com>

Bitcoin Core version 0.10.2 is now available from:

  <https://bitcoin.org/bin/bitcoin-core-0.10.2/>

The distribution is also available as torrent:

   https://bitcoin.org/bin/bitcoin-core-0.10.2/bitcoin-0.10.2.torrent

   magnet:?xt=urn:btih:746a616aa8de97856c207e7a899c7ee315e8c44d&dn=bitcoin-core-0.10.2&tr=udp%3A%2F%2Ftracker.openbittorrent.com%3A80%2Fannounce&tr=udp%3A%2F%2Ftracker.publicbt.com%3A80%2Fannounce&tr=udp%3A%2F%2Ftracker.ccc.de%3A80%2Fannounce&tr=udp%3A%2F%2Ftracker.coppersurfer.tk%3A6969&tr=udp%3A%2F%2Fopen.demonii.com%3A1337&ws=https%3A%2F%2Fbitcoin.org%2Fbin%2

The source code can be found in git under the tag `v0.10.2`, or in
`bitcoin-0.10.2.tar.gz` in the distribution.

This is a new minor version release, bringing minor bug fixes and translation
updates. It is only necessary to upgrade to this version when unable
to start the
application on Windows with 0.10.1.

Please report bugs using the issue tracker at github:

  <https://github.com/bitcoin/bitcoin/issues>

Upgrading and downgrading
=========================

How to Upgrade
--------------

If you are running an older version, shut it down. Wait until it has completely
shut down (which might take a few minutes for older versions), then run the
installer (on Windows) or just copy over /Applications/Bitcoin-Qt (on Mac) or
bitcoind/bitcoin-qt (on Linux).

Downgrade warning
------------------

Because release 0.10.0 and later makes use of headers-first synchronization and
parallel block download (see further), the block files and databases are not
backwards-compatible with pre-0.10 versions of Bitcoin Core or other software:

* Blocks will be stored on disk out of order (in the order they are
received, really), which makes it incompatible with some tools or
other programs. Reindexing using earlier versions will also not work
anymore as a result of this.

* The block index database will now hold headers for which no block is
stored on disk, which earlier versions won't support.

If you want to be able to downgrade smoothly, make a backup of your entire data
directory. Without this your node will need start syncing (or importing from
bootstrap.dat) anew afterwards. It is possible that the data from a completely
synchronised 0.10 node may be usable in older versions as-is, but this is not
supported and may break as soon as the older version attempts to reindex.

This does not affect wallet forward or backward compatibility.

Notable changes
===============

This fixes a serious problem on Windows with data directories that
have non-ASCII
characters (https://github.com/bitcoin/bitcoin/issues/6078).

For other platforms there are no notable changes.

For the notable changes in 0.10, refer to the release notes
at https://github.com/bitcoin/bitcoin/blob/v0.10.0/doc/release-notes.md

0.10.2 Change log
=================

Detailed release notes follow. This overview includes changes that
affect external
behavior, not code moves, refactors or string updates.

Wallet:
- `824c011` fix boost::get usage with boost 1.58

Miscellaneous:
- `da65606` Avoid crash on start in TestBlockValidity with gen=1.
- `424ae66` don't imbue boost::filesystem::path with locale "C" on
windows (fixes #6078)

Credits
=======

Thanks to everyone who directly contributed to this release:

- Cory Fields
- Gregory Maxwell
- Jonas Schnelli
- Wladimir J. van der Laan

And all those who contributed additional code review and/or security research:

- dexX7
- Pieter Wuille
- vayvanne

As well as everyone that helped translating on
[Transifex](https://www.transifex.com/projects/p/bitcoin/).

On Tue, May 19, 2015 at 1:44 PM, Wladimir J. van der Laan
<laanwj at gmail.com> wrote:
>



From davec at conformal.com  Tue May 19 16:05:18 2015
From: davec at conformal.com (Dave Collins)
Date: Tue, 19 May 2015 11:05:18 -0500
Subject: [Bitcoin-development] Regtest Consensus Forking Behavior Introduced
 in Bitcoin Core in May 2014
Message-ID: <555B5F3E.1070605@conformal.com>

Hello All,

Josh Rickmar and I discovered a subtle consensus change in Bitcoin Core
which causes forking behavior on regtest.  Luckily it does not affect
mainnet or testnet, however it does mean that regtest difficulty
retargetting is broken.

I've made a post to the bitcointalk forums at
https://bitcointalk.org/index.php?topic=1065504 for the nicer formatting
which explains in detail.

Regards,

Dave Collins

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 834 bytes
Desc: OpenPGP digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150519/05125acd/attachment.sig>

From eric at bitpay.com  Tue May 19 16:13:49 2015
From: eric at bitpay.com (Eric Martindale)
Date: Tue, 19 May 2015 09:13:49 -0700
Subject: [Bitcoin-development] ChainDB Whitepaper
Message-ID: <555B613D.8030208@bitpay.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

Hello all,

BitPay has just released our first whitepaper on ChainDB, a new
peer-to-peer database system backed by the Bitcoin blockchain.  This
paper outlines our intended consensus mechanism, proof of fee.

Please take a look at the paper here: https://bitpay.com/chaindb.pdf

We are seeking comments and feedback on this mechanism.  I am happy to
answer any questions about the paper itself.

Sincerely,

Eric Martindale
-----BEGIN PGP SIGNATURE-----
Comment: GPGTools - https://gpgtools.org

iQIcBAEBCgAGBQJVW2E9AAoJEHLoNvKeOhrJkLwP/1J14yGlZzddp4ApGRFsnnIz
t8U9uZVvjsqxseYv6Pw3ZStQRkuBgcPDcQwMexeBi/0Z5K34LOM1565XRLtNG2sb
AeLHG11ZLNK9SQSga2B0yc95uXs2Zje7Z+A+Q+h7HjhnkcQKbuLA+kB2+ZJv1CA3
dV/5A0oCMBbZukzuFkbgmnhCaNwYjWY15UbwksKb2c3ktuLxZ5zUq/ZI+W+0PZsN
Px2m/qkKb0UiUfbZU5Zva8HSI8lxQrEm/dkv4voglwlG3M7fvmgXcUi+8q0VslDi
2Bx99rhpBaC79eHDUouhTNvLykP7Hal4KdyuzShlNBN+Z6AQyoeOdAQhk9YNw/iq
c/tyiw6fFQVjEOJuJfetl2thByI+/hNH2m70BRXnaOtM+rQ4iIeaR7KevMi+WyYr
+X9M6eqaYvkVXD1y0lEDCfsatYIhLUcXUVkM8gAdXF2yatqfCHENVYdZu9EDhYNa
zC/N2akO+XNmj0a4mder3Oy0/j7vHTXq8HLHGFbCy3S3nld+A0Qe0/JTo/Vj1IZX
REyBnWsaguIE8l/I/+423rzQYKlSEwP5j+V/ObTYouVCwmy+uJC8evNCI8T/APy9
Y04ocYLb2DnKLDOD8mlf+huf4x9WwK8+CdF/wm2g1SxLBchy5lkrmhbbD846HiRF
m7EvzfRGI5zweCNIyx9Y
=nDJ2
-----END PGP SIGNATURE-----




From onelineproof at gmail.com  Wed May 20 02:55:49 2015
From: onelineproof at gmail.com (Andrew)
Date: Wed, 20 May 2015 02:55:49 +0000
Subject: [Bitcoin-development] Scaling Bitcoin with Subchains
Message-ID: <CAL8tG==LG=xC_DzOaghbGGKab4=UVpGLQV7781pU4wg+WnFdMg@mail.gmail.com>

Hi

I briefly mentioned something about this on the bitcoin-dev IRC room. In
general, it seems experts (like sipa i.e. Pieter) are against using
sidechains as a way of scaling. As I only have a high level understanding
of the Bitcoin protocol, I cannot be sure if what I want to do is actually
defined as a side chain, but let me just propose it, and please let me know
whether it can work, and if not why not (I'm not scared of digging into
more technical resources in order to fully understand). I do have a good
academic/practical background for Bitcoin, and I'm ready to contribute code
if needed (one of my contributions includes a paper wallet creator written
in C).

The main problem I see with increasing the block size limit is that it
increases the amount of storage required to fully validate all transactions
for say 100 years (a person's life). With 1 MB blocks, you can store all
lifetime transactions on a 5 TB drive, which basically any regular user can
do. With 10 MB blocks, you need a 50 TB drive, not accessible for regular
users. Yes, it's possible that in the future hard drive technology will get
cheaper and smaller, but this still didn't happen, so we can't just say "it
should be doable at the rate of Moore's law etc...", we need to know that
it is accessible for everyone, now. Also, don't forget that human life
expectancy can increase with time as well. I know, it sounds silly to use a
human lifetime as a measurement of how far back each user should be able to
store transactions for, but what is a better measurement? This is a
technology made for people i.e. humans, right, and the important part is
that it is for regular people and not just well privileged people. You can
search my last four emails for some more calculations.

What sipa told me on the IRC channel is that Bitcoin Core does not care
about old transactions. It only looks at the current blocks. Yes, that
makes sense, but how do you know that your machine wasn't compromised when
validating the previous blocks? And what if you want to check some old
transactions (assuming you didn't index everything)? What if some of your
old transaction data was lost or corrupted? I think it is clear that it is
useful to be able to validate all blocks (since 100 years) rather than just
a pruned part. It empowers people to have as much information about Bitcoin
transactions as do large data centers; transactions that may include
government or corporate corruption. This is the key to how Bitcoin enables
transparency for those who should be transparent (individual users with
private addresses can still remain anonymous). Also, 5 TB takes about 20
days to sync starting fresh, on a regular computer, so it allows easy entry
into the system.

So assuming we agree that people should be able to store ~ a lifetime of
transactions, then we need 1 MB blocks. But of course, this leads to huge
transaction costs, and small purchases will be out of limits. So to fix
this, I propose adding a 10 1 MB chains below the main chain (sorry on the
IRC room I said 10 10 MB chains by mistake), so effectively, you have a new
10 MB chain that is partitioned into 10 parts. You can also add a third
level: 100 1 MB chains, and keep going like that. The idea is that when you
make a large transaction, you put it through the top chain; when you make a
medium sized transaction, you put it through one of the middle chains,
which will be verified (mined) by the middle chain, and the top chain will
verify the aggregate transactions of the middle chain. If you have a small
sized transaction, you put it through one of the bottom chains, the bottom
chain verifies it, the middle chain verifies the aggregate transactions of
the bottom chain, and the top chain verifies the aggregate transactions of
the middle chain. By aggregate transaction, I mean the net result of
multiple transactions, and I suppose it can be 20 transactions belonging
only to one "sibling" chain for level 2, or 200 transactions for level 3,
etc...

Now, how does the system decide to which of the 10 chains the middle sized
transaction goes to? I propose just taking some simple function of the
input addresses mod 10, so that you can just keep randomly generating a
wallet until you get one with only addresses that map to only one of the 10
chains (even distribution), so that someone can choose one of the 10
chains, and store only the transactions that belong to that chain. They
should also choose a chain from level 3, etc... So in effect, they will be
storing a chain with block size O(n) where n is the number of levels. They
may store multiple sibling chains at one level, if they want to track of
other people's transactions, such as those of their government MP, or
perhaps, they want to have a separate identity that would be more anonymous
with a separate series of sibling chains. This will increase the storage
size, but the increase will be proportional to the number of things you
want to keep track of (at least this kind of system gives you the ability
to fine tune your storage needs to the level of "things" you want to keep
track of). Also, note that there may likely be duplication of transactions,
since transactions can include addresses that are associated with different
silbling chains, but this effect shouldn't make a big difference, and again
will depend on the complexity of the transactions you want to keep track of.

So how can this work? I propose that we keep the current chain as the top
chain, and then create 10 level 2 chains that also store Bitcoin and the
Bitcoin can be transferred between chains (I think this is the idea of
sidechains). How can we incentivize people to keep mining on the level 1
chain? Perhaps force it into the (soft fork) protocol that anyone mining on
level 2, has to also mine on level 1, and in general, anyone mining on
level n+1 has to also mine on levels n,n-1,...,1. Also, level 1 will have
the best decentralization, so there should be enough people paying fees to
get transactions there for their large transactions that require a high
level of security and trust. Even if people stop using level 1, any bitcoin
you own in the level 1 chain, can be transferred to level 2, and still you
have 1 MB blocks due to the partitioning scheme. How to prevent
transactions from clustering on one or a  few sibling chains in a
particular level? Well the more empty chains should have lower fees, so
that should incentivize people... Note: This system also allows for the
fine tuning of the transaction size to security ratio. Yes the lower chains
will be less secure, but a lower sized transaction does not need as much
security.

For instant transactions, there can also be Lightning channels linked to
whatever level of chain you want.

OK so it seems to me that this can work and would only require a soft fork.
But, as I said, I only have a high level understanding of the Bitcoin
protocol, so it feels kind of too good to be true, and I am ready for heavy
criticism. I am only writing this because I care about Bitcoin and I want
it to remain decentralized and become the best that it can be. I think it
is important to do the right thing rather than (as most people naturally
do) the most convenient thing.

Thanks

-- 
PGP: B6AC 822C 451D 6304 6A28  49E9 7DB7 011C D53B 5647
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150520/ca03dd02/attachment.html>

From pete at petertodd.org  Wed May 20 06:26:11 2015
From: pete at petertodd.org (Peter Todd)
Date: Wed, 20 May 2015 02:26:11 -0400
Subject: [Bitcoin-development] ChainDB Whitepaper
In-Reply-To: <555B613D.8030208@bitpay.com>
References: <555B613D.8030208@bitpay.com>
Message-ID: <20150520062611.GA11204@muck>

On Tue, May 19, 2015 at 09:13:49AM -0700, Eric Martindale wrote:
> 
> Hello all,
> 
> BitPay has just released our first whitepaper on ChainDB, a new
> peer-to-peer database system backed by the Bitcoin blockchain.  This
> paper outlines our intended consensus mechanism, proof of fee.
> 
> Please take a look at the paper here: https://bitpay.com/chaindb.pdf
> 
> We are seeking comments and feedback on this mechanism.  I am happy to
> answer any questions about the paper itself.

I'm quite disappointed to see that you still haven't fixed the problem
that transaction fees prove nothing at all. Among other things, you risk
creating a system where miners can much more cheaply sell the service of
including the requisite "high-fee" transactions in blocks they mine for
the much lower cost of the risk of the blocks being orphaned and other
miners getting those fees. In particular, the more hash power you have,
the lower that cost is - exactly the opposite kind of incentive than we
want. As described this is an extremely dangerous project, both to its
users, and Bitcoin as a whole; in general the idea of anything that
tries to use transaction fees as "proof" is highly dangerous.

You should implement this with direct provably unspendable OP_RETURN
sacrifices for now, and perhaps in the future, sacrifice to
any-one-can-spend-in-the-future scriptPubKeys once CLTV is deployed.  If
you do this the interval needs to be long enough to robustly get past
business cycles - e.g. 1 year - to avoid the well-known problem that
large miners can sell these proofs cheaply.


Other comments:

* Bitcoin does not securely store data; Bitcoin proves the publication of
data.(1) This can be seen by the recently added(2) pruning functionality
which allows full nodes to discard all blockchain data other than the
UTXO set and some number of recent blocks. (to handle reorganizations
efficiently) Additionally even the UTXO set can be discarded in
principle if my TXO commitments proposal is implemented.  Between both
proposals there's no guarantee that data published to the Bitcoin
blockchain will be stored by anyone at all, let alone be readily made
available.

* The paper lacks a clear statement about what exactly the ChainDB
proposal is attempting to accomplish, and what ChainDB attempts to
prevent from happening. Are we trying to prove that data existed before
a certain time? (timestamping) Are we trying to prove that data reached
a certain audience? (proof-of-publication) Are we trying to come to
consensus on some type of mapping? (key:value consensus) What are we
assuming from miners? Might miners attempt to censor ChainDB
transactions? For instance you say "In the second rule, applying an
unpredictable order for selecting the best chain mitigates certain
attacks by Bitcoin miners" but you don't say what those attacks are.  A
key question related to that is whether or not the ChainDB chains are or
are not private, both recent and historical history.

* "A comprehensive ordering of all transactions also makes it possible
to select a block even when some blocks are being withheld." Keep in
mind that what has been "withheld" depends on what blocks you have
access too; from the point of view of one ChainDB user the withheld
blocks may be the blocks another ChainDB user has access too and
vice-versa. Again, the Bitcoin consensus is a way to prove publication
of data with strong sybil attack detection - the cost to sybil attack
ChainDB will be quite low in many situations as miners have the
priviledged position of having very low costs to include a transaction.

* "To minimize the risk that a builder loses bitcoin in the bidding
process, builders coordinate to select a common UTXO that all bid
transactions use as an input. In so doing, bid transactions are created
such that they deliberately conflict." This is a clever idea; I believe
Jeff Garzik deserves credit for this. (his auction proposal) Note too
that with SIGHASH_ANYONECANPAY the consensus scheme could be arranged
such that anyone can also add additional funds to a proposed consensus
that they agree with. Better yet, with SIGHASH_SINGLE by "stacking"
additional inputs to the transaction you would ensure all bids end up in
the same transaction, simplifying the consensus logic. (otherwise the
total bid is the sum of potentially multiple transactions sacrificing
funds in support of the same consensus)

* Speaking of, proof-of-sacrifice or proof-of-burn is the common term
used for a cryptographically provable expenditure. (e.g. for a fidelity
bond(3)) Although in this case, it's not a true sacrifice as fee-paying
transactions by themselves can be trivially collected by miners.

* "And Factom [8] has advanced the concept of using the Bitcoin block
chain directly for timestamping data" Factom goes well beyond simply
timestamping data. (something my much earlier OpenTimestamps project did
among many others) Rather Factom acts as a proof-of-publication layer
that allows the proving of the negative.(4)


Zookeyv
-------

ChainDB has a lot of similarities with my Zookeyv(5) proposal, as well
as some key differences. To recap the idea was to come to consensus on a
key:value mapping, such that there was a well-defined cost to change any
particular k:v pair, and such that 'uncontroversial' key:value pairs
would become more expensive to change over time as latter k:v pairs
would add to the cost to change of previous ones.

My original proposal was create a DAG of sacrifices, each committing a
key:value pair, and one or more previous nodes. (the case where n=1
being a linear chain) Nodes that set a key:value already assigned would
be considered invalid. For any tip you'd be able to determine a sum
sacrifice, and equally, a sum sacrificed on top of any key:value pair.
In hindsight, the rule set could be extended to all kinds of situations
akin to a blockchain. (as you propose)

A key question I came up with was whether or not the minimal data
required to prove the shape of the graph be published directly in the
blockchain. e.g. if a node consists of {H(key), H(value),
prev_node_hash[]} do you require those values to be themselves published
in the blockchain, or are they hidden behind a hash? The latter is more
efficient and censorship resistant, while the former makes it possible
to detect possible 51% attacks and outspend them. (Note how this notion
of "reactive security" can be efficiently used to fend off attackers by
outspending them after the fact, while keeping sacrifices low in the
general case; the sacrifice could even be crowdfunded with
SIGHASH_ANYONECANPAY transactions)


1) "[Bitcoin-development] Disentangling Crypto-Coin Mining: Timestamping, Proof-of-Publication, and Validation"
   Peter Todd, Nov 19th, 2013,
   http://www.mail-archive.com/bitcoin-development at lists.sourceforge.net/msg03307.html

2) https://github.com/bitcoin/bitcoin/pull/5863

3) https://en.bitcoin.it/wiki/Fidelity_bonds

4) "Factom - Business Processes Secured by Immutable Audit Trails on the Blockchain"
   Paul Snow et. al, Nov 17th 2014,
   https://github.com/FactomProject/FactomDocs/blob/master/Factom_Whitepaper.pdf

5) #bitcoin-wizards discussion, May 31st 2013

-- 
'peter'[:-1]@petertodd.org
00000000000000000e7980aab9c096c46e7f34c43a661c5cb2ea71525ebb8af7
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150520/e3843511/attachment.sig>

From el33th4x0r at gmail.com  Wed May 20 10:25:01 2015
From: el33th4x0r at gmail.com (=?UTF-8?Q?Emin_G=C3=BCn_Sirer?=)
Date: Wed, 20 May 2015 06:25:01 -0400
Subject: [Bitcoin-development] Virtual Notary.
Message-ID: <CAPkFh0tWykVJU-9mCTR95eqUF0B5TO-ZO7B3L0wf_QYAmAuuBA@mail.gmail.com>

Hi everyone,

Given the recent discussions on projects that use the Bitcoin blockchain to
record factoids, people on this list might be interested in the Virtual
Notary project. Virtual Notary is essentially an online witness (aka
attestor) to online factoids. It can provide:

  * proof of Bitcoin funds (without revealing public addresses or fund
location on the blockchain)

  * proof of Bitcoin address ownership

  * proof of Tweet

  * proof of real estate value

  * proof of DNS ownership

  * proof of existence

  * proof of web page contents

  * proof of weather conditions

The factoids can be recorded on the blockchain (if you pay for the
transaction with Bitcoin or PayPal), or they can be part of a free
attestation chain that we maintain. The website provides a permanent URL to
the factoids it generates; it also provides an X.509 certificate that you
can download and keep safe in perpetuity, independent of the website.

The link to the website is here:
  http://virtual-notary.org

The link to the writeup describing the various factoids and their use cases
is here:
  http://hackingdistributed.com/2013/06/20/virtual-notary-intro/

We are actively looking for people who are interested in developing the
service further. Specifically, if you have suggestions for how to extend
the service, for new proof/factoid types, or for how to build a business
case around the core idea, please let us know.

Best,
- egs
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150520/995e8043/attachment.html>

From jgarzik at bitpay.com  Wed May 20 15:54:33 2015
From: jgarzik at bitpay.com (Jeff Garzik)
Date: Wed, 20 May 2015 08:54:33 -0700
Subject: [Bitcoin-development] Virtual Notary.
In-Reply-To: <CAPkFh0tWykVJU-9mCTR95eqUF0B5TO-ZO7B3L0wf_QYAmAuuBA@mail.gmail.com>
References: <CAPkFh0tWykVJU-9mCTR95eqUF0B5TO-ZO7B3L0wf_QYAmAuuBA@mail.gmail.com>
Message-ID: <CAJHLa0Ot_2VH-iAnpeZr7_Wniw5Zsu2KS11yN2sqewY5FueZaw@mail.gmail.com>

On Wed, May 20, 2015 at 3:25 AM, Emin G?n Sirer <el33th4x0r at gmail.com>
wrote:

> Hi everyone,
>
> Given the recent discussions on projects that use the Bitcoin blockchain
> to record factoids, people on this list might be interested in the Virtual
> Notary project. Virtual Notary is essentially an online witness (aka
> attestor) to online factoids. It can provide:
>
>   * proof of Bitcoin funds (without revealing public addresses or fund
> location on the blockchain)
>
>   * proof of Bitcoin address ownership
>
>   * proof of Tweet
>


For what it's worth, a subsidiary of Dunvegan Space Systems is pursuing
exactly this as a business.

EMail JGarzik at DSS.co if you want to know more.

-- 
Jeff Garzik
Bitcoin core developer and open source evangelist
BitPay, Inc.      https://bitpay.com/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150520/99197051/attachment.html>

From dev at jonasschnelli.ch  Fri May 22 09:00:24 2015
From: dev at jonasschnelli.ch (Jonas Schnelli)
Date: Fri, 22 May 2015 11:00:24 +0200
Subject: [Bitcoin-development] Virtual Notary.
Message-ID: <555EF028.2010302@jonasschnelli.ch>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

> * proof of Bitcoin funds (without revealing public addresses or 
> fund location on the blockchain)
> 
> * proof of Bitcoin address ownership
> 
> * proof of Tweet
> 
> * proof of real estate value
> 
> * proof of DNS ownership
> 
> * proof of existence
> 
> * proof of web page contents
> 
> * proof of weather conditions
> 
> The factoids can be recorded on the blockchain (if you pay for the 
> transaction with Bitcoin or PayPal), or they can be part of a free 
> attestation chain that we maintain. The website provides a 
> permanent URL to the factoids it generates; it also provides an 
> X.509 certificate that you can download and keep safe in 
> perpetuity, independent of the website.


Hi Emin

This is going into the right direction. Well done!
The certificates (X.509/p12) are far more enduser-friendly than just a
normal PoE hash.

Your site needs some UX love and i just tried to OR_RETURN a
Email-Address-Verification. But after creating a 0.0001 tx and waiting
for two confirmations it still said that the payment has not yet been
received. There is probably something broken regarding the bitcoin
payment verification.

The weather and real estate notarization definitively needs a ?US
only? badge somewhere.

Two ideas:
- - Maybe adding a way of decentralize your notary service log via a
opensource p2p daemon (obviously sensitive data should be somehow
encrypted)?
- - Adding a opensource UI app to examine certs (maybe offline capable
with p2p daemon chain as mentioned above). This could prove
independence from your website/service.

</jonas>
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQIcBAEBAgAGBQJVXvAoAAoJECnUvLZBb1PsJpsQAKRYDUTUYA59765w0jbBlK+S
ArxpaxwPmG7ZLhDYoTHJ/welvXsMSzREZrJNKYl7LBHQBPldeTRQHfHwH05qiwBL
H5rC+BTyaglud3x7Bxo0fNrXJB4tkfX2ykPJs+2bqPi9OE0uVlXi2Vh/6cV1U/Uq
RWRfpa19GnSE7IRft5G19FVsG8hrrpuLhzVraAQeZTLyGBKd+hlpjI/qr6TOl8ra
5K3bFb2J1+UoaFXLlKCSsSx+9PsydlcJFwnr2H/Z7r1M39j5XYag3Ba6W58ats4z
6DCTL1xRVOCTNDbVgkYzZUDCtv5oDspQ2S0nauJLDVz5ADUaZ+bsmBFwseo+XuZV
TLUxsYfPsqEzUKF2a7ZfMjQG0EUx8oh5DU+o1F5wcBSXDOM+ucdOGYbMrBMV1i9W
GoPUN1QPkqfUTTRiYYnzP2ySyPUoJqZrcwEB7E7nV8O2xE4Q00zCDlOSqU8aVl7j
9lIs/sTpcK5S0kFfc68n6NVlWYU+CBdGlnmvMdbEkydV2P3ft1+THqQ8LNiYRhWX
7kHzgG58yUQjvgsOEEb4xTXgA5u4euxBVY+SwKN6cTXA7dWg1s39UEJroaKuXYN5
iZTj2XkBtD+pwtUPIMs79Kb2/PZRGy7SJui2RbExFX1/8oBbHRV5Ii6+MNw11RNz
RTV0kHof6+6u1BFYHTFX
=UmgJ
-----END PGP SIGNATURE-----



From me at thomaskerin.io  Fri May 22 17:28:02 2015
From: me at thomaskerin.io (Thomas Kerin)
Date: Fri, 22 May 2015 18:28:02 +0100
Subject: [Bitcoin-development] BIP for deterministic pay-to-script-hash
 multi-signature addresses
In-Reply-To: <54DE8C1C.60804@thomaskerin.io>
References: <54DD1E3F.60006@thomaskerin.io>	<201502122213.34765.luke@dashjr.org>
	<54DE8C1C.60804@thomaskerin.io>
Message-ID: <555F6722.7000103@thomaskerin.io>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

I wonder are there any other blockers or modifications that need to be
made for this to be merged?

Latest version of the document:
https://github.com/afk11/bips/blob/213e8a27a3a2eaaf44f79221a9f9f888af002801/bip-0067.mediawiki



On 13/02/15 23:43, Thomas Kerin wrote:
>
> On 12/02/15 22:13, Luke Dashjr wrote:
>> Where is the Specification section?? Does this support arbitrary
scripts, or
>> only the simplest CHECKMULTISIG case?
>
> The BIP is a process for deriving only the type of scripts you would
encounter doing addmultisigaddress. More complicated scripts would
require more metadata to be shared, but the only case we describe is
when given public keys and the number of signatures required.
>
> You're right, we're missing a Specification. I have tweaked the
document to cover this now.
>
>
>
> On 13/02/15 07:53, Peter Todd wrote:
>> It might be enough to rewrite this BIP to basically say "all pubkeys
executed by all CHECKMULTISIG opcodes will be in the following canonical
order", followed by some explanatory examples of how to apply this
simple rule. OTOH we don't yet have a standard way of even talking about
arbitrary scripts, so it may very well turn out to be the case that the
above rule is too restrictive in many cases - I certainly would not want
to do a soft-fork to enforce this, or even make it an IsStandard() rule.
>
> It would be interesting, but I agree it should not be brought into
these validation rules - just a convention for people to follow for now.
I think it's fair that implementers are free to order them however they
please. But I think there is good reason for wallets to opt in to the
convention and declare this, for ease of recovery, and for
interoperability reasons.
>
>
> --
> Thomas Kerin
> -------------------------
> My PGP key can be found here
<http://pgp.mit.edu/pks/lookup?op=get&search=0x3F0D2F83A2966155>
>
>
>
------------------------------------------------------------------------------
> Dive into the World of Parallel Programming. The Go Parallel Website,
> sponsored by Intel and developed in partnership with Slashdot Media,
is your
> hub for all things parallel software development, from weekly thought
> leadership blogs to news, videos, case studies, tutorials and more. Take a
> look and join the conversation now. http://goparallel.sourceforge.net/
>
>
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development

- -- 
Thomas Kerin
- -------------------------

My PGP key can be found here
<http://pgp.mit.edu/pks/lookup?op=get&search=0x3F0D2F83A2966155>
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (GNU/Linux)

iQJ8BAEBCgBmBQJVX2ciXxSAAAAAAC4AKGlzc3Vlci1mcHJAbm90YXRpb25zLm9w
ZW5wZ3AuZmlmdGhob3JzZW1hbi5uZXQ2MzI1MzM4QjJGOTU5OEUzREMzQzc0MzAz
RjBEMkY4M0EyOTY2MTU1AAoJED8NL4OilmFVlOwP/1w/Omr/6jGyi7spqW22HQ7P
4+lNNzcsWp5/pv8e6YelUOSYiHuh/KxRoFfWL+wF+PNS2EtjRxSsXxg/R2nMft7B
JQLNmIG6zTzVg/lhVObeSslXaia7repZxZ1S4nyEcs8rDVt7kkNnNguFOeONF95O
3usCnrch+QbQacIt9StySAz155u1SuHeSmGmA/fRGLfArndXDdN0fYwE1KGyv5wm
LqZ1PQfmYaCc0TUKRvpDRuc/+KF7q1fDMzuP9mZ3WiPdvTDKCXSRxYfbQYJdxplg
AC0CFiOne+DXgiBdTOIcs9pcp1/6SyZs75Bkpv71AxBCmTlRTuYpsfH7O3VuZBGP
FrN/4BMYnzMbGnNmvZwerUKH59MmzZTAzLSwZlpvj7ZxRks6KOp1CHInFWQlHAXJ
O5c5McvqSdQ0rPHLcQ4DwB00Q1els18NRULjxdsTfLrT32birIXn3M1Hn/Q9d8Sa
N+Y/cfXkojf4rJt75+XwjLyHECwS378ZFC8lfs1m/B3VSQxTtTZWA8905a1IRv/F
nPQ2eaxBrFjm4OatE5lx+I/xmVAQuybG54UdcZGaKVXJbMg3sOslcYg7eA77pmR5
7jRoRU+q7GhiRsUmxSkD+57FfhaMzX7iUl4xe3YK14KUS/pONuv0USC9to8a62kA
gz9kb4pJMEhTtZNv7z9C
=iq37
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150522/09d9bd89/attachment.html>

From benkay at gmail.com  Sat May 23 01:46:12 2015
From: benkay at gmail.com (Ben Vulpes)
Date: Fri, 22 May 2015 18:46:12 -0700
Subject: [Bitcoin-development] Virtual Notary.
In-Reply-To: <555EF028.2010302@jonasschnelli.ch>
References: <555EF028.2010302@jonasschnelli.ch>
Message-ID: <CACMPkv=NL7mCLMiw-KcLDu61RgA1rsUmV7Sdn+KeMn6zi3a8yA@mail.gmail.com>

I cannot let http://www.deedbot.org go unmentioned on this thread.

On Friday, May 22, 2015, Jonas Schnelli <dev at jonasschnelli.ch> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> > * proof of Bitcoin funds (without revealing public addresses or
> > fund location on the blockchain)
> >
> > * proof of Bitcoin address ownership
> >
> > * proof of Tweet
> >
> > * proof of real estate value
> >
> > * proof of DNS ownership
> >
> > * proof of existence
> >
> > * proof of web page contents
> >
> > * proof of weather conditions
> >
> > The factoids can be recorded on the blockchain (if you pay for the
> > transaction with Bitcoin or PayPal), or they can be part of a free
> > attestation chain that we maintain. The website provides a
> > permanent URL to the factoids it generates; it also provides an
> > X.509 certificate that you can download and keep safe in
> > perpetuity, independent of the website.
>
>
> Hi Emin
>
> This is going into the right direction. Well done!
> The certificates (X.509/p12) are far more enduser-friendly than just a
> normal PoE hash.
>
> Your site needs some UX love and i just tried to OR_RETURN a
> Email-Address-Verification. But after creating a 0.0001 tx and waiting
> for two confirmations it still said that the payment has not yet been
> received. There is probably something broken regarding the bitcoin
> payment verification.
>
> The weather and real estate notarization definitively needs a ?US
> only? badge somewhere.
>
> Two ideas:
> - - Maybe adding a way of decentralize your notary service log via a
> opensource p2p daemon (obviously sensitive data should be somehow
> encrypted)?
> - - Adding a opensource UI app to examine certs (maybe offline capable
> with p2p daemon chain as mentioned above). This could prove
> independence from your website/service.
>
> </jonas>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1
>
> iQIcBAEBAgAGBQJVXvAoAAoJECnUvLZBb1PsJpsQAKRYDUTUYA59765w0jbBlK+S
> ArxpaxwPmG7ZLhDYoTHJ/welvXsMSzREZrJNKYl7LBHQBPldeTRQHfHwH05qiwBL
> H5rC+BTyaglud3x7Bxo0fNrXJB4tkfX2ykPJs+2bqPi9OE0uVlXi2Vh/6cV1U/Uq
> RWRfpa19GnSE7IRft5G19FVsG8hrrpuLhzVraAQeZTLyGBKd+hlpjI/qr6TOl8ra
> 5K3bFb2J1+UoaFXLlKCSsSx+9PsydlcJFwnr2H/Z7r1M39j5XYag3Ba6W58ats4z
> 6DCTL1xRVOCTNDbVgkYzZUDCtv5oDspQ2S0nauJLDVz5ADUaZ+bsmBFwseo+XuZV
> TLUxsYfPsqEzUKF2a7ZfMjQG0EUx8oh5DU+o1F5wcBSXDOM+ucdOGYbMrBMV1i9W
> GoPUN1QPkqfUTTRiYYnzP2ySyPUoJqZrcwEB7E7nV8O2xE4Q00zCDlOSqU8aVl7j
> 9lIs/sTpcK5S0kFfc68n6NVlWYU+CBdGlnmvMdbEkydV2P3ft1+THqQ8LNiYRhWX
> 7kHzgG58yUQjvgsOEEb4xTXgA5u4euxBVY+SwKN6cTXA7dWg1s39UEJroaKuXYN5
> iZTj2XkBtD+pwtUPIMs79Kb2/PZRGy7SJui2RbExFX1/8oBbHRV5Ii6+MNw11RNz
> RTV0kHof6+6u1BFYHTFX
> =UmgJ
> -----END PGP SIGNATURE-----
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net <javascript:;>
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150522/bd3e1553/attachment.html>

From pete at petertodd.org  Sat May 23 18:26:21 2015
From: pete at petertodd.org (Peter Todd)
Date: Sat, 23 May 2015 14:26:21 -0400
Subject: [Bitcoin-development] Replace-by-fee v0.10.2 - Serious DoS attack
 fixed! - Also novel variants of existing attacks w/ Bitcoin XT and Android
 Bitcoin Wallet
In-Reply-To: <20150504043601.GA14728@savin.petertodd.org>
References: <20150212064719.GA6563@savin.petertodd.org>
	<20150504043601.GA14728@savin.petertodd.org>
Message-ID: <20150523182621.GA12761@savin.petertodd.org>

My replace-by-fee patch is now available for the Bitcoin Core v0.10.2
release:

    https://github.com/petertodd/bitcoin/tree/replace-by-fee-v0.10.2

This release fixes a serious DoS attack present in previous releases.
Upgrading is strongly recommended for relay nodes, and mandatory for
miners. Users of Luke-Jr's gentoo distribution should either disable RBF
until a patch is released, or run their node behind a patched node.

Previously replacements that spent outputs the transactions they
conflicted with would be accepted. This would lead to orphaned
transactions in the mempool, a potential bandwidth DoS attack for relay
nodes, and even worse, on mining nodes would cause Bitcoin to crash when
CreateNewBlock() was called.

Thanks goes to to Suhas Daftuar for finding this issue.


Additionally, while investigating this issue I found that
Andresen/Harding's relay doublespends patch?, included in Bitcoin XT?,
also fails to verify that doublespends don't spend outputs of the
transactions they conflict with. As the transactions aren't accepted to
the mempool the issue is simply a variant of the bandwidth DoS attack
that's a well-known issue of Bitcoin XT. However, interestingly in
testing I found that Schildbach's Android Bitcoin Wallet? fails to
detect this case, and displays the transaction as a valid unconfirmed
transaction, potentially leading to the user being defrauded with a
doublespend.  While a well-known issue in general - Schildbach's
implementation trusts peers to only send it valid transactions and
doesn't even detect doublespends it receives from peers - it's
interesting how in this case the attacker doesn't need to also do a
sybil attack.

1) https://github.com/bitcoin/bitcoin/pull/3883
2) https://github.com/bitcoinxt/bitcoinxt
3) https://play.google.com/store/apps/details?id=de.schildbach.wallet

-- 
'peter'[:-1]@petertodd.org
0000000000000000026ca21b4a83e1a818be96db4b532b7e9be2f60d47efff0a
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150523/359a957c/attachment.sig>

From elombrozo at gmail.com  Sun May 24 00:44:20 2015
From: elombrozo at gmail.com (Eric Lombrozo)
Date: Sat, 23 May 2015 17:44:20 -0700
Subject: [Bitcoin-development] BIP for deterministic pay-to-script-hash
	multi-signature addresses
In-Reply-To: <20150213075314.GA2122@savin.petertodd.org>
References: <54DD1E3F.60006@thomaskerin.io>
	<201502122213.34765.luke@dashjr.org>
	<20150213075314.GA2122@savin.petertodd.org>
Message-ID: <234B9DB2-3FF1-49CA-BBAE-EA4823839C00@gmail.com>

A few months back, William Swanson and I had worked on a more general script template format. Unfortunately, other work has prevented us from being able to fully complete it - but here?s the start:

https://docs.google.com/document/d/1nGF6LjGwhzuiJ9AQwKAhN1a1SXvGGHWxoKmDSkiIsPI <https://docs.google.com/document/d/1nGF6LjGwhzuiJ9AQwKAhN1a1SXvGGHWxoKmDSkiIsPI>/

- Eric Lombrozo

> On Feb 12, 2015, at 11:53 PM, Peter Todd <pete at petertodd.org> wrote:
> 
> On Thu, Feb 12, 2015 at 10:13:33PM +0000, Luke Dashjr wrote:
>> Where is the Specification section?? Does this support arbitrary scripts, or
>> only the simplest CHECKMULTISIG case?
> 
> It might be enough to rewrite this BIP to basically say "all pubkeys
> executed by all CHECKMULTISIG opcodes will be in the following canonical
> order", followed by some explanatory examples of how to apply this
> simple rule.
> 
> OTOH we don't yet have a standard way of even talking about arbitrary
> scripts, so it may very well turn out to be the case that the above rule
> is too restrictive in many cases - I certainly would not want to do a
> soft-fork to enforce this, or even make it an IsStandard() rule.
> 
> --
> 'peter'[:-1]@petertodd.org
> 000000000000000013cf8270118ba2efce8b304f8de359599fef95c3ab43dcb1
> ------------------------------------------------------------------------------
> Dive into the World of Parallel Programming. The Go Parallel Website,
> sponsored by Intel and developed in partnership with Slashdot Media, is your
> hub for all things parallel software development, from weekly thought
> leadership blogs to news, videos, case studies, tutorials and more. Take a
> look and join the conversation now. http://goparallel.sourceforge.net/_______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150523/076f18ee/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 842 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150523/076f18ee/attachment.sig>

From laanwj at gmail.com  Sun May 24 07:47:57 2015
From: laanwj at gmail.com (Wladimir J. van der Laan)
Date: Sun, 24 May 2015 09:47:57 +0200
Subject: [Bitcoin-development] Bitcoin Core 0.9.5 released
Message-ID: <20150524074756.GA17475@amethyst.visucore.com>

Bitcoin Core version 0.9.5 is now available from:

  https://bitcoin.org/bin/0.9.5/

This is a new minor version release, with the goal of backporting BIP66. There
are also a few bug fixes and updated translations. Upgrading to this release is
recommended.

Please report bugs using the issue tracker at github:

  https://github.com/bitcoin/bitcoin/issues

How to Upgrade
===============

If you are running an older version, shut it down. Wait until it has completely
shut down (which might take a few minutes for older versions), then run the
installer (on Windows) or just copy over /Applications/Bitcoin-Qt (on Mac) or
bitcoind/bitcoin-qt (on Linux).

Notable changes
================

Mining and relay policy enhancements
------------------------------------

Bitcoin Core's block templates are now for version 3 blocks only, and any mining
software relying on its `getblocktemplate` must be updated in parallel to use
libblkmaker either version 0.4.2 or any version from 0.5.1 onward.
If you are solo mining, this will affect you the moment you upgrade Bitcoin
Core, which must be done prior to BIP66 achieving its 951/1001 status.
If you are mining with the stratum mining protocol: this does not affect you.
If you are mining with the getblocktemplate protocol to a pool: this will affect
you at the pool operator's discretion, which must be no later than BIP66
achieving its 951/1001 status.

0.9.5 changelog
================

- `74f29c2` Check pindexBestForkBase for null
- `9cd1dd9` Fix priority calculation in CreateTransaction
- `6b4163b` Sanitize command strings before logging them.
- `3230b32` Raise version of created blocks, and enforce DERSIG in mempool
- `989d499` Backport of some of BIP66's tests
- `ab03660` Implement BIP 66 validation rules and switchover logic
- `8438074` build: fix dynamic boost check when --with-boost= is used

Credits
--------

Thanks to who contributed to this release, at least:

- 21E14
- Alex Morcos
- Cory Fields
- Gregory Maxwell
- Pieter Wuille
- Wladimir J. van der Laan

As well as everyone that helped translating on [Transifex](https://www.transifex.com/projects/p/bitcoin/).




From kalle at rosenbaum.se  Sun May 24 20:45:16 2015
From: kalle at rosenbaum.se (Kalle Rosenbaum)
Date: Sun, 24 May 2015 22:45:16 +0200
Subject: [Bitcoin-development] Proof of Payment BIP-able?
Message-ID: <CAPswA9x8YNCUb_W30LMDbUQ34W=1OUnrghaSx_PGOwt=VnBVTg@mail.gmail.com>

Hi all!

As indicated in my first email regarding Proof of Payment (Mars 13, subject
"Proof of Payment"), I would like to BIP it. I have two proposals:

* PoP datastructure and process:
https://github.com/kallerosenbaum/poppoc/wiki/Proof-of-Payment
* btcpop: URI scheme:
https://github.com/kallerosenbaum/poppoc/wiki/btcpop-scheme

Basically, my question to the community is: Do you agree that these are
BIP-able?

The proposals are not yet BIP formatted, but pretty complete. An
implementation is avaliable at https://github.com/kallerosenbaum/poppoc.
Specifically, the PoP validating code is in PopValidator.java
<https://github.com/kallerosenbaum/poppoc/blob/master/src/main/java/se/rosenbaum/poppoc/core/validate/PopValidator.java>
.

As far as I can tell from the previous thread, no major objection against
the idea was raised. PoP, if standardized, would bring a lot of utility to
bitcoin: Paysite login, concert tickets, left luggage lockers, lotteries,
video rental, etc.

Further on, I'd like to extend BIP70 to support PoP, but that will have to
wait until we have consensus around the two basic proposals above.

I have received some great feedback from the community and included most of
it in the updated version of the specification. The essential changes are:

* If a PoP for some reason appears in the bitcoin p2p network, we must make
sure that IF it is included in a block it should have minimal impact. The
solution I chose was to include all outputs of the original paymet in the
PoP. That way, if the PoP is included it will not alter the payees. (Thanks
to Tom Harding for pointing out the problem and Magnus Andersson for the
initial solution).

* The check if the transaction is actually a tx that you want proof for is
moved to later in the validation process. Otherwise, one could get
information on what transactions pays for which services by simply sending
erroneously signed PoPs with a transaction id we're interested in.

* A version field of 2 bytes is included. Currently the only valid version
is 0x00 0x01. (Thanks Martin Lie)

* The "PoP" literal is removed. It provides little value as the receiver of
a PoP expects a PoP. (Again, thanks Martin Lie for making me think about
this.)

Regards,
Kalle Rosenbaum
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150524/4aa5257e/attachment.html>

From mike at plan99.net  Mon May 25 18:07:09 2015
From: mike at plan99.net (Mike Hearn)
Date: Mon, 25 May 2015 20:07:09 +0200
Subject: [Bitcoin-development] Virtual Notary.
In-Reply-To: <CAPkFh0tWykVJU-9mCTR95eqUF0B5TO-ZO7B3L0wf_QYAmAuuBA@mail.gmail.com>
References: <CAPkFh0tWykVJU-9mCTR95eqUF0B5TO-ZO7B3L0wf_QYAmAuuBA@mail.gmail.com>
Message-ID: <CANEZrP2BChNrX-GKse82CtjeMe2Trt8CfaZDyvH2b85EGF+FeQ@mail.gmail.com>

Very nice Emin! This could be very useful as a building block for oracle
based services. If only there were opcodes for working with X.509 ;)

I'd suggest at least documenting in the FAQ how to extract the data from
the certificate:

openssl pkcs12 -in virtual-notary-cert-stocks-16070.p12 -nodes -passin
pass:"" | openssl x509 -text|less

That's good enough to get started, but I note two issues:


   1. X.509 is kind of annoying to work with: example code in popular
   languages/frameworks to extract the statement would be useful.

   2. The stock price plugin, at least, embeds the data as text inside the
   X.509 certificate. That's also not terribly developer friendly and risks
   parsing errors undermining security schemes built on it.

   The way I'd solve this is to embed either a protocol buffer or DER
   encoded structure inside the extension, so developers can extract the
   notarised data directly, without needing to do any additional parsing.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150525/eae53ab1/attachment.html>

From mike at plan99.net  Mon May 25 18:15:39 2015
From: mike at plan99.net (Mike Hearn)
Date: Mon, 25 May 2015 20:15:39 +0200
Subject: [Bitcoin-development] Scaling Bitcoin with Subchains
In-Reply-To: <CAL8tG==LG=xC_DzOaghbGGKab4=UVpGLQV7781pU4wg+WnFdMg@mail.gmail.com>
References: <CAL8tG==LG=xC_DzOaghbGGKab4=UVpGLQV7781pU4wg+WnFdMg@mail.gmail.com>
Message-ID: <CANEZrP1p3FU_0fvGKTDWF95Zns5S6KciayViZWiP6OmcqrQDUA@mail.gmail.com>

Hi Andrew,

Your belief that Bitcoin has to be constrained by the belief that hardware
will never improve is extremist, but regardless, your concerns are easy to
assuage: there is no requirement that the block chain be stored on hard
disks. As you note yourself the block chain is used for building/auditing
the ledger. Random access to it is not required, if all you care about is
running a full node.

Luckily this makes it a great fit for tape backup. Technology that can
store 185 terabytes *per cartridge* has already been developed:

http://www.itworld.com/article/2693369/sony-develops-tape-tech-that-could-lead-to-185-tb-cartridges.html

As you could certainly share costs of a block chain archive with other
people, the cost would not be a major concern even today. And it's
virtually guaranteed that humanity will not hit a storage technology wall
in 2015.

If your computer is compromised then all bets are off. Validating the chain
on a compromised host is meaningless.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150525/2d786fb8/attachment.html>

From mike at plan99.net  Mon May 25 18:31:12 2015
From: mike at plan99.net (Mike Hearn)
Date: Mon, 25 May 2015 20:31:12 +0200
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <5550D8BE.6070207@electrum.org>
References: <5550D8BE.6070207@electrum.org>
Message-ID: <CANEZrP2x+fBitgcvoaC2qBbJS-Ek_hgS3ZGM55UtURKc-oDZMQ@mail.gmail.com>

Hi Thomas,

My problem is that this seems to lacks a vision.
>

Are you aware of my proposal for network assurance contracts?

There is a discussion here:


https://www.mail-archive.com/bitcoin-development at lists.sourceforge.net/msg07552.html

But I agree with Gavin that attempting to plan for 20 years from now is
ambitious at best. Bitcoin might not even exist 20 years from now, or might
be an abandoned backwater a la USENET.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150525/3c45d04b/attachment.html>

From mike at plan99.net  Mon May 25 18:36:04 2015
From: mike at plan99.net (Mike Hearn)
Date: Mon, 25 May 2015 20:36:04 +0200
Subject: [Bitcoin-development] No Bitcoin For You
In-Reply-To: <5554BDC1.6070206@thinlink.com>
References: <5554BDC1.6070206@thinlink.com>
Message-ID: <CANEZrP3AbNOW8G-4SyNZNLbD56TrB9c0zz8SCZPFacxDzDVt=g@mail.gmail.com>

>
> If capacity grows, fewer individuals would be able to run full nodes.
>

Hardly. Nobody is currently exhausting the CPU capacity of even a normal
computer currently and even if we did a 20x increase in load overnight,
that still wouldn't even warm up most machines good enough to be always on.

The reasons full nodes are unpopular to run seem to be:

1. Uncontrollable bandwidth usage from sending people the chain
2. People don't run them all the time, then don't want to wait for them to
catch up

The first can be fixed with better code (you can already easily opt out of
uploading the chain, it's just not as fine-grained as desirable), and the
second is fundamental to what full nodes do and how people work. For
merchants, who are the most important demographic we want to be using full
nodes, they can just keep it running all the time. No biggie.


> Therefore miners and other full nodes would depend on
> it, which is rather critical as those nodes grow closer to data-center
> proportions.
>

This meme about datacenter-sized nodes has to die. The Bitcoin wiki is down
right now, but I showed years ago that you could keep up with VISA on a
single well specced server with today's technology. Only people living in a
dreamworld think that Bitcoin might actually have to match that level of
transaction demand with today's hardware. As noted previously, "too many
users" is simply not a problem Bitcoin has .... and may never have!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150525/2b8563b3/attachment.html>

From mike at plan99.net  Mon May 25 18:41:06 2015
From: mike at plan99.net (Mike Hearn)
Date: Mon, 25 May 2015 20:41:06 +0200
Subject: [Bitcoin-development] A suggestion for reducing the size of the
 UTXO database
In-Reply-To: <2114827.D6GUhXtGkV@crushinator>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
	<2114827.D6GUhXtGkV@crushinator>
Message-ID: <CANEZrP2KnL9NO-DgUuaT5-VHE0oT5MTsok2YuAO1nJiznLfpMA@mail.gmail.com>

>
> some wallets (e.g., Andreas Schildbach's wallet) don't even allow it - you
> can only spend confirmed UTXOs. I can't tell you how aggravating it is to
> have to tell a friend, "Oh, oops, I can't pay you yet. I have to wait for
> the last transaction I did to confirm first." All the more aggravating
> because I know, if I have multiple UTXOs in my wallet, I can make multiple
> spends within the same block.
>

Andreas' wallet hasn't done that for years. Are you repeating this from
some very old memory or do you actually see this issue in reality?

The only time you're forced to wait for confirmations is when you have an
unconfirmed inbound transaction, and thus the sender is unknown.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150525/31357329/attachment.html>

From mike at plan99.net  Mon May 25 18:44:18 2015
From: mike at plan99.net (Mike Hearn)
Date: Mon, 25 May 2015 20:44:18 +0200
Subject: [Bitcoin-development] A suggestion for reducing the size of the
 UTXO database
In-Reply-To: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
Message-ID: <CANEZrP0DL8yA=neK0DTq0npEqc0q+RvTQD57OndNVg0vi2=yMg@mail.gmail.com>

Wallets are incentivised to do a better job with defragmentation already,
as if you have lots of tiny UTXOs then your fees end up being huge when
trying to make a payment.

The reason they largely don't is just one of manpower. Nobody is working on
it.

As a wallet developer myself, one way I'd like to see this issue be fixed
by making free transactions more reliable. Then wallets can submit free
transactions to the network to consolidate UTXOs together, e.g. at night
when the user is sleeping. They would then fit into whatever space is
available in the block during periods of low demand, like on Sunday.

If we don't do this then wallets won't automatically defragment, as we'd be
unable to explain to the user why their money is slowly leaking out of
their wallet without them doing anything. Trying to explain the existing
transaction fees is hard enough already ("I thought bitcoin doesn't have
banks" etc).

There is another way:  as the fee is based on a rounded 1kb calculation, if
you go into the next fee band adding some more outputs and making a bigger
change output becomes "free" for another output or two. But wallets don't
exploit this today.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150525/7676f9f7/attachment.html>

From bip at mattwhitlock.name  Mon May 25 20:03:28 2015
From: bip at mattwhitlock.name (Matt Whitlock)
Date: Mon, 25 May 2015 16:03:28 -0400
Subject: [Bitcoin-development] A suggestion for reducing the size of the
	UTXO database
In-Reply-To: <CANEZrP2KnL9NO-DgUuaT5-VHE0oT5MTsok2YuAO1nJiznLfpMA@mail.gmail.com>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
	<2114827.D6GUhXtGkV@crushinator>
	<CANEZrP2KnL9NO-DgUuaT5-VHE0oT5MTsok2YuAO1nJiznLfpMA@mail.gmail.com>
Message-ID: <1515563.NQHYuaqTfB@crushinator>

On Monday, 25 May 2015, at 8:41 pm, Mike Hearn wrote:
> > some wallets (e.g., Andreas Schildbach's wallet) don't even allow it - you
> > can only spend confirmed UTXOs. I can't tell you how aggravating it is to
> > have to tell a friend, "Oh, oops, I can't pay you yet. I have to wait for
> > the last transaction I did to confirm first." All the more aggravating
> > because I know, if I have multiple UTXOs in my wallet, I can make multiple
> > spends within the same block.
> 
> Andreas' wallet hasn't done that for years. Are you repeating this from
> some very old memory or do you actually see this issue in reality?
> 
> The only time you're forced to wait for confirmations is when you have an
> unconfirmed inbound transaction, and thus the sender is unknown.

I see this behavior all the time. I am using the latest release, as far as I know. Version 4.30.

The same behavior occurs in the Testnet3 variant of the app. Go in there with an empty wallet and receive one payment and wait for it to confirm. Then send a payment and, before it confirms, try to send another one. The wallet won't let you send the second payment. It'll say something like, "You need x.xxxxxx more bitcoins to make this payment." But if you wait for your first payment to confirm, then you'll be able to make the second payment.

If it matters, I configure the app to connect only to my own trusted Bitcoin node, so I only ever have one active connection at most. I notice that outgoing payments never show as "Sent" until they appear in a block, presumably because the app never sees the transaction come in over any connection.



From rdwnj at yahoo.com  Mon May 25 20:14:17 2015
From: rdwnj at yahoo.com (Ron)
Date: Mon, 25 May 2015 20:14:17 +0000 (UTC)
Subject: [Bitcoin-development] alternatives to the 20MB block limit,
	measure first!
Message-ID: <542308084.933798.1432584857775.JavaMail.yahoo@mail.yahoo.com>

Hello all,

With all the discussion about the Block size limit, I thought it would be interesting to measure, in some sense, the average Tx size.? Then given a fixed average block period (Bp) of 10 minutes (i.e 600 seconds), all one needs to do to estimate an average block size is ask the question: what average transaction rate (tps) do you want?

So for tps ~ 10 (Tx/sec) and an average transaction size (avgTxSz) of 612 Bytes (last ten blocks up to block 357998 (2:05pm EDT 5/25/2015) we have a block size of 612 * 10 * 600 = 3,672,000 Bytes

Alternatively, given an avgTxSz ~612 and maxBl = 1,000,000 we have (maxBl / avgBlSz) / Bp is the actual current max tps, which is ~2.72 tps.

The avgBlSz for the 10 blocks up to block # 357999 is ~ 576 Bytes, so the current possible tps is ~2.89 and the maxBL for a tps = 10 is 3,456,000 bytes.

So I think one should state one's assumed tps and a measured or presumed avgTxSz before saying what a maxBl should be. So for a maxBl ~20,000,000 Bytes and a current avgTxSz ~600 Bytes, the tps ~55.5 FWIW

Ron (aka old c coder)

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150525/943ed1d9/attachment.html>

From andreas at schildbach.de  Mon May 25 20:29:26 2015
From: andreas at schildbach.de (Andreas Schildbach)
Date: Mon, 25 May 2015 22:29:26 +0200
Subject: [Bitcoin-development] A suggestion for reducing the size of the
	UTXO database
In-Reply-To: <1515563.NQHYuaqTfB@crushinator>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>	<2114827.D6GUhXtGkV@crushinator>	<CANEZrP2KnL9NO-DgUuaT5-VHE0oT5MTsok2YuAO1nJiznLfpMA@mail.gmail.com>
	<1515563.NQHYuaqTfB@crushinator>
Message-ID: <mk00n6$719$1@ger.gmane.org>

On 05/25/2015 10:03 PM, Matt Whitlock wrote:
> On Monday, 25 May 2015, at 8:41 pm, Mike Hearn wrote:
>>> some wallets (e.g., Andreas Schildbach's wallet) don't even allow it - you
>>> can only spend confirmed UTXOs. I can't tell you how aggravating it is to
>>> have to tell a friend, "Oh, oops, I can't pay you yet. I have to wait for
>>> the last transaction I did to confirm first." All the more aggravating
>>> because I know, if I have multiple UTXOs in my wallet, I can make multiple
>>> spends within the same block.
>>
>> Andreas' wallet hasn't done that for years. Are you repeating this from
>> some very old memory or do you actually see this issue in reality?
>>
>> The only time you're forced to wait for confirmations is when you have an
>> unconfirmed inbound transaction, and thus the sender is unknown.
> 
> I see this behavior all the time. I am using the latest release, as far as I know. Version 4.30.
> 
> The same behavior occurs in the Testnet3 variant of the app. Go in there with an empty wallet and receive one payment and wait for it to confirm. Then send a payment and, before it confirms, try to send another one. The wallet won't let you send the second payment. It'll say something like, "You need x.xxxxxx more bitcoins to make this payment." But if you wait for your first payment to confirm, then you'll be able to make the second payment.
> 
> If it matters, I configure the app to connect only to my own trusted Bitcoin node, so I only ever have one active connection at most. I notice that outgoing payments never show as "Sent" until they appear in a block, presumably because the app never sees the transaction come in over any connection.

Yes, that's the issue. Because you're connecting only to one node, you
don't get any instant confirmations -- due to a Bitcoin protocol
limitation you can only get them from nodes you don't post the tx to.






From pete at petertodd.org  Mon May 25 21:05:41 2015
From: pete at petertodd.org (Peter Todd)
Date: Mon, 25 May 2015 17:05:41 -0400
Subject: [Bitcoin-development] A suggestion for reducing the size of the
 UTXO database
In-Reply-To: <mk00n6$719$1@ger.gmane.org>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
	<2114827.D6GUhXtGkV@crushinator>
	<CANEZrP2KnL9NO-DgUuaT5-VHE0oT5MTsok2YuAO1nJiznLfpMA@mail.gmail.com>
	<1515563.NQHYuaqTfB@crushinator> <mk00n6$719$1@ger.gmane.org>
Message-ID: <20150525210541.GA12430@savin.petertodd.org>

On Mon, May 25, 2015 at 10:29:26PM +0200, Andreas Schildbach wrote:
> > I see this behavior all the time. I am using the latest release, as far as I know. Version 4.30.
> > 
> > The same behavior occurs in the Testnet3 variant of the app. Go in there with an empty wallet and receive one payment and wait for it to confirm. Then send a payment and, before it confirms, try to send another one. The wallet won't let you send the second payment. It'll say something like, "You need x.xxxxxx more bitcoins to make this payment." But if you wait for your first payment to confirm, then you'll be able to make the second payment.
> > 
> > If it matters, I configure the app to connect only to my own trusted Bitcoin node, so I only ever have one active connection at most. I notice that outgoing payments never show as "Sent" until they appear in a block, presumably because the app never sees the transaction come in over any connection.
> 
> Yes, that's the issue. Because you're connecting only to one node, you
> don't get any instant confirmations -- due to a Bitcoin protocol
> limitation you can only get them from nodes you don't post the tx to.

Odd, I just tried the above as well - with multiple peers connected -
and had the exact same problem.

-- 
'peter'[:-1]@petertodd.org
00000000000000000e83c311f4244e4eefb54aa845abb181e46f16d126ab21e1
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150525/a2334287/attachment.sig>

From mike at plan99.net  Mon May 25 21:12:58 2015
From: mike at plan99.net (Mike Hearn)
Date: Mon, 25 May 2015 23:12:58 +0200
Subject: [Bitcoin-development] A suggestion for reducing the size of the
 UTXO database
In-Reply-To: <1515563.NQHYuaqTfB@crushinator>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
	<2114827.D6GUhXtGkV@crushinator>
	<CANEZrP2KnL9NO-DgUuaT5-VHE0oT5MTsok2YuAO1nJiznLfpMA@mail.gmail.com>
	<1515563.NQHYuaqTfB@crushinator>
Message-ID: <CANEZrP2FjxmMn3TKPGdP-mTMDt4a4aJB5AisEp+NdW6qCAAEEw@mail.gmail.com>

>
> If it matters, I configure the app to connect only to my own trusted
> Bitcoin node, so I only ever have one active connection at most.


Ah, I see, non default configuration. Because the Bitcoin network can and
does change in backwards incompatible ways, the app wants to see that the
transaction it made actually propagated across the network. If you set a
trusted node it won't see that.

Probably the logic should be tweaked so if you set a trusted node you're
just assumed to know what you're doing and we assume the transactions we
make ourselves always work.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150525/2c1f1d06/attachment.html>

From wtogami at gmail.com  Mon May 25 21:14:46 2015
From: wtogami at gmail.com (Warren Togami Jr.)
Date: Mon, 25 May 2015 14:14:46 -0700
Subject: [Bitcoin-development] A suggestion for reducing the size of the
 UTXO database
In-Reply-To: <mk00n6$719$1@ger.gmane.org>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
	<2114827.D6GUhXtGkV@crushinator>
	<CANEZrP2KnL9NO-DgUuaT5-VHE0oT5MTsok2YuAO1nJiznLfpMA@mail.gmail.com>
	<1515563.NQHYuaqTfB@crushinator> <mk00n6$719$1@ger.gmane.org>
Message-ID: <CAEz79PrfWpkNKNDpsh6q3KNpdceTpH++w4j_BusADSB2OqBtXA@mail.gmail.com>

On Mon, May 25, 2015 at 1:29 PM, Andreas Schildbach
<andreas at schildbach.de> wrote:
> Yes, that's the issue. Because you're connecting only to one node, you
> don't get any instant confirmations -- due to a Bitcoin protocol
> limitation you can only get them from nodes you don't post the tx to.

Is it really wise to call this a "confirmation"?  All this is really
telling you is one seemingly random peer has relayed the transaction
back to you that you sent to a presumably different seemingly random
peer.

Warren



From pete at petertodd.org  Mon May 25 21:26:38 2015
From: pete at petertodd.org (Peter Todd)
Date: Mon, 25 May 2015 17:26:38 -0400
Subject: [Bitcoin-development] A suggestion for reducing the size of the
 UTXO database
In-Reply-To: <CANEZrP0DL8yA=neK0DTq0npEqc0q+RvTQD57OndNVg0vi2=yMg@mail.gmail.com>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
	<CANEZrP0DL8yA=neK0DTq0npEqc0q+RvTQD57OndNVg0vi2=yMg@mail.gmail.com>
Message-ID: <20150525212638.GB12430@savin.petertodd.org>

On Mon, May 25, 2015 at 08:44:18PM +0200, Mike Hearn wrote:
> Wallets are incentivised to do a better job with defragmentation already,
> as if you have lots of tiny UTXOs then your fees end up being huge when
> trying to make a payment.
> 
> The reason they largely don't is just one of manpower. Nobody is working on
> it.
> 
> As a wallet developer myself, one way I'd like to see this issue be fixed
> by making free transactions more reliable. Then wallets can submit free
> transactions to the network to consolidate UTXOs together, e.g. at night
> when the user is sleeping. They would then fit into whatever space is
> available in the block during periods of low demand, like on Sunday.

This can cause problems as until those transactions confirm, even more
of the user's outputs are unavailable for spending, causing confusion as
to why they can't send their full balance. It's also inefficient, as in
the case where the user does try to send a small payment that could be
satisfied by one or more of these small UTXO's, the wallet has to use a
larger UTXO.

With replace-by-fee however this problem goes away, as you can simply
double-spend the pending defragmentation transactions instead if they
are still unconfirmed when you need to use them.

-- 
'peter'[:-1]@petertodd.org
00000000000000000aa9033c06c10d6131eafa3754c3157d74c2267c1dd2ca35
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150525/80f62ec5/attachment.sig>

From mike at plan99.net  Mon May 25 22:03:09 2015
From: mike at plan99.net (Mike Hearn)
Date: Tue, 26 May 2015 00:03:09 +0200
Subject: [Bitcoin-development] A suggestion for reducing the size of the
 UTXO database
In-Reply-To: <20150525212638.GB12430@savin.petertodd.org>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
	<CANEZrP0DL8yA=neK0DTq0npEqc0q+RvTQD57OndNVg0vi2=yMg@mail.gmail.com>
	<20150525212638.GB12430@savin.petertodd.org>
Message-ID: <CANEZrP1k-rUBSj2GMKqOEZsOuHp=axKUSxShOiN01DorzkFODQ@mail.gmail.com>

CPFP also solves it just fine.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150526/cc086865/attachment.html>

From pete at petertodd.org  Tue May 26 00:10:34 2015
From: pete at petertodd.org (Peter Todd)
Date: Mon, 25 May 2015 20:10:34 -0400
Subject: [Bitcoin-development]  Cost savings by using replace-by-fee, 30-90%
In-Reply-To: <CANEZrP1k-rUBSj2GMKqOEZsOuHp=axKUSxShOiN01DorzkFODQ@mail.gmail.com>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
	<CANEZrP0DL8yA=neK0DTq0npEqc0q+RvTQD57OndNVg0vi2=yMg@mail.gmail.com>
	<20150525212638.GB12430@savin.petertodd.org>
	<CANEZrP1k-rUBSj2GMKqOEZsOuHp=axKUSxShOiN01DorzkFODQ@mail.gmail.com>
Message-ID: <20150526001034.GF21367@savin.petertodd.org>

On Tue, May 26, 2015 at 12:03:09AM +0200, Mike Hearn wrote:
> CPFP also solves it just fine.

CPFP is a significantly more expensive way of paying fees than RBF,
particularly for the use-case of defragmenting outputs, with cost
savings ranging from 30% to 90%


Case 1: CPFP vs. RBF for increasing the fee on a single tx
----------------------------------------------------------

Creating an spending a P2PKH output uses 34 bytes of txout, and 148
bytes of txin, 182 bytes total.

Let's suppose I have a 1 BTC P2PKH output and I want to pay 0.1 BTC to
Alice. This results in a 1in/2out transaction t1 that's 226 bytes in size.
I forget to click on the "priority fee" option, so it goes out with the
minimum fee of 2.26uBTC. Whoops! I use CPFP to spend that output,
creating a new transaction t2 that's 192 bytes in size. I want to pay
1mBTC/KB for a fast confirmation, so I'm now paying 418uBTC of
transaction fees.

On the other hand, had I use RBF, my wallet would have simply
rebroadcast t1 with the change address decreased. The rules require you
to pay 2.26uBTC for the bandwidth consumed broadcasting it, plus the new
fee level, or 218uBTC of fees in total.

Cost savings: 48%


Case 2: Paying multiple recipients in succession
------------------------------------------------

Suppose that after I pay Alice, I also decide to pay Bob for his hard
work demonstrating cryptographic protocols. I need to create a new
transaction t2 spending t1's change address. Normally t2 would be
another 226 bytes in size, resulting in 226uBTC additional fees.

With RBF on the other hand I can simply double-spend t1 with a
transaction paying both Alice and Bob. This new transaction is 260 bytes
in size. I have to pay 2.6uBTC additional fees to pay for the bandwidth
consumed broadcasting it, resulting in an additional 36uBTC of fees.

Cost savings: 84%


Case 3: Paying multiple recipients from a 2-of-3 multisig wallet
----------------------------------------------------------------

The above situation gets even worse with multisig. t1 in the multisig
case is 367 bytes; t2 another 367 bytes, costing an additional 367uBTC
in fees. With RBF we rewrite t1 with an additional output, resulting in
a 399 byte transaction, with just 36uBTC in additional fees.

Cost savings: 90%


Case 4: Dust defragmentation
----------------------------

My wallet has a two transaction outputs that it wants to combine into
one for the purpose of UTXO defragmentation. It broadcasts transaction
t1 with two inputs and one output, size 340 bytes, paying zero fees.

Prior to the transaction confirming I find I need to spend those funds
for a priority transaction at the 1mBTC/KB fee level. This transaction,
t2a, has one input and two outputs, 226 bytes in size. However it needs
to pay fees for both transactions at once, resulting in a combined total
fee of 556uBTC. If this situation happens frequently, defragmenting
UTXOs is likely to cost more in additional fees than it saves.

With RBF I'd simply doublespend t1 with a 2-in-2-out transaction 374
bytes in size, paying 374uBTC. Even better, if one of the two inputs is
sufficiently large to cover my costs I can doublespend t1 with a
1-in-2-out tx just 226 bytes in size, paying 226uBTC.

Cost savings: 32% to 59%, or even infinite if defragmentation w/o RBF
              costs you more than you save

-- 
'peter'[:-1]@petertodd.org
0000000000000000134ce6577d4122094479f548b997baf84367eaf0c190bc9f
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150525/ae1be84d/attachment.sig>

From jim at ergophobia.org  Tue May 26 02:26:42 2015
From: jim at ergophobia.org (Jim Phillips)
Date: Mon, 25 May 2015 21:26:42 -0500
Subject: [Bitcoin-development] No Bitcoin For You
In-Reply-To: <CANEZrP3AbNOW8G-4SyNZNLbD56TrB9c0zz8SCZPFacxDzDVt=g@mail.gmail.com>
References: <5554BDC1.6070206@thinlink.com>
	<CANEZrP3AbNOW8G-4SyNZNLbD56TrB9c0zz8SCZPFacxDzDVt=g@mail.gmail.com>
Message-ID: <CANe1mWz4qTOw8JYC-m8x6ajdLfm+Y__L1jn+W0HmNhCJ0tX4Kw@mail.gmail.com>

On Mon, May 25, 2015 at 1:36 PM, Mike Hearn <mike at plan99.net> wrote:

This meme about datacenter-sized nodes has to die. The Bitcoin wiki is down
> right now, but I showed years ago that you could keep up with VISA on a
> single well specced server with today's technology. Only people living in a
> dreamworld think that Bitcoin might actually have to match that level of
> transaction demand with today's hardware. As noted previously, "too many
> users" is simply not a problem Bitcoin has .... and may never have!
>
>
... And will certainly NEVER have if we can't solve the capacity problem
SOON.

In a former life, I was a capacity planner for Bank of America's mid-range
server group. We had one hard and fast rule. When you are typically
exceeding 75% of capacity on a given metric, it's time to expand capacity.
Period. You don't do silly things like adjusting the business model to
disincentivize use. Unless there's some flaw in the system and it's leaking
resources, if usage has increased to the point where you are at or near the
limits of capacity, you expand capacity. It's as simple as that, and I've
found that same rule fits quite well in a number of systems.

In Bitcoin, we're not leaking resources. There's no flaw. The system is
performing as intended. Usage is increasing because it works so well, and
there is huge potential for future growth as we identify more uses and
attract more users. There might be a few technical things we can do to
reduce consumption, but the metric we're concerned with right now is how
many transactions we can fit in a block. We've broken through the 75%
marker and are regularly bumping up against the 100% limit.

It is time to stop debating this and take action to expand capacity. The
only questions that should remain are how much capacity do we add, and how
soon can we do it. Given that most existing computer systems and networks
can easily handle 20MB blocks every 10 minutes, and given that that will
increase capacity 20-fold, I can't think of a single reason why we can't go
to 20MB as soon as humanly possible. And in a few years, when the average
block size is over 15MB, we bump it up again to as high as we can go then
without pushing typical computers or networks beyond their capacity. We can
worry about ways to slow down growth without affecting the usefulness of
Bitcoin as we get closer to the hard technical limits on our capacity.

And you know what else? If miners need higher fees to accommodate the costs
of bigger blocks, they can configure their nodes to only mine transactions
with higher fees.. Let the miners decide how to charge enough to pay for
their costs. We don't need to cripple the network just for them.

--
*James G. Phillips IV*
<https://plus.google.com/u/0/113107039501292625391/posts>

*"Don't bunt. Aim out of the ball park. Aim for the company of immortals."
-- David Ogilvy*

 *This message was created with 100% recycled electrons. Please think twice
before printing.*
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150525/4c46b15f/attachment.html>

From thyshizzle at outlook.com  Tue May 26 02:30:52 2015
From: thyshizzle at outlook.com (Thy Shizzle)
Date: Tue, 26 May 2015 12:30:52 +1000
Subject: [Bitcoin-development] No Bitcoin For You
Message-ID: <BAY403-EAS278EF7A9628FBB64F90CF09C2CC0@phx.gbl>

Nah don't make blocks 20mb, then you are slowing down block propagation and blowing out conf tikes as a result. Just decrease the time it takes to make a 1mb block, then you still see the same propagation times today and just increase the transaction throughput.
________________________________
From: Jim Phillips<mailto:jim at ergophobia.org>
Sent: ?26/?05/?2015 12:27 PM
To: Mike Hearn<mailto:mike at plan99.net>
Cc: Bitcoin Dev<mailto:bitcoin-development at lists.sourceforge.net>
Subject: Re: [Bitcoin-development] No Bitcoin For You

On Mon, May 25, 2015 at 1:36 PM, Mike Hearn <mike at plan99.net> wrote:

This meme about datacenter-sized nodes has to die. The Bitcoin wiki is down
> right now, but I showed years ago that you could keep up with VISA on a
> single well specced server with today's technology. Only people living in a
> dreamworld think that Bitcoin might actually have to match that level of
> transaction demand with today's hardware. As noted previously, "too many
> users" is simply not a problem Bitcoin has .... and may never have!
>
>
... And will certainly NEVER have if we can't solve the capacity problem
SOON.

In a former life, I was a capacity planner for Bank of America's mid-range
server group. We had one hard and fast rule. When you are typically
exceeding 75% of capacity on a given metric, it's time to expand capacity.
Period. You don't do silly things like adjusting the business model to
disincentivize use. Unless there's some flaw in the system and it's leaking
resources, if usage has increased to the point where you are at or near the
limits of capacity, you expand capacity. It's as simple as that, and I've
found that same rule fits quite well in a number of systems.

In Bitcoin, we're not leaking resources. There's no flaw. The system is
performing as intended. Usage is increasing because it works so well, and
there is huge potential for future growth as we identify more uses and
attract more users. There might be a few technical things we can do to
reduce consumption, but the metric we're concerned with right now is how
many transactions we can fit in a block. We've broken through the 75%
marker and are regularly bumping up against the 100% limit.

It is time to stop debating this and take action to expand capacity. The
only questions that should remain are how much capacity do we add, and how
soon can we do it. Given that most existing computer systems and networks
can easily handle 20MB blocks every 10 minutes, and given that that will
increase capacity 20-fold, I can't think of a single reason why we can't go
to 20MB as soon as humanly possible. And in a few years, when the average
block size is over 15MB, we bump it up again to as high as we can go then
without pushing typical computers or networks beyond their capacity. We can
worry about ways to slow down growth without affecting the usefulness of
Bitcoin as we get closer to the hard technical limits on our capacity.

And you know what else? If miners need higher fees to accommodate the costs
of bigger blocks, they can configure their nodes to only mine transactions
with higher fees.. Let the miners decide how to charge enough to pay for
their costs. We don't need to cripple the network just for them.

--
*James G. Phillips IV*
<https://plus.google.com/u/0/113107039501292625391/posts>

*"Don't bunt. Aim out of the ball park. Aim for the company of immortals."
-- David Ogilvy*

 *This message was created with 100% recycled electrons. Please think twice
before printing.*
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150526/744b3e51/attachment.html>
-------------- next part --------------
------------------------------------------------------------------------------
One dashboard for servers and applications across Physical-Virtual-Cloud 
Widest out-of-the-box monitoring support with 50+ applications
Performance metrics, stats and reports that give you Actionable Insights
Deep dive visibility with transaction tracing using APM Insight.
http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
-------------- next part --------------
_______________________________________________
Bitcoin-development mailing list
Bitcoin-development at lists.sourceforge.net
https://lists.sourceforge.net/lists/listinfo/bitcoin-development

From gappleto97 at gmail.com  Tue May 26 02:41:28 2015
From: gappleto97 at gmail.com (gabe appleton)
Date: Mon, 25 May 2015 22:41:28 -0400
Subject: [Bitcoin-development] No Bitcoin For You
In-Reply-To: <BAY403-EAS278EF7A9628FBB64F90CF09C2CC0@phx.gbl>
References: <BAY403-EAS278EF7A9628FBB64F90CF09C2CC0@phx.gbl>
Message-ID: <CANJO25K2C9KT-eGSBdJDLZfwuamyMUE+=4ghhL+hqU5ORh0oWw@mail.gmail.com>

But don't you see the same trade-off in the end there? You're still
propagating the same amount of data over the same amount of time, so unless
I misunderstand, the costs of such a move should be approximately the same,
just in different areas. The risks as I understand are as follows:

20MB:


   1. Longer per-block propagation (eventually)
   2. Longer processing time (eventually)
   3. Longer sync time

1 Minute:

   1. Weaker individual confirmations (approx. equal per confirmation*time)
   2. Higher orphan rate (immediately)
   3. Longer sync time

That risk-set makes me want a middle-ground approach. Something where the
immediate consequences aren't all that strong, and where we have some idea
of what to do in the future. Is there any chance we can get decent network
simulations at various configurations (5MB/4min, etc)? Perhaps
re-appropriate the testnet?

On Mon, May 25, 2015 at 10:30 PM, Thy Shizzle <thyshizzle at outlook.com>
wrote:

>  Nah don't make blocks 20mb, then you are slowing down block propagation
> and blowing out conf tikes as a result. Just decrease the time it takes to
> make a 1mb block, then you still see the same propagation times today and
> just increase the transaction throughput.
>  ------------------------------
> From: Jim Phillips <jim at ergophobia.org>
> Sent: ?26/?05/?2015 12:27 PM
> To: Mike Hearn <mike at plan99.net>
> Cc: Bitcoin Dev <bitcoin-development at lists.sourceforge.net>
> Subject: Re: [Bitcoin-development] No Bitcoin For You
>
>
> On Mon, May 25, 2015 at 1:36 PM, Mike Hearn <mike at plan99.net> wrote:
>
>   This meme about datacenter-sized nodes has to die. The Bitcoin wiki is
> down right now, but I showed years ago that you could keep up with VISA on
> a single well specced server with today's technology. Only people living in
> a dreamworld think that Bitcoin might actually have to match that level of
> transaction demand with today's hardware. As noted previously, "too many
> users" is simply not a problem Bitcoin has .... and may never have!
>
>
>  ... And will certainly NEVER have if we can't solve the capacity problem
> SOON.
>
>  In a former life, I was a capacity planner for Bank of America's
> mid-range server group. We had one hard and fast rule. When you are
> typically exceeding 75% of capacity on a given metric, it's time to expand
> capacity. Period. You don't do silly things like adjusting the business
> model to disincentivize use. Unless there's some flaw in the system and
> it's leaking resources, if usage has increased to the point where you are
> at or near the limits of capacity, you expand capacity. It's as simple as
> that, and I've found that same rule fits quite well in a number of systems.
>
>  In Bitcoin, we're not leaking resources. There's no flaw. The system is
> performing as intended. Usage is increasing because it works so well, and
> there is huge potential for future growth as we identify more uses and
> attract more users. There might be a few technical things we can do to
> reduce consumption, but the metric we're concerned with right now is how
> many transactions we can fit in a block. We've broken through the 75%
> marker and are regularly bumping up against the 100% limit.
>
>  It is time to stop debating this and take action to expand capacity. The
> only questions that should remain are how much capacity do we add, and how
> soon can we do it. Given that most existing computer systems and networks
> can easily handle 20MB blocks every 10 minutes, and given that that will
> increase capacity 20-fold, I can't think of a single reason why we can't go
> to 20MB as soon as humanly possible. And in a few years, when the average
> block size is over 15MB, we bump it up again to as high as we can go then
> without pushing typical computers or networks beyond their capacity. We can
> worry about ways to slow down growth without affecting the usefulness of
> Bitcoin as we get closer to the hard technical limits on our capacity.
>
>  And you know what else? If miners need higher fees to accommodate the
> costs of bigger blocks, they can configure their nodes to only mine
> transactions with higher fees.. Let the miners decide how to charge enough
> to pay for their costs. We don't need to cripple the network just for them.
>
>  --
> *James G. Phillips IV*
> <https://plus.google.com/u/0/113107039501292625391/posts>
>
> *"Don't bunt. Aim out of the ball park. Aim for the company of immortals."
> -- David Ogilvy *
>
>   *This message was created with 100% recycled electrons. Please think
> twice before printing.*
>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150525/7cd4d54f/attachment.html>

From thyshizzle at outlook.com  Tue May 26 02:51:00 2015
From: thyshizzle at outlook.com (Thy Shizzle)
Date: Tue, 26 May 2015 12:51:00 +1000
Subject: [Bitcoin-development] No Bitcoin For You
Message-ID: <BAY403-EAS100C211D1C5E57BFB80BFE6C2CC0@phx.gbl>

I wouldn't say same trade-off because you need the whole 20mb block before you can start to use it where as a 1mb block can be used quicker thus transactions found in tge block quicker etc. As for tge higher rate of orphans, I think this would be complimented by a faster correction rate, so if you're pumping out blocks at a rate of 1 per minute, if we get a fork and the next block comes in 10 minutes and is the decider, it took 10 minutes to determine which block is the orphan. But at a rate of 1 block per 1 minute then it only takes 1 minute to resolve the orphan (obviously this is very simplified) so I'm not so sure that orphan rate is a big issue here. Indeed you would need to draw upon more confirmations for easier block creation but surely that is not an issue?

Why would sync time be longer as opposed to 20mb blocks?
________________________________
From: gabe appleton<mailto:gappleto97 at gmail.com>
Sent: ?26/?05/?2015 12:41 PM
To: Thy Shizzle<mailto:thyshizzle at outlook.com>
Cc: Jim Phillips<mailto:jim at ergophobia.org>; Mike Hearn<mailto:mike at plan99.net>; Bitcoin Dev<mailto:bitcoin-development at lists.sourceforge.net>
Subject: Re: [Bitcoin-development] No Bitcoin For You

But don't you see the same trade-off in the end there? You're still
propagating the same amount of data over the same amount of time, so unless
I misunderstand, the costs of such a move should be approximately the same,
just in different areas. The risks as I understand are as follows:

20MB:


   1. Longer per-block propagation (eventually)
   2. Longer processing time (eventually)
   3. Longer sync time

1 Minute:

   1. Weaker individual confirmations (approx. equal per confirmation*time)
   2. Higher orphan rate (immediately)
   3. Longer sync time

That risk-set makes me want a middle-ground approach. Something where the
immediate consequences aren't all that strong, and where we have some idea
of what to do in the future. Is there any chance we can get decent network
simulations at various configurations (5MB/4min, etc)? Perhaps
re-appropriate the testnet?

On Mon, May 25, 2015 at 10:30 PM, Thy Shizzle <thyshizzle at outlook.com>
wrote:

>  Nah don't make blocks 20mb, then you are slowing down block propagation
> and blowing out conf tikes as a result. Just decrease the time it takes to
> make a 1mb block, then you still see the same propagation times today and
> just increase the transaction throughput.
>  ------------------------------
> From: Jim Phillips <jim at ergophobia.org>
> Sent: ?26/?05/?2015 12:27 PM
> To: Mike Hearn <mike at plan99.net>
> Cc: Bitcoin Dev <bitcoin-development at lists.sourceforge.net>
> Subject: Re: [Bitcoin-development] No Bitcoin For You
>
>
> On Mon, May 25, 2015 at 1:36 PM, Mike Hearn <mike at plan99.net> wrote:
>
>   This meme about datacenter-sized nodes has to die. The Bitcoin wiki is
> down right now, but I showed years ago that you could keep up with VISA on
> a single well specced server with today's technology. Only people living in
> a dreamworld think that Bitcoin might actually have to match that level of
> transaction demand with today's hardware. As noted previously, "too many
> users" is simply not a problem Bitcoin has .... and may never have!
>
>
>  ... And will certainly NEVER have if we can't solve the capacity problem
> SOON.
>
>  In a former life, I was a capacity planner for Bank of America's
> mid-range server group. We had one hard and fast rule. When you are
> typically exceeding 75% of capacity on a given metric, it's time to expand
> capacity. Period. You don't do silly things like adjusting the business
> model to disincentivize use. Unless there's some flaw in the system and
> it's leaking resources, if usage has increased to the point where you are
> at or near the limits of capacity, you expand capacity. It's as simple as
> that, and I've found that same rule fits quite well in a number of systems.
>
>  In Bitcoin, we're not leaking resources. There's no flaw. The system is
> performing as intended. Usage is increasing because it works so well, and
> there is huge potential for future growth as we identify more uses and
> attract more users. There might be a few technical things we can do to
> reduce consumption, but the metric we're concerned with right now is how
> many transactions we can fit in a block. We've broken through the 75%
> marker and are regularly bumping up against the 100% limit.
>
>  It is time to stop debating this and take action to expand capacity. The
> only questions that should remain are how much capacity do we add, and how
> soon can we do it. Given that most existing computer systems and networks
> can easily handle 20MB blocks every 10 minutes, and given that that will
> increase capacity 20-fold, I can't think of a single reason why we can't go
> to 20MB as soon as humanly possible. And in a few years, when the average
> block size is over 15MB, we bump it up again to as high as we can go then
> without pushing typical computers or networks beyond their capacity. We can
> worry about ways to slow down growth without affecting the usefulness of
> Bitcoin as we get closer to the hard technical limits on our capacity.
>
>  And you know what else? If miners need higher fees to accommodate the
> costs of bigger blocks, they can configure their nodes to only mine
> transactions with higher fees.. Let the miners decide how to charge enough
> to pay for their costs. We don't need to cripple the network just for them.
>
>  --
> *James G. Phillips IV*
> <https://plus.google.com/u/0/113107039501292625391/posts>
>
> *"Don't bunt. Aim out of the ball park. Aim for the company of immortals."
> -- David Ogilvy *
>
>   *This message was created with 100% recycled electrons. Please think
> twice before printing.*
>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150526/f03594e9/attachment.html>

From jim at ergophobia.org  Tue May 26 02:53:10 2015
From: jim at ergophobia.org (Jim Phillips)
Date: Mon, 25 May 2015 21:53:10 -0500
Subject: [Bitcoin-development] No Bitcoin For You
In-Reply-To: <BAY403-EAS278EF7A9628FBB64F90CF09C2CC0@phx.gbl>
References: <BAY403-EAS278EF7A9628FBB64F90CF09C2CC0@phx.gbl>
Message-ID: <CANe1mWxUTR1Syu242eaS7h6AK6rsuw5bmNKmcoLtoSO=KGG6Dg@mail.gmail.com>

Frankly I'm good with either way. I'm definitely in favor of faster
confirmation times.

The important thing is that we need to increase the amount of transactions
that get into blocks over a given time frame to a point that is in line
with what current technology can handle. We can handle WAY more than we are
doing right now. The Bitcoin network is not currently Disk, CPU, or RAM
bound.. Not even close. The metric we're closest to being restricted by
would be Network bandwidth. I live in a developing country. 2Mbps is a
typical broadband speed here (although 5Mbps and 10Mbps connections are
affordable). That equates to about 17MB per minute, or 170x more capacity
than what I need to receive a full copy of the blockchain if I only talk to
one peer. If I relay to say 10 peers, I can still handle 17x larger block
sizes on a slow 2Mbps connection.

Also, even if we reduce the difficulty so that we're doing 1MB blocks every
minute, that's still only 10MB every 10 minutes. Eventually we're going to
have to increase that, and we can only reduce the confirmation period so
much. I think someone once said 30 seconds or so is about the shortest
period you can practically achieve.

--
*James G. Phillips IV*
<https://plus.google.com/u/0/113107039501292625391/posts>
<http://www.linkedin.com/in/ergophobe>

*"Don't bunt. Aim out of the ball park. Aim for the company of immortals."
-- David Ogilvy*

 *This message was created with 100% recycled electrons. Please think twice
before printing.*

On Mon, May 25, 2015 at 9:30 PM, Thy Shizzle <thyshizzle at outlook.com> wrote:

>  Nah don't make blocks 20mb, then you are slowing down block propagation
> and blowing out conf tikes as a result. Just decrease the time it takes to
> make a 1mb block, then you still see the same propagation times today and
> just increase the transaction throughput.
>  ------------------------------
> From: Jim Phillips <jim at ergophobia.org>
> Sent: ?26/?05/?2015 12:27 PM
> To: Mike Hearn <mike at plan99.net>
> Cc: Bitcoin Dev <bitcoin-development at lists.sourceforge.net>
> Subject: Re: [Bitcoin-development] No Bitcoin For You
>
>
> On Mon, May 25, 2015 at 1:36 PM, Mike Hearn <mike at plan99.net> wrote:
>
>   This meme about datacenter-sized nodes has to die. The Bitcoin wiki is
> down right now, but I showed years ago that you could keep up with VISA on
> a single well specced server with today's technology. Only people living in
> a dreamworld think that Bitcoin might actually have to match that level of
> transaction demand with today's hardware. As noted previously, "too many
> users" is simply not a problem Bitcoin has .... and may never have!
>
>
>  ... And will certainly NEVER have if we can't solve the capacity problem
> SOON.
>
>  In a former life, I was a capacity planner for Bank of America's
> mid-range server group. We had one hard and fast rule. When you are
> typically exceeding 75% of capacity on a given metric, it's time to expand
> capacity. Period. You don't do silly things like adjusting the business
> model to disincentivize use. Unless there's some flaw in the system and
> it's leaking resources, if usage has increased to the point where you are
> at or near the limits of capacity, you expand capacity. It's as simple as
> that, and I've found that same rule fits quite well in a number of systems.
>
>  In Bitcoin, we're not leaking resources. There's no flaw. The system is
> performing as intended. Usage is increasing because it works so well, and
> there is huge potential for future growth as we identify more uses and
> attract more users. There might be a few technical things we can do to
> reduce consumption, but the metric we're concerned with right now is how
> many transactions we can fit in a block. We've broken through the 75%
> marker and are regularly bumping up against the 100% limit.
>
>  It is time to stop debating this and take action to expand capacity. The
> only questions that should remain are how much capacity do we add, and how
> soon can we do it. Given that most existing computer systems and networks
> can easily handle 20MB blocks every 10 minutes, and given that that will
> increase capacity 20-fold, I can't think of a single reason why we can't go
> to 20MB as soon as humanly possible. And in a few years, when the average
> block size is over 15MB, we bump it up again to as high as we can go then
> without pushing typical computers or networks beyond their capacity. We can
> worry about ways to slow down growth without affecting the usefulness of
> Bitcoin as we get closer to the hard technical limits on our capacity.
>
>  And you know what else? If miners need higher fees to accommodate the
> costs of bigger blocks, they can configure their nodes to only mine
> transactions with higher fees.. Let the miners decide how to charge enough
> to pay for their costs. We don't need to cripple the network just for them.
>
>  --
> *James G. Phillips IV*
> <https://plus.google.com/u/0/113107039501292625391/posts>
>
> *"Don't bunt. Aim out of the ball park. Aim for the company of immortals."
> -- David Ogilvy *
>
>   *This message was created with 100% recycled electrons. Please think
> twice before printing.*
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150525/3c8eea08/attachment.html>

From thyshizzle at outlook.com  Tue May 26 03:02:00 2015
From: thyshizzle at outlook.com (Thy Shizzle)
Date: Tue, 26 May 2015 13:02:00 +1000
Subject: [Bitcoin-development] No Bitcoin For You
Message-ID: <BAY403-EAS63EE0AAE718842E0E3EFD6C2CC0@phx.gbl>

Indeed Jim, your internet connection makes a good reason why I don't like 20mb blocks (right now). It would take you well over a minute to download the block before you could even relay it on, so much slow down in propagation! Yes I do see how decreasing the time to create blocks is a bit of a band-aid fix, and to use tge term I've seen mentioned here "kicking the can down the road" I agree that this is doing this, however as you say bandwidth is our biggest enemy right now and so hopefully by the time we exceed the capacity gained by the decrease in block time, we can then look to bump up block size because hopefully 20mbps connections will be baseline by then etc.
________________________________
From: Jim Phillips<mailto:jim at ergophobia.org>
Sent: ?26/?05/?2015 12:53 PM
To: Thy Shizzle<mailto:thyshizzle at outlook.com>
Cc: Mike Hearn<mailto:mike at plan99.net>; Bitcoin Dev<mailto:bitcoin-development at lists.sourceforge.net>
Subject: Re: [Bitcoin-development] No Bitcoin For You

Frankly I'm good with either way. I'm definitely in favor of faster
confirmation times.

The important thing is that we need to increase the amount of transactions
that get into blocks over a given time frame to a point that is in line
with what current technology can handle. We can handle WAY more than we are
doing right now. The Bitcoin network is not currently Disk, CPU, or RAM
bound.. Not even close. The metric we're closest to being restricted by
would be Network bandwidth. I live in a developing country. 2Mbps is a
typical broadband speed here (although 5Mbps and 10Mbps connections are
affordable). That equates to about 17MB per minute, or 170x more capacity
than what I need to receive a full copy of the blockchain if I only talk to
one peer. If I relay to say 10 peers, I can still handle 17x larger block
sizes on a slow 2Mbps connection.

Also, even if we reduce the difficulty so that we're doing 1MB blocks every
minute, that's still only 10MB every 10 minutes. Eventually we're going to
have to increase that, and we can only reduce the confirmation period so
much. I think someone once said 30 seconds or so is about the shortest
period you can practically achieve.

--
*James G. Phillips IV*
<https://plus.google.com/u/0/113107039501292625391/posts>
<http://www.linkedin.com/in/ergophobe>

*"Don't bunt. Aim out of the ball park. Aim for the company of immortals."
-- David Ogilvy*

 *This message was created with 100% recycled electrons. Please think twice
before printing.*

On Mon, May 25, 2015 at 9:30 PM, Thy Shizzle <thyshizzle at outlook.com> wrote:

>  Nah don't make blocks 20mb, then you are slowing down block propagation
> and blowing out conf tikes as a result. Just decrease the time it takes to
> make a 1mb block, then you still see the same propagation times today and
> just increase the transaction throughput.
>  ------------------------------
> From: Jim Phillips <jim at ergophobia.org>
> Sent: ?26/?05/?2015 12:27 PM
> To: Mike Hearn <mike at plan99.net>
> Cc: Bitcoin Dev <bitcoin-development at lists.sourceforge.net>
> Subject: Re: [Bitcoin-development] No Bitcoin For You
>
>
> On Mon, May 25, 2015 at 1:36 PM, Mike Hearn <mike at plan99.net> wrote:
>
>   This meme about datacenter-sized nodes has to die. The Bitcoin wiki is
> down right now, but I showed years ago that you could keep up with VISA on
> a single well specced server with today's technology. Only people living in
> a dreamworld think that Bitcoin might actually have to match that level of
> transaction demand with today's hardware. As noted previously, "too many
> users" is simply not a problem Bitcoin has .... and may never have!
>
>
>  ... And will certainly NEVER have if we can't solve the capacity problem
> SOON.
>
>  In a former life, I was a capacity planner for Bank of America's
> mid-range server group. We had one hard and fast rule. When you are
> typically exceeding 75% of capacity on a given metric, it's time to expand
> capacity. Period. You don't do silly things like adjusting the business
> model to disincentivize use. Unless there's some flaw in the system and
> it's leaking resources, if usage has increased to the point where you are
> at or near the limits of capacity, you expand capacity. It's as simple as
> that, and I've found that same rule fits quite well in a number of systems.
>
>  In Bitcoin, we're not leaking resources. There's no flaw. The system is
> performing as intended. Usage is increasing because it works so well, and
> there is huge potential for future growth as we identify more uses and
> attract more users. There might be a few technical things we can do to
> reduce consumption, but the metric we're concerned with right now is how
> many transactions we can fit in a block. We've broken through the 75%
> marker and are regularly bumping up against the 100% limit.
>
>  It is time to stop debating this and take action to expand capacity. The
> only questions that should remain are how much capacity do we add, and how
> soon can we do it. Given that most existing computer systems and networks
> can easily handle 20MB blocks every 10 minutes, and given that that will
> increase capacity 20-fold, I can't think of a single reason why we can't go
> to 20MB as soon as humanly possible. And in a few years, when the average
> block size is over 15MB, we bump it up again to as high as we can go then
> without pushing typical computers or networks beyond their capacity. We can
> worry about ways to slow down growth without affecting the usefulness of
> Bitcoin as we get closer to the hard technical limits on our capacity.
>
>  And you know what else? If miners need higher fees to accommodate the
> costs of bigger blocks, they can configure their nodes to only mine
> transactions with higher fees.. Let the miners decide how to charge enough
> to pay for their costs. We don't need to cripple the network just for them.
>
>  --
> *James G. Phillips IV*
> <https://plus.google.com/u/0/113107039501292625391/posts>
>
> *"Don't bunt. Aim out of the ball park. Aim for the company of immortals."
> -- David Ogilvy *
>
>   *This message was created with 100% recycled electrons. Please think
> twice before printing.*
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150526/40d01923/attachment.html>

From jim at ergophobia.org  Tue May 26 03:23:35 2015
From: jim at ergophobia.org (Jim Phillips)
Date: Mon, 25 May 2015 22:23:35 -0500
Subject: [Bitcoin-development] No Bitcoin For You
In-Reply-To: <BAY403-EAS63EE0AAE718842E0E3EFD6C2CC0@phx.gbl>
References: <BAY403-EAS63EE0AAE718842E0E3EFD6C2CC0@phx.gbl>
Message-ID: <CANe1mWw-yJv=1_aLc+T8Mq1XgUv8VeDxHee-hVzQNH0hFs1ryg@mail.gmail.com>

I don't see how the fact that my 2Mbps connection causes me to not be a
very good relay has any bearing on whether or not the network as a whole
would be negatively impacted by a 20MB block. My inability to rapidly
propagate blocks doesn't really harm the network. It's only if MOST relays
are as slow as mine that it creates an issue. I'm one node in thousands
(potentially tens or hundreds of thousands if/when Bitcoin goes
mainstream). And I'm an individual. There's no reason at all for me to run
a full node from my home, except to have my own trusted and validated copy
of the blockchain on a computer I control directly. I don't need to act as
a relay for that and as long as I can download blocks faster than they are
created I'm fine. Also, I can easily afford a VPS server or several to run
full nodes as relays if I am feeling altruistic. It's actually cheaper for
me to lease a VPS than to keep my own home PC on 24/7, which is why I have
2 of them.

And as a business, the cost of a server and bandwidth to run a full node is
a drop in the bucket. I'm involved in several projects where we have full
nodes running on leased servers with multiple 1Gbps connections. It's an
almost zero cost. Those nodes could handle 20MB blocks today without
thinking about it, and I'm sure our nodes are just a few amongst thousands
just like them. I'm not at all concerned about the network being too
centralized.

What concerns me is the fact that we are using edge cases like my home PC
as a lame excuse to debate expanding the capacity of the network.

--
*James G. Phillips IV*
<https://plus.google.com/u/0/113107039501292625391/posts>
<http://www.linkedin.com/in/ergophobe>

*"Don't bunt. Aim out of the ball park. Aim for the company of immortals."
-- David Ogilvy*

 *This message was created with 100% recycled electrons. Please think twice
before printing.*

On Mon, May 25, 2015 at 10:02 PM, Thy Shizzle <thyshizzle at outlook.com>
wrote:

>  Indeed Jim, your internet connection makes a good reason why I don't
> like 20mb blocks (right now). It would take you well over a minute to
> download the block before you could even relay it on, so much slow down in
> propagation! Yes I do see how decreasing the time to create blocks is a bit
> of a band-aid fix, and to use tge term I've seen mentioned here "kicking
> the can down the road" I agree that this is doing this, however as you say
> bandwidth is our biggest enemy right now and so hopefully by the time we
> exceed the capacity gained by the decrease in block time, we can then look
> to bump up block size because hopefully 20mbps connections will be baseline
> by then etc.
>  ------------------------------
> From: Jim Phillips <jim at ergophobia.org>
> Sent: ?26/?05/?2015 12:53 PM
> To: Thy Shizzle <thyshizzle at outlook.com>
> Cc: Mike Hearn <mike at plan99.net>; Bitcoin Dev
> <bitcoin-development at lists.sourceforge.net>
>
> Subject: Re: [Bitcoin-development] No Bitcoin For You
>
>  Frankly I'm good with either way. I'm definitely in favor of faster
> confirmation times.
>
>  The important thing is that we need to increase the amount of
> transactions that get into blocks over a given time frame to a point that
> is in line with what current technology can handle. We can handle WAY more
> than we are doing right now. The Bitcoin network is not currently Disk,
> CPU, or RAM bound.. Not even close. The metric we're closest to being
> restricted by would be Network bandwidth. I live in a developing country.
> 2Mbps is a typical broadband speed here (although 5Mbps and 10Mbps
> connections are affordable). That equates to about 17MB per minute, or 170x
> more capacity than what I need to receive a full copy of the blockchain if
> I only talk to one peer. If I relay to say 10 peers, I can still handle 17x
> larger block sizes on a slow 2Mbps connection.
>
>  Also, even if we reduce the difficulty so that we're doing 1MB blocks
> every minute, that's still only 10MB every 10 minutes. Eventually we're
> going to have to increase that, and we can only reduce the confirmation
> period so much. I think someone once said 30 seconds or so is about the
> shortest period you can practically achieve.
>
>  --
> *James G. Phillips IV*
> <https://plus.google.com/u/0/113107039501292625391/posts>
> <http://www.linkedin.com/in/ergophobe>
>
> *"Don't bunt. Aim out of the ball park. Aim for the company of immortals."
> -- David Ogilvy *
>
>   *This message was created with 100% recycled electrons. Please think
> twice before printing.*
>
> On Mon, May 25, 2015 at 9:30 PM, Thy Shizzle <thyshizzle at outlook.com>
> wrote:
>
>  Nah don't make blocks 20mb, then you are slowing down block propagation
> and blowing out conf tikes as a result. Just decrease the time it takes to
> make a 1mb block, then you still see the same propagation times today and
> just increase the transaction throughput.
>  ------------------------------
> From: Jim Phillips <jim at ergophobia.org>
> Sent: ?26/?05/?2015 12:27 PM
> To: Mike Hearn <mike at plan99.net>
> Cc: Bitcoin Dev <bitcoin-development at lists.sourceforge.net>
> Subject: Re: [Bitcoin-development] No Bitcoin For You
>
>
> On Mon, May 25, 2015 at 1:36 PM, Mike Hearn <mike at plan99.net> wrote:
>
>   This meme about datacenter-sized nodes has to die. The Bitcoin wiki is
> down right now, but I showed years ago that you could keep up with VISA on
> a single well specced server with today's technology. Only people living in
> a dreamworld think that Bitcoin might actually have to match that level of
> transaction demand with today's hardware. As noted previously, "too many
> users" is simply not a problem Bitcoin has .... and may never have!
>
>
>  ... And will certainly NEVER have if we can't solve the capacity problem
> SOON.
>
>  In a former life, I was a capacity planner for Bank of America's
> mid-range server group. We had one hard and fast rule. When you are
> typically exceeding 75% of capacity on a given metric, it's time to expand
> capacity. Period. You don't do silly things like adjusting the business
> model to disincentivize use. Unless there's some flaw in the system and
> it's leaking resources, if usage has increased to the point where you are
> at or near the limits of capacity, you expand capacity. It's as simple as
> that, and I've found that same rule fits quite well in a number of systems.
>
>  In Bitcoin, we're not leaking resources. There's no flaw. The system is
> performing as intended. Usage is increasing because it works so well, and
> there is huge potential for future growth as we identify more uses and
> attract more users. There might be a few technical things we can do to
> reduce consumption, but the metric we're concerned with right now is how
> many transactions we can fit in a block. We've broken through the 75%
> marker and are regularly bumping up against the 100% limit.
>
>  It is time to stop debating this and take action to expand capacity. The
> only questions that should remain are how much capacity do we add, and how
> soon can we do it. Given that most existing computer systems and networks
> can easily handle 20MB blocks every 10 minutes, and given that that will
> increase capacity 20-fold, I can't think of a single reason why we can't go
> to 20MB as soon as humanly possible. And in a few years, when the average
> block size is over 15MB, we bump it up again to as high as we can go then
> without pushing typical computers or networks beyond their capacity. We can
> worry about ways to slow down growth without affecting the usefulness of
> Bitcoin as we get closer to the hard technical limits on our capacity.
>
>  And you know what else? If miners need higher fees to accommodate the
> costs of bigger blocks, they can configure their nodes to only mine
> transactions with higher fees.. Let the miners decide how to charge enough
> to pay for their costs. We don't need to cripple the network just for them.
>
>  --
> *James G. Phillips IV*
> <https://plus.google.com/u/0/113107039501292625391/posts>
>
> *"Don't bunt. Aim out of the ball park. Aim for the company of immortals."
> -- David Ogilvy *
>
>   *This message was created with 100% recycled electrons. Please think
> twice before printing.*
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150525/5c6d4699/attachment.html>

From jim at ergophobia.org  Tue May 26 03:49:04 2015
From: jim at ergophobia.org (Jim Phillips)
Date: Mon, 25 May 2015 22:49:04 -0500
Subject: [Bitcoin-development] No Bitcoin For You
In-Reply-To: <CANe1mWw-yJv=1_aLc+T8Mq1XgUv8VeDxHee-hVzQNH0hFs1ryg@mail.gmail.com>
References: <BAY403-EAS63EE0AAE718842E0E3EFD6C2CC0@phx.gbl>
	<CANe1mWw-yJv=1_aLc+T8Mq1XgUv8VeDxHee-hVzQNH0hFs1ryg@mail.gmail.com>
Message-ID: <CANe1mWw2os6GUbRiyegn=Z+2ZM_J8x76rD4uh_0C3z+ix8aK+A@mail.gmail.com>

Incidentally, even once we have the "Internet of Things" brought on by 21,
Inc. or whoever beats them to it, I would expect the average home to have
only a single full node "hub" receiving the blockchain and broadcasting
transactions created by all the minor SPV connected devices running within
the house. The in-home full node would be peered with high bandwidth
full-node relays running at the ISP or in the cloud. There are more than
enough ISPs and cloud compute providers in the world such that there should
be no concern at all about centralization of relays. Full nodes could some
day become as ubiquitous on the Internet as authoritative DNS servers. And
just like DNS servers, if you don't trust the nodes your ISP creates or
it's too slow or censors transactions, there's nothing preventing you from
peering with nodes hosted by the Googles or OpenDNSs out there, or running
your own if you're really paranoid and have a few extra bucks for a VPS.

--
*James G. Phillips IV*
<https://plus.google.com/u/0/113107039501292625391/posts>
<http://www.linkedin.com/in/ergophobe>

*"Don't bunt. Aim out of the ball park. Aim for the company of immortals."
-- David Ogilvy*

 *This message was created with 100% recycled electrons. Please think twice
before printing.*

On Mon, May 25, 2015 at 10:23 PM, Jim Phillips <jim at ergophobia.org> wrote:

> I don't see how the fact that my 2Mbps connection causes me to not be a
> very good relay has any bearing on whether or not the network as a whole
> would be negatively impacted by a 20MB block. My inability to rapidly
> propagate blocks doesn't really harm the network. It's only if MOST relays
> are as slow as mine that it creates an issue. I'm one node in thousands
> (potentially tens or hundreds of thousands if/when Bitcoin goes
> mainstream). And I'm an individual. There's no reason at all for me to run
> a full node from my home, except to have my own trusted and validated copy
> of the blockchain on a computer I control directly. I don't need to act as
> a relay for that and as long as I can download blocks faster than they are
> created I'm fine. Also, I can easily afford a VPS server or several to run
> full nodes as relays if I am feeling altruistic. It's actually cheaper for
> me to lease a VPS than to keep my own home PC on 24/7, which is why I have
> 2 of them.
>
> And as a business, the cost of a server and bandwidth to run a full node
> is a drop in the bucket. I'm involved in several projects where we have
> full nodes running on leased servers with multiple 1Gbps connections. It's
> an almost zero cost. Those nodes could handle 20MB blocks today without
> thinking about it, and I'm sure our nodes are just a few amongst thousands
> just like them. I'm not at all concerned about the network being too
> centralized.
>
> What concerns me is the fact that we are using edge cases like my home PC
> as a lame excuse to debate expanding the capacity of the network.
>
> --
> *James G. Phillips IV*
> <https://plus.google.com/u/0/113107039501292625391/posts>
> <http://www.linkedin.com/in/ergophobe>
>
> *"Don't bunt. Aim out of the ball park. Aim for the company of immortals."
> -- David Ogilvy*
>
>  *This message was created with 100% recycled electrons. Please think
> twice before printing.*
>
> On Mon, May 25, 2015 at 10:02 PM, Thy Shizzle <thyshizzle at outlook.com>
> wrote:
>
>>  Indeed Jim, your internet connection makes a good reason why I don't
>> like 20mb blocks (right now). It would take you well over a minute to
>> download the block before you could even relay it on, so much slow down in
>> propagation! Yes I do see how decreasing the time to create blocks is a bit
>> of a band-aid fix, and to use tge term I've seen mentioned here "kicking
>> the can down the road" I agree that this is doing this, however as you say
>> bandwidth is our biggest enemy right now and so hopefully by the time we
>> exceed the capacity gained by the decrease in block time, we can then look
>> to bump up block size because hopefully 20mbps connections will be baseline
>> by then etc.
>>  ------------------------------
>> From: Jim Phillips <jim at ergophobia.org>
>> Sent: ?26/?05/?2015 12:53 PM
>> To: Thy Shizzle <thyshizzle at outlook.com>
>> Cc: Mike Hearn <mike at plan99.net>; Bitcoin Dev
>> <bitcoin-development at lists.sourceforge.net>
>>
>> Subject: Re: [Bitcoin-development] No Bitcoin For You
>>
>>  Frankly I'm good with either way. I'm definitely in favor of faster
>> confirmation times.
>>
>>  The important thing is that we need to increase the amount of
>> transactions that get into blocks over a given time frame to a point that
>> is in line with what current technology can handle. We can handle WAY more
>> than we are doing right now. The Bitcoin network is not currently Disk,
>> CPU, or RAM bound.. Not even close. The metric we're closest to being
>> restricted by would be Network bandwidth. I live in a developing country.
>> 2Mbps is a typical broadband speed here (although 5Mbps and 10Mbps
>> connections are affordable). That equates to about 17MB per minute, or 170x
>> more capacity than what I need to receive a full copy of the blockchain if
>> I only talk to one peer. If I relay to say 10 peers, I can still handle 17x
>> larger block sizes on a slow 2Mbps connection.
>>
>>  Also, even if we reduce the difficulty so that we're doing 1MB blocks
>> every minute, that's still only 10MB every 10 minutes. Eventually we're
>> going to have to increase that, and we can only reduce the confirmation
>> period so much. I think someone once said 30 seconds or so is about the
>> shortest period you can practically achieve.
>>
>>  --
>> *James G. Phillips IV*
>> <https://plus.google.com/u/0/113107039501292625391/posts>
>> <http://www.linkedin.com/in/ergophobe>
>>
>> *"Don't bunt. Aim out of the ball park. Aim for the company of
>> immortals." -- David Ogilvy *
>>
>>   *This message was created with 100% recycled electrons. Please think
>> twice before printing.*
>>
>> On Mon, May 25, 2015 at 9:30 PM, Thy Shizzle <thyshizzle at outlook.com>
>> wrote:
>>
>>  Nah don't make blocks 20mb, then you are slowing down block propagation
>> and blowing out conf tikes as a result. Just decrease the time it takes to
>> make a 1mb block, then you still see the same propagation times today and
>> just increase the transaction throughput.
>>  ------------------------------
>> From: Jim Phillips <jim at ergophobia.org>
>> Sent: ?26/?05/?2015 12:27 PM
>> To: Mike Hearn <mike at plan99.net>
>> Cc: Bitcoin Dev <bitcoin-development at lists.sourceforge.net>
>> Subject: Re: [Bitcoin-development] No Bitcoin For You
>>
>>
>> On Mon, May 25, 2015 at 1:36 PM, Mike Hearn <mike at plan99.net> wrote:
>>
>>   This meme about datacenter-sized nodes has to die. The Bitcoin wiki is
>> down right now, but I showed years ago that you could keep up with VISA on
>> a single well specced server with today's technology. Only people living in
>> a dreamworld think that Bitcoin might actually have to match that level of
>> transaction demand with today's hardware. As noted previously, "too many
>> users" is simply not a problem Bitcoin has .... and may never have!
>>
>>
>>  ... And will certainly NEVER have if we can't solve the capacity
>> problem SOON.
>>
>>  In a former life, I was a capacity planner for Bank of America's
>> mid-range server group. We had one hard and fast rule. When you are
>> typically exceeding 75% of capacity on a given metric, it's time to expand
>> capacity. Period. You don't do silly things like adjusting the business
>> model to disincentivize use. Unless there's some flaw in the system and
>> it's leaking resources, if usage has increased to the point where you are
>> at or near the limits of capacity, you expand capacity. It's as simple as
>> that, and I've found that same rule fits quite well in a number of systems.
>>
>>  In Bitcoin, we're not leaking resources. There's no flaw. The system is
>> performing as intended. Usage is increasing because it works so well, and
>> there is huge potential for future growth as we identify more uses and
>> attract more users. There might be a few technical things we can do to
>> reduce consumption, but the metric we're concerned with right now is how
>> many transactions we can fit in a block. We've broken through the 75%
>> marker and are regularly bumping up against the 100% limit.
>>
>>  It is time to stop debating this and take action to expand capacity.
>> The only questions that should remain are how much capacity do we add, and
>> how soon can we do it. Given that most existing computer systems and
>> networks can easily handle 20MB blocks every 10 minutes, and given that
>> that will increase capacity 20-fold, I can't think of a single reason why
>> we can't go to 20MB as soon as humanly possible. And in a few years, when
>> the average block size is over 15MB, we bump it up again to as high as we
>> can go then without pushing typical computers or networks beyond their
>> capacity. We can worry about ways to slow down growth without affecting the
>> usefulness of Bitcoin as we get closer to the hard technical limits on our
>> capacity.
>>
>>  And you know what else? If miners need higher fees to accommodate the
>> costs of bigger blocks, they can configure their nodes to only mine
>> transactions with higher fees.. Let the miners decide how to charge enough
>> to pay for their costs. We don't need to cripple the network just for them.
>>
>>  --
>> *James G. Phillips IV*
>> <https://plus.google.com/u/0/113107039501292625391/posts>
>>
>> *"Don't bunt. Aim out of the ball park. Aim for the company of
>> immortals." -- David Ogilvy *
>>
>>   *This message was created with 100% recycled electrons. Please think
>> twice before printing.*
>>
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150525/96ec3c6b/attachment.html>

From jim at ergophobia.org  Tue May 26 04:06:38 2015
From: jim at ergophobia.org (Jim Phillips)
Date: Mon, 25 May 2015 23:06:38 -0500
Subject: [Bitcoin-development] Zero-Conf for Full Node Discovery
Message-ID: <CANe1mWwi+fxFU43_2mq-yd_qRsmCwMu_c5wWOpvFS4Un_FoT+Q@mail.gmail.com>

Is there any work being done on using some kind of zero-conf service
discovery protocol so that lightweight clients can find a full node on the
same LAN to peer with rather than having to tie up WAN bandwidth?

I envision a future where lightweight devices within a home use SPV over
WiFi to connect with a home server which in turn relays the transactions
they create out to the larger and faster relays on the Internet.

In a situation where there are hundreds or thousands of small SPV devices
in a single home (if 21, Inc. is successful) monitoring the blockchain,
this could result in lower traffic across the slow WAN connection.  And
yes, I realize it could potentially take a LOT of these devices before the
total bandwidth is greater than downloading a full copy of the blockchain,
but there's other reasons to host your own full node -- trust being one.

--
*James G. Phillips IV*
<https://plus.google.com/u/0/113107039501292625391/posts>
<http://www.linkedin.com/in/ergophobe>

*"Don't bunt. Aim out of the ball park. Aim for the company of immortals."
-- David Ogilvy*

 *This message was created with 100% recycled electrons. Please think twice
before printing.*
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150525/1f012536/attachment.html>

From bip at mattwhitlock.name  Tue May 26 04:37:18 2015
From: bip at mattwhitlock.name (Matt Whitlock)
Date: Tue, 26 May 2015 00:37:18 -0400
Subject: [Bitcoin-development] Zero-Conf for Full Node Discovery
In-Reply-To: <CANe1mWwi+fxFU43_2mq-yd_qRsmCwMu_c5wWOpvFS4Un_FoT+Q@mail.gmail.com>
References: <CANe1mWwi+fxFU43_2mq-yd_qRsmCwMu_c5wWOpvFS4Un_FoT+Q@mail.gmail.com>
Message-ID: <2916218.tfdjj1Sv9m@crushinator>

This is very simple to do. Just ping the "all nodes" address (ff02::1) and try connecting to TCP port 8333 of each node that responds. Shouldn't take but more than a few milliseconds on any but the most densely populated LANs.


On Monday, 25 May 2015, at 11:06 pm, Jim Phillips wrote:
> Is there any work being done on using some kind of zero-conf service
> discovery protocol so that lightweight clients can find a full node on the
> same LAN to peer with rather than having to tie up WAN bandwidth?
> 
> I envision a future where lightweight devices within a home use SPV over
> WiFi to connect with a home server which in turn relays the transactions
> they create out to the larger and faster relays on the Internet.
> 
> In a situation where there are hundreds or thousands of small SPV devices
> in a single home (if 21, Inc. is successful) monitoring the blockchain,
> this could result in lower traffic across the slow WAN connection.  And
> yes, I realize it could potentially take a LOT of these devices before the
> total bandwidth is greater than downloading a full copy of the blockchain,
> but there's other reasons to host your own full node -- trust being one.
> 
> --
> *James G. Phillips IV*
> <https://plus.google.com/u/0/113107039501292625391/posts>
> <http://www.linkedin.com/in/ergophobe>
> 
> *"Don't bunt. Aim out of the ball park. Aim for the company of immortals."
> -- David Ogilvy*
> 
>  *This message was created with 100% recycled electrons. Please think twice
> before printing.*



From kgreenek at gmail.com  Tue May 26 04:46:22 2015
From: kgreenek at gmail.com (Kevin Greene)
Date: Mon, 25 May 2015 21:46:22 -0700
Subject: [Bitcoin-development] Zero-Conf for Full Node Discovery
In-Reply-To: <2916218.tfdjj1Sv9m@crushinator>
References: <CANe1mWwi+fxFU43_2mq-yd_qRsmCwMu_c5wWOpvFS4Un_FoT+Q@mail.gmail.com>
	<2916218.tfdjj1Sv9m@crushinator>
Message-ID: <CAEY8wq40vyG8CFZ7U1Z3hhF_ziSqEQ3GDpXLwm1MAVtK03aT-A@mail.gmail.com>

This is something you actually don't want. In order to make it as difficult
as possible for an attacker to perform a sybil attack, you want to choose a
set of peers that is as diverse, and unpredictable as possible.


On Mon, May 25, 2015 at 9:37 PM, Matt Whitlock <bip at mattwhitlock.name>
wrote:

> This is very simple to do. Just ping the "all nodes" address (ff02::1) and
> try connecting to TCP port 8333 of each node that responds. Shouldn't take
> but more than a few milliseconds on any but the most densely populated LANs.
>
>
> On Monday, 25 May 2015, at 11:06 pm, Jim Phillips wrote:
> > Is there any work being done on using some kind of zero-conf service
> > discovery protocol so that lightweight clients can find a full node on
> the
> > same LAN to peer with rather than having to tie up WAN bandwidth?
> >
> > I envision a future where lightweight devices within a home use SPV over
> > WiFi to connect with a home server which in turn relays the transactions
> > they create out to the larger and faster relays on the Internet.
> >
> > In a situation where there are hundreds or thousands of small SPV devices
> > in a single home (if 21, Inc. is successful) monitoring the blockchain,
> > this could result in lower traffic across the slow WAN connection.  And
> > yes, I realize it could potentially take a LOT of these devices before
> the
> > total bandwidth is greater than downloading a full copy of the
> blockchain,
> > but there's other reasons to host your own full node -- trust being one.
> >
> > --
> > *James G. Phillips IV*
> > <https://plus.google.com/u/0/113107039501292625391/posts>
> > <http://www.linkedin.com/in/ergophobe>
> >
> > *"Don't bunt. Aim out of the ball park. Aim for the company of
> immortals."
> > -- David Ogilvy*
> >
> >  *This message was created with 100% recycled electrons. Please think
> twice
> > before printing.*
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150525/1324d033/attachment.html>

From jim at ergophobia.org  Tue May 26 04:48:16 2015
From: jim at ergophobia.org (Jim Phillips)
Date: Mon, 25 May 2015 23:48:16 -0500
Subject: [Bitcoin-development] Zero-Conf for Full Node Discovery
In-Reply-To: <2916218.tfdjj1Sv9m@crushinator>
References: <CANe1mWwi+fxFU43_2mq-yd_qRsmCwMu_c5wWOpvFS4Un_FoT+Q@mail.gmail.com>
	<2916218.tfdjj1Sv9m@crushinator>
Message-ID: <CANe1mWzeLsOWv+2qwx1b3s61HqCwy5GLd2Rv3LgWLrOa_jkFjw@mail.gmail.com>

Do any wallets actually do this yet?
On May 25, 2015 11:37 PM, "Matt Whitlock" <bip at mattwhitlock.name> wrote:

> This is very simple to do. Just ping the "all nodes" address (ff02::1) and
> try connecting to TCP port 8333 of each node that responds. Shouldn't take
> but more than a few milliseconds on any but the most densely populated LANs.
>
>
> On Monday, 25 May 2015, at 11:06 pm, Jim Phillips wrote:
> > Is there any work being done on using some kind of zero-conf service
> > discovery protocol so that lightweight clients can find a full node on
> the
> > same LAN to peer with rather than having to tie up WAN bandwidth?
> >
> > I envision a future where lightweight devices within a home use SPV over
> > WiFi to connect with a home server which in turn relays the transactions
> > they create out to the larger and faster relays on the Internet.
> >
> > In a situation where there are hundreds or thousands of small SPV devices
> > in a single home (if 21, Inc. is successful) monitoring the blockchain,
> > this could result in lower traffic across the slow WAN connection.  And
> > yes, I realize it could potentially take a LOT of these devices before
> the
> > total bandwidth is greater than downloading a full copy of the
> blockchain,
> > but there's other reasons to host your own full node -- trust being one.
> >
> > --
> > *James G. Phillips IV*
> > <https://plus.google.com/u/0/113107039501292625391/posts>
> > <http://www.linkedin.com/in/ergophobe>
> >
> > *"Don't bunt. Aim out of the ball park. Aim for the company of
> immortals."
> > -- David Ogilvy*
> >
> >  *This message was created with 100% recycled electrons. Please think
> twice
> > before printing.*
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150525/a9d0482b/attachment.html>

From bip at mattwhitlock.name  Tue May 26 04:52:07 2015
From: bip at mattwhitlock.name (Matt Whitlock)
Date: Tue, 26 May 2015 00:52:07 -0400
Subject: [Bitcoin-development] Zero-Conf for Full Node Discovery
In-Reply-To: <CANe1mWzeLsOWv+2qwx1b3s61HqCwy5GLd2Rv3LgWLrOa_jkFjw@mail.gmail.com>
References: <CANe1mWwi+fxFU43_2mq-yd_qRsmCwMu_c5wWOpvFS4Un_FoT+Q@mail.gmail.com>
	<2916218.tfdjj1Sv9m@crushinator>
	<CANe1mWzeLsOWv+2qwx1b3s61HqCwy5GLd2Rv3LgWLrOa_jkFjw@mail.gmail.com>
Message-ID: <23111107.dfGN69SrR9@crushinator>

On Monday, 25 May 2015, at 11:48 pm, Jim Phillips wrote:
> Do any wallets actually do this yet?

Not that I know of, but they do seed their address database via DNS, which you can poison if you control the LAN's DNS resolver. I did this for a Bitcoin-only Wi-Fi network I operated at a remote festival. We had well over a hundred lightweight wallets, all trying to connect to the Bitcoin P2P network over a very bandwidth-constrained Internet link, so I poisoned the DNS and rejected all outbound connection attempts on port 8333, to force all the wallets to connect to a single local full node, which had connectivity to a single remote node over the Internet. Thus, all the lightweight wallets at the festival had Bitcoin network connectivity, but we only needed to backhaul the Bitcoin network's transaction traffic once.



> On May 25, 2015 11:37 PM, "Matt Whitlock" <bip at mattwhitlock.name> wrote:
> 
> > This is very simple to do. Just ping the "all nodes" address (ff02::1) and
> > try connecting to TCP port 8333 of each node that responds. Shouldn't take
> > but more than a few milliseconds on any but the most densely populated LANs.
> >
> >
> > On Monday, 25 May 2015, at 11:06 pm, Jim Phillips wrote:
> > > Is there any work being done on using some kind of zero-conf service
> > > discovery protocol so that lightweight clients can find a full node on
> > the
> > > same LAN to peer with rather than having to tie up WAN bandwidth?
> > >
> > > I envision a future where lightweight devices within a home use SPV over
> > > WiFi to connect with a home server which in turn relays the transactions
> > > they create out to the larger and faster relays on the Internet.
> > >
> > > In a situation where there are hundreds or thousands of small SPV devices
> > > in a single home (if 21, Inc. is successful) monitoring the blockchain,
> > > this could result in lower traffic across the slow WAN connection.  And
> > > yes, I realize it could potentially take a LOT of these devices before
> > the
> > > total bandwidth is greater than downloading a full copy of the
> > blockchain,
> > > but there's other reasons to host your own full node -- trust being one.
> > >
> > > --
> > > *James G. Phillips IV*
> > > <https://plus.google.com/u/0/113107039501292625391/posts>
> > > <http://www.linkedin.com/in/ergophobe>
> > >
> > > *"Don't bunt. Aim out of the ball park. Aim for the company of
> > immortals."
> > > -- David Ogilvy*
> > >
> > >  *This message was created with 100% recycled electrons. Please think
> > twice
> > > before printing.*
> >



From bip at mattwhitlock.name  Tue May 26 04:56:28 2015
From: bip at mattwhitlock.name (Matt Whitlock)
Date: Tue, 26 May 2015 00:56:28 -0400
Subject: [Bitcoin-development] Zero-Conf for Full Node Discovery
In-Reply-To: <CAEY8wq40vyG8CFZ7U1Z3hhF_ziSqEQ3GDpXLwm1MAVtK03aT-A@mail.gmail.com>
References: <CANe1mWwi+fxFU43_2mq-yd_qRsmCwMu_c5wWOpvFS4Un_FoT+Q@mail.gmail.com>
	<2916218.tfdjj1Sv9m@crushinator>
	<CAEY8wq40vyG8CFZ7U1Z3hhF_ziSqEQ3GDpXLwm1MAVtK03aT-A@mail.gmail.com>
Message-ID: <2508972.mm4E72Fj6S@crushinator>

Who would be performing a Sybil attack against themselves? We're talking about a LAN here. All the nodes would be under the control of the same entity. In that case, you actually want them all connecting solely to a central hub node on the LAN, and the hub node should connect to "diverse and unpredictable" other nodes on the Bitcoin network.


On Monday, 25 May 2015, at 9:46 pm, Kevin Greene wrote:
> This is something you actually don't want. In order to make it as difficult
> as possible for an attacker to perform a sybil attack, you want to choose a
> set of peers that is as diverse, and unpredictable as possible.
> 
> 
> On Mon, May 25, 2015 at 9:37 PM, Matt Whitlock <bip at mattwhitlock.name>
> wrote:
> 
> > This is very simple to do. Just ping the "all nodes" address (ff02::1) and
> > try connecting to TCP port 8333 of each node that responds. Shouldn't take
> > but more than a few milliseconds on any but the most densely populated LANs.
> >
> >
> > On Monday, 25 May 2015, at 11:06 pm, Jim Phillips wrote:
> > > Is there any work being done on using some kind of zero-conf service
> > > discovery protocol so that lightweight clients can find a full node on
> > the
> > > same LAN to peer with rather than having to tie up WAN bandwidth?
> > >
> > > I envision a future where lightweight devices within a home use SPV over
> > > WiFi to connect with a home server which in turn relays the transactions
> > > they create out to the larger and faster relays on the Internet.
> > >
> > > In a situation where there are hundreds or thousands of small SPV devices
> > > in a single home (if 21, Inc. is successful) monitoring the blockchain,
> > > this could result in lower traffic across the slow WAN connection.  And
> > > yes, I realize it could potentially take a LOT of these devices before
> > the
> > > total bandwidth is greater than downloading a full copy of the
> > blockchain,
> > > but there's other reasons to host your own full node -- trust being one.
> > >
> > > --
> > > *James G. Phillips IV*
> > > <https://plus.google.com/u/0/113107039501292625391/posts>
> > > <http://www.linkedin.com/in/ergophobe>
> > >
> > > *"Don't bunt. Aim out of the ball park. Aim for the company of
> > immortals."
> > > -- David Ogilvy*
> > >
> > >  *This message was created with 100% recycled electrons. Please think
> > twice
> > > before printing.*
> >
> >
> > ------------------------------------------------------------------------------
> > One dashboard for servers and applications across Physical-Virtual-Cloud
> > Widest out-of-the-box monitoring support with 50+ applications
> > Performance metrics, stats and reports that give you Actionable Insights
> > Deep dive visibility with transaction tracing using APM Insight.
> > http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> > _______________________________________________
> > Bitcoin-development mailing list
> > Bitcoin-development at lists.sourceforge.net
> > https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> >



From kgreenek at gmail.com  Tue May 26 05:12:04 2015
From: kgreenek at gmail.com (Kevin Greene)
Date: Mon, 25 May 2015 22:12:04 -0700
Subject: [Bitcoin-development] Zero-Conf for Full Node Discovery
In-Reply-To: <2508972.mm4E72Fj6S@crushinator>
References: <CANe1mWwi+fxFU43_2mq-yd_qRsmCwMu_c5wWOpvFS4Un_FoT+Q@mail.gmail.com>
	<2916218.tfdjj1Sv9m@crushinator>
	<CAEY8wq40vyG8CFZ7U1Z3hhF_ziSqEQ3GDpXLwm1MAVtK03aT-A@mail.gmail.com>
	<2508972.mm4E72Fj6S@crushinator>
Message-ID: <CAEY8wq4+X3JbgY8Oedz=uuDd7Y8LjqcPYt3vw_LRawEG4aCNHg@mail.gmail.com>

This is true, but the device doesn't know if the LAN it's on is a safe
network or a hotel wifi, for example. So there would be a tricky UX there.
You'd have to ask the user during set up if this is a trusted LAN or not;
or something like that. That may not be an issue though depending on the
nature of the product. For example, Chromecast doesn't need any security
protections against trolls on the same LAN. I guess it just depends on what
you're planning to build.

On Mon, May 25, 2015 at 9:56 PM, Matt Whitlock <bip at mattwhitlock.name>
wrote:

> Who would be performing a Sybil attack against themselves? We're talking
> about a LAN here. All the nodes would be under the control of the same
> entity. In that case, you actually want them all connecting solely to a
> central hub node on the LAN, and the hub node should connect to "diverse
> and unpredictable" other nodes on the Bitcoin network.
>
>
> On Monday, 25 May 2015, at 9:46 pm, Kevin Greene wrote:
> > This is something you actually don't want. In order to make it as
> difficult
> > as possible for an attacker to perform a sybil attack, you want to
> choose a
> > set of peers that is as diverse, and unpredictable as possible.
> >
> >
> > On Mon, May 25, 2015 at 9:37 PM, Matt Whitlock <bip at mattwhitlock.name>
> > wrote:
> >
> > > This is very simple to do. Just ping the "all nodes" address (ff02::1)
> and
> > > try connecting to TCP port 8333 of each node that responds. Shouldn't
> take
> > > but more than a few milliseconds on any but the most densely populated
> LANs.
> > >
> > >
> > > On Monday, 25 May 2015, at 11:06 pm, Jim Phillips wrote:
> > > > Is there any work being done on using some kind of zero-conf service
> > > > discovery protocol so that lightweight clients can find a full node
> on
> > > the
> > > > same LAN to peer with rather than having to tie up WAN bandwidth?
> > > >
> > > > I envision a future where lightweight devices within a home use SPV
> over
> > > > WiFi to connect with a home server which in turn relays the
> transactions
> > > > they create out to the larger and faster relays on the Internet.
> > > >
> > > > In a situation where there are hundreds or thousands of small SPV
> devices
> > > > in a single home (if 21, Inc. is successful) monitoring the
> blockchain,
> > > > this could result in lower traffic across the slow WAN connection.
> And
> > > > yes, I realize it could potentially take a LOT of these devices
> before
> > > the
> > > > total bandwidth is greater than downloading a full copy of the
> > > blockchain,
> > > > but there's other reasons to host your own full node -- trust being
> one.
> > > >
> > > > --
> > > > *James G. Phillips IV*
> > > > <https://plus.google.com/u/0/113107039501292625391/posts>
> > > > <http://www.linkedin.com/in/ergophobe>
> > > >
> > > > *"Don't bunt. Aim out of the ball park. Aim for the company of
> > > immortals."
> > > > -- David Ogilvy*
> > > >
> > > >  *This message was created with 100% recycled electrons. Please think
> > > twice
> > > > before printing.*
> > >
> > >
> > >
> ------------------------------------------------------------------------------
> > > One dashboard for servers and applications across
> Physical-Virtual-Cloud
> > > Widest out-of-the-box monitoring support with 50+ applications
> > > Performance metrics, stats and reports that give you Actionable
> Insights
> > > Deep dive visibility with transaction tracing using APM Insight.
> > > http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> > > _______________________________________________
> > > Bitcoin-development mailing list
> > > Bitcoin-development at lists.sourceforge.net
> > > https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> > >
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150525/05bd344b/attachment.html>

From pete at petertodd.org  Tue May 26 05:13:05 2015
From: pete at petertodd.org (Peter Todd)
Date: Tue, 26 May 2015 01:13:05 -0400
Subject: [Bitcoin-development] First-Seen-Safe Replace-by-Fee
Message-ID: <20150526051305.GA23502@savin.petertodd.org>

Summary
-------

First-seen-safe replace-by-fee (FSS RBF) does the following:

1) Give users effective ways of getting "stuck" transactions unstuck.
2) Use blockchain space efficiently.

without:

3) Changing the status quo with regard to zeroconf.

The current Bitcoin Core implementation has "first-seen" mempool
behavior. Once transaction t1 has been accepted, the transaction is
never removed from the mempool until mined, or double-spent by a
transaction in a block. The author's previously proposed replace-by-fee
replaced this behavior with simply accepting the transaction paying the
highest fee.

FSS RBF is a compromise between these two behaviors. Transactions may be
replaced by higher-fee paying transactions, provided that all outputs in
the previous transaction are still paid by the replacement. While not as
general as standard RBF, and with higher costs than standard RBF, this
still allows fees on transaction to be increased after the fact with
less cost and higher efficiency than child-pays-for-parent in many
common situations; in some situations CPFP is unusable, leaving RBF as
the only option.


Semantics
---------

For reference, standard replace-by-fee has the following criteria for
determining whether to replace a transaction.

1) t2 pays > fees than t1

2) The delta fees pay by t2, t2.fee - t1.fee, are >= the minimum fee
   required to relay t2. (t2.size * min_fee_per_kb)

3) t2 pays more fees/kb than t1

FSS RBF adds the following additional criteria to replace-by-fee before
allowing a transaction t1 to be replaced with t2:

1) All outputs of t1 exist in t2 and pay >= the value in t1.

2) All outputs of t1 are unspent.

3) The order of outputs in t2 is the same as in t1 with additional new
   outputs at the end of the output list.

4) t2 only conflicts with a single transaction, t1

5) t2 does not spend any outputs of t1 (which would make it an invalid
   transaction, impossible to mine)

These additional criteria respect the existing "first-seen" behavior of
the Bitcoin Core mempool implementation, such that once an address is
payed some amount of BTC, all subsequent replacement transactions will
pay an equal or greater amount. In short, FSS-RBF is "zeroconf safe" and
has no affect on the ability of attackers to doublespend. (beyond of
course the fact that any changes what-so-ever to mempool behavior are
potential zeroconf doublespend vulnerabilities)


Implementation
--------------

Pull-req for git HEAD: https://github.com/bitcoin/bitcoin/pull/6176

A backport to v0.10.2 is pending.

An implementation of fee bumping respecting FSS rules is available at:

https://github.com/petertodd/replace-by-fee-tools/blob/master/bump-fee.py


Usage Scenarios
---------------

Case 1: Increasing the fee on a single tx
-----------------------------------------

We start with a 1-in-2-out P2PKH using transaction t1, 226 bytes in size
with the minimal relay fee, 2.26uBTC. Increasing the fee while
respecting FSS-RBF rules requires the addition of one more txin, with
the change output value increased appropriately, resulting in
transaction t2, size 374 bytes. If the change txout is sufficient for
the fee increase, increasing the fee via CPFP requires a second
1-in-1-out transaction, 192 bytes, for a total of 418 bytes; if another
input is required, CPFP requires a 2-in-1-out tx, 340 bytes, for a total
of 566 bytes.

Benefits: 11% to 34%+ cost savings, and RBF can increase fees even in
          cases where the original transaction didn't have a change
          output.


Case 2: Paying multiple recipients in succession
------------------------------------------------

We have a 1-in-2-out P2PKH transaction t1, 226 bytes, that pays Alice.
We now need to pay Bob. With plain RBF we'd just add a new outptu and
reduce the value of the change address, a 90% savings. However with FSS
RBF, decreasing the value is not allowed, so we have to add an input.

If the change of t1 is sufficient to pay Bob, a second 1-in-2-out tx can
be created, 2*226=452 bytes in total. With FSS RBF we can replace t1
with a 2-in-3-out tx paying both, increasing the value of the change
output appropriately, resulting in 408 bytes transaction saving 10%

Similar to the above example in the case where the change address of t1
is insufficient to pay Bob the end result is one less transaction output
in the wallet, defragmenting it. Spending these outputs later on would
require two 148 byte inputs compared to one with RBF, resulting in an
overall savings of 25%


Case 3: Paying the same recipient multiple times
------------------------------------------------

For example, consider the situation of an exchange, Acme Bitcoin Sales,
that keeps the majority of coins in cold storage. Acme wants to move
funds to cold storage at the lowest possible cost, taking advantage of
periods of higher capacity. (inevitable due to the poisson nature of
block creation) At the same time they would like to defragment their
incoming outputs to keep redemption costs low, particularly since
spending their high-security 3-of-7 P2SH multisigs is expensive. Acme
creates a low fee transaction with a single output to cold storage,
periodically adding new inputs as funds need to be moved to storage.
Estimating the cost savings here is complex, and depends greatly on
details of Acme's business, but regardless the approach works from a
technical point of view. For instance if Acme's business is such that
the total hotwallet size needed heavily depends on external factors like
volatility, as hotwallet demand decreases throughout a day they can add
inputs to the pending transaction. (simply asking customers to deposit
funds directly to the cold storage is also a useful strategy)

However this is another case where standard RBF is significantly more
useful. For instance, as withdrawal requests come in the exchange can
quickly replace their pending transactions sending funds to cold storage
with transactions sending those funds to customers instead, each time
avoiding multiple costly transactions. In particular, by reducing the
need to access cold storage at all, the security of the cold-stored
funds is increased.


Wallet Compatibility
--------------------

All wallets should treat conflicting incoming transactions as equivalent
so long as the transaction outputs owned by them do not change. In
addition to compatibility with RBF-related practices, this prevents
unnecessary user concern if transactions are mutated. Wallets must not
assume TXIDs are fixed until confirmed in the blockchain; a fixed TXID
is not guaranteed by the Bitcoin protocol.

-- 
'peter'[:-1]@petertodd.org
00000000000000000c7ea0fcac58a9d7267fef8551b9d6a5206bf42b849618cb
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150526/e5647cbe/attachment.sig>

From pete at petertodd.org  Tue May 26 05:15:46 2015
From: pete at petertodd.org (Peter Todd)
Date: Tue, 26 May 2015 01:15:46 -0400
Subject: [Bitcoin-development] Zero-Conf for Full Node Discovery
In-Reply-To: <23111107.dfGN69SrR9@crushinator>
References: <CANe1mWwi+fxFU43_2mq-yd_qRsmCwMu_c5wWOpvFS4Un_FoT+Q@mail.gmail.com>
	<2916218.tfdjj1Sv9m@crushinator>
	<CANe1mWzeLsOWv+2qwx1b3s61HqCwy5GLd2Rv3LgWLrOa_jkFjw@mail.gmail.com>
	<23111107.dfGN69SrR9@crushinator>
Message-ID: <20150526051546.GB23502@savin.petertodd.org>

On Tue, May 26, 2015 at 12:52:07AM -0400, Matt Whitlock wrote:
> On Monday, 25 May 2015, at 11:48 pm, Jim Phillips wrote:
> > Do any wallets actually do this yet?
> 
> Not that I know of, but they do seed their address database via DNS, which you can poison if you control the LAN's DNS resolver. I did this for a Bitcoin-only Wi-Fi network I operated at a remote festival. We had well over a hundred lightweight wallets, all trying to connect to the Bitcoin P2P network over a very bandwidth-constrained Internet link, so I poisoned the DNS and rejected all outbound connection attempts on port 8333, to force all the wallets to connect to a single local full node, which had connectivity to a single remote node over the Internet. Thus, all the lightweight wallets at the festival had Bitcoin network connectivity, but we only needed to backhaul the Bitcoin network's transaction traffic once.

Interesting!

What festival was this?

-- 
'peter'[:-1]@petertodd.org
000000000000000003ce9f2f90736ab7bd24d29f40346057f9e217b3753896bb
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150526/bf034861/attachment.sig>

From luke at dashjr.org  Tue May 26 05:23:04 2015
From: luke at dashjr.org (Luke Dashjr)
Date: Tue, 26 May 2015 05:23:04 +0000
Subject: [Bitcoin-development] Zero-Conf for Full Node Discovery
In-Reply-To: <CAEY8wq40vyG8CFZ7U1Z3hhF_ziSqEQ3GDpXLwm1MAVtK03aT-A@mail.gmail.com>
References: <CANe1mWwi+fxFU43_2mq-yd_qRsmCwMu_c5wWOpvFS4Un_FoT+Q@mail.gmail.com>
	<2916218.tfdjj1Sv9m@crushinator>
	<CAEY8wq40vyG8CFZ7U1Z3hhF_ziSqEQ3GDpXLwm1MAVtK03aT-A@mail.gmail.com>
Message-ID: <201505260523.05104.luke@dashjr.org>

On Tuesday, May 26, 2015 4:46:22 AM Kevin Greene wrote:
> This is something you actually don't want. In order to make it as difficult
> as possible for an attacker to perform a sybil attack, you want to choose a
> set of peers that is as diverse, and unpredictable as possible.

It doesn't hurt to have a local node or two, though. Might as well to improve 
propagation, while maintaining the other peers to avoid sybil attacks.

Luke



From gappleto97 at gmail.com  Tue May 26 05:43:17 2015
From: gappleto97 at gmail.com (gabe appleton)
Date: Tue, 26 May 2015 01:43:17 -0400
Subject: [Bitcoin-development] No Bitcoin For You
In-Reply-To: <CANe1mWw2os6GUbRiyegn=Z+2ZM_J8x76rD4uh_0C3z+ix8aK+A@mail.gmail.com>
References: <BAY403-EAS63EE0AAE718842E0E3EFD6C2CC0@phx.gbl>
	<CANe1mWw-yJv=1_aLc+T8Mq1XgUv8VeDxHee-hVzQNH0hFs1ryg@mail.gmail.com>
	<CANe1mWw2os6GUbRiyegn=Z+2ZM_J8x76rD4uh_0C3z+ix8aK+A@mail.gmail.com>
Message-ID: <CANJO25LfwscmT06gwk3D==+=Cj6eBt9dUCHwyrGAs6U9Eoi5Uw@mail.gmail.com>

Sync time wouldn't be longer compared to 20MB, it would (eventually) be
longer under either setup.

Also, and this is probably a silly concern, but wouldn't changing block
time change the supply curve? If we cut the rate in half or a power of two,
that affects nothing, but if we want to keep it in round numbers, we need
to do it by 10, 5, or 2. I feel like most people would bank for 10 or 5,
both of which change the supply curve due to truncation.

Again, it's a trivial concern, but probably one that should be addressed.
On May 25, 2015 11:52 PM, "Jim Phillips" <jim at ergophobia.org> wrote:

> Incidentally, even once we have the "Internet of Things" brought on by 21,
> Inc. or whoever beats them to it, I would expect the average home to have
> only a single full node "hub" receiving the blockchain and broadcasting
> transactions created by all the minor SPV connected devices running within
> the house. The in-home full node would be peered with high bandwidth
> full-node relays running at the ISP or in the cloud. There are more than
> enough ISPs and cloud compute providers in the world such that there should
> be no concern at all about centralization of relays. Full nodes could some
> day become as ubiquitous on the Internet as authoritative DNS servers. And
> just like DNS servers, if you don't trust the nodes your ISP creates or
> it's too slow or censors transactions, there's nothing preventing you from
> peering with nodes hosted by the Googles or OpenDNSs out there, or running
> your own if you're really paranoid and have a few extra bucks for a VPS.
>
> --
> *James G. Phillips IV*
> <https://plus.google.com/u/0/113107039501292625391/posts>
> <http://www.linkedin.com/in/ergophobe>
>
> *"Don't bunt. Aim out of the ball park. Aim for the company of immortals."
> -- David Ogilvy*
>
>  *This message was created with 100% recycled electrons. Please think
> twice before printing.*
>
> On Mon, May 25, 2015 at 10:23 PM, Jim Phillips <jim at ergophobia.org> wrote:
>
>> I don't see how the fact that my 2Mbps connection causes me to not be a
>> very good relay has any bearing on whether or not the network as a whole
>> would be negatively impacted by a 20MB block. My inability to rapidly
>> propagate blocks doesn't really harm the network. It's only if MOST relays
>> are as slow as mine that it creates an issue. I'm one node in thousands
>> (potentially tens or hundreds of thousands if/when Bitcoin goes
>> mainstream). And I'm an individual. There's no reason at all for me to run
>> a full node from my home, except to have my own trusted and validated copy
>> of the blockchain on a computer I control directly. I don't need to act as
>> a relay for that and as long as I can download blocks faster than they are
>> created I'm fine. Also, I can easily afford a VPS server or several to run
>> full nodes as relays if I am feeling altruistic. It's actually cheaper for
>> me to lease a VPS than to keep my own home PC on 24/7, which is why I have
>> 2 of them.
>>
>> And as a business, the cost of a server and bandwidth to run a full node
>> is a drop in the bucket. I'm involved in several projects where we have
>> full nodes running on leased servers with multiple 1Gbps connections. It's
>> an almost zero cost. Those nodes could handle 20MB blocks today without
>> thinking about it, and I'm sure our nodes are just a few amongst thousands
>> just like them. I'm not at all concerned about the network being too
>> centralized.
>>
>> What concerns me is the fact that we are using edge cases like my home PC
>> as a lame excuse to debate expanding the capacity of the network.
>>
>> --
>> *James G. Phillips IV*
>> <https://plus.google.com/u/0/113107039501292625391/posts>
>> <http://www.linkedin.com/in/ergophobe>
>>
>> *"Don't bunt. Aim out of the ball park. Aim for the company of
>> immortals." -- David Ogilvy*
>>
>>  *This message was created with 100% recycled electrons. Please think
>> twice before printing.*
>>
>> On Mon, May 25, 2015 at 10:02 PM, Thy Shizzle <thyshizzle at outlook.com>
>> wrote:
>>
>>>  Indeed Jim, your internet connection makes a good reason why I don't
>>> like 20mb blocks (right now). It would take you well over a minute to
>>> download the block before you could even relay it on, so much slow down in
>>> propagation! Yes I do see how decreasing the time to create blocks is a bit
>>> of a band-aid fix, and to use tge term I've seen mentioned here "kicking
>>> the can down the road" I agree that this is doing this, however as you say
>>> bandwidth is our biggest enemy right now and so hopefully by the time we
>>> exceed the capacity gained by the decrease in block time, we can then look
>>> to bump up block size because hopefully 20mbps connections will be baseline
>>> by then etc.
>>>  ------------------------------
>>> From: Jim Phillips <jim at ergophobia.org>
>>> Sent: ?26/?05/?2015 12:53 PM
>>> To: Thy Shizzle <thyshizzle at outlook.com>
>>> Cc: Mike Hearn <mike at plan99.net>; Bitcoin Dev
>>> <bitcoin-development at lists.sourceforge.net>
>>>
>>> Subject: Re: [Bitcoin-development] No Bitcoin For You
>>>
>>>  Frankly I'm good with either way. I'm definitely in favor of faster
>>> confirmation times.
>>>
>>>  The important thing is that we need to increase the amount of
>>> transactions that get into blocks over a given time frame to a point that
>>> is in line with what current technology can handle. We can handle WAY more
>>> than we are doing right now. The Bitcoin network is not currently Disk,
>>> CPU, or RAM bound.. Not even close. The metric we're closest to being
>>> restricted by would be Network bandwidth. I live in a developing country.
>>> 2Mbps is a typical broadband speed here (although 5Mbps and 10Mbps
>>> connections are affordable). That equates to about 17MB per minute, or 170x
>>> more capacity than what I need to receive a full copy of the blockchain if
>>> I only talk to one peer. If I relay to say 10 peers, I can still handle 17x
>>> larger block sizes on a slow 2Mbps connection.
>>>
>>>  Also, even if we reduce the difficulty so that we're doing 1MB blocks
>>> every minute, that's still only 10MB every 10 minutes. Eventually we're
>>> going to have to increase that, and we can only reduce the confirmation
>>> period so much. I think someone once said 30 seconds or so is about the
>>> shortest period you can practically achieve.
>>>
>>>  --
>>> *James G. Phillips IV*
>>> <https://plus.google.com/u/0/113107039501292625391/posts>
>>> <http://www.linkedin.com/in/ergophobe>
>>>
>>> *"Don't bunt. Aim out of the ball park. Aim for the company of
>>> immortals." -- David Ogilvy *
>>>
>>>   *This message was created with 100% recycled electrons. Please think
>>> twice before printing.*
>>>
>>> On Mon, May 25, 2015 at 9:30 PM, Thy Shizzle <thyshizzle at outlook.com>
>>> wrote:
>>>
>>>  Nah don't make blocks 20mb, then you are slowing down block
>>> propagation and blowing out conf tikes as a result. Just decrease the time
>>> it takes to make a 1mb block, then you still see the same propagation times
>>> today and just increase the transaction throughput.
>>>  ------------------------------
>>> From: Jim Phillips <jim at ergophobia.org>
>>> Sent: ?26/?05/?2015 12:27 PM
>>> To: Mike Hearn <mike at plan99.net>
>>> Cc: Bitcoin Dev <bitcoin-development at lists.sourceforge.net>
>>> Subject: Re: [Bitcoin-development] No Bitcoin For You
>>>
>>>
>>> On Mon, May 25, 2015 at 1:36 PM, Mike Hearn <mike at plan99.net> wrote:
>>>
>>>   This meme about datacenter-sized nodes has to die. The Bitcoin wiki
>>> is down right now, but I showed years ago that you could keep up with VISA
>>> on a single well specced server with today's technology. Only people living
>>> in a dreamworld think that Bitcoin might actually have to match that level
>>> of transaction demand with today's hardware. As noted previously, "too many
>>> users" is simply not a problem Bitcoin has .... and may never have!
>>>
>>>
>>>  ... And will certainly NEVER have if we can't solve the capacity
>>> problem SOON.
>>>
>>>  In a former life, I was a capacity planner for Bank of America's
>>> mid-range server group. We had one hard and fast rule. When you are
>>> typically exceeding 75% of capacity on a given metric, it's time to expand
>>> capacity. Period. You don't do silly things like adjusting the business
>>> model to disincentivize use. Unless there's some flaw in the system and
>>> it's leaking resources, if usage has increased to the point where you are
>>> at or near the limits of capacity, you expand capacity. It's as simple as
>>> that, and I've found that same rule fits quite well in a number of systems.
>>>
>>>  In Bitcoin, we're not leaking resources. There's no flaw. The system
>>> is performing as intended. Usage is increasing because it works so well,
>>> and there is huge potential for future growth as we identify more uses and
>>> attract more users. There might be a few technical things we can do to
>>> reduce consumption, but the metric we're concerned with right now is how
>>> many transactions we can fit in a block. We've broken through the 75%
>>> marker and are regularly bumping up against the 100% limit.
>>>
>>>  It is time to stop debating this and take action to expand capacity.
>>> The only questions that should remain are how much capacity do we add, and
>>> how soon can we do it. Given that most existing computer systems and
>>> networks can easily handle 20MB blocks every 10 minutes, and given that
>>> that will increase capacity 20-fold, I can't think of a single reason why
>>> we can't go to 20MB as soon as humanly possible. And in a few years, when
>>> the average block size is over 15MB, we bump it up again to as high as we
>>> can go then without pushing typical computers or networks beyond their
>>> capacity. We can worry about ways to slow down growth without affecting the
>>> usefulness of Bitcoin as we get closer to the hard technical limits on our
>>> capacity.
>>>
>>>  And you know what else? If miners need higher fees to accommodate the
>>> costs of bigger blocks, they can configure their nodes to only mine
>>> transactions with higher fees.. Let the miners decide how to charge enough
>>> to pay for their costs. We don't need to cripple the network just for them.
>>>
>>>  --
>>> *James G. Phillips IV*
>>> <https://plus.google.com/u/0/113107039501292625391/posts>
>>>
>>> *"Don't bunt. Aim out of the ball park. Aim for the company of
>>> immortals." -- David Ogilvy *
>>>
>>>   *This message was created with 100% recycled electrons. Please think
>>> twice before printing.*
>>>
>>>
>>>
>>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150526/4cbf3ecd/attachment.html>

From bip at mattwhitlock.name  Tue May 26 05:47:37 2015
From: bip at mattwhitlock.name (Matt Whitlock)
Date: Tue, 26 May 2015 01:47:37 -0400
Subject: [Bitcoin-development] Zero-Conf for Full Node Discovery
In-Reply-To: <20150526051546.GB23502@savin.petertodd.org>
References: <CANe1mWwi+fxFU43_2mq-yd_qRsmCwMu_c5wWOpvFS4Un_FoT+Q@mail.gmail.com>
	<23111107.dfGN69SrR9@crushinator>
	<20150526051546.GB23502@savin.petertodd.org>
Message-ID: <2558087.GVnsa68lBj@crushinator>

On Tuesday, 26 May 2015, at 1:15 am, Peter Todd wrote:
> On Tue, May 26, 2015 at 12:52:07AM -0400, Matt Whitlock wrote:
> > On Monday, 25 May 2015, at 11:48 pm, Jim Phillips wrote:
> > > Do any wallets actually do this yet?
> > 
> > Not that I know of, but they do seed their address database via DNS, which you can poison if you control the LAN's DNS resolver. I did this for a Bitcoin-only Wi-Fi network I operated at a remote festival. We had well over a hundred lightweight wallets, all trying to connect to the Bitcoin P2P network over a very bandwidth-constrained Internet link, so I poisoned the DNS and rejected all outbound connection attempts on port 8333, to force all the wallets to connect to a single local full node, which had connectivity to a single remote node over the Internet. Thus, all the lightweight wallets at the festival had Bitcoin network connectivity, but we only needed to backhaul the Bitcoin network's transaction traffic once.
> 
> Interesting!
> 
> What festival was this?

The Porcupine Freedom Festival ("PorcFest") in New Hampshire last summer. I strongly suspect that it's the largest gathering of Bitcoin users at any event that is not specifically Bitcoin-themed. There's a lot of overlap between the Bitcoin and liberty communities. PorcFest draws somewhere around 1000-2000 attendees, a solid quarter of whom have Bitcoin wallets on their mobile devices.

The backhaul was a 3G cellular Internet connection, and the local Bitcoin node and network router were hosted on a Raspberry Pi with some Netfilter tricks to restrict connectivity. The net result was that all Bitcoin nodes (lightweight and heavyweight) on the local Wi-Fi network were unable to connect to any Bitcoin nodes except for the local node, which they discovered via DNS. I also had provisions in place to allow outbound connectivity to the API servers for Mycelium, Blockchain, and Coinbase wallets, by feeding the DNS resolver's results in real-time into a whitelisting Netfilter rule utilizing IP Sets.

For your amusement, here's the graphic for the banner that I had made to advertise the network at the festival (*chuckle*): http://www.mattwhitlock.com/bitcoin_wifi.png



From jim at ergophobia.org  Tue May 26 08:29:31 2015
From: jim at ergophobia.org (Jim Phillips)
Date: Tue, 26 May 2015 03:29:31 -0500
Subject: [Bitcoin-development] No Bitcoin For You
In-Reply-To: <CANJO25LfwscmT06gwk3D==+=Cj6eBt9dUCHwyrGAs6U9Eoi5Uw@mail.gmail.com>
References: <BAY403-EAS63EE0AAE718842E0E3EFD6C2CC0@phx.gbl>
	<CANe1mWw-yJv=1_aLc+T8Mq1XgUv8VeDxHee-hVzQNH0hFs1ryg@mail.gmail.com>
	<CANe1mWw2os6GUbRiyegn=Z+2ZM_J8x76rD4uh_0C3z+ix8aK+A@mail.gmail.com>
	<CANJO25LfwscmT06gwk3D==+=Cj6eBt9dUCHwyrGAs6U9Eoi5Uw@mail.gmail.com>
Message-ID: <CANe1mWzK-8PM-7tPKGhEUAYmC058QXge7Ncz+uCX_h9Xbxon_g@mail.gmail.com>

I think all the suggestions recommending cutting the block time down also
suggest reducing the rewards to compensate.

--
*James G. Phillips IV*
<https://plus.google.com/u/0/113107039501292625391/posts>
<http://www.linkedin.com/in/ergophobe>

*"Don't bunt. Aim out of the ball park. Aim for the company of immortals."
-- David Ogilvy*

 *This message was created with 100% recycled electrons. Please think twice
before printing.*

On Tue, May 26, 2015 at 12:43 AM, gabe appleton <gappleto97 at gmail.com>
wrote:

> Sync time wouldn't be longer compared to 20MB, it would (eventually) be
> longer under either setup.
>
> Also, and this is probably a silly concern, but wouldn't changing block
> time change the supply curve? If we cut the rate in half or a power of two,
> that affects nothing, but if we want to keep it in round numbers, we need
> to do it by 10, 5, or 2. I feel like most people would bank for 10 or 5,
> both of which change the supply curve due to truncation.
>
> Again, it's a trivial concern, but probably one that should be addressed.
> On May 25, 2015 11:52 PM, "Jim Phillips" <jim at ergophobia.org> wrote:
>
>> Incidentally, even once we have the "Internet of Things" brought on by
>> 21, Inc. or whoever beats them to it, I would expect the average home to
>> have only a single full node "hub" receiving the blockchain and
>> broadcasting transactions created by all the minor SPV connected devices
>> running within the house. The in-home full node would be peered with high
>> bandwidth full-node relays running at the ISP or in the cloud. There are
>> more than enough ISPs and cloud compute providers in the world such that
>> there should be no concern at all about centralization of relays. Full
>> nodes could some day become as ubiquitous on the Internet as authoritative
>> DNS servers. And just like DNS servers, if you don't trust the nodes your
>> ISP creates or it's too slow or censors transactions, there's nothing
>> preventing you from peering with nodes hosted by the Googles or OpenDNSs
>> out there, or running your own if you're really paranoid and have a few
>> extra bucks for a VPS.
>>
>> --
>> *James G. Phillips IV*
>> <https://plus.google.com/u/0/113107039501292625391/posts>
>> <http://www.linkedin.com/in/ergophobe>
>>
>> *"Don't bunt. Aim out of the ball park. Aim for the company of
>> immortals." -- David Ogilvy*
>>
>>  *This message was created with 100% recycled electrons. Please think
>> twice before printing.*
>>
>> On Mon, May 25, 2015 at 10:23 PM, Jim Phillips <jim at ergophobia.org>
>> wrote:
>>
>>> I don't see how the fact that my 2Mbps connection causes me to not be a
>>> very good relay has any bearing on whether or not the network as a whole
>>> would be negatively impacted by a 20MB block. My inability to rapidly
>>> propagate blocks doesn't really harm the network. It's only if MOST relays
>>> are as slow as mine that it creates an issue. I'm one node in thousands
>>> (potentially tens or hundreds of thousands if/when Bitcoin goes
>>> mainstream). And I'm an individual. There's no reason at all for me to run
>>> a full node from my home, except to have my own trusted and validated copy
>>> of the blockchain on a computer I control directly. I don't need to act as
>>> a relay for that and as long as I can download blocks faster than they are
>>> created I'm fine. Also, I can easily afford a VPS server or several to run
>>> full nodes as relays if I am feeling altruistic. It's actually cheaper for
>>> me to lease a VPS than to keep my own home PC on 24/7, which is why I have
>>> 2 of them.
>>>
>>> And as a business, the cost of a server and bandwidth to run a full node
>>> is a drop in the bucket. I'm involved in several projects where we have
>>> full nodes running on leased servers with multiple 1Gbps connections. It's
>>> an almost zero cost. Those nodes could handle 20MB blocks today without
>>> thinking about it, and I'm sure our nodes are just a few amongst thousands
>>> just like them. I'm not at all concerned about the network being too
>>> centralized.
>>>
>>> What concerns me is the fact that we are using edge cases like my home
>>> PC as a lame excuse to debate expanding the capacity of the network.
>>>
>>> --
>>> *James G. Phillips IV*
>>> <https://plus.google.com/u/0/113107039501292625391/posts>
>>> <http://www.linkedin.com/in/ergophobe>
>>>
>>> *"Don't bunt. Aim out of the ball park. Aim for the company of
>>> immortals." -- David Ogilvy*
>>>
>>>  *This message was created with 100% recycled electrons. Please think
>>> twice before printing.*
>>>
>>> On Mon, May 25, 2015 at 10:02 PM, Thy Shizzle <thyshizzle at outlook.com>
>>> wrote:
>>>
>>>>  Indeed Jim, your internet connection makes a good reason why I don't
>>>> like 20mb blocks (right now). It would take you well over a minute to
>>>> download the block before you could even relay it on, so much slow down in
>>>> propagation! Yes I do see how decreasing the time to create blocks is a bit
>>>> of a band-aid fix, and to use tge term I've seen mentioned here "kicking
>>>> the can down the road" I agree that this is doing this, however as you say
>>>> bandwidth is our biggest enemy right now and so hopefully by the time we
>>>> exceed the capacity gained by the decrease in block time, we can then look
>>>> to bump up block size because hopefully 20mbps connections will be baseline
>>>> by then etc.
>>>>  ------------------------------
>>>> From: Jim Phillips <jim at ergophobia.org>
>>>> Sent: ?26/?05/?2015 12:53 PM
>>>> To: Thy Shizzle <thyshizzle at outlook.com>
>>>> Cc: Mike Hearn <mike at plan99.net>; Bitcoin Dev
>>>> <bitcoin-development at lists.sourceforge.net>
>>>>
>>>> Subject: Re: [Bitcoin-development] No Bitcoin For You
>>>>
>>>>  Frankly I'm good with either way. I'm definitely in favor of faster
>>>> confirmation times.
>>>>
>>>>  The important thing is that we need to increase the amount of
>>>> transactions that get into blocks over a given time frame to a point that
>>>> is in line with what current technology can handle. We can handle WAY more
>>>> than we are doing right now. The Bitcoin network is not currently Disk,
>>>> CPU, or RAM bound.. Not even close. The metric we're closest to being
>>>> restricted by would be Network bandwidth. I live in a developing country.
>>>> 2Mbps is a typical broadband speed here (although 5Mbps and 10Mbps
>>>> connections are affordable). That equates to about 17MB per minute, or 170x
>>>> more capacity than what I need to receive a full copy of the blockchain if
>>>> I only talk to one peer. If I relay to say 10 peers, I can still handle 17x
>>>> larger block sizes on a slow 2Mbps connection.
>>>>
>>>>  Also, even if we reduce the difficulty so that we're doing 1MB blocks
>>>> every minute, that's still only 10MB every 10 minutes. Eventually we're
>>>> going to have to increase that, and we can only reduce the confirmation
>>>> period so much. I think someone once said 30 seconds or so is about the
>>>> shortest period you can practically achieve.
>>>>
>>>>  --
>>>> *James G. Phillips IV*
>>>> <https://plus.google.com/u/0/113107039501292625391/posts>
>>>> <http://www.linkedin.com/in/ergophobe>
>>>>
>>>> *"Don't bunt. Aim out of the ball park. Aim for the company of
>>>> immortals." -- David Ogilvy *
>>>>
>>>>   *This message was created with 100% recycled electrons. Please think
>>>> twice before printing.*
>>>>
>>>> On Mon, May 25, 2015 at 9:30 PM, Thy Shizzle <thyshizzle at outlook.com>
>>>> wrote:
>>>>
>>>>  Nah don't make blocks 20mb, then you are slowing down block
>>>> propagation and blowing out conf tikes as a result. Just decrease the time
>>>> it takes to make a 1mb block, then you still see the same propagation times
>>>> today and just increase the transaction throughput.
>>>>  ------------------------------
>>>> From: Jim Phillips <jim at ergophobia.org>
>>>> Sent: ?26/?05/?2015 12:27 PM
>>>> To: Mike Hearn <mike at plan99.net>
>>>> Cc: Bitcoin Dev <bitcoin-development at lists.sourceforge.net>
>>>> Subject: Re: [Bitcoin-development] No Bitcoin For You
>>>>
>>>>
>>>> On Mon, May 25, 2015 at 1:36 PM, Mike Hearn <mike at plan99.net> wrote:
>>>>
>>>>   This meme about datacenter-sized nodes has to die. The Bitcoin wiki
>>>> is down right now, but I showed years ago that you could keep up with VISA
>>>> on a single well specced server with today's technology. Only people living
>>>> in a dreamworld think that Bitcoin might actually have to match that level
>>>> of transaction demand with today's hardware. As noted previously, "too many
>>>> users" is simply not a problem Bitcoin has .... and may never have!
>>>>
>>>>
>>>>  ... And will certainly NEVER have if we can't solve the capacity
>>>> problem SOON.
>>>>
>>>>  In a former life, I was a capacity planner for Bank of America's
>>>> mid-range server group. We had one hard and fast rule. When you are
>>>> typically exceeding 75% of capacity on a given metric, it's time to expand
>>>> capacity. Period. You don't do silly things like adjusting the business
>>>> model to disincentivize use. Unless there's some flaw in the system and
>>>> it's leaking resources, if usage has increased to the point where you are
>>>> at or near the limits of capacity, you expand capacity. It's as simple as
>>>> that, and I've found that same rule fits quite well in a number of systems.
>>>>
>>>>  In Bitcoin, we're not leaking resources. There's no flaw. The system
>>>> is performing as intended. Usage is increasing because it works so well,
>>>> and there is huge potential for future growth as we identify more uses and
>>>> attract more users. There might be a few technical things we can do to
>>>> reduce consumption, but the metric we're concerned with right now is how
>>>> many transactions we can fit in a block. We've broken through the 75%
>>>> marker and are regularly bumping up against the 100% limit.
>>>>
>>>>  It is time to stop debating this and take action to expand capacity.
>>>> The only questions that should remain are how much capacity do we add, and
>>>> how soon can we do it. Given that most existing computer systems and
>>>> networks can easily handle 20MB blocks every 10 minutes, and given that
>>>> that will increase capacity 20-fold, I can't think of a single reason why
>>>> we can't go to 20MB as soon as humanly possible. And in a few years, when
>>>> the average block size is over 15MB, we bump it up again to as high as we
>>>> can go then without pushing typical computers or networks beyond their
>>>> capacity. We can worry about ways to slow down growth without affecting the
>>>> usefulness of Bitcoin as we get closer to the hard technical limits on our
>>>> capacity.
>>>>
>>>>  And you know what else? If miners need higher fees to accommodate the
>>>> costs of bigger blocks, they can configure their nodes to only mine
>>>> transactions with higher fees.. Let the miners decide how to charge enough
>>>> to pay for their costs. We don't need to cripple the network just for them.
>>>>
>>>>  --
>>>> *James G. Phillips IV*
>>>> <https://plus.google.com/u/0/113107039501292625391/posts>
>>>>
>>>> *"Don't bunt. Aim out of the ball park. Aim for the company of
>>>> immortals." -- David Ogilvy *
>>>>
>>>>   *This message was created with 100% recycled electrons. Please think
>>>> twice before printing.*
>>>>
>>>>
>>>>
>>>
>>
>>
>> ------------------------------------------------------------------------------
>> One dashboard for servers and applications across Physical-Virtual-Cloud
>> Widest out-of-the-box monitoring support with 50+ applications
>> Performance metrics, stats and reports that give you Actionable Insights
>> Deep dive visibility with transaction tracing using APM Insight.
>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150526/909baed8/attachment.html>

From mike at plan99.net  Tue May 26 10:48:46 2015
From: mike at plan99.net (Mike Hearn)
Date: Tue, 26 May 2015 12:48:46 +0200
Subject: [Bitcoin-development] Zero-Conf for Full Node Discovery
In-Reply-To: <2558087.GVnsa68lBj@crushinator>
References: <CANe1mWwi+fxFU43_2mq-yd_qRsmCwMu_c5wWOpvFS4Un_FoT+Q@mail.gmail.com>
	<23111107.dfGN69SrR9@crushinator>
	<20150526051546.GB23502@savin.petertodd.org>
	<2558087.GVnsa68lBj@crushinator>
Message-ID: <CANEZrP3tR-PTHnrAj4ptZnLh0PuWO_TWZ0FqpYe2TLNJC5C+xQ@mail.gmail.com>

Very interesting Matt.

For what it's worth, in future bitcoinj is very likely to bootstrap from
Cartographer nodes (signed HTTP) rather than DNS, and we're also steadily
working towards Tor by default. So this approach will probably stop working
at some point. As breaking PorcFest would kind of suck, we might want a
ZeroConf/Rendezvous solution in place so local LANs can capture Bitcoin
traffic away from Tor (with some notification to the user, presumably).



On Tue, May 26, 2015 at 7:47 AM, Matt Whitlock <bip at mattwhitlock.name>
wrote:

> On Tuesday, 26 May 2015, at 1:15 am, Peter Todd wrote:
> > On Tue, May 26, 2015 at 12:52:07AM -0400, Matt Whitlock wrote:
> > > On Monday, 25 May 2015, at 11:48 pm, Jim Phillips wrote:
> > > > Do any wallets actually do this yet?
> > >
> > > Not that I know of, but they do seed their address database via DNS,
> which you can poison if you control the LAN's DNS resolver. I did this for
> a Bitcoin-only Wi-Fi network I operated at a remote festival. We had well
> over a hundred lightweight wallets, all trying to connect to the Bitcoin
> P2P network over a very bandwidth-constrained Internet link, so I poisoned
> the DNS and rejected all outbound connection attempts on port 8333, to
> force all the wallets to connect to a single local full node, which had
> connectivity to a single remote node over the Internet. Thus, all the
> lightweight wallets at the festival had Bitcoin network connectivity, but
> we only needed to backhaul the Bitcoin network's transaction traffic once.
> >
> > Interesting!
> >
> > What festival was this?
>
> The Porcupine Freedom Festival ("PorcFest") in New Hampshire last summer.
> I strongly suspect that it's the largest gathering of Bitcoin users at any
> event that is not specifically Bitcoin-themed. There's a lot of overlap
> between the Bitcoin and liberty communities. PorcFest draws somewhere
> around 1000-2000 attendees, a solid quarter of whom have Bitcoin wallets on
> their mobile devices.
>
> The backhaul was a 3G cellular Internet connection, and the local Bitcoin
> node and network router were hosted on a Raspberry Pi with some Netfilter
> tricks to restrict connectivity. The net result was that all Bitcoin nodes
> (lightweight and heavyweight) on the local Wi-Fi network were unable to
> connect to any Bitcoin nodes except for the local node, which they
> discovered via DNS. I also had provisions in place to allow outbound
> connectivity to the API servers for Mycelium, Blockchain, and Coinbase
> wallets, by feeding the DNS resolver's results in real-time into a
> whitelisting Netfilter rule utilizing IP Sets.
>
> For your amusement, here's the graphic for the banner that I had made to
> advertise the network at the festival (*chuckle*):
> http://www.mattwhitlock.com/bitcoin_wifi.png
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150526/31cce561/attachment.html>

From andreas at schildbach.de  Tue May 26 12:40:28 2015
From: andreas at schildbach.de (Andreas Schildbach)
Date: Tue, 26 May 2015 14:40:28 +0200
Subject: [Bitcoin-development] A suggestion for reducing the size of the
	UTXO database
In-Reply-To: <20150525210541.GA12430@savin.petertodd.org>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>	<2114827.D6GUhXtGkV@crushinator>	<CANEZrP2KnL9NO-DgUuaT5-VHE0oT5MTsok2YuAO1nJiznLfpMA@mail.gmail.com>	<1515563.NQHYuaqTfB@crushinator>
	<mk00n6$719$1@ger.gmane.org>
	<20150525210541.GA12430@savin.petertodd.org>
Message-ID: <mk1pjs$pgq$1@ger.gmane.org>

On 05/25/2015 11:05 PM, Peter Todd wrote:
> On Mon, May 25, 2015 at 10:29:26PM +0200, Andreas Schildbach wrote:
>>> I see this behavior all the time. I am using the latest release, as far as I know. Version 4.30.
>>>
>>> The same behavior occurs in the Testnet3 variant of the app. Go in there with an empty wallet and receive one payment and wait for it to confirm. Then send a payment and, before it confirms, try to send another one. The wallet won't let you send the second payment. It'll say something like, "You need x.xxxxxx more bitcoins to make this payment." But if you wait for your first payment to confirm, then you'll be able to make the second payment.
>>>
>>> If it matters, I configure the app to connect only to my own trusted Bitcoin node, so I only ever have one active connection at most. I notice that outgoing payments never show as "Sent" until they appear in a block, presumably because the app never sees the transaction come in over any connection.
>>
>> Yes, that's the issue. Because you're connecting only to one node, you
>> don't get any instant confirmations -- due to a Bitcoin protocol
>> limitation you can only get them from nodes you don't post the tx to.
> 
> Odd, I just tried the above as well - with multiple peers connected -
> and had the exact same problem.

It should work, I'm testing this regularly. Can you report an issue
through the app and attach your log when this happens again?





From tschorsch at informatik.hu-berlin.de  Tue May 26 13:54:03 2015
From: tschorsch at informatik.hu-berlin.de (Florian Tschorsch)
Date: Tue, 26 May 2015 15:54:03 +0200
Subject: [Bitcoin-development] Bitcoin Survey Paper
Message-ID: <55647AFB.3000909@informatik.hu-berlin.de>


Hi all,

some time ago, we became interested in Bitcoin, but gathering relevant
work and getting an overview was kind of painful. We took it as a sign
that a survey paper on Bitcoin is desperately needed.

Since then we observed the activities of the Bitcoin community. Recently
we finished a technical report that is our attempt to contribute the
lacking Bitcoin survey. Maybe it will be of interest to some of you:
https://eprint.iacr.org/2015/464

Feedback is highly appreciated and would help to improve the quality of
future revisions.

Cheers, Florian.



From d at domob.eu  Tue May 26 14:11:14 2015
From: d at domob.eu (Daniel Kraft)
Date: Tue, 26 May 2015 16:11:14 +0200
Subject: [Bitcoin-development] Bitcoin Survey Paper
In-Reply-To: <55647AFB.3000909@informatik.hu-berlin.de>
References: <55647AFB.3000909@informatik.hu-berlin.de>
Message-ID: <55647F02.5080308@domob.eu>

Hi Florian!

On 2015-05-26 15:54, Florian Tschorsch wrote:
> some time ago, we became interested in Bitcoin, but gathering relevant
> work and getting an overview was kind of painful. We took it as a sign
> that a survey paper on Bitcoin is desperately needed.
> 
> Since then we observed the activities of the Bitcoin community. Recently
> we finished a technical report that is our attempt to contribute the
> lacking Bitcoin survey. Maybe it will be of interest to some of you:
> https://eprint.iacr.org/2015/464

Thanks for the work you (and your collegue) put into this paper!  It is
definitely a good step in the right direction!

> Feedback is highly appreciated and would help to improve the quality of
> future revisions.

Do you know [1]?  I've only glanced at both papers, but it seems that's
also a research paper about Bitcoin & co.

  [1] http://www.jbonneau.com/doc/BMCNKF15-IEEESP-bitcoin.pdf

Apart from that, let me advertise myself a little bit. ;)  In case you
are interested in the difficulty mechanism (which you only mention
briefly), I've recently written about it [2] (official publication) [3]
(preprint without paywall).

  [2] http://link.springer.com/article/10.1007/s12083-015-0347-x
  [3] http://www.domob.eu/research/DifficultyControl.pdf

Good luck with your further research!

Yours,
Daniel

-- 
http://www.domob.eu/
OpenPGP: 1142 850E 6DFF 65BA 63D6  88A8 B249 2AC4 A733 0737
Namecoin: id/domob -> https://nameid.org/?name=domob
--
Done:  Arc-Bar-Cav-Hea-Kni-Ran-Rog-Sam-Tou-Val-Wiz
To go: Mon-Pri

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 836 bytes
Desc: OpenPGP digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150526/16225ec7/attachment.sig>

From danny.thorpe at gmail.com  Tue May 26 18:22:00 2015
From: danny.thorpe at gmail.com (Danny Thorpe)
Date: Tue, 26 May 2015 11:22:00 -0700
Subject: [Bitcoin-development] Cost savings by using replace-by-fee,
	30-90%
In-Reply-To: <20150526001034.GF21367@savin.petertodd.org>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
	<CANEZrP0DL8yA=neK0DTq0npEqc0q+RvTQD57OndNVg0vi2=yMg@mail.gmail.com>
	<20150525212638.GB12430@savin.petertodd.org>
	<CANEZrP1k-rUBSj2GMKqOEZsOuHp=axKUSxShOiN01DorzkFODQ@mail.gmail.com>
	<20150526001034.GF21367@savin.petertodd.org>
Message-ID: <CAJN5wHV=bVgM16PPQqsOd1Qu+pALeAPmGz4-6xEV1qG6Fo+ToA@mail.gmail.com>

What prevents RBF from being used for fraudulent payment reversals?

Pay 1BTC to Alice for hard goods, then after you receive the goods
broadcast a double spend of that transaction to pay Alice nothing? Your
only cost is the higher network fee of the 2nd tx.

Thanks,
-Danny

On Mon, May 25, 2015 at 5:10 PM, Peter Todd <pete at petertodd.org> wrote:

> On Tue, May 26, 2015 at 12:03:09AM +0200, Mike Hearn wrote:
> > CPFP also solves it just fine.
>
> CPFP is a significantly more expensive way of paying fees than RBF,
> particularly for the use-case of defragmenting outputs, with cost
> savings ranging from 30% to 90%
>
>
> Case 1: CPFP vs. RBF for increasing the fee on a single tx
> ----------------------------------------------------------
>
> Creating an spending a P2PKH output uses 34 bytes of txout, and 148
> bytes of txin, 182 bytes total.
>
> Let's suppose I have a 1 BTC P2PKH output and I want to pay 0.1 BTC to
> Alice. This results in a 1in/2out transaction t1 that's 226 bytes in size.
> I forget to click on the "priority fee" option, so it goes out with the
> minimum fee of 2.26uBTC. Whoops! I use CPFP to spend that output,
> creating a new transaction t2 that's 192 bytes in size. I want to pay
> 1mBTC/KB for a fast confirmation, so I'm now paying 418uBTC of
> transaction fees.
>
> On the other hand, had I use RBF, my wallet would have simply
> rebroadcast t1 with the change address decreased. The rules require you
> to pay 2.26uBTC for the bandwidth consumed broadcasting it, plus the new
> fee level, or 218uBTC of fees in total.
>
> Cost savings: 48%
>
>
> Case 2: Paying multiple recipients in succession
> ------------------------------------------------
>
> Suppose that after I pay Alice, I also decide to pay Bob for his hard
> work demonstrating cryptographic protocols. I need to create a new
> transaction t2 spending t1's change address. Normally t2 would be
> another 226 bytes in size, resulting in 226uBTC additional fees.
>
> With RBF on the other hand I can simply double-spend t1 with a
> transaction paying both Alice and Bob. This new transaction is 260 bytes
> in size. I have to pay 2.6uBTC additional fees to pay for the bandwidth
> consumed broadcasting it, resulting in an additional 36uBTC of fees.
>
> Cost savings: 84%
>
>
> Case 3: Paying multiple recipients from a 2-of-3 multisig wallet
> ----------------------------------------------------------------
>
> The above situation gets even worse with multisig. t1 in the multisig
> case is 367 bytes; t2 another 367 bytes, costing an additional 367uBTC
> in fees. With RBF we rewrite t1 with an additional output, resulting in
> a 399 byte transaction, with just 36uBTC in additional fees.
>
> Cost savings: 90%
>
>
> Case 4: Dust defragmentation
> ----------------------------
>
> My wallet has a two transaction outputs that it wants to combine into
> one for the purpose of UTXO defragmentation. It broadcasts transaction
> t1 with two inputs and one output, size 340 bytes, paying zero fees.
>
> Prior to the transaction confirming I find I need to spend those funds
> for a priority transaction at the 1mBTC/KB fee level. This transaction,
> t2a, has one input and two outputs, 226 bytes in size. However it needs
> to pay fees for both transactions at once, resulting in a combined total
> fee of 556uBTC. If this situation happens frequently, defragmenting
> UTXOs is likely to cost more in additional fees than it saves.
>
> With RBF I'd simply doublespend t1 with a 2-in-2-out transaction 374
> bytes in size, paying 374uBTC. Even better, if one of the two inputs is
> sufficiently large to cover my costs I can doublespend t1 with a
> 1-in-2-out tx just 226 bytes in size, paying 226uBTC.
>
> Cost savings: 32% to 59%, or even infinite if defragmentation w/o RBF
>               costs you more than you save
>
> --
> 'peter'[:-1]@petertodd.org
> 0000000000000000134ce6577d4122094479f548b997baf84367eaf0c190bc9f
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150526/4f1264c0/attachment.html>

From tomh at thinlink.com  Tue May 26 17:54:05 2015
From: tomh at thinlink.com (Tom Harding)
Date: Tue, 26 May 2015 10:54:05 -0700
Subject: [Bitcoin-development] First-Seen-Safe Replace-by-Fee
In-Reply-To: <20150526051305.GA23502@savin.petertodd.org>
References: <20150526051305.GA23502@savin.petertodd.org>
Message-ID: <5564B33D.3070107@thinlink.com>


I think this is a significant step forward.

I suggest you also need to ensure that no inputs can be removed or 
changed (other than scriptsigs) -- only added.  Otherwise, the semantics 
change too much for the original signers.  Imagine a tx with two inputs 
from different parties.  Should it be easy for party 1 to be able to 
eliminate party 2 as a contributor of funds?  It's not difficult to 
imagine real-world consequences to not having contributed to the 
transaction.  And unless you can think of a reason, tx-level attributes 
like nLocktime should not change either.

The result would be something very like CPFP, but with the new inputs 
and outputs merged into the original tx, keeping most of the overhead 
savings you describe.

It should be submitted to bitcoin/bitcoin because like most inconsistent 
relay policies, inconsistently deployed FSS RBF invites attacks (see 
https://gist.github.com/aalness/a78e3e35b90f52140f0d).

Generally, to be kind to zeroconf:

  - Align relay and validation rules
  - Keep first-seen
  - Relay double-spends as alerts
  - Allow nLocktime transactions into the mempool a bit before they 
become final
  - ...

It's not unlike making a best-effort to reduce sources of malleability.  
FSS RBF should be compatible with this if deployed consistently.



On 5/25/2015 10:13 PM, Peter Todd wrote:
> Summary
> -------
>
> First-seen-safe replace-by-fee (FSS RBF) does the following:
>
> 1) Give users effective ways of getting "stuck" transactions unstuck.
> 2) Use blockchain space efficiently.
>
> without:
>
> 3) Changing the status quo with regard to zeroconf.
>
> The current Bitcoin Core implementation has "first-seen" mempool
> behavior. Once transaction t1 has been accepted, the transaction is
> never removed from the mempool until mined, or double-spent by a
> transaction in a block. The author's previously proposed replace-by-fee
> replaced this behavior with simply accepting the transaction paying the
> highest fee.
>
> FSS RBF is a compromise between these two behaviors. Transactions may be
> replaced by higher-fee paying transactions, provided that all outputs in
> the previous transaction are still paid by the replacement. While not as
> general as standard RBF, and with higher costs than standard RBF, this
> still allows fees on transaction to be increased after the fact with
> less cost and higher efficiency than child-pays-for-parent in many
> common situations; in some situations CPFP is unusable, leaving RBF as
> the only option.
>
>
> Semantics
> ---------
>
> For reference, standard replace-by-fee has the following criteria for
> determining whether to replace a transaction.
>
> 1) t2 pays > fees than t1
>
> 2) The delta fees pay by t2, t2.fee - t1.fee, are >= the minimum fee
>     required to relay t2. (t2.size * min_fee_per_kb)
>
> 3) t2 pays more fees/kb than t1
>
> FSS RBF adds the following additional criteria to replace-by-fee before
> allowing a transaction t1 to be replaced with t2:
>
> 1) All outputs of t1 exist in t2 and pay >= the value in t1.
>
> 2) All outputs of t1 are unspent.
>
> 3) The order of outputs in t2 is the same as in t1 with additional new
>     outputs at the end of the output list.
>
> 4) t2 only conflicts with a single transaction, t1
>
> 5) t2 does not spend any outputs of t1 (which would make it an invalid
>     transaction, impossible to mine)
>
> These additional criteria respect the existing "first-seen" behavior of
> the Bitcoin Core mempool implementation, such that once an address is
> payed some amount of BTC, all subsequent replacement transactions will
> pay an equal or greater amount. In short, FSS-RBF is "zeroconf safe" and
> has no affect on the ability of attackers to doublespend. (beyond of
> course the fact that any changes what-so-ever to mempool behavior are
> potential zeroconf doublespend vulnerabilities)
>
>
> Implementation
> --------------
>
> Pull-req for git HEAD: https://github.com/bitcoin/bitcoin/pull/6176
>
> A backport to v0.10.2 is pending.
>
> An implementation of fee bumping respecting FSS rules is available at:
>
> https://github.com/petertodd/replace-by-fee-tools/blob/master/bump-fee.py
>
>
> Usage Scenarios
> ---------------
>
> Case 1: Increasing the fee on a single tx
> -----------------------------------------
>
> We start with a 1-in-2-out P2PKH using transaction t1, 226 bytes in size
> with the minimal relay fee, 2.26uBTC. Increasing the fee while
> respecting FSS-RBF rules requires the addition of one more txin, with
> the change output value increased appropriately, resulting in
> transaction t2, size 374 bytes. If the change txout is sufficient for
> the fee increase, increasing the fee via CPFP requires a second
> 1-in-1-out transaction, 192 bytes, for a total of 418 bytes; if another
> input is required, CPFP requires a 2-in-1-out tx, 340 bytes, for a total
> of 566 bytes.
>
> Benefits: 11% to 34%+ cost savings, and RBF can increase fees even in
>            cases where the original transaction didn't have a change
>            output.
>
>
> Case 2: Paying multiple recipients in succession
> ------------------------------------------------
>
> We have a 1-in-2-out P2PKH transaction t1, 226 bytes, that pays Alice.
> We now need to pay Bob. With plain RBF we'd just add a new outptu and
> reduce the value of the change address, a 90% savings. However with FSS
> RBF, decreasing the value is not allowed, so we have to add an input.
>
> If the change of t1 is sufficient to pay Bob, a second 1-in-2-out tx can
> be created, 2*226=452 bytes in total. With FSS RBF we can replace t1
> with a 2-in-3-out tx paying both, increasing the value of the change
> output appropriately, resulting in 408 bytes transaction saving 10%
>
> Similar to the above example in the case where the change address of t1
> is insufficient to pay Bob the end result is one less transaction output
> in the wallet, defragmenting it. Spending these outputs later on would
> require two 148 byte inputs compared to one with RBF, resulting in an
> overall savings of 25%
>
>
> Case 3: Paying the same recipient multiple times
> ------------------------------------------------
>
> For example, consider the situation of an exchange, Acme Bitcoin Sales,
> that keeps the majority of coins in cold storage. Acme wants to move
> funds to cold storage at the lowest possible cost, taking advantage of
> periods of higher capacity. (inevitable due to the poisson nature of
> block creation) At the same time they would like to defragment their
> incoming outputs to keep redemption costs low, particularly since
> spending their high-security 3-of-7 P2SH multisigs is expensive. Acme
> creates a low fee transaction with a single output to cold storage,
> periodically adding new inputs as funds need to be moved to storage.
> Estimating the cost savings here is complex, and depends greatly on
> details of Acme's business, but regardless the approach works from a
> technical point of view. For instance if Acme's business is such that
> the total hotwallet size needed heavily depends on external factors like
> volatility, as hotwallet demand decreases throughout a day they can add
> inputs to the pending transaction. (simply asking customers to deposit
> funds directly to the cold storage is also a useful strategy)
>
> However this is another case where standard RBF is significantly more
> useful. For instance, as withdrawal requests come in the exchange can
> quickly replace their pending transactions sending funds to cold storage
> with transactions sending those funds to customers instead, each time
> avoiding multiple costly transactions. In particular, by reducing the
> need to access cold storage at all, the security of the cold-stored
> funds is increased.
>
>
> Wallet Compatibility
> --------------------
>
> All wallets should treat conflicting incoming transactions as equivalent
> so long as the transaction outputs owned by them do not change. In
> addition to compatibility with RBF-related practices, this prevents
> unnecessary user concern if transactions are mutated. Wallets must not
> assume TXIDs are fixed until confirmed in the blockchain; a fixed TXID
> is not guaranteed by the Bitcoin protocol.
>
>




From allen.piscitello at gmail.com  Tue May 26 18:38:08 2015
From: allen.piscitello at gmail.com (Allen Piscitello)
Date: Tue, 26 May 2015 13:38:08 -0500
Subject: [Bitcoin-development] Cost savings by using replace-by-fee,
	30-90%
In-Reply-To: <CAJN5wHV=bVgM16PPQqsOd1Qu+pALeAPmGz4-6xEV1qG6Fo+ToA@mail.gmail.com>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
	<CANEZrP0DL8yA=neK0DTq0npEqc0q+RvTQD57OndNVg0vi2=yMg@mail.gmail.com>
	<20150525212638.GB12430@savin.petertodd.org>
	<CANEZrP1k-rUBSj2GMKqOEZsOuHp=axKUSxShOiN01DorzkFODQ@mail.gmail.com>
	<20150526001034.GF21367@savin.petertodd.org>
	<CAJN5wHV=bVgM16PPQqsOd1Qu+pALeAPmGz4-6xEV1qG6Fo+ToA@mail.gmail.com>
Message-ID: <CAJfRnm6BZqavor_e14B7yXwvEXBE=B_usQRn2KLoMQ9VcTtaog@mail.gmail.com>

What prevents you from writing a bad check using today's systems?

On Tue, May 26, 2015 at 1:22 PM, Danny Thorpe <danny.thorpe at gmail.com>
wrote:

> What prevents RBF from being used for fraudulent payment reversals?
>
> Pay 1BTC to Alice for hard goods, then after you receive the goods
> broadcast a double spend of that transaction to pay Alice nothing? Your
> only cost is the higher network fee of the 2nd tx.
>
> Thanks,
> -Danny
>
> On Mon, May 25, 2015 at 5:10 PM, Peter Todd <pete at petertodd.org> wrote:
>
>> On Tue, May 26, 2015 at 12:03:09AM +0200, Mike Hearn wrote:
>> > CPFP also solves it just fine.
>>
>> CPFP is a significantly more expensive way of paying fees than RBF,
>> particularly for the use-case of defragmenting outputs, with cost
>> savings ranging from 30% to 90%
>>
>>
>> Case 1: CPFP vs. RBF for increasing the fee on a single tx
>> ----------------------------------------------------------
>>
>> Creating an spending a P2PKH output uses 34 bytes of txout, and 148
>> bytes of txin, 182 bytes total.
>>
>> Let's suppose I have a 1 BTC P2PKH output and I want to pay 0.1 BTC to
>> Alice. This results in a 1in/2out transaction t1 that's 226 bytes in size.
>> I forget to click on the "priority fee" option, so it goes out with the
>> minimum fee of 2.26uBTC. Whoops! I use CPFP to spend that output,
>> creating a new transaction t2 that's 192 bytes in size. I want to pay
>> 1mBTC/KB for a fast confirmation, so I'm now paying 418uBTC of
>> transaction fees.
>>
>> On the other hand, had I use RBF, my wallet would have simply
>> rebroadcast t1 with the change address decreased. The rules require you
>> to pay 2.26uBTC for the bandwidth consumed broadcasting it, plus the new
>> fee level, or 218uBTC of fees in total.
>>
>> Cost savings: 48%
>>
>>
>> Case 2: Paying multiple recipients in succession
>> ------------------------------------------------
>>
>> Suppose that after I pay Alice, I also decide to pay Bob for his hard
>> work demonstrating cryptographic protocols. I need to create a new
>> transaction t2 spending t1's change address. Normally t2 would be
>> another 226 bytes in size, resulting in 226uBTC additional fees.
>>
>> With RBF on the other hand I can simply double-spend t1 with a
>> transaction paying both Alice and Bob. This new transaction is 260 bytes
>> in size. I have to pay 2.6uBTC additional fees to pay for the bandwidth
>> consumed broadcasting it, resulting in an additional 36uBTC of fees.
>>
>> Cost savings: 84%
>>
>>
>> Case 3: Paying multiple recipients from a 2-of-3 multisig wallet
>> ----------------------------------------------------------------
>>
>> The above situation gets even worse with multisig. t1 in the multisig
>> case is 367 bytes; t2 another 367 bytes, costing an additional 367uBTC
>> in fees. With RBF we rewrite t1 with an additional output, resulting in
>> a 399 byte transaction, with just 36uBTC in additional fees.
>>
>> Cost savings: 90%
>>
>>
>> Case 4: Dust defragmentation
>> ----------------------------
>>
>> My wallet has a two transaction outputs that it wants to combine into
>> one for the purpose of UTXO defragmentation. It broadcasts transaction
>> t1 with two inputs and one output, size 340 bytes, paying zero fees.
>>
>> Prior to the transaction confirming I find I need to spend those funds
>> for a priority transaction at the 1mBTC/KB fee level. This transaction,
>> t2a, has one input and two outputs, 226 bytes in size. However it needs
>> to pay fees for both transactions at once, resulting in a combined total
>> fee of 556uBTC. If this situation happens frequently, defragmenting
>> UTXOs is likely to cost more in additional fees than it saves.
>>
>> With RBF I'd simply doublespend t1 with a 2-in-2-out transaction 374
>> bytes in size, paying 374uBTC. Even better, if one of the two inputs is
>> sufficiently large to cover my costs I can doublespend t1 with a
>> 1-in-2-out tx just 226 bytes in size, paying 226uBTC.
>>
>> Cost savings: 32% to 59%, or even infinite if defragmentation w/o RBF
>>               costs you more than you save
>>
>> --
>> 'peter'[:-1]@petertodd.org
>> 0000000000000000134ce6577d4122094479f548b997baf84367eaf0c190bc9f
>>
>>
>> ------------------------------------------------------------------------------
>> One dashboard for servers and applications across Physical-Virtual-Cloud
>> Widest out-of-the-box monitoring support with 50+ applications
>> Performance metrics, stats and reports that give you Actionable Insights
>> Deep dive visibility with transaction tracing using APM Insight.
>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150526/a7fd8020/attachment.html>

From exutechnology at gmail.com  Tue May 26 18:39:36 2015
From: exutechnology at gmail.com (Da Xu)
Date: Tue, 26 May 2015 14:39:36 -0400
Subject: [Bitcoin-development] please remove me from the list
Message-ID: <CA+Yi3-ed5shiqCc+JOmm2h=1rZrXwTSebscBC4M5KO3yrMio4Q@mail.gmail.com>

Thanks.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150526/87d21b75/attachment.html>

From voisine at gmail.com  Tue May 26 18:42:37 2015
From: voisine at gmail.com (Aaron Voisine)
Date: Tue, 26 May 2015 11:42:37 -0700
Subject: [Bitcoin-development] Cost savings by using replace-by-fee,
	30-90%
In-Reply-To: <CAJN5wHV=bVgM16PPQqsOd1Qu+pALeAPmGz4-6xEV1qG6Fo+ToA@mail.gmail.com>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
	<CANEZrP0DL8yA=neK0DTq0npEqc0q+RvTQD57OndNVg0vi2=yMg@mail.gmail.com>
	<20150525212638.GB12430@savin.petertodd.org>
	<CANEZrP1k-rUBSj2GMKqOEZsOuHp=axKUSxShOiN01DorzkFODQ@mail.gmail.com>
	<20150526001034.GF21367@savin.petertodd.org>
	<CAJN5wHV=bVgM16PPQqsOd1Qu+pALeAPmGz4-6xEV1qG6Fo+ToA@mail.gmail.com>
Message-ID: <CACq0ZD7pu0q1P9cMWK-F1s_CHTWuHhawjwiJ_rQT7isYqQ4OFw@mail.gmail.com>

See the "first-seen-safe replace-by-fee" thread


Aaron Voisine
co-founder and CEO
breadwallet.com

On Tue, May 26, 2015 at 11:22 AM, Danny Thorpe <danny.thorpe at gmail.com>
wrote:

> What prevents RBF from being used for fraudulent payment reversals?
>
> Pay 1BTC to Alice for hard goods, then after you receive the goods
> broadcast a double spend of that transaction to pay Alice nothing? Your
> only cost is the higher network fee of the 2nd tx.
>
> Thanks,
> -Danny
>
> On Mon, May 25, 2015 at 5:10 PM, Peter Todd <pete at petertodd.org> wrote:
>
>> On Tue, May 26, 2015 at 12:03:09AM +0200, Mike Hearn wrote:
>> > CPFP also solves it just fine.
>>
>> CPFP is a significantly more expensive way of paying fees than RBF,
>> particularly for the use-case of defragmenting outputs, with cost
>> savings ranging from 30% to 90%
>>
>>
>> Case 1: CPFP vs. RBF for increasing the fee on a single tx
>> ----------------------------------------------------------
>>
>> Creating an spending a P2PKH output uses 34 bytes of txout, and 148
>> bytes of txin, 182 bytes total.
>>
>> Let's suppose I have a 1 BTC P2PKH output and I want to pay 0.1 BTC to
>> Alice. This results in a 1in/2out transaction t1 that's 226 bytes in size.
>> I forget to click on the "priority fee" option, so it goes out with the
>> minimum fee of 2.26uBTC. Whoops! I use CPFP to spend that output,
>> creating a new transaction t2 that's 192 bytes in size. I want to pay
>> 1mBTC/KB for a fast confirmation, so I'm now paying 418uBTC of
>> transaction fees.
>>
>> On the other hand, had I use RBF, my wallet would have simply
>> rebroadcast t1 with the change address decreased. The rules require you
>> to pay 2.26uBTC for the bandwidth consumed broadcasting it, plus the new
>> fee level, or 218uBTC of fees in total.
>>
>> Cost savings: 48%
>>
>>
>> Case 2: Paying multiple recipients in succession
>> ------------------------------------------------
>>
>> Suppose that after I pay Alice, I also decide to pay Bob for his hard
>> work demonstrating cryptographic protocols. I need to create a new
>> transaction t2 spending t1's change address. Normally t2 would be
>> another 226 bytes in size, resulting in 226uBTC additional fees.
>>
>> With RBF on the other hand I can simply double-spend t1 with a
>> transaction paying both Alice and Bob. This new transaction is 260 bytes
>> in size. I have to pay 2.6uBTC additional fees to pay for the bandwidth
>> consumed broadcasting it, resulting in an additional 36uBTC of fees.
>>
>> Cost savings: 84%
>>
>>
>> Case 3: Paying multiple recipients from a 2-of-3 multisig wallet
>> ----------------------------------------------------------------
>>
>> The above situation gets even worse with multisig. t1 in the multisig
>> case is 367 bytes; t2 another 367 bytes, costing an additional 367uBTC
>> in fees. With RBF we rewrite t1 with an additional output, resulting in
>> a 399 byte transaction, with just 36uBTC in additional fees.
>>
>> Cost savings: 90%
>>
>>
>> Case 4: Dust defragmentation
>> ----------------------------
>>
>> My wallet has a two transaction outputs that it wants to combine into
>> one for the purpose of UTXO defragmentation. It broadcasts transaction
>> t1 with two inputs and one output, size 340 bytes, paying zero fees.
>>
>> Prior to the transaction confirming I find I need to spend those funds
>> for a priority transaction at the 1mBTC/KB fee level. This transaction,
>> t2a, has one input and two outputs, 226 bytes in size. However it needs
>> to pay fees for both transactions at once, resulting in a combined total
>> fee of 556uBTC. If this situation happens frequently, defragmenting
>> UTXOs is likely to cost more in additional fees than it saves.
>>
>> With RBF I'd simply doublespend t1 with a 2-in-2-out transaction 374
>> bytes in size, paying 374uBTC. Even better, if one of the two inputs is
>> sufficiently large to cover my costs I can doublespend t1 with a
>> 1-in-2-out tx just 226 bytes in size, paying 226uBTC.
>>
>> Cost savings: 32% to 59%, or even infinite if defragmentation w/o RBF
>>               costs you more than you save
>>
>> --
>> 'peter'[:-1]@petertodd.org
>> 0000000000000000134ce6577d4122094479f548b997baf84367eaf0c190bc9f
>>
>>
>> ------------------------------------------------------------------------------
>> One dashboard for servers and applications across Physical-Virtual-Cloud
>> Widest out-of-the-box monitoring support with 50+ applications
>> Performance metrics, stats and reports that give you Actionable Insights
>> Deep dive visibility with transaction tracing using APM Insight.
>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150526/cf2d8823/attachment.html>

From thomasv at electrum.org  Tue May 26 18:47:15 2015
From: thomasv at electrum.org (Thomas Voegtlin)
Date: Tue, 26 May 2015 20:47:15 +0200
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <CANEZrP2x+fBitgcvoaC2qBbJS-Ek_hgS3ZGM55UtURKc-oDZMQ@mail.gmail.com>
References: <5550D8BE.6070207@electrum.org>
	<CANEZrP2x+fBitgcvoaC2qBbJS-Ek_hgS3ZGM55UtURKc-oDZMQ@mail.gmail.com>
Message-ID: <5564BFB3.5080403@electrum.org>

Hello Mike,

> 
> Are you aware of my proposal for network assurance contracts?
> 

Yes I am aware of that; sorry for not mentioning it. I think it is an
interesting proposal, but I would not rely on it today, because it
includes a large share of unproven social experiment.

(Bitcoin too is a social experiment, but so far it has been working)


> But I agree with Gavin that attempting to plan for 20 years from now is
> ambitious at best. Bitcoin might not even exist 20 years from now, or might
> be an abandoned backwater a la USENET.

I agree with that, but I don't think it can be used as a way to justify
how decisions are made today.

The opposition to block size increase comes from two things:
(1) The perceived risk of increased centralization.
(2) Long-term considerations on the need for fee pressure.

I believe you and Gavin have properly addressed (1). Concerning (2), I
think the belief that miners can eventually be funded by a fee market is
wishful thinking. Thus, I am not against the proposed block size increase.

However, the issue of long-term mining incentives remains. So far, the
only proven method to incentivize mining has been direct block reward.

The easiest solution to ensure long-term viability of Bitcoin would be
to put an end to the original block halving schedule, and to keep the
block reward constant (this is what Monero does, btw). That solution is
inflationary, but in practice, users happen to lose private keys all the
time. The rate of coins loss would eventually converge to whatever rate
of emission is chosen, because the care people take of their coins
depends on their value.

Another solution, that does not break Bitcoin's social contract, would
be to keep the original block halving schedule, but to allow miners to
also redeem lost coins (defined as: coins that have not moved for a
fixed number of years. Some time averaging of the lost coins may be
needed in order to prevent non-productive miner strategies). That
solution would create less uncertainty on the actual money supply, and
better acceptability.

I do not expect such a solution to be adopted before miner incentives
become a problem. Neither am I attempting to predict the future; a
completely different solution might be found before the problem arises,
or Bitcoin might stop to exist for some other reason.

However, if I had to decide today, I would choose such a solution,
instead of relying on completely unproven mechanisms.

More important, since we need to decide about block size today, I want
to make it clear that my support is motivated by that long-term
possibility. I believe that the "we will need fee pressure" argument can
reasonably be dismissed, not because we don't know how Bitcoin will work
in 20 years, but because we know how it works today, and it is not
thanks to fee pressure.

Thomas



From adam at cypherspace.org  Tue May 26 18:47:39 2015
From: adam at cypherspace.org (Adam Back)
Date: Tue, 26 May 2015 19:47:39 +0100
Subject: [Bitcoin-development] Cost savings by using replace-by-fee,
	30-90%
In-Reply-To: <CAJN5wHV=bVgM16PPQqsOd1Qu+pALeAPmGz4-6xEV1qG6Fo+ToA@mail.gmail.com>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
	<CANEZrP0DL8yA=neK0DTq0npEqc0q+RvTQD57OndNVg0vi2=yMg@mail.gmail.com>
	<20150525212638.GB12430@savin.petertodd.org>
	<CANEZrP1k-rUBSj2GMKqOEZsOuHp=axKUSxShOiN01DorzkFODQ@mail.gmail.com>
	<20150526001034.GF21367@savin.petertodd.org>
	<CAJN5wHV=bVgM16PPQqsOd1Qu+pALeAPmGz4-6xEV1qG6Fo+ToA@mail.gmail.com>
Message-ID: <CALqxMTFJ1SKbfv2oux2oqytVGKT34cfLNkZiZsXaMiMSUU1KrA@mail.gmail.com>

The general idea for replace by fee is that it would be restricted so
as to make it safe, eg all the original addresses should receive no
less bitcoin (more addresses can be added).

The scorched earth game theory stuff (allowing removing recipients) is
kind of orthogonal.

Adam

On 26 May 2015 at 19:22, Danny Thorpe <danny.thorpe at gmail.com> wrote:
> What prevents RBF from being used for fraudulent payment reversals?
>
> Pay 1BTC to Alice for hard goods, then after you receive the goods broadcast
> a double spend of that transaction to pay Alice nothing? Your only cost is
> the higher network fee of the 2nd tx.
>
> Thanks,
> -Danny
>
> On Mon, May 25, 2015 at 5:10 PM, Peter Todd <pete at petertodd.org> wrote:
>>
>> On Tue, May 26, 2015 at 12:03:09AM +0200, Mike Hearn wrote:
>> > CPFP also solves it just fine.
>>
>> CPFP is a significantly more expensive way of paying fees than RBF,
>> particularly for the use-case of defragmenting outputs, with cost
>> savings ranging from 30% to 90%
>>
>>
>> Case 1: CPFP vs. RBF for increasing the fee on a single tx
>> ----------------------------------------------------------
>>
>> Creating an spending a P2PKH output uses 34 bytes of txout, and 148
>> bytes of txin, 182 bytes total.
>>
>> Let's suppose I have a 1 BTC P2PKH output and I want to pay 0.1 BTC to
>> Alice. This results in a 1in/2out transaction t1 that's 226 bytes in size.
>> I forget to click on the "priority fee" option, so it goes out with the
>> minimum fee of 2.26uBTC. Whoops! I use CPFP to spend that output,
>> creating a new transaction t2 that's 192 bytes in size. I want to pay
>> 1mBTC/KB for a fast confirmation, so I'm now paying 418uBTC of
>> transaction fees.
>>
>> On the other hand, had I use RBF, my wallet would have simply
>> rebroadcast t1 with the change address decreased. The rules require you
>> to pay 2.26uBTC for the bandwidth consumed broadcasting it, plus the new
>> fee level, or 218uBTC of fees in total.
>>
>> Cost savings: 48%
>>
>>
>> Case 2: Paying multiple recipients in succession
>> ------------------------------------------------
>>
>> Suppose that after I pay Alice, I also decide to pay Bob for his hard
>> work demonstrating cryptographic protocols. I need to create a new
>> transaction t2 spending t1's change address. Normally t2 would be
>> another 226 bytes in size, resulting in 226uBTC additional fees.
>>
>> With RBF on the other hand I can simply double-spend t1 with a
>> transaction paying both Alice and Bob. This new transaction is 260 bytes
>> in size. I have to pay 2.6uBTC additional fees to pay for the bandwidth
>> consumed broadcasting it, resulting in an additional 36uBTC of fees.
>>
>> Cost savings: 84%
>>
>>
>> Case 3: Paying multiple recipients from a 2-of-3 multisig wallet
>> ----------------------------------------------------------------
>>
>> The above situation gets even worse with multisig. t1 in the multisig
>> case is 367 bytes; t2 another 367 bytes, costing an additional 367uBTC
>> in fees. With RBF we rewrite t1 with an additional output, resulting in
>> a 399 byte transaction, with just 36uBTC in additional fees.
>>
>> Cost savings: 90%
>>
>>
>> Case 4: Dust defragmentation
>> ----------------------------
>>
>> My wallet has a two transaction outputs that it wants to combine into
>> one for the purpose of UTXO defragmentation. It broadcasts transaction
>> t1 with two inputs and one output, size 340 bytes, paying zero fees.
>>
>> Prior to the transaction confirming I find I need to spend those funds
>> for a priority transaction at the 1mBTC/KB fee level. This transaction,
>> t2a, has one input and two outputs, 226 bytes in size. However it needs
>> to pay fees for both transactions at once, resulting in a combined total
>> fee of 556uBTC. If this situation happens frequently, defragmenting
>> UTXOs is likely to cost more in additional fees than it saves.
>>
>> With RBF I'd simply doublespend t1 with a 2-in-2-out transaction 374
>> bytes in size, paying 374uBTC. Even better, if one of the two inputs is
>> sufficiently large to cover my costs I can doublespend t1 with a
>> 1-in-2-out tx just 226 bytes in size, paying 226uBTC.
>>
>> Cost savings: 32% to 59%, or even infinite if defragmentation w/o RBF
>>               costs you more than you save
>>
>> --
>> 'peter'[:-1]@petertodd.org
>> 0000000000000000134ce6577d4122094479f548b997baf84367eaf0c190bc9f
>>
>>
>> ------------------------------------------------------------------------------
>> One dashboard for servers and applications across Physical-Virtual-Cloud
>> Widest out-of-the-box monitoring support with 50+ applications
>> Performance metrics, stats and reports that give you Actionable Insights
>> Deep dive visibility with transaction tracing using APM Insight.
>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>



From gmaxwell at gmail.com  Tue May 26 19:10:25 2015
From: gmaxwell at gmail.com (Gregory Maxwell)
Date: Tue, 26 May 2015 19:10:25 +0000
Subject: [Bitcoin-development] First-Seen-Safe Replace-by-Fee
In-Reply-To: <5564B33D.3070107@thinlink.com>
References: <20150526051305.GA23502@savin.petertodd.org>
	<5564B33D.3070107@thinlink.com>
Message-ID: <CAAS2fgSEW9RjZ-=-XE8AkdToHjjAyzBfW6X7JjFtUbppcExbDw@mail.gmail.com>

On Tue, May 26, 2015 at 5:54 PM, Tom Harding <tomh at thinlink.com> wrote:
>  It's not difficult to
> imagine real-world consequences to not having contributed to the
> transaction.

I'm having a hard time. Can you help me understand a specific case
where this makes a difference.

It appears to be a gratuitous requirement;  if I have another unused
input that happens to be larger by the required fee-- why not just use
it?

The inherent malleability of signatures makes it unreliable to depend
on the signature content of a transaction until its good and buried,
regardless. And an inability to replace an input means you could not
RBF for additional fees without taking change in more cases; there
ought to be a benefit to that.



From raystonn at hotmail.com  Tue May 26 18:43:14 2015
From: raystonn at hotmail.com (Raystonn)
Date: Tue, 26 May 2015 11:43:14 -0700
Subject: [Bitcoin-development] Cost savings by using replace-by-fee,
	30-90%
Message-ID: <COL402-EAS4159F66FD091F6563A7C5FDCDCC0@phx.gbl>

An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150526/06a5078b/attachment.html>

From allen.piscitello at gmail.com  Tue May 26 20:12:41 2015
From: allen.piscitello at gmail.com (Allen Piscitello)
Date: Tue, 26 May 2015 15:12:41 -0500
Subject: [Bitcoin-development] Cost savings by using replace-by-fee,
	30-90%
In-Reply-To: <COL402-EAS4159F66FD091F6563A7C5FDCDCC0@phx.gbl>
References: <COL402-EAS4159F66FD091F6563A7C5FDCDCC0@phx.gbl>
Message-ID: <CAJfRnm4+VjHPj=ubcwRHs=xnb2qTYFMrKWY2LGMQqBxggZ8LUA@mail.gmail.com>

I am not the one presenting this as some kind of novel attack on
transactions in general.

On Tue, May 26, 2015 at 1:43 PM, Raystonn <raystonn at hotmail.com> wrote:

> Trust, regulation, law, and the threat of force.  Are you serious?
>  On 26 May 2015 11:38 am, Allen Piscitello <allen.piscitello at gmail.com>
> wrote:
>
> What prevents you from writing a bad check using today's systems?
>
> On Tue, May 26, 2015 at 1:22 PM, Danny Thorpe <danny.thorpe at gmail.com>
> wrote:
>
> What prevents RBF from being used for fraudulent payment reversals?
>
> Pay 1BTC to Alice for hard goods, then after you receive the goods
> broadcast a double spend of that transaction to pay Alice nothing? Your
> only cost is the higher network fee of the 2nd tx.
>
> Thanks,
> -Danny
>
> On Mon, May 25, 2015 at 5:10 PM, Peter Todd <pete at petertodd.org> wrote:
>
> On Tue, May 26, 2015 at 12:03:09AM +0200, Mike Hearn wrote:
> > CPFP also solves it just fine.
>
> CPFP is a significantly more expensive way of paying fees than RBF,
> particularly for the use-case of defragmenting outputs, with cost
> savings ranging from 30% to 90%
>
>
> Case 1: CPFP vs. RBF for increasing the fee on a single tx
> ----------------------------------------------------------
>
> Creating an spending a P2PKH output uses 34 bytes of txout, and 148
> bytes of txin, 182 bytes total.
>
> Let's suppose I have a 1 BTC P2PKH output and I want to pay 0.1 BTC to
> Alice. This results in a 1in/2out transaction t1 that's 226 bytes in size.
> I forget to click on the "priority fee" option, so it goes out with the
> minimum fee of 2.26uBTC. Whoops! I use CPFP to spend that output,
> creating a new transaction t2 that's 192 bytes in size. I want to pay
> 1mBTC/KB for a fast confirmation, so I'm now paying 418uBTC of
> transaction fees.
>
> On the other hand, had I use RBF, my wallet would have simply
> rebroadcast t1 with the change address decreased. The rules require you
> to pay 2.26uBTC for the bandwidth consumed broadcasting it, plus the new
> fee level, or 218uBTC of fees in total.
>
> Cost savings: 48%
>
>
> Case 2: Paying multiple recipients in succession
> ------------------------------------------------
>
> Suppose that after I pay Alice, I also decide to pay Bob for his hard
> work demonstrating cryptographic protocols. I need to create a new
> transaction t2 spending t1's change address. Normally t2 would be
> another 226 bytes in size, resulting in 226uBTC additional fees.
>
> With RBF on the other hand I can simply double-spend t1 with a
> transaction paying both Alice and Bob. This new transaction is 260 bytes
> in size. I have to pay 2.6uBTC additional fees to pay for the bandwidth
> consumed broadcasting it, resulting in an additional 36uBTC of fees.
>
> Cost savings: 84%
>
>
> Case 3: Paying multiple recipients from a 2-of-3 multisig wallet
> ----------------------------------------------------------------
>
> The above situation gets even worse with multisig. t1 in the multisig
> case is 367 bytes; t2 another 367 bytes, costing an additional 367uBTC
> in fees. With RBF we rewrite t1 with an additional output, resulting in
> a 399 byte transaction, with just 36uBTC in additional fees.
>
> Cost savings: 90%
>
>
> Case 4: Dust defragmentation
> ----------------------------
>
> My wallet has a two transaction outputs that it wants to combine into
> one for the purpose of UTXO defragmentation. It broadcasts transaction
> t1 with two inputs and one output, size 340 bytes, paying zero fees.
>
> Prior to the transaction confirming I find I need to spend those funds
> for a priority transaction at the 1mBTC/KB fee level. This transaction,
> t2a, has one input and two outputs, 226 bytes in size. However it needs
> to pay fees for both transactions at once, resulting in a combined total
> fee of 556uBTC. If this situation happens frequently, defragmenting
> UTXOs is likely to cost more in additional fees than it saves.
>
> With RBF I'd simply doublespend t1 with a 2-in-2-out transaction 374
> bytes in size, paying 374uBTC. Even better, if one of the two inputs is
> sufficiently large to cover my costs I can doublespend t1 with a
> 1-in-2-out tx just 226 bytes in size, paying 226uBTC.
>
> Cost savings: 32% to 59%, or even infinite if defragmentation w/o RBF
>               costs you more than you save
>
> --
> 'peter'[:-1]@petertodd.org
> 0000000000000000134ce6577d4122094479f548b997baf84367eaf0c190bc9f
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150526/0d10c771/attachment.html>

From bip at mattwhitlock.name  Tue May 26 20:18:06 2015
From: bip at mattwhitlock.name (Matt Whitlock)
Date: Tue, 26 May 2015 16:18:06 -0400
Subject: [Bitcoin-development] Cost savings by using replace-by-fee,
	30-90%
In-Reply-To: <CAJN5wHV=bVgM16PPQqsOd1Qu+pALeAPmGz4-6xEV1qG6Fo+ToA@mail.gmail.com>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
	<20150526001034.GF21367@savin.petertodd.org>
	<CAJN5wHV=bVgM16PPQqsOd1Qu+pALeAPmGz4-6xEV1qG6Fo+ToA@mail.gmail.com>
Message-ID: <2886521.cot1MDGd5p@crushinator>

On Tuesday, 26 May 2015, at 11:22 am, Danny Thorpe wrote:
> What prevents RBF from being used for fraudulent payment reversals?
> 
> Pay 1BTC to Alice for hard goods, then after you receive the goods
> broadcast a double spend of that transaction to pay Alice nothing? Your
> only cost is the higher network fee of the 2nd tx.

The "First-Seen-Safe" replace-by-fee presently being discussed on this list disallows fraudulent payment reversals, as it disallows a replacing transaction that pays less to any output script than the replaced transaction paid.



From joliver at airmail.cc  Tue May 26 20:30:48 2015
From: joliver at airmail.cc (joliver at airmail.cc)
Date: Tue, 26 May 2015 20:30:48 +0000
Subject: [Bitcoin-development] Cost savings by using replace-by-fee,
 30-90%
In-Reply-To: <20150526001034.GF21367@savin.petertodd.org>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
	<CANEZrP0DL8yA=neK0DTq0npEqc0q+RvTQD57OndNVg0vi2=yMg@mail.gmail.com>
	<20150525212638.GB12430@savin.petertodd.org>
	<CANEZrP1k-rUBSj2GMKqOEZsOuHp=axKUSxShOiN01DorzkFODQ@mail.gmail.com>
	<20150526001034.GF21367@savin.petertodd.org>
Message-ID: <475dfb44d4e54649839e6438ad748b59@airmail.cc>

You're the Chief Scientist of __ViaCoin__ a alt with 30 second blocks 
and you have big banks as clients. Shit like replace-by-fee and leading 
the anti-scaling mob is for your clients, not Bitcoin. Get the fuck out.

Peter Todd - 8930511 Canada Ltd.
1214-1423 Mississauga Valley Blvd.
Mississauga ON L5A 4A5
Canada

https://www.ic.gc.ca/app/scr/cc/CorporationsCanada/fdrlCrpDtls.html?corpId=8930511

On 2015-05-26 00:10, Peter Todd wrote:
> On Tue, May 26, 2015 at 12:03:09AM +0200, Mike Hearn wrote:
>> CPFP also solves it just fine.
> 
> CPFP is a significantly more expensive way of paying fees than RBF,
> particularly for the use-case of defragmenting outputs, with cost
> savings ranging from 30% to 90%
> 
> 
> Case 1: CPFP vs. RBF for increasing the fee on a single tx
> ----------------------------------------------------------
> 
> Creating an spending a P2PKH output uses 34 bytes of txout, and 148
> bytes of txin, 182 bytes total.
> 
> Let's suppose I have a 1 BTC P2PKH output and I want to pay 0.1 BTC to
> Alice. This results in a 1in/2out transaction t1 that's 226 bytes in 
> size.
> I forget to click on the "priority fee" option, so it goes out with the
> minimum fee of 2.26uBTC. Whoops! I use CPFP to spend that output,
> creating a new transaction t2 that's 192 bytes in size. I want to pay
> 1mBTC/KB for a fast confirmation, so I'm now paying 418uBTC of
> transaction fees.
> 
> On the other hand, had I use RBF, my wallet would have simply
> rebroadcast t1 with the change address decreased. The rules require you
> to pay 2.26uBTC for the bandwidth consumed broadcasting it, plus the 
> new
> fee level, or 218uBTC of fees in total.
> 
> Cost savings: 48%
> 
> 
> Case 2: Paying multiple recipients in succession
> ------------------------------------------------
> 
> Suppose that after I pay Alice, I also decide to pay Bob for his hard
> work demonstrating cryptographic protocols. I need to create a new
> transaction t2 spending t1's change address. Normally t2 would be
> another 226 bytes in size, resulting in 226uBTC additional fees.
> 
> With RBF on the other hand I can simply double-spend t1 with a
> transaction paying both Alice and Bob. This new transaction is 260 
> bytes
> in size. I have to pay 2.6uBTC additional fees to pay for the bandwidth
> consumed broadcasting it, resulting in an additional 36uBTC of fees.
> 
> Cost savings: 84%
> 
> 
> Case 3: Paying multiple recipients from a 2-of-3 multisig wallet
> ----------------------------------------------------------------
> 
> The above situation gets even worse with multisig. t1 in the multisig
> case is 367 bytes; t2 another 367 bytes, costing an additional 367uBTC
> in fees. With RBF we rewrite t1 with an additional output, resulting in
> a 399 byte transaction, with just 36uBTC in additional fees.
> 
> Cost savings: 90%
> 
> 
> Case 4: Dust defragmentation
> ----------------------------
> 
> My wallet has a two transaction outputs that it wants to combine into
> one for the purpose of UTXO defragmentation. It broadcasts transaction
> t1 with two inputs and one output, size 340 bytes, paying zero fees.
> 
> Prior to the transaction confirming I find I need to spend those funds
> for a priority transaction at the 1mBTC/KB fee level. This transaction,
> t2a, has one input and two outputs, 226 bytes in size. However it needs
> to pay fees for both transactions at once, resulting in a combined 
> total
> fee of 556uBTC. If this situation happens frequently, defragmenting
> UTXOs is likely to cost more in additional fees than it saves.
> 
> With RBF I'd simply doublespend t1 with a 2-in-2-out transaction 374
> bytes in size, paying 374uBTC. Even better, if one of the two inputs is
> sufficiently large to cover my costs I can doublespend t1 with a
> 1-in-2-out tx just 226 bytes in size, paying 226uBTC.
> 
> Cost savings: 32% to 59%, or even infinite if defragmentation w/o RBF
>               costs you more than you save
> 
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across 
> Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable 
> Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> 
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development



From mark at friedenbach.org  Tue May 26 20:56:06 2015
From: mark at friedenbach.org (Mark Friedenbach)
Date: Tue, 26 May 2015 13:56:06 -0700
Subject: [Bitcoin-development] Cost savings by using replace-by-fee,
	30-90%
In-Reply-To: <475dfb44d4e54649839e6438ad748b59@airmail.cc>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
	<CANEZrP0DL8yA=neK0DTq0npEqc0q+RvTQD57OndNVg0vi2=yMg@mail.gmail.com>
	<20150525212638.GB12430@savin.petertodd.org>
	<CANEZrP1k-rUBSj2GMKqOEZsOuHp=axKUSxShOiN01DorzkFODQ@mail.gmail.com>
	<20150526001034.GF21367@savin.petertodd.org>
	<475dfb44d4e54649839e6438ad748b59@airmail.cc>
Message-ID: <CAOG=w-vmYh_KJk7zpVP0=gvKTod7yYy9jhORNQJNRg=rDBHDOA@mail.gmail.com>

Please let's at least have some civility and decorum on this list.

On Tue, May 26, 2015 at 1:30 PM, <joliver at airmail.cc> wrote:

> You're the Chief Scientist of __ViaCoin__ a alt with 30 second blocks
> and you have big banks as clients. Shit like replace-by-fee and leading
> the anti-scaling mob is for your clients, not Bitcoin. Get the fuck out.
>
> Peter Todd - 8930511 Canada Ltd.
> 1214-1423 Mississauga Valley Blvd.
> Mississauga ON L5A 4A5
> Canada
>
>
> https://www.ic.gc.ca/app/scr/cc/CorporationsCanada/fdrlCrpDtls.html?corpId=8930511
>
> On 2015-05-26 00:10, Peter Todd wrote:
> > On Tue, May 26, 2015 at 12:03:09AM +0200, Mike Hearn wrote:
> >> CPFP also solves it just fine.
> >
> > CPFP is a significantly more expensive way of paying fees than RBF,
> > particularly for the use-case of defragmenting outputs, with cost
> > savings ranging from 30% to 90%
> >
> >
> > Case 1: CPFP vs. RBF for increasing the fee on a single tx
> > ----------------------------------------------------------
> >
> > Creating an spending a P2PKH output uses 34 bytes of txout, and 148
> > bytes of txin, 182 bytes total.
> >
> > Let's suppose I have a 1 BTC P2PKH output and I want to pay 0.1 BTC to
> > Alice. This results in a 1in/2out transaction t1 that's 226 bytes in
> > size.
> > I forget to click on the "priority fee" option, so it goes out with the
> > minimum fee of 2.26uBTC. Whoops! I use CPFP to spend that output,
> > creating a new transaction t2 that's 192 bytes in size. I want to pay
> > 1mBTC/KB for a fast confirmation, so I'm now paying 418uBTC of
> > transaction fees.
> >
> > On the other hand, had I use RBF, my wallet would have simply
> > rebroadcast t1 with the change address decreased. The rules require you
> > to pay 2.26uBTC for the bandwidth consumed broadcasting it, plus the
> > new
> > fee level, or 218uBTC of fees in total.
> >
> > Cost savings: 48%
> >
> >
> > Case 2: Paying multiple recipients in succession
> > ------------------------------------------------
> >
> > Suppose that after I pay Alice, I also decide to pay Bob for his hard
> > work demonstrating cryptographic protocols. I need to create a new
> > transaction t2 spending t1's change address. Normally t2 would be
> > another 226 bytes in size, resulting in 226uBTC additional fees.
> >
> > With RBF on the other hand I can simply double-spend t1 with a
> > transaction paying both Alice and Bob. This new transaction is 260
> > bytes
> > in size. I have to pay 2.6uBTC additional fees to pay for the bandwidth
> > consumed broadcasting it, resulting in an additional 36uBTC of fees.
> >
> > Cost savings: 84%
> >
> >
> > Case 3: Paying multiple recipients from a 2-of-3 multisig wallet
> > ----------------------------------------------------------------
> >
> > The above situation gets even worse with multisig. t1 in the multisig
> > case is 367 bytes; t2 another 367 bytes, costing an additional 367uBTC
> > in fees. With RBF we rewrite t1 with an additional output, resulting in
> > a 399 byte transaction, with just 36uBTC in additional fees.
> >
> > Cost savings: 90%
> >
> >
> > Case 4: Dust defragmentation
> > ----------------------------
> >
> > My wallet has a two transaction outputs that it wants to combine into
> > one for the purpose of UTXO defragmentation. It broadcasts transaction
> > t1 with two inputs and one output, size 340 bytes, paying zero fees.
> >
> > Prior to the transaction confirming I find I need to spend those funds
> > for a priority transaction at the 1mBTC/KB fee level. This transaction,
> > t2a, has one input and two outputs, 226 bytes in size. However it needs
> > to pay fees for both transactions at once, resulting in a combined
> > total
> > fee of 556uBTC. If this situation happens frequently, defragmenting
> > UTXOs is likely to cost more in additional fees than it saves.
> >
> > With RBF I'd simply doublespend t1 with a 2-in-2-out transaction 374
> > bytes in size, paying 374uBTC. Even better, if one of the two inputs is
> > sufficiently large to cover my costs I can doublespend t1 with a
> > 1-in-2-out tx just 226 bytes in size, paying 226uBTC.
> >
> > Cost savings: 32% to 59%, or even infinite if defragmentation w/o RBF
> >               costs you more than you save
> >
> >
> ------------------------------------------------------------------------------
> > One dashboard for servers and applications across
> > Physical-Virtual-Cloud
> > Widest out-of-the-box monitoring support with 50+ applications
> > Performance metrics, stats and reports that give you Actionable
> > Insights
> > Deep dive visibility with transaction tracing using APM Insight.
> > http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> >
> > _______________________________________________
> > Bitcoin-development mailing list
> > Bitcoin-development at lists.sourceforge.net
> > https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
> ------------------------------------------------------------------------------
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150526/38c108d3/attachment.html>

From danny.thorpe at gmail.com  Tue May 26 21:20:35 2015
From: danny.thorpe at gmail.com (Danny Thorpe)
Date: Tue, 26 May 2015 14:20:35 -0700
Subject: [Bitcoin-development] First-Seen-Safe Replace-by-Fee
In-Reply-To: <20150526051305.GA23502@savin.petertodd.org>
References: <20150526051305.GA23502@savin.petertodd.org>
Message-ID: <CAJN5wHXRMfZigtgJ4JTKqRMkoQgkZ-d8sZ5rkpspqySwFEQEKg@mail.gmail.com>

Apologies if this has already been stated and I missed it, but:

Can transactions in a buried block be overridden/replaced by RBF?

Or is RBF strictly limited to transactions that have not yet been
incorporated into a block?

Thanks,
-Danny

On Mon, May 25, 2015 at 10:13 PM, Peter Todd <pete at petertodd.org> wrote:

> Summary
> -------
>
> First-seen-safe replace-by-fee (FSS RBF) does the following:
>
> 1) Give users effective ways of getting "stuck" transactions unstuck.
> 2) Use blockchain space efficiently.
>
> without:
>
> 3) Changing the status quo with regard to zeroconf.
>
> The current Bitcoin Core implementation has "first-seen" mempool
> behavior. Once transaction t1 has been accepted, the transaction is
> never removed from the mempool until mined, or double-spent by a
> transaction in a block. The author's previously proposed replace-by-fee
> replaced this behavior with simply accepting the transaction paying the
> highest fee.
>
> FSS RBF is a compromise between these two behaviors. Transactions may be
> replaced by higher-fee paying transactions, provided that all outputs in
> the previous transaction are still paid by the replacement. While not as
> general as standard RBF, and with higher costs than standard RBF, this
> still allows fees on transaction to be increased after the fact with
> less cost and higher efficiency than child-pays-for-parent in many
> common situations; in some situations CPFP is unusable, leaving RBF as
> the only option.
>
>
> Semantics
> ---------
>
> For reference, standard replace-by-fee has the following criteria for
> determining whether to replace a transaction.
>
> 1) t2 pays > fees than t1
>
> 2) The delta fees pay by t2, t2.fee - t1.fee, are >= the minimum fee
>    required to relay t2. (t2.size * min_fee_per_kb)
>
> 3) t2 pays more fees/kb than t1
>
> FSS RBF adds the following additional criteria to replace-by-fee before
> allowing a transaction t1 to be replaced with t2:
>
> 1) All outputs of t1 exist in t2 and pay >= the value in t1.
>
> 2) All outputs of t1 are unspent.
>
> 3) The order of outputs in t2 is the same as in t1 with additional new
>    outputs at the end of the output list.
>
> 4) t2 only conflicts with a single transaction, t1
>
> 5) t2 does not spend any outputs of t1 (which would make it an invalid
>    transaction, impossible to mine)
>
> These additional criteria respect the existing "first-seen" behavior of
> the Bitcoin Core mempool implementation, such that once an address is
> payed some amount of BTC, all subsequent replacement transactions will
> pay an equal or greater amount. In short, FSS-RBF is "zeroconf safe" and
> has no affect on the ability of attackers to doublespend. (beyond of
> course the fact that any changes what-so-ever to mempool behavior are
> potential zeroconf doublespend vulnerabilities)
>
>
> Implementation
> --------------
>
> Pull-req for git HEAD: https://github.com/bitcoin/bitcoin/pull/6176
>
> A backport to v0.10.2 is pending.
>
> An implementation of fee bumping respecting FSS rules is available at:
>
> https://github.com/petertodd/replace-by-fee-tools/blob/master/bump-fee.py
>
>
> Usage Scenarios
> ---------------
>
> Case 1: Increasing the fee on a single tx
> -----------------------------------------
>
> We start with a 1-in-2-out P2PKH using transaction t1, 226 bytes in size
> with the minimal relay fee, 2.26uBTC. Increasing the fee while
> respecting FSS-RBF rules requires the addition of one more txin, with
> the change output value increased appropriately, resulting in
> transaction t2, size 374 bytes. If the change txout is sufficient for
> the fee increase, increasing the fee via CPFP requires a second
> 1-in-1-out transaction, 192 bytes, for a total of 418 bytes; if another
> input is required, CPFP requires a 2-in-1-out tx, 340 bytes, for a total
> of 566 bytes.
>
> Benefits: 11% to 34%+ cost savings, and RBF can increase fees even in
>           cases where the original transaction didn't have a change
>           output.
>
>
> Case 2: Paying multiple recipients in succession
> ------------------------------------------------
>
> We have a 1-in-2-out P2PKH transaction t1, 226 bytes, that pays Alice.
> We now need to pay Bob. With plain RBF we'd just add a new outptu and
> reduce the value of the change address, a 90% savings. However with FSS
> RBF, decreasing the value is not allowed, so we have to add an input.
>
> If the change of t1 is sufficient to pay Bob, a second 1-in-2-out tx can
> be created, 2*226=452 bytes in total. With FSS RBF we can replace t1
> with a 2-in-3-out tx paying both, increasing the value of the change
> output appropriately, resulting in 408 bytes transaction saving 10%
>
> Similar to the above example in the case where the change address of t1
> is insufficient to pay Bob the end result is one less transaction output
> in the wallet, defragmenting it. Spending these outputs later on would
> require two 148 byte inputs compared to one with RBF, resulting in an
> overall savings of 25%
>
>
> Case 3: Paying the same recipient multiple times
> ------------------------------------------------
>
> For example, consider the situation of an exchange, Acme Bitcoin Sales,
> that keeps the majority of coins in cold storage. Acme wants to move
> funds to cold storage at the lowest possible cost, taking advantage of
> periods of higher capacity. (inevitable due to the poisson nature of
> block creation) At the same time they would like to defragment their
> incoming outputs to keep redemption costs low, particularly since
> spending their high-security 3-of-7 P2SH multisigs is expensive. Acme
> creates a low fee transaction with a single output to cold storage,
> periodically adding new inputs as funds need to be moved to storage.
> Estimating the cost savings here is complex, and depends greatly on
> details of Acme's business, but regardless the approach works from a
> technical point of view. For instance if Acme's business is such that
> the total hotwallet size needed heavily depends on external factors like
> volatility, as hotwallet demand decreases throughout a day they can add
> inputs to the pending transaction. (simply asking customers to deposit
> funds directly to the cold storage is also a useful strategy)
>
> However this is another case where standard RBF is significantly more
> useful. For instance, as withdrawal requests come in the exchange can
> quickly replace their pending transactions sending funds to cold storage
> with transactions sending those funds to customers instead, each time
> avoiding multiple costly transactions. In particular, by reducing the
> need to access cold storage at all, the security of the cold-stored
> funds is increased.
>
>
> Wallet Compatibility
> --------------------
>
> All wallets should treat conflicting incoming transactions as equivalent
> so long as the transaction outputs owned by them do not change. In
> addition to compatibility with RBF-related practices, this prevents
> unnecessary user concern if transactions are mutated. Wallets must not
> assume TXIDs are fixed until confirmed in the blockchain; a fixed TXID
> is not guaranteed by the Bitcoin protocol.
>
> --
> 'peter'[:-1]@petertodd.org
> 00000000000000000c7ea0fcac58a9d7267fef8551b9d6a5206bf42b849618cb
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150526/833cbbca/attachment.html>

From pieter.wuille at gmail.com  Tue May 26 21:27:04 2015
From: pieter.wuille at gmail.com (Pieter Wuille)
Date: Tue, 26 May 2015 14:27:04 -0700
Subject: [Bitcoin-development] First-Seen-Safe Replace-by-Fee
In-Reply-To: <CAJN5wHXRMfZigtgJ4JTKqRMkoQgkZ-d8sZ5rkpspqySwFEQEKg@mail.gmail.com>
References: <20150526051305.GA23502@savin.petertodd.org>
	<CAJN5wHXRMfZigtgJ4JTKqRMkoQgkZ-d8sZ5rkpspqySwFEQEKg@mail.gmail.com>
Message-ID: <CAPg+sBisM6FVEDo0uqgvFwVxB71r_f4T5bAr91esv9r78wf6wA@mail.gmail.com>

It's just a mempool policy rule.

Allowing the contents of blocks to change (other than by mining a competing
chain) would be pretty much the largest possible change to Bitcoin's
design....
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150526/f6aef9dd/attachment.html>

From s7r at sky-ip.org  Tue May 26 21:29:28 2015
From: s7r at sky-ip.org (s7r)
Date: Wed, 27 May 2015 00:29:28 +0300
Subject: [Bitcoin-development] Cost savings by using replace-by-fee,
	30-90%
In-Reply-To: <475dfb44d4e54649839e6438ad748b59@airmail.cc>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>	<CANEZrP0DL8yA=neK0DTq0npEqc0q+RvTQD57OndNVg0vi2=yMg@mail.gmail.com>	<20150525212638.GB12430@savin.petertodd.org>	<CANEZrP1k-rUBSj2GMKqOEZsOuHp=axKUSxShOiN01DorzkFODQ@mail.gmail.com>	<20150526001034.GF21367@savin.petertodd.org>
	<475dfb44d4e54649839e6438ad748b59@airmail.cc>
Message-ID: <5564E5B8.3090802@sky-ip.org>

What is wrong with the man testing some ideas on his custom branch? This
is how improvements come to life. I saw in the BIPs some really
interesting ideas and nice brainstorming which came from Peter Todd.

Now, my question, if replace by fee doesn't allow me to change the
inputs or the outputs, I can only add outputs... what can I do with this
feature? If I sent a tx and want to replace it with a higher fee one,
the higher fee one can only have maybe additional change addresses or
another payment, if the inputs suffice? Do we have any real use cases?

P.S. is it planned to include this by default in bitcoin core 10.0.3 or
it will remain just on Peter's branch?

On 5/26/2015 11:30 PM, joliver at airmail.cc wrote:
> You're the Chief Scientist of __ViaCoin__ a alt with 30 second blocks 
> and you have big banks as clients. Shit like replace-by-fee and leading 
> the anti-scaling mob is for your clients, not Bitcoin. Get the fuck out.
> 
> Peter Todd - 8930511 Canada Ltd.
> 1214-1423 Mississauga Valley Blvd.
> Mississauga ON L5A 4A5
> Canada
> 
> https://www.ic.gc.ca/app/scr/cc/CorporationsCanada/fdrlCrpDtls.html?corpId=8930511
> 
> On 2015-05-26 00:10, Peter Todd wrote:
>> On Tue, May 26, 2015 at 12:03:09AM +0200, Mike Hearn wrote:
>>> CPFP also solves it just fine.
>>
>> CPFP is a significantly more expensive way of paying fees than RBF,
>> particularly for the use-case of defragmenting outputs, with cost
>> savings ranging from 30% to 90%
>>
>>
>> Case 1: CPFP vs. RBF for increasing the fee on a single tx
>> ----------------------------------------------------------
>>
>> Creating an spending a P2PKH output uses 34 bytes of txout, and 148
>> bytes of txin, 182 bytes total.
>>
>> Let's suppose I have a 1 BTC P2PKH output and I want to pay 0.1 BTC to
>> Alice. This results in a 1in/2out transaction t1 that's 226 bytes in 
>> size.
>> I forget to click on the "priority fee" option, so it goes out with the
>> minimum fee of 2.26uBTC. Whoops! I use CPFP to spend that output,
>> creating a new transaction t2 that's 192 bytes in size. I want to pay
>> 1mBTC/KB for a fast confirmation, so I'm now paying 418uBTC of
>> transaction fees.
>>
>> On the other hand, had I use RBF, my wallet would have simply
>> rebroadcast t1 with the change address decreased. The rules require you
>> to pay 2.26uBTC for the bandwidth consumed broadcasting it, plus the 
>> new
>> fee level, or 218uBTC of fees in total.
>>
>> Cost savings: 48%
>>
>>
>> Case 2: Paying multiple recipients in succession
>> ------------------------------------------------
>>
>> Suppose that after I pay Alice, I also decide to pay Bob for his hard
>> work demonstrating cryptographic protocols. I need to create a new
>> transaction t2 spending t1's change address. Normally t2 would be
>> another 226 bytes in size, resulting in 226uBTC additional fees.
>>
>> With RBF on the other hand I can simply double-spend t1 with a
>> transaction paying both Alice and Bob. This new transaction is 260 
>> bytes
>> in size. I have to pay 2.6uBTC additional fees to pay for the bandwidth
>> consumed broadcasting it, resulting in an additional 36uBTC of fees.
>>
>> Cost savings: 84%
>>
>>
>> Case 3: Paying multiple recipients from a 2-of-3 multisig wallet
>> ----------------------------------------------------------------
>>
>> The above situation gets even worse with multisig. t1 in the multisig
>> case is 367 bytes; t2 another 367 bytes, costing an additional 367uBTC
>> in fees. With RBF we rewrite t1 with an additional output, resulting in
>> a 399 byte transaction, with just 36uBTC in additional fees.
>>
>> Cost savings: 90%
>>
>>
>> Case 4: Dust defragmentation
>> ----------------------------
>>
>> My wallet has a two transaction outputs that it wants to combine into
>> one for the purpose of UTXO defragmentation. It broadcasts transaction
>> t1 with two inputs and one output, size 340 bytes, paying zero fees.
>>
>> Prior to the transaction confirming I find I need to spend those funds
>> for a priority transaction at the 1mBTC/KB fee level. This transaction,
>> t2a, has one input and two outputs, 226 bytes in size. However it needs
>> to pay fees for both transactions at once, resulting in a combined 
>> total
>> fee of 556uBTC. If this situation happens frequently, defragmenting
>> UTXOs is likely to cost more in additional fees than it saves.
>>
>> With RBF I'd simply doublespend t1 with a 2-in-2-out transaction 374
>> bytes in size, paying 374uBTC. Even better, if one of the two inputs is
>> sufficiently large to cover my costs I can doublespend t1 with a
>> 1-in-2-out tx just 226 bytes in size, paying 226uBTC.
>>
>> Cost savings: 32% to 59%, or even infinite if defragmentation w/o RBF
>>               costs you more than you save
>>
>> ------------------------------------------------------------------------------
>> One dashboard for servers and applications across 
>> Physical-Virtual-Cloud
>> Widest out-of-the-box monitoring support with 50+ applications
>> Performance metrics, stats and reports that give you Actionable 
>> Insights
>> Deep dive visibility with transaction tracing using APM Insight.
>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>>
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> 
> ------------------------------------------------------------------------------
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> 



From adam at cypherspace.org  Tue May 26 22:06:42 2015
From: adam at cypherspace.org (Adam Back)
Date: Tue, 26 May 2015 23:06:42 +0100
Subject: [Bitcoin-development] Cost savings by using replace-by-fee,
	30-90%
In-Reply-To: <5564E5B8.3090802@sky-ip.org>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
	<CANEZrP0DL8yA=neK0DTq0npEqc0q+RvTQD57OndNVg0vi2=yMg@mail.gmail.com>
	<20150525212638.GB12430@savin.petertodd.org>
	<CANEZrP1k-rUBSj2GMKqOEZsOuHp=axKUSxShOiN01DorzkFODQ@mail.gmail.com>
	<20150526001034.GF21367@savin.petertodd.org>
	<475dfb44d4e54649839e6438ad748b59@airmail.cc>
	<5564E5B8.3090802@sky-ip.org>
Message-ID: <CALqxMTH3N2fwcVYhpVE0ovWm3sOMmqGceR3JKLSekDu_s9vhgA@mail.gmail.com>

Well so for example it could have an additional input (to increase the
BTC paid into the transaction) and pay more to an existing change
address and higher fee, or add an additional change address, and leave
a larger fee, or if you had a right-sized coin add an additional input
that all goes to fees.

(As well as optionally tacking on additional pending payments to other
addresses funded from the higher input).

Adam

On 26 May 2015 at 22:29, s7r <s7r at sky-ip.org> wrote:
> What is wrong with the man testing some ideas on his custom branch? This
> is how improvements come to life. I saw in the BIPs some really
> interesting ideas and nice brainstorming which came from Peter Todd.
>
> Now, my question, if replace by fee doesn't allow me to change the
> inputs or the outputs, I can only add outputs... what can I do with this
> feature? If I sent a tx and want to replace it with a higher fee one,
> the higher fee one can only have maybe additional change addresses or
> another payment, if the inputs suffice? Do we have any real use cases?
>
> P.S. is it planned to include this by default in bitcoin core 10.0.3 or
> it will remain just on Peter's branch?
>
> On 5/26/2015 11:30 PM, joliver at airmail.cc wrote:
>> You're the Chief Scientist of __ViaCoin__ a alt with 30 second blocks
>> and you have big banks as clients. Shit like replace-by-fee and leading
>> the anti-scaling mob is for your clients, not Bitcoin. Get the fuck out.
>>
>> Peter Todd - 8930511 Canada Ltd.
>> 1214-1423 Mississauga Valley Blvd.
>> Mississauga ON L5A 4A5
>> Canada
>>
>> https://www.ic.gc.ca/app/scr/cc/CorporationsCanada/fdrlCrpDtls.html?corpId=8930511
>>
>> On 2015-05-26 00:10, Peter Todd wrote:
>>> On Tue, May 26, 2015 at 12:03:09AM +0200, Mike Hearn wrote:
>>>> CPFP also solves it just fine.
>>>
>>> CPFP is a significantly more expensive way of paying fees than RBF,
>>> particularly for the use-case of defragmenting outputs, with cost
>>> savings ranging from 30% to 90%
>>>
>>>
>>> Case 1: CPFP vs. RBF for increasing the fee on a single tx
>>> ----------------------------------------------------------
>>>
>>> Creating an spending a P2PKH output uses 34 bytes of txout, and 148
>>> bytes of txin, 182 bytes total.
>>>
>>> Let's suppose I have a 1 BTC P2PKH output and I want to pay 0.1 BTC to
>>> Alice. This results in a 1in/2out transaction t1 that's 226 bytes in
>>> size.
>>> I forget to click on the "priority fee" option, so it goes out with the
>>> minimum fee of 2.26uBTC. Whoops! I use CPFP to spend that output,
>>> creating a new transaction t2 that's 192 bytes in size. I want to pay
>>> 1mBTC/KB for a fast confirmation, so I'm now paying 418uBTC of
>>> transaction fees.
>>>
>>> On the other hand, had I use RBF, my wallet would have simply
>>> rebroadcast t1 with the change address decreased. The rules require you
>>> to pay 2.26uBTC for the bandwidth consumed broadcasting it, plus the
>>> new
>>> fee level, or 218uBTC of fees in total.
>>>
>>> Cost savings: 48%
>>>
>>>
>>> Case 2: Paying multiple recipients in succession
>>> ------------------------------------------------
>>>
>>> Suppose that after I pay Alice, I also decide to pay Bob for his hard
>>> work demonstrating cryptographic protocols. I need to create a new
>>> transaction t2 spending t1's change address. Normally t2 would be
>>> another 226 bytes in size, resulting in 226uBTC additional fees.
>>>
>>> With RBF on the other hand I can simply double-spend t1 with a
>>> transaction paying both Alice and Bob. This new transaction is 260
>>> bytes
>>> in size. I have to pay 2.6uBTC additional fees to pay for the bandwidth
>>> consumed broadcasting it, resulting in an additional 36uBTC of fees.
>>>
>>> Cost savings: 84%
>>>
>>>
>>> Case 3: Paying multiple recipients from a 2-of-3 multisig wallet
>>> ----------------------------------------------------------------
>>>
>>> The above situation gets even worse with multisig. t1 in the multisig
>>> case is 367 bytes; t2 another 367 bytes, costing an additional 367uBTC
>>> in fees. With RBF we rewrite t1 with an additional output, resulting in
>>> a 399 byte transaction, with just 36uBTC in additional fees.
>>>
>>> Cost savings: 90%
>>>
>>>
>>> Case 4: Dust defragmentation
>>> ----------------------------
>>>
>>> My wallet has a two transaction outputs that it wants to combine into
>>> one for the purpose of UTXO defragmentation. It broadcasts transaction
>>> t1 with two inputs and one output, size 340 bytes, paying zero fees.
>>>
>>> Prior to the transaction confirming I find I need to spend those funds
>>> for a priority transaction at the 1mBTC/KB fee level. This transaction,
>>> t2a, has one input and two outputs, 226 bytes in size. However it needs
>>> to pay fees for both transactions at once, resulting in a combined
>>> total
>>> fee of 556uBTC. If this situation happens frequently, defragmenting
>>> UTXOs is likely to cost more in additional fees than it saves.
>>>
>>> With RBF I'd simply doublespend t1 with a 2-in-2-out transaction 374
>>> bytes in size, paying 374uBTC. Even better, if one of the two inputs is
>>> sufficiently large to cover my costs I can doublespend t1 with a
>>> 1-in-2-out tx just 226 bytes in size, paying 226uBTC.
>>>
>>> Cost savings: 32% to 59%, or even infinite if defragmentation w/o RBF
>>>               costs you more than you save
>>>
>>> ------------------------------------------------------------------------------
>>> One dashboard for servers and applications across
>>> Physical-Virtual-Cloud
>>> Widest out-of-the-box monitoring support with 50+ applications
>>> Performance metrics, stats and reports that give you Actionable
>>> Insights
>>> Deep dive visibility with transaction tracing using APM Insight.
>>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>>>
>>> _______________________________________________
>>> Bitcoin-development mailing list
>>> Bitcoin-development at lists.sourceforge.net
>>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>> ------------------------------------------------------------------------------
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>
> ------------------------------------------------------------------------------
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development



From danny.thorpe at gmail.com  Tue May 26 22:09:35 2015
From: danny.thorpe at gmail.com (Danny Thorpe)
Date: Tue, 26 May 2015 15:09:35 -0700
Subject: [Bitcoin-development] First-Seen-Safe Replace-by-Fee
In-Reply-To: <CAPg+sBisM6FVEDo0uqgvFwVxB71r_f4T5bAr91esv9r78wf6wA@mail.gmail.com>
References: <20150526051305.GA23502@savin.petertodd.org>
	<CAJN5wHXRMfZigtgJ4JTKqRMkoQgkZ-d8sZ5rkpspqySwFEQEKg@mail.gmail.com>
	<CAPg+sBisM6FVEDo0uqgvFwVxB71r_f4T5bAr91esv9r78wf6wA@mail.gmail.com>
Message-ID: <CAJN5wHVq67m-fDZLwkHhjtsoDdqP70DKMziuM7RueazQ=+tdhg@mail.gmail.com>

Thanks for the clarification.

So, since RBF applies only to pending transactions in the mempool awaiting
incorporation into a block, there is a window of opportunity in which the
pending tx is incorporated into a block at the same time that the spender
is constructing and publishing a replacement for that pending tx.

The replacement transaction would be rejected by the peer network as a
double spend because it conflicts with the now confirmed original tx, and
the spender will have to go back and create a new stand-alone transaction
to accomplish what they hoped to do with an RBF replacement.

So an implementation that wishes to take advantage of RBF will still need
to have a "plan B" implementation path to handle the corner case of a
replacement tx being rejected as a double spend.

Is this correct?

I'm just trying to get my head around the implementation cost vs benefit of
RBF in the context of my applications.

Thanks,
-Danny

On Tue, May 26, 2015 at 2:27 PM, Pieter Wuille <pieter.wuille at gmail.com>
wrote:

> It's just a mempool policy rule.
>
> Allowing the contents of blocks to change (other than by mining a
> competing chain) would be pretty much the largest possible change to
> Bitcoin's design....
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150526/ac340045/attachment.html>

From adam at cypherspace.org  Tue May 26 22:18:42 2015
From: adam at cypherspace.org (Adam Back)
Date: Tue, 26 May 2015 23:18:42 +0100
Subject: [Bitcoin-development] First-Seen-Safe Replace-by-Fee
In-Reply-To: <CAJN5wHVq67m-fDZLwkHhjtsoDdqP70DKMziuM7RueazQ=+tdhg@mail.gmail.com>
References: <20150526051305.GA23502@savin.petertodd.org>
	<CAJN5wHXRMfZigtgJ4JTKqRMkoQgkZ-d8sZ5rkpspqySwFEQEKg@mail.gmail.com>
	<CAPg+sBisM6FVEDo0uqgvFwVxB71r_f4T5bAr91esv9r78wf6wA@mail.gmail.com>
	<CAJN5wHVq67m-fDZLwkHhjtsoDdqP70DKMziuM7RueazQ=+tdhg@mail.gmail.com>
Message-ID: <CALqxMTHq1E3XPggF_-CmWb15rz6VU0HEmbxLutrZ8NCLyQ77sQ@mail.gmail.com>

I think the point is the replacement tx spends the same inputs (plus
additional inputs), so if the original tx is accepted, and your
replacement rejected, thats good news - you dont have to pay the
higher fee, the extra input remains unspent (and can be used later for
other purpose) and the extra change address is unused.

(If you had bundled extra transactions into the replacement, spending
from the additional inputs, then you'll need to resubmit those as a
separate transaction).

(You have to keep in mind re-orgs so for example the original tx could
be put into a block, and then that block could get reorged by another
block that grows into a longer chain with the replacement tx in it (or
vice versa)).

Adam

On 26 May 2015 at 23:09, Danny Thorpe <danny.thorpe at gmail.com> wrote:
> Thanks for the clarification.
>
> So, since RBF applies only to pending transactions in the mempool awaiting
> incorporation into a block, there is a window of opportunity in which the
> pending tx is incorporated into a block at the same time that the spender is
> constructing and publishing a replacement for that pending tx.
>
> The replacement transaction would be rejected by the peer network as a
> double spend because it conflicts with the now confirmed original tx, and
> the spender will have to go back and create a new stand-alone transaction to
> accomplish what they hoped to do with an RBF replacement.
>
> So an implementation that wishes to take advantage of RBF will still need to
> have a "plan B" implementation path to handle the corner case of a
> replacement tx being rejected as a double spend.
>
> Is this correct?
>
> I'm just trying to get my head around the implementation cost vs benefit of
> RBF in the context of my applications.
>
> Thanks,
> -Danny
>
> On Tue, May 26, 2015 at 2:27 PM, Pieter Wuille <pieter.wuille at gmail.com>
> wrote:
>>
>> It's just a mempool policy rule.
>>
>> Allowing the contents of blocks to change (other than by mining a
>> competing chain) would be pretty much the largest possible change to
>> Bitcoin's design....
>
>
>
> ------------------------------------------------------------------------------
>
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>



From jgarzik at bitpay.com  Tue May 26 22:29:40 2015
From: jgarzik at bitpay.com (Jeff Garzik)
Date: Tue, 26 May 2015 18:29:40 -0400
Subject: [Bitcoin-development] Cost savings by using replace-by-fee,
	30-90%
In-Reply-To: <475dfb44d4e54649839e6438ad748b59@airmail.cc>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
	<CANEZrP0DL8yA=neK0DTq0npEqc0q+RvTQD57OndNVg0vi2=yMg@mail.gmail.com>
	<20150525212638.GB12430@savin.petertodd.org>
	<CANEZrP1k-rUBSj2GMKqOEZsOuHp=axKUSxShOiN01DorzkFODQ@mail.gmail.com>
	<20150526001034.GF21367@savin.petertodd.org>
	<475dfb44d4e54649839e6438ad748b59@airmail.cc>
Message-ID: <CAJHLa0MYViRFsXEO=cNzssg98ngBF0x92pJrjJ0TKjyiBcNtSw@mail.gmail.com>

That attitude and doxxing is not appropriate for this list.


On Tue, May 26, 2015 at 4:30 PM, <joliver at airmail.cc> wrote:

> You're the Chief Scientist of __ViaCoin__ a alt with 30 second blocks
> and you have big banks as clients. Shit like replace-by-fee and leading
> the anti-scaling mob is for your clients, not Bitcoin. Get the fuck out.
> <https://lists.sourceforge.net/lists/listinfo/bitcoin-development>
>



-- 
Jeff Garzik
Bitcoin core developer and open source evangelist
BitPay, Inc.      https://bitpay.com/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150526/74d8851a/attachment.html>

From tomh at thinlink.com  Tue May 26 23:00:01 2015
From: tomh at thinlink.com (Tom Harding)
Date: Tue, 26 May 2015 16:00:01 -0700
Subject: [Bitcoin-development] First-Seen-Safe Replace-by-Fee
In-Reply-To: <CAAS2fgSEW9RjZ-=-XE8AkdToHjjAyzBfW6X7JjFtUbppcExbDw@mail.gmail.com>
References: <20150526051305.GA23502@savin.petertodd.org>	<5564B33D.3070107@thinlink.com>
	<CAAS2fgSEW9RjZ-=-XE8AkdToHjjAyzBfW6X7JjFtUbppcExbDw@mail.gmail.com>
Message-ID: <5564FAF1.1050907@thinlink.com>

On 5/26/2015 12:10 PM, Gregory Maxwell wrote:
> On Tue, May 26, 2015 at 5:54 PM, Tom Harding <tomh at thinlink.com> wrote:
>>   It's not difficult to
>> imagine real-world consequences to not having contributed to the
>> transaction.
> I'm having a hard time. Can you help me understand a specific case
> where this makes a difference.
>

The bitcoin transaction is part of a real-world "deal" with unknown 
connections to the other parts.  New inputs combined with new or 
increased outputs can be thought of as a second deal sharing the same 
envelope. That's not the case if paying parties are kicked out of the 
deal, and possibly don't learn about it right away.

A subset of parties to an Armory simulfunding transaction (an actual 
multi-input use case) could replace one signer's input after they 
broadcast it.  Whether that's a problem depends on real-world 
connections.  Maybe the receiver cares where he is paid from or is 
basing a subsequent decision on it.  Maybe a new output is being added, 
whose presence makes the transaction less likely to be confirmed 
quickly, with that speed affecting the business.

With Kalle's Proof of Payment proposed standard, one payer in a 
two-input transaction could decide to boot the other, and claim the 
concert tickets all for himself.  The fact that he pays is not the only 
consideration in the real world -- what if these are the last 2 tickets?

Mempool policy shouldn't help one payer make a unilateral decision to 
become the sole party to a deal after various parties have seen it 
broadcast.


> The inherent malleability of signatures makes it unreliable to depend
> on the signature content of a transaction until its good and buried,
> regardless.

I'd argue that changing how an input is signed doesn't change the deal.  
For example if a different 2 of 3 multisig participants sign, those 3 
people gave up that level of control when they created the multisig.

Replacement is new - we have a choice what kind of warnings we need to 
give to signers of multi-input transactions.  IMHO we should avoid 
needing a stronger warning than is already needed for 0-conf.





From gmaxwell at gmail.com  Tue May 26 23:11:17 2015
From: gmaxwell at gmail.com (Gregory Maxwell)
Date: Tue, 26 May 2015 23:11:17 +0000
Subject: [Bitcoin-development] First-Seen-Safe Replace-by-Fee
In-Reply-To: <5564FAF1.1050907@thinlink.com>
References: <20150526051305.GA23502@savin.petertodd.org>
	<5564B33D.3070107@thinlink.com>
	<CAAS2fgSEW9RjZ-=-XE8AkdToHjjAyzBfW6X7JjFtUbppcExbDw@mail.gmail.com>
	<5564FAF1.1050907@thinlink.com>
Message-ID: <CAAS2fgRDF-p3-4CruCXkNtV3tDTQLUx3x+Dq7WN7WnQJdBtu3A@mail.gmail.com>

On Tue, May 26, 2015 at 11:00 PM, Tom Harding <tomh at thinlink.com> wrote:
> The bitcoin transaction is part of a real-world "deal" with unknown
> connections to the other parts

I'm having a hard time parsing this.  You might as well say that its
part of a weeblix for how informative it is, since you've not defined
it.

> not the case if paying parties are kicked out of the deal, and possibly
> don't learn about it right away.

The signatures of a transaction can always be changed any any time,
including by the miner, as they're not signed.

> A subset of parties to an Armory simulfunding transaction (an actual
> multi-input use case) could replace one signer's input after they broadcast
> it.

They can already do this.

> Maybe the
> receiver cares where he is paid from or is basing a subsequent decision on
> it.  Maybe a new output is being added, whose presence makes the transaction
> less likely to be confirmed quickly, with that speed affecting the business.

The RBF behavior always moves in the direction of more prefered or
otherwise the node would not switch to the replacement. Petertodd
should perhaps make that more clear.

But your "maybe"s are what I was asking you to clarify. You said it
wasn't hard to imagine; so I was asking for specific clarification.

> With Kalle's Proof of Payment proposed standard, one payer in a two-input
> transaction could decide to boot the other, and claim the concert tickets
> all for himself.  The fact that he pays is not the only consideration in the
> real world -- what if these are the last 2 tickets?

They can already do that.

> I'd argue that changing how an input is signed doesn't change the deal.  For
> example if a different 2 of 3 multisig participants sign, those 3 people
> gave up that level of control when they created the multisig.

Then why do you not argue that changing the input set does not change
the weeblix?

Why is one case of writing out a participant different that the other
case of writing out a participant?

> Replacement is new - we have a choice what kind of warnings we need to give
> to signers of multi-input transactions.  IMHO we should avoid needing a
> stronger warning than is already needed for 0-conf.

How could a _stronger_ warning be required?



From tomh at thinlink.com  Tue May 26 23:42:23 2015
From: tomh at thinlink.com (Tom Harding)
Date: Tue, 26 May 2015 16:42:23 -0700
Subject: [Bitcoin-development] First-Seen-Safe Replace-by-Fee
In-Reply-To: <CAAS2fgRDF-p3-4CruCXkNtV3tDTQLUx3x+Dq7WN7WnQJdBtu3A@mail.gmail.com>
References: <20150526051305.GA23502@savin.petertodd.org>	<5564B33D.3070107@thinlink.com>	<CAAS2fgSEW9RjZ-=-XE8AkdToHjjAyzBfW6X7JjFtUbppcExbDw@mail.gmail.com>	<5564FAF1.1050907@thinlink.com>
	<CAAS2fgRDF-p3-4CruCXkNtV3tDTQLUx3x+Dq7WN7WnQJdBtu3A@mail.gmail.com>
Message-ID: <556504DF.7060309@thinlink.com>

On 5/26/2015 4:11 PM, Gregory Maxwell wrote:
> On Tue, May 26, 2015 at 11:00 PM, Tom Harding <tomh at thinlink.com> wrote:
>> The bitcoin transaction is part of a real-world "deal" with unknown
>> connections to the other parts
> I'm having a hard time parsing this.  You might as well say that its
> part of a weeblix for how informative it is, since you've not defined
> it.

For example, you are paying for concert tickets.  The deal is concert 
tickets for bitcoin.  Or you're buying a company with 3 other investors.


>> not the case if paying parties are kicked out of the deal, and possibly
>> don't learn about it right away.
> The signatures of a transaction can always be changed any any time,
> including by the miner, as they're not signed.

Miners can't update the signature on input #0 after removing input #1.


>
>> A subset of parties to an Armory simulfunding transaction (an actual
>> multi-input use case) could replace one signer's input after they broadcast
>> it.
> They can already do this.

Replacement is about how difficult it is to change the tx after it is 
broadcast and seen by observers.


>> Maybe the
>> receiver cares where he is paid from or is basing a subsequent decision on
>> it.  Maybe a new output is being added, whose presence makes the transaction
>> less likely to be confirmed quickly, with that speed affecting the business.
> The RBF behavior always moves in the direction of more prefered or
> otherwise the node would not switch to the replacement. Petertodd
> should perhaps make that more clear.
>
> But your "maybe"s are what I was asking you to clarify. You said it
> wasn't hard to imagine; so I was asking for specific clarification.

Pick any one "maybe".  They're only maybes because it's not realistic 
for them all to happen at once.


>
>> With Kalle's Proof of Payment proposed standard, one payer in a two-input
>> transaction could decide to boot the other, and claim the concert tickets
>> all for himself.  The fact that he pays is not the only consideration in the
>> real world -- what if these are the last 2 tickets?
> They can already do that.

Not without replacement, after broadcast, unless they successfully pay 
twice.


>
>> I'd argue that changing how an input is signed doesn't change the deal.  For
>> example if a different 2 of 3 multisig participants sign, those 3 people
>> gave up that level of control when they created the multisig.
> Then why do you not argue that changing the input set does not change
> the weeblix?
>
> Why is one case of writing out a participant different that the other
> case of writing out a participant?

In the multisig input case, each signer already accepted the possibility 
of being written out.  Peter Todd's proposal is in the spirit of not 
willfully making unconfirmed txes less reliable.  I'm suggesting that 
multi-input signers should be included in the set of people for whom 
they don't get less reliable.


>
>> Replacement is new - we have a choice what kind of warnings we need to give
>> to signers of multi-input transactions.  IMHO we should avoid needing a
>> stronger warning than is already needed for 0-conf.
> How could a _stronger_ warning be required?

We'd have to warn signers to multi-input txes instead of just warning 
receivers.




From pete at petertodd.org  Wed May 27 01:25:21 2015
From: pete at petertodd.org (Peter Todd)
Date: Tue, 26 May 2015 21:25:21 -0400
Subject: [Bitcoin-development] Cost savings by using replace-by-fee,
 30-90%
In-Reply-To: <5564E5B8.3090802@sky-ip.org>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
	<CANEZrP0DL8yA=neK0DTq0npEqc0q+RvTQD57OndNVg0vi2=yMg@mail.gmail.com>
	<20150525212638.GB12430@savin.petertodd.org>
	<CANEZrP1k-rUBSj2GMKqOEZsOuHp=axKUSxShOiN01DorzkFODQ@mail.gmail.com>
	<20150526001034.GF21367@savin.petertodd.org>
	<475dfb44d4e54649839e6438ad748b59@airmail.cc>
	<5564E5B8.3090802@sky-ip.org>
Message-ID: <20150527012520.GA7618@muck>

On Wed, May 27, 2015 at 12:29:28AM +0300, s7r wrote:
> What is wrong with the man testing some ideas on his custom branch? This
> is how improvements come to life. I saw in the BIPs some really
> interesting ideas and nice brainstorming which came from Peter Todd.
> 
> Now, my question, if replace by fee doesn't allow me to change the
> inputs or the outputs, I can only add outputs... what can I do with this
> feature? If I sent a tx and want to replace it with a higher fee one,
> the higher fee one can only have maybe additional change addresses or
> another payment, if the inputs suffice? Do we have any real use cases?

You're a bit mistaken there: standard RBF lets you change anything, and
FSS RBF lets you modify inputs and add outputs and/or make the value of
outputs higher.

> P.S. is it planned to include this by default in bitcoin core 10.0.3 or
> it will remain just on Peter's branch?

Any significant change to mempool policy like RBF is very unlikely to be
incorporated in the Bitcoin Core v0.10.x branch, simply because it'd be
too large a change for a minor, mostly bugfix, release.

Having said that, I already maintain a standard RBF branch for v0.10.x,
and have been asked by a major minor to backport FSS RBF for v0.10.x as
well.

-- 
'peter'[:-1]@petertodd.org
00000000000000000b9e6c1ce35e6e06c01b1f381840bcd9297f307cb1e6aae8
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150526/c047c16b/attachment.sig>

From pieter.wuille at gmail.com  Wed May 27 01:48:05 2015
From: pieter.wuille at gmail.com (Pieter Wuille)
Date: Tue, 26 May 2015 18:48:05 -0700
Subject: [Bitcoin-development] Version bits proposal
Message-ID: <CAPg+sBg5TqQ=zjyZ7dp-d1oBGp31Krnix3zyt9suP4-AGbxW=Q@mail.gmail.com>

Hello everyone,

here is a proposal for how to coordinate future soft-forking consensus
changes: https://gist.github.com/sipa/bf69659f43e763540550

It supports multiple parallel changes, as well as changes that get
permanently rejected without obstructing the rollout of others.

Feel free to comment. As the gist does not support notifying participants
of new comments, I would suggest using the mailing list instead.

This is joint work with Peter Todd and Greg Maxwell.

-- 
Pieter
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150526/87f14925/attachment.html>

From mark at friedenbach.org  Wed May 27 01:50:29 2015
From: mark at friedenbach.org (Mark Friedenbach)
Date: Tue, 26 May 2015 18:50:29 -0700
Subject: [Bitcoin-development] Consensus-enforced transaction replacement
	via sequence numbers
Message-ID: <CAOG=w-sfiUQQGUh=RR55NU-TkAi1+2g3_Z+YP3dGDjp8zXYBGQ@mail.gmail.com>

Sequence numbers appear to have been originally intended as a mechanism for
transaction replacement within the context of multi-party transaction
construction, e.g. a micropayment channel. The idea is that a participant
can sign successive versions of a transaction, each time incrementing the
sequence field by some amount. Relay nodes perform transaction replacement
according to some policy rule making use of the sequence numbers, e.g.
requiring sequence numbers in a replacement to be monotonically increasing.

As it happens, this cannot be made safe in the bitcoin protocol as deployed
today, as there is no enforcement of the rule that miners include the most
recent transaction in their blocks. As such, any protocol relying on a
transaction replacement policy can be defeated by miners choosing not to
follow that policy, which they may even be incentivised to do so (if older
transactions provide higher fee per byte, for example). Transaction
replacement is presently disabled in Bitcoin Core.

These shortcomings can be fixed in an elegant way by giving sequence
numbers new consensus-enforced semantics as a relative lock-time: if a
sequence number is non-final (MAX_INT), its bitwise inverse is interpreted
as either a relative height or time delta which is added to the height or
median time of the block containing the output being spent to form a
per-input lock-time. The lock-time of each input constructed in this manor,
plus the nLockTime of the transaction itself if any input is non-final must
be satisfied for a transaction to be valid.

For example, a transaction with an txin.nSequence set to 0xffffff9b [==
~(uint32_t)100] is prevented by consensus rule from being selected for
inclusion in a block until the 100th block following the one including the
parent transaction referenced by that input.

In this way one may construct, for example, a bidirectional micropayment
channel where each change of direction increments sequence numbers to make
the transaction become valid prior to any of the previously exchanged
transactions.

This also enables the discussed relative-form of CHECKLOCKTIMEVERIFY to be
implemented in the same way: by checking transaction data only and not
requiring contextual information like the block height or timestamp.

An example implementation of this concept, as a policy change to the
mempool processing of Bitcoin Core is available on github:

https://github.com/maaku/bitcoin/tree/sequencenumbers
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150526/74091cca/attachment.html>

From doug at bitcoinarmory.com  Wed May 27 02:31:21 2015
From: doug at bitcoinarmory.com (Douglas Roark)
Date: Tue, 26 May 2015 22:31:21 -0400
Subject: [Bitcoin-development] Version bits proposal
In-Reply-To: <CAPg+sBg5TqQ=zjyZ7dp-d1oBGp31Krnix3zyt9suP4-AGbxW=Q@mail.gmail.com>
References: <CAPg+sBg5TqQ=zjyZ7dp-d1oBGp31Krnix3zyt9suP4-AGbxW=Q@mail.gmail.com>
Message-ID: <55652C79.4080305@bitcoinarmory.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

On 2015/5/26 21:48, Pieter Wuille wrote:
> here is a proposal for how to coordinate future soft-forking
> consensus changes:
> https://gist.github.com/sipa/bf69659f43e763540550
> 
> It supports multiple parallel changes, as well as changes that get 
> permanently rejected without obstructing the rollout of others.
> 
> Feel free to comment. As the gist does not support notifying 
> participants of new comments, I would suggest using the mailing
> list instead.

Hi Pieter. Thanks for posting the proposal. I think the concept itself
is pretty solid. I know some people have been proposing alternate
methods too. I hope they'll share here, assuming they haven't already.
As is, my comments concern typos and general copy editing.

- - Just speaking in general, I found the BIP to be a bit hard to read.
AFAIK, the basic facts are accurate. I just found myself having to
re-read certain passages two or three times. A little polish wouldn't
hurt. For example, using the "it" pronoun can be confusing, such as
multiple uses in the abstract. Specifying what "it" is (e.g., "The
proposed change relies on...") would really help. In addition, the way
the "W" value is handled seems like it could be improved a bit. I know
the wording is accurate. Seeing 1000 change to 1001 is still a little
weird.
- - In "Multi-stage soft forks," I presume the second sentence should
end as follows: "[...] with additional validation rules that get
enabled one by _one_." Depending on semantics, I'd consider changing
"one by one" to "incremental steps," but that's your call.
- - I found the "High bits" section to be confusing at first. It looks
like you chose to show everything as little endian data, matching
what's actually in the block. My personal preference would be to
represent the data, for readability purposes, as big endian. I doubt
I'm the only one who finds big endian to be much easier to process
mentally.
- - Some sort of legend showing A, I, W, etc. would really help, as
opposed to just running into them as one goes along. Otherwise, the
alphabet soup can be a bit confusing.

Thanks again.

- -- 
- ---
Douglas Roark
Senior Developer
Armory Technologies, Inc.
doug at bitcoinarmory.com
PGP key ID: 92ADC0D7
-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.22 (Darwin)
Comment: GPGTools - https://gpgtools.org

iQIcBAEBCgAGBQJVZSx5AAoJEGybVGGSrcDXrYEQAOIrsggoZv0LdJHZjPGpEkeb
7ULhO4krZtQmKXjWDP0KnHAsFiyo5EOh1fYFRZz11OCqO4QmteTLPbodZFz47tKp
tIYv5uc0qYhjfo5uLkzxuUky08VE4dUoELfqdbNciC45xHras7Wh/+KXc1a20Fib
TaisWx9aL6VfPf7urM8b6mQ9XMba4YB3e2syAY8AA+qAEEP4DK2V6tuOQJD3kxP2
tbHtJnDvkDoXEY6tnL7fePo9X/IrlXLi8vNWGqPIf/hoiHmdvU+ORwHta7z9YeIO
zi4LRs8n8sYmifY4nt6Wkkc1aoPsmpoXmI3tKgFM2h5bfdg0n3fN3K0nTMWtnR6z
HUq8JhrQkZUP8uunN/23bt94FZolvnHTdL9YuWoyrlJ0gQri5YxV1BAN4hM9oCZy
1SqlSmFRplIFWu45q8/I5duDSphmA4NP2qc59QRjftcGYpNxmzaeSViiCDWzAjI9
qTLZgLTa/nf3TFN8oU8RwquGpwD82/fFo9V+uKdNGj79kdV8WOv4sa9q63OTVimJ
w+r4l1gDZYyToe0heKtV2kL9Tt4HTn23bj7EvU+98uaKEpfWSP8a3BN9mPR7ork/
lNRGEGQ0tvkeDUzKy9IHuAjXo2XkKctbBRJwZJCGc5WW2sN0HdSu/GFPXrOOLf0J
JXqeKpfaS0UriFXkxVHO
=8uNL
-----END PGP SIGNATURE-----



From luke at dashjr.org  Wed May 27 03:46:15 2015
From: luke at dashjr.org (Luke Dashjr)
Date: Wed, 27 May 2015 03:46:15 +0000
Subject: [Bitcoin-development] Version bits proposal
In-Reply-To: <CAPg+sBg5TqQ=zjyZ7dp-d1oBGp31Krnix3zyt9suP4-AGbxW=Q@mail.gmail.com>
References: <CAPg+sBg5TqQ=zjyZ7dp-d1oBGp31Krnix3zyt9suP4-AGbxW=Q@mail.gmail.com>
Message-ID: <201505270346.17014.luke@dashjr.org>

On Wednesday, May 27, 2015 1:48:05 AM Pieter Wuille wrote:
> Feel free to comment. As the gist does not support notifying participants
> of new comments, I would suggest using the mailing list instead.

I suggest adding a section describing how this interacts with and changes GBT.

Currently, the client tells the server what the highest block version it 
supports is, and the server indicates a block version to use in its template, 
as well as optional instructions for the client to forcefully use this version 
despite its own maximum version number. Making the version a bitfield 
contradicts the increment-only assumption of this design, and since GBT 
clients are not aware of overall network consensus state, reused bits can 
easily become confused. I suggest, therefore, that GBT clients should indicate 
(instead of a maximum supported version number) a list of softforks by 
identifier keyword, and the GBT server respond with a template indicating:
- An object of softfork keywords to bit values, that the server will accept.
- The version number, as presently conveyed, indicating the preferred softfork 
flags.

Does this sound reasonable, and/or am I missing anything else?

Luke



From jtimon at jtimon.cc  Wed May 27 03:51:00 2015
From: jtimon at jtimon.cc (=?UTF-8?B?Sm9yZ2UgVGltw7Nu?=)
Date: Wed, 27 May 2015 05:51:00 +0200
Subject: [Bitcoin-development] Version bits proposal
In-Reply-To: <201505270346.17014.luke@dashjr.org>
References: <CAPg+sBg5TqQ=zjyZ7dp-d1oBGp31Krnix3zyt9suP4-AGbxW=Q@mail.gmail.com>
	<201505270346.17014.luke@dashjr.org>
Message-ID: <CABm2gDoriDaQ1AjRDFxCT9zCNPQakJd9xRxfWkOJBf4v22hndQ@mail.gmail.com>

It would also help to see the actual code changes required, which I'm sure
will be much shorter than the explanation itself.
On May 27, 2015 5:47 AM, "Luke Dashjr" <luke at dashjr.org> wrote:

> On Wednesday, May 27, 2015 1:48:05 AM Pieter Wuille wrote:
> > Feel free to comment. As the gist does not support notifying participants
> > of new comments, I would suggest using the mailing list instead.
>
> I suggest adding a section describing how this interacts with and changes
> GBT.
>
> Currently, the client tells the server what the highest block version it
> supports is, and the server indicates a block version to use in its
> template,
> as well as optional instructions for the client to forcefully use this
> version
> despite its own maximum version number. Making the version a bitfield
> contradicts the increment-only assumption of this design, and since GBT
> clients are not aware of overall network consensus state, reused bits can
> easily become confused. I suggest, therefore, that GBT clients should
> indicate
> (instead of a maximum supported version number) a list of softforks by
> identifier keyword, and the GBT server respond with a template indicating:
> - An object of softfork keywords to bit values, that the server will
> accept.
> - The version number, as presently conveyed, indicating the preferred
> softfork
> flags.
>
> Does this sound reasonable, and/or am I missing anything else?
>
> Luke
>
>
> ------------------------------------------------------------------------------
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150527/52292ec6/attachment.html>

From pete at petertodd.org  Wed May 27 07:30:32 2015
From: pete at petertodd.org (Peter Todd)
Date: Wed, 27 May 2015 03:30:32 -0400
Subject: [Bitcoin-development] First-Seen-Safe Replace-by-Fee
In-Reply-To: <20150526051305.GA23502@savin.petertodd.org>
References: <20150526051305.GA23502@savin.petertodd.org>
Message-ID: <20150527073032.GA22286@savin.petertodd.org>

On Tue, May 26, 2015 at 01:13:05AM -0400, Peter Todd wrote:
> Case 1: Increasing the fee on a single tx
> -----------------------------------------
> 
> We start with a 1-in-2-out P2PKH using transaction t1, 226 bytes in size
> with the minimal relay fee, 2.26uBTC. Increasing the fee while
> respecting FSS-RBF rules requires the addition of one more txin, with
> the change output value increased appropriately, resulting in
> transaction t2, size 374 bytes. If the change txout is sufficient for
> the fee increase, increasing the fee via CPFP requires a second
> 1-in-1-out transaction, 192 bytes, for a total of 418 bytes; if another
> input is required, CPFP requires a 2-in-1-out tx, 340 bytes, for a total
> of 566 bytes.
> 
> Benefits: 11% to 34%+ cost savings, and RBF can increase fees even in
>           cases where the original transaction didn't have a change
>           output.

To clarify a point raised(1) on the pull-req itself:

The replacement transaction is allowed to not only add new txin's, but
also replace txins. Suppose t1 is a 2-in-2-out P2PKH using transaction,
374 bytes in size. With CPFP accomplished by a 1-in-1-out tx, 192 bytes,
you have 566 bytes total. With FSS RBF if you have an unspent output
greater in value than one of the outputs spent by t1, you can replace
that output in t1's vin txin set and rebroadcast the transaction, still
374 bytes in size. This gives you a 34% cost savings vs. CPFP.

> Case 2: Paying multiple recipients in succession
> ------------------------------------------------
> 
> We have a 1-in-2-out P2PKH transaction t1, 226 bytes, that pays Alice.
> We now need to pay Bob. With plain RBF we'd just add a new outptu and
> reduce the value of the change address, a 90% savings. However with FSS
> RBF, decreasing the value is not allowed, so we have to add an input.
> 
> If the change of t1 is sufficient to pay Bob, a second 1-in-2-out tx can
> be created, 2*226=452 bytes in total. With FSS RBF we can replace t1
> with a 2-in-3-out tx paying both, increasing the value of the change
> output appropriately, resulting in 408 bytes transaction saving 10%
> 
> Similar to the above example in the case where the change address of t1
> is insufficient to pay Bob the end result is one less transaction output
> in the wallet, defragmenting it. Spending these outputs later on would
> require two 148 byte inputs compared to one with RBF, resulting in an
> overall savings of 25%

Similarly in the multiple recipients case, if sufficiently large
outputs are available the additional funds can be obtained by swapping
one input for another.

For instance if Alice has three outputs, 1.0, 0.5, and 0.2 BTC, and
needs to pay Bob 1.1 BTC, she can create t1:

    1.0 -> Bob   1.1
    0.2 -> Alice 0.1

If she then needs to pay Charlie 0.2 BTC she can doublespend that with:

    1.0 -> Bob     1.1
    0.5 -> Charlie 0.2
        -> Alice   0.2

Note that care does need to be taken to ensure that multiple rounds of
this always leave at least one input unchanged.


1) https://github.com/bitcoin/bitcoin/pull/6176#issuecomment-105630255

-- 
'peter'[:-1]@petertodd.org
00000000000000000ec0c3a90baa52289171046469fe4a21dc5a0dac4cb758a9
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150527/c079858a/attachment.sig>

From pete at petertodd.org  Wed May 27 07:47:13 2015
From: pete at petertodd.org (Peter Todd)
Date: Wed, 27 May 2015 03:47:13 -0400
Subject: [Bitcoin-development] Consensus-enforced transaction
 replacement via sequence numbers
In-Reply-To: <CAOG=w-sfiUQQGUh=RR55NU-TkAi1+2g3_Z+YP3dGDjp8zXYBGQ@mail.gmail.com>
References: <CAOG=w-sfiUQQGUh=RR55NU-TkAi1+2g3_Z+YP3dGDjp8zXYBGQ@mail.gmail.com>
Message-ID: <20150527074713.GB22286@savin.petertodd.org>

On Tue, May 26, 2015 at 06:50:29PM -0700, Mark Friedenbach wrote:
> Sequence numbers appear to have been originally intended as a mechanism for
> transaction replacement within the context of multi-party transaction
> construction, e.g. a micropayment channel. The idea is that a participant
> can sign successive versions of a transaction, each time incrementing the
> sequence field by some amount. Relay nodes perform transaction replacement
> according to some policy rule making use of the sequence numbers, e.g.
> requiring sequence numbers in a replacement to be monotonically increasing.

Can you provide a worked example of this in use? I think I see a major
flaw, but I'd like to see a worked example first.

Keep in mind that there's absolutely no reason to have pending
transactions in mempools until we actually expect them to be mined.
Equally this proposal is no more "consensus enforcement" than simply
increasing the fee (and possibly decreasing the absolute nLockTime) for
each replacement would be; increasing the fee for each mempool
replacement is a hard requirement as an anti-DoS anyway. (this was all
discussed on the mailing list two years ago when RBF was first proposed)

-- 
'peter'[:-1]@petertodd.org
00000000000000000ec0c3a90baa52289171046469fe4a21dc5a0dac4cb758a9
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150527/fa8ed6a4/attachment.sig>

From lemientelephone at gmail.com  Wed May 27 08:04:09 2015
From: lemientelephone at gmail.com (Telephone Lemien)
Date: Wed, 27 May 2015 10:04:09 +0200
Subject: [Bitcoin-development] Consensus-enforced transaction
 replacement via sequence numbers
In-Reply-To: <CAOG=w-sfiUQQGUh=RR55NU-TkAi1+2g3_Z+YP3dGDjp8zXYBGQ@mail.gmail.com>
References: <CAOG=w-sfiUQQGUh=RR55NU-TkAi1+2g3_Z+YP3dGDjp8zXYBGQ@mail.gmail.com>
Message-ID: <CAL6tygZbYOXh3bS50ejwS6aynhuxu2xCoAOV9Fb7hfLu-4RFpA@mail.gmail.com>

Please remove me from the mailing list

2015-05-27 3:50 GMT+02:00 Mark Friedenbach <mark at friedenbach.org>:

> Sequence numbers appear to have been originally intended as a mechanism
> for transaction replacement within the context of multi-party transaction
> construction, e.g. a micropayment channel. The idea is that a participant
> can sign successive versions of a transaction, each time incrementing the
> sequence field by some amount. Relay nodes perform transaction replacement
> according to some policy rule making use of the sequence numbers, e.g.
> requiring sequence numbers in a replacement to be monotonically increasing.
>
> As it happens, this cannot be made safe in the bitcoin protocol as
> deployed today, as there is no enforcement of the rule that miners include
> the most recent transaction in their blocks. As such, any protocol relying
> on a transaction replacement policy can be defeated by miners choosing not
> to follow that policy, which they may even be incentivised to do so (if
> older transactions provide higher fee per byte, for example). Transaction
> replacement is presently disabled in Bitcoin Core.
>
> These shortcomings can be fixed in an elegant way by giving sequence
> numbers new consensus-enforced semantics as a relative lock-time: if a
> sequence number is non-final (MAX_INT), its bitwise inverse is interpreted
> as either a relative height or time delta which is added to the height or
> median time of the block containing the output being spent to form a
> per-input lock-time. The lock-time of each input constructed in this manor,
> plus the nLockTime of the transaction itself if any input is non-final must
> be satisfied for a transaction to be valid.
>
> For example, a transaction with an txin.nSequence set to 0xffffff9b [==
> ~(uint32_t)100] is prevented by consensus rule from being selected for
> inclusion in a block until the 100th block following the one including the
> parent transaction referenced by that input.
>
> In this way one may construct, for example, a bidirectional micropayment
> channel where each change of direction increments sequence numbers to make
> the transaction become valid prior to any of the previously exchanged
> transactions.
>
> This also enables the discussed relative-form of CHECKLOCKTIMEVERIFY to be
> implemented in the same way: by checking transaction data only and not
> requiring contextual information like the block height or timestamp.
>
> An example implementation of this concept, as a policy change to the
> mempool processing of Bitcoin Core is available on github:
>
> https://github.com/maaku/bitcoin/tree/sequencenumbers
>
>
> ------------------------------------------------------------------------------
>
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150527/ed83c67b/attachment.html>

From gmaxwell at gmail.com  Wed May 27 08:18:52 2015
From: gmaxwell at gmail.com (Gregory Maxwell)
Date: Wed, 27 May 2015 08:18:52 +0000
Subject: [Bitcoin-development] Consensus-enforced transaction
 replacement via sequence numbers
In-Reply-To: <20150527074713.GB22286@savin.petertodd.org>
References: <CAOG=w-sfiUQQGUh=RR55NU-TkAi1+2g3_Z+YP3dGDjp8zXYBGQ@mail.gmail.com>
	<20150527074713.GB22286@savin.petertodd.org>
Message-ID: <CAAS2fgSjT-dtS8cNoRjvEhtBeG9SUi4OsKAAGkAf_WkxEyg=9g@mail.gmail.com>

On Wed, May 27, 2015 at 7:47 AM, Peter Todd <pete at petertodd.org> wrote:
> Equally this proposal is no more "consensus enforcement" than simply
> increasing the fee (and possibly decreasing the absolute nLockTime) for

You've misunderstood it, I think-- Functionally nlocktime but relative
to each txin's height.

But the construction gives the sequence numbers a rational meaning,
they count down the earliest position a transaction can be included.
(e.g. the highest possible sequence number can be included any time
the inputs are included) the next lower sequence number can only be
included one block later than the input its assigned to is included,
the next lower one block beyond that. All consensus enforced.   A
miner could opt to not include the higher sequence number (which is
the only one of the set which it _can_ include) it the hopes of
collecting more fees later on the next block, similar to how someone
could ignore an eligible locked transaction in the hopes that a future
double spend will be more profitable (and that it'll enjoy that
profit) but in both cases it must take nothing at all this block, and
risk being cut off by someone else (and, of course, nothing requires
users use sequence numbers only one apart...).

It makes sequence numbers work exactly like you'd expect-- within the
bounds of whats possible in a decentralized system.  At the same time,
all it is ... is relative nlocktime.



From tier.nolan at gmail.com  Wed May 27 09:35:03 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Wed, 27 May 2015 10:35:03 +0100
Subject: [Bitcoin-development] Version bits proposal
In-Reply-To: <CABm2gDoriDaQ1AjRDFxCT9zCNPQakJd9xRxfWkOJBf4v22hndQ@mail.gmail.com>
References: <CAPg+sBg5TqQ=zjyZ7dp-d1oBGp31Krnix3zyt9suP4-AGbxW=Q@mail.gmail.com>
	<201505270346.17014.luke@dashjr.org>
	<CABm2gDoriDaQ1AjRDFxCT9zCNPQakJd9xRxfWkOJBf4v22hndQ@mail.gmail.com>
Message-ID: <CAE-z3OVAKyppLVEWR=qNX-_p5yVAj_0Y7Kw76o4qaywf2DKtVw@mail.gmail.com>

I think it would be better to have the deadlines set as block counts.  That
eliminates the need to use the median time mechanism.

The deadline could be matched to a "start-line".  The definition would then
be something like

BIP 105
Start block: 325000
End block: 350000
Activation: 750 of 1000
Implication: 950 of 1000
Bit: 9

This would allow creation of a simple table of known BIPs.  It also keeps
multiple users of the bit as strictly separate.

The alternative to the start time is that it is set equal to the deadline
or implication time of the previous user of the bit.

Was the intention to change the 95% rule.  You need 750 of the last 1000 to
activate and then must wait at least 1000 for implication?


On Wed, May 27, 2015 at 4:51 AM, Jorge Tim?n <jtimon at jtimon.cc> wrote:

> It would also help to see the actual code changes required, which I'm sure
> will be much shorter than the explanation itself.
> On May 27, 2015 5:47 AM, "Luke Dashjr" <luke at dashjr.org> wrote:
>
>> On Wednesday, May 27, 2015 1:48:05 AM Pieter Wuille wrote:
>> > Feel free to comment. As the gist does not support notifying
>> participants
>> > of new comments, I would suggest using the mailing list instead.
>>
>> I suggest adding a section describing how this interacts with and changes
>> GBT.
>>
>> Currently, the client tells the server what the highest block version it
>> supports is, and the server indicates a block version to use in its
>> template,
>> as well as optional instructions for the client to forcefully use this
>> version
>> despite its own maximum version number. Making the version a bitfield
>> contradicts the increment-only assumption of this design, and since GBT
>> clients are not aware of overall network consensus state, reused bits can
>> easily become confused. I suggest, therefore, that GBT clients should
>> indicate
>> (instead of a maximum supported version number) a list of softforks by
>> identifier keyword, and the GBT server respond with a template indicating:
>> - An object of softfork keywords to bit values, that the server will
>> accept.
>> - The version number, as presently conveyed, indicating the preferred
>> softfork
>> flags.
>>
>> Does this sound reasonable, and/or am I missing anything else?
>>
>> Luke
>>
>>
>> ------------------------------------------------------------------------------
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>
>
> ------------------------------------------------------------------------------
>
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150527/cd5723c3/attachment.html>

From tier.nolan at gmail.com  Wed May 27 10:00:16 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Wed, 27 May 2015 11:00:16 +0100
Subject: [Bitcoin-development] Consensus-enforced transaction
 replacement via sequence numbers
In-Reply-To: <CAAS2fgSjT-dtS8cNoRjvEhtBeG9SUi4OsKAAGkAf_WkxEyg=9g@mail.gmail.com>
References: <CAOG=w-sfiUQQGUh=RR55NU-TkAi1+2g3_Z+YP3dGDjp8zXYBGQ@mail.gmail.com>
	<20150527074713.GB22286@savin.petertodd.org>
	<CAAS2fgSjT-dtS8cNoRjvEhtBeG9SUi4OsKAAGkAf_WkxEyg=9g@mail.gmail.com>
Message-ID: <CAE-z3OW29KpLzvD5-THOjQbL=5QH=1MRCA26FbN=6Bz80h0Nzg@mail.gmail.com>

This could cause legacy transactions to become unspendable.


A new transaction version number should be used to indicate the change of
the field from sequence number to relative lock time.

Legacy transactions should not have the rule applied to them.

On Wed, May 27, 2015 at 9:18 AM, Gregory Maxwell <gmaxwell at gmail.com> wrote:

> On Wed, May 27, 2015 at 7:47 AM, Peter Todd <pete at petertodd.org> wrote:
> > Equally this proposal is no more "consensus enforcement" than simply
> > increasing the fee (and possibly decreasing the absolute nLockTime) for
>
> You've misunderstood it, I think-- Functionally nlocktime but relative
> to each txin's height.
>
> But the construction gives the sequence numbers a rational meaning,
> they count down the earliest position a transaction can be included.
> (e.g. the highest possible sequence number can be included any time
> the inputs are included) the next lower sequence number can only be
> included one block later than the input its assigned to is included,
> the next lower one block beyond that. All consensus enforced.   A
> miner could opt to not include the higher sequence number (which is
> the only one of the set which it _can_ include) it the hopes of
> collecting more fees later on the next block, similar to how someone
> could ignore an eligible locked transaction in the hopes that a future
> double spend will be more profitable (and that it'll enjoy that
> profit) but in both cases it must take nothing at all this block, and
> risk being cut off by someone else (and, of course, nothing requires
> users use sequence numbers only one apart...).
>
> It makes sequence numbers work exactly like you'd expect-- within the
> bounds of whats possible in a decentralized system.  At the same time,
> all it is ... is relative nlocktime.
>
>
> ------------------------------------------------------------------------------
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150527/e68c2a37/attachment.html>

From mike at plan99.net  Wed May 27 10:11:26 2015
From: mike at plan99.net (Mike Hearn)
Date: Wed, 27 May 2015 12:11:26 +0200
Subject: [Bitcoin-development] Consensus-enforced transaction
 replacement via sequence numbers
In-Reply-To: <CAOG=w-sfiUQQGUh=RR55NU-TkAi1+2g3_Z+YP3dGDjp8zXYBGQ@mail.gmail.com>
References: <CAOG=w-sfiUQQGUh=RR55NU-TkAi1+2g3_Z+YP3dGDjp8zXYBGQ@mail.gmail.com>
Message-ID: <CANEZrP0QMHp9PwBr=ekkujtA+=LXbgiL4xkXRSmcOGqaLJEp0g@mail.gmail.com>

>
> Sequence numbers appear to have been originally intended as a mechanism
> for transaction replacement within the context of multi-party transaction
> construction, e.g. a micropayment channel.
>

Yes indeed they were. Satoshis mechanism was more general than micropayment
channels and could do HFT between any set of parties.


> As it happens, this cannot be made safe in the bitcoin protocol as
> deployed today, as there is no enforcement of the rule that miners include
> the most recent transaction in their blocks.
>

Safe is relative - this is the same logic the original replace-by-fee
argument uses. There's no enforcement that miners use any particular
ordering of transactions.

As I believe out of all proposed protocols Satoshi's is still the most
powerful, I would suggest that any change to the semantics on nSequence be
gated by a high bit or something, so the original meaning remains available
if/when resource scheduling and update flood damping are implemented. That
way people can try it out and if miners are breaking things too frequently
by ignoring the chronological ordering people can abandon protocols that
rely on it, and if they aren't they can proceed and benefit from the
greater flexibility.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150527/4ed103cd/attachment.html>

From pete at petertodd.org  Wed May 27 10:15:16 2015
From: pete at petertodd.org (Peter Todd)
Date: Wed, 27 May 2015 06:15:16 -0400
Subject: [Bitcoin-development] Version bits proposal
In-Reply-To: <CAE-z3OVAKyppLVEWR=qNX-_p5yVAj_0Y7Kw76o4qaywf2DKtVw@mail.gmail.com>
References: <CAPg+sBg5TqQ=zjyZ7dp-d1oBGp31Krnix3zyt9suP4-AGbxW=Q@mail.gmail.com>
	<201505270346.17014.luke@dashjr.org>
	<CABm2gDoriDaQ1AjRDFxCT9zCNPQakJd9xRxfWkOJBf4v22hndQ@mail.gmail.com>
	<CAE-z3OVAKyppLVEWR=qNX-_p5yVAj_0Y7Kw76o4qaywf2DKtVw@mail.gmail.com>
Message-ID: <20150527101516.GB25814@savin.petertodd.org>

On Wed, May 27, 2015 at 10:35:03AM +0100, Tier Nolan wrote:
> I think it would be better to have the deadlines set as block counts.  That
> eliminates the need to use the median time mechanism.

The median time mechanism is basically a way for hashing power to show
what time they think it is. Equally, the nVersion soft-fork mechanism is
a way for hashing power to show what features they want to support.

Block counts are inconvenient for planning, as there's no guarantee
they'll actually happen in any particular time frame, forward and back.
There's no particular incentive problems here - the median time clearly
shows support by a majority of hashing power - so I don't see any reason
to make planning more difficult.

> The deadline could be matched to a "start-line".  The definition would then
> be something like
> 
> BIP 105
> Start block: 325000
> End block: 350000
> Activation: 750 of 1000
> Implication: 950 of 1000
> Bit: 9
> 
> This would allow creation of a simple table of known BIPs.  It also keeps
> multiple users of the bit as strictly separate.

If you assume no large reorganizations, your table of known BIPs can
just as easily be a list of block heights even if the median time
mechanism is used.

If you do assume there may be large reorganizations you can't have a
"simple table"

-- 
'peter'[:-1]@petertodd.org
000000000000000001643f7706f3dcbc3a386e4c1bfba852ff628d8024f875b6
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150527/2107dc0e/attachment.sig>

From jtimon at jtimon.cc  Wed May 27 10:15:46 2015
From: jtimon at jtimon.cc (=?UTF-8?B?Sm9yZ2UgVGltw7Nu?=)
Date: Wed, 27 May 2015 12:15:46 +0200
Subject: [Bitcoin-development] Version bits proposal
In-Reply-To: <CAE-z3OVAKyppLVEWR=qNX-_p5yVAj_0Y7Kw76o4qaywf2DKtVw@mail.gmail.com>
References: <CAPg+sBg5TqQ=zjyZ7dp-d1oBGp31Krnix3zyt9suP4-AGbxW=Q@mail.gmail.com>
	<201505270346.17014.luke@dashjr.org>
	<CABm2gDoriDaQ1AjRDFxCT9zCNPQakJd9xRxfWkOJBf4v22hndQ@mail.gmail.com>
	<CAE-z3OVAKyppLVEWR=qNX-_p5yVAj_0Y7Kw76o4qaywf2DKtVw@mail.gmail.com>
Message-ID: <CABm2gDqf+XEged3dCvKYWgqNdQ=XVZXQZP-g5CDxJ+m+VaoQNg@mail.gmail.com>

On May 27, 2015 11:35 AM, "Tier Nolan" <tier.nolan at gmail.com> wrote:

> Was the intention to change the 95% rule.  You need 750 of the last 1000
to activate and then must wait at least 1000 for implication?

You need 75% to start applying it, 95% to start rejecting blocks that don't
apply it.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150527/2cc99991/attachment.html>

From lrossouw at gmail.com  Wed May 27 10:16:49 2015
From: lrossouw at gmail.com (Louis Rossouw)
Date: Wed, 27 May 2015 10:16:49 +0000
Subject: [Bitcoin-development] Zero-Conf for Full Node Discovery
In-Reply-To: <CANEZrP3tR-PTHnrAj4ptZnLh0PuWO_TWZ0FqpYe2TLNJC5C+xQ@mail.gmail.com>
References: <CANe1mWwi+fxFU43_2mq-yd_qRsmCwMu_c5wWOpvFS4Un_FoT+Q@mail.gmail.com>
	<23111107.dfGN69SrR9@crushinator>
	<20150526051546.GB23502@savin.petertodd.org>
	<2558087.GVnsa68lBj@crushinator>
	<CANEZrP3tR-PTHnrAj4ptZnLh0PuWO_TWZ0FqpYe2TLNJC5C+xQ@mail.gmail.com>
Message-ID: <CAELsELuvhrDh27-FayEW=w=V5oN0UB+4qrAi1NspRR3bfUzbUg@mail.gmail.com>

Also think it would be useful.

Created an issue for it some time back:
https://github.com/bitcoin/bitcoin/issues/3802
I think nodes don't "only" have to connect to LAN nodes. Especially with
headers first.
They can still connect to other nodes as well.  Having said that security
is problematic in any case on a hotel wifi or similar.  All traffic can be
spoofed.
With HF they'd be loading most of the data from the LAN node though.
This will help people having multiple nodes at home reduce bandwidth and
improve sync without difficult setup.


On Tue, 26 May 2015 at 12:50 Mike Hearn <mike at plan99.net> wrote:

> Very interesting Matt.
>
> For what it's worth, in future bitcoinj is very likely to bootstrap from
> Cartographer nodes (signed HTTP) rather than DNS, and we're also steadily
> working towards Tor by default. So this approach will probably stop working
> at some point. As breaking PorcFest would kind of suck, we might want a
> ZeroConf/Rendezvous solution in place so local LANs can capture Bitcoin
> traffic away from Tor (with some notification to the user, presumably).
>
>
>
> On Tue, May 26, 2015 at 7:47 AM, Matt Whitlock <bip at mattwhitlock.name>
> wrote:
>
>> On Tuesday, 26 May 2015, at 1:15 am, Peter Todd wrote:
>> > On Tue, May 26, 2015 at 12:52:07AM -0400, Matt Whitlock wrote:
>> > > On Monday, 25 May 2015, at 11:48 pm, Jim Phillips wrote:
>> > > > Do any wallets actually do this yet?
>> > >
>> > > Not that I know of, but they do seed their address database via DNS,
>> which you can poison if you control the LAN's DNS resolver. I did this for
>> a Bitcoin-only Wi-Fi network I operated at a remote festival. We had well
>> over a hundred lightweight wallets, all trying to connect to the Bitcoin
>> P2P network over a very bandwidth-constrained Internet link, so I poisoned
>> the DNS and rejected all outbound connection attempts on port 8333, to
>> force all the wallets to connect to a single local full node, which had
>> connectivity to a single remote node over the Internet. Thus, all the
>> lightweight wallets at the festival had Bitcoin network connectivity, but
>> we only needed to backhaul the Bitcoin network's transaction traffic once.
>> >
>> > Interesting!
>> >
>> > What festival was this?
>>
>> The Porcupine Freedom Festival ("PorcFest") in New Hampshire last summer.
>> I strongly suspect that it's the largest gathering of Bitcoin users at any
>> event that is not specifically Bitcoin-themed. There's a lot of overlap
>> between the Bitcoin and liberty communities. PorcFest draws somewhere
>> around 1000-2000 attendees, a solid quarter of whom have Bitcoin wallets on
>> their mobile devices.
>>
>> The backhaul was a 3G cellular Internet connection, and the local Bitcoin
>> node and network router were hosted on a Raspberry Pi with some Netfilter
>> tricks to restrict connectivity. The net result was that all Bitcoin nodes
>> (lightweight and heavyweight) on the local Wi-Fi network were unable to
>> connect to any Bitcoin nodes except for the local node, which they
>> discovered via DNS. I also had provisions in place to allow outbound
>> connectivity to the API servers for Mycelium, Blockchain, and Coinbase
>> wallets, by feeding the DNS resolver's results in real-time into a
>> whitelisting Netfilter rule utilizing IP Sets.
>>
>> For your amusement, here's the graphic for the banner that I had made to
>> advertise the network at the festival (*chuckle*):
>> http://www.mattwhitlock.com/bitcoin_wifi.png
>>
>>
>> ------------------------------------------------------------------------------
>> One dashboard for servers and applications across Physical-Virtual-Cloud
>> Widest out-of-the-box monitoring support with 50+ applications
>> Performance metrics, stats and reports that give you Actionable Insights
>> Deep dive visibility with transaction tracing using APM Insight.
>> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150527/d9684800/attachment.html>

From pete at petertodd.org  Wed May 27 10:58:05 2015
From: pete at petertodd.org (Peter Todd)
Date: Wed, 27 May 2015 06:58:05 -0400
Subject: [Bitcoin-development] Consensus-enforced transaction
 replacement via sequence numbers
In-Reply-To: <CAAS2fgSjT-dtS8cNoRjvEhtBeG9SUi4OsKAAGkAf_WkxEyg=9g@mail.gmail.com>
References: <CAOG=w-sfiUQQGUh=RR55NU-TkAi1+2g3_Z+YP3dGDjp8zXYBGQ@mail.gmail.com>
	<20150527074713.GB22286@savin.petertodd.org>
	<CAAS2fgSjT-dtS8cNoRjvEhtBeG9SUi4OsKAAGkAf_WkxEyg=9g@mail.gmail.com>
Message-ID: <20150527105805.GC25814@savin.petertodd.org>

On Wed, May 27, 2015 at 08:18:52AM +0000, Gregory Maxwell wrote:
> On Wed, May 27, 2015 at 7:47 AM, Peter Todd <pete at petertodd.org> wrote:
> > Equally this proposal is no more "consensus enforcement" than simply
> > increasing the fee (and possibly decreasing the absolute nLockTime) for
> 
> You've misunderstood it, I think-- Functionally nlocktime but relative
> to each txin's height.
> 
> But the construction gives the sequence numbers a rational meaning,
> they count down the earliest position a transaction can be included.
> (e.g. the highest possible sequence number can be included any time
> the inputs are included) the next lower sequence number can only be
> included one block later than the input its assigned to is included,
> the next lower one block beyond that. All consensus enforced.   A
> miner could opt to not include the higher sequence number (which is
> the only one of the set which it _can_ include) it the hopes of
> collecting more fees later on the next block, similar to how someone
> could ignore an eligible locked transaction in the hopes that a future
> double spend will be more profitable (and that it'll enjoy that
> profit) but in both cases it must take nothing at all this block, and
> risk being cut off by someone else (and, of course, nothing requires
> users use sequence numbers only one apart...).

I understand that part.

I'm just saying it's not clear to me what's the functional difference in
practice between it and having both parties sign a decreasing absolute
nLockTime. For instance, you and I could setup a payment channel using
the following transaction t0:

    1.0 BTC: PT -> 1.0 BTC: PT && (GM || <expiry> CLTV)
    1.0 BTC: GM -> 1.0 BTC: GM && (PT || <expiry> CLTV)

After <expiry> both of us are guaranteed to get our funds back
regardless. I can then give you funds by signing my part of t1a:

    t0.vout[0] <PT sig> <blank> -> 0.5 BTC: PT
    t0.vout[1] <blank> <PT sig> -> 1.5 BTC: GM
    nLockTime = <expiry - 1>

You can then give me funds with t1b:

    t0.vout[0] <blank> <GM sig> -> 1.5 BTC: PT
    t0.vout[1] <GM sig> <blank> -> 0.5 BTC: GM
    nLockTime = <expiry - 2>

etc. etc. We can close the channel by signing a non-nLockTime'd tx at
any time. If you don't co-operate, I have to wait, and hope I get my tx
mined before you get yours.

What I'm not seeing is how the relative nLockTime that nSequence
provides fundamentally changes any of this.

-- 
'peter'[:-1]@petertodd.org
000000000000000001643f7706f3dcbc3a386e4c1bfba852ff628d8024f875b6
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150527/a3370384/attachment.sig>

From tier.nolan at gmail.com  Wed May 27 11:26:33 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Wed, 27 May 2015 12:26:33 +0100
Subject: [Bitcoin-development] Version bits proposal
In-Reply-To: <20150527101516.GB25814@savin.petertodd.org>
References: <CAPg+sBg5TqQ=zjyZ7dp-d1oBGp31Krnix3zyt9suP4-AGbxW=Q@mail.gmail.com>
	<201505270346.17014.luke@dashjr.org>
	<CABm2gDoriDaQ1AjRDFxCT9zCNPQakJd9xRxfWkOJBf4v22hndQ@mail.gmail.com>
	<CAE-z3OVAKyppLVEWR=qNX-_p5yVAj_0Y7Kw76o4qaywf2DKtVw@mail.gmail.com>
	<20150527101516.GB25814@savin.petertodd.org>
Message-ID: <CAE-z3OVskd1JAE5g-WW2eDiPcxysYhbv-NsOYu7yKZvzu88VSg@mail.gmail.com>

On Wed, May 27, 2015 at 11:15 AM, Peter Todd <pete at petertodd.org> wrote:

> The median time mechanism is basically a way for hashing power to show
> what time they think it is. Equally, the nVersion soft-fork mechanism is
> a way for hashing power to show what features they want to support.
>
>
Fair enough.  It means slightly more processing, but the median time could
be cached in the header index, so no big deal.

Block counts are inconvenient for planning, as there's no guarantee
> they'll actually happen in any particular time frame, forward and back.
>

I don't think the deadline needs to be set that accurately.  A roughly 6
month deadline should be fine, but as you say a majority of miners is
needed to abuse the median time and it is already a miner poll.

Perhaps the number of blocks used in the median could be increased to
reduce "noise".

The median time could be median of the last 144 blocks plus 12 hours.


> If you assume no large reorganizations, your table of known BIPs can
> just as easily be a list of block heights even if the median time
> mechanism is used.
>

I think it makes it easier to write the code.  It reduced the state that
needs to be stored per BIP.  You don't need to check if the previous bips
were all accepted.

Each bit is assigned to a particular BIP for a particular range of times
(or blocks).

If block numbers were used for the deadline, you just need to check the
block index for the deadline block.

enum {
    BIP_INACTIVE = 0,
    BIP_ACTIVE,
    BIP_LOCKED
    BIP_INVALID_BLOCK,
}

int GetBIPState(block, bip)
{
    if (block.height == bip.deadline)  // Bit must be set to match
locked/unlocked at deadline
    {
        int bipState = check_supermajority(...);
        if (bipState == BIP_LOCKED && (block.nVersion & bip.bit)
            return BIP_LOCKED;

        if (bipState != BIP_LOCKED && (block.nVersion & (~bip.bit)))
            return BIP_INACTIVE;

        return BIP_INVALID_BLOCK;
    }

    if (block.height > deadline) // Look at the deadline block to determine
if the BIP is locked
        return (block_index[deadline].nVersion & bip_bit) != 0 ? BIP_LOCKED
: BIP_INACTIVE;

    if (block.height < startline + I) // BIP cannot activate/lock until
startline + implicit window size
        return INACTIVE;

    return check_supermajority(....) // Check supermajority of bit
}

The block at height deadline would indicate if the BIP was locked in.

Block time could still be used as long as the block height was set after
that.  The deadline_time could be in six months.  The startline height
could be the current block height and the deadline_height could be
startline + 35000.

The gives roughly

start time = now
deadline time = now + six months
deadline height = now + eight months

The deadline height is the block height when the bit is returned to the
pool but the deadline time is when the BIP has to be accepted.

It also helps with the warning system.  For each block height, there is a
set of known BIP bits that are allowed.  Once the final deadline is passed,
the expected mask is zeros.

On Wed, May 27, 2015 at 11:15 AM, Jorge Tim?n <jtimon at jtimon.cc> wrote:

> On May 27, 2015 11:35 AM, "Tier Nolan" <tier.nolan at gmail.com> wrote:
>
> > Was the intention to change the 95% rule.  You need 750 of the last 1000
> to activate and then must wait at least 1000 for implication?
>
> You need 75% to start applying it, 95% to start rejecting blocks that
> don't apply it.
>

I think the phrasing is ambiguous.  I was just asking for clarification.

"Whenever I out of any W *subsequent* blocks (regardless of the block
itself) have bit B set,"

That suggests that the I of W blocks for the 95% rule must happen after
activation.  This makes the rule checking harder.  Easier to use the
current system, where blocks that were part of the 750 rule also count
towards the 95% rule.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150527/90a022e8/attachment.html>

From mark at friedenbach.org  Wed May 27 15:26:52 2015
From: mark at friedenbach.org (Mark Friedenbach)
Date: Wed, 27 May 2015 08:26:52 -0700
Subject: [Bitcoin-development] Consensus-enforced transaction
 replacement via sequence numbers
In-Reply-To: <CANEZrP0QMHp9PwBr=ekkujtA+=LXbgiL4xkXRSmcOGqaLJEp0g@mail.gmail.com>
References: <CAOG=w-sfiUQQGUh=RR55NU-TkAi1+2g3_Z+YP3dGDjp8zXYBGQ@mail.gmail.com>
	<CANEZrP0QMHp9PwBr=ekkujtA+=LXbgiL4xkXRSmcOGqaLJEp0g@mail.gmail.com>
Message-ID: <CAOG=w-s7JkB6SyEE0=KwmrasyH22aB2Zf3jBdKcXvrGoNhN_Nw@mail.gmail.com>

On Wed, May 27, 2015 at 3:11 AM, Mike Hearn <mike at plan99.net> wrote:

>
> As I believe out of all proposed protocols Satoshi's is still the most
> powerful, I would suggest that any change to the semantics on nSequence be
> gated by a high bit or something, so the original meaning remains available
> if/when resource scheduling and update flood damping are implemented. That
> way people can try it out and if miners are breaking things too frequently
> by ignoring the chronological ordering people can abandon protocols that
> rely on it, and if they aren't they can proceed and benefit from the
> greater flexibility.
>
>
Mike, this proposal was purposefully constructed to maintain as well as
possible the semantics of Satoshi's original construction. Higher sequence
numbers -- chronologically later transactions -- are able to hit the chain
earlier, and therefore it can be reasonably argued will be selected by
miners before the later transactions mature. Did I fail in some way to
capture that original intent?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150527/7d354be0/attachment.html>

From jtimon at jtimon.cc  Wed May 27 17:07:24 2015
From: jtimon at jtimon.cc (=?UTF-8?B?Sm9yZ2UgVGltw7Nu?=)
Date: Wed, 27 May 2015 19:07:24 +0200
Subject: [Bitcoin-development] Consensus-enforced transaction
 replacement via sequence numbers
In-Reply-To: <20150527105805.GC25814@savin.petertodd.org>
References: <CAOG=w-sfiUQQGUh=RR55NU-TkAi1+2g3_Z+YP3dGDjp8zXYBGQ@mail.gmail.com>
	<20150527074713.GB22286@savin.petertodd.org>
	<CAAS2fgSjT-dtS8cNoRjvEhtBeG9SUi4OsKAAGkAf_WkxEyg=9g@mail.gmail.com>
	<20150527105805.GC25814@savin.petertodd.org>
Message-ID: <CABm2gDoOyjWex=j+yro2xspEH-zsdy3iu6Dyx81ziJ8ZvvVj2w@mail.gmail.com>

On May 27, 2015 12:58 PM, "Peter Todd" <pete at petertodd.org> wrote:

> What I'm not seeing is how the relative nLockTime that nSequence
> provides fundamentally changes any of this.

This allows the implementation of a rcltv that doesn't make script depend
on the current height, in a similar way that cltv uses the nLockTime (which
has been compared with the current height already when checking the script).
In fact, the implementation could be simpler if the goal of maintaining the
original nSequence semantics was ignored ( although not that simpler, but
you wouldn't need to use ~ (bitwise not).
I'm still not sure whether there should be 2 BIPs for this or just one.

> --
> 'peter'[:-1]@petertodd.org
> 000000000000000001643f7706f3dcbc3a386e4c1bfba852ff628d8024f875b6
>
>
------------------------------------------------------------------------------
>
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150527/244fa6f5/attachment.html>

From mike at plan99.net  Wed May 27 17:39:29 2015
From: mike at plan99.net (Mike Hearn)
Date: Wed, 27 May 2015 19:39:29 +0200
Subject: [Bitcoin-development] Consensus-enforced transaction
 replacement via sequence numbers
In-Reply-To: <CAOG=w-s7JkB6SyEE0=KwmrasyH22aB2Zf3jBdKcXvrGoNhN_Nw@mail.gmail.com>
References: <CAOG=w-sfiUQQGUh=RR55NU-TkAi1+2g3_Z+YP3dGDjp8zXYBGQ@mail.gmail.com>
	<CANEZrP0QMHp9PwBr=ekkujtA+=LXbgiL4xkXRSmcOGqaLJEp0g@mail.gmail.com>
	<CAOG=w-s7JkB6SyEE0=KwmrasyH22aB2Zf3jBdKcXvrGoNhN_Nw@mail.gmail.com>
Message-ID: <CANEZrP0zKe7hK0KjiXN9M6CHnJxKZfW9myez3G+GWpr3fugBCg@mail.gmail.com>

>
> Mike, this proposal was purposefully constructed to maintain as well as
> possible the semantics of Satoshi's original construction. Higher sequence
> numbers -- chronologically later transactions -- are able to hit the chain
> earlier, and therefore it can be reasonably argued will be selected by
> miners before the later transactions mature. Did I fail in some way to
> capture that original intent?
>

Right, but the original protocol allowed for e.g. millions of revisions of
the transaction, hence for high frequency trading (that's actually how
Satoshi originally explained it to me - as a way to do HFT - back then the
channel concept didn't exist).

As you point out, with a careful construction of channels you should only
need to bump the sequence number when the channel reverses direction. If
your app only needs to do that rarely, it's a fine approach.And your
proposal does sounds better than sequence numbers being useless like at the
moment. I'm just wondering if we can get back to the original somehow or at
least leave a path open to it, as it seems to be a superset of all other
proposals, features-wise.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150527/8c096952/attachment.html>

From s7r at sky-ip.org  Wed May 27 19:28:55 2015
From: s7r at sky-ip.org (s7r)
Date: Wed, 27 May 2015 22:28:55 +0300
Subject: [Bitcoin-development] Cost savings by using replace-by-fee,
	30-90%
In-Reply-To: <20150527012520.GA7618@muck>
References: <CANe1mWzBy8-C+CWfwaOLxJ2wokjy8ytQUh2TkRY_Ummn1BpPzw@mail.gmail.com>
	<CANEZrP0DL8yA=neK0DTq0npEqc0q+RvTQD57OndNVg0vi2=yMg@mail.gmail.com>
	<20150525212638.GB12430@savin.petertodd.org>
	<CANEZrP1k-rUBSj2GMKqOEZsOuHp=axKUSxShOiN01DorzkFODQ@mail.gmail.com>
	<20150526001034.GF21367@savin.petertodd.org>
	<475dfb44d4e54649839e6438ad748b59@airmail.cc>
	<5564E5B8.3090802@sky-ip.org> <20150527012520.GA7618@muck>
Message-ID: <55661AF7.9000006@sky-ip.org>

Hi Peter,

Thanks for your reply.

I know and bookmarked your branch - nice work.

So, to clarify:
- bitcoin core (official / default) 0.10.x currently has First-seen
mempool behavior
- your custom branch uses replace by fee mempool behavior which allows
an user to change anything in a tx (I guess it needs just to have at
least one same input, so it can link it to another previously signed tx
with lower fee and substitute it in the mempool, correct?).

- First Seen Safe Replace by Fee (FSF-RBF) mempool behavior which allows
an user only to add inputs and/or increase the value of outputs will be
in yet another branch, maintained by you, but not in default / official
bitcoin core?

Another thing, if FSF-RBF lets you change TXes in the manner described
above, how does the client know which tx needs to be replaced in the
mempool? Since the txid naturally changes. How does it map tx1 with tx2
(to know tx2 has a higher fee and needs to substitute tx1) if quite a
lot of params from the transaction structure can change?

Thanks!

On 5/27/2015 4:25 AM, Peter Todd wrote:
> On Wed, May 27, 2015 at 12:29:28AM +0300, s7r wrote:
>> What is wrong with the man testing some ideas on his custom branch? This
>> is how improvements come to life. I saw in the BIPs some really
>> interesting ideas and nice brainstorming which came from Peter Todd.
>>
>> Now, my question, if replace by fee doesn't allow me to change the
>> inputs or the outputs, I can only add outputs... what can I do with this
>> feature? If I sent a tx and want to replace it with a higher fee one,
>> the higher fee one can only have maybe additional change addresses or
>> another payment, if the inputs suffice? Do we have any real use cases?
> 
> You're a bit mistaken there: standard RBF lets you change anything, and
> FSS RBF lets you modify inputs and add outputs and/or make the value of
> outputs higher.
> 
>> P.S. is it planned to include this by default in bitcoin core 10.0.3 or
>> it will remain just on Peter's branch?
> 
> Any significant change to mempool policy like RBF is very unlikely to be
> incorporated in the Bitcoin Core v0.10.x branch, simply because it'd be
> too large a change for a minor, mostly bugfix, release.
> 
> Having said that, I already maintain a standard RBF branch for v0.10.x,
> and have been asked by a major minor to backport FSS RBF for v0.10.x as
> well.
> 



From mike at plan99.net  Wed May 27 21:59:02 2015
From: mike at plan99.net (Mike Hearn)
Date: Wed, 27 May 2015 23:59:02 +0200
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <CANEZrP2x+fBitgcvoaC2qBbJS-Ek_hgS3ZGM55UtURKc-oDZMQ@mail.gmail.com>
References: <5550D8BE.6070207@electrum.org>
	<CANEZrP2x+fBitgcvoaC2qBbJS-Ek_hgS3ZGM55UtURKc-oDZMQ@mail.gmail.com>
Message-ID: <CANEZrP0ZdGp6Punh34mNMgaukHDQvMwDM_KEEsnuHn8Fj3Pt2Q@mail.gmail.com>

I wrote an article that explains the hashing assurance contract concept:

https://medium.com/@octskyward/hashing-7d04a887acc8

(it doesn't contain an in depth protocol description)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150527/2c8684cb/attachment.html>

From gmaxwell at gmail.com  Wed May 27 22:22:48 2015
From: gmaxwell at gmail.com (Gregory Maxwell)
Date: Wed, 27 May 2015 22:22:48 +0000
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <CANEZrP0ZdGp6Punh34mNMgaukHDQvMwDM_KEEsnuHn8Fj3Pt2Q@mail.gmail.com>
References: <5550D8BE.6070207@electrum.org>
	<CANEZrP2x+fBitgcvoaC2qBbJS-Ek_hgS3ZGM55UtURKc-oDZMQ@mail.gmail.com>
	<CANEZrP0ZdGp6Punh34mNMgaukHDQvMwDM_KEEsnuHn8Fj3Pt2Q@mail.gmail.com>
Message-ID: <CAAS2fgTdt9zY8KeOaob+idse1j9eraazBo5HukxJ8nkC_h=Zfw@mail.gmail.com>

On Wed, May 27, 2015 at 9:59 PM, Mike Hearn <mike at plan99.net> wrote:
> I wrote an article that explains the hashing assurance contract concept:
>
> https://medium.com/@octskyward/hashing-7d04a887acc8
>
> (it doesn't contain an in depth protocol description)

The prior (and seemingly this) assurance contract proposals pay the
miners who mines a chain supportive of your interests and miners whom
mine against your interests identically.

There is already a mechanism built into Bitcoin for paying for
security which doesn't have this problem, and which mitigates the
common action problem of people just sitting around for other people
to pay for security: transaction fees. Fixing the problem with
assurance contracts effectively makes them end up working like
transaction fees in any case.  Considering the near-failure in just
keeping development funded, I'm not sure where the believe this this
model will be workable comes from; in particular unlike a lighthouse
(but like development) security is ongoing and not primarily a fixed
one time cost. I note that many existing crowdfunding platforms
(including your own) do not do ongoing costs with this kind of binary
contract.

Also work reminding people that mining per-contract is a long
identified existential risk to Bitcoin which has been seeing more
analysis lately:
http://www.jbonneau.com/doc/BFGKN14-bitcoin_bribery.pdf



From sergiolerner at certimix.com  Wed May 27 22:52:18 2015
From: sergiolerner at certimix.com (Sergio Lerner)
Date: Wed, 27 May 2015 19:52:18 -0300
Subject: [Bitcoin-development] Version bits proposal
In-Reply-To: <CAE-z3OVskd1JAE5g-WW2eDiPcxysYhbv-NsOYu7yKZvzu88VSg@mail.gmail.com>
References: <CAPg+sBg5TqQ=zjyZ7dp-d1oBGp31Krnix3zyt9suP4-AGbxW=Q@mail.gmail.com>	<201505270346.17014.luke@dashjr.org>	<CABm2gDoriDaQ1AjRDFxCT9zCNPQakJd9xRxfWkOJBf4v22hndQ@mail.gmail.com>	<CAE-z3OVAKyppLVEWR=qNX-_p5yVAj_0Y7Kw76o4qaywf2DKtVw@mail.gmail.com>	<20150527101516.GB25814@savin.petertodd.org>
	<CAE-z3OVskd1JAE5g-WW2eDiPcxysYhbv-NsOYu7yKZvzu88VSg@mail.gmail.com>
Message-ID: <55664AA2.7020206@certimix.com>

I like the idea but I think we should leave at least 16 bits of the
version fixed as an extra-nonce.
If we don't then miners may use them as a nonce anyway, and mess with
the soft-fork voting system.
My original proposal was this: https://github.com/bitcoin/bitcoin/pull/5102

Best regards




From patrick.strateman at gmail.com  Thu May 28 01:05:08 2015
From: patrick.strateman at gmail.com (Patrick Strateman)
Date: Wed, 27 May 2015 18:05:08 -0700
Subject: [Bitcoin-development] Version bits proposal
In-Reply-To: <55664AA2.7020206@certimix.com>
References: <CAPg+sBg5TqQ=zjyZ7dp-d1oBGp31Krnix3zyt9suP4-AGbxW=Q@mail.gmail.com>	<201505270346.17014.luke@dashjr.org>	<CABm2gDoriDaQ1AjRDFxCT9zCNPQakJd9xRxfWkOJBf4v22hndQ@mail.gmail.com>	<CAE-z3OVAKyppLVEWR=qNX-_p5yVAj_0Y7Kw76o4qaywf2DKtVw@mail.gmail.com>	<20150527101516.GB25814@savin.petertodd.org>	<CAE-z3OVskd1JAE5g-WW2eDiPcxysYhbv-NsOYu7yKZvzu88VSg@mail.gmail.com>
	<55664AA2.7020206@certimix.com>
Message-ID: <556669C4.50406@gmail.com>

There is absolutely no reason to do this.

Any reasonable micro-controller can build merkle tree roots
significantly faster than is necessary.

1 Th/s walks the nonce range once every 4.3ms.

The largest valid merkle trees are 14 nodes high.

That translates to 28 SHA256 ops per 4.3ms or 6511 SHA256 ops/second.

For reference an RPi 1 model B does 2451050 SHA256 ops/second.

On 05/27/2015 03:52 PM, Sergio Lerner wrote:
> I like the idea but I think we should leave at least 16 bits of the
> version fixed as an extra-nonce.
> If we don't then miners may use them as a nonce anyway, and mess with
> the soft-fork voting system.
> My original proposal was this: https://github.com/bitcoin/bitcoin/pull/5102
>
> Best regards
>
>
> ------------------------------------------------------------------------------
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development





From onelineproof at gmail.com  Thu May 28 02:16:36 2015
From: onelineproof at gmail.com (Andrew)
Date: Thu, 28 May 2015 02:16:36 +0000
Subject: [Bitcoin-development] Scaling Bitcoin with Subchains
In-Reply-To: <CANEZrP1p3FU_0fvGKTDWF95Zns5S6KciayViZWiP6OmcqrQDUA@mail.gmail.com>
References: <CAL8tG==LG=xC_DzOaghbGGKab4=UVpGLQV7781pU4wg+WnFdMg@mail.gmail.com>
	<CANEZrP1p3FU_0fvGKTDWF95Zns5S6KciayViZWiP6OmcqrQDUA@mail.gmail.com>
Message-ID: <CAL8tG=m8kjPT8e5KsyhoGA4ni7Y9VeR=enX24MQVG4Kh0LnBKA@mail.gmail.com>

Hi All

I discussed this idea with some other core developers (on IRC) and they
generally seem to agree that it can be done.

It may be equivalent to an idea called "blockchain extensions" but when I
looked it up on bitcointalk.org I didn't see exactly the same proposal I am
making.

One person suggested I should replace the address to chain function with a
protocol addition that allows one to specify the target chain. Yes, this
can also be done without changing the key properties.

One person said that the main problem is that I am not saying anything
specific, and I should address the sidechain problems written about in the
sidechains paper. Well, actually, there is one quite specific thing I am
saying, in case you didn't notice: With this system, the network can
achieve effectively 5^{n-1} MB blocks with each participant only storing n
MB blocks. So for example, you can have effectively a block size of 625 MB
(= 5^4) with each participant only storing 3 MB blocks; or 3.125 GB blocks
with each participant only storing 4 MB blocks. For these calculations, I
am assuming that only two separate sibling chains are involved in a
transaction, so there is a duplication effect that divides in two the
effective size of a given level of blocks (that's why it's 5 instead of 10
as would be without duplication). If you want to involve multiple sibling
chains in one transaction, you can effectively achieve this by performing
multiple transactions involving 2 of the multiple chains. Yes, the fees
would be higher since you have more transactions to make, but it is
reasonable to expect more fees for more complicated transactions, and I
don't think it will result in people clustering on one chain (people who do
these kinds of transactions would probably track multiple chain paths). As
for the problems with sidechains, I think they would be eliminated due to
the child-parent dependence I specified. I also propose the following
additional rule: In case of conflict between parent and child chains (due
to reorganizations), the child chain must choose the consensus of the
parent chain. Also, for transferring from child to parent, the miners on
the parent have the final say, but to make it more clear, they can use the
relative difference of difficulty between their chain and the child chain
to decide how many blocks deep a transaction in the child chain has to be
to be accepted in the parent chain.

Gavin was the only one who disapproved of this, but I am not sure if he
actually read the whole thing that I wrote. He said something along the
line of "the outputs will span the subchains" and when I asked for an
explanation he just said that I need to learn more about things. I stated
to him my willingness to learn, but have yet to get a response from him.

Mike: You should also keep in mind the big picture when it comes to
decentralization. If the hard drives (or tapes) can only be produced by a
small number of large companies like Western Digital or Seagate, then you
can't really count those for a decentralized system. A truly decentralized
system would have the devices needed to participate in (and verify) the
system be easily created by a regular user of the system without relying on
a central power. So for example, the hard drives needed to store the
bitcoin transaction records should be able to be produced at a regular
person's home on a 3D printer starting from just the raw materials. I don't
know how close we are to this ideal, but just pointing out that it needs to
be considered. This is also a reason why I like that Bitcoin uses the
simple SHA sum for mining instead of a more complicated function such as
scrypt. It makes it easier for small scale entities to understand and to
produce the ASIC miners. Also, in addition to the centralization of storage
device manufacturing, one should also consider what would happen if
everyone wanted to have a 5 TB drive at home. What would happen to the
price of hard drives? Keep in mind also that the human population is likely
increasing, so there are less real resources per person... Yes maybe in the
future we can solve these problems, but we still haven't, so let's not
assume they are solved. Also, you mentioned sharing the costs of a hard
drive with other people. Do you mean trusting that others did not
compromise the hard drives? If you want you can do so, but not every
participant should be forced to trust others, a point I think I made
already. And finally, this is all a discussion on the costs of running a
Bitcoin node. Bitcoin is not all that people will use hard drives and
computers for; we need to leave room for other things.

So Mike, I have a question for you. Are you supporting a block size
increase partly due to philosophical reasons (i.e. you believe that regular
people shouldn't have such strong freedom as I want) or do you just not
care so much about the long term future and you just want to get your
Bitcoin related projects up and running with minimal complications? Or is
it a combination of both things? You should disclose this to the people
following your words because they trust you as an experienced professional
with a good reputation, and it would be dishonest to not disclose this to
them. (same goes for Gavin)

Overall, I think this system is the only system that I heard of that can
scale decentralization without a block size increase. Lightning by itself,
for example, requires a block size increase that depends on how many such
Lightning contracts are being made, so relies on people changing the
protocol, which is obviously less secure and robust than a fixed protocol.
But I am not ruling out any other possibilities, so other things should
also be considered. But eventually, we may have to decide how to scale
without knowing for sure whether the chosen scaling method is the ultimate
scaling method. And I think this is a good candidate for that, and also,
can be reversed later on without changing the original protocol before the
softfork. Actually, we can just make nodes advertise whether they support
the soft fork or not, and if a better scaling protocol comes along, those
nodes can switch to advertise the better one. So it is quite a harmless
soft fork to make, in my opinion.


On Mon, May 25, 2015 at 6:15 PM, Mike Hearn <mike at plan99.net> wrote:

> Hi Andrew,
>
> Your belief that Bitcoin has to be constrained by the belief that hardware
> will never improve is extremist, but regardless, your concerns are easy to
> assuage: there is no requirement that the block chain be stored on hard
> disks. As you note yourself the block chain is used for building/auditing
> the ledger. Random access to it is not required, if all you care about is
> running a full node.
>
> Luckily this makes it a great fit for tape backup. Technology that can
> store 185 terabytes *per cartridge* has already been developed:
>
>
> http://www.itworld.com/article/2693369/sony-develops-tape-tech-that-could-lead-to-185-tb-cartridges.html
>
> As you could certainly share costs of a block chain archive with other
> people, the cost would not be a major concern even today. And it's
> virtually guaranteed that humanity will not hit a storage technology wall
> in 2015.
>
> If your computer is compromised then all bets are off. Validating the
> chain on a compromised host is meaningless.
>



-- 
PGP: B6AC 822C 451D 6304 6A28  49E9 7DB7 011C D53B 5647
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150528/5f7a0d37/attachment.html>

From kanzure at gmail.com  Thu May 28 02:34:28 2015
From: kanzure at gmail.com (Bryan Bishop)
Date: Wed, 27 May 2015 21:34:28 -0500
Subject: [Bitcoin-development] Scaling Bitcoin with Subchains
In-Reply-To: <CAL8tG=m8kjPT8e5KsyhoGA4ni7Y9VeR=enX24MQVG4Kh0LnBKA@mail.gmail.com>
References: <CAL8tG==LG=xC_DzOaghbGGKab4=UVpGLQV7781pU4wg+WnFdMg@mail.gmail.com>
	<CANEZrP1p3FU_0fvGKTDWF95Zns5S6KciayViZWiP6OmcqrQDUA@mail.gmail.com>
	<CAL8tG=m8kjPT8e5KsyhoGA4ni7Y9VeR=enX24MQVG4Kh0LnBKA@mail.gmail.com>
Message-ID: <CABaSBay22Xse0ubsEWQ-g9o+UmCqz3KeV8fKhoBUXC+Dg+s8bQ@mail.gmail.com>

On Wed, May 27, 2015 at 9:16 PM, Andrew <onelineproof at gmail.com> wrote:

> You should also keep in mind the big picture when it comes to
> decentralization. If the hard drives (or tapes) can only be produced by a
> small number of large companies like Western Digital or Seagate, then you
> can't really count those for a decentralized system. A truly decentralized
> system would have the devices needed to participate in (and verify) the
> system be easily created by a regular user of the system without relying on
> a central power. So for example, the hard drives needed to store the
> bitcoin transaction records should be able to be produced at a regular
> person's home on a 3D printer starting from just the raw materials. I don't
> know how close we are to this ideal, but just pointing out that it needs to
> be considered. This is also a reason why I like that Bitcoin uses the
> simple SHA sum for mining instead of a more complicated function such as
> scrypt. It makes it easier for small scale entities to understand and to
> produce the ASIC miners.


I am a huge fan of do-it-yourself at-home ASIC manufacturing. The original
4004 and earlier devices are within the scope of what could be accomplished
in a home environment. The homecmos project is an interesting glimpse at
these possibilities. Relevant-scale mining will most likely never be an
option for home manufacturing, but bitcoin wallets and other devices can
definitely be etched by hand or using maskless projector lithography.

Here's what the homecmos group was up to:
https://code.google.com/p/homecmos/
http://homecmos.drawersteak.com/wiki/
http://diyhpl.us/~bryan/papers2/optics/photolithography/DIY%20fabrication%20of%20microstructures%20by%20projection%20photolithography.pdf

LCD projection lithography:
http://diyhpl.us/~bryan/papers2/optics/photolithography/Cell%20micropatterning%20using%20photopolymerization%20with%20a%20liquid%20crystal%20device%20(LCD)%20commercial%20projector%20-%20Itoga%20-%202003.pdf
http://diyhpl.us/~bryan/papers2/optics/photolithography/Development%20of%20microfabrication%20technology%20with%20maskless%20photolithography%20device%20using%20LCD%20projector%20-%20Itoga%20-%202010.pdf
http://diyhpl.us/~bryan/papers2/optics/photolithography/Second-generation%20maskless%20photolithography%20device%20for%20surface%20micropatterning%20and%20microfluidic%20channel%20fabrication%20(using%20an%20LCD%20projector).pdf

DMD lithography:
http://diyhpl.us/~bryan/papers2/optics/photolithography/Maskless%20microscopic%20lithography%20through%20shaping%20ultraviolet%20(UV)%20laser%20with%20digital%20micromirror%20device%20(DMD)%20-%202013.pdf
http://diyhpl.us/~bryan/papers2/optics/photolithography/A%20maskless%20photolithographic%20prototyping%20system%20using%20a%20low-cost%20consumer%20projector%20and%20a%20microscope.pdf

There's actually a method of doing this with conventional camera roll film:
https://groups.google.com/d/msg/diybio/5hpQXZ6hFKY/baGNfY_-Wx8J

- Bryan
http://heybryan.org/
1 512 203 0507
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150527/7e468480/attachment.html>

From decker.christian at gmail.com  Thu May 28 07:51:39 2015
From: decker.christian at gmail.com (Christian Decker)
Date: Thu, 28 May 2015 07:51:39 +0000
Subject: [Bitcoin-development] Version bits proposal
In-Reply-To: <556669C4.50406@gmail.com>
References: <CAPg+sBg5TqQ=zjyZ7dp-d1oBGp31Krnix3zyt9suP4-AGbxW=Q@mail.gmail.com>
	<201505270346.17014.luke@dashjr.org>
	<CABm2gDoriDaQ1AjRDFxCT9zCNPQakJd9xRxfWkOJBf4v22hndQ@mail.gmail.com>
	<CAE-z3OVAKyppLVEWR=qNX-_p5yVAj_0Y7Kw76o4qaywf2DKtVw@mail.gmail.com>
	<20150527101516.GB25814@savin.petertodd.org>
	<CAE-z3OVskd1JAE5g-WW2eDiPcxysYhbv-NsOYu7yKZvzu88VSg@mail.gmail.com>
	<55664AA2.7020206@certimix.com> <556669C4.50406@gmail.com>
Message-ID: <CALxbBHU3hT7+zOddryE0aW7otmE0OfQWi8WmFuhR_XZRK2VRNQ@mail.gmail.com>

Agreed, there is no need to misuse the version field as well. There is more
than enough variability you could roll in the merkle tree including and
excluding transactions, and the scriptSig of the coinbase transaction,
which also influences the merkle root.

I have a fundamental dislike of retroactively changing semantics, and the
version field should be used just for that: a version. I don't even
particularly like flagging support for a fork in the version field, but
since I have no better solution, count me as supporting Sipa's proposal. We
definitely need a more comfortable way of rolling out new features.

Regards,
Chris

On Thu, May 28, 2015 at 3:08 AM Patrick Strateman <
patrick.strateman at gmail.com> wrote:

> There is absolutely no reason to do this.
>
> Any reasonable micro-controller can build merkle tree roots
> significantly faster than is necessary.
>
> 1 Th/s walks the nonce range once every 4.3ms.
>
> The largest valid merkle trees are 14 nodes high.
>
> That translates to 28 SHA256 ops per 4.3ms or 6511 SHA256 ops/second.
>
> For reference an RPi 1 model B does 2451050 SHA256 ops/second.
>
> On 05/27/2015 03:52 PM, Sergio Lerner wrote:
> > I like the idea but I think we should leave at least 16 bits of the
> > version fixed as an extra-nonce.
> > If we don't then miners may use them as a nonce anyway, and mess with
> > the soft-fork voting system.
> > My original proposal was this:
> https://github.com/bitcoin/bitcoin/pull/5102
> >
> > Best regards
> >
> >
> >
> ------------------------------------------------------------------------------
> > _______________________________________________
> > Bitcoin-development mailing list
> > Bitcoin-development at lists.sourceforge.net
> > https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
>
>
> ------------------------------------------------------------------------------
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150528/ee647d97/attachment.html>

From adam at cypherspace.org  Thu May 28 08:11:21 2015
From: adam at cypherspace.org (Adam Back)
Date: Thu, 28 May 2015 09:11:21 +0100
Subject: [Bitcoin-development] Version bits proposal
In-Reply-To: <CALxbBHU3hT7+zOddryE0aW7otmE0OfQWi8WmFuhR_XZRK2VRNQ@mail.gmail.com>
References: <CAPg+sBg5TqQ=zjyZ7dp-d1oBGp31Krnix3zyt9suP4-AGbxW=Q@mail.gmail.com>
	<201505270346.17014.luke@dashjr.org>
	<CABm2gDoriDaQ1AjRDFxCT9zCNPQakJd9xRxfWkOJBf4v22hndQ@mail.gmail.com>
	<CAE-z3OVAKyppLVEWR=qNX-_p5yVAj_0Y7Kw76o4qaywf2DKtVw@mail.gmail.com>
	<20150527101516.GB25814@savin.petertodd.org>
	<CAE-z3OVskd1JAE5g-WW2eDiPcxysYhbv-NsOYu7yKZvzu88VSg@mail.gmail.com>
	<55664AA2.7020206@certimix.com> <556669C4.50406@gmail.com>
	<CALxbBHU3hT7+zOddryE0aW7otmE0OfQWi8WmFuhR_XZRK2VRNQ@mail.gmail.com>
Message-ID: <CALqxMTEc4K_YQo8aU1RwgJYasPs=bR8ORux8pyp0XDMTmNqNAg@mail.gmail.com>

Or as far as that goes, permuting (the non-dependent) transactions in
the block by permuting the internal merkle tree nodes at increasing
depths.  (Dependent because transactions that depend on each other
have to come in-order; but one could eg put the n-1 of each n sequence
of in-order transactions in the left-half and unordered in the right
half.)

That makes the tree manipulations maximum depth independent, and even
transaction independent possibly - just need to know enough depth in
the tree of hashes that are permutation safe.

Adam

On 28 May 2015 at 08:51, Christian Decker <decker.christian at gmail.com> wrote:
> Agreed, there is no need to misuse the version field as well. There is more
> than enough variability you could roll in the merkle tree including and
> excluding transactions, and the scriptSig of the coinbase transaction, which
> also influences the merkle root.
>
> I have a fundamental dislike of retroactively changing semantics, and the
> version field should be used just for that: a version. I don't even
> particularly like flagging support for a fork in the version field, but
> since I have no better solution, count me as supporting Sipa's proposal. We
> definitely need a more comfortable way of rolling out new features.
>
> Regards,
> Chris
>
> On Thu, May 28, 2015 at 3:08 AM Patrick Strateman
> <patrick.strateman at gmail.com> wrote:
>>
>> There is absolutely no reason to do this.
>>
>> Any reasonable micro-controller can build merkle tree roots
>> significantly faster than is necessary.
>>
>> 1 Th/s walks the nonce range once every 4.3ms.
>>
>> The largest valid merkle trees are 14 nodes high.
>>
>> That translates to 28 SHA256 ops per 4.3ms or 6511 SHA256 ops/second.
>>
>> For reference an RPi 1 model B does 2451050 SHA256 ops/second.
>>
>> On 05/27/2015 03:52 PM, Sergio Lerner wrote:
>> > I like the idea but I think we should leave at least 16 bits of the
>> > version fixed as an extra-nonce.
>> > If we don't then miners may use them as a nonce anyway, and mess with
>> > the soft-fork voting system.
>> > My original proposal was this:
>> > https://github.com/bitcoin/bitcoin/pull/5102
>> >
>> > Best regards
>> >
>> >
>> >
>> > ------------------------------------------------------------------------------
>> > _______________________________________________
>> > Bitcoin-development mailing list
>> > Bitcoin-development at lists.sourceforge.net
>> > https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>>
>>
>>
>> ------------------------------------------------------------------------------
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
> ------------------------------------------------------------------------------
>
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>



From mark at friedenbach.org  Thu May 28 09:56:36 2015
From: mark at friedenbach.org (Mark Friedenbach)
Date: Thu, 28 May 2015 02:56:36 -0700
Subject: [Bitcoin-development] Consensus-enforced transaction
 replacement via sequence numbers
In-Reply-To: <CANEZrP0zKe7hK0KjiXN9M6CHnJxKZfW9myez3G+GWpr3fugBCg@mail.gmail.com>
References: <CAOG=w-sfiUQQGUh=RR55NU-TkAi1+2g3_Z+YP3dGDjp8zXYBGQ@mail.gmail.com>
	<CANEZrP0QMHp9PwBr=ekkujtA+=LXbgiL4xkXRSmcOGqaLJEp0g@mail.gmail.com>
	<CAOG=w-s7JkB6SyEE0=KwmrasyH22aB2Zf3jBdKcXvrGoNhN_Nw@mail.gmail.com>
	<CANEZrP0zKe7hK0KjiXN9M6CHnJxKZfW9myez3G+GWpr3fugBCg@mail.gmail.com>
Message-ID: <CAOG=w-vusO30sBZfsuP94wbkUUfHupmhQtScGsJ2463sO=EpzA@mail.gmail.com>

I have no problem with modifying the proposal to have the most significant
bit signal use of the nSequence field as a relative lock-time. That leaves
a full 31 bits for experimentation when relative lock-time is not in use. I
have adjusted the code appropriately:

https://github.com/maaku/bitcoin/tree/sequencenumbers

On Wed, May 27, 2015 at 10:39 AM, Mike Hearn <mike at plan99.net> wrote:

> Mike, this proposal was purposefully constructed to maintain as well as
>> possible the semantics of Satoshi's original construction. Higher sequence
>> numbers -- chronologically later transactions -- are able to hit the chain
>> earlier, and therefore it can be reasonably argued will be selected by
>> miners before the later transactions mature. Did I fail in some way to
>> capture that original intent?
>>
>
> Right, but the original protocol allowed for e.g. millions of revisions of
> the transaction, hence for high frequency trading (that's actually how
> Satoshi originally explained it to me - as a way to do HFT - back then the
> channel concept didn't exist).
>
> As you point out, with a careful construction of channels you should only
> need to bump the sequence number when the channel reverses direction. If
> your app only needs to do that rarely, it's a fine approach.And your
> proposal does sounds better than sequence numbers being useless like at the
> moment. I'm just wondering if we can get back to the original somehow or at
> least leave a path open to it, as it seems to be a superset of all other
> proposals, features-wise.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150528/ae531ae4/attachment.html>

From mike at plan99.net  Thu May 28 10:23:48 2015
From: mike at plan99.net (Mike Hearn)
Date: Thu, 28 May 2015 12:23:48 +0200
Subject: [Bitcoin-development] Consensus-enforced transaction
 replacement via sequence numbers
In-Reply-To: <CAOG=w-vusO30sBZfsuP94wbkUUfHupmhQtScGsJ2463sO=EpzA@mail.gmail.com>
References: <CAOG=w-sfiUQQGUh=RR55NU-TkAi1+2g3_Z+YP3dGDjp8zXYBGQ@mail.gmail.com>
	<CANEZrP0QMHp9PwBr=ekkujtA+=LXbgiL4xkXRSmcOGqaLJEp0g@mail.gmail.com>
	<CAOG=w-s7JkB6SyEE0=KwmrasyH22aB2Zf3jBdKcXvrGoNhN_Nw@mail.gmail.com>
	<CANEZrP0zKe7hK0KjiXN9M6CHnJxKZfW9myez3G+GWpr3fugBCg@mail.gmail.com>
	<CAOG=w-vusO30sBZfsuP94wbkUUfHupmhQtScGsJ2463sO=EpzA@mail.gmail.com>
Message-ID: <CANEZrP0=R6-6CQsd3+OsY8Aq646d4i+FUB3G475OyvgbmjFyEg@mail.gmail.com>

Cool, thanks.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150528/855f7291/attachment.html>

From tier.nolan at gmail.com  Thu May 28 10:30:18 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Thu, 28 May 2015 11:30:18 +0100
Subject: [Bitcoin-development] Consensus-enforced transaction
 replacement via sequence numbers
In-Reply-To: <CAOG=w-vusO30sBZfsuP94wbkUUfHupmhQtScGsJ2463sO=EpzA@mail.gmail.com>
References: <CAOG=w-sfiUQQGUh=RR55NU-TkAi1+2g3_Z+YP3dGDjp8zXYBGQ@mail.gmail.com>
	<CANEZrP0QMHp9PwBr=ekkujtA+=LXbgiL4xkXRSmcOGqaLJEp0g@mail.gmail.com>
	<CAOG=w-s7JkB6SyEE0=KwmrasyH22aB2Zf3jBdKcXvrGoNhN_Nw@mail.gmail.com>
	<CANEZrP0zKe7hK0KjiXN9M6CHnJxKZfW9myez3G+GWpr3fugBCg@mail.gmail.com>
	<CAOG=w-vusO30sBZfsuP94wbkUUfHupmhQtScGsJ2463sO=EpzA@mail.gmail.com>
Message-ID: <CAE-z3OUG5p_hAOFvaE10kTT7sa=2GrzvZpis5FzATSEcNwZpyw@mail.gmail.com>

Can you update it so that it only applies to transactions with version
number 3 and higher.  Changing the meaning of a field is exactly what the
version numbers are for.

You could even decode version 3 transactions like that.

Version 3 transactions have a sequence number of 0xFFFFFFFF and the
sequence number field is re-purposed for relative lock time.

This means that legacy transactions that have already been signed but have
a locktime in the future will still be able to enter the blockchain
(without having to wait significantly longer than expected).

On Thu, May 28, 2015 at 10:56 AM, Mark Friedenbach <mark at friedenbach.org>
wrote:

> I have no problem with modifying the proposal to have the most significant
> bit signal use of the nSequence field as a relative lock-time. That leaves
> a full 31 bits for experimentation when relative lock-time is not in use. I
> have adjusted the code appropriately:
>
> https://github.com/maaku/bitcoin/tree/sequencenumbers
>
> On Wed, May 27, 2015 at 10:39 AM, Mike Hearn <mike at plan99.net> wrote:
>
>> Mike, this proposal was purposefully constructed to maintain as well as
>>> possible the semantics of Satoshi's original construction. Higher sequence
>>> numbers -- chronologically later transactions -- are able to hit the chain
>>> earlier, and therefore it can be reasonably argued will be selected by
>>> miners before the later transactions mature. Did I fail in some way to
>>> capture that original intent?
>>>
>>
>> Right, but the original protocol allowed for e.g. millions of revisions
>> of the transaction, hence for high frequency trading (that's actually how
>> Satoshi originally explained it to me - as a way to do HFT - back then the
>> channel concept didn't exist).
>>
>> As you point out, with a careful construction of channels you should only
>> need to bump the sequence number when the channel reverses direction. If
>> your app only needs to do that rarely, it's a fine approach.And your
>> proposal does sounds better than sequence numbers being useless like at the
>> moment. I'm just wondering if we can get back to the original somehow or at
>> least leave a path open to it, as it seems to be a superset of all other
>> proposals, features-wise.
>>
>
>
>
> ------------------------------------------------------------------------------
>
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150528/e03cd831/attachment.html>

From mike at plan99.net  Thu May 28 10:30:55 2015
From: mike at plan99.net (Mike Hearn)
Date: Thu, 28 May 2015 12:30:55 +0200
Subject: [Bitcoin-development] Long-term mining incentives
In-Reply-To: <CAAS2fgTdt9zY8KeOaob+idse1j9eraazBo5HukxJ8nkC_h=Zfw@mail.gmail.com>
References: <5550D8BE.6070207@electrum.org>
	<CANEZrP2x+fBitgcvoaC2qBbJS-Ek_hgS3ZGM55UtURKc-oDZMQ@mail.gmail.com>
	<CANEZrP0ZdGp6Punh34mNMgaukHDQvMwDM_KEEsnuHn8Fj3Pt2Q@mail.gmail.com>
	<CAAS2fgTdt9zY8KeOaob+idse1j9eraazBo5HukxJ8nkC_h=Zfw@mail.gmail.com>
Message-ID: <CANEZrP0toD-oJZRL62GN=TOVeG=dfd8k3MNh54mvkdteETA4XA@mail.gmail.com>

>
> The prior (and seemingly this) assurance contract proposals pay the
> miners who mines a chain supportive of your interests and miners whom
> mine against your interests identically.
>

The same is true today - via inflation I pay for blocks regardless of
whether they contain or double spend my transactions or not. So I don't see
why it'd be different in future.


> There is already a mechanism built into Bitcoin for paying for
> security which doesn't have this problem, and which mitigates the
> common action problem of people just sitting around for other people
> to pay for security: transaction fees.


The article states quite clearly that assurance contracts are proposed only
if people setting transaction fees themselves doesn't work. There's some
reasonably good arguments that it probably won't work, but I don't assign
very high weight to game theoretic arguments these days so it wouldn't
surprise me if Satoshi's original plan worked out OK too.

Of course, by the time this matters I plan to be sipping a pina colada on
my private retirement beach :) It's a problem the next generation can
tackle, as far as I am concerned.


> Considering the near-failure in just keeping development funded, I'm not
> sure where the believe this this model will be workable comes from


Patience :)

Right now it's a lot easier to get development money from VC funds and rich
benefactors than raising it directly from the community, so unsurprisingly
that's what most people do.

Despite that, the Hourglass design document project now has sufficient
pre-pledges that it should be possible to crowdfund it successfully once I
get around to actually doing the work. And BitSquare was able to raise
nearly half of their target despite an incredibly aggressive deadline and
the fact that they hadn't shipped a usable prototype. I think as people get
better at crafting their contracts and people get more experience with
funding work this way, we'll see it get more common.

But yes. Paying for things via assurance contracts is a long term and very
experimental plan, for sure.


> one time cost. I note that many existing crowdfunding platforms
> (including your own) do not do ongoing costs with this kind of binary
> contract.
>

Lighthouse wasn't written to do hashing assurance contracts, so no, it
doesn't have such a feature. Perhaps in version 2.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150528/c7d06ab0/attachment.html>

From pete at petertodd.org  Thu May 28 12:04:34 2015
From: pete at petertodd.org (Peter Todd)
Date: Thu, 28 May 2015 08:04:34 -0400
Subject: [Bitcoin-development] Consensus-enforced transaction
 replacement via sequence numbers
In-Reply-To: <CAE-z3OUG5p_hAOFvaE10kTT7sa=2GrzvZpis5FzATSEcNwZpyw@mail.gmail.com>
References: <CAOG=w-sfiUQQGUh=RR55NU-TkAi1+2g3_Z+YP3dGDjp8zXYBGQ@mail.gmail.com>
	<CANEZrP0QMHp9PwBr=ekkujtA+=LXbgiL4xkXRSmcOGqaLJEp0g@mail.gmail.com>
	<CAOG=w-s7JkB6SyEE0=KwmrasyH22aB2Zf3jBdKcXvrGoNhN_Nw@mail.gmail.com>
	<CANEZrP0zKe7hK0KjiXN9M6CHnJxKZfW9myez3G+GWpr3fugBCg@mail.gmail.com>
	<CAOG=w-vusO30sBZfsuP94wbkUUfHupmhQtScGsJ2463sO=EpzA@mail.gmail.com>
	<CAE-z3OUG5p_hAOFvaE10kTT7sa=2GrzvZpis5FzATSEcNwZpyw@mail.gmail.com>
Message-ID: <20150528120434.GA31349@savin.petertodd.org>

On Thu, May 28, 2015 at 11:30:18AM +0100, Tier Nolan wrote:
> Can you update it so that it only applies to transactions with version
> number 3 and higher.  Changing the meaning of a field is exactly what the
> version numbers are for.
> 
> You could even decode version 3 transactions like that.
> 
> Version 3 transactions have a sequence number of 0xFFFFFFFF and the
> sequence number field is re-purposed for relative lock time.
> 
> This means that legacy transactions that have already been signed but have
> a locktime in the future will still be able to enter the blockchain
> (without having to wait significantly longer than expected).

For that matter, we probably don't want to treat this as a *version*
change, but rather a *feature* flag. For instance, nSequence is
potentially useful for co-ordinating multiple signatures to ensure they
can only be used in certain combinations, a use-case not neccesarily
compatible with this idea of a relative lock. Similarly it's potentially
useful for dealing with malleability.

nSequence is currently the *only* thing in CTxIn's that the signature
signs that can be freely changed; I won't be surprised if we find other
uses for it.

Of course, all of the above is assuming this proposal is useful; that's
not clear to me yet and won't be without fleshed out examples.

-- 
'peter'[:-1]@petertodd.org
000000000000000008464a6a19387029fa99edace15996d06a6343a8345d6167
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150528/b3fb4c20/attachment.sig>

From tier.nolan at gmail.com  Thu May 28 13:35:57 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Thu, 28 May 2015 14:35:57 +0100
Subject: [Bitcoin-development] Consensus-enforced transaction
 replacement via sequence numbers
In-Reply-To: <20150528120434.GA31349@savin.petertodd.org>
References: <CAOG=w-sfiUQQGUh=RR55NU-TkAi1+2g3_Z+YP3dGDjp8zXYBGQ@mail.gmail.com>
	<CANEZrP0QMHp9PwBr=ekkujtA+=LXbgiL4xkXRSmcOGqaLJEp0g@mail.gmail.com>
	<CAOG=w-s7JkB6SyEE0=KwmrasyH22aB2Zf3jBdKcXvrGoNhN_Nw@mail.gmail.com>
	<CANEZrP0zKe7hK0KjiXN9M6CHnJxKZfW9myez3G+GWpr3fugBCg@mail.gmail.com>
	<CAOG=w-vusO30sBZfsuP94wbkUUfHupmhQtScGsJ2463sO=EpzA@mail.gmail.com>
	<CAE-z3OUG5p_hAOFvaE10kTT7sa=2GrzvZpis5FzATSEcNwZpyw@mail.gmail.com>
	<20150528120434.GA31349@savin.petertodd.org>
Message-ID: <CAE-z3OX6pn8HpCXhsN1r_7rX9Wno_e-8dgnrzq0egQNk7N=r3w@mail.gmail.com>

On Thu, May 28, 2015 at 1:04 PM, Peter Todd <pete at petertodd.org> wrote:

> For that matter, we probably don't want to treat this as a *version*
> change, but rather a *feature* flag.


I think it is still a version change.  At the moment, the 4 bytes refer to
the sequence number and afterwards they mean something else.

For relative locktime verify, I think most use cases could be block count
based and don't need to be able to count very high.

I think the main benefit is that protocols can have one party trigger a
step while giving the other party guaranteed time to respond.


*Fast Channel Close*

This assumes that malleability is fixed.

Alice creates

TXA:
output (x) to [multisig A1 & B1]

Refund:
input TXA (signed by Alice)
Output [(A2 & relative_check_locktime(150)) OR (multisig A3 &  B2)]

Alice sends Refund to Bob

Bob signs it and sends it back to Alice

Alice verifies the signature, adds her own and sends it to Bob.

She broadcasts TXA (would wait until Bob confirms acceptance).

This means that both Alice and Bob have the refund transaction and can use
it to close the channel (assuming TXA is not mutated).

Alice can send money to Bob by creating a transaction which spends the
output of the refund transaction (splitting the output x-b for Alice and b
for Bob), signing it and sending it to Bob.

Alice can force Bob to close the channel by broadcasting the refund
transaction.  150 blocks later, she gets the channel deposit if he doesn't
act.

If she had sent some money to Bob, he has 150 blocks to sign the
transaction that pays him the most money and broadcast it.  Alice gets the
remainder of the deposit.

Alice cannot broadcast earlier version, since Bob doesn't send her the
signed versions.

This means that the channel doesn't need a defined end date.  Either party
can close the channel whenever they want.

TXA could be protected against malleability by adding a locktime path.
This would only be for use if the transaction is mutated.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150528/c68865b7/attachment.html>

From mark at friedenbach.org  Thu May 28 14:59:13 2015
From: mark at friedenbach.org (Mark Friedenbach)
Date: Thu, 28 May 2015 07:59:13 -0700
Subject: [Bitcoin-development] Consensus-enforced transaction
 replacement via sequence numbers
In-Reply-To: <CAE-z3OUG5p_hAOFvaE10kTT7sa=2GrzvZpis5FzATSEcNwZpyw@mail.gmail.com>
References: <CAOG=w-sfiUQQGUh=RR55NU-TkAi1+2g3_Z+YP3dGDjp8zXYBGQ@mail.gmail.com>
	<CANEZrP0QMHp9PwBr=ekkujtA+=LXbgiL4xkXRSmcOGqaLJEp0g@mail.gmail.com>
	<CAOG=w-s7JkB6SyEE0=KwmrasyH22aB2Zf3jBdKcXvrGoNhN_Nw@mail.gmail.com>
	<CANEZrP0zKe7hK0KjiXN9M6CHnJxKZfW9myez3G+GWpr3fugBCg@mail.gmail.com>
	<CAOG=w-vusO30sBZfsuP94wbkUUfHupmhQtScGsJ2463sO=EpzA@mail.gmail.com>
	<CAE-z3OUG5p_hAOFvaE10kTT7sa=2GrzvZpis5FzATSEcNwZpyw@mail.gmail.com>
Message-ID: <CAOG=w-tQyrc8ncAFauDObmBYn3uSwBcLoWVqruaV6PcTUFbTKg@mail.gmail.com>

Why 3? Do we have a version 2?

As for doing it in serialization, that would alter the txid making it a
hard fork change.
On May 28, 2015 03:30, "Tier Nolan" <tier.nolan at gmail.com> wrote:

> Can you update it so that it only applies to transactions with version
> number 3 and higher.  Changing the meaning of a field is exactly what the
> version numbers are for.
>
> You could even decode version 3 transactions like that.
>
> Version 3 transactions have a sequence number of 0xFFFFFFFF and the
> sequence number field is re-purposed for relative lock time.
>
> This means that legacy transactions that have already been signed but have
> a locktime in the future will still be able to enter the blockchain
> (without having to wait significantly longer than expected).
>
> On Thu, May 28, 2015 at 10:56 AM, Mark Friedenbach <mark at friedenbach.org>
> wrote:
>
>> I have no problem with modifying the proposal to have the most
>> significant bit signal use of the nSequence field as a relative lock-time.
>> That leaves a full 31 bits for experimentation when relative lock-time is
>> not in use. I have adjusted the code appropriately:
>>
>> https://github.com/maaku/bitcoin/tree/sequencenumbers
>>
>> On Wed, May 27, 2015 at 10:39 AM, Mike Hearn <mike at plan99.net> wrote:
>>
>>> Mike, this proposal was purposefully constructed to maintain as well as
>>>> possible the semantics of Satoshi's original construction. Higher sequence
>>>> numbers -- chronologically later transactions -- are able to hit the chain
>>>> earlier, and therefore it can be reasonably argued will be selected by
>>>> miners before the later transactions mature. Did I fail in some way to
>>>> capture that original intent?
>>>>
>>>
>>> Right, but the original protocol allowed for e.g. millions of revisions
>>> of the transaction, hence for high frequency trading (that's actually how
>>> Satoshi originally explained it to me - as a way to do HFT - back then the
>>> channel concept didn't exist).
>>>
>>> As you point out, with a careful construction of channels you should
>>> only need to bump the sequence number when the channel reverses direction.
>>> If your app only needs to do that rarely, it's a fine approach.And your
>>> proposal does sounds better than sequence numbers being useless like at the
>>> moment. I'm just wondering if we can get back to the original somehow or at
>>> least leave a path open to it, as it seems to be a superset of all other
>>> proposals, features-wise.
>>>
>>
>>
>>
>> ------------------------------------------------------------------------------
>>
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>>
>
>
> ------------------------------------------------------------------------------
>
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150528/0d4e5a2a/attachment.html>

From tier.nolan at gmail.com  Thu May 28 15:18:05 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Thu, 28 May 2015 16:18:05 +0100
Subject: [Bitcoin-development] Consensus-enforced transaction
 replacement via sequence numbers
In-Reply-To: <CAOG=w-tQyrc8ncAFauDObmBYn3uSwBcLoWVqruaV6PcTUFbTKg@mail.gmail.com>
References: <CAOG=w-sfiUQQGUh=RR55NU-TkAi1+2g3_Z+YP3dGDjp8zXYBGQ@mail.gmail.com>
	<CANEZrP0QMHp9PwBr=ekkujtA+=LXbgiL4xkXRSmcOGqaLJEp0g@mail.gmail.com>
	<CAOG=w-s7JkB6SyEE0=KwmrasyH22aB2Zf3jBdKcXvrGoNhN_Nw@mail.gmail.com>
	<CANEZrP0zKe7hK0KjiXN9M6CHnJxKZfW9myez3G+GWpr3fugBCg@mail.gmail.com>
	<CAOG=w-vusO30sBZfsuP94wbkUUfHupmhQtScGsJ2463sO=EpzA@mail.gmail.com>
	<CAE-z3OUG5p_hAOFvaE10kTT7sa=2GrzvZpis5FzATSEcNwZpyw@mail.gmail.com>
	<CAOG=w-tQyrc8ncAFauDObmBYn3uSwBcLoWVqruaV6PcTUFbTKg@mail.gmail.com>
Message-ID: <CAE-z3OXO++0n+UVKe1KYyGv=GyHrZ-MsJtYELk+KC6cEV2UbHQ@mail.gmail.com>

On Thu, May 28, 2015 at 3:59 PM, Mark Friedenbach <mark at friedenbach.org>
wrote:

> Why 3? Do we have a version 2?
>
I meant whatever the next version is, so you are right, it's version 2.

> As for doing it in serialization, that would alter the txid making it a
> hard fork change.
>
The change is backwards compatible (since there is no restrictions on
sequence numbers).   This makes it a soft fork.

That doesn't change the fact that you are changing what a field in the
transaction represents.

You could say that the sequence number is no longer encoded in the
serialization, it is assumed to be 0xFFFFFFFF for all version 2+
transactions and the relative locktime is a whole new field that is the
same size (and position).

I think keeping some of the bytes for other uses is a good idea.  The
entire top 2 bytes could be ignored when working out relative locktime
verify.  That leaves them fully free to be set to anything.

It could be that if the MSB of the bottom 2 bytes is set, then that
activates the rule and the top 2 bytes are ignored.

Are there any use-cases which need a RLTV of more than 8191 blocks delay
(that can't be covered by the absolute version)?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150528/c5be8db5/attachment.html>

From mark at friedenbach.org  Thu May 28 15:38:43 2015
From: mark at friedenbach.org (Mark Friedenbach)
Date: Thu, 28 May 2015 08:38:43 -0700
Subject: [Bitcoin-development] Consensus-enforced transaction
 replacement via sequence numbers
In-Reply-To: <CAE-z3OXO++0n+UVKe1KYyGv=GyHrZ-MsJtYELk+KC6cEV2UbHQ@mail.gmail.com>
References: <CAOG=w-sfiUQQGUh=RR55NU-TkAi1+2g3_Z+YP3dGDjp8zXYBGQ@mail.gmail.com>
	<CANEZrP0QMHp9PwBr=ekkujtA+=LXbgiL4xkXRSmcOGqaLJEp0g@mail.gmail.com>
	<CAOG=w-s7JkB6SyEE0=KwmrasyH22aB2Zf3jBdKcXvrGoNhN_Nw@mail.gmail.com>
	<CANEZrP0zKe7hK0KjiXN9M6CHnJxKZfW9myez3G+GWpr3fugBCg@mail.gmail.com>
	<CAOG=w-vusO30sBZfsuP94wbkUUfHupmhQtScGsJ2463sO=EpzA@mail.gmail.com>
	<CAE-z3OUG5p_hAOFvaE10kTT7sa=2GrzvZpis5FzATSEcNwZpyw@mail.gmail.com>
	<CAOG=w-tQyrc8ncAFauDObmBYn3uSwBcLoWVqruaV6PcTUFbTKg@mail.gmail.com>
	<CAE-z3OXO++0n+UVKe1KYyGv=GyHrZ-MsJtYELk+KC6cEV2UbHQ@mail.gmail.com>
Message-ID: <CAOG=w-vY7WHso90mtzhSRiuTLVfahMv1Xr6p_AZvyh4krxPLSg@mail.gmail.com>

Oh ok you mean a semantic difference for the purpose of explaining. It
doesn't actually change the code.

Regarding saving more bits, there really isn't much room if you consider
time-based relative locktimes and long-lived channels on the order of a
year or more.

On Thu, May 28, 2015 at 8:18 AM, Tier Nolan <tier.nolan at gmail.com> wrote:

> On Thu, May 28, 2015 at 3:59 PM, Mark Friedenbach <mark at friedenbach.org>
> wrote:
>
>> Why 3? Do we have a version 2?
>>
> I meant whatever the next version is, so you are right, it's version 2.
>
>> As for doing it in serialization, that would alter the txid making it a
>> hard fork change.
>>
> The change is backwards compatible (since there is no restrictions on
> sequence numbers).   This makes it a soft fork.
>
> That doesn't change the fact that you are changing what a field in the
> transaction represents.
>
> You could say that the sequence number is no longer encoded in the
> serialization, it is assumed to be 0xFFFFFFFF for all version 2+
> transactions and the relative locktime is a whole new field that is the
> same size (and position).
>
> I think keeping some of the bytes for other uses is a good idea.  The
> entire top 2 bytes could be ignored when working out relative locktime
> verify.  That leaves them fully free to be set to anything.
>
> It could be that if the MSB of the bottom 2 bytes is set, then that
> activates the rule and the top 2 bytes are ignored.
>
> Are there any use-cases which need a RLTV of more than 8191 blocks delay
> (that can't be covered by the absolute version)?
>
>
> ------------------------------------------------------------------------------
>
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150528/37f27f81/attachment.html>

From gavinandresen at gmail.com  Thu May 28 15:53:41 2015
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Thu, 28 May 2015 11:53:41 -0400
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <16096345.A1MpJQQkRW@crushinator>
References: <16096345.A1MpJQQkRW@crushinator>
Message-ID: <CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>

On Fri, May 8, 2015 at 3:20 AM, Matt Whitlock <bip at mattwhitlock.name> wrote:

> Between all the flames on this list, several ideas were raised that did
> not get much attention. I hereby resubmit these ideas for consideration and
> discussion.
>
> - Perhaps the hard block size limit should be a function of the actual
> block sizes over some trailing sampling period. For example, take the
> median block size among the most recent 2016 blocks and multiply it by 1.5.
> This allows Bitcoin to scale up gradually and organically, rather than
> having human beings guessing at what is an appropriate limit.
>

A lot of people like this idea, or something like it. It is nice and
simple, which is really important for consensus-critical code.

With this rule in place, I believe there would be more "fee pressure"
(miners would be creating smaller blocks) today. I created a couple of
histograms of block sizes to infer what policy miners are ACTUALLY
following today with respect to block size:

Last 1,000 blocks:
  http://bitcoincore.org/~gavin/sizes_last1000.html

Notice a big spike at 750K -- the default size for Bitcoin Core.
This graph might be misleading, because transaction volume or fees might
not be high enough over the last few days to fill blocks to whatever limit
miners are willing to mine.

So I graphed a time when (according to statoshi.info) there WERE a lot of
transactions waiting to be confirmed:
   http://bitcoincore.org/~gavin/sizes_357511.html

That might also be misleading, because it is possible there were a lot of
transactions waiting to be confirmed because miners who choose to create
small blocks got lucky and found more blocks than normal.  In fact, it
looks like that is what happened: more smaller-than-normal blocks were
found, and the memory pool backed up.

So: what if we had a dynamic maximum size limit based on recent history?

The average block size is about 400K, so a 1.5x rule would make the max
block size 600K; miners would definitely be squeezing out transactions /
putting pressure to increase transaction fees. Even a 2x rule (implying
800K max blocks) would, today, be squeezing out transactions / putting
pressure to increase fees.

Using a median size instead of an average means the size can increase or
decrease more quickly. For example, imagine the rule is "median of last
2016 blocks" and 49% of miners are producing 0-size blocks and 51% are
producing max-size blocks. The median is max-size, so the 51% have total
control over making blocks bigger.  Swap the roles, and the median is
min-size.

Because of that, I think using an average is better-- it means the max size
will change (up or down) more slowly.

I also think 2016 blocks is too long, because transaction volumes change
quicker than that. An average over 144 blocks (last 24 hours) would be
better able to handle increased transaction volume around major holidays,
and would also be able to react more quickly if an economically irrational
attacker attempted to flood the network with fee-paying transactions.

So my straw-man proposal would be:  max size 2x average size over last 144
blocks, calculated at every block.

There are a couple of other changes I'd pair with that consensus change:

+ Make the default mining policy for Bitcoin Core neutral-- have its target
block size be the average size, so miners that don't care will "go along
with the people who do care."

+ Use something like Greg's formula for size instead of bytes-on-the-wire,
to discourage bloating the UTXO set.


---------

When I've proposed (privately, to the other core committers) some dynamic
algorithm the objection has been "but that gives miners complete control
over the max block size."

I think that worry is unjustified right now-- certainly, until we have
size-independent new block propagation there is an incentive for miners to
keep their blocks small, and we see miners creating small blocks even when
there are fee-paying transactions waiting to be confirmed.

I don't even think it will be a problem if/when we do have size-independent
new block propagation, because I think the combination of the random timing
of block-finding plus a dynamic limit as described above will create a
healthy system.

If I'm wrong, then it seems to me the miners will have a very strong
incentive to, collectively, impose whatever rules are necessary (maybe a
soft-fork to put a hard cap on block size) to make the system healthy again.


-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150528/5681756b/attachment.html>

From tier.nolan at gmail.com  Thu May 28 15:57:15 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Thu, 28 May 2015 16:57:15 +0100
Subject: [Bitcoin-development] Consensus-enforced transaction
 replacement via sequence numbers
In-Reply-To: <CAOG=w-vY7WHso90mtzhSRiuTLVfahMv1Xr6p_AZvyh4krxPLSg@mail.gmail.com>
References: <CAOG=w-sfiUQQGUh=RR55NU-TkAi1+2g3_Z+YP3dGDjp8zXYBGQ@mail.gmail.com>
	<CANEZrP0QMHp9PwBr=ekkujtA+=LXbgiL4xkXRSmcOGqaLJEp0g@mail.gmail.com>
	<CAOG=w-s7JkB6SyEE0=KwmrasyH22aB2Zf3jBdKcXvrGoNhN_Nw@mail.gmail.com>
	<CANEZrP0zKe7hK0KjiXN9M6CHnJxKZfW9myez3G+GWpr3fugBCg@mail.gmail.com>
	<CAOG=w-vusO30sBZfsuP94wbkUUfHupmhQtScGsJ2463sO=EpzA@mail.gmail.com>
	<CAE-z3OUG5p_hAOFvaE10kTT7sa=2GrzvZpis5FzATSEcNwZpyw@mail.gmail.com>
	<CAOG=w-tQyrc8ncAFauDObmBYn3uSwBcLoWVqruaV6PcTUFbTKg@mail.gmail.com>
	<CAE-z3OXO++0n+UVKe1KYyGv=GyHrZ-MsJtYELk+KC6cEV2UbHQ@mail.gmail.com>
	<CAOG=w-vY7WHso90mtzhSRiuTLVfahMv1Xr6p_AZvyh4krxPLSg@mail.gmail.com>
Message-ID: <CAE-z3OWrVP+jE9bL=9+eC+RE5L5kYQ_Y-JT4Go2r+o-M=eYssw@mail.gmail.com>

What are the use cases for relative lock time verify?  I have 1 and I think
that is the kind of thing it is useful for.

I think that most cases are just to guarantee that the other party has a
chance to react.  This means that 8191 blocks should be more than enough
(and most would set it lower).

For long term, the absolute version is just as good.  That depends on use
cases.  "You can't take step 4 until 3 months after step 3 has completed"
doesn't seem useful.

On Thu, May 28, 2015 at 4:38 PM, Mark Friedenbach <mark at friedenbach.org>
wrote:

> Oh ok you mean a semantic difference for the purpose of explaining. It
> doesn't actually change the code.
>
> Regarding saving more bits, there really isn't much room if you consider
> time-based relative locktimes and long-lived channels on the order of a
> year or more.
>
> On Thu, May 28, 2015 at 8:18 AM, Tier Nolan <tier.nolan at gmail.com> wrote:
>
>> On Thu, May 28, 2015 at 3:59 PM, Mark Friedenbach <mark at friedenbach.org>
>> wrote:
>>
>>> Why 3? Do we have a version 2?
>>>
>> I meant whatever the next version is, so you are right, it's version 2.
>>
>>> As for doing it in serialization, that would alter the txid making it a
>>> hard fork change.
>>>
>> The change is backwards compatible (since there is no restrictions on
>> sequence numbers).   This makes it a soft fork.
>>
>> That doesn't change the fact that you are changing what a field in the
>> transaction represents.
>>
>> You could say that the sequence number is no longer encoded in the
>> serialization, it is assumed to be 0xFFFFFFFF for all version 2+
>> transactions and the relative locktime is a whole new field that is the
>> same size (and position).
>>
>> I think keeping some of the bytes for other uses is a good idea.  The
>> entire top 2 bytes could be ignored when working out relative locktime
>> verify.  That leaves them fully free to be set to anything.
>>
>> It could be that if the MSB of the bottom 2 bytes is set, then that
>> activates the rule and the top 2 bytes are ignored.
>>
>> Are there any use-cases which need a RLTV of more than 8191 blocks delay
>> (that can't be covered by the absolute version)?
>>
>>
>> ------------------------------------------------------------------------------
>>
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150528/066bb1f3/attachment.html>

From s7r at sky-ip.org  Thu May 28 16:22:46 2015
From: s7r at sky-ip.org (s7r)
Date: Thu, 28 May 2015 19:22:46 +0300
Subject: [Bitcoin-development] Consensus-enforced transaction
 replacement via sequence numbers
In-Reply-To: <CAE-z3OX6pn8HpCXhsN1r_7rX9Wno_e-8dgnrzq0egQNk7N=r3w@mail.gmail.com>
References: <CAOG=w-sfiUQQGUh=RR55NU-TkAi1+2g3_Z+YP3dGDjp8zXYBGQ@mail.gmail.com>	<CANEZrP0QMHp9PwBr=ekkujtA+=LXbgiL4xkXRSmcOGqaLJEp0g@mail.gmail.com>	<CAOG=w-s7JkB6SyEE0=KwmrasyH22aB2Zf3jBdKcXvrGoNhN_Nw@mail.gmail.com>	<CANEZrP0zKe7hK0KjiXN9M6CHnJxKZfW9myez3G+GWpr3fugBCg@mail.gmail.com>	<CAOG=w-vusO30sBZfsuP94wbkUUfHupmhQtScGsJ2463sO=EpzA@mail.gmail.com>	<CAE-z3OUG5p_hAOFvaE10kTT7sa=2GrzvZpis5FzATSEcNwZpyw@mail.gmail.com>	<20150528120434.GA31349@savin.petertodd.org>
	<CAE-z3OX6pn8HpCXhsN1r_7rX9Wno_e-8dgnrzq0egQNk7N=r3w@mail.gmail.com>
Message-ID: <556740D6.5040004@sky-ip.org>



On 5/28/2015 4:35 PM, Tier Nolan wrote:
> On Thu, May 28, 2015 at 1:04 PM, Peter Todd <pete at petertodd.org
> <mailto:pete at petertodd.org>> wrote:
> 
>     For that matter, we probably don't want to treat this as a *version*
>     change, but rather a *feature* flag. 
> 
> 
> I think it is still a version change.  At the moment, the 4 bytes refer
> to the sequence number and afterwards they mean something else.
> 
> For relative locktime verify, I think most use cases could be block
> count based and don't need to be able to count very high. 
> 
> I think the main benefit is that protocols can have one party trigger a
> step while giving the other party guaranteed time to respond.
> 
> *Fast Channel Close
> *
> 
> This assumes that malleability is fixed.
> 

Indeed. This is very important for refunds.

> Alice creates
> 
> TXA:
> output (x) to [multisig A1 & B1]
> 
> Refund:
> input TXA (signed by Alice)
> Output [(A2 & relative_check_locktime(150)) OR (multisig A3 &  B2)]
> 
> Alice sends Refund to Bob
> 
> Bob signs it and sends it back to Alice
> 
> Alice verifies the signature, adds her own and sends it to Bob.
> 
> She broadcasts TXA (would wait until Bob confirms acceptance).
> 
> This means that both Alice and Bob have the refund transaction and can
> use it to close the channel (assuming TXA is not mutated).
> 

In this scenario, if channel is closed, Alice is the only one who can
take the coins back after a relative locktime of 150 blocks. Bob is not
able to do this.

> Alice can send money to Bob by creating a transaction which spends the
> output of the refund transaction (splitting the output x-b for Alice and
> b for Bob), signing it and sending it to Bob.
> 
> Alice can force Bob to close the channel by broadcasting the refund
> transaction.  150 blocks later, she gets the channel deposit if he
> doesn't act.
> 

How is Bob protected in this scenario? If Alice sings a transaction
which spends the output of the refund transaction and gives it to Bob,
Bob can just add its signature and claim his slice of the output,
without necessarily shipping the goods or delivering the services to Alice.

> If she had sent some money to Bob, he has 150 blocks to sign the
> transaction that pays him the most money and broadcast it.  Alice gets
> the remainder of the deposit.
> 
Can you be more explicit here? It doesn't make sense for me.

> Alice cannot broadcast earlier version, since Bob doesn't send her the
> signed versions.
> 
> This means that the channel doesn't need a defined end date.  Either
> party can close the channel whenever they want.
> 
With some risks.

> TXA could be protected against malleability by adding a locktime path. 
> This would only be for use if the transaction is mutated.
> 
How do you apply a locktime path to a tx in the current network consensus?

> 
> ------------------------------------------------------------------------------
> 
> 
> 
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> 



From steven.pine at gmail.com  Thu May 28 16:30:34 2015
From: steven.pine at gmail.com (Steven Pine)
Date: Thu, 28 May 2015 12:30:34 -0400
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CAAjy6kDdB8uODpPcmS8h4eap8fke7Y2y773NHJZja8tB5mPk4Q@mail.gmail.com>
References: <CAAjy6kDdB8uODpPcmS8h4eap8fke7Y2y773NHJZja8tB5mPk4Q@mail.gmail.com>
Message-ID: <CAAjy6kAsNJNJHHU7H91LsAOJZUjiuy3V3r1n-wqntUhCHdgYKw@mail.gmail.com>

I would support a dynamic block size increase as outlined. I have a few
questions though.

Is scaling by average block size the best and easiest method, why not scale
by transactions confirmed instead? Anyone can write and relay a
transaction, and those are what we want to scale for, why not measure it
directly?

I would prefer changes every 2016 blocks, it is a well known change and a
reasonable time period for planning on changes. Two weeks is plenty fast,
especially at a 50% rate increase, in a few months the block size could be
dramatically larger.

Daily change to size seems confusing especially considering that max block
size will be dipping up and down. Also if something breaks trying to fix it
in a day seems problematic. The hard fork database size difference error
comes to mind. Finally daily 50% increases could quickly crowd out smaller
nodes if changes happen too quickly to adapt for.





> Date: Thu, 28 May 2015 11:53:41 -0400
> From: Gavin Andresen <gavinandresen at gmail.com>
> Subject:
> To: Matt Whitlock <bip at mattwhitlock.name>
> Cc: Bitcoin Dev <bitcoin-development at lists.sourceforge.net>
> Message-ID:
>         <
CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> On Fri, May 8, 2015 at 3:20 AM, Matt Whitlock <bip at mattwhitlock.name>
wrote:
>
> > Between all the flames on this list, several ideas were raised that did
> > not get much attention. I hereby resubmit these ideas for consideration
and
> > discussion.
> >
> > - Perhaps the hard block size limit should be a function of the actual
> > block sizes over some trailing sampling period. For example, take the
> > median block size among the most recent 2016 blocks and multiply it by
1.5.
> > This allows Bitcoin to scale up gradually and organically, rather than
> > having human beings guessing at what is an appropriate limit.
> >
>
> A lot of people like this idea, or something like it. It is nice and
> simple, which is really important for consensus-critical code.
>
> With this rule in place, I believe there would be more "fee pressure"
> (miners would be creating smaller blocks) today. I created a couple of
> histograms of block sizes to infer what policy miners are ACTUALLY
> following today with respect to block size:
>
> Last 1,000 blocks:
>   http://bitcoincore.org/~gavin/sizes_last1000.html
>
> Notice a big spike at 750K -- the default size for Bitcoin Core.
> This graph might be misleading, because transaction volume or fees might
> not be high enough over the last few days to fill blocks to whatever limit
> miners are willing to mine.
>
> So I graphed a time when (according to statoshi.info) there WERE a lot of
> transactions waiting to be confirmed:
>    http://bitcoincore.org/~gavin/sizes_357511.html
>
> That might also be misleading, because it is possible there were a lot of
> transactions waiting to be confirmed because miners who choose to create
> small blocks got lucky and found more blocks than normal.  In fact, it
> looks like that is what happened: more smaller-than-normal blocks were
> found, and the memory pool backed up.
>
> So: what if we had a dynamic maximum size limit based on recent history?
>
> The average block size is about 400K, so a 1.5x rule would make the max
> block size 600K; miners would definitely be squeezing out transactions /
> putting pressure to increase transaction fees. Even a 2x rule (implying
> 800K max blocks) would, today, be squeezing out transactions / putting
> pressure to increase fees.
>
> Using a median size instead of an average means the size can increase or
> decrease more quickly. For example, imagine the rule is "median of last
> 2016 blocks" and 49% of miners are producing 0-size blocks and 51% are
> producing max-size blocks. The median is max-size, so the 51% have total
> control over making blocks bigger.  Swap the roles, and the median is
> min-size.
>
> Because of that, I think using an average is better-- it means the max
size
> will change (up or down) more slowly.
>
> I also think 2016 blocks is too long, because transaction volumes change
> quicker than that. An average over 144 blocks (last 24 hours) would be
> better able to handle increased transaction volume around major holidays,
> and would also be able to react more quickly if an economically irrational
> attacker attempted to flood the network with fee-paying transactions.
>
> So my straw-man proposal would be:  max size 2x average size over last 144
> blocks, calculated at every block.
>
> There are a couple of other changes I'd pair with that consensus change:
>
> + Make the default mining policy for Bitcoin Core neutral-- have its
target
> block size be the average size, so miners that don't care will "go along
> with the people who do care."
>
> + Use something like Greg's formula for size instead of bytes-on-the-wire,
> to discourage bloating the UTXO set.
>
>
> ---------
>
> When I've proposed (privately, to the other core committers) some dynamic
> algorithm the objection has been "but that gives miners complete control
> over the max block size."
>
> I think that worry is unjustified right now-- certainly, until we have
> size-independent new block propagation there is an incentive for miners to
> keep their blocks small, and we see miners creating small blocks even when
> there are fee-paying transactions waiting to be confirmed.
>
> I don't even think it will be a problem if/when we do have
size-independent
> new block propagation, because I think the combination of the random
timing
> of block-finding plus a dynamic limit as described above will create a
> healthy system.
>
> If I'm wrong, then it seems to me the miners will have a very strong
> incentive to, collectively, impose whatever rules are necessary (maybe a
> soft-fork to put a hard cap on block size) to make the system healthy
again.
>
>
> --
> --
> Gavin Andresen
> -------------- next part --------------
> An HTML attachment was scrubbed...
>
> ------------------------------
>
>
------------------------------------------------------------------------------
>
>
> ------------------------------
>
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
> End of Bitcoin-development Digest, Vol 48, Issue 122
> ****************************************************
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150528/9bc538ee/attachment.html>

From mike at plan99.net  Thu May 28 17:05:18 2015
From: mike at plan99.net (Mike Hearn)
Date: Thu, 28 May 2015 19:05:18 +0200
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>
Message-ID: <CANEZrP3VCaFsW4+gPm2kCJ9z7oVUZYVaeNf=_cJWEWwh4ZxiPQ@mail.gmail.com>

>
> Even a 2x rule (implying 800K max blocks) would, today, be squeezing out
> transactions / putting pressure to increase fees .....
>
> So my straw-man proposal would be:  max size 2x average size over last 144
> blocks, calculated at every block.
>

Isn't that a step backwards, then? I see no reason for fee pressure to
exist at the moment. All it's doing is turning away users for no purpose:
mining isn't supported by fees, and the tiny fees we use right now seem to
be good enough to stop penny flooding.

Why not set the max size to be 20x the average size? Why 2x, given you just
pointed out that'd result in blocks shrinking rather than growing.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150528/1e8e17c3/attachment.html>

From thomasv at electrum.org  Thu May 28 17:14:05 2015
From: thomasv at electrum.org (Thomas Voegtlin)
Date: Thu, 28 May 2015 19:14:05 +0200
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
 function
In-Reply-To: <CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>
Message-ID: <55674CDD.8080703@electrum.org>

Le 28/05/2015 17:53, Gavin Andresen a ?crit :
> 
> So my straw-man proposal would be:  max size 2x average size over last 144
> blocks, calculated at every block.
> 

I like that idea.

Average is a better choice than median. The median is not well defined
on discrete sets, as shown in your example, and there is no need to be
robust to outliers, thanks to the max size.




From gavinandresen at gmail.com  Thu May 28 17:19:44 2015
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Thu, 28 May 2015 13:19:44 -0400
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CANEZrP3VCaFsW4+gPm2kCJ9z7oVUZYVaeNf=_cJWEWwh4ZxiPQ@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>
	<CANEZrP3VCaFsW4+gPm2kCJ9z7oVUZYVaeNf=_cJWEWwh4ZxiPQ@mail.gmail.com>
Message-ID: <CABsx9T21zjHyO-nh1aSBM3z4Bg015O0rOfYq7=Sy4mf=QxUVQA@mail.gmail.com>

On Thu, May 28, 2015 at 1:05 PM, Mike Hearn <mike at plan99.net> wrote:

> Isn't that a step backwards, then? I see no reason for fee pressure to
>> exist at the moment. All it's doing is turning away users for no purpose:
>> mining isn't supported by fees, and the tiny fees we use right now seem to
>> be good enough to stop penny flooding.
>>
>
> Why not set the max size to be 20x the average size? Why 2x, given you
> just pointed out that'd result in blocks shrinking rather than growing.
>

Twenty is scary.

And two is a very neutral number: if 50% of hashpower want the max size to
grow as fast as possible and 50% are dead-set opposed to any increase in
max size, then half produce blocks 2 times as big, half produce empty
blocks, and the max size doesn't change. If it was 20, then a small
minority of miners could force a max size increase.  (if it is less than 2,
then a minority of minors can force the block size down)


As for whether there "should" be fee pressure now or not: I have no
opinion, besides "we should make block propagation faster so there is no
technical reason for miners to produce tiny blocks." I don't think us
developers should be deciding things like whether or not fees are too high,
too low, .....

-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150528/ef414a76/attachment.html>

From tier.nolan at gmail.com  Thu May 28 17:21:34 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Thu, 28 May 2015 18:21:34 +0100
Subject: [Bitcoin-development] Consensus-enforced transaction
 replacement via sequence numbers
In-Reply-To: <556740D6.5040004@sky-ip.org>
References: <CAOG=w-sfiUQQGUh=RR55NU-TkAi1+2g3_Z+YP3dGDjp8zXYBGQ@mail.gmail.com>
	<CANEZrP0QMHp9PwBr=ekkujtA+=LXbgiL4xkXRSmcOGqaLJEp0g@mail.gmail.com>
	<CAOG=w-s7JkB6SyEE0=KwmrasyH22aB2Zf3jBdKcXvrGoNhN_Nw@mail.gmail.com>
	<CANEZrP0zKe7hK0KjiXN9M6CHnJxKZfW9myez3G+GWpr3fugBCg@mail.gmail.com>
	<CAOG=w-vusO30sBZfsuP94wbkUUfHupmhQtScGsJ2463sO=EpzA@mail.gmail.com>
	<CAE-z3OUG5p_hAOFvaE10kTT7sa=2GrzvZpis5FzATSEcNwZpyw@mail.gmail.com>
	<20150528120434.GA31349@savin.petertodd.org>
	<CAE-z3OX6pn8HpCXhsN1r_7rX9Wno_e-8dgnrzq0egQNk7N=r3w@mail.gmail.com>
	<556740D6.5040004@sky-ip.org>
Message-ID: <CAE-z3OX+eNfjyXw3MKOktLz4vDdep7qCG8dkJEUDRp5RyGq9MQ@mail.gmail.com>

On Thu, May 28, 2015 at 5:22 PM, s7r <s7r at sky-ip.org> wrote:

> In this scenario, if channel is closed, Alice is the only one who can
> take the coins back after a relative locktime of 150 blocks. Bob is not
> able to do this.
>

Yes, Alice is assumed to be the one who funded the channel.  It is a single
direction channel (Alice to Bob).


> How is Bob protected in this scenario?


Assuming the deposit is 1 BTC.

When the channel is created, Alice can broadcast the refund transaction
immediately and the get her money back 150 blocks later.

The full scriptPubKey for the refund transaction would be

OP_IF
    <150> OP_RELATIVE_CHECKLOCKTIME_VERIFY OP_DROP <Alice's public key 2>
OP_CHECKSIGVERIFY
OP_ELSE
    OP_2 <Alice's public key 3> <Bob's public key 2> OP_2
OP_CHECKMULTISIGVERIFY
OP_ENDIF

This means that Alice can spend the output after 150 blocks but with both
signatures Bob and Alice can spend the output without the delay.

She can send money to Bob by spending the non-locked output of the refund
transaction (0.01BTC for Bob and 0.99BTC for Alice).

Bob has a transaction that pays him 0.01BTC and pays Alice 0.99BTC from the
refund transaction and is signed by Alice, but still requires his
signature.  Only Bob can make the transaction valid.

It can be spent as soon as the refund transaction is broadcast.

He has the refund transaction, so he can start the process whenever he
wishes.

Assume the channel runs for a while, and Alice sends 0.3BTC total.

Bob has a transaction which pays him 0.3BTC and Alice 0.7BTC.  He also has
some that pay him less than 0.3, but there is no point in him using those
ones.

Alice decides she wants to close the channel, so asks bob to sign his final
transaction and broadcast it and the refund transaction.

If Bob refuses to do that, then Alice can just broadcast the refund
transaction.

If Bob still refuses to broadcast his final transaction, then Alice gets
1BTC and he gets nothing, after 150 blocks.

This means he will send his final transaction before the 150 blocks have
passed.  This gets him 0.3 and Alice 0.7.

Bob can close the channel immediately and Alice can force it to be closed
within 150 blocks (~1 day).


> If Alice sings a transaction
> which spends the output of the refund transaction and gives it to Bob,
> Bob can just add its signature and claim his slice of the output,
> without necessarily shipping the goods or delivering the services to Alice.
>

Protection against that type of fraud isn't covered by channels.  They are
just to make sure money is handed over.


>  Can you be more explicit here? It doesn't make sense for me.
>

Does the explanation above help?

With some risks.
>

As long as Bob is online and sees the refund transaction being broadcast by
Alice, then there is no risk to him.

Alice can close the transaction whenever she wants, so there is no holdup
risk for her.


> How do you apply a locktime path to a tx in the current network consensus?
>

I mean with OP_CHECKLOCKTIMEVERIFY.

She could say that TXA pays to her in 6 months.

If TXA ends up mutated after being broadcast, then she would have to wait
the 6 months.  It's better than nothing and maybe Bob would sign the
mutated transaction.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150528/00a2a35f/attachment.html>

From pieter.wuille at gmail.com  Thu May 28 17:34:32 2015
From: pieter.wuille at gmail.com (Pieter Wuille)
Date: Thu, 28 May 2015 10:34:32 -0700
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>
Message-ID: <CAPg+sBgf84O9QpppSn=tNqR9jofbfRr02X8xweVgGyFbHQznXA@mail.gmail.com>

> until we have size-independent new block propagation

I don't really believe that is possible. I'll argue why below. To be clear,
this is not an argument against increasing the block size, only against
using the assumption of size-independent propagation.

There are several significant improvements likely possible to various
aspects of block propagation, but I don't believe you can make any part
completely size-independent. Perhaps the remaining aspects result in terms
in the total time that vanish compared to the link latencies for 1 MB
blocks, but there will be some block sizes for which this is no longer the
case, and we need to know where that is the case.

* You can't assume that every transaction is pre-relayed and pre-validated.
This can happen due to non-uniform relay policies (different codebases, and
future things like size-limited mempools), double spend attempts, and
transactions generated before a block had time to propagate. You've
previously argued for a policy of not including too recent transactions,
but that requires a bound on network diameter, and if these late
transactions are profitable, it has exactly the same problem as making
larger blocks non-proportionally more economic for larger pools groups if
propagation time is size dependent).
  * This results in extra bandwidth usage for efficient relay protocols,
and if discrepancy estimation mispredicts the size of IBLT or error
correction data needed, extra roundtrips.
  * Signature validation for unrelayed transactions will be needed at block
relay time.
  * Database lookups for the inputs of unrelayed transactions cannot be
cached in advance.

* Block validation with 100% known and pre-validated transactions is not
constant time, due to updates that need to be made to the UTXO set (and
future ideas like UTXO commitments would make this effect an order of
magnitude worse).

* More efficient relay protocols also have higher CPU cost for
encoding/decoding.

Again, none of this is a reason why the block size can't increase. If
availability of hardware with higher bandwidth, faster disk/ram access
times, and faster CPUs increases, we should be able to have larger blocks
with the same propagation profile as smaller blocks with earlier technology.

But we should know how technology scales with larger blocks, and I don't
believe we do, apart from microbenchmarks in laboratory conditions.

-- 
Pieter
 On Fri, May 8, 2015 at 3:20 AM, Matt Whitlock <bip at mattwhitlock.name>
wrote:

> Between all the flames on this list, several ideas were raised that did
> not get much attention. I hereby resubmit these ideas for consideration and
> discussion.
>
> - Perhaps the hard block size limit should be a function of the actual
> block sizes over some trailing sampling period. For example, take the
> median block size among the most recent 2016 blocks and multiply it by 1.5.
> This allows Bitcoin to scale up gradually and organically, rather than
> having human beings guessing at what is an appropriate limit.
>

A lot of people like this idea, or something like it. It is nice and
simple, which is really important for consensus-critical code.

With this rule in place, I believe there would be more "fee pressure"
(miners would be creating smaller blocks) today. I created a couple of
histograms of block sizes to infer what policy miners are ACTUALLY
following today with respect to block size:

Last 1,000 blocks:
  http://bitcoincore.org/~gavin/sizes_last1000.html

Notice a big spike at 750K -- the default size for Bitcoin Core.
This graph might be misleading, because transaction volume or fees might
not be high enough over the last few days to fill blocks to whatever limit
miners are willing to mine.

So I graphed a time when (according to statoshi.info) there WERE a lot of
transactions waiting to be confirmed:
   http://bitcoincore.org/~gavin/sizes_357511.html

That might also be misleading, because it is possible there were a lot of
transactions waiting to be confirmed because miners who choose to create
small blocks got lucky and found more blocks than normal.  In fact, it
looks like that is what happened: more smaller-than-normal blocks were
found, and the memory pool backed up.

So: what if we had a dynamic maximum size limit based on recent history?

The average block size is about 400K, so a 1.5x rule would make the max
block size 600K; miners would definitely be squeezing out transactions /
putting pressure to increase transaction fees. Even a 2x rule (implying
800K max blocks) would, today, be squeezing out transactions / putting
pressure to increase fees.

Using a median size instead of an average means the size can increase or
decrease more quickly. For example, imagine the rule is "median of last
2016 blocks" and 49% of miners are producing 0-size blocks and 51% are
producing max-size blocks. The median is max-size, so the 51% have total
control over making blocks bigger.  Swap the roles, and the median is
min-size.

Because of that, I think using an average is better-- it means the max size
will change (up or down) more slowly.

I also think 2016 blocks is too long, because transaction volumes change
quicker than that. An average over 144 blocks (last 24 hours) would be
better able to handle increased transaction volume around major holidays,
and would also be able to react more quickly if an economically irrational
attacker attempted to flood the network with fee-paying transactions.

So my straw-man proposal would be:  max size 2x average size over last 144
blocks, calculated at every block.

There are a couple of other changes I'd pair with that consensus change:

+ Make the default mining policy for Bitcoin Core neutral-- have its target
block size be the average size, so miners that don't care will "go along
with the people who do care."

+ Use something like Greg's formula for size instead of bytes-on-the-wire,
to discourage bloating the UTXO set.


---------

When I've proposed (privately, to the other core committers) some dynamic
algorithm the objection has been "but that gives miners complete control
over the max block size."

I think that worry is unjustified right now-- certainly, until we have
size-independent new block propagation there is an incentive for miners to
keep their blocks small, and we see miners creating small blocks even when
there are fee-paying transactions waiting to be confirmed.

I don't even think it will be a problem if/when we do have size-independent
new block propagation, because I think the combination of the random timing
of block-finding plus a dynamic limit as described above will create a
healthy system.

If I'm wrong, then it seems to me the miners will have a very strong
incentive to, collectively, impose whatever rules are necessary (maybe a
soft-fork to put a hard cap on block size) to make the system healthy again.


-- 
--
Gavin Andresen


------------------------------------------------------------------------------

_______________________________________________
Bitcoin-development mailing list
Bitcoin-development at lists.sourceforge.net
https://lists.sourceforge.net/lists/listinfo/bitcoin-development
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150528/5c893428/attachment.html>

From mike at plan99.net  Thu May 28 17:34:42 2015
From: mike at plan99.net (Mike Hearn)
Date: Thu, 28 May 2015 19:34:42 +0200
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CABsx9T21zjHyO-nh1aSBM3z4Bg015O0rOfYq7=Sy4mf=QxUVQA@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>
	<CANEZrP3VCaFsW4+gPm2kCJ9z7oVUZYVaeNf=_cJWEWwh4ZxiPQ@mail.gmail.com>
	<CABsx9T21zjHyO-nh1aSBM3z4Bg015O0rOfYq7=Sy4mf=QxUVQA@mail.gmail.com>
Message-ID: <CANEZrP2BaKwhpPgcUHWAHswOmUeFLgEk4ysrn4+73qNzWDJ=yQ@mail.gmail.com>

>
> Twenty is scary.
>

To whom? The only justification for the max size is DoS attacks, right?
Back when Bitcoin had an average block size of 10kb, the max block size was
100x the average. Things worked fine, nobody was scared.

The max block size is really a limit set by hardware capability, which is
something that's difficult to measure in software. I think I preferred your
original formula that guesstimated based on previous trends to one that
just tries to follow some average.

As noted, many miners just accept the defaults. With your proposed change
their target would effectively *drop* from 1mb to 800kb today, which seems
crazy. That's the exact opposite of what is needed right now.

I am very skeptical about this idea.


> I don't think us developers should be deciding things like whether or not
> fees are too high, too low,
>

Miners can already attempt to apply fee pressure by just not mining
transactions that they feel don't pay enough. Some sort of auto-cartel that
attempts to restrict supply based on everyone looking at everyone else
feels overly complex and prone to strange situations: it looks a lot like
some kind of Mexican standoff to me.

Additionally, the justification for the block size limit was DoS by someone
mining "troll blocks". It was never meant to be about fee pressure.
Resource management inside Bitcoin Core is certainly something to be
handled by developers.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150528/3359ad4a/attachment.html>

From raystonn at hotmail.com  Thu May 28 17:39:29 2015
From: raystonn at hotmail.com (Raystonn .)
Date: Thu, 28 May 2015 10:39:29 -0700
Subject: [Bitcoin-development] Proposed alternatives to the 20MB
	stepfunction
In-Reply-To: <CABsx9T21zjHyO-nh1aSBM3z4Bg015O0rOfYq7=Sy4mf=QxUVQA@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator><CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com><CANEZrP3VCaFsW4+gPm2kCJ9z7oVUZYVaeNf=_cJWEWwh4ZxiPQ@mail.gmail.com>
	<CABsx9T21zjHyO-nh1aSBM3z4Bg015O0rOfYq7=Sy4mf=QxUVQA@mail.gmail.com>
Message-ID: <COL131-DS24FC87C7C6622E23F5EF58CDCA0@phx.gbl>

I agree that developers should avoid imposing economic policy.  It is dangerous for Bitcoin and the core developers themselves to become such a central point of attack for those wishing to disrupt Bitcoin.  My opinion is these things are better left to a decentralized free market anyhow.


From: Gavin Andresen 
Sent: Thursday, May 28, 2015 10:19 AM
To: Mike Hearn 
Cc: Bitcoin Dev 
Subject: Re: [Bitcoin-development] Proposed alternatives to the 20MB stepfunction

On Thu, May 28, 2015 at 1:05 PM, Mike Hearn <mike at plan99.net> wrote:

    Isn't that a step backwards, then? I see no reason for fee pressure to exist at the moment. All it's doing is turning away users for no purpose: mining isn't supported by fees, and the tiny fees we use right now seem to be good enough to stop penny flooding.


  Why not set the max size to be 20x the average size? Why 2x, given you just pointed out that'd result in blocks shrinking rather than growing.

Twenty is scary.

And two is a very neutral number: if 50% of hashpower want the max size to grow as fast as possible and 50% are dead-set opposed to any increase in max size, then half produce blocks 2 times as big, half produce empty blocks, and the max size doesn't change. If it was 20, then a small minority of miners could force a max size increase.  (if it is less than 2, then a minority of minors can force the block size down)


As for whether there "should" be fee pressure now or not: I have no opinion, besides "we should make block propagation faster so there is no technical reason for miners to produce tiny blocks." I don't think us developers should be deciding things like whether or not fees are too high, too low, .....

-- 

--
Gavin Andresen



--------------------------------------------------------------------------------
------------------------------------------------------------------------------



--------------------------------------------------------------------------------
_______________________________________________
Bitcoin-development mailing list
Bitcoin-development at lists.sourceforge.net
https://lists.sourceforge.net/lists/listinfo/bitcoin-development
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150528/21f0f238/attachment.html>

From pete at petertodd.org  Thu May 28 17:50:00 2015
From: pete at petertodd.org (Peter Todd)
Date: Thu, 28 May 2015 13:50:00 -0400
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
 function
In-Reply-To: <CABsx9T21zjHyO-nh1aSBM3z4Bg015O0rOfYq7=Sy4mf=QxUVQA@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>
	<CANEZrP3VCaFsW4+gPm2kCJ9z7oVUZYVaeNf=_cJWEWwh4ZxiPQ@mail.gmail.com>
	<CABsx9T21zjHyO-nh1aSBM3z4Bg015O0rOfYq7=Sy4mf=QxUVQA@mail.gmail.com>
Message-ID: <20150528175000.GA11913@muck>

On Thu, May 28, 2015 at 01:19:44PM -0400, Gavin Andresen wrote:
> As for whether there "should" be fee pressure now or not: I have no
> opinion, besides "we should make block propagation faster so there is no
> technical reason for miners to produce tiny blocks." I don't think us
> developers should be deciding things like whether or not fees are too high,
> too low, .....

Note that the majority of hashing power is using Matt Corallo's block
relay network, something I confirmed the other day through my mining
contacts. Interestingly, the miners that aren't using it include some of
the largest pools; I haven't yet gotten an answer as to what their
rational for not using it was exactly.

Importantly, this does mean that block propagation is probably fairly
close to optimal already, modulo major changes to the consensus
protocol; IBLT won't improve the situation much, if any.

It's also notable that we're already having issues with miners turning
validation off as a way to lower their latency; I've been asked myself
about the possibility of creating an "SPV miner" that skips validation
while new blocks are propagating to shave off time and builds directly
off of block headers corresponding to blocks with unknown contents.

-- 
'peter'[:-1]@petertodd.org
00000000000000000327487b689490b73f9d336b3008f82114fd3ada336bcac0
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150528/7268e906/attachment.sig>

From pieter.wuille at gmail.com  Thu May 28 17:59:11 2015
From: pieter.wuille at gmail.com (Pieter Wuille)
Date: Thu, 28 May 2015 10:59:11 -0700
Subject: [Bitcoin-development] Proposed alternatives to the 20MB
	stepfunction
In-Reply-To: <COL131-DS24FC87C7C6622E23F5EF58CDCA0@phx.gbl>
References: <16096345.A1MpJQQkRW@crushinator>
	<CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>
	<CANEZrP3VCaFsW4+gPm2kCJ9z7oVUZYVaeNf=_cJWEWwh4ZxiPQ@mail.gmail.com>
	<CABsx9T21zjHyO-nh1aSBM3z4Bg015O0rOfYq7=Sy4mf=QxUVQA@mail.gmail.com>
	<COL131-DS24FC87C7C6622E23F5EF58CDCA0@phx.gbl>
Message-ID: <CAPg+sBhuHrMHZym8xQ2-dMknR4zdM=ZULcnZ-fcGnKLserDd-A@mail.gmail.com>

On May 28, 2015 10:42 AM, "Raystonn ." <raystonn at hotmail.com> wrote:
>
> I agree that developers should avoid imposing economic policy.  It is
dangerous for Bitcoin and the core developers themselves to become such a
central point of attack for those wishing to disrupt Bitcoin.

I could not agree more that developers should not be in charge of the
network rules.

Which is why - in my opinion - hard forks cannot be controversial things. A
controversial change to the software, forced to be adopted by the public
because the only alternative is a permanent chain fork, is a use of power
that developers (or anyone) should not have, and an incredibly dangerous
precedent for other changes that only a subset of participants would want.

The block size is also not just an economic policy. It is the compromise
the _network_ chooses to make between utility and various forms of
centralization pressure, and we should treat it as a compromise, and not as
some limit that is inferior to scaling demands.

I personally think the block size should increase, by the way, but only if
we can do it under a policy of doing it after technological growth has been
shown to be sufficient to support it without increased risk.

-- 
Pieter
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150528/e5331642/attachment.html>

From gavinandresen at gmail.com  Thu May 28 18:21:48 2015
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Thu, 28 May 2015 14:21:48 -0400
Subject: [Bitcoin-development] Proposed alternatives to the 20MB
	stepfunction
In-Reply-To: <CAPg+sBhuHrMHZym8xQ2-dMknR4zdM=ZULcnZ-fcGnKLserDd-A@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>
	<CANEZrP3VCaFsW4+gPm2kCJ9z7oVUZYVaeNf=_cJWEWwh4ZxiPQ@mail.gmail.com>
	<CABsx9T21zjHyO-nh1aSBM3z4Bg015O0rOfYq7=Sy4mf=QxUVQA@mail.gmail.com>
	<COL131-DS24FC87C7C6622E23F5EF58CDCA0@phx.gbl>
	<CAPg+sBhuHrMHZym8xQ2-dMknR4zdM=ZULcnZ-fcGnKLserDd-A@mail.gmail.com>
Message-ID: <CABsx9T06sk8srz016tfgxcYrn9Ebc33Oj95tK7i4D1i0=+p9rA@mail.gmail.com>

On Thu, May 28, 2015 at 1:59 PM, Pieter Wuille <pieter.wuille at gmail.com>
wrote:

> I personally think the block size should increase, by the way, but only if
> we can do it under a policy of doing it after technological growth has been
> shown to be sufficient to support it without increased risk.
>
> Can you be more specific about this? What risks are you worried about?

I've tried to cover all that I've heard about in my blog posts about why I
think the risks of 20MB blocks are outweighed by the benefits, am I missing
something?
  (blog posts are linked from
http://gavinandresen.ninja/time-to-roll-out-bigger-blocks )

There is the "a sudden jump to a 20MB max might have unforseen
consequences" risk that I don't address, but a dynamic increase would fix
that.

-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150528/11fdd5fc/attachment.html>

From gavinandresen at gmail.com  Thu May 28 18:23:59 2015
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Thu, 28 May 2015 14:23:59 -0400
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CANEZrP2BaKwhpPgcUHWAHswOmUeFLgEk4ysrn4+73qNzWDJ=yQ@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>
	<CANEZrP3VCaFsW4+gPm2kCJ9z7oVUZYVaeNf=_cJWEWwh4ZxiPQ@mail.gmail.com>
	<CABsx9T21zjHyO-nh1aSBM3z4Bg015O0rOfYq7=Sy4mf=QxUVQA@mail.gmail.com>
	<CANEZrP2BaKwhpPgcUHWAHswOmUeFLgEk4ysrn4+73qNzWDJ=yQ@mail.gmail.com>
Message-ID: <CABsx9T3nCJ-w_v-yEbEE2Ytb+xC65mhYqhoAhoOHw9tkPpG0TA@mail.gmail.com>

On Thu, May 28, 2015 at 1:34 PM, Mike Hearn <mike at plan99.net> wrote:

> As noted, many miners just accept the defaults. With your proposed change
>> their target would effectively *drop* from 1mb to 800kb today, which
>> seems crazy. That's the exact opposite of what is needed right now.
>>
>
> I am very skeptical about this idea.
>

By the time a hard fork can happen, I expect average block size will be
above 500K.

Would you support a rule that was "larger of 1MB or 2x average size" ? That
is strictly better than the situation we're in today.

-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150528/fada3906/attachment.html>

From steven.pine at gmail.com  Thu May 28 18:25:17 2015
From: steven.pine at gmail.com (Steven Pine)
Date: Thu, 28 May 2015 14:25:17 -0400
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CABsx9T03aNRC5DRbR06nNtsiBdJAcQsGAHvbCOe3pnuRpdvq5w@mail.gmail.com>
References: <CAAjy6kDdB8uODpPcmS8h4eap8fke7Y2y773NHJZja8tB5mPk4Q@mail.gmail.com>
	<CAAjy6kAsNJNJHHU7H91LsAOJZUjiuy3V3r1n-wqntUhCHdgYKw@mail.gmail.com>
	<CABsx9T03aNRC5DRbR06nNtsiBdJAcQsGAHvbCOe3pnuRpdvq5w@mail.gmail.com>
Message-ID: <CAAjy6kBRJ6n_hE1EsDaGFDopw=TgTYsBqRK1jiaWaoBfvzk6YQ@mail.gmail.com>

My understanding, which is very likely wrong in one way or another, is
transaction size and block size are two slightly different things but
perhaps it's so negligible that block size is a fine stand-in for total
transaction throughput.

Potentially Doubling the block size everyday is frankly imprudent. The
logarithmic increases in difficulty, which were often closer to 10% or 20%
every 2016 blocks was and is plenty fast, potentially changing blocksize by
twice daily is the mentality I would expect from a startup with the move
fast break things motto.

Infrastructure takes time, not everyone wants to run a node on a virtual
amazon instance, provisioning additional hard drive and bandwidth can't
happen overnight and trying to plan when block size from one week to the
next is a total mystery would be extremely difficult.

Anyone who has spent time examining the mining difficulty increases and
trajectory knows future planning is very very hard, allowing block size to
double daily would make it impossible.

Perhaps a middle way would be 300%  increase every 2016 blocks, that will
scale to 20mbs within a  month or two

The problem is logarithmic increases seem slow until they seem fast. If the
network begins to grow and block size hits 20, then the next day 40, 80...
Small nodes could get swamped within a week or less.

As for your point about Christmas, Bitcoin is a global network, Christmas,
while widely celebrated, isn't the only holiday, and planning around
American buying habits seems short sighted and no different from developers
trying to choose what the right fee pressure is.

On May 28, 2015 1:22 PM, "Gavin Andresen" <gavinandresen at gmail.com> wrote:
>
> On Thu, May 28, 2015 at 12:30 PM, Steven Pine <steven.pine at gmail.com>
wrote:
>>
>> I would support a dynamic block size increase as outlined. I have a few
questions though.
>>
>> Is scaling by average block size the best and easiest method, why not
scale by transactions confirmed instead? Anyone can write and relay a
transaction, and those are what we want to scale for, why not measure it
directly?
>
>
> What do you mean? Transactions aren't confirmed until they're in a
block...
>
>>
>> I would prefer changes every 2016 blocks, it is a well known change and
a reasonable time period for planning on changes. Two weeks is plenty fast,
especially at a 50% rate increase, in a few months the block size could be
dramatically larger.
>
>
> What type of planning do you imagine is necessary?
>
> And have you looked at transaction volumes for credit-card payment
networks around Christmas?
>
>>
>> Daily change to size seems confusing especially considering that max
block size will be dipping up and down. Also if something breaks trying to
fix it in a day seems problematic. The hard fork database size difference
error comes to mind. Finally daily 50% increases could quickly crowd out
smaller nodes if changes happen too quickly to adapt for.
>
> The bottleneck is transaction volume; blocks won't get bigger unless
there are fee-paying transactions around to pay them. What scenario are you
imagining where transaction volume increases by 50% a day for a sustained
period of time?
>
> --
> --
> Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150528/6daaf026/attachment.html>

From gavinandresen at gmail.com  Thu May 28 18:31:43 2015
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Thu, 28 May 2015 14:31:43 -0400
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CAAjy6kBRJ6n_hE1EsDaGFDopw=TgTYsBqRK1jiaWaoBfvzk6YQ@mail.gmail.com>
References: <CAAjy6kDdB8uODpPcmS8h4eap8fke7Y2y773NHJZja8tB5mPk4Q@mail.gmail.com>
	<CAAjy6kAsNJNJHHU7H91LsAOJZUjiuy3V3r1n-wqntUhCHdgYKw@mail.gmail.com>
	<CABsx9T03aNRC5DRbR06nNtsiBdJAcQsGAHvbCOe3pnuRpdvq5w@mail.gmail.com>
	<CAAjy6kBRJ6n_hE1EsDaGFDopw=TgTYsBqRK1jiaWaoBfvzk6YQ@mail.gmail.com>
Message-ID: <CABsx9T3_bGMmRKNEmMczcLG9yLywW1LXBy7=3F30LdAOeM9VuA@mail.gmail.com>

Can we hold off on bike-shedding the particular choice of parameters until
people have a chance to weigh in on whether or not there is SOME set of
dynamic parameters they would support right now?


-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150528/af73282f/attachment.html>

From mike at plan99.net  Fri May 29 11:26:40 2015
From: mike at plan99.net (Mike Hearn)
Date: Fri, 29 May 2015 13:26:40 +0200
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CABsx9T3nCJ-w_v-yEbEE2Ytb+xC65mhYqhoAhoOHw9tkPpG0TA@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>
	<CANEZrP3VCaFsW4+gPm2kCJ9z7oVUZYVaeNf=_cJWEWwh4ZxiPQ@mail.gmail.com>
	<CABsx9T21zjHyO-nh1aSBM3z4Bg015O0rOfYq7=Sy4mf=QxUVQA@mail.gmail.com>
	<CANEZrP2BaKwhpPgcUHWAHswOmUeFLgEk4ysrn4+73qNzWDJ=yQ@mail.gmail.com>
	<CABsx9T3nCJ-w_v-yEbEE2Ytb+xC65mhYqhoAhoOHw9tkPpG0TA@mail.gmail.com>
Message-ID: <CANEZrP1qH+zucYsGrMgnfi99e61Edxaj+xm=u_xYXga1g0WzJQ@mail.gmail.com>

>
> By the time a hard fork can happen, I expect average block size will be
> above 500K.
>

Yes, possibly.


> Would you support a rule that was "larger of 1MB or 2x average size" ?
> That is strictly better than the situation we're in today.
>

It is, but only by a trivial amount - hitting the limit is still very
likely. I don't want to see this issue come up over and over again. Ideally
never. We shouldn't be artificially throttling organic growth of the
network, especially not by accident.

IMO it's not even clear there needs to be a size limit at all. Currently
the 32mb message cap imposes one anyway, but if miners can always just
discourage blocks over some particular size if they want to.

But I can get behind a 20mb limit (or 20mb+N) as it represents a reasonable
compromise: the limit still exists, it's far below VISA capacity etc, but
it should also free up enough space that everyone can get back to what we
*should* be focusing on, which is user growth!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150529/9ca670f1/attachment.html>

From tier.nolan at gmail.com  Fri May 29 11:42:09 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Fri, 29 May 2015 12:42:09 +0100
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CANEZrP1qH+zucYsGrMgnfi99e61Edxaj+xm=u_xYXga1g0WzJQ@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>
	<CANEZrP3VCaFsW4+gPm2kCJ9z7oVUZYVaeNf=_cJWEWwh4ZxiPQ@mail.gmail.com>
	<CABsx9T21zjHyO-nh1aSBM3z4Bg015O0rOfYq7=Sy4mf=QxUVQA@mail.gmail.com>
	<CANEZrP2BaKwhpPgcUHWAHswOmUeFLgEk4ysrn4+73qNzWDJ=yQ@mail.gmail.com>
	<CABsx9T3nCJ-w_v-yEbEE2Ytb+xC65mhYqhoAhoOHw9tkPpG0TA@mail.gmail.com>
	<CANEZrP1qH+zucYsGrMgnfi99e61Edxaj+xm=u_xYXga1g0WzJQ@mail.gmail.com>
Message-ID: <CAE-z3OVmw+0doCe0hmYE6A1D61h0AUh4Mtnf5Fg1e4zQBkpraQ@mail.gmail.com>

On Fri, May 29, 2015 at 12:26 PM, Mike Hearn <mike at plan99.net> wrote:

> IMO it's not even clear there needs to be a size limit at all. Currently
> the 32mb message cap imposes one anyway
>

If the plan is a fix once and for all, then that should be changed too.  It
could be set so that it is at least some multiple of the max block size
allowed.

Alternatively, the merkle block message already incorporates the required
functionality.

Send
- headers message (with 1 header)
- merkleblock messages (max 1MB per message)

The transactions for each merkleblock could be sent directly before each
merkleblock, as is currently the case.

That system can send a block of any size.  It would require a change to the
processing of any merkleblocks received.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150529/21895008/attachment.html>

From mike at plan99.net  Fri May 29 11:57:42 2015
From: mike at plan99.net (Mike Hearn)
Date: Fri, 29 May 2015 13:57:42 +0200
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CAE-z3OVmw+0doCe0hmYE6A1D61h0AUh4Mtnf5Fg1e4zQBkpraQ@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>
	<CANEZrP3VCaFsW4+gPm2kCJ9z7oVUZYVaeNf=_cJWEWwh4ZxiPQ@mail.gmail.com>
	<CABsx9T21zjHyO-nh1aSBM3z4Bg015O0rOfYq7=Sy4mf=QxUVQA@mail.gmail.com>
	<CANEZrP2BaKwhpPgcUHWAHswOmUeFLgEk4ysrn4+73qNzWDJ=yQ@mail.gmail.com>
	<CABsx9T3nCJ-w_v-yEbEE2Ytb+xC65mhYqhoAhoOHw9tkPpG0TA@mail.gmail.com>
	<CANEZrP1qH+zucYsGrMgnfi99e61Edxaj+xm=u_xYXga1g0WzJQ@mail.gmail.com>
	<CAE-z3OVmw+0doCe0hmYE6A1D61h0AUh4Mtnf5Fg1e4zQBkpraQ@mail.gmail.com>
Message-ID: <CANEZrP0psA7hcJdKdA-r01UEt7ig3O-9vjwBMqKSEq-csu0hPQ@mail.gmail.com>

>
> If the plan is a fix once and for all, then that should be changed too.
> It could be set so that it is at least some multiple of the max block size
> allowed.
>

Well, but RAM is not infinite :-) Effectively what these caps are doing is
setting the minimum hardware requirements for running a Bitcoin node.

That's OK by me - I don't think we are actually going to exhaust the
hardware abilities of any reasonable computer any time soon, but still,
having the software recognise the finite nature of a computing machine
doesn't seem unwise.


> That system can send a block of any size.  It would require a change to
> the processing of any merkleblocks received.
>

Not "any" size because, again, the remote node must buffer things up and
have the transaction data actually in memory in order to digest it. But a
much larger size, yes.

However, that's a bigger change.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150529/6aebe66a/attachment.html>

From gavinandresen at gmail.com  Fri May 29 12:39:30 2015
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Fri, 29 May 2015 08:39:30 -0400
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CANEZrP0psA7hcJdKdA-r01UEt7ig3O-9vjwBMqKSEq-csu0hPQ@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>
	<CANEZrP3VCaFsW4+gPm2kCJ9z7oVUZYVaeNf=_cJWEWwh4ZxiPQ@mail.gmail.com>
	<CABsx9T21zjHyO-nh1aSBM3z4Bg015O0rOfYq7=Sy4mf=QxUVQA@mail.gmail.com>
	<CANEZrP2BaKwhpPgcUHWAHswOmUeFLgEk4ysrn4+73qNzWDJ=yQ@mail.gmail.com>
	<CABsx9T3nCJ-w_v-yEbEE2Ytb+xC65mhYqhoAhoOHw9tkPpG0TA@mail.gmail.com>
	<CANEZrP1qH+zucYsGrMgnfi99e61Edxaj+xm=u_xYXga1g0WzJQ@mail.gmail.com>
	<CAE-z3OVmw+0doCe0hmYE6A1D61h0AUh4Mtnf5Fg1e4zQBkpraQ@mail.gmail.com>
	<CANEZrP0psA7hcJdKdA-r01UEt7ig3O-9vjwBMqKSEq-csu0hPQ@mail.gmail.com>
Message-ID: <CABsx9T23r_y2R9OEgqb3AAZf47Hh8BUJncjxxmPp5v_9uKEiqQ@mail.gmail.com>

What do other people think?


If we can't come to an agreement soon, then I'll ask for help
reviewing/submitting patches to Mike's Bitcoin-Xt project that implement a
big increase now that grows over time so we may never have to go through
all this rancor and debate again.

I'll then ask for help lobbying the merchant services and exchanges and
hosted wallet companies and other bitcoind-using-infrastructure companies
(and anybody who agrees with me that we need bigger blocks sooner rather
than later) to run Bitcoin-Xt instead of Bitcoin Core, and state that they
are running it. We'll be able to see uptake on the network by monitoring
client versions.

Perhaps by the time that happens there will be consensus bigger blocks are
needed sooner rather than later; if so, great! The early deployment will
just serve as early testing, and all of the software already deployed will
ready for bigger blocks.

But if there is still no consensus among developers but the "bigger blocks
now" movement is successful, I'll ask for help getting big miners to do the
same, and use the soft-fork block version voting mechanism to (hopefully)
get a majority and then a super-majority willing to produce bigger blocks.
The purpose of that process is to prove to any doubters that they'd better
start supporting bigger blocks or they'll be left behind, and to give them
a chance to upgrade before that happens.


Because if we can't come to consensus here, the ultimate authority for
determining consensus is what code the majority of merchants and exchanges
and miners are running.


-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150529/3480fef4/attachment.html>

From insecurity at national.shitposting.agency  Fri May 29 14:00:54 2015
From: insecurity at national.shitposting.agency (insecurity at national.shitposting.agency)
Date: Fri, 29 May 2015 14:00:54 +0000
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
 function
In-Reply-To: <CABsx9T23r_y2R9OEgqb3AAZf47Hh8BUJncjxxmPp5v_9uKEiqQ@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>
	<CANEZrP3VCaFsW4+gPm2kCJ9z7oVUZYVaeNf=_cJWEWwh4ZxiPQ@mail.gmail.com>
	<CABsx9T21zjHyO-nh1aSBM3z4Bg015O0rOfYq7=Sy4mf=QxUVQA@mail.gmail.com>
	<CANEZrP2BaKwhpPgcUHWAHswOmUeFLgEk4ysrn4+73qNzWDJ=yQ@mail.gmail.com>
	<CABsx9T3nCJ-w_v-yEbEE2Ytb+xC65mhYqhoAhoOHw9tkPpG0TA@mail.gmail.com>
	<CANEZrP1qH+zucYsGrMgnfi99e61Edxaj+xm=u_xYXga1g0WzJQ@mail.gmail.com>
	<CAE-z3OVmw+0doCe0hmYE6A1D61h0AUh4Mtnf5Fg1e4zQBkpraQ@mail.gmail.com>
	<CANEZrP0psA7hcJdKdA-r01UEt7ig3O-9vjwBMqKSEq-csu0hPQ@mail.gmail.com>
	<CABsx9T23r_y2R9OEgqb3AAZf47Hh8BUJncjxxmPp5v_9uKEiqQ@mail.gmail.com>
Message-ID: <c7638510161365275aeaeabf121031bc@national.shitposting.agency>

Are you really that pig headed that you are going to try and blow up the 
entire system just to get your way? A bunch of ignorant redditors do not 
make consensus, mercifully.


On 2015-05-29 12:39, Gavin Andresen wrote:
> What do other people think?
> 
> If we can't come to an agreement soon, then I'll ask for help
> reviewing/submitting patches to Mike's Bitcoin-Xt project that
> implement a big increase now that grows over time so we may never have
> to go through all this rancor and debate again.
> 
> I'll then ask for help lobbying the merchant services and exchanges
> and hosted wallet companies and other bitcoind-using-infrastructure
> companies (and anybody who agrees with me that we need bigger blocks
> sooner rather than later) to run Bitcoin-Xt instead of Bitcoin Core,
> and state that they are running it. We'll be able to see uptake on the
> network by monitoring client versions.
> 
> Perhaps by the time that happens there will be consensus bigger blocks
> are needed sooner rather than later; if so, great! The early
> deployment will just serve as early testing, and all of the software
> already deployed will ready for bigger blocks.
> 
> But if there is still no consensus among developers but the "bigger
> blocks now" movement is successful, I'll ask for help getting big
> miners to do the same, and use the soft-fork block version voting
> mechanism to (hopefully) get a majority and then a super-majority
> willing to produce bigger blocks. The purpose of that process is to
> prove to any doubters that they'd better start supporting bigger
> blocks or they'll be left behind, and to give them a chance to upgrade
> before that happens.
> 
> Because if we can't come to consensus here, the ultimate authority for
> determining consensus is what code the majority of merchants and
> exchanges and miners are running.
> 
> --
> 
> --
> Gavin Andresen
> 
> ------------------------------------------------------------------------------
> 
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development



From tier.nolan at gmail.com  Fri May 29 14:09:20 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Fri, 29 May 2015 15:09:20 +0100
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CABsx9T23r_y2R9OEgqb3AAZf47Hh8BUJncjxxmPp5v_9uKEiqQ@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>
	<CANEZrP3VCaFsW4+gPm2kCJ9z7oVUZYVaeNf=_cJWEWwh4ZxiPQ@mail.gmail.com>
	<CABsx9T21zjHyO-nh1aSBM3z4Bg015O0rOfYq7=Sy4mf=QxUVQA@mail.gmail.com>
	<CANEZrP2BaKwhpPgcUHWAHswOmUeFLgEk4ysrn4+73qNzWDJ=yQ@mail.gmail.com>
	<CABsx9T3nCJ-w_v-yEbEE2Ytb+xC65mhYqhoAhoOHw9tkPpG0TA@mail.gmail.com>
	<CANEZrP1qH+zucYsGrMgnfi99e61Edxaj+xm=u_xYXga1g0WzJQ@mail.gmail.com>
	<CAE-z3OVmw+0doCe0hmYE6A1D61h0AUh4Mtnf5Fg1e4zQBkpraQ@mail.gmail.com>
	<CANEZrP0psA7hcJdKdA-r01UEt7ig3O-9vjwBMqKSEq-csu0hPQ@mail.gmail.com>
	<CABsx9T23r_y2R9OEgqb3AAZf47Hh8BUJncjxxmPp5v_9uKEiqQ@mail.gmail.com>
Message-ID: <CAE-z3OXEGcUYYAsqqrVMQw=XA=5dt9u7XHDmuzhMJ8OkZ+k3yg@mail.gmail.com>

On Fri, May 29, 2015 at 1:39 PM, Gavin Andresen <gavinandresen at gmail.com>
wrote:

> But if there is still no consensus among developers but the "bigger blocks
> now" movement is successful, I'll ask for help getting big miners to do the
> same, and use the soft-fork block version voting mechanism to (hopefully)
> get a majority and then a super-majority willing to produce bigger blocks.
> The purpose of that process is to prove to any doubters that they'd better
> start supporting bigger blocks or they'll be left behind, and to give them
> a chance to upgrade before that happens.
>

How do you define that the movement is successful?

For


> Because if we can't come to consensus here, the ultimate authority for
> determining consensus is what code the majority of merchants and exchanges
> and miners are running.
>

The measure is miner consensus.  How do you intend to measure
exchange/merchant acceptance?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150529/84672694/attachment.html>

From bbrelin at gmail.com  Fri May 29 14:15:43 2015
From: bbrelin at gmail.com (Braun Brelin)
Date: Fri, 29 May 2015 17:15:43 +0300
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <c7638510161365275aeaeabf121031bc@national.shitposting.agency>
References: <16096345.A1MpJQQkRW@crushinator>
	<CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>
	<CANEZrP3VCaFsW4+gPm2kCJ9z7oVUZYVaeNf=_cJWEWwh4ZxiPQ@mail.gmail.com>
	<CABsx9T21zjHyO-nh1aSBM3z4Bg015O0rOfYq7=Sy4mf=QxUVQA@mail.gmail.com>
	<CANEZrP2BaKwhpPgcUHWAHswOmUeFLgEk4ysrn4+73qNzWDJ=yQ@mail.gmail.com>
	<CABsx9T3nCJ-w_v-yEbEE2Ytb+xC65mhYqhoAhoOHw9tkPpG0TA@mail.gmail.com>
	<CANEZrP1qH+zucYsGrMgnfi99e61Edxaj+xm=u_xYXga1g0WzJQ@mail.gmail.com>
	<CAE-z3OVmw+0doCe0hmYE6A1D61h0AUh4Mtnf5Fg1e4zQBkpraQ@mail.gmail.com>
	<CANEZrP0psA7hcJdKdA-r01UEt7ig3O-9vjwBMqKSEq-csu0hPQ@mail.gmail.com>
	<CABsx9T23r_y2R9OEgqb3AAZf47Hh8BUJncjxxmPp5v_9uKEiqQ@mail.gmail.com>
	<c7638510161365275aeaeabf121031bc@national.shitposting.agency>
Message-ID: <CAJ2OvphPRm4KcnGfArZOom8cBK-hrC_wQaqV3_oTUO+vpCbztw@mail.gmail.com>

How is this being pigheaded? In my opinion, this is leadership.  If
*something* isn't implemented soon, the network is going to have some real
problems, right at the
time when adoption is starting to accelerate.  I've been seeing nothing but
navel-gazing and circlejerks on this issue for weeks now.  Gavin or Mike or
someone at some
point needs to step up and say "follow me".

Braun Brelin


On Fri, May 29, 2015 at 5:00 PM, <insecurity at national.shitposting.agency>
wrote:

> Are you really that pig headed that you are going to try and blow up the
> entire system just to get your way? A bunch of ignorant redditors do not
> make consensus, mercifully.
>
>
> On 2015-05-29 12:39, Gavin Andresen wrote:
> > What do other people think?
> >
> > If we can't come to an agreement soon, then I'll ask for help
> > reviewing/submitting patches to Mike's Bitcoin-Xt project that
> > implement a big increase now that grows over time so we may never have
> > to go through all this rancor and debate again.
> >
> > I'll then ask for help lobbying the merchant services and exchanges
> > and hosted wallet companies and other bitcoind-using-infrastructure
> > companies (and anybody who agrees with me that we need bigger blocks
> > sooner rather than later) to run Bitcoin-Xt instead of Bitcoin Core,
> > and state that they are running it. We'll be able to see uptake on the
> > network by monitoring client versions.
> >
> > Perhaps by the time that happens there will be consensus bigger blocks
> > are needed sooner rather than later; if so, great! The early
> > deployment will just serve as early testing, and all of the software
> > already deployed will ready for bigger blocks.
> >
> > But if there is still no consensus among developers but the "bigger
> > blocks now" movement is successful, I'll ask for help getting big
> > miners to do the same, and use the soft-fork block version voting
> > mechanism to (hopefully) get a majority and then a super-majority
> > willing to produce bigger blocks. The purpose of that process is to
> > prove to any doubters that they'd better start supporting bigger
> > blocks or they'll be left behind, and to give them a chance to upgrade
> > before that happens.
> >
> > Because if we can't come to consensus here, the ultimate authority for
> > determining consensus is what code the majority of merchants and
> > exchanges and miners are running.
> >
> > --
> >
> > --
> > Gavin Andresen
> >
> >
> ------------------------------------------------------------------------------
> >
> > _______________________________________________
> > Bitcoin-development mailing list
> > Bitcoin-development at lists.sourceforge.net
> > https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
> ------------------------------------------------------------------------------
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150529/6353ffbd/attachment.html>

From gavinandresen at gmail.com  Fri May 29 14:20:01 2015
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Fri, 29 May 2015 10:20:01 -0400
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CAE-z3OXEGcUYYAsqqrVMQw=XA=5dt9u7XHDmuzhMJ8OkZ+k3yg@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>
	<CANEZrP3VCaFsW4+gPm2kCJ9z7oVUZYVaeNf=_cJWEWwh4ZxiPQ@mail.gmail.com>
	<CABsx9T21zjHyO-nh1aSBM3z4Bg015O0rOfYq7=Sy4mf=QxUVQA@mail.gmail.com>
	<CANEZrP2BaKwhpPgcUHWAHswOmUeFLgEk4ysrn4+73qNzWDJ=yQ@mail.gmail.com>
	<CABsx9T3nCJ-w_v-yEbEE2Ytb+xC65mhYqhoAhoOHw9tkPpG0TA@mail.gmail.com>
	<CANEZrP1qH+zucYsGrMgnfi99e61Edxaj+xm=u_xYXga1g0WzJQ@mail.gmail.com>
	<CAE-z3OVmw+0doCe0hmYE6A1D61h0AUh4Mtnf5Fg1e4zQBkpraQ@mail.gmail.com>
	<CANEZrP0psA7hcJdKdA-r01UEt7ig3O-9vjwBMqKSEq-csu0hPQ@mail.gmail.com>
	<CABsx9T23r_y2R9OEgqb3AAZf47Hh8BUJncjxxmPp5v_9uKEiqQ@mail.gmail.com>
	<CAE-z3OXEGcUYYAsqqrVMQw=XA=5dt9u7XHDmuzhMJ8OkZ+k3yg@mail.gmail.com>
Message-ID: <CABsx9T2-NypB1g4-5wsvR_CUXBoHi5yR3VsivrGsn_pLbEd+-g@mail.gmail.com>

On Fri, May 29, 2015 at 10:09 AM, Tier Nolan <tier.nolan at gmail.com> wrote:

>  How do you intend to measure exchange/merchant acceptance?
>

Public statements saying "we're running software that is ready for bigger
blocks."

And looking at the version (aka user-agent) strings of publicly reachable
nodes on the network.
(e.g. see the count at  https://getaddr.bitnodes.io/nodes/ )

-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150529/f02fc1b9/attachment.html>

From mike at plan99.net  Fri May 29 14:21:02 2015
From: mike at plan99.net (Mike Hearn)
Date: Fri, 29 May 2015 16:21:02 +0200
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CAE-z3OXEGcUYYAsqqrVMQw=XA=5dt9u7XHDmuzhMJ8OkZ+k3yg@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>
	<CANEZrP3VCaFsW4+gPm2kCJ9z7oVUZYVaeNf=_cJWEWwh4ZxiPQ@mail.gmail.com>
	<CABsx9T21zjHyO-nh1aSBM3z4Bg015O0rOfYq7=Sy4mf=QxUVQA@mail.gmail.com>
	<CANEZrP2BaKwhpPgcUHWAHswOmUeFLgEk4ysrn4+73qNzWDJ=yQ@mail.gmail.com>
	<CABsx9T3nCJ-w_v-yEbEE2Ytb+xC65mhYqhoAhoOHw9tkPpG0TA@mail.gmail.com>
	<CANEZrP1qH+zucYsGrMgnfi99e61Edxaj+xm=u_xYXga1g0WzJQ@mail.gmail.com>
	<CAE-z3OVmw+0doCe0hmYE6A1D61h0AUh4Mtnf5Fg1e4zQBkpraQ@mail.gmail.com>
	<CANEZrP0psA7hcJdKdA-r01UEt7ig3O-9vjwBMqKSEq-csu0hPQ@mail.gmail.com>
	<CABsx9T23r_y2R9OEgqb3AAZf47Hh8BUJncjxxmPp5v_9uKEiqQ@mail.gmail.com>
	<CAE-z3OXEGcUYYAsqqrVMQw=XA=5dt9u7XHDmuzhMJ8OkZ+k3yg@mail.gmail.com>
Message-ID: <CANEZrP15X2JbMazMN7Rw2oxums6X-D3m5zBP02YoqTa6UTzfHQ@mail.gmail.com>

>
> The measure is miner consensus.  How do you intend to measure
> exchange/merchant acceptance?
>

Asking them.

In fact, we already have. I have been talking to well known people and CEOs
in the Bitcoin community for some time now. *All* of them support bigger
blocks, this includes:

   - Every wallet developer I have asked (other than Bitcoin Core)
   - So far, every payment processor and every exchange company

I know Gavin has also been talking to people about this.

There's a feeling on this list that there's no consensus, or that Gavin and
myself are on the wrong side of it. I'd put it differently - there's very
strong consensus out in the wider community and this list is something of
an aberration.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150529/d159d41b/attachment.html>

From mike at plan99.net  Fri May 29 14:22:22 2015
From: mike at plan99.net (Mike Hearn)
Date: Fri, 29 May 2015 16:22:22 +0200
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CABsx9T2-NypB1g4-5wsvR_CUXBoHi5yR3VsivrGsn_pLbEd+-g@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>
	<CANEZrP3VCaFsW4+gPm2kCJ9z7oVUZYVaeNf=_cJWEWwh4ZxiPQ@mail.gmail.com>
	<CABsx9T21zjHyO-nh1aSBM3z4Bg015O0rOfYq7=Sy4mf=QxUVQA@mail.gmail.com>
	<CANEZrP2BaKwhpPgcUHWAHswOmUeFLgEk4ysrn4+73qNzWDJ=yQ@mail.gmail.com>
	<CABsx9T3nCJ-w_v-yEbEE2Ytb+xC65mhYqhoAhoOHw9tkPpG0TA@mail.gmail.com>
	<CANEZrP1qH+zucYsGrMgnfi99e61Edxaj+xm=u_xYXga1g0WzJQ@mail.gmail.com>
	<CAE-z3OVmw+0doCe0hmYE6A1D61h0AUh4Mtnf5Fg1e4zQBkpraQ@mail.gmail.com>
	<CANEZrP0psA7hcJdKdA-r01UEt7ig3O-9vjwBMqKSEq-csu0hPQ@mail.gmail.com>
	<CABsx9T23r_y2R9OEgqb3AAZf47Hh8BUJncjxxmPp5v_9uKEiqQ@mail.gmail.com>
	<CAE-z3OXEGcUYYAsqqrVMQw=XA=5dt9u7XHDmuzhMJ8OkZ+k3yg@mail.gmail.com>
	<CABsx9T2-NypB1g4-5wsvR_CUXBoHi5yR3VsivrGsn_pLbEd+-g@mail.gmail.com>
Message-ID: <CANEZrP11O796UAAZj0mgPLtme97kiOsg1dU3WjFx0Z2yisQ3ag@mail.gmail.com>

>
> And looking at the version (aka user-agent) strings of publicly reachable
> nodes on the network.
> (e.g. see the count at  https://getaddr.bitnodes.io/nodes/ )
>

Yeah, though FYI Luke informed me last week that I somehow managed to take
out the change to the user-agent string in Bitcoin XT, presumably I made a
mistake during a rebase of the rebranding change. So the actual number of
XT nodes is a bit higher than counting user-agent strings would suggest.

I sort of neglected XT lately. If we go ahead with this then I'll fix
things like this.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150529/83bc21bf/attachment.html>

From tier.nolan at gmail.com  Fri May 29 14:22:27 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Fri, 29 May 2015 15:22:27 +0100
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CAE-z3OXEGcUYYAsqqrVMQw=XA=5dt9u7XHDmuzhMJ8OkZ+k3yg@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>
	<CANEZrP3VCaFsW4+gPm2kCJ9z7oVUZYVaeNf=_cJWEWwh4ZxiPQ@mail.gmail.com>
	<CABsx9T21zjHyO-nh1aSBM3z4Bg015O0rOfYq7=Sy4mf=QxUVQA@mail.gmail.com>
	<CANEZrP2BaKwhpPgcUHWAHswOmUeFLgEk4ysrn4+73qNzWDJ=yQ@mail.gmail.com>
	<CABsx9T3nCJ-w_v-yEbEE2Ytb+xC65mhYqhoAhoOHw9tkPpG0TA@mail.gmail.com>
	<CANEZrP1qH+zucYsGrMgnfi99e61Edxaj+xm=u_xYXga1g0WzJQ@mail.gmail.com>
	<CAE-z3OVmw+0doCe0hmYE6A1D61h0AUh4Mtnf5Fg1e4zQBkpraQ@mail.gmail.com>
	<CANEZrP0psA7hcJdKdA-r01UEt7ig3O-9vjwBMqKSEq-csu0hPQ@mail.gmail.com>
	<CABsx9T23r_y2R9OEgqb3AAZf47Hh8BUJncjxxmPp5v_9uKEiqQ@mail.gmail.com>
	<CAE-z3OXEGcUYYAsqqrVMQw=XA=5dt9u7XHDmuzhMJ8OkZ+k3yg@mail.gmail.com>
Message-ID: <CAE-z3OU8Vtmi_UK=nF1UNLsXCwd17mKDMS1qKudYB_kwDbOguA@mail.gmail.com>

On Fri, May 29, 2015 at 3:09 PM, Tier Nolan <tier.nolan at gmail.com> wrote:

>
>
> On Fri, May 29, 2015 at 1:39 PM, Gavin Andresen <gavinandresen at gmail.com>
> wrote:
>
>> But if there is still no consensus among developers but the "bigger
>> blocks now" movement is successful, I'll ask for help getting big miners to
>> do the same, and use the soft-fork block version voting mechanism to
>> (hopefully) get a majority and then a super-majority willing to produce
>> bigger blocks. The purpose of that process is to prove to any doubters that
>> they'd better start supporting bigger blocks or they'll be left behind, and
>> to give them a chance to upgrade before that happens.
>>
>
> How do you define that the movement is successful?
>

Sorry again, I keep auto-sending from gmail when trying to delete.

In theory, using the "nuclear option", the block size can be increased via
soft fork.

Version 4 blocks would contain the hash of the a valid extended block in
the coinbase.

<block height> <32 byte extended hash>

To send coins to the auxiliary block, you send them to some template.

OP_P2SH_EXTENDED <scriptPubKey hash> OP_TRUE

This transaction can be spent by anyone (under the current rules).  The
soft fork would lock the transaction output unless it transferred money
from the extended block.

To unlock the transaction output, you need to include the txid of
transaction(s) in the extended block and signature(s) in the scriptSig.

The transaction output can be spent in the extended block using P2SH
against the scriptPubKey hash.

This means that people can choose to move their money to the extended
block.  It might have lower security than leaving it in the root chain.

The extended chain could use the updated script language too.

This is obviously more complex than just increasing the size though, but it
could be a fallback option if no consensus is reached.  It has the
advantage of giving people a choice.  They can move their money to the
extended chain or not, as they wish.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150529/8bedd264/attachment.html>

From raystonn at hotmail.com  Fri May 29 16:39:29 2015
From: raystonn at hotmail.com (Raystonn .)
Date: Fri, 29 May 2015 09:39:29 -0700
Subject: [Bitcoin-development] Proposed alternatives to the 20MB
	stepfunction
In-Reply-To: <CAE-z3OU8Vtmi_UK=nF1UNLsXCwd17mKDMS1qKudYB_kwDbOguA@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator><CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com><CANEZrP3VCaFsW4+gPm2kCJ9z7oVUZYVaeNf=_cJWEWwh4ZxiPQ@mail.gmail.com><CABsx9T21zjHyO-nh1aSBM3z4Bg015O0rOfYq7=Sy4mf=QxUVQA@mail.gmail.com><CANEZrP2BaKwhpPgcUHWAHswOmUeFLgEk4ysrn4+73qNzWDJ=yQ@mail.gmail.com><CABsx9T3nCJ-w_v-yEbEE2Ytb+xC65mhYqhoAhoOHw9tkPpG0TA@mail.gmail.com><CANEZrP1qH+zucYsGrMgnfi99e61Edxaj+xm=u_xYXga1g0WzJQ@mail.gmail.com><CAE-z3OVmw+0doCe0hmYE6A1D61h0AUh4Mtnf5Fg1e4zQBkpraQ@mail.gmail.com><CANEZrP0psA7hcJdKdA-r01UEt7ig3O-9vjwBMqKSEq-csu0hPQ@mail.gmail.com><CABsx9T23r_y2R9OEgqb3AAZf47Hh8BUJncjxxmPp5v_9uKEiqQ@mail.gmail.com><CAE-z3OXEGcUYYAsqqrVMQw=XA=5dt9u7XHDmuzhMJ8OkZ+k3yg@mail.gmail.com>
	<CAE-z3OU8Vtmi_UK=nF1UNLsXCwd17mKDMS1qKudYB_kwDbOguA@mail.gmail.com>
Message-ID: <COL131-DS8AE5724250D730A8B03C5CDC90@phx.gbl>

Regarding Tier?s proposal: The lower security you mention for extended blocks would delay, possibly forever, the larger blocks maximum block size that we want for the entire network.  That doesn?t sound like an optimal solution.

Regarding consensus for larger maximum block size, what we are seeing on this list is typical of what we see in the U.S. Congress.  Support for changes by the stakeholders (support for bills by the citizens as a whole) has become irrelevant to the probability of these changes being adopted.  Lobbyists have all the sway in getting their policies enacted.  In our case, I would bet on some lobbying of core developers by wealthy miners.

Someone recently proposed that secret ballots could help eliminate the power of lobbyists in Congress.  Nobody invests in that which cannot be confirmed.  Secret ballots mean the vote you are buying cannot be confirmed.  Perhaps this will work for Bitcoin Core as well.


From: Tier Nolan 
Sent: Friday, May 29, 2015 7:22 AM
Cc: Bitcoin Dev 
Subject: Re: [Bitcoin-development] Proposed alternatives to the 20MB stepfunction

On Fri, May 29, 2015 at 3:09 PM, Tier Nolan <tier.nolan at gmail.com> wrote:



  On Fri, May 29, 2015 at 1:39 PM, Gavin Andresen <gavinandresen at gmail.com> wrote:

    But if there is still no consensus among developers but the "bigger blocks now" movement is successful, I'll ask for help getting big miners to do the same, and use the soft-fork block version voting mechanism to (hopefully) get a majority and then a super-majority willing to produce bigger blocks. The purpose of that process is to prove to any doubters that they'd better start supporting bigger blocks or they'll be left behind, and to give them a chance to upgrade before that happens.

  How do you define that the movement is successful?


Sorry again, I keep auto-sending from gmail when trying to delete.


In theory, using the "nuclear option", the block size can be increased via soft fork.


Version 4 blocks would contain the hash of the a valid extended block in the coinbase.


<block height> <32 byte extended hash>


To send coins to the auxiliary block, you send them to some template.


OP_P2SH_EXTENDED <scriptPubKey hash> OP_TRUE


This transaction can be spent by anyone (under the current rules).  The soft fork would lock the transaction output unless it transferred money from the extended block.


To unlock the transaction output, you need to include the txid of transaction(s) in the extended block and signature(s) in the scriptSig.


The transaction output can be spent in the extended block using P2SH against the scriptPubKey hash.


This means that people can choose to move their money to the extended block.  It might have lower security than leaving it in the root chain.


The extended chain could use the updated script language too.


This is obviously more complex than just increasing the size though, but it could be a fallback option if no consensus is reached.  It has the advantage of giving people a choice.  They can move their money to the extended chain or not, as they wish.



--------------------------------------------------------------------------------
------------------------------------------------------------------------------



--------------------------------------------------------------------------------
_______________________________________________
Bitcoin-development mailing list
Bitcoin-development at lists.sourceforge.net
https://lists.sourceforge.net/lists/listinfo/bitcoin-development
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150529/9eaf701c/attachment.html>

From voisine at gmail.com  Fri May 29 17:45:39 2015
From: voisine at gmail.com (Aaron Voisine)
Date: Fri, 29 May 2015 10:45:39 -0700
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>
Message-ID: <CACq0ZD7hQGsR+-AORrjMYBzLzW80goKAsUEKf_GPfyL5bXN5iA@mail.gmail.com>

> miners would definitely be squeezing out transactions / putting pressure
to increase transaction fees

I'd just like to re-iterate that transactions getting "squeezed out"
(failure after a lengthy period of uncertainty) is a radical change from
the current behavior of the network. There are plenty of avenues to create
fee pressure without resorting to such a drastic change in how the network
works today.


Aaron Voisine
co-founder and CEO
breadwallet.com

On Thu, May 28, 2015 at 8:53 AM, Gavin Andresen <gavinandresen at gmail.com>
wrote:

> On Fri, May 8, 2015 at 3:20 AM, Matt Whitlock <bip at mattwhitlock.name>
> wrote:
>
>> Between all the flames on this list, several ideas were raised that did
>> not get much attention. I hereby resubmit these ideas for consideration and
>> discussion.
>>
>> - Perhaps the hard block size limit should be a function of the actual
>> block sizes over some trailing sampling period. For example, take the
>> median block size among the most recent 2016 blocks and multiply it by 1.5.
>> This allows Bitcoin to scale up gradually and organically, rather than
>> having human beings guessing at what is an appropriate limit.
>>
>
> A lot of people like this idea, or something like it. It is nice and
> simple, which is really important for consensus-critical code.
>
> With this rule in place, I believe there would be more "fee pressure"
> (miners would be creating smaller blocks) today. I created a couple of
> histograms of block sizes to infer what policy miners are ACTUALLY
> following today with respect to block size:
>
> Last 1,000 blocks:
>   http://bitcoincore.org/~gavin/sizes_last1000.html
>
> Notice a big spike at 750K -- the default size for Bitcoin Core.
> This graph might be misleading, because transaction volume or fees might
> not be high enough over the last few days to fill blocks to whatever limit
> miners are willing to mine.
>
> So I graphed a time when (according to statoshi.info) there WERE a lot of
> transactions waiting to be confirmed:
>    http://bitcoincore.org/~gavin/sizes_357511.html
>
> That might also be misleading, because it is possible there were a lot of
> transactions waiting to be confirmed because miners who choose to create
> small blocks got lucky and found more blocks than normal.  In fact, it
> looks like that is what happened: more smaller-than-normal blocks were
> found, and the memory pool backed up.
>
> So: what if we had a dynamic maximum size limit based on recent history?
>
> The average block size is about 400K, so a 1.5x rule would make the max
> block size 600K; miners would definitely be squeezing out transactions /
> putting pressure to increase transaction fees. Even a 2x rule (implying
> 800K max blocks) would, today, be squeezing out transactions / putting
> pressure to increase fees.
>
> Using a median size instead of an average means the size can increase or
> decrease more quickly. For example, imagine the rule is "median of last
> 2016 blocks" and 49% of miners are producing 0-size blocks and 51% are
> producing max-size blocks. The median is max-size, so the 51% have total
> control over making blocks bigger.  Swap the roles, and the median is
> min-size.
>
> Because of that, I think using an average is better-- it means the max
> size will change (up or down) more slowly.
>
> I also think 2016 blocks is too long, because transaction volumes change
> quicker than that. An average over 144 blocks (last 24 hours) would be
> better able to handle increased transaction volume around major holidays,
> and would also be able to react more quickly if an economically irrational
> attacker attempted to flood the network with fee-paying transactions.
>
> So my straw-man proposal would be:  max size 2x average size over last 144
> blocks, calculated at every block.
>
> There are a couple of other changes I'd pair with that consensus change:
>
> + Make the default mining policy for Bitcoin Core neutral-- have its
> target block size be the average size, so miners that don't care will "go
> along with the people who do care."
>
> + Use something like Greg's formula for size instead of bytes-on-the-wire,
> to discourage bloating the UTXO set.
>
>
> ---------
>
> When I've proposed (privately, to the other core committers) some dynamic
> algorithm the objection has been "but that gives miners complete control
> over the max block size."
>
> I think that worry is unjustified right now-- certainly, until we have
> size-independent new block propagation there is an incentive for miners to
> keep their blocks small, and we see miners creating small blocks even when
> there are fee-paying transactions waiting to be confirmed.
>
> I don't even think it will be a problem if/when we do have
> size-independent new block propagation, because I think the combination of
> the random timing of block-finding plus a dynamic limit as described above
> will create a healthy system.
>
> If I'm wrong, then it seems to me the miners will have a very strong
> incentive to, collectively, impose whatever rules are necessary (maybe a
> soft-fork to put a hard cap on block size) to make the system healthy again.
>
>
> --
> --
> Gavin Andresen
>
>
>
> ------------------------------------------------------------------------------
>
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150529/8755354e/attachment.html>

From andy at ftlio.com  Fri May 29 17:53:55 2015
From: andy at ftlio.com (Admin Istrator)
Date: Fri, 29 May 2015 10:53:55 -0700
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CABsx9T23r_y2R9OEgqb3AAZf47Hh8BUJncjxxmPp5v_9uKEiqQ@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>
	<CANEZrP3VCaFsW4+gPm2kCJ9z7oVUZYVaeNf=_cJWEWwh4ZxiPQ@mail.gmail.com>
	<CABsx9T21zjHyO-nh1aSBM3z4Bg015O0rOfYq7=Sy4mf=QxUVQA@mail.gmail.com>
	<CANEZrP2BaKwhpPgcUHWAHswOmUeFLgEk4ysrn4+73qNzWDJ=yQ@mail.gmail.com>
	<CABsx9T3nCJ-w_v-yEbEE2Ytb+xC65mhYqhoAhoOHw9tkPpG0TA@mail.gmail.com>
	<CANEZrP1qH+zucYsGrMgnfi99e61Edxaj+xm=u_xYXga1g0WzJQ@mail.gmail.com>
	<CAE-z3OVmw+0doCe0hmYE6A1D61h0AUh4Mtnf5Fg1e4zQBkpraQ@mail.gmail.com>
	<CANEZrP0psA7hcJdKdA-r01UEt7ig3O-9vjwBMqKSEq-csu0hPQ@mail.gmail.com>
	<CABsx9T23r_y2R9OEgqb3AAZf47Hh8BUJncjxxmPp5v_9uKEiqQ@mail.gmail.com>
Message-ID: <CA+VAk3O7SmDkxL9rATWe9oqCVVKcT=cFXDJnARPN8pv=UiHaiA@mail.gmail.com>

What about trying the dynamic scaling method within the 20MB range + 1 year
with a 40% increase of that cap?  Until a way to dynamically scale is
found, the cap will only continue to be an issue.  With 20 MB + 40% yoy,
we're either imposing an arbitrary cap later, or achieving less than great
DOS protection always.  Why not set that policy as a maximum for 2 years as
a protection against the possibility of dynamic scaling abuse, and see what
happens with a dynamic method in the mean time.  The policy of Max(1MB,
(average size over previous 144 blocks) * 2) calculated at each block seems
pretty reasonable.

As an outsider, the real 'median' here seems to be 'keeping the cap as
small as possible while allowing for larger blocks still'.    We know
miners will want to keep space in their blocks relatively scarce, but we
also know that doesn't exclude the more powerful miners from
including superfluous transactions to increase their effective share of the
network.  I have the luck of not being drained by this topic over the past
three years, so it looks to me as if its two poles of 'block size must
increase' and 'block size must not increase' are forcing what is the clear
route to establishing the 'right' block size off the table.

--Andrew Len
(sorry if anybody received this twice, sent as the wrong email the first
time around).

On Fri, May 29, 2015 at 5:39 AM, Gavin Andresen <gavinandresen at gmail.com>
wrote:

> What do other people think?
>
>
> If we can't come to an agreement soon, then I'll ask for help
> reviewing/submitting patches to Mike's Bitcoin-Xt project that implement a
> big increase now that grows over time so we may never have to go through
> all this rancor and debate again.
>
> I'll then ask for help lobbying the merchant services and exchanges and
> hosted wallet companies and other bitcoind-using-infrastructure companies
> (and anybody who agrees with me that we need bigger blocks sooner rather
> than later) to run Bitcoin-Xt instead of Bitcoin Core, and state that they
> are running it. We'll be able to see uptake on the network by monitoring
> client versions.
>
> Perhaps by the time that happens there will be consensus bigger blocks are
> needed sooner rather than later; if so, great! The early deployment will
> just serve as early testing, and all of the software already deployed will
> ready for bigger blocks.
>
> But if there is still no consensus among developers but the "bigger blocks
> now" movement is successful, I'll ask for help getting big miners to do the
> same, and use the soft-fork block version voting mechanism to (hopefully)
> get a majority and then a super-majority willing to produce bigger blocks.
> The purpose of that process is to prove to any doubters that they'd better
> start supporting bigger blocks or they'll be left behind, and to give them
> a chance to upgrade before that happens.
>
>
> Because if we can't come to consensus here, the ultimate authority for
> determining consensus is what code the majority of merchants and exchanges
> and miners are running.
>
>
> --
> --
> Gavin Andresen
>
>
> ------------------------------------------------------------------------------
>
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150529/3d4a11fb/attachment.html>

From tier.nolan at gmail.com  Fri May 29 18:28:22 2015
From: tier.nolan at gmail.com (Tier Nolan)
Date: Fri, 29 May 2015 19:28:22 +0100
Subject: [Bitcoin-development] Proposed alternatives to the 20MB
	stepfunction
In-Reply-To: <COL131-DS8AE5724250D730A8B03C5CDC90@phx.gbl>
References: <16096345.A1MpJQQkRW@crushinator>
	<CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>
	<CANEZrP3VCaFsW4+gPm2kCJ9z7oVUZYVaeNf=_cJWEWwh4ZxiPQ@mail.gmail.com>
	<CABsx9T21zjHyO-nh1aSBM3z4Bg015O0rOfYq7=Sy4mf=QxUVQA@mail.gmail.com>
	<CANEZrP2BaKwhpPgcUHWAHswOmUeFLgEk4ysrn4+73qNzWDJ=yQ@mail.gmail.com>
	<CABsx9T3nCJ-w_v-yEbEE2Ytb+xC65mhYqhoAhoOHw9tkPpG0TA@mail.gmail.com>
	<CANEZrP1qH+zucYsGrMgnfi99e61Edxaj+xm=u_xYXga1g0WzJQ@mail.gmail.com>
	<CAE-z3OVmw+0doCe0hmYE6A1D61h0AUh4Mtnf5Fg1e4zQBkpraQ@mail.gmail.com>
	<CANEZrP0psA7hcJdKdA-r01UEt7ig3O-9vjwBMqKSEq-csu0hPQ@mail.gmail.com>
	<CABsx9T23r_y2R9OEgqb3AAZf47Hh8BUJncjxxmPp5v_9uKEiqQ@mail.gmail.com>
	<CAE-z3OXEGcUYYAsqqrVMQw=XA=5dt9u7XHDmuzhMJ8OkZ+k3yg@mail.gmail.com>
	<CAE-z3OU8Vtmi_UK=nF1UNLsXCwd17mKDMS1qKudYB_kwDbOguA@mail.gmail.com>
	<COL131-DS8AE5724250D730A8B03C5CDC90@phx.gbl>
Message-ID: <CAE-z3OXxNhhVND5O3Sz3nkJehHj_xLsk6nbmy7n-F+H_VMbWtw@mail.gmail.com>

On Fri, May 29, 2015 at 5:39 PM, Raystonn . <raystonn at hotmail.com> wrote:

>   Regarding Tier?s proposal: The lower security you mention for extended
> blocks would delay, possibly forever, the larger blocks maximum block size
> that we want for the entire network.  That doesn?t sound like an optimal
> solution.
>

I don't think so.  The lower security is the potential centralisation
risk.  If you have your money in the "root" chain, then you can watch it.
You can probably also watch it in a 20MB chain.

Full nodes would still verify the entire block (root + extended).  It is a
"nuclear option", since you can make any changes you want to the rules for
the extended chain.  The only safe guard is that people have to voluntarly
transfer coins to the extended block.

The extended block might have 10-15% of the total bitcoins, but still be
useful, since they would be the ones that move the most.  If you want to
store your coins long term, you move them back to the root block where you
can watch them more closely.

It does make things more complex though.  Wallets would have to list 2
balances.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150529/27a2d71c/attachment.html>

From bryan at blockcypher.com  Fri May 29 18:47:31 2015
From: bryan at blockcypher.com (Bryan Cheng)
Date: Fri, 29 May 2015 11:47:31 -0700
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CABsx9T23r_y2R9OEgqb3AAZf47Hh8BUJncjxxmPp5v_9uKEiqQ@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>
	<CANEZrP3VCaFsW4+gPm2kCJ9z7oVUZYVaeNf=_cJWEWwh4ZxiPQ@mail.gmail.com>
	<CABsx9T21zjHyO-nh1aSBM3z4Bg015O0rOfYq7=Sy4mf=QxUVQA@mail.gmail.com>
	<CANEZrP2BaKwhpPgcUHWAHswOmUeFLgEk4ysrn4+73qNzWDJ=yQ@mail.gmail.com>
	<CABsx9T3nCJ-w_v-yEbEE2Ytb+xC65mhYqhoAhoOHw9tkPpG0TA@mail.gmail.com>
	<CANEZrP1qH+zucYsGrMgnfi99e61Edxaj+xm=u_xYXga1g0WzJQ@mail.gmail.com>
	<CAE-z3OVmw+0doCe0hmYE6A1D61h0AUh4Mtnf5Fg1e4zQBkpraQ@mail.gmail.com>
	<CANEZrP0psA7hcJdKdA-r01UEt7ig3O-9vjwBMqKSEq-csu0hPQ@mail.gmail.com>
	<CABsx9T23r_y2R9OEgqb3AAZf47Hh8BUJncjxxmPp5v_9uKEiqQ@mail.gmail.com>
Message-ID: <CANeMN=8Q3CF6kfA+4X8Rf0HHWwjEJ5kb4ePgHccWgGJ2CPz3eA@mail.gmail.com>

On Fri, May 29, 2015 at 5:39 AM, Gavin Andresen <gavinandresen at gmail.com>
wrote:

> What do other people think?
>
>
> If we can't come to an agreement soon, then I'll ask for help
> reviewing/submitting patches to Mike's Bitcoin-Xt project that implement a
> big increase now that grows over time so we may never have to go through
> all this rancor and debate again.
>
> I'll then ask for help lobbying the merchant services and exchanges and
> hosted wallet companies and other bitcoind-using-infrastructure companies
> (and anybody who agrees with me that we need bigger blocks sooner rather
> than later) to run Bitcoin-Xt instead of Bitcoin Core, and state that they
> are running it. We'll be able to see uptake on the network by monitoring
> client versions.
>
>
>
While I think we'd all prefer Core to make changes like this, the current
environment may make that impossible. If this change happens in XT, we will
support the necessary changes in our own implementation. The block size
limit is a problem _today_, and I'd rather we solve today's problems with
today's understanding rather than let speculation about future unknowns
stop our ability to respond to known issues.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150529/64fa5360/attachment.html>

From gavinandresen at gmail.com  Fri May 29 22:36:51 2015
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Fri, 29 May 2015 18:36:51 -0400
Subject: [Bitcoin-development] Block Size Increase Requirements
In-Reply-To: <554BE0E1.5030001@bluematt.me>
References: <554BE0E1.5030001@bluematt.me>
Message-ID: <CABsx9T2ysKj5HVbN_7_o33fMehs4KH6E_R583Mt_VPC4gDA0LQ@mail.gmail.com>

Matt brought this up on Twitter, I have no idea why I didn't respond weeks
ago (busy writing blog posts, probably):

On Thu, May 7, 2015 at 6:02 PM, Matt Corallo <bitcoin-list at bluematt.me>
wrote:

>
>
>  * Though there are many proposals floating around which could
> significantly decrease block propagation latency, none of them are
> implemented today.


If block propagation isn't fixed, then mines have a strong incentive to
create smaller blocks.

So the max block size is irrelevant, it won't get hit.


> In addition, I'd expect to
> see analysis of how these systems perform in the worst-case, not just
> packet-loss-wise, but in the face of miners attempting to break the system.
>

See http://gavinandresen.ninja/are-bigger-blocks-better-for-bigger-miners
for analysis of "but that means bigger miners can get an advantage"
argument.

Executive summary: if little miners are stupid and produce huge blocks,
then yes, big miners have an advantage.

But they're not, so they won't.

Until the block reward goes away, and assuming transaction fees become an
important source of revenue for miners.
I think it is too early to worry about that; see:

   http://gavinandresen.ninja/when-the-block-reward-goes-away


>  * I'd very much like to see someone working on better scaling
> technology, both in terms of development and in terms of getting
> traction in the marketplace.


Ok. What does this have to do with the max block size?

Are you arguing that work won't happen if the max block size increases?

  * I'd like to see some better conclusions to the discussion around

> long-term incentives within the system.


Again, see http://gavinandresen.ninja/when-the-block-reward-goes-away for
what I think about that.

-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150529/c145f6b9/attachment.html>

From bitcoin-list at bluematt.me  Fri May 29 23:25:27 2015
From: bitcoin-list at bluematt.me (Matt Corallo)
Date: Fri, 29 May 2015 23:25:27 +0000
Subject: [Bitcoin-development] Block Size Increase Requirements
In-Reply-To: <CABsx9T2ysKj5HVbN_7_o33fMehs4KH6E_R583Mt_VPC4gDA0LQ@mail.gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CABsx9T2ysKj5HVbN_7_o33fMehs4KH6E_R583Mt_VPC4gDA0LQ@mail.gmail.com>
Message-ID: <5568F567.3050608@bluematt.me>



On 05/29/15 22:36, Gavin Andresen wrote:
> Matt brought this up on Twitter, I have no idea why I didn't respond
> weeks ago (busy writing blog posts, probably):
> 
> On Thu, May 7, 2015 at 6:02 PM, Matt Corallo <bitcoin-list at bluematt.me
> <mailto:bitcoin-list at bluematt.me>> wrote:
> 
> 
> 
>      * Though there are many proposals floating around which could
>     significantly decrease block propagation latency, none of them are
>     implemented today.
> 
> 
> If block propagation isn't fixed, then mines have a strong incentive to
> create smaller blocks.
> 
> So the max block size is irrelevant, it won't get hit.

Sadly, this is very far from the whole story. The issue of miners
optimizing for returns has been discussed several times during this
discussion, and, sadly, miners who are geographically colocated who are
optimizing for returns with a free-floating blocksize will optimize away
50% of the network!

> 
>     In addition, I'd expect to
>     see analysis of how these systems perform in the worst-case, not just
>     packet-loss-wise, but in the face of miners attempting to break the
>     system.
> 
> 
> See http://gavinandresen.ninja/are-bigger-blocks-better-for-bigger-miners for
> analysis of "but that means bigger miners can get an advantage" argument.
> 
> Executive summary: if little miners are stupid and produce huge blocks,
> then yes, big miners have an advantage.

I'll talk about transaction fees in a second, but there are several
problems with this already. As pointed out in the original mail, gfw has
already been known to interfere with Bitcoin P2P traffic. So now by
"little" miners, you mean any miner who is not located in mainland
China? Whats worse, the disadvantage is symmetric - little miners are at
a disadvantage when *anyone* mines a bigger block, and miners dont even
have to be "evil" for this to happen - just optimize for profits.

> But they're not, so they won't.

I dont know what you're referring to with this. Are you claiming little
miners today optimize for relay times and have good visibility into the
Bitcoin network and calculate an optimal block size based on this (or
would with a 20MB block size)?

> Until the block reward goes away, and assuming transaction fees become
> an important source of revenue for miners.
> I think it is too early to worry about that; see:
> 
>    http://gavinandresen.ninja/when-the-block-reward-goes-away

You dont make any points here with which I can argue, but let me respond
with the reason /I/ think it is a problem worth thinking a little bit
about...If we increase the blocksize sufficiently such that transaction
fees are not the way in which miners make their money, then either
miners are not being funded (ie hashpower has to drop to very little),
or the only people mining/funding miners are large orgs who are
"running" Bitcoin (ie the web wallets, payment processors, big
merchants, and exchanges of the world). Sadly, this is no longer a
decentralized Bitcoin and is, in fact, pretty much how the banking world
works today.

I'm not sure who, if anyone, claims Bitcoin is novel or interesting for
any reason other than its decentralization properties, and, in a world
which you are apparently proposing, the "natural" course of things is to
very strongly centralize.

>      * I'd very much like to see someone working on better scaling
>     technology, both in terms of development and in terms of getting
>     traction in the marketplace. 
> 
> 
> Ok. What does this have to do with the max block size?
> 
> Are you arguing that work won't happen if the max block size increases?

Yes, I am arguing that by increasing the blocksize the incentives to
actually make Bitcoin scale go away. Even if amazing technologies get
built, no one will have any reason to use them.

>   * I'd like to see some better conclusions to the discussion around
> 
>     long-term incentives within the system.
> 
> 
> Again, see http://gavinandresen.ninja/when-the-block-reward-goes-away
> for what I think about that.



From 1240902 at gmail.com  Fri May 29 23:42:16 2015
From: 1240902 at gmail.com (Chun Wang)
Date: Sat, 30 May 2015 07:42:16 +0800
Subject: [Bitcoin-development] Block Size Increase Requirements
In-Reply-To: <554BE0E1.5030001@bluematt.me>
References: <554BE0E1.5030001@bluematt.me>
Message-ID: <CAFzgq-xByQ1E_33_m3UpXQFUkGc78HKnA=7XXMshANDuTkNsvA@mail.gmail.com>

Hello. I am from F2Pool. We are currently mining the biggest blocks on
the network. So far top 100 biggest bitcoin blocks are all from us. We
do support bigger blocks and sooner rather than later. But we cannot
handle 20 MB blocks right now. I know most blocks would not be 20 MB
over night. But only if a small fraction of blocks more than 10 MB, it
could dramatically increase of our orphan rate, result of higher fee
to miners. Bad miners could attack us and the network with artificial
big blocks. As yhou know, other Chinese pools, AntPool, BW, they
produces ASIC chips and mining mostly with their own machines. They do
not care about a few percent of orphan increase as much as we do. They
would continue their zero fee policy. We would be the biggest loser.
As the exchanges had taught us, zero fee is not health to the network.
Also we have to redevelop our block broadcast logic. Server bandwidth
is a lot more expensive in China. And the Internet is slow. Currently
China has more than 50% of mining power, if block size increases, I
bet European and American pools could suffer more than us. We think
the max block size should be increased, but must be increased
smoothly, 2 MB first, and then after one or two years 4 MB, then 8 MB,
and so on. Thanks.

On Fri, May 8, 2015 at 6:02 AM, Matt Corallo <bitcoin-list at bluematt.me> wrote:
> OK, so lets do that. I've seen a lot of "I'm not entirely comfortable
> with committing to this right now, but think we should eventually", but
> not much "I'd be comfortable with committing to this when I see X". In
> the interest of ignoring debate and pushing people towards a consensus
> at all costs, ( ;) ) I'm gonna go ahead and suggest we talk about the
> second.
>
> Personally, there are several things that worry me significantly about
> committing to a blocksize increase, which I'd like to see resolved
> before I'd consider supporting a blocksize increase commitment.
>
>  * Though there are many proposals floating around which could
> significantly decrease block propagation latency, none of them are
> implemented today. I'd expect to see these not only implemented but
> being used in production (though I dont particularly care about them
> being all that stable). I'd want to see measurements of how they perform
> both in production and in the face of high packet loss (eg across the
> GFW or in the case of small/moderate DoS). In addition, I'd expect to
> see analysis of how these systems perform in the worst-case, not just
> packet-loss-wise, but in the face of miners attempting to break the system.
>
>  * I'd very much like to see someone working on better scaling
> technology, both in terms of development and in terms of getting
> traction in the marketplace. I know StrawPay is working on development,
> though its not obvious to me how far they are from their website, but I
> dont know of any commitments by large players (either SPV wallets,
> centralized wallet services, payment processors, or any others) to
> support such a system (to be fair, its probably too early for such
> players to commit to anything, since anything doesnt exist in public).
>
>  * I'd like to see some better conclusions to the discussion around
> long-term incentives within the system. If we're just building Bitcoin
> to work in five years, great, but if we want it all to keep working as
> subsidy drops significantly, I'd like a better answer than "we'll deal
> with it when we get there" or "it will happen, all the predictions based
> on people's behavior today say so" (which are hopefully invalid thanks
> to the previous point). Ideally, I'd love to see some real free pressure
> already on the network starting to develop when we commit to hardforking
> in a year. Not just full blocks with some fees because wallets are
> including far greater fees than they really need to, but software which
> properly handles fees across the ecosystem, smart fee increases when
> transactions arent confirming (eg replace-by-fee, which could be limited
> to increase-in-fees-only for those worried about double-spends).
>
> I probably forgot one or two and certainly dont want to back myself into
> a corner on committing to something here, but those are a few things I
> see today as big blockers on larger blocks.
>
> Luckily, people have been making progress on building the software
> needed in all of the above for a while now, but I think they're all
> very, very immature today.
>
> On 05/07/15 19:13, Jeff Garzik wrote:> On Thu, May 7, 2015 at 3:03 PM,
> Matt Corallo <bitcoin-list at bluematt.me
>> <mailto:bitcoin-list at bluematt.me>> wrote:
> -snip-
>>> If, instead, there had been an intro on the list as "I think we should
>>> do the blocksize increase soon, what do people think?", the response
>>> could likely have focused much more around creating a specific list of
>>> things we should do before we (the technical community) think we are
>>> prepared for a blocksize increase.
>>
>> Agreed, but that is water under the bridge at this point.  You - rightly
>> - opened the topic here and now we're discussing it.
>>
>> Mike and Gavin are due the benefit of doubt because making a change to a
>> leaderless automaton powered by leaderless open source software is
>> breaking new ground.  I don't focus so much on how we got to this point,
>> but rather, where we go from here.
>
> ------------------------------------------------------------------------------
> One dashboard for servers and applications across Physical-Virtual-Cloud
> Widest out-of-the-box monitoring support with 50+ applications
> Performance metrics, stats and reports that give you Actionable Insights
> Deep dive visibility with transaction tracing using APM Insight.
> http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development



From adam at cypherspace.org  Sat May 30 00:00:28 2015
From: adam at cypherspace.org (Adam Back)
Date: Sat, 30 May 2015 01:00:28 +0100
Subject: [Bitcoin-development] soft-fork block size increase (extension
 blocks) Re: Proposed alternatives to the 20MB stepfunction
Message-ID: <CALqxMTFoMkAmwpMmB9mbAi8rx4B_iH14t=U4XGtpzhjVYLUR+g@mail.gmail.com>

I discussed the extension block idea on wizards a while back and it is
a way to soft-fork an opt-in block-size increase.  Like everything
here there are pros and cons.

The security is better than Raylstonn inferred from Tier's explanation
I think..  It works as Tier described - there is an extension block
(say 10MB) and the existing 1MB block.  The extension block is
committed to in the 1MB chain.  Users can transfer bitcoin into the
extension block, and they can transfer them out.

The interesting thing is this makes block sizes changes opt-in and
gives users choice.  Choice is good.  Bitcoin has a one-size-fits-all
blocksize at present hence the block size debate.  If a bigger
block-size were an opt-in choice, and some people wanted 10MB or even
100MB blocks for low value transactions I expect it would be far
easier a discussion - people who think 100MB blocks are dangerously
centralising, would not opt to use them (or would put only small
values they can afford to lose in them).  There are some security
implications though, so this also is nuanced, and more on that in a
bit.

Fee pressure still exists for blocks of difference size as the
security assurances are not the same.  It is plausible that some
people would pay more for transactions in the 1MB block.

Now there are three choices of validation level, rather than the
normal 2-levels of SPV or full-node, with extension blocks we get a
choice: A) a user could run a full node for both 1MB and 10MB blocks,
and get full security for both 1MB and 10MB block transactions (but at
higher bandwidth cost), or B) a user could run a full node on the 1MB
block, but operate as an SPV node for the 10MB block, or C) run in SPV
mode for both 1MB and 10MB blocks.

Similarly for mining - miners could validate 1MB and 10MB transactions
(solo mine or GBT-style), or they could self-validate 1MB transactions
and pool mine 10MB transactions (have a pool validate those).

1MB full node users who do not upgrade to software that understands
extension blocks, could run in SPV mode with respect to 10MB blocks.
Here lies the risk - this imposes a security downgrade on the 1MB
non-upgraded users, and also on users who upgrade but dont have the
bandwidth to validate 10MB blocks.


We could defend non-upgrade users by making receiving funds that came
via the extension block opt-in also, eg an optional to use new address
version and construct the extension block so that payments out of it
can only go to new version addresses.

We could harden 1MB block SPV security (when receiving weaker
extension block transactions) in a number of ways: UTXO commitments,
fraud proofs (and fraud bounties) for moving from the extension block
to the 1MB block.  We could optionally require coins moving via the
extension block to the 1MB block to be matured (eg 100 blocks delay)


Anyway something else to evaluate.  Not as simple to code as a
hard-fork, but way safer transition than a hard-fork, and opt-in - if
you prefer the higher decentralisation of 1MB blocks, keep using them;
if you prefer 10MB blocks you can opt-in to them.

Adam

On 29 May 2015 at 17:39, Raystonn . <raystonn at hotmail.com> wrote:
> Regarding Tier?s proposal: The lower security you mention for extended
> blocks would delay, possibly forever, the larger blocks maximum block size
> that we want for the entire network.  That doesn?t sound like an optimal
> solution.
>
> Regarding consensus for larger maximum block size, what we are seeing on
> this list is typical of what we see in the U.S. Congress.  Support for
> changes by the stakeholders (support for bills by the citizens as a whole)
> has become irrelevant to the probability of these changes being adopted.
> Lobbyists have all the sway in getting their policies enacted.  In our case,
> I would bet on some lobbying of core developers by wealthy miners.
>
> Someone recently proposed that secret ballots could help eliminate the power
> of lobbyists in Congress.  Nobody invests in that which cannot be confirmed.
> Secret ballots mean the vote you are buying cannot be confirmed.  Perhaps
> this will work for Bitcoin Core as well.
>
>
> From: Tier Nolan
> Sent: Friday, May 29, 2015 7:22 AM
> Cc: Bitcoin Dev
> Subject: Re: [Bitcoin-development] Proposed alternatives to the 20MB
> stepfunction
>
> On Fri, May 29, 2015 at 3:09 PM, Tier Nolan <tier.nolan at gmail.com> wrote:
>>
>>
>>
>> On Fri, May 29, 2015 at 1:39 PM, Gavin Andresen <gavinandresen at gmail.com>
>> wrote:
>>>
>>> But if there is still no consensus among developers but the "bigger
>>> blocks now" movement is successful, I'll ask for help getting big miners to
>>> do the same, and use the soft-fork block version voting mechanism to
>>> (hopefully) get a majority and then a super-majority willing to produce
>>> bigger blocks. The purpose of that process is to prove to any doubters that
>>> they'd better start supporting bigger blocks or they'll be left behind, and
>>> to give them a chance to upgrade before that happens.
>>
>>
>> How do you define that the movement is successful?
>
>
> Sorry again, I keep auto-sending from gmail when trying to delete.
>
> In theory, using the "nuclear option", the block size can be increased via
> soft fork.
>
> Version 4 blocks would contain the hash of the a valid extended block in the
> coinbase.
>
> <block height> <32 byte extended hash>
>
> To send coins to the auxiliary block, you send them to some template.
>
> OP_P2SH_EXTENDED <scriptPubKey hash> OP_TRUE
>
> This transaction can be spent by anyone (under the current rules).  The soft
> fork would lock the transaction output unless it transferred money from the
> extended block.
>
> To unlock the transaction output, you need to include the txid of
> transaction(s) in the extended block and signature(s) in the scriptSig.
>
> The transaction output can be spent in the extended block using P2SH against
> the scriptPubKey hash.
>
> This means that people can choose to move their money to the extended block.
> It might have lower security than leaving it in the root chain.
>
> The extended chain could use the updated script language too.
>
> This is obviously more complex than just increasing the size though, but it
> could be a fallback option if no consensus is reached.  It has the advantage
> of giving people a choice.  They can move their money to the extended chain
> or not, as they wish.



From gavinandresen at gmail.com  Sat May 30 00:16:01 2015
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Fri, 29 May 2015 20:16:01 -0400
Subject: [Bitcoin-development] soft-fork block size increase (extension
 blocks) Re: Proposed alternatives to the 20MB stepfunction
In-Reply-To: <CALqxMTFoMkAmwpMmB9mbAi8rx4B_iH14t=U4XGtpzhjVYLUR+g@mail.gmail.com>
References: <CALqxMTFoMkAmwpMmB9mbAi8rx4B_iH14t=U4XGtpzhjVYLUR+g@mail.gmail.com>
Message-ID: <CABsx9T309r6rT+sVtOb0Qmi=PLr+CUGApmLjuXs-_NcMS4K=gg@mail.gmail.com>

RE: soft-forking an "extension block":

So... go for it, code it up. Implement it in the Bitcoin Core wallet.

Then ask the various wallet developer how long it would take them to update
their software to support something like this, and do some UI mockups of
what the experience would look like for users.

If there are two engineering solutions to a problem, one really simple, and
one complex, why would you pick the complex one?

Especially if the complex solution has all of the problems of the simple
one (20MB extension blocks are just as "dangerous" as 20MB main blocks,
yes? If not, why not?)


-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150529/9b9298b2/attachment.html>

From da2ce7 at gmail.com  Sat May 30 01:36:39 2015
From: da2ce7 at gmail.com (Cameron Garnham)
Date: Sat, 30 May 2015 09:36:39 +0800
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
 function
In-Reply-To: <CANeMN=8Q3CF6kfA+4X8Rf0HHWwjEJ5kb4ePgHccWgGJ2CPz3eA@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>	<CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>	<CANEZrP3VCaFsW4+gPm2kCJ9z7oVUZYVaeNf=_cJWEWwh4ZxiPQ@mail.gmail.com>	<CABsx9T21zjHyO-nh1aSBM3z4Bg015O0rOfYq7=Sy4mf=QxUVQA@mail.gmail.com>	<CANEZrP2BaKwhpPgcUHWAHswOmUeFLgEk4ysrn4+73qNzWDJ=yQ@mail.gmail.com>	<CABsx9T3nCJ-w_v-yEbEE2Ytb+xC65mhYqhoAhoOHw9tkPpG0TA@mail.gmail.com>	<CANEZrP1qH+zucYsGrMgnfi99e61Edxaj+xm=u_xYXga1g0WzJQ@mail.gmail.com>	<CAE-z3OVmw+0doCe0hmYE6A1D61h0AUh4Mtnf5Fg1e4zQBkpraQ@mail.gmail.com>	<CANEZrP0psA7hcJdKdA-r01UEt7ig3O-9vjwBMqKSEq-csu0hPQ@mail.gmail.com>	<CABsx9T23r_y2R9OEgqb3AAZf47Hh8BUJncjxxmPp5v_9uKEiqQ@mail.gmail.com>
	<CANeMN=8Q3CF6kfA+4X8Rf0HHWwjEJ5kb4ePgHccWgGJ2CPz3eA@mail.gmail.com>
Message-ID: <55691427.6000600@gmail.com>

First off, I am glad that the idea of dynamic block size adjustment is
gaining some attention, in particular the model that I proposed.

I wanted to take some time and explain some of the philosophy of how,
and why, I proposed this this particular model.

When Bitcoin was first made, there was a 32MB block size limit; this
was quickly found to be open to spam (and potentially DOS, as the code
was not-at-all optimized to support large blocks), and was reduced to
1MB, this was a quick fix that was never intended to last; at some
point the network should come to an understanding, a consensus if you
will, of what (and how much) belongs in a block.
The core point of this is that miners have always, and will always;
hold the power, to decide what goes into blocks; this implicitly,
obviously, includes how large blocks are. Miners are able to come any
sort of agreement they wish, providing the bitcoin clients accept
their blocks as valid.

Say if Satoshi never decided to place the 1MB block limit: It would be
up to the miners to decide what they consider a ?reasonable? block is.
However, they would need to find some way to communicate this and
reach an agreement; some protocol.  They, say, could have done this
informally on what is now the bitcointalk forum, or used Twitter.
However, what they really need is indeed a "consensus protocol". Some
simple terms to define what is acceptable and what is not.

Hence, the proposal introducing a consensus protocol for block sizes;
instead of just having a hard limit (enforced by everyone), instead,
we have a constant factor above the average block size over a fixed
intervals that is soft-forked by only the miners. (The next simplest
mathematical construct).
This proposal is entirely a soft-fork and may be implemented without
changing any client code what so ever. In-fact, it could be
implemented by only a simple 51% majority of miners, with-or-without
gaining the wider community consensus. (Assuming that the 1MB block
size rule still applies).
The nice thing about this is that it really is impossible to stop,
for-example, if pre-relaying of block headers is implemented; the
miners could always soft-fork to include the block-size in the
coinbase. The only reason that the miners have not done this yet, is
that there has not yet been a strong will to increase transaction fees.

If we assume the miners will operate in a way to collectively maximize
profit; then we can assume they will not try to maximize utility of
the network (having as many transactions as possible), rather have as
few transactions as the total economy can support the cost.  Meaning
that limiting to much smaller blocks will probably be much more
profitable than having large blocks.

Since there is no requirement for the clients to know about the block
size consensus protocol, this truly can be a
?bi-directional-soft-fork?, in that the miners can choose to change
the rules at any time, with only a simple 51% majority. Therefore, any
parameters that we pick are always up for debate.

Why the 1.5x over 2016 blocks? -  Using some game theory, and
deduction: I wished to pick the type of agreement that would be
natural for the miners to come to (selfishly).

First, Why 1.5x, this means that only a super-majority of miners can
easily increase the block size. ? There is no natural incentive for
miners to produce large blocks that have very few fees.

Second, Why 2016 blocks for adjusting the average:  Miners HATE
unpredictability, for shorter time periods the miner will need to have
infrastructure ready to support potentially much larger block almost
immediately. 2016 blocks is a period that the miners are already well
used to, meaning that it will take slightly less than a month for
blocks of double size to be permitted.

This entire infrastructure can be implemented without needing to
update any clients; once implemented, tested, solid, and well accepted
by the (mining) community then we can revisit increasing the 1M hard
limit. (If we still have demand for it, maybe the average block size
will reduce to say, 100KB).


Cam.






> -----BEGIN PGP SIGNED MESSAGE----- Hash: SHA256
> 
> While being in the Bitcoin community for a long time, I haven't
> been so directly involved in the development.  However I wish to
> suggest a different pre-hard-fork soft-fork approach:
> 
> 
> Set a 'block size cap' in the similar same way as we set
> difficulty.
> 
> Every 2016 blocks take the average size of the blocks and multiply
> the size by 1.5x, rejecting blocks that are larger than this size,
> for the next 2016 period.
> 
> I would of-course suggest that we keep the limits at min 100kb and
> max (initially) 990kb (not 1mb on purpose, as this should become
> the new limit), rounding up to the nearest 10kb.
> 
> A: we don't have pressure at the 1mb limit, (we reduce the limit in
> a flexible manner to 990kb).
> 
> B: we can upgrade the network to XYZ hard-limit, then slowly raze
> the soft-limit after being sure the network, as-a-whole is ready.
> 
> If we on-day remove the block-size limit, this rule will stop a
> rouge miner from making 10mb, or 100mb blocks, or 1gb blocks.
> 
> This could be implemented by the miners without breaking any of
> the clients, and would tend to produce a better dynamic fee
> pressure.
> 
> 
> This will give the mechanics to the miners to create consensus to 
> agree what block-sizes they believe are best for the network, and 
> allows the block-sizes to dynamically grow in response to larger
> demand.
> 
> 
> 
> On 5/8/2015 10:35 AM, Pieter Wuille wrote:
>> On May 7, 2015 3:08 PM, "Roy Badami" <roy at gnomon.org.uk> wrote:
>>> 
>>> On Thu, May 07, 2015 at 11:49:28PM +0200, Pieter Wuille wrote:
>>>> I would not modify my node if the change introduced a
>>>> perpetual 100 BTC subsidy per block, even if 99% of miners
>>>> went along with it.
>>> 
>>> Surely, in that scenario Bitcoin is dead.  If the fork you
>>> prefer has only 1% of the hash power it is trivially vulnerably
>>> not just to a 51% attack but to a 501% attack, not to mention
>>> the fact that you'd only be getting one block every 16 hours.
>> 
>> Yes, indeed, Bitcoin would be dead if this actually happens. But 
>> that is still where the power lies: before anyone (miners or 
>> others) would think about trying such a change, they would need
>> to convince people and be sure they will effectively modify
>> their code.
>> 
>> 
>> 
>> ----------------------------------------------------------------------
>
>> 
- --------
>> 
>> 
> One dashboard for servers and applications across
> Physical-Virtual-Cloud
>> Widest out-of-the-box monitoring support with 50+ applications 
>> Performance metrics, stats and reports that give you Actionable 
>> Insights Deep dive visibility with transaction tracing using APM 
>> Insight. http://ad.doubleclick.net/ddm/clk/290420510;117567292;y
>> 
>> 
>> 
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net 
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>> 
> -----BEGIN PGP SIGNATURE----- Version: GnuPG v2
> 
> iF4EAREIAAYFAlVMKZYACgkQBJ8cMDO159aTiQEApTITEBrhE1DRbj/w+GncNeqB 
> 0hGvmIBa1z0hGww0kaMBAOhxjn/K5leRJgdt1fKhNEDKKHdeCOIX3QRgry90D3NO 
> =p0+H -----END PGP SIGNATURE-----


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 213 bytes
Desc: OpenPGP digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150530/f41e56f7/attachment.sig>

From raystonn at hotmail.com  Sat May 30 01:36:50 2015
From: raystonn at hotmail.com (Raystonn)
Date: Fri, 29 May 2015 18:36:50 -0700
Subject: [Bitcoin-development] soft-fork block size increase (extension
 blocks) Re: Proposed alternatives to the 20MB stepfunction
Message-ID: <COL402-EAS985F0C95920085B4CDDD93CDC80@phx.gbl>

An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150529/19cf34ff/attachment.html>

From onelineproof at gmail.com  Sat May 30 03:27:36 2015
From: onelineproof at gmail.com (Andrew)
Date: Sat, 30 May 2015 03:27:36 +0000
Subject: [Bitcoin-development] soft-fork block size increase (extension
 blocks) Re: Proposed alternatives to the 20MB stepfunction
In-Reply-To: <COL402-EAS985F0C95920085B4CDDD93CDC80@phx.gbl>
References: <COL402-EAS985F0C95920085B4CDDD93CDC80@phx.gbl>
Message-ID: <CAL8tG=nfs+UQJt7zWMc=p1Rf8vDcwFRctpEOR-Z358vKnpphAA@mail.gmail.com>

Hello Adam

First of all, thank you for inventing hashcash, which is basically what
bitcoin is!

Some people have said that my proposal, subject line "Scaling Bitcoin with
Subchains" is essentially the idea of blockchain extensions. Though, I
think there is quite a difference between what I propose and what you
propose. You want to add one optional 10 MB blockchain that synchronizes
with the 1 MB blockchain, while I want to add ten 1 MB
 blockchains that each synchronize with the 1 MB chain (and you can
continue like that). I think, as long as we want to keep using blockchains
for our cryptocurrency, we will need a tree structure of blockchains in
order to scale for an arbitrary number of transactions. With just one 10 MB
blockchain, someone who wants to do the lower valued transactions will need
to validate all 10 MB, while with ten 1 MB chains, they can choose just the
chain or chains that are of interest to them. With a tree structure you get
O(a^(n-1)) MB of transactions in the network while each participant only
has to validate O(n) MB of transactions (a is just the number of children
chains per parent divided by 2, so 5 in the case of 10 children as I
described). With just one child chain, you don't get this scaling, and it
is pretty much equivalent to increasing the blocksize, though with a
soft-fork instead of a hard-fork.

I think the actual way that the blockchains interact can be still worked
out (Recently I was thinking of maybe creating a contract system or even a
decentralized market between chains). But still, everyone should agree that
you need this kind of tree structure. Even if you want to only run a pruned
node, the CPU usage and memory scales just as bad. The tree structure also
has good privacy and miner decentralization properties, as I can write
about later.

But another thing that I recommend is an "exit plan". What if we go with
some kind of soft fork and then in the future some better idea comes along?
Then we should have a way to reverse the soft fork. If people already have
coins tied up in sidechains, it can be problematic. So perhaps, in case
people want to later ditch the soft fork, nodes in the parent chain can
allow only old transactions inside the child chains to be accepted back up,
while new transactions are not recognized anymore. That way you can limit
the amount of useless transaction traffic that results in case we want
something else.

On Sat, May 30, 2015 at 1:36 AM, Raystonn <raystonn at hotmail.com> wrote:

> My fear now is too much unnecessary complexity.  More complex means
> brittle code, but also fewer programmers working on this, which is a risk.
>
> We shouldn't delay forever until every potential solution has been
> explored.  There's always going to be one more thing to explore.
>  On 29 May 2015 5:16 pm, Gavin Andresen <gavinandresen at gmail.com> wrote:
>
> RE: soft-forking an "extension block":
>
> So... go for it, code it up. Implement it in the Bitcoin Core wallet.
>
> Then ask the various wallet developer how long it would take them to
> update their software to support something like this, and do some UI
> mockups of what the experience would look like for users.
>
> If there are two engineering solutions to a problem, one really simple,
> and one complex, why would you pick the complex one?
>
> Especially if the complex solution has all of the problems of the simple
> one (20MB extension blocks are just as "dangerous" as 20MB main blocks,
> yes? If not, why not?)
>
>
> --
> --
> Gavin Andresen
>
>
>
> ------------------------------------------------------------------------------
>
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>


-- 
PGP: B6AC 822C 451D 6304 6A28  49E9 7DB7 011C D53B 5647
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150530/8252af9b/attachment.html>

From voisine at gmail.com  Sat May 30 09:03:36 2015
From: voisine at gmail.com (Aaron Voisine)
Date: Sat, 30 May 2015 02:03:36 -0700
Subject: [Bitcoin-development] Proposed alternatives to the 20MB step
	function
In-Reply-To: <CA+VAk3O7SmDkxL9rATWe9oqCVVKcT=cFXDJnARPN8pv=UiHaiA@mail.gmail.com>
References: <16096345.A1MpJQQkRW@crushinator>
	<CABsx9T3-zxCAagAS0megd06xvG5n-3tUL9NUK9TT3vt7XNL9Tg@mail.gmail.com>
	<CANEZrP3VCaFsW4+gPm2kCJ9z7oVUZYVaeNf=_cJWEWwh4ZxiPQ@mail.gmail.com>
	<CABsx9T21zjHyO-nh1aSBM3z4Bg015O0rOfYq7=Sy4mf=QxUVQA@mail.gmail.com>
	<CANEZrP2BaKwhpPgcUHWAHswOmUeFLgEk4ysrn4+73qNzWDJ=yQ@mail.gmail.com>
	<CABsx9T3nCJ-w_v-yEbEE2Ytb+xC65mhYqhoAhoOHw9tkPpG0TA@mail.gmail.com>
	<CANEZrP1qH+zucYsGrMgnfi99e61Edxaj+xm=u_xYXga1g0WzJQ@mail.gmail.com>
	<CAE-z3OVmw+0doCe0hmYE6A1D61h0AUh4Mtnf5Fg1e4zQBkpraQ@mail.gmail.com>
	<CANEZrP0psA7hcJdKdA-r01UEt7ig3O-9vjwBMqKSEq-csu0hPQ@mail.gmail.com>
	<CABsx9T23r_y2R9OEgqb3AAZf47Hh8BUJncjxxmPp5v_9uKEiqQ@mail.gmail.com>
	<CA+VAk3O7SmDkxL9rATWe9oqCVVKcT=cFXDJnARPN8pv=UiHaiA@mail.gmail.com>
Message-ID: <CACq0ZD7-qr4BCdnqOSXLYv-i58vAXWGcQ1oLsrbHoNFMeiNTtg@mail.gmail.com>

> or achieving less than great DOS protection

Right now a bunch of redditors can DOS the network at the cost of a few
thousand dollars per day, shared between them. Since the cost of validating
transactions is far lower than current minimum relay fees, then increasing
the block size increases the cost of DOSing the network.


Aaron Voisine
co-founder and CEO
breadwallet.com

On Fri, May 29, 2015 at 10:53 AM, Admin Istrator <andy at ftlio.com> wrote:

> What about trying the dynamic scaling method within the 20MB range + 1
> year with a 40% increase of that cap?  Until a way to dynamically scale is
> found, the cap will only continue to be an issue.  With 20 MB + 40% yoy,
> we're either imposing an arbitrary cap later, or achieving less than great
> DOS protection always.  Why not set that policy as a maximum for 2 years as
> a protection against the possibility of dynamic scaling abuse, and see what
> happens with a dynamic method in the mean time.  The policy of Max(1MB,
> (average size over previous 144 blocks) * 2) calculated at each block seems
> pretty reasonable.
>
> As an outsider, the real 'median' here seems to be 'keeping the cap as
> small as possible while allowing for larger blocks still'.    We know
> miners will want to keep space in their blocks relatively scarce, but we
> also know that doesn't exclude the more powerful miners from
> including superfluous transactions to increase their effective share of the
> network.  I have the luck of not being drained by this topic over the past
> three years, so it looks to me as if its two poles of 'block size must
> increase' and 'block size must not increase' are forcing what is the clear
> route to establishing the 'right' block size off the table.
>
> --Andrew Len
> (sorry if anybody received this twice, sent as the wrong email the first
> time around).
>
> On Fri, May 29, 2015 at 5:39 AM, Gavin Andresen <gavinandresen at gmail.com>
> wrote:
>
>> What do other people think?
>>
>>
>> If we can't come to an agreement soon, then I'll ask for help
>> reviewing/submitting patches to Mike's Bitcoin-Xt project that implement a
>> big increase now that grows over time so we may never have to go through
>> all this rancor and debate again.
>>
>> I'll then ask for help lobbying the merchant services and exchanges and
>> hosted wallet companies and other bitcoind-using-infrastructure companies
>> (and anybody who agrees with me that we need bigger blocks sooner rather
>> than later) to run Bitcoin-Xt instead of Bitcoin Core, and state that they
>> are running it. We'll be able to see uptake on the network by monitoring
>> client versions.
>>
>> Perhaps by the time that happens there will be consensus bigger blocks
>> are needed sooner rather than later; if so, great! The early deployment
>> will just serve as early testing, and all of the software already deployed
>> will ready for bigger blocks.
>>
>> But if there is still no consensus among developers but the "bigger
>> blocks now" movement is successful, I'll ask for help getting big miners to
>> do the same, and use the soft-fork block version voting mechanism to
>> (hopefully) get a majority and then a super-majority willing to produce
>> bigger blocks. The purpose of that process is to prove to any doubters that
>> they'd better start supporting bigger blocks or they'll be left behind, and
>> to give them a chance to upgrade before that happens.
>>
>>
>> Because if we can't come to consensus here, the ultimate authority for
>> determining consensus is what code the majority of merchants and exchanges
>> and miners are running.
>>
>>
>> --
>> --
>> Gavin Andresen
>>
>>
>> ------------------------------------------------------------------------------
>>
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>>
>
>
> ------------------------------------------------------------------------------
>
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150530/bf19ef13/attachment.html>

From gavinandresen at gmail.com  Sat May 30 13:57:32 2015
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Sat, 30 May 2015 09:57:32 -0400
Subject: [Bitcoin-development] Block Size Increase Requirements
In-Reply-To: <CAFzgq-xByQ1E_33_m3UpXQFUkGc78HKnA=7XXMshANDuTkNsvA@mail.gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CAFzgq-xByQ1E_33_m3UpXQFUkGc78HKnA=7XXMshANDuTkNsvA@mail.gmail.com>
Message-ID: <CABsx9T0kbRe31LMwk499MQUw225f5GGd67GfhXBezHmDqxkioA@mail.gmail.com>

On Fri, May 29, 2015 at 7:42 PM, Chun Wang <1240902 at gmail.com> wrote:

> Hello. I am from F2Pool. We are currently mining the biggest blocks on
> the network.


Thanks for giving your opinion!



> Bad miners could attack us and the network with artificial
> big blocks.


How?

I ran some simulations, and I could not find a network topology where a big
miner producing big blocks could cause a loss of profit to another miner
(big or small) producing smaller blocks:

http://gavinandresen.ninja/are-bigger-blocks-better-for-bigger-miners

(the 0.3% advantage I DID find was for the situation where EVERYBODY was
producing big blocks).


> We think
> the max block size should be increased, but must be increased
> smoothly, 2 MB first, and then after one or two years 4 MB, then 8 MB,
> and so on. Thanks.


Why 2 MB ?   You said that server bandwidth is much more expensive in
China; what would be the difference in your bandwidth costs between 2MB
blocks and 20MB blocks?


-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150530/643c32da/attachment.html>

From pindar.wong at gmail.com  Sat May 30 14:08:13 2015
From: pindar.wong at gmail.com (Pindar Wong)
Date: Sat, 30 May 2015 22:08:13 +0800
Subject: [Bitcoin-development] Block Size Increase Requirements
In-Reply-To: <CABsx9T0kbRe31LMwk499MQUw225f5GGd67GfhXBezHmDqxkioA@mail.gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CAFzgq-xByQ1E_33_m3UpXQFUkGc78HKnA=7XXMshANDuTkNsvA@mail.gmail.com>
	<CABsx9T0kbRe31LMwk499MQUw225f5GGd67GfhXBezHmDqxkioA@mail.gmail.com>
Message-ID: <CAM7BtUosinSotczf=EkZs3o0S2QV3sQKfYJzjyLnj8pRz_2-Rg@mail.gmail.com>

On Sat, May 30, 2015 at 9:57 PM, Gavin Andresen <gavinandresen at gmail.com>
wrote:

> On Fri, May 29, 2015 at 7:42 PM, Chun Wang <1240902 at gmail.com> wrote:
>
>> Hello. I am from F2Pool. We are currently mining the biggest blocks on
>> the network.
>
>
> Thanks for giving your opinion!
>
>
>
>> Bad miners could attack us and the network with artificial
>> big blocks.
>
>
> How?
>
> I ran some simulations, and I could not find a network topology where a
> big miner producing big blocks could cause a loss of profit to another
> miner (big or small) producing smaller blocks:
>
> http://gavinandresen.ninja/are-bigger-blocks-better-for-bigger-miners
>
> (the 0.3% advantage I DID find was for the situation where EVERYBODY was
> producing big blocks).
>
>
>> We think
>> the max block size should be increased, but must be increased
>> smoothly, 2 MB first, and then after one or two years 4 MB, then 8 MB,
>> and so on. Thanks.
>
>
> Why 2 MB ?   You said that server bandwidth is much more expensive in
> China; what would be the difference in your bandwidth costs between 2MB
> blocks and 20MB blocks?
>

Perhaps we should arrange to run some more 'simulations' with miners from
China and elsewhere?

Let me know there's interest to do.

p.

>
>
> --
> --
> Gavin Andresen
>
>
> ------------------------------------------------------------------------------
>
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150530/527c779b/attachment.html>

From bitcoin-list at bluematt.me  Sat May 30 19:32:22 2015
From: bitcoin-list at bluematt.me (Matt Corallo)
Date: Sat, 30 May 2015 19:32:22 +0000
Subject: [Bitcoin-development] Block Size Increase Requirements
In-Reply-To: <CABsx9T3__mHZ_kseRg-w-x2=8v78QJLhe+BWPezv+hpbFCufpw@mail.gmail.com>
References: <554BE0E1.5030001@bluematt.me>	<CABsx9T2ysKj5HVbN_7_o33fMehs4KH6E_R583Mt_VPC4gDA0LQ@mail.gmail.com>	<5568F567.3050608@bluematt.me>
	<CABsx9T3__mHZ_kseRg-w-x2=8v78QJLhe+BWPezv+hpbFCufpw@mail.gmail.com>
Message-ID: <556A1046.50807@bluematt.me>



On 05/29/15 23:48, Gavin Andresen wrote:
> On Fri, May 29, 2015 at 7:25 PM, Matt Corallo <bitcoin-list at bluematt.me
> <mailto:bitcoin-list at bluematt.me>> wrote:
> 
>     Sadly, this is very far from the whole story. The issue of miners
>     optimizing for returns has been discussed several times during this
>     discussion, and, sadly, miners who are geographically colocated who are
>     optimizing for returns with a free-floating blocksize will optimize away
>     50% of the network!
> 
> 
> I must have missed that analysis-- link please?  Or summary of HOW they
> will optimize away 50% of the network?
> 
> Or are you assuming that 50% of the network is colocated... (which is a
> potential problem independent of blocksize)

If, for example, the majority of miners are in China (they are), and
there is really poor connectivity in and out of China (there is) and a
miner naively optimizes for profit, they will create blocks which are
large and take a while to relay out of China. By simple trial-and-error
an individual large miner might notice that when they create larger
blocks which fork off miners in other parts of the world, they get more
income. Obviously forking off 50% of the network would be a rather
extreme situation and assumes all kinds of simplified models, but it
shows that the incentives here are very far from aligned, and your
simplified good-behavior models are very far from convincing.

> 
>     >
>     >     In addition, I'd expect to
>     >     see analysis of how these systems perform in the worst-case, not just
>     >     packet-loss-wise, but in the face of miners attempting to break the
>     >     system.
>     >
>     >
>     > See http://gavinandresen.ninja/are-bigger-blocks-better-for-bigger-miners for
>     > analysis of "but that means bigger miners can get an advantage" argument.
>     >
>     > Executive summary: if little miners are stupid and produce huge blocks,
>     > then yes, big miners have an advantage.
> 
>     I'll talk about transaction fees in a second, but there are several
>     problems with this already. As pointed out in the original mail, gfw has
>     already been known to interfere with Bitcoin P2P traffic. So now by
>     "little" miners, you mean any miner who is not located in mainland
>     China? Whats worse, the disadvantage is symmetric - little miners are at
>     a disadvantage when *anyone* mines a bigger block, and miners dont even
>     have to be "evil" for this to happen - just optimize for profits.
> 
> 
> But the disadvantage is tiny. And essentially zero if they connect to
> your fast relay network (or anything like it).
> 

The disadvantage is small with 1MB blocks, but already non-zero. 20MB
blocks are much, much worse (lots of things here dont scale linearly,
even just transfer over a high-packet-loss-link). I mentioned this in my
original email as something which doesnt make me comfortable with 20MB
blocks, but something which needs simulation and study, and might
actually be just fine!

> 
>     > But they're not, so they won't.
> 
>     I dont know what you're referring to with this. Are you claiming little
>     miners today optimize for relay times and have good visibility into the
>     Bitcoin network and calculate an optimal block size based on this (or
>     would with a 20MB block size)?
> 
> 
> Do you have another explanation for why miners choose to leave
> fee-paying transactions in their mempool and create small blocks?

Defaults? Dumb designs? Most miners just use the default 750K blocks, as
far as I can tell, other miners probably didnt see transactions relayed
across several hops or so, and a select few miners are doing crazy
things like making their blocks fit in a single packet to cross the gfw,
but that is probably overkill and not well-researched.

>     > Until the block reward goes away, and assuming transaction fees become
>     > an important source of revenue for miners.
>     > I think it is too early to worry about that; see:
>     >
>     >    http://gavinandresen.ninja/when-the-block-reward-goes-away
> 
>     You dont make any points here with which I can argue, but let me respond
>     with the reason /I/ think it is a problem worth thinking a little bit
>     about...If we increase the blocksize sufficiently such that transaction
>     fees are not the way in which miners make their money
> 
> 
> I'm not suggesting that we increase the blocksize sufficiently such that
> transaction fees are not the way in which miners make their money.
> 
> I'm suggesting the blocksize be increased to 20MB (and then doubled
> every couple of years).

Do you have convincing evidence that at 20MB miners will be able to
break even on transaction fees for a long time? (The answer is no
because no one has any idea how bitcoin transaction volumes are going to
scale, period.)

> And "in which miners make their money" is the wrong metric-- we want
> enough mining so the network to be "secure enough" against double-spends.

Sure, do you have a value of hashpower which is "secure enough" (which
is a whole other rabbit hole to go down...).

> 
>     , then either
>     miners are not being funded (ie hashpower has to drop to very little),
>     or the only people mining/funding miners are large orgs who are
>     "running" Bitcoin (ie the web wallets, payment processors, big
>     merchants, and exchanges of the world). Sadly, this is no longer a
>     decentralized Bitcoin and is, in fact, pretty much how the banking world
>     works today.
> 
> 
> Even if we end up in a world where only big companies can run full nodes
> (and I am NOT NOT NOT NOT NOT proposing any such thing), there is a
> difference-- you don't need permission to "open up a bank" on the
> Bitcoin network.
> 

Oh? You mention at http://gavinandresen.ninja/bigger-blocks-another-way
that "I struggle with wanting to stay true to Satoshi?s original vision
of Bitcoin as a system that scales up to Visa-level transaction volume".
That is in direct contradiction.

>     I'm not sure who, if anyone, claims Bitcoin is novel or interesting for
>     any reason other than its decentralization properties, and, in a world
>     which you are apparently proposing, the "natural" course of things is to
>     very strongly centralize.
> 
> 
>     >      * I'd very much like to see someone working on better scaling
>     >     technology, both in terms of development and in terms of getting
>     >     traction in the marketplace.
>     >
>     >
>     > Ok. What does this have to do with the max block size?
>     >
>     > Are you arguing that work won't happen if the max block size increases?
> 
>     Yes, I am arguing that by increasing the blocksize the incentives to
>     actually make Bitcoin scale go away. Even if amazing technologies get
>     built, no one will have any reason to use them.
> 
> 
> Ok, I wrote about that here:
> 
> http://gavinandresen.ninja/it-must-be-done-but-is-not-a-panacea
> 

"it is not a panacea", but everyone in the community seems to be taking
it as one. You've claimed many times that many of the big
webwallet/payment processors/etc have been coming to you and saying they
need bigger block sizes to continue operating. In reality, they dont, it
just makes it easier.

Matt



From gavinandresen at gmail.com  Sat May 30 20:37:15 2015
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Sat, 30 May 2015 16:37:15 -0400
Subject: [Bitcoin-development] Block Size Increase Requirements
In-Reply-To: <556A1046.50807@bluematt.me>
References: <554BE0E1.5030001@bluematt.me>
	<CABsx9T2ysKj5HVbN_7_o33fMehs4KH6E_R583Mt_VPC4gDA0LQ@mail.gmail.com>
	<5568F567.3050608@bluematt.me>
	<CABsx9T3__mHZ_kseRg-w-x2=8v78QJLhe+BWPezv+hpbFCufpw@mail.gmail.com>
	<556A1046.50807@bluematt.me>
Message-ID: <CABsx9T3qPiQ+PL3ZNT+QJzw4ALEzKjMjC4=uEKTG+4vVPdXr-g@mail.gmail.com>

On Sat, May 30, 2015 at 3:32 PM, Matt Corallo <bitcoin-list at bluematt.me>
wrote:

> If, for example, the majority of miners are in China (they are), and
> there is really poor connectivity in and out of China (there is) and a
> miner naively optimizes for profit, they will create blocks which are
> large and take a while to relay out of China. By simple trial-and-error
> an individual large miner might notice that when they create larger
> blocks which fork off miners in other parts of the world, they get more
> income. Obviously forking off 50% of the network would be a rather
> extreme situation and assumes all kinds of simplified models, but it
> shows that the incentives here are very far from aligned, and your
> simplified good-behavior models are very far from convincing.
>

"good behavior" models? I intentionally modeled what should be a worst-case.

If you have a specific network topology you want to model, please email me
details and I'll see what worst case is. Or, even better, take my
simulation code and run it yourself (it's C++, easy to compile, easy to
modify if you think it is too simple).

I get frustrated with all of the armchair "but what if..."
how-many-miners-can-dance-on-the-head-of-a-pin arguments.



> >     I'll talk about transaction fees in a second, but there are several
> >     problems with this already. As pointed out in the original mail, gfw
> has
> >     already been known to interfere with Bitcoin P2P traffic. So now by
> >     "little" miners, you mean any miner who is not located in mainland
> >     China? Whats worse, the disadvantage is symmetric - little miners
> are at
> >     a disadvantage when *anyone* mines a bigger block


No, they're not. They are only at a disadvantage when THEY mine bigger
blocks.

I guess I wasn't clear in the "do bigger miners have an advantage" blog
post.


> ... I mentioned this in my
> original email as something which doesnt make me comfortable with 20MB
> blocks, but something which needs simulation and study, and might
> actually be just fine!
>

I spent last week doing simulation and study. Please, do your own
simulation and study if you don't trust my results. There are big
full-scale-bitcoin-network-simulations spinning up that should have results
in a month or two, also, but there will ALWAYS be "but we didn't think
about what if THIS happens" scenarios that can require more simulation and
study.


>
> > Do you have another explanation for why miners choose to leave
> > fee-paying transactions in their mempool and create small blocks?
>
> Defaults? Dumb designs? Most miners just use the default 750K blocks, as
> far as I can tell, other miners probably didnt see transactions relayed
> across several hops or so, and a select few miners are doing crazy
> things like making their blocks fit in a single packet to cross the gfw,
> but that is probably overkill and not well-researched.
>

Last night's transaction volume test shows that most miners do just go
along with defaults:
  http://bitcoincore.org/~gavin/sizes_358594.html

> I'm not suggesting that we increase the blocksize sufficiently such that
> > transaction fees are not the way in which miners make their money.
> >
> > I'm suggesting the blocksize be increased to 20MB (and then doubled
> > every couple of years).
>
> Do you have convincing evidence that at 20MB miners will be able to
> break even on transaction fees for a long time? (The answer is no
> because no one has any idea how bitcoin transaction volumes are going to
> scale, period.)
>


Mining is a competitive business, the marginal miner will ALWAYS be going
out of business.

That is completely independent of the block size, block subsidy, or
transaction fees.

The question is "will there be enough fee+subsidy revenue to make it
unprofitable for an attacker to buy or rent enough hashpower to
double-spend."

It is obvious to me that bigger blocks make it more likely the answer to
that question is "yes."



>
> > And "in which miners make their money" is the wrong metric-- we want
> > enough mining so the network to be "secure enough" against double-spends.
>
> Sure, do you have a value of hashpower which is "secure enough" (which
> is a whole other rabbit hole to go down...).
>

Mike Hearn wrote about that just a couple days ago:
  https://medium.com/@octskyward/hashing-7d04a887acc8
(See "How much is too much" section)


> > Even if we end up in a world where only big companies can run full nodes
> > (and I am NOT NOT NOT NOT NOT proposing any such thing), there is a
> > difference-- you don't need permission to "open up a bank" on the
> > Bitcoin network.
> >
>
> Oh? You mention at http://gavinandresen.ninja/bigger-blocks-another-way
> that "I struggle with wanting to stay true to Satoshi?s original vision
> of Bitcoin as a system that scales up to Visa-level transaction volume".
> That is in direct contradiction.
>

I have said repeatedly that if it was left completely up to me I would go
back to Satoshi's original "there is no consensus-level blocksize limit".

20MB is a compromise.

 > Ok, I wrote about that here:

> >
> > http://gavinandresen.ninja/it-must-be-done-but-is-not-a-panacea
> >
>
> "it is not a panacea", but everyone in the community seems to be taking
> it as one. You've claimed many times that many of the big
> webwallet/payment processors/etc have been coming to you and saying they
> need bigger block sizes to continue operating. In reality, they dont, it
> just makes it easier
>
>
... and now you're pissing me off. I have NEVER EVER said that they need
bigger blocks to continue operating. Please stop being overly dramatic.

They believe that bigger blocks are better for Bitcoin.

Brian Armstrong at Coinbase, in particular, said that smaller blocks drive
centralization towards services like Coinbase ("look ma! No blockchain
transaction!" <-- if you pay a Coinbase merchant from your Coinbase
wallet), but he supports bigger blocks because more transactions on our
existing decentralized network is better.

-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150530/b6824987/attachment.html>

From alex.mizrahi at gmail.com  Sat May 30 22:05:15 2015
From: alex.mizrahi at gmail.com (Alex Mizrahi)
Date: Sun, 31 May 2015 01:05:15 +0300
Subject: [Bitcoin-development] Block Size Increase Requirements
In-Reply-To: <CABsx9T0kbRe31LMwk499MQUw225f5GGd67GfhXBezHmDqxkioA@mail.gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CAFzgq-xByQ1E_33_m3UpXQFUkGc78HKnA=7XXMshANDuTkNsvA@mail.gmail.com>
	<CABsx9T0kbRe31LMwk499MQUw225f5GGd67GfhXBezHmDqxkioA@mail.gmail.com>
Message-ID: <CAE28kUTSgrU0kY6zLHrZXAAP+XD2H=NqT8rE3jt6Cp+1qGkHRg@mail.gmail.com>

> Why 2 MB ?
>

Why 20 MB? Do you anticipate 20x transaction count growth in 2016?

Why not grow it by 1 MB per year?
This is a safer option, I don't think that anybody claims that 2 MB blocks
will be a problem.
And in 10 years when we get to 10 MB we'll get more evidence as to whether
network can handle 10 MB blocks.

So this might be a solution which would satisfy both sides:
  *  people who are concerned about block size growth will have an
opportunity to stop it before it grows too much (e.g. with a soft fork),
  *  while people who want bigger blocks will get an equivalent of 25% per
year growth within the first 10 years, which isn't bad, is it?

So far I haven't heard any valid arguments against linear growth.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150531/29b010f3/attachment.html>

From brianchoffman at gmail.com  Sat May 30 23:16:42 2015
From: brianchoffman at gmail.com (Brian Hoffman)
Date: Sat, 30 May 2015 19:16:42 -0400
Subject: [Bitcoin-development] Block Size Increase Requirements
In-Reply-To: <CAE28kUTSgrU0kY6zLHrZXAAP+XD2H=NqT8rE3jt6Cp+1qGkHRg@mail.gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CAFzgq-xByQ1E_33_m3UpXQFUkGc78HKnA=7XXMshANDuTkNsvA@mail.gmail.com>
	<CABsx9T0kbRe31LMwk499MQUw225f5GGd67GfhXBezHmDqxkioA@mail.gmail.com>
	<CAE28kUTSgrU0kY6zLHrZXAAP+XD2H=NqT8rE3jt6Cp+1qGkHRg@mail.gmail.com>
Message-ID: <44570322-FBAE-4BAF-A0DA-2E478EF436B4@gmail.com>

> Why 20 MB? Do you anticipate 20x transaction count growth in 2016?


Do you anticipate linear growth?

> On May 30, 2015, at 6:05 PM, Alex Mizrahi <alex.mizrahi at gmail.com> wrote:
> 
>  
>> Why 2 MB ?
> 
> Why 20 MB? Do you anticipate 20x transaction count growth in 2016?
> 
> Why not grow it by 1 MB per year?
> This is a safer option, I don't think that anybody claims that 2 MB blocks will be a problem.
> And in 10 years when we get to 10 MB we'll get more evidence as to whether network can handle 10 MB blocks.
> 
> So this might be a solution which would satisfy both sides:
>   *  people who are concerned about block size growth will have an opportunity to stop it before it grows too much (e.g. with a soft fork),
>   *  while people who want bigger blocks will get an equivalent of 25% per year growth within the first 10 years, which isn't bad, is it?
> 
> So far I haven't heard any valid arguments against linear growth.
> ------------------------------------------------------------------------------
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150530/250c732e/attachment.html>

From raystonn at hotmail.com  Sat May 30 23:18:48 2015
From: raystonn at hotmail.com (Raystonn)
Date: Sat, 30 May 2015 16:18:48 -0700
Subject: [Bitcoin-development] Block Size Increase Requirements
Message-ID: <COL402-EAS257D9744762445A974BDA85CDC80@phx.gbl>

An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150530/7028370e/attachment.html>

From alex.mizrahi at gmail.com  Sun May 31 00:13:30 2015
From: alex.mizrahi at gmail.com (Alex Mizrahi)
Date: Sun, 31 May 2015 03:13:30 +0300
Subject: [Bitcoin-development] Block Size Increase Requirements
In-Reply-To: <44570322-FBAE-4BAF-A0DA-2E478EF436B4@gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CAFzgq-xByQ1E_33_m3UpXQFUkGc78HKnA=7XXMshANDuTkNsvA@mail.gmail.com>
	<CABsx9T0kbRe31LMwk499MQUw225f5GGd67GfhXBezHmDqxkioA@mail.gmail.com>
	<CAE28kUTSgrU0kY6zLHrZXAAP+XD2H=NqT8rE3jt6Cp+1qGkHRg@mail.gmail.com>
	<44570322-FBAE-4BAF-A0DA-2E478EF436B4@gmail.com>
Message-ID: <CAE28kUSe07r=Z4WtcsAQ211iO3W_fb_Na89UhhMOoX95ef-H1A@mail.gmail.com>

> Why 20 MB? Do you anticipate 20x transaction count growth in 2016?
>
> Do you anticipate linear growth?
>

It's safe to say that absolutely nobody can predict the actual growth with
any degree of an accuracy.
I believe that linear growth compares very favorably to other alternatives:

1. Exponential growth: Linear growth is better at modelling diminishing
returns, that is, risk that it grows too much is much smaller. At the same
time initially it will grow faster than reasonable exponential models.
   E.g. linear year-over-year relative growth:    100% 50% 33% 25% ...10%
   While exponential one which gives the same result in 10 years:
   25% 25% ... 25%
   This is on the same scale, but exponential starts slower than we want at
start (1.25 MB will be too little for 2016 as we already see fully filled 1
MB blocks), but goes a bit too fast in the long term. It's highly unlikely
we'll see bandwidth growing 10x each 10 years in the long term.

2. Single step increase: an obvious advantage is that linear growth gives
us time to adapt to near realities, time to change something if there is an
unwanted effects, etc. At the same a single step is not a long-term
solution.
While a slow-but-steady growth might be.

3. Adaptive solutions (e.g. limit depends on the last N blocks or something
of that nature):
  The problem with them is that they are  rather complex, and also:
  3.1. prone to manipulation: somebody might try to push the limit if it
will favor him in future
  3.2. possibility of a positive feedback loop.
  3.3. possibility of an unhealthy game-theoretic dynamics

The main problem is that we do not understand game theoretic aspects of
bitcoin mining in presence of various real-world factors such as block
propagation delays. Thus we can't design a proper adaptive solution.


There is no perfect solution to this problem as we cannot predict the
future and our understanding is limited.
But among the 5 alternatives (linear, exponential, single step, adaptive,
no limit), linear seems to be the best option at this point as it's both
quite safe and doesn't stunt growth too much.

> bitcoin is really really small right now, any sign of real adoption could
make it grow 100x or even more in a matter of weeks.

This is certainly possible, but the thing is:

1) this can't be predicted;
2) this will be a serious problem for many bitcoind installations;
3) it's not necessarily a healthy thing, perhaps it will grow 100x in a
matter of weeks, and then will go to zero in matter of weeks as well.

So I don't think that sudden growth spurts is something we should take into
account on the planning stage. If anything we'd like to prevent them from
happening, slow growth is usually better.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150531/7511ce61/attachment.html>

From bip at mattwhitlock.name  Sun May 31 00:29:25 2015
From: bip at mattwhitlock.name (Matt Whitlock)
Date: Sat, 30 May 2015 20:29:25 -0400
Subject: [Bitcoin-development] Proposal: A measured response to save Bitcoin
	Core
Message-ID: <3698747.VeHb3lFFLZ@crushinator>

Greg, Pieter, Jeff, and Wladimir,

I'll try to be brief to respect your time.

1. I don't want to see Bitcoin die.

2. As has been discussed on this list and elsewhere: Bitcoin could potentially die due to economic and/or game-theoretic complications arising from raising the block size limit, but Bitcoin could also die due to usability complications arising from NOT raising the block size limit. Strong, personally held opinions by various members of this community notwithstanding, it is not clear which of these scenarios is more likely.

3. What *is* clear at this point is that Gavin will move ahead with his proposal, regardless of whether the remainder of the Bitcoin Core committers agree with him. If he has to commit his changes to Bitcoin XT and then rally the miners to switch, then that's what he'll do. He believes that he is working in the best interests of Bitcoin (as I would hope we all do), and so I do not fault him for his intentions. However, I think his proposal is too risky.

4. I also think that ignoring the immediate problem is too risky. If allowing significantly larger blocks will cause a serious problem for Bitcoin (which is a possibility that we cannot rule out, as we lack omniscience), then NOT making any change to Bitcoin Core will virtually *assure* that we cause exactly this problem, as the popular (non-technical) consensus appears to be in favor of Bitcoin XT and a larger block size limit. If we do nothing, then there's a very real chance that Bitcoin XT takes over, for better or worse.

5. I'd like to propose a way that we can have our cake and eat it too. My proposal attempts to satisfy both those who want larger blocks AND those who want to be extremely cautious about changing the fundamental economic parameters of Bitcoin.

6. Something I've never understood about Gavin's (et al.) proposal is why there is a massive step right up front. Assuming we accept his argument that we're critically close to running out of capacity, I still must ask: why do we need a 20x increase all at once?

7. It's not a given that blocks will immediately expand to meet the hard limit. In fact, there are strong and compelling arguments why this will NOT happen. But in any software system, if a given scenario is *possible*, then one MUST assume that it will happen and must have a plan to handle it.

8. My primary objection is not to raising the block size limit; my objection is to raising it *suddenly*. You can argue that, because we'll have plenty of time before March 2016, it's not "sudden," but, whether we do it now or a year from now or a decade from now, a step function is, by definition, sudden.

9. My proposal is that we raise the block size limit *gradually*, using an approximately smooth function, without a step discontinuity. We can employ a linear growth function to adjust the block size limit *smoothly* from 1 MB to 20 MB over the course of several years, beginning next March.

10. This is the difference between cannonballing into the deep end of the pool and walking gingerly down the steps into the shallow end. Both get you to the eventual goal, but one is reckless while the other is measured and deliberate. If there's a problem that larger blocks will enable, then I'd prefer to see the problem crop up gradually rather than all at once. If it's gradual, then we'll have time to discuss and fix it without panicking.

11. I am offering to implement this proposal and submit a pull request to Bitcoin Core. However, if another dev who is more familiar with the internals would like to step forward, then that would be superior.

Respectfully submitted,
Matt Whitlock



From alex.mizrahi at gmail.com  Sun May 31 00:32:34 2015
From: alex.mizrahi at gmail.com (Alex Mizrahi)
Date: Sun, 31 May 2015 03:32:34 +0300
Subject: [Bitcoin-development] Block Size Increase Requirements
In-Reply-To: <COL402-EAS257D9744762445A974BDA85CDC80@phx.gbl>
References: <COL402-EAS257D9744762445A974BDA85CDC80@phx.gbl>
Message-ID: <CAE28kUQ8HYFAjsUXrah0CoRY9xJBVx7jo8RFgpVsP11ppThXtw@mail.gmail.com>

>
> Stop trying to dictate block growth limits.  Block size will be determined
> by competition between miners and availability of transactions, not through
> hard-coded limits.
>
Do you even game theory, bro? It doesn't work that way.

Mike Hearn described the problem in this article:
https://medium.com/@octskyward/hashing-7d04a887acc8

But the solution he's proposing is ridiculously bad and unsound: he expects
business owners to donate large sums of money towards mining. If it comes
to this, what sane business owner will donate, say, 100 BTC to miners
instead of seeking some alternatives? Proof-of-stake coins are already
there. I'm well aware of theoretical issues with PoS security, but those
theoretical issues aren't as bad as donation-funded cryptocurrency security.

But you know what works? Mining fees + block size limit.
Users and merchants are interested in their transactions being confirmed,
but block size limit won't allow it to turn into a race to bottom.
This is actually game-theoretically sound.


>   I see now the temporary 1MB limit was a mistake.  It should have gone in
> as a dynamic limit that scales with average block size.
>
This means that miners will control it, and miners couldn't care less about
things like decentralization and about problems of ordinary users. This
means that in this scenario Bitcoin will be 100% controlled by few huge-ass
mining operations.

Possibly a single operation. We already saw GHASH.IO using 51% of total
hashpower. Is that what you want?

Miners are NOT benevolent. This was already demonstrated. They are greedy.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150531/695a6691/attachment.html>

From 1240902 at gmail.com  Sun May 31 01:31:45 2015
From: 1240902 at gmail.com (Chun Wang)
Date: Sun, 31 May 2015 09:31:45 +0800
Subject: [Bitcoin-development] Fwd:  Block Size Increase Requirements
In-Reply-To: <CAFzgq-z5WCznGhbOexS0XESNGAVauw45ewEV-1eMij7yDT61=Q@mail.gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CAFzgq-xByQ1E_33_m3UpXQFUkGc78HKnA=7XXMshANDuTkNsvA@mail.gmail.com>
	<CABsx9T0kbRe31LMwk499MQUw225f5GGd67GfhXBezHmDqxkioA@mail.gmail.com>
	<CAFzgq-z5WCznGhbOexS0XESNGAVauw45ewEV-1eMij7yDT61=Q@mail.gmail.com>
Message-ID: <CAFzgq-zTybEQyGz0nq90u5n5JZcJzxQS_XKaTpr5POJi-tHM6A@mail.gmail.com>

On Sat, May 30, 2015 at 9:57 PM, Gavin Andresen <gavinandresen at gmail.com> wrote:
>> Bad miners could attack us and the network with artificial
>> big blocks.
>
>
> How?
>
> I ran some simulations, and I could not find a network topology where a big
> miner producing big blocks could cause a loss of profit to another miner
> (big or small) producing smaller blocks:
>
> http://gavinandresen.ninja/are-bigger-blocks-better-for-bigger-miners
>
> (the 0.3% advantage I DID find was for the situation where EVERYBODY was
> producing big blocks).

If someone propagate a 20MB block, it will take at best 6 seconds for
us to receive to verify it at current configuration, result of one
percent orphan rate increase. Or, we can mine the next block only on
the previous block's header, in this case, the network would see many
more transaction-less blocks.

Our orphan rate is about 0.5% over the past few months. If the network
floods 20MB blocks, it can be well above 2%. Besides bandwidth, A 20MB
block could contain an average of 50000 transactions, hundred of
thousands of sigops, Do you have an estimate how long it takes on the
submitblock rpccall?

For references, our 30Mbps bandwidth in Beijing costs us 1350 dollars
per month. We also use Aliyun and Linode cloud services for block
propagation. As of May 2015, the price is 0.13 U.S. dollars per GB for
100Mbps connectivity at Aliyun. For a single cross-border TCP
connection, it would be certainly far slower than 12.5 MB/s.

I think we can accept 5MB block at most.

(sorry forgot to cc to the mailing list)



From pindar.wong at gmail.com  Sun May 31 02:20:42 2015
From: pindar.wong at gmail.com (Pindar Wong)
Date: Sun, 31 May 2015 10:20:42 +0800
Subject: [Bitcoin-development] Fwd: Block Size Increase Requirements
In-Reply-To: <CAFzgq-zTybEQyGz0nq90u5n5JZcJzxQS_XKaTpr5POJi-tHM6A@mail.gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CAFzgq-xByQ1E_33_m3UpXQFUkGc78HKnA=7XXMshANDuTkNsvA@mail.gmail.com>
	<CABsx9T0kbRe31LMwk499MQUw225f5GGd67GfhXBezHmDqxkioA@mail.gmail.com>
	<CAFzgq-z5WCznGhbOexS0XESNGAVauw45ewEV-1eMij7yDT61=Q@mail.gmail.com>
	<CAFzgq-zTybEQyGz0nq90u5n5JZcJzxQS_XKaTpr5POJi-tHM6A@mail.gmail.com>
Message-ID: <CAM7BtUoq_j+0b_GUQRU0gknSWW8m1NSviX4BXACw9cL=yi1R7Q@mail.gmail.com>

Thank you very much Chun Wang for the details below.

While I'm based in HK, but I'd like to propose that the miners in China
work together with Gavin and others to run an experiment of sorts next
month to gather more details for the community.

p.




On Sun, May 31, 2015 at 9:31 AM, Chun Wang <1240902 at gmail.com> wrote:

> On Sat, May 30, 2015 at 9:57 PM, Gavin Andresen <gavinandresen at gmail.com>
> wrote:
> >> Bad miners could attack us and the network with artificial
> >> big blocks.
> >
> >
> > How?
> >
> > I ran some simulations, and I could not find a network topology where a
> big
> > miner producing big blocks could cause a loss of profit to another miner
> > (big or small) producing smaller blocks:
> >
> > http://gavinandresen.ninja/are-bigger-blocks-better-for-bigger-miners
> >
> > (the 0.3% advantage I DID find was for the situation where EVERYBODY was
> > producing big blocks).
>
> If someone propagate a 20MB block, it will take at best 6 seconds for
> us to receive to verify it at current configuration, result of one
> percent orphan rate increase. Or, we can mine the next block only on
> the previous block's header, in this case, the network would see many
> more transaction-less blocks.
>
> Our orphan rate is about 0.5% over the past few months. If the network
> floods 20MB blocks, it can be well above 2%. Besides bandwidth, A 20MB
> block could contain an average of 50000 transactions, hundred of
> thousands of sigops, Do you have an estimate how long it takes on the
> submitblock rpccall?
>
> For references, our 30Mbps bandwidth in Beijing costs us 1350 dollars
> per month. We also use Aliyun and Linode cloud services for block
> propagation. As of May 2015, the price is 0.13 U.S. dollars per GB for
> 100Mbps connectivity at Aliyun. For a single cross-border TCP
> connection, it would be certainly far slower than 12.5 MB/s.
>
> I think we can accept 5MB block at most.
>
> (sorry forgot to cc to the mailing list)
>
>
> ------------------------------------------------------------------------------
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150531/0a109f73/attachment.html>

From kiwigb at yahoo.com  Sun May 31 05:05:56 2015
From: kiwigb at yahoo.com (gb)
Date: Sun, 31 May 2015 17:05:56 +1200
Subject: [Bitcoin-development] Block Size Increase Requirements
In-Reply-To: <CAE28kUTSgrU0kY6zLHrZXAAP+XD2H=NqT8rE3jt6Cp+1qGkHRg@mail.gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CAFzgq-xByQ1E_33_m3UpXQFUkGc78HKnA=7XXMshANDuTkNsvA@mail.gmail.com>
	<CABsx9T0kbRe31LMwk499MQUw225f5GGd67GfhXBezHmDqxkioA@mail.gmail.com>
	<CAE28kUTSgrU0kY6zLHrZXAAP+XD2H=NqT8rE3jt6Cp+1qGkHRg@mail.gmail.com>
Message-ID: <1433048756.2156.15.camel@yahoo.com>

Linear growth is indeed the 'simplest' model for growth so removes
concerns of complexity using such a growth model. Seems like it might be
a safe compromise between exponential growth, zero growth and buys some
time to observe the longer term scale network behaviour. 

A simple linear growth 'hard' technical limit could also be used
conjunction with the simple periodic soft dynamic limit adjustment (e.g.
1.5x of moving average) as discussed recently. So that the combination
provides for growth, with fee pressure, up until if/when the technical
hard limit is hit. And if we keep hitting the hard limit that signals a
market demand for ancillary layers to be built out, that has been
missing until now.

On Sun, 2015-05-31 at 01:05 +0300, Alex Mizrahi wrote:
>  
>         
>         Why 2 MB ?
> 
> 
> Why 20 MB? Do you anticipate 20x transaction count growth in 2016?
> 
> 
> Why not grow it by 1 MB per year?
> This is a safer option, I don't think that anybody claims that 2 MB
> blocks will be a problem.
> And in 10 years when we get to 10 MB we'll get more evidence as to
> whether network can handle 10 MB blocks.
> 
> 
> So this might be a solution which would satisfy both sides:
>   *  people who are concerned about block size growth will have an
> opportunity to stop it before it grows too much (e.g. with a soft
> fork),
>   *  while people who want bigger blocks will get an equivalent of 25%
> per year growth within the first 10 years, which isn't bad, is it?
> 
> 
> So far I haven't heard any valid arguments against linear growth.
> ------------------------------------------------------------------------------
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development





From pete at petertodd.org  Sun May 31 07:05:30 2015
From: pete at petertodd.org (Peter Todd)
Date: Sun, 31 May 2015 09:05:30 +0200
Subject: [Bitcoin-development] Block Size Increase Requirements
In-Reply-To: <CAFzgq-xByQ1E_33_m3UpXQFUkGc78HKnA=7XXMshANDuTkNsvA@mail.gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CAFzgq-xByQ1E_33_m3UpXQFUkGc78HKnA=7XXMshANDuTkNsvA@mail.gmail.com>
Message-ID: <20150531070530.GD12966@muck>

On Sat, May 30, 2015 at 07:42:16AM +0800, Chun Wang wrote:
> Hello. I am from F2Pool. We are currently mining the biggest blocks on
> the network. So far top 100 biggest bitcoin blocks are all from us. We
> do support bigger blocks and sooner rather than later. But we cannot
> handle 20 MB blocks right now. I know most blocks would not be 20 MB
> over night. But only if a small fraction of blocks more than 10 MB, it
> could dramatically increase of our orphan rate, result of higher fee
> to miners. Bad miners could attack us and the network with artificial
> big blocks. As yhou know, other Chinese pools, AntPool, BW, they
> produces ASIC chips and mining mostly with their own machines. They do
> not care about a few percent of orphan increase as much as we do. They
> would continue their zero fee policy. We would be the biggest loser.
> As the exchanges had taught us, zero fee is not health to the network.
> Also we have to redevelop our block broadcast logic. Server bandwidth
> is a lot more expensive in China. And the Internet is slow. Currently
> China has more than 50% of mining power, if block size increases, I
> bet European and American pools could suffer more than us. We think
> the max block size should be increased, but must be increased
> smoothly, 2 MB first, and then after one or two years 4 MB, then 8 MB,
> and so on. Thanks.

Great to hear from you!

Yeah, I'm pretty surprised myself that Gavin never accepted the
compromises offered by others in this space for a slow growth solution,
rather than starting with over an order of magnitude blocksize increase.
This is particularly surprising when his own calculations - after
correcting an artithmetic error - came up with 8MB blocks rather than
20MB.

Something important to note in Gavin Andresen's analysises of this issue
is that he's using quite optimistic scenarios for how nodes are
connected to each other. For instance, assuming that connections between
miners are direct is a very optimistic assumption that depends on a
permissive, unregulated, environment where miners co-operate with each
other - obviously that's easily subject to change! Better block
broadcasting logic helps this in the "co-operation" case, but there's
not much it can do in the worst-case.


Unrelated: feel free to contact me directly if you have any questions
re: the BIP66 upgrade; I hear you guys were planning on upgrading your
mining nodes soon.

-- 
'peter'[:-1]@petertodd.org
00000000000000000db932d1cbd04a29d8e55989eda3f096d3ab8e8d95eb28e9
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150531/59f5b2ed/attachment.sig>

From s7r at sky-ip.org  Sun May 31 09:32:08 2015
From: s7r at sky-ip.org (s7r)
Date: Sun, 31 May 2015 12:32:08 +0300
Subject: [Bitcoin-development] Proposal: A measured response to save
 Bitcoin Core
In-Reply-To: <3698747.VeHb3lFFLZ@crushinator>
References: <3698747.VeHb3lFFLZ@crushinator>
Message-ID: <556AD518.6030207@sky-ip.org>

Hi,

For the less crypto engineering experts but highly interested in Bitcoin
and working with Bitcoin on daily basis reading the list, what would be
an easy to understand explanation about how does this solution represent
a good fix?

So, we have a hard cap of 1 MB block currently. This is not enough
because more and more people use Bitcoin and the transaction volume
increased (yeey, good news). So, rather than fixing the issue for good,
we just increase the block size hard cap to 20 MB. I will not discuss if
this causes problems or not. But what are the future plans, when the 20
MB hard cap will be reached? Increase it again? This doesn't sound like
a fix, it sounds more like pushing the can down the road. Obviously if 1
MB is not enough now, we have the reasonable suspicion that 20 MB could
not be enough in few years.

What is the explanation that 20 MB blocks will be sufficient for life
time? Is it because 'probably other solutions will appear, such as
micropayment channels and offchain transactions'?  If this is the case,
those can easily function with 1 MB blocks as well, and we should see
those in action sooner rather than later.

I run multiple full nodes, including one with Bitcoin XT and I don't
want to see Bitcoin XT and Bitcoin Core divide into different consensus
and create 2 altcoins instead of one Bitcoin.

On 5/31/2015 3:29 AM, Matt Whitlock wrote:
> Greg, Pieter, Jeff, and Wladimir,
> 
> I'll try to be brief to respect your time.
> 
> 1. I don't want to see Bitcoin die.
> 
> 2. As has been discussed on this list and elsewhere: Bitcoin could potentially die due to economic and/or game-theoretic complications arising from raising the block size limit, but Bitcoin could also die due to usability complications arising from NOT raising the block size limit. Strong, personally held opinions by various members of this community notwithstanding, it is not clear which of these scenarios is more likely.
> 
> 3. What *is* clear at this point is that Gavin will move ahead with his proposal, regardless of whether the remainder of the Bitcoin Core committers agree with him. If he has to commit his changes to Bitcoin XT and then rally the miners to switch, then that's what he'll do. He believes that he is working in the best interests of Bitcoin (as I would hope we all do), and so I do not fault him for his intentions. However, I think his proposal is too risky.
> 
> 4. I also think that ignoring the immediate problem is too risky. If allowing significantly larger blocks will cause a serious problem for Bitcoin (which is a possibility that we cannot rule out, as we lack omniscience), then NOT making any change to Bitcoin Core will virtually *assure* that we cause exactly this problem, as the popular (non-technical) consensus appears to be in favor of Bitcoin XT and a larger block size limit. If we do nothing, then there's a very real chance that Bitcoin XT takes over, for better or worse.
> 
> 5. I'd like to propose a way that we can have our cake and eat it too. My proposal attempts to satisfy both those who want larger blocks AND those who want to be extremely cautious about changing the fundamental economic parameters of Bitcoin.
> 
> 6. Something I've never understood about Gavin's (et al.) proposal is why there is a massive step right up front. Assuming we accept his argument that we're critically close to running out of capacity, I still must ask: why do we need a 20x increase all at once?
> 
> 7. It's not a given that blocks will immediately expand to meet the hard limit. In fact, there are strong and compelling arguments why this will NOT happen. But in any software system, if a given scenario is *possible*, then one MUST assume that it will happen and must have a plan to handle it.
> 
> 8. My primary objection is not to raising the block size limit; my objection is to raising it *suddenly*. You can argue that, because we'll have plenty of time before March 2016, it's not "sudden," but, whether we do it now or a year from now or a decade from now, a step function is, by definition, sudden.
> 
> 9. My proposal is that we raise the block size limit *gradually*, using an approximately smooth function, without a step discontinuity. We can employ a linear growth function to adjust the block size limit *smoothly* from 1 MB to 20 MB over the course of several years, beginning next March.
> 
> 10. This is the difference between cannonballing into the deep end of the pool and walking gingerly down the steps into the shallow end. Both get you to the eventual goal, but one is reckless while the other is measured and deliberate. If there's a problem that larger blocks will enable, then I'd prefer to see the problem crop up gradually rather than all at once. If it's gradual, then we'll have time to discuss and fix it without panicking.
> 
> 11. I am offering to implement this proposal and submit a pull request to Bitcoin Core. However, if another dev who is more familiar with the internals would like to step forward, then that would be superior.
> 
> Respectfully submitted,
> Matt Whitlock
> 
> ------------------------------------------------------------------------------
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> 



From btcdrak at gmail.com  Sun May 31 09:35:20 2015
From: btcdrak at gmail.com (Btc Drak)
Date: Sun, 31 May 2015 10:35:20 +0100
Subject: [Bitcoin-development] Proposal: A measured response to save
 Bitcoin Core
In-Reply-To: <3698747.VeHb3lFFLZ@crushinator>
References: <3698747.VeHb3lFFLZ@crushinator>
Message-ID: <CADJgMztZuqt1BM8S2W1nOOBET=na+L+SZe4RRPdLU4tnbA-7cA@mail.gmail.com>

On Sun, May 31, 2015 at 1:29 AM, Matt Whitlock <bip at mattwhitlock.name>
wrote:

> 3. What *is* clear at this point is that Gavin will move ahead with his
> proposal, regardless of whether the remainder of the Bitcoin Core
> committers agree with him. If he has to commit his changes to Bitcoin XT
> and then rally the miners to switch, then that's what he'll do. He believes
> that he is working in the best interests of Bitcoin (as I would hope we all
> do), and so I do not fault him for his intentions. However, I think his
> proposal is too risky.
>

I seriously doubt if miners and merchants who's income depends on bitcoin
are going to risk a network split. Gavin isn't pedalling some mempool
policy which doesn't affect consensus. The changes have to be universally
adopted by miners and full nodes. If there is any uncertainty about that
global acceptance, those financially dependent on bitcoin will not take the
risk just to be political. You can see how conservative the mining
community is already by their slow upgrade of Bitcoin Core as it is. Even
if some miners and merchants generally support the idea of bigger blocks,
they most certainly are not going to take the risk of leading a hard fork
when there is substantial risk of it failing.

Until there is actual consensus among the technical community I wouldn't be
too concerned.


> 4. I also think that ignoring the immediate problem is too risky. If
> allowing significantly larger blocks will cause a serious problem for
> Bitcoin (which is a possibility that we cannot rule out, as we lack
> omniscience), then NOT making any change to Bitcoin Core will virtually
> *assure* that we cause exactly this problem, as the popular (non-technical)
> consensus appears to be in favor of Bitcoin XT and a larger block size
> limit. If we do nothing, then there's a very real chance that Bitcoin XT
> takes over, for better or worse.
>

I don't think anyone is ignoring the issues, nor that everyone accepts that
blocksize may have to eventually change. The overwhelming technical
majority do not agree there is a problem that needs to be immediately
addressed. It would be far more helpful if we focused on stuff that helps
enable level 2 technologies so that bitcoin can actually scale, (like
R/CLTV and malleability fixes which are being delayed by BIP66 rollout and
pending the new "concurrent soft-forks" proposal).


> 7. It's not a given that blocks will immediately expand to meet the hard
> limit. In fact, there are strong and compelling arguments why this will NOT
> happen. But in any software system, if a given scenario is *possible*, then
> one MUST assume that it will happen and must have a plan to handle it.
>

But of course it would be dealt with if and when it becomes necessary. It's
not like there is blanket opposition to increasing the blocksize ever, it's
the matter of if, when and how; but when is defintely not now.

9. My proposal is that we raise the block size limit *gradually*, using an
> approximately smooth function, without a step discontinuity. We can employ
> a linear growth function to adjust the block size limit *smoothly* from 1
> MB to 20 MB over the course of several years, beginning next March.
>

Automatic or dynamic blocksize increase risks being very difficult to shut
down if later we find it is negatively impacting the ecosystem... and
that's part of the reluctance with bigger blocks because we still have not
studied the potential downsides enough beyond some sketchy and disputed
calculations and overall it's not addressing scalability at all.


> 10. This is the difference between cannonballing into the deep end of the
> pool and walking gingerly down the steps into the shallow end. Both get you
> to the eventual goal, but one is reckless while the other is measured and
> deliberate. If there's a problem that larger blocks will enable, then I'd
> prefer to see the problem crop up gradually rather than all at once. If
> it's gradual, then we'll have time to discuss and fix it without panicking.


Extending blocksize now would be nothing more than a political move. I have
no idea what will be decided in the end, but I do know that in order for
bitcoin to survive, changes must be based on well thought out and discussed
technical merits and not the result of political pressure. Politics and
good software do not mix.

Drak
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150531/c680bfb1/attachment.html>

From elombrozo at gmail.com  Sun May 31 10:01:53 2015
From: elombrozo at gmail.com (Eric Lombrozo)
Date: Sun, 31 May 2015 03:01:53 -0700
Subject: [Bitcoin-development] Proposal: A measured response to save
 Bitcoin Core
In-Reply-To: <CADJgMztZuqt1BM8S2W1nOOBET=na+L+SZe4RRPdLU4tnbA-7cA@mail.gmail.com>
References: <3698747.VeHb3lFFLZ@crushinator>
	<CADJgMztZuqt1BM8S2W1nOOBET=na+L+SZe4RRPdLU4tnbA-7cA@mail.gmail.com>
Message-ID: <CABr1YTcSPcJBb-ZFQ59cYuywix4bfKpic_KjBProiAZ47o8fPg@mail.gmail.com>

Drak,

I mostly agree with your assessment...except for your last claim.

Not that I wouldn't like to find a way to avoid politics, but like I've
argued before, it is inevitable that sooner or later any consensus protocol
that seeks dynamism will encounter politics.

The block size discussion, while ultimately necessary, for now is in the
best case merely serving as an example of the kind of political issues we
*really* need to be finding some solution for...and in the worst case is a
distraction and evasion.

Some protocol updates will be merely technical optimizations or feature
enhancements that are fairly uncontroversial...but some will inevitably be
highly controversial with real-world economic consequences, winners and
losers. We lack a process for deciding these issues. No matter how
sophistocated we make the protocol, somethings will inevitably require
external input to make these issues decidable...it is a Goedelian
implication. This external input could be some sort of vote (of which
hashing power is a particular kind) or perhaps something else.

There's something to be said for building the dynamics of hard forks *into*
our model rather than avoiding it at all costs.  However, forks are the
easy part. The difficulty is in merging different branches. Perhaps we
should learn a thing or two from git. Perhaps the question we should be
asking is not "how do we avoid hard forks" but "how can we design the
network to allow for merging?"

- Eric Lombrozo
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150531/142f646d/attachment.html>

From gavinandresen at gmail.com  Sun May 31 12:40:35 2015
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Sun, 31 May 2015 08:40:35 -0400
Subject: [Bitcoin-development] Fwd: Block Size Increase Requirements
In-Reply-To: <CAFzgq-zTybEQyGz0nq90u5n5JZcJzxQS_XKaTpr5POJi-tHM6A@mail.gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CAFzgq-xByQ1E_33_m3UpXQFUkGc78HKnA=7XXMshANDuTkNsvA@mail.gmail.com>
	<CABsx9T0kbRe31LMwk499MQUw225f5GGd67GfhXBezHmDqxkioA@mail.gmail.com>
	<CAFzgq-z5WCznGhbOexS0XESNGAVauw45ewEV-1eMij7yDT61=Q@mail.gmail.com>
	<CAFzgq-zTybEQyGz0nq90u5n5JZcJzxQS_XKaTpr5POJi-tHM6A@mail.gmail.com>
Message-ID: <CABsx9T2L5bi-c63-KqSifOMeNayUWSPo0_Hx8VjMR_4=kC3ixg@mail.gmail.com>

On Sat, May 30, 2015 at 9:31 PM, Chun Wang <1240902 at gmail.com> wrote:
>
> If someone propagate a 20MB block, it will take at best 6 seconds for
> us to receive to verify it at current configuration, result of one
> percent orphan rate increase.


That orphan rate increase will go to whoever is producing the 20MB blocks,
NOT you.


Or, we can mine the next block only on
> the previous block's header, in this case, the network would see many
> more transaction-less blocks.
>

Are you sure that is the best strategy? If a big block is slow to
propagate, I suspect it will be better to punish the miner that created it
by refusing to build on it until it has been fully validated.

I'll try to find time to run a couple of simulations.



>
> Our orphan rate is about 0.5% over the past few months. If the network
> floods 20MB blocks, it can be well above 2%. Besides bandwidth, A 20MB
> block could contain an average of 50000 transactions, hundred of
> thousands of sigops, Do you have an estimate how long it takes on the
> submitblock rpccall?
>

I can benchmark it. It should be pretty fast, and sipa has a couple of
patches pending to make the UTXO cache much faster.

It can be fast because the vast majority of the work of validating all
those transactions can happen as they are received into the memory pool.


> For references, our 30Mbps bandwidth in Beijing costs us 1350 dollars
> per month.


You should be able to handle 20MB blocks no problem; if I round up to 100MB
per block that works out to 1.3Mbps.

We also use Aliyun and Linode cloud services for block
> propagation. As of May 2015, the price is 0.13 U.S. dollars per GB for
> 100Mbps connectivity at Aliyun.


That speed will handle 20MB blocks no problem.

If each 20MB block is 100MB of data up/down the wire (I'm vastly
over-estimating, after optimization it should be 40MB) then you'll be
paying...uhhh:

0.1 GB / block-data-on-wire * 144 blocks/day * 30.5 days/month * 0.13 $ /
GB = $57

Less than $2 per day in bandwidth, surely you can afford that.


> For a single cross-border TCP
> connection, it would be certainly far slower than 12.5 MB/s.


That's OK, you'll 1.3Mbps or less.


> I think we can accept 5MB block at most.
>

Are you worried about paying too much, or do 20MB blocks "feel like too
much" ?

-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150531/41d199dc/attachment.html>

From gavinandresen at gmail.com  Sun May 31 12:51:04 2015
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Sun, 31 May 2015 08:51:04 -0400
Subject: [Bitcoin-development] Block Size Increase Requirements
In-Reply-To: <20150531070530.GD12966@muck>
References: <554BE0E1.5030001@bluematt.me>
	<CAFzgq-xByQ1E_33_m3UpXQFUkGc78HKnA=7XXMshANDuTkNsvA@mail.gmail.com>
	<20150531070530.GD12966@muck>
Message-ID: <CABsx9T1jpOTxm3c4RYqK7sTF2YShL_ZYDsOWQuNZZXdBKa3Ytw@mail.gmail.com>

On Sun, May 31, 2015 at 3:05 AM, Peter Todd <pete at petertodd.org> wrote:

> Yeah, I'm pretty surprised myself that Gavin never accepted the
> compromises offered by others in this space for a slow growth solution
>

What compromise? I haven't seen a specific proposal that could be turned
into a pull request.




> Something important to note in Gavin Andresen's analysises of this issue
> is that he's using quite optimistic scenarios for how nodes are
> connected to each other.


NO I AM NOT.

I simulated a variety of connectivities; see the .cfg files at
  https://github.com/gavinandresen/bitcoin_miningsim

The results I give in the "are bigger blocks better" blog post are for
WORST CASE connectivity (one dominant big miner, multiple little miners,
big miner connects to only 30% of little miners, but all the little miners
connected directly to each other).


> For instance, assuming that connections between
> miners are direct is a very optimistic assumption


Again, I did not simulate all miners directly connected to each other.

I will note that miners are VERY HIGHLY connected today. It is in their
best interest to be highly connected to each other.


> that depends on a
> permissive, unregulated, environment where miners co-operate with each
> other - obviously that's easily subject to change!


Really? How is that easily subject to change? If it is easily subject to
change, do bigger blocks have any effect? Why are 1MB blocks not subject to
change?

I talk about "what if your government bans Bitcoin entirely" here:
   http://gavinandresen.ninja/big-blocks-and-tor

... and the issues are essentially the same, independent of block size.


-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150531/15190ca7/attachment.html>

From gavinandresen at gmail.com  Sun May 31 12:52:45 2015
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Sun, 31 May 2015 08:52:45 -0400
Subject: [Bitcoin-development] Fwd: Block Size Increase Requirements
In-Reply-To: <CAFzgq-zTybEQyGz0nq90u5n5JZcJzxQS_XKaTpr5POJi-tHM6A@mail.gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CAFzgq-xByQ1E_33_m3UpXQFUkGc78HKnA=7XXMshANDuTkNsvA@mail.gmail.com>
	<CABsx9T0kbRe31LMwk499MQUw225f5GGd67GfhXBezHmDqxkioA@mail.gmail.com>
	<CAFzgq-z5WCznGhbOexS0XESNGAVauw45ewEV-1eMij7yDT61=Q@mail.gmail.com>
	<CAFzgq-zTybEQyGz0nq90u5n5JZcJzxQS_XKaTpr5POJi-tHM6A@mail.gmail.com>
Message-ID: <CABsx9T37jE3AtmUOOuW+emLGTparbS6OozPRL_hCrC+2JEzxgQ@mail.gmail.com>

On Sat, May 30, 2015 at 9:31 PM, Chun Wang <1240902 at gmail.com> wrote:
>
> If someone propagate a 20MB block, it will take at best 6 seconds for
> us to receive to verify it at current configuration, result of one
> percent orphan rate increase.


That orphan rate increase will go to whoever is producing the 20MB blocks,
NOT you.


Or, we can mine the next block only on
> the previous block's header, in this case, the network would see many
> more transaction-less blocks.
>

Are you sure that is the best strategy? If a big block is slow to
propagate, I suspect it will be better to punish the miner that created it
by refusing to build on it until it has been fully validated.

I'll try to find time to run a couple of simulations.



>
> Our orphan rate is about 0.5% over the past few months. If the network
> floods 20MB blocks, it can be well above 2%. Besides bandwidth, A 20MB
> block could contain an average of 50000 transactions, hundred of
> thousands of sigops, Do you have an estimate how long it takes on the
> submitblock rpccall?
>

I can benchmark it. It should be pretty fast, and sipa has a couple of
patches pending to make the UTXO cache much faster.

It can be fast because the vast majority of the work of validating all
those transactions can happen as they are received into the memory pool.


> For references, our 30Mbps bandwidth in Beijing costs us 1350 dollars
> per month.


You should be able to handle 20MB blocks no problem; if I round up to 100MB
per block that works out to 1.3Mbps.

We also use Aliyun and Linode cloud services for block
> propagation. As of May 2015, the price is 0.13 U.S. dollars per GB for
> 100Mbps connectivity at Aliyun.


That speed will handle 20MB blocks no problem.

If each 20MB block is 100MB of data up/down the wire (I'm vastly
over-estimating, after optimization it should be 40MB) then you'll be
paying...uhhh:

0.1 GB / block-data-on-wire * 144 blocks/day * 30.5 days/month * 0.13 $ /
GB = $57

Less than $2 per day in bandwidth.


> For a single cross-border TCP
> connection, it would be certainly far slower than 12.5 MB/s.


That's OK, you'll 1.3Mbps or less.


> I think we can accept 5MB block at most.
>

Are you worried about paying too much, or do 20MB blocks "feel like too
much" ?

-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150531/79089b53/attachment.html>

From kiwigb at yahoo.com  Sun May 31 13:31:25 2015
From: kiwigb at yahoo.com (gb)
Date: Mon, 01 Jun 2015 01:31:25 +1200
Subject: [Bitcoin-development] [Bulk] Re: Fwd: Block Size Increase
 Requirements
In-Reply-To: <CABsx9T37jE3AtmUOOuW+emLGTparbS6OozPRL_hCrC+2JEzxgQ@mail.gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CAFzgq-xByQ1E_33_m3UpXQFUkGc78HKnA=7XXMshANDuTkNsvA@mail.gmail.com>
	<CABsx9T0kbRe31LMwk499MQUw225f5GGd67GfhXBezHmDqxkioA@mail.gmail.com>
	<CAFzgq-z5WCznGhbOexS0XESNGAVauw45ewEV-1eMij7yDT61=Q@mail.gmail.com>
	<CAFzgq-zTybEQyGz0nq90u5n5JZcJzxQS_XKaTpr5POJi-tHM6A@mail.gmail.com>
	<CABsx9T37jE3AtmUOOuW+emLGTparbS6OozPRL_hCrC+2JEzxgQ@mail.gmail.com>
Message-ID: <1433079085.5422.10.camel@yahoo.com>


Aren't you calculating bandwidth for a singly-connected node? A "highly
connected" miner could have 30-100 node connections so you probably need
to increase your traffic estimates by that factor.

I.e. For 100MB blocks, 30-100 Mbps and $60-$100 per day data costs.

> You should be able to handle 20MB blocks no problem; if I round up to
> 100MB per block that works out to 1.3Mbps.
> 
> 
>         We also use Aliyun and Linode cloud services for block
>         propagation. As of May 2015, the price is 0.13 U.S. dollars
>         per GB for
>         100Mbps connectivity at Aliyun.
> 
> 
> That speed will handle 20MB blocks no problem.
> 
> 
> If each 20MB block is 100MB of data up/down the wire (I'm vastly
> over-estimating, after optimization it should be 40MB) then you'll be
> paying...uhhh:
> 
> 
> 0.1 GB / block-data-on-wire * 144 blocks/day * 30.5 days/month * 0.13
> $ / GB = $57
> 
> 
> Less than $2 per day in bandwidth.
>  
>         For a single cross-border TCP
>         connection, it would be certainly far slower than 12.5 MB/s. 
> 
> 
> That's OK, you'll 1.3Mbps or less


> -- 
> --
> Gavin Andresen
> 
> ------------------------------------------------------------------------------
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development





From alex.mizrahi at gmail.com  Sun May 31 13:45:25 2015
From: alex.mizrahi at gmail.com (Alex Mizrahi)
Date: Sun, 31 May 2015 16:45:25 +0300
Subject: [Bitcoin-development] Fwd: Block Size Increase Requirements
In-Reply-To: <CABsx9T2L5bi-c63-KqSifOMeNayUWSPo0_Hx8VjMR_4=kC3ixg@mail.gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CAFzgq-xByQ1E_33_m3UpXQFUkGc78HKnA=7XXMshANDuTkNsvA@mail.gmail.com>
	<CABsx9T0kbRe31LMwk499MQUw225f5GGd67GfhXBezHmDqxkioA@mail.gmail.com>
	<CAFzgq-z5WCznGhbOexS0XESNGAVauw45ewEV-1eMij7yDT61=Q@mail.gmail.com>
	<CAFzgq-zTybEQyGz0nq90u5n5JZcJzxQS_XKaTpr5POJi-tHM6A@mail.gmail.com>
	<CABsx9T2L5bi-c63-KqSifOMeNayUWSPo0_Hx8VjMR_4=kC3ixg@mail.gmail.com>
Message-ID: <CAE28kUT61qYxqV0mOqw5Dan=eMiCvnG2SnsAeWzOWTxwLydyeQ@mail.gmail.com>

> That orphan rate increase will go to whoever is producing the 20MB blocks,
> NOT you.
>

This depends on how miners are connected.

E.g. suppose there are three miners, A and B have fast connectivity between
then, and C has a slow network.
Suppose that A miners a block and B receives it in 1 second. C receives it
in 6 seconds.
This means that blocks mined by C during these ~5 seconds will be orphaned
because B gets A's block first.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150531/500f47c7/attachment.html>

From dave at hashingit.com  Sun May 31 14:17:10 2015
From: dave at hashingit.com (Dave Hudson)
Date: Sun, 31 May 2015 15:17:10 +0100
Subject: [Bitcoin-development] Fwd: Block Size Increase Requirements
In-Reply-To: <CABsx9T37jE3AtmUOOuW+emLGTparbS6OozPRL_hCrC+2JEzxgQ@mail.gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CAFzgq-xByQ1E_33_m3UpXQFUkGc78HKnA=7XXMshANDuTkNsvA@mail.gmail.com>
	<CABsx9T0kbRe31LMwk499MQUw225f5GGd67GfhXBezHmDqxkioA@mail.gmail.com>
	<CAFzgq-z5WCznGhbOexS0XESNGAVauw45ewEV-1eMij7yDT61=Q@mail.gmail.com>
	<CAFzgq-zTybEQyGz0nq90u5n5JZcJzxQS_XKaTpr5POJi-tHM6A@mail.gmail.com>
	<CABsx9T37jE3AtmUOOuW+emLGTparbS6OozPRL_hCrC+2JEzxgQ@mail.gmail.com>
Message-ID: <91BD6826-3A60-4DD6-807A-2DCEDB00CE87@hashingit.com>


> On 31 May 2015, at 13:52, Gavin Andresen <gavinandresen at gmail.com> wrote:
> 
> On Sat, May 30, 2015 at 9:31 PM, Chun Wang <1240902 at gmail.com <mailto:1240902 at gmail.com>> wrote:
> If someone propagate a 20MB block, it will take at best 6 seconds for
> us to receive to verify it at current configuration, result of one
> percent orphan rate increase.
> 
> That orphan rate increase will go to whoever is producing the 20MB blocks, NOT you.

There's an interesting incentives question if the mining fees ever become large enough to be interesting. Given two potential blocks on which to build then for the best interests of the system we'd want miners to select the block that confirmed the largest number of transactions since that puts less pressure on the network later. This is at odds with the incentives for our would-be block maker though because the incentive for mining would be to use whichever block left the largest potential fees available; that's generally going to be the smaller of the two.

This, of course, only gets worse as the block reward reduces and fees become the dominant way for miners to be paid (and my hypothesis that eventually this could lead to miners trying to deliberately orphan earlier blocks to "steal" fees because the fixed block reward is no longer the dominant part of their income).

When coupled with the block propagation delay problem increasing the risk of orphan races I'm pretty sure that this actually leads to miners having an incentive to continually mine smaller blocks, and that's aside from the question of whether smaller blocks will push up fees (which also benefits miners). 


Cheers,
Dave


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150531/2622fb5b/attachment.html>

From yifu at coinapex.com  Sun May 31 14:34:21 2015
From: yifu at coinapex.com (Yifu Guo)
Date: Sun, 31 May 2015 10:34:21 -0400
Subject: [Bitcoin-development] Fwd: Block Size Increase Requirements
In-Reply-To: <CAFzgq-zTybEQyGz0nq90u5n5JZcJzxQS_XKaTpr5POJi-tHM6A@mail.gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CAFzgq-xByQ1E_33_m3UpXQFUkGc78HKnA=7XXMshANDuTkNsvA@mail.gmail.com>
	<CABsx9T0kbRe31LMwk499MQUw225f5GGd67GfhXBezHmDqxkioA@mail.gmail.com>
	<CAFzgq-z5WCznGhbOexS0XESNGAVauw45ewEV-1eMij7yDT61=Q@mail.gmail.com>
	<CAFzgq-zTybEQyGz0nq90u5n5JZcJzxQS_XKaTpr5POJi-tHM6A@mail.gmail.com>
Message-ID: <CAHcfU-WfSPCFrX5OwGQCtOEtDTwWBRmN2r5m_Fi3wAsO7eQWUQ@mail.gmail.com>

I will abstain on this wrangle of "when",

Instead I'd like to address some of the network topology health issues
that's been brought up in this debate.

Due to how blocks are being broadcast by miners at the moment, it is not
difficult to find the origin node of these blocks. These more influential
origin nodes are a minority, about <100 out of ~6000, <2%. These data
points are important to certain attack vectors. It is highly recommended
that pools adopt broadcast logic that rotates broadcasting nodes and
increase their node count.. Eloipool has this implanted for those seeking
to adopt/see it in action in the wild.

China is a particular worse-case due to the sporadic nature of their
internet infrastructure, especially connecting from/to outside of gfw, on a
average node-walk I can get up to a 10% difference while I know for a fact
some of the nodes shown to be down are up.

In F2Pool's case, I see 6 replay nodes, I don't know if that's enough or
that's all the nodes F2Pool runs, but it may be beneficial to set up
multi-homing with shadowsocks over mptcp to increase the stability. also
see if you can get a CERNET connection to be part of your rotations since
their backbone is quite good.

comments, question and grievances welcome.

On Sat, May 30, 2015 at 9:31 PM, Chun Wang <1240902 at gmail.com> wrote:

> On Sat, May 30, 2015 at 9:57 PM, Gavin Andresen <gavinandresen at gmail.com>
> wrote:
> >> Bad miners could attack us and the network with artificial
> >> big blocks.
> >
> >
> > How?
> >
> > I ran some simulations, and I could not find a network topology where a
> big
> > miner producing big blocks could cause a loss of profit to another miner
> > (big or small) producing smaller blocks:
> >
> > http://gavinandresen.ninja/are-bigger-blocks-better-for-bigger-miners
> >
> > (the 0.3% advantage I DID find was for the situation where EVERYBODY was
> > producing big blocks).
>
> If someone propagate a 20MB block, it will take at best 6 seconds for
> us to receive to verify it at current configuration, result of one
> percent orphan rate increase. Or, we can mine the next block only on
> the previous block's header, in this case, the network would see many
> more transaction-less blocks.
>
> Our orphan rate is about 0.5% over the past few months. If the network
> floods 20MB blocks, it can be well above 2%. Besides bandwidth, A 20MB
> block could contain an average of 50000 transactions, hundred of
> thousands of sigops, Do you have an estimate how long it takes on the
> submitblock rpccall?
>
> For references, our 30Mbps bandwidth in Beijing costs us 1350 dollars
> per month. We also use Aliyun and Linode cloud services for block
> propagation. As of May 2015, the price is 0.13 U.S. dollars per GB for
> 100Mbps connectivity at Aliyun. For a single cross-border TCP
> connection, it would be certainly far slower than 12.5 MB/s.
>
> I think we can accept 5MB block at most.
>
> (sorry forgot to cc to the mailing list)
>
>
> ------------------------------------------------------------------------------
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>



-- 
*Yifu Guo*
*"Life is an everlasting self-improvement."*
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150531/6cbb311b/attachment.html>

From jtimon at jtimon.cc  Sun May 31 14:46:58 2015
From: jtimon at jtimon.cc (=?UTF-8?B?Sm9yZ2UgVGltw7Nu?=)
Date: Sun, 31 May 2015 16:46:58 +0200
Subject: [Bitcoin-development] Block Size Increase Requirements
In-Reply-To: <CABsx9T3qPiQ+PL3ZNT+QJzw4ALEzKjMjC4=uEKTG+4vVPdXr-g@mail.gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CABsx9T2ysKj5HVbN_7_o33fMehs4KH6E_R583Mt_VPC4gDA0LQ@mail.gmail.com>
	<5568F567.3050608@bluematt.me>
	<CABsx9T3__mHZ_kseRg-w-x2=8v78QJLhe+BWPezv+hpbFCufpw@mail.gmail.com>
	<556A1046.50807@bluematt.me>
	<CABsx9T3qPiQ+PL3ZNT+QJzw4ALEzKjMjC4=uEKTG+4vVPdXr-g@mail.gmail.com>
Message-ID: <CABm2gDoE5kbE2cnFzZPAOZbHMdXBaZG7pB7c6dovj=1unPentw@mail.gmail.com>

On May 30, 2015 10:38 PM, "Gavin Andresen" <gavinandresen at gmail.com> wrote:
>
> Mining is a competitive business, the marginal miner will ALWAYS be going
out of business.
>
> That is completely independent of the block size, block subsidy, or
transaction fees.

No, the later determines who can be profitable.
Here's a thought experiment:

Subsidy is gone, all the block reward comes from fees.
Miner A has great connectivity and mines 20 MB blocks, with an average of
20 btc per block.
Miner B has a connectivity such that 2 MB blocks puts it on a reasonable
orphan rate, so it gets an average of 2 btc per block mined.
But the difficulty is the same for all and it can rise up to miner A
breaking even after energy costs.
Will miner B be profitable with this setup? The answer is no and miner B
will just go out of business. In that sense too, bigger blocks mean more
mining centralization.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150531/c2fce858/attachment.html>

From gavinandresen at gmail.com  Sun May 31 14:47:10 2015
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Sun, 31 May 2015 10:47:10 -0400
Subject: [Bitcoin-development] Fwd: Block Size Increase Requirements
In-Reply-To: <CAHcfU-WfSPCFrX5OwGQCtOEtDTwWBRmN2r5m_Fi3wAsO7eQWUQ@mail.gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CAFzgq-xByQ1E_33_m3UpXQFUkGc78HKnA=7XXMshANDuTkNsvA@mail.gmail.com>
	<CABsx9T0kbRe31LMwk499MQUw225f5GGd67GfhXBezHmDqxkioA@mail.gmail.com>
	<CAFzgq-z5WCznGhbOexS0XESNGAVauw45ewEV-1eMij7yDT61=Q@mail.gmail.com>
	<CAFzgq-zTybEQyGz0nq90u5n5JZcJzxQS_XKaTpr5POJi-tHM6A@mail.gmail.com>
	<CAHcfU-WfSPCFrX5OwGQCtOEtDTwWBRmN2r5m_Fi3wAsO7eQWUQ@mail.gmail.com>
Message-ID: <CABsx9T2A_Q7ebYTiREO8-2z99UHGRX1a+R=+-u8D6H-XfsYQgA@mail.gmail.com>

On Sun, May 31, 2015 at 10:34 AM, Yifu Guo <yifu at coinapex.com> wrote:

> comments, question and grievances welcome.
>

Thanks for chiming in with facts, Yifu!

Do you have any real-world data on latency/bandwidth/cost through the gfw ?
Chung Wang's post was very helpful to get away from hypotheticals to "what
would it actually cost."

-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150531/69330aa7/attachment.html>

From gavinandresen at gmail.com  Sun May 31 14:49:02 2015
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Sun, 31 May 2015 10:49:02 -0400
Subject: [Bitcoin-development] Block Size Increase Requirements
In-Reply-To: <CABm2gDoE5kbE2cnFzZPAOZbHMdXBaZG7pB7c6dovj=1unPentw@mail.gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CABsx9T2ysKj5HVbN_7_o33fMehs4KH6E_R583Mt_VPC4gDA0LQ@mail.gmail.com>
	<5568F567.3050608@bluematt.me>
	<CABsx9T3__mHZ_kseRg-w-x2=8v78QJLhe+BWPezv+hpbFCufpw@mail.gmail.com>
	<556A1046.50807@bluematt.me>
	<CABsx9T3qPiQ+PL3ZNT+QJzw4ALEzKjMjC4=uEKTG+4vVPdXr-g@mail.gmail.com>
	<CABm2gDoE5kbE2cnFzZPAOZbHMdXBaZG7pB7c6dovj=1unPentw@mail.gmail.com>
Message-ID: <CABsx9T0SVW9ASBH=Xyet5EKQtjAoJ7nLpAab5_yLQdUo=QpV7w@mail.gmail.com>

On Sun, May 31, 2015 at 10:46 AM, Jorge Tim?n <jtimon at jtimon.cc> wrote:

> Here's a thought experiment:
>
> Subsidy is gone, all the block reward comes from fees.
>
I wrote about long-term hypotheticals and why I think it is a big mistake
to waste time worrying about them here:
   http://gavinandresen.ninja/when-the-block-reward-goes-away


-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150531/0360b568/attachment.html>

From gavinandresen at gmail.com  Sun May 31 14:54:10 2015
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Sun, 31 May 2015 10:54:10 -0400
Subject: [Bitcoin-development] Fwd: Block Size Increase Requirements
In-Reply-To: <CAE28kUT61qYxqV0mOqw5Dan=eMiCvnG2SnsAeWzOWTxwLydyeQ@mail.gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CAFzgq-xByQ1E_33_m3UpXQFUkGc78HKnA=7XXMshANDuTkNsvA@mail.gmail.com>
	<CABsx9T0kbRe31LMwk499MQUw225f5GGd67GfhXBezHmDqxkioA@mail.gmail.com>
	<CAFzgq-z5WCznGhbOexS0XESNGAVauw45ewEV-1eMij7yDT61=Q@mail.gmail.com>
	<CAFzgq-zTybEQyGz0nq90u5n5JZcJzxQS_XKaTpr5POJi-tHM6A@mail.gmail.com>
	<CABsx9T2L5bi-c63-KqSifOMeNayUWSPo0_Hx8VjMR_4=kC3ixg@mail.gmail.com>
	<CAE28kUT61qYxqV0mOqw5Dan=eMiCvnG2SnsAeWzOWTxwLydyeQ@mail.gmail.com>
Message-ID: <CABsx9T2hfpts5y_M6PdDcxmq9Q2smesJ0Nmp9a9iyPD_MoPC9g@mail.gmail.com>

On Sun, May 31, 2015 at 9:45 AM, Alex Mizrahi <alex.mizrahi at gmail.com>
wrote:

>
>
>> That orphan rate increase will go to whoever is producing the 20MB
>> blocks, NOT you.
>>
>
> This depends on how miners are connected.
>
> E.g. suppose there are three miners, A and B have fast connectivity
> between then, and C has a slow network.
> Suppose that A miners a block and B receives it in 1 second. C receives it
> in 6 seconds.
> This means that blocks mined by C during these ~5 seconds will be orphaned
> because B gets A's block first.
>

Yes, if you are on a slow network then you are at a (slight) disadvantage.
So?

There are lots of equations that go into the "is mining profitable"
equation: cost of power, Internet cost and connectivity, cost of capital,
access to technology other miners don't have, inexpensive labor or rent,
inexpensive cooling, ability to use waste heat...

That's good. An equation with lots of variables has lots of different
maximum solutions, and that means better decentralization -- there is less
likely to be one perfect place or way to mine.

-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150531/11fb2d62/attachment.html>

From jtimon at jtimon.cc  Sun May 31 14:59:45 2015
From: jtimon at jtimon.cc (=?UTF-8?B?Sm9yZ2UgVGltw7Nu?=)
Date: Sun, 31 May 2015 16:59:45 +0200
Subject: [Bitcoin-development] Block Size Increase Requirements
In-Reply-To: <CABsx9T0SVW9ASBH=Xyet5EKQtjAoJ7nLpAab5_yLQdUo=QpV7w@mail.gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CABsx9T2ysKj5HVbN_7_o33fMehs4KH6E_R583Mt_VPC4gDA0LQ@mail.gmail.com>
	<5568F567.3050608@bluematt.me>
	<CABsx9T3__mHZ_kseRg-w-x2=8v78QJLhe+BWPezv+hpbFCufpw@mail.gmail.com>
	<556A1046.50807@bluematt.me>
	<CABsx9T3qPiQ+PL3ZNT+QJzw4ALEzKjMjC4=uEKTG+4vVPdXr-g@mail.gmail.com>
	<CABm2gDoE5kbE2cnFzZPAOZbHMdXBaZG7pB7c6dovj=1unPentw@mail.gmail.com>
	<CABsx9T0SVW9ASBH=Xyet5EKQtjAoJ7nLpAab5_yLQdUo=QpV7w@mail.gmail.com>
Message-ID: <CABm2gDr4G7V5OLfiFq0onGNb3HCWHk9K46FtVcLOVetvxiLqRg@mail.gmail.com>

Whatever...let's use the current subsidies, the same argument applies, it's
just 20 + 25 = 45 btc per block for miner B vs 27 btc for miner B.
Miner B would still go out of business, bigger blocks still mean more
mining and validation centralization. The question is how far I we willing
to go with this "scaling by sacrificing decentralization", but the answer
can't be "that's to far away in the future to worry about it, right now as
far as we think we can using orphan rate as the only criterion".
On May 31, 2015 4:49 PM, "Gavin Andresen" <gavinandresen at gmail.com> wrote:

> On Sun, May 31, 2015 at 10:46 AM, Jorge Tim?n <jtimon at jtimon.cc> wrote:
>
>> Here's a thought experiment:
>>
>> Subsidy is gone, all the block reward comes from fees.
>>
> I wrote about long-term hypotheticals and why I think it is a big mistake
> to waste time worrying about them here:
>    http://gavinandresen.ninja/when-the-block-reward-goes-away
>
>
> --
> --
> Gavin Andresen
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150531/b880d9d2/attachment.html>

From gavinandresen at gmail.com  Sun May 31 15:08:12 2015
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Sun, 31 May 2015 11:08:12 -0400
Subject: [Bitcoin-development] Block Size Increase Requirements
In-Reply-To: <CABm2gDr4G7V5OLfiFq0onGNb3HCWHk9K46FtVcLOVetvxiLqRg@mail.gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CABsx9T2ysKj5HVbN_7_o33fMehs4KH6E_R583Mt_VPC4gDA0LQ@mail.gmail.com>
	<5568F567.3050608@bluematt.me>
	<CABsx9T3__mHZ_kseRg-w-x2=8v78QJLhe+BWPezv+hpbFCufpw@mail.gmail.com>
	<556A1046.50807@bluematt.me>
	<CABsx9T3qPiQ+PL3ZNT+QJzw4ALEzKjMjC4=uEKTG+4vVPdXr-g@mail.gmail.com>
	<CABm2gDoE5kbE2cnFzZPAOZbHMdXBaZG7pB7c6dovj=1unPentw@mail.gmail.com>
	<CABsx9T0SVW9ASBH=Xyet5EKQtjAoJ7nLpAab5_yLQdUo=QpV7w@mail.gmail.com>
	<CABm2gDr4G7V5OLfiFq0onGNb3HCWHk9K46FtVcLOVetvxiLqRg@mail.gmail.com>
Message-ID: <CABsx9T3_MVw6WBv8b35E0+NdJreRTbHHbweckdO=XZu4LRcOEQ@mail.gmail.com>

On Sun, May 31, 2015 at 10:59 AM, Jorge Tim?n <jtimon at jtimon.cc> wrote:

> Whatever...let's use the current subsidies, the same argument applies,
> it's just 20 + 25 = 45 btc per block for miner B vs 27 btc for miner B.
> Miner B would still go out of business, bigger blocks still mean more
> mining and validation centralization
>
Sorry, but that's ridiculous.

If Miner B is leaving 18BTC per block on the table because they have bad
connectivity, then they need to pay for better connectivity.

If you are arguing "I should be able to mine on a 56K modem connection from
the middle of the Sahara" then we're going to have to agree to disagree.

So: what is your specific proposal for minimum requirements for
connectivity to run a full node? The 20MB number comes from estimating
costs to run a full node, and as my back-and-forth to Chang Wung shows, the
costs are not excessive.

-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150531/08d60b07/attachment.html>

From jtimon at jtimon.cc  Sun May 31 15:45:01 2015
From: jtimon at jtimon.cc (=?UTF-8?B?Sm9yZ2UgVGltw7Nu?=)
Date: Sun, 31 May 2015 17:45:01 +0200
Subject: [Bitcoin-development] Block Size Increase Requirements
In-Reply-To: <CABsx9T3_MVw6WBv8b35E0+NdJreRTbHHbweckdO=XZu4LRcOEQ@mail.gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CABsx9T2ysKj5HVbN_7_o33fMehs4KH6E_R583Mt_VPC4gDA0LQ@mail.gmail.com>
	<5568F567.3050608@bluematt.me>
	<CABsx9T3__mHZ_kseRg-w-x2=8v78QJLhe+BWPezv+hpbFCufpw@mail.gmail.com>
	<556A1046.50807@bluematt.me>
	<CABsx9T3qPiQ+PL3ZNT+QJzw4ALEzKjMjC4=uEKTG+4vVPdXr-g@mail.gmail.com>
	<CABm2gDoE5kbE2cnFzZPAOZbHMdXBaZG7pB7c6dovj=1unPentw@mail.gmail.com>
	<CABsx9T0SVW9ASBH=Xyet5EKQtjAoJ7nLpAab5_yLQdUo=QpV7w@mail.gmail.com>
	<CABm2gDr4G7V5OLfiFq0onGNb3HCWHk9K46FtVcLOVetvxiLqRg@mail.gmail.com>
	<CABsx9T3_MVw6WBv8b35E0+NdJreRTbHHbweckdO=XZu4LRcOEQ@mail.gmail.com>
Message-ID: <CABm2gDobPy+j4+7F=boUG4DkbzOUwcWTT2iPorCiptFwgE3yJw@mail.gmail.com>

On May 31, 2015 5:08 PM, "Gavin Andresen" <gavinandresen at gmail.com> wrote:
>
> On Sun, May 31, 2015 at 10:59 AM, Jorge Tim?n <jtimon at jtimon.cc> wrote:
>>
>> Whatever...let's use the current subsidies, the same argument applies,
it's just 20 + 25 = 45 btc per block for miner B vs 27 btc for miner B.
>> Miner B would still go out of business, bigger blocks still mean more
mining and validation centralization
>
> Sorry, but that's ridiculous.
>
> If Miner B is leaving 18BTC per block on the table because they have bad
connectivity, then they need to pay for better connectivity.

Well, I was assuming they just can't upgrade their connection (without
moving thei operations to another place). Maybe that assumption is
ridiculous as well.

> If you are arguing "I should be able to mine on a 56K modem connection
from the middle of the Sahara" then we're going to have to agree to
disagree.

No, I'm not suggesting that.

> So: what is your specific proposal for minimum requirements for
connectivity to run a full node? The 20MB number comes from estimating
costs to run a full node, and as my back-and-forth to Chang Wung shows, the
costs are not excessive.

Well, you were I think assuming a new desktop connecting from somewhere in
the US. I would be more confortable with an eee pc from a hotel in India,
for example. But yeah, targeting some concrete minimum specs seems like the
right approach for deciding "how far to go when increasing centralization".

But "hitting the limit will be chaos" seems to imply that completely
removing the consensus maximum blocksize is the only logical solution. What
happens when we hit the limit next time? When do we stop kicking the can
down the road? When do we voluntarily get that "chaos"?
Again, "that's too far away in the future to worry about it" is not a very
conving answer to me.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150531/009b8b53/attachment.html>

From stephencalebmorse at gmail.com  Sun May 31 19:04:32 2015
From: stephencalebmorse at gmail.com (Stephen Morse)
Date: Sun, 31 May 2015 15:04:32 -0400
Subject: [Bitcoin-development] Max Block Size: Simple Voting Procedure
Message-ID: <CABHVRKSFV_dXZeLnhBLfRK=wrBFsRH5kFBZqwECh-LyCkwrmtQ@mail.gmail.com>

This is likely very similar to other proposals, but I want to bring voting
procedures back into the discussion. The goal here is to create a voting
procedure that is as simple as possible to increase the block size limit.

Votes are aggregated over each 2016 block period. Each coinbase transaction
may have an output at tx.vout[0] with OP_RETURN data in it of the format:

  OP_RETURN {OP_1 or OP_2}

OP_2 means the miner votes to increase the block size limit. OP_1 means the
miner votes to not increase the block size limit. *Not including such a
vote is equivalent to voting to NOT increase the block size. *I first
thought that not voting should mean that you vote with your block size, but
then decided that it would be too gameable by others broadcasting
transactions to affect your block size.

If in a 2016 block round there were more than 1008 blocks that voted to
increase the block size limit, then the max block size increases by 500 kb.
The votes can start when there is a supermajority of miners signaling
support for the voting procedure.

A few important properties of this simple voting:

   - It's not gameable via broadcasting transactions (assuming miners don't
   set their votes to be automatic, based on the size of recent blocks).
   - Miners don't have to bloat their blocks artificially just to place a
   vote for larger block sizes, and, similarly, don't need to exclude
   transactions even when they think the block size does not need to be raised.
   - The chain up until the point that this goes into effect may be
   interpreted as just lacking votes to increase the block size.

We can't trust all miners, but we have to trust that >50% of them are
honest for the system to work. This system makes it so that altering the
maximum block size requires >50% of miners (hash power) to vote to increase
the consensus-limit.

Thanks for your time. I think this is an important time in Bitcoin's
history. I'm not married to this proposal, but I think it would work. I
think a lot of the proposals mentioned on this mailing list would work. I
think it's time we just pick one and run with it.

Please let me know your thoughts. I will start working on a pull request if
this receives any support from miners/core devs/community members, unless
someone with more experience volunteers.

Best,
Stephen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150531/eaca8eaa/attachment.html>

From gavinandresen at gmail.com  Sun May 31 19:49:05 2015
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Sun, 31 May 2015 15:49:05 -0400
Subject: [Bitcoin-development] [Bulk] Re: Fwd: Block Size Increase
	Requirements
In-Reply-To: <1433079085.5422.10.camel@yahoo.com>
References: <554BE0E1.5030001@bluematt.me>
	<CAFzgq-xByQ1E_33_m3UpXQFUkGc78HKnA=7XXMshANDuTkNsvA@mail.gmail.com>
	<CABsx9T0kbRe31LMwk499MQUw225f5GGd67GfhXBezHmDqxkioA@mail.gmail.com>
	<CAFzgq-z5WCznGhbOexS0XESNGAVauw45ewEV-1eMij7yDT61=Q@mail.gmail.com>
	<CAFzgq-zTybEQyGz0nq90u5n5JZcJzxQS_XKaTpr5POJi-tHM6A@mail.gmail.com>
	<CABsx9T37jE3AtmUOOuW+emLGTparbS6OozPRL_hCrC+2JEzxgQ@mail.gmail.com>
	<1433079085.5422.10.camel@yahoo.com>
Message-ID: <CABsx9T3UXCeh_-5bpKiF53+9LrufN596LnFyRq4fqN7PcVq7jg@mail.gmail.com>

On Sun, May 31, 2015 at 9:31 AM, gb <kiwigb at yahoo.com> wrote:

> Aren't you calculating bandwidth for a singly-connected node? A "highly
> connected" miner could have 30-100 node connections so you probably need
> to increase your traffic estimates by that factor.
>
> I.e. For 100MB blocks, 30-100 Mbps and $60-$100 per day data costs.
>

No, randomly connected gossip networks (which is what the Bitcoin p2p
network is) don't work that way, bandwidth is (roughly) O(N) where N is the
number of bytes relayed to everybody.

(it is actually a small multiple of N, because of the overhead of 'inv'
messages, and if we ever get really serious about scaling up we'll need to
fix the protocol to reduce that overhead, but that won't be a problem for
years).


-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150531/a4940550/attachment.html>

From alex.mizrahi at gmail.com  Sun May 31 22:55:06 2015
From: alex.mizrahi at gmail.com (Alex Mizrahi)
Date: Mon, 1 Jun 2015 01:55:06 +0300
Subject: [Bitcoin-development] Fwd: Block Size Increase Requirements
In-Reply-To: <CABsx9T2hfpts5y_M6PdDcxmq9Q2smesJ0Nmp9a9iyPD_MoPC9g@mail.gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CAFzgq-xByQ1E_33_m3UpXQFUkGc78HKnA=7XXMshANDuTkNsvA@mail.gmail.com>
	<CABsx9T0kbRe31LMwk499MQUw225f5GGd67GfhXBezHmDqxkioA@mail.gmail.com>
	<CAFzgq-z5WCznGhbOexS0XESNGAVauw45ewEV-1eMij7yDT61=Q@mail.gmail.com>
	<CAFzgq-zTybEQyGz0nq90u5n5JZcJzxQS_XKaTpr5POJi-tHM6A@mail.gmail.com>
	<CABsx9T2L5bi-c63-KqSifOMeNayUWSPo0_Hx8VjMR_4=kC3ixg@mail.gmail.com>
	<CAE28kUT61qYxqV0mOqw5Dan=eMiCvnG2SnsAeWzOWTxwLydyeQ@mail.gmail.com>
	<CABsx9T2hfpts5y_M6PdDcxmq9Q2smesJ0Nmp9a9iyPD_MoPC9g@mail.gmail.com>
Message-ID: <CAE28kUTZV3YsaSCX2d5YwLetnf=f+bOWGrwxLXdZFywTZ=+Pjg@mail.gmail.com>

>
> Yes, if you are on a slow network then you are at a (slight) disadvantage.
> So?
>

Chun mentioned that his pool is on a slow network, and thus bigger blocks
give it an disadvantage. (Orphan rate is proportional to block size.)
You said that no, on contrary those who make big blocks have a disadvantage.
And now you say that yes, this disadvantage exist.

Did you just lie to Chun?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150601/28766322/attachment.html>

From ricardojdfilipe at gmail.com  Sun May 31 23:23:23 2015
From: ricardojdfilipe at gmail.com (Ricardo Filipe)
Date: Mon, 1 Jun 2015 00:23:23 +0100
Subject: [Bitcoin-development] Fwd: Block Size Increase Requirements
In-Reply-To: <CAE28kUTZV3YsaSCX2d5YwLetnf=f+bOWGrwxLXdZFywTZ=+Pjg@mail.gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CAFzgq-xByQ1E_33_m3UpXQFUkGc78HKnA=7XXMshANDuTkNsvA@mail.gmail.com>
	<CABsx9T0kbRe31LMwk499MQUw225f5GGd67GfhXBezHmDqxkioA@mail.gmail.com>
	<CAFzgq-z5WCznGhbOexS0XESNGAVauw45ewEV-1eMij7yDT61=Q@mail.gmail.com>
	<CAFzgq-zTybEQyGz0nq90u5n5JZcJzxQS_XKaTpr5POJi-tHM6A@mail.gmail.com>
	<CABsx9T2L5bi-c63-KqSifOMeNayUWSPo0_Hx8VjMR_4=kC3ixg@mail.gmail.com>
	<CAE28kUT61qYxqV0mOqw5Dan=eMiCvnG2SnsAeWzOWTxwLydyeQ@mail.gmail.com>
	<CABsx9T2hfpts5y_M6PdDcxmq9Q2smesJ0Nmp9a9iyPD_MoPC9g@mail.gmail.com>
	<CAE28kUTZV3YsaSCX2d5YwLetnf=f+bOWGrwxLXdZFywTZ=+Pjg@mail.gmail.com>
Message-ID: <CALC81CNq-GK5q6R4bmgHL5_Ej2+cZrtQMMLVmuhvMxkZokM3hQ@mail.gmail.com>

He also said that the equation for miners has many variables, as it
should. There is no disadvantage if the network speed is the same
between the miners. If there is a difference in network speed, the
miner is incentivized to invest in their network infrastructure.

2015-05-31 23:55 GMT+01:00 Alex Mizrahi <alex.mizrahi at gmail.com>:
>> Yes, if you are on a slow network then you are at a (slight) disadvantage.
>> So?
>
>
> Chun mentioned that his pool is on a slow network, and thus bigger blocks
> give it an disadvantage. (Orphan rate is proportional to block size.)
> You said that no, on contrary those who make big blocks have a disadvantage.
> And now you say that yes, this disadvantage exist.
>
> Did you just lie to Chun?
>
>
> ------------------------------------------------------------------------------
>
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>



From pindar.wong at gmail.com  Sun May 31 23:40:30 2015
From: pindar.wong at gmail.com (Pindar Wong)
Date: Mon, 1 Jun 2015 07:40:30 +0800
Subject: [Bitcoin-development] Fwd: Block Size Increase Requirements
In-Reply-To: <CALC81CNq-GK5q6R4bmgHL5_Ej2+cZrtQMMLVmuhvMxkZokM3hQ@mail.gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CAFzgq-xByQ1E_33_m3UpXQFUkGc78HKnA=7XXMshANDuTkNsvA@mail.gmail.com>
	<CABsx9T0kbRe31LMwk499MQUw225f5GGd67GfhXBezHmDqxkioA@mail.gmail.com>
	<CAFzgq-z5WCznGhbOexS0XESNGAVauw45ewEV-1eMij7yDT61=Q@mail.gmail.com>
	<CAFzgq-zTybEQyGz0nq90u5n5JZcJzxQS_XKaTpr5POJi-tHM6A@mail.gmail.com>
	<CABsx9T2L5bi-c63-KqSifOMeNayUWSPo0_Hx8VjMR_4=kC3ixg@mail.gmail.com>
	<CAE28kUT61qYxqV0mOqw5Dan=eMiCvnG2SnsAeWzOWTxwLydyeQ@mail.gmail.com>
	<CABsx9T2hfpts5y_M6PdDcxmq9Q2smesJ0Nmp9a9iyPD_MoPC9g@mail.gmail.com>
	<CAE28kUTZV3YsaSCX2d5YwLetnf=f+bOWGrwxLXdZFywTZ=+Pjg@mail.gmail.com>
	<CALC81CNq-GK5q6R4bmgHL5_Ej2+cZrtQMMLVmuhvMxkZokM3hQ@mail.gmail.com>
Message-ID: <CAM7BtUr3msGfp_XiBc-D6=G+b834YhnxVQ_d59EJUE=avxpL1g@mail.gmail.com>

On Mon, Jun 1, 2015 at 7:23 AM, Ricardo Filipe <ricardojdfilipe at gmail.com>
wrote:

> He also said that the equation for miners has many variables, as it
> should. There is no disadvantage if the network speed is the same
> between the miners.


Hi,

Is that an assumption?

If there is a difference in network speed, the
> miner is incentivized to invest in their network infrastructure.
>

Perhaps it's best not to  assume that investing in Internet network
infrastructure's a free or open market everywhere.

p.


>
> 2015-05-31 23:55 GMT+01:00 Alex Mizrahi <alex.mizrahi at gmail.com>:
> >> Yes, if you are on a slow network then you are at a (slight)
> disadvantage.
> >> So?
> >
> >
> > Chun mentioned that his pool is on a slow network, and thus bigger blocks
> > give it an disadvantage. (Orphan rate is proportional to block size.)
> > You said that no, on contrary those who make big blocks have a
> disadvantage.
> > And now you say that yes, this disadvantage exist.
> >
> > Did you just lie to Chun?
> >
> >
> >
> ------------------------------------------------------------------------------
> >
> > _______________________________________________
> > Bitcoin-development mailing list
> > Bitcoin-development at lists.sourceforge.net
> > https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> >
>
>
> ------------------------------------------------------------------------------
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150601/913e7526/attachment.html>

From ricardojdfilipe at gmail.com  Sun May 31 23:58:13 2015
From: ricardojdfilipe at gmail.com (Ricardo Filipe)
Date: Mon, 1 Jun 2015 00:58:13 +0100
Subject: [Bitcoin-development] Fwd: Block Size Increase Requirements
In-Reply-To: <CAM7BtUr3msGfp_XiBc-D6=G+b834YhnxVQ_d59EJUE=avxpL1g@mail.gmail.com>
References: <554BE0E1.5030001@bluematt.me>
	<CAFzgq-xByQ1E_33_m3UpXQFUkGc78HKnA=7XXMshANDuTkNsvA@mail.gmail.com>
	<CABsx9T0kbRe31LMwk499MQUw225f5GGd67GfhXBezHmDqxkioA@mail.gmail.com>
	<CAFzgq-z5WCznGhbOexS0XESNGAVauw45ewEV-1eMij7yDT61=Q@mail.gmail.com>
	<CAFzgq-zTybEQyGz0nq90u5n5JZcJzxQS_XKaTpr5POJi-tHM6A@mail.gmail.com>
	<CABsx9T2L5bi-c63-KqSifOMeNayUWSPo0_Hx8VjMR_4=kC3ixg@mail.gmail.com>
	<CAE28kUT61qYxqV0mOqw5Dan=eMiCvnG2SnsAeWzOWTxwLydyeQ@mail.gmail.com>
	<CABsx9T2hfpts5y_M6PdDcxmq9Q2smesJ0Nmp9a9iyPD_MoPC9g@mail.gmail.com>
	<CAE28kUTZV3YsaSCX2d5YwLetnf=f+bOWGrwxLXdZFywTZ=+Pjg@mail.gmail.com>
	<CALC81CNq-GK5q6R4bmgHL5_Ej2+cZrtQMMLVmuhvMxkZokM3hQ@mail.gmail.com>
	<CAM7BtUr3msGfp_XiBc-D6=G+b834YhnxVQ_d59EJUE=avxpL1g@mail.gmail.com>
Message-ID: <CALC81CMR_9KsCa4rr-YbVtXLLA81Sn1RtgUEuaaj5qgPUHUUuw@mail.gmail.com>

2015-06-01 0:40 GMT+01:00 Pindar Wong <pindar.wong at gmail.com>:
>
>
> On Mon, Jun 1, 2015 at 7:23 AM, Ricardo Filipe <ricardojdfilipe at gmail.com>
> wrote:
>>
>> He also said that the equation for miners has many variables, as it
>> should. There is no disadvantage if the network speed is the same
>> between the miners.
>
>
> Hi,
>
> Is that an assumption?
no, let me rephrase: The disadvantage alex refers to only exists if
miners do not have the same network speed.

>
>> If there is a difference in network speed, the
>> miner is incentivized to invest in their network infrastructure.
>
>
> Perhaps it's best not to  assume that investing in Internet network
> infrastructure's a free or open market everywhere.
Just like easy ASIC access, low price electricity, etc are not a free
and open market.

>
> p.
>
>>
>>
>> 2015-05-31 23:55 GMT+01:00 Alex Mizrahi <alex.mizrahi at gmail.com>:
>> >> Yes, if you are on a slow network then you are at a (slight)
>> >> disadvantage.
>> >> So?
>> >
>> >
>> > Chun mentioned that his pool is on a slow network, and thus bigger
>> > blocks
>> > give it an disadvantage. (Orphan rate is proportional to block size.)
>> > You said that no, on contrary those who make big blocks have a
>> > disadvantage.
>> > And now you say that yes, this disadvantage exist.
>> >
>> > Did you just lie to Chun?
>> >
>> >
>> >
>> > ------------------------------------------------------------------------------
>> >
>> > _______________________________________________
>> > Bitcoin-development mailing list
>> > Bitcoin-development at lists.sourceforge.net
>> > https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>> >
>>
>>
>> ------------------------------------------------------------------------------
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>



