From mark at friedenbach.org  Wed Nov  1 01:46:54 2017
From: mark at friedenbach.org (Mark Friedenbach)
Date: Tue, 31 Oct 2017 18:46:54 -0700
Subject: [bitcoin-dev] Simplicity: An alternative to Script
In-Reply-To: <CAMZUoKmNEaTEoHV6cWOdLR=G9XiqTQ9AmHhyxegVEEmXVhU+7w@mail.gmail.com>
References: <CAMZUoK=VNRMda8oRCtxniE6-vLwG-b=je2Hx+sD9sCzS--v9kQ@mail.gmail.com>
	<E63C347E-5321-4F7F-B69C-75747E88AC06@mattcorallo.com>
	<CAMZUoKmos5BMkFNsmNnTJhryfho_0fGhSKDQ82D6SPjPBhvd0A@mail.gmail.com>
	<CAOG=w-vsTCTNW9x5TCHChN6_13pAabWjDQ30Eoo4xQduJ01fdQ@mail.gmail.com>
	<CAMZUoKmNEaTEoHV6cWOdLR=G9XiqTQ9AmHhyxegVEEmXVhU+7w@mail.gmail.com>
Message-ID: <5E7A6643-C478-44EC-BC54-404D86D1D151@friedenbach.org>

I don?t think you need to set an order of operations, just treat the jet as TRUE, but don?t stop validation. Order of operations doesn?t matter. Either way it?ll execute both branches and terminate of the understood conditions don?t hold.

But maybe I?m missing something here. 

> On Oct 31, 2017, at 2:01 PM, Russell O'Connor <roconnor at blockstream.io> wrote:
> 
> That approach is worth considering.  However there is a wrinkle that Simplicity's denotational semantics doesn't imply an order of operations.  For example, if one half of a pair contains a assertion failure (fail-closed), and the other half contains a unknown jet (fail-open), then does the program succeed or fail?
> 
> This could be solved by providing an order of operations; however I fear that will complicate formal reasoning about Simplicity expressions.  Formal reasoning is hard enough as is and I hesitate to complicate the semantics in ways that make formal reasoning harder still.
> 
> 
> On Oct 31, 2017 15:47, "Mark Friedenbach" <mark at friedenbach.org> wrote:
> Nit, but if you go down that specific path I would suggest making just
> the jet itself fail-open. That way you are not so limited in requiring
> validation of the full contract -- one party can verify simply that
> whatever condition they care about holds on reaching that part of the
> contract. E.g. maybe their signature is needed at the top level, and
> then they don't care what further restrictions are placed.
> 
> On Tue, Oct 31, 2017 at 1:38 PM, Russell O'Connor via bitcoin-dev
> <bitcoin-dev at lists.linuxfoundation.org> wrote:
> > (sorry, I forgot to reply-all earlier)
> >
> > The very short answer to this question is that I plan on using Luke's
> > fail-success-on-unknown-operation in Simplicity.  This is something that
> > isn't detailed at all in the paper.
> >
> > The plan is that discounted jets will be explicitly labeled as jets in the
> > commitment.  If you can provide a Merkle path from the root to a node that
> > is an explicit jet, but that jet isn't among the finite number of known
> > discounted jets, then the script is automatically successful (making it
> > anyone-can-spend).  When new jets are wanted they can be soft-forked into
> > the protocol (for example if we get a suitable quantum-resistant digital
> > signature scheme) and the list of known discounted jets grows.  Old nodes
> > get a merkle path to the new jet, which they view as an unknown jet, and
> > allow the transaction as a anyone-can-spend transaction.  New nodes see a
> > regular Simplicity redemption.  (I haven't worked out the details of how the
> > P2P protocol will negotiate with old nodes, but I don't forsee any
> > problems.)
> >
> > Note that this implies that you should never participate in any Simplicity
> > contract where you don't get access to the entire source code of all
> > branches to check that it doesn't have an unknown jet.
> >
> > On Mon, Oct 30, 2017 at 5:42 PM, Matt Corallo <lf-lists at mattcorallo.com>
> > wrote:
> >>
> >> I admittedly haven't had a chance to read the paper in full details, but I
> >> was curious how you propose dealing with "jets" in something like Bitcoin.
> >> AFAIU, other similar systems are left doing hard-forks to reduce the
> >> sigops/weight/fee-cost of transactions every time they want to add useful
> >> optimized drop-ins. For obvious reasons, this seems rather impractical and a
> >> potentially critical barrier to adoption of such optimized drop-ins, which I
> >> imagine would be required to do any new cryptographic algorithms due to the
> >> significant fee cost of interpreting such things.
> >>
> >> Is there some insight I'm missing here?
> >>
> >> Matt
> >>
> >>
> >> On October 30, 2017 11:22:20 AM EDT, Russell O'Connor via bitcoin-dev
> >> <bitcoin-dev at lists.linuxfoundation.org> wrote:
> >>>
> >>> I've been working on the design and implementation of an alternative to
> >>> Bitcoin Script, which I call Simplicity.  Today, I am presenting my design
> >>> at the PLAS 2017 Workshop on Programming Languages and Analysis for
> >>> Security.  You find a copy of my Simplicity paper at
> >>> https://blockstream.com/simplicity.pdf
> >>>
> >>> Simplicity is a low-level, typed, functional, native MAST language where
> >>> programs are built from basic combinators.  Like Bitcoin Script, Simplicity
> >>> is designed to operate at the consensus layer.  While one can write
> >>> Simplicity by hand, it is expected to be the target of one, or multiple,
> >>> front-end languages.
> >>>
> >>> Simplicity comes with formal denotational semantics (i.e. semantics of
> >>> what programs compute) and formal operational semantics (i.e. semantics of
> >>> how programs compute). These are both formalized in the Coq proof assistant
> >>> and proven equivalent.
> >>>
> >>> Formal denotational semantics are of limited value unless one can use
> >>> them in practice to reason about programs. I've used Simplicity's formal
> >>> semantics to prove correct an implementation of the SHA-256 compression
> >>> function written in Simplicity.  I have also implemented a variant of ECDSA
> >>> signature verification in Simplicity, and plan to formally validate its
> >>> correctness along with the associated elliptic curve operations.
> >>>
> >>> Simplicity comes with easy to compute static analyses that can compute
> >>> bounds on the space and time resources needed for evaluation.  This is
> >>> important for both node operators, so that the costs are knows before
> >>> evaluation, and for designing Simplicity programs, so that smart-contract
> >>> participants can know the costs of their contract before committing to it.
> >>>
> >>> As a native MAST language, unused branches of Simplicity programs are
> >>> pruned at redemption time.  This enhances privacy, reduces the block weight
> >>> used, and can reduce space and time resource costs needed for evaluation.
> >>>
> >>> To make Simplicity practical, jets replace common Simplicity expressions
> >>> (identified by their MAST root) and directly implement them with C code.  I
> >>> anticipate developing a broad set of useful jets covering arithmetic
> >>> operations, elliptic curve operations, and cryptographic operations
> >>> including hashing and digital signature validation.
> >>>
> >>> The paper I am presenting at PLAS describes only the foundation of the
> >>> Simplicity language.  The final design includes extensions not covered in
> >>> the paper, including
> >>>
> >>> - full convent support, allowing access to all transaction data.
> >>> - support for signature aggregation.
> >>> - support for delegation.
> >>>
> >>> Simplicity is still in a research and development phase.  I'm working to
> >>> produce a bare-bones SDK that will include
> >>>
> >>> - the formal semantics and correctness proofs in Coq
> >>> - a Haskell implementation for constructing Simplicity programs
> >>> - and a C interpreter for Simplicity.
> >>>
> >>> After an SDK is complete the next step will be making Simplicity
> >>> available in the Elements project so that anyone can start experimenting
> >>> with Simplicity in sidechains. Only after extensive vetting would it be
> >>> suitable to consider Simplicity for inclusion in Bitcoin.
> >>>
> >>> Simplicity has a long ways to go still, and this work is not intended to
> >>> delay consideration of the various Merkelized Script proposals that are
> >>> currently ongoing.
> >
> >
> >
> > _______________________________________________
> > bitcoin-dev mailing list
> > bitcoin-dev at lists.linuxfoundation.org
> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> >
> 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171031/d72ca20a/attachment.html>

From karljohan-alm at garage.co.jp  Wed Nov  1 03:36:07 2017
From: karljohan-alm at garage.co.jp (Karl Johan Alm)
Date: Wed, 1 Nov 2017 12:36:07 +0900
Subject: [bitcoin-dev] Mempool optimized fees, etc. (Scaling Bitcoin)
Message-ID: <CALJw2w5qacB3ezQq=Ca8ZheYvBw06ROMFSZZ=ZVYf9+sHmKA_A@mail.gmail.com>

This is the paper detailing the research behind my talk "Optimizing
fee estimation via the mempool state" (the presentation only covers
part of the paper) at Scaling Stanford (this coming Sunday). Feedback
welcome.

https://bc-2.jp/mempool.pdf

From luke at dashjr.org  Wed Nov  1 08:43:48 2017
From: luke at dashjr.org (Luke Dashjr)
Date: Wed, 1 Nov 2017 08:43:48 +0000
Subject: [bitcoin-dev] Merkle branch verification & tail-call semantics
	for generalized MAST
In-Reply-To: <3FE16880-868C-40BA-BCC5-954B15478FB2@friedenbach.org>
References: <5B6756D0-6BEF-4A01-BDB8-52C646916E29@friedenbach.org>
	<3FE16880-868C-40BA-BCC5-954B15478FB2@friedenbach.org>
Message-ID: <201711010843.49771.luke@dashjr.org>

Mark,

I think I have found an improvement that can be made.

As you recall, a downside to this approach is that one must make two 
commitments: first, to the particular "membership-checking script"; and then 
in that script, to the particular merkle root of possible scripts.

Would there be any harm in, instead of checking membership, *calculating* the 
root? If not, then we could define that instead of the witness program 
committing to H(membership-check script), it rather commits to H(membership-
calculation script | data added by an OP_ADDTOSCRIPTHASH). This would, I 
believe, securely reduce the commitment of both to a single hash.

It also doesn't reduce flexibility, since one could omit OP_ADDTOSCRIPTHASH 
from their "membership-calculation" script to get the previous membership-
check behaviour, and use <hash> OP_EQUAL in its place.

What do you think?

Luke


On Saturday 28 October 2017 4:40:01 AM Mark Friedenbach wrote:
> I have completed updating the three BIPs with all the feedback that I have
> received so far. In short summary, here is an incomplete list of the
> changes that were made:
> 
> * Modified the hashing function fast-SHA256 so that an internal node cannot
> be interpreted simultaneously as a leaf. * Changed MERKLEBRANCHVERIFY to
> verify a configurable number of elements from the tree, instead of just
> one. * Changed MERKLEBRANCHVERIFY to have two modes: one where the inputs
> are assumed to be hashes, and one where they are run through double-SHA256
> first. * Made tail-call eval compatible with BIP141?s CLEANSTACK consensus
> rule by allowing parameters to be passed on the alt-stack. * Restricted
> tail-call eval to segwit scripts only, so that checking sigop and opcode
> limits of the policy script would not be necessary.
> 
> There were a bunch of other small modifications, typo fixes, and
> optimizations that were made as well.
> 
> I am now ready to submit these BIPs as a PR against the bitcoin/bips repo,
> and I request that the BIP editor assign numbers.
> 
> Thank you,
> Mark Friedenbach
> 
> > On Sep 6, 2017, at 5:38 PM, Mark Friedenbach <mark at friedenbach.org>
> > wrote:
> > 
> > I would like to propose two new script features to be added to the
> > bitcoin protocol by means of soft-fork activation. These features are
> > a new opcode, MERKLE-BRANCH-VERIFY (MBV) and tail-call execution
> > semantics.
> > 
> > In brief summary, MERKLE-BRANCH-VERIFY allows script authors to force
> > redemption to use values selected from a pre-determined set committed
> > to in the scriptPubKey, but without requiring revelation of unused
> > elements in the set for both enhanced privacy and smaller script
> > sizes. Tail-call execution semantics allows a single level of
> > recursion into a subscript, providing properties similar to P2SH while
> > at the same time more flexible.
> > 
> > These two features together are enough to enable a range of
> > applications such as tree signatures (minus Schnorr aggregation) as
> > described by Pieter Wuille [1], and a generalized MAST useful for
> > constructing private smart contracts. It also brings privacy and
> > fungibility improvements to users of counter-signing wallet/vault
> > services as unique redemption policies need only be revealed if/when
> > exceptional circumstances demand it, leaving most transactions looking
> > the same as any other MAST-enabled multi-sig script.
> > 
> > I believe that the implementation of these features is simple enough,
> > and the use cases compelling enough that we could BIP 8/9 rollout of
> > these features in relatively short order, perhaps before the end of
> > the year.
> > 
> > I have written three BIPs to describe these features, and their
> > associated implementation, for which I now invite public review and
> > discussion:
> > 
> > Fast Merkle Trees
> > BIP: https://gist.github.com/maaku/41b0054de0731321d23e9da90ba4ee0a
> > Code: https://github.com/maaku/bitcoin/tree/fast-merkle-tree
> > 
> > MERKLEBRANCHVERIFY
> > BIP: https://gist.github.com/maaku/bcf63a208880bbf8135e453994c0e431
> > Code: https://github.com/maaku/bitcoin/tree/merkle-branch-verify
> > 
> > Tail-call execution semantics
> > BIP: https://gist.github.com/maaku/f7b2e710c53f601279549aa74eeb5368
> > Code: https://github.com/maaku/bitcoin/tree/tail-call-semantics
> > 
> > Note: I have circulated this idea privately among a few people, and I
> > will note that there is one piece of feedback which I agree with but
> > is not incorporated yet: there should be a multi-element MBV opcode
> > that allows verifying multiple items are extracted from a single
> > tree. It is not obvious how MBV could be modified to support this
> > without sacrificing important properties, or whether should be a
> > separate multi-MBV opcode instead.
> > 
> > Kind regards,
> > Mark Friedenbach

From mark at friedenbach.org  Wed Nov  1 15:08:46 2017
From: mark at friedenbach.org (Mark Friedenbach)
Date: Wed, 1 Nov 2017 08:08:46 -0700
Subject: [bitcoin-dev] Merkle branch verification & tail-call semantics
	for generalized MAST
In-Reply-To: <201711010843.49771.luke@dashjr.org>
References: <5B6756D0-6BEF-4A01-BDB8-52C646916E29@friedenbach.org>
	<3FE16880-868C-40BA-BCC5-954B15478FB2@friedenbach.org>
	<201711010843.49771.luke@dashjr.org>
Message-ID: <4F328120-94E0-4EFF-A76D-99E6007FA906@friedenbach.org>

Yes, if you use a witness script version you can save about 40 witness bytes by templating the MBV script, which I think is equivalent to what you are suggesting. 32 bytes from the saved hash, plus another 8 bytes or so from script templates and more efficient serialization.

I believe the conservatively correct approach is to do this in stages, however. First roll out MBV and tail call to witness v0. Then once there is experience with people using it in production, design and deploy a hashing template for script v1. It might be that we learn more and think of something better in the meantime.

> On Nov 1, 2017, at 1:43 AM, Luke Dashjr <luke at dashjr.org> wrote:
> 
> Mark,
> 
> I think I have found an improvement that can be made.
> 
> As you recall, a downside to this approach is that one must make two 
> commitments: first, to the particular "membership-checking script"; and then 
> in that script, to the particular merkle root of possible scripts.
> 
> Would there be any harm in, instead of checking membership, *calculating* the 
> root? If not, then we could define that instead of the witness program 
> committing to H(membership-check script), it rather commits to H(membership-
> calculation script | data added by an OP_ADDTOSCRIPTHASH). This would, I 
> believe, securely reduce the commitment of both to a single hash.
> 
> It also doesn't reduce flexibility, since one could omit OP_ADDTOSCRIPTHASH 
> from their "membership-calculation" script to get the previous membership-
> check behaviour, and use <hash> OP_EQUAL in its place.
> 
> What do you think?
> 
> Luke
> 
> 
>> On Saturday 28 October 2017 4:40:01 AM Mark Friedenbach wrote:
>> I have completed updating the three BIPs with all the feedback that I have
>> received so far. In short summary, here is an incomplete list of the
>> changes that were made:
>> 
>> * Modified the hashing function fast-SHA256 so that an internal node cannot
>> be interpreted simultaneously as a leaf. * Changed MERKLEBRANCHVERIFY to
>> verify a configurable number of elements from the tree, instead of just
>> one. * Changed MERKLEBRANCHVERIFY to have two modes: one where the inputs
>> are assumed to be hashes, and one where they are run through double-SHA256
>> first. * Made tail-call eval compatible with BIP141?s CLEANSTACK consensus
>> rule by allowing parameters to be passed on the alt-stack. * Restricted
>> tail-call eval to segwit scripts only, so that checking sigop and opcode
>> limits of the policy script would not be necessary.
>> 
>> There were a bunch of other small modifications, typo fixes, and
>> optimizations that were made as well.
>> 
>> I am now ready to submit these BIPs as a PR against the bitcoin/bips repo,
>> and I request that the BIP editor assign numbers.
>> 
>> Thank you,
>> Mark Friedenbach
>> 
>>> On Sep 6, 2017, at 5:38 PM, Mark Friedenbach <mark at friedenbach.org>
>>> wrote:
>>> 
>>> I would like to propose two new script features to be added to the
>>> bitcoin protocol by means of soft-fork activation. These features are
>>> a new opcode, MERKLE-BRANCH-VERIFY (MBV) and tail-call execution
>>> semantics.
>>> 
>>> In brief summary, MERKLE-BRANCH-VERIFY allows script authors to force
>>> redemption to use values selected from a pre-determined set committed
>>> to in the scriptPubKey, but without requiring revelation of unused
>>> elements in the set for both enhanced privacy and smaller script
>>> sizes. Tail-call execution semantics allows a single level of
>>> recursion into a subscript, providing properties similar to P2SH while
>>> at the same time more flexible.
>>> 
>>> These two features together are enough to enable a range of
>>> applications such as tree signatures (minus Schnorr aggregation) as
>>> described by Pieter Wuille [1], and a generalized MAST useful for
>>> constructing private smart contracts. It also brings privacy and
>>> fungibility improvements to users of counter-signing wallet/vault
>>> services as unique redemption policies need only be revealed if/when
>>> exceptional circumstances demand it, leaving most transactions looking
>>> the same as any other MAST-enabled multi-sig script.
>>> 
>>> I believe that the implementation of these features is simple enough,
>>> and the use cases compelling enough that we could BIP 8/9 rollout of
>>> these features in relatively short order, perhaps before the end of
>>> the year.
>>> 
>>> I have written three BIPs to describe these features, and their
>>> associated implementation, for which I now invite public review and
>>> discussion:
>>> 
>>> Fast Merkle Trees
>>> BIP: https://gist.github.com/maaku/41b0054de0731321d23e9da90ba4ee0a
>>> Code: https://github.com/maaku/bitcoin/tree/fast-merkle-tree
>>> 
>>> MERKLEBRANCHVERIFY
>>> BIP: https://gist.github.com/maaku/bcf63a208880bbf8135e453994c0e431
>>> Code: https://github.com/maaku/bitcoin/tree/merkle-branch-verify
>>> 
>>> Tail-call execution semantics
>>> BIP: https://gist.github.com/maaku/f7b2e710c53f601279549aa74eeb5368
>>> Code: https://github.com/maaku/bitcoin/tree/tail-call-semantics
>>> 
>>> Note: I have circulated this idea privately among a few people, and I
>>> will note that there is one piece of feedback which I agree with but
>>> is not incorporated yet: there should be a multi-element MBV opcode
>>> that allows verifying multiple items are extracted from a single
>>> tree. It is not obvious how MBV could be modified to support this
>>> without sacrificing important properties, or whether should be a
>>> separate multi-MBV opcode instead.
>>> 
>>> Kind regards,
>>> Mark Friedenbach

From thomasv at electrum.org  Thu Nov  2 09:56:15 2017
From: thomasv at electrum.org (Thomas Voegtlin)
Date: Thu, 2 Nov 2017 10:56:15 +0100
Subject: [bitcoin-dev] Electrum 3.0 release
Message-ID: <b846adac-263a-5fe1-9ce5-05e28af26519@electrum.org>

Electrum 3.0 was tagged and released yesterday night.

Release notes:

# Release 3.0 - Uncanny Valley (November 1st, 2017)

  * The project was migrated to Python3 and Qt5. Python2 is no longer
    supported. If you cloned the source repository, you will need to
    run "python3 setup.py install" in order to install the new
    dependencies.

  * Segwit support:

    - Native segwit scripts are supported using a new type of
      seed. The version number for segwit seeds is 0x100. The install
      wizard will not create segwit seeds by default; users must
      opt-in with the segwit option.

    - Native segwit scripts are represented using bech32 addresses,
      following BIP173. Please note that BIP173 is still in draft
      status, and that other wallets/websites may not support
      it. Thus, you should keep a non-segwit wallet in order to be
      able to receive bitcoins during the transition period. If BIP173
      ends up being rejected or substantially modified, your wallet
      may have to be restored from seed. This will not affect funds
      sent to bech32 addresses, and it will not affect the capacity of
      Electrum to spend these funds.

    - Segwit scripts embedded in p2sh are supported with hardware
      wallets or bip39 seeds. To create a segwit-in-p2sh wallet,
      trezor/ledger users will need to enter a BIP49 derivation path.

    - The BIP32 master keys of segwit wallets are serialized using new
      version numbers. The new version numbers encode the script type,
      and they result in the following prefixes:

         * xpub/xprv : p2pkh or p2sh
         * ypub/yprv : p2wpkh-in-p2sh
         * Ypub/Yprv : p2wsh-in-p2sh
         * zpub/zprv : p2wpkh
         * Zpub/Zprv : p2wsh

      These values are identical for mainnet and testnet; tpub/tprv
      prefixes are no longer used in testnet wallets.

    - The Wallet Import Format (WIF) is similarly extended for segwit
      scripts. After a base58-encoded key is decoded to binary, its
      first byte encodes the script type:

         * 128 + 0: p2pkh
         * 128 + 1: p2wpkh
         * 128 + 2: p2wpkh-in-p2sh
         * 128 + 5: p2sh
         * 128 + 6: p2wsh
         * 128 + 7: p2wsh-in-p2sh

      The distinction between p2sh and p2pkh in private key means that
      it is not possible to import a p2sh private key and associate it
      to a p2pkh address.

  * A new version of the Electrum protocol is required by the client
    (version 1.1). Servers using older versions of the protocol will
    not be displayed in the GUI.

  * By default, transactions are time-locked to the height of the
    current block. Other values of locktime may be passed using the
    command line.





-- 
Electrum Technologies GmbH / Waldemarstr 37a / 10999 Berlin / Germany
Sitz, Registergericht: Berlin, Amtsgericht Charlottenburg, HRB 164636
Gesch?ftsf?hrer: Thomas Voegtlin

From c1.bitcoin at niftybox.net  Wed Nov  1 05:48:27 2017
From: c1.bitcoin at niftybox.net (Devrandom)
Date: Wed, 01 Nov 2017 05:48:27 +0000
Subject: [bitcoin-dev] Introducing a POW through a soft-fork
Message-ID: <CAB0O3SVjhG19R61B78hFCPwfwWemTXj=tOsvgAgoNbjFYXXAtg@mail.gmail.com>

Hi all,

Feedback is welcome on the draft below.  In particular, I want to see if
there is interest in further development of the idea and also interested in
any attack vectors or undesirable dynamics.

(Formatted version available here:
https://github.com/devrandom/btc-papers/blob/master/aux-pow.md )

# Soft-fork Introduction of a New POW

## Motivation:

- Mitigate mining centralization pressures by introducing a POW that does
not have economies of scale
- Introduce an intermediary confirmation point, reducing the impact of
mining power fluctuations

Note however that choice of a suitable POW will require deep analysis.
Some pitfalls include: botnet mining, POWs that seem ASIC resistant but are
not, unexpected/covert optimization.

In particular, unexpected/covert optimizations, such as ASCIBOOST, present
a potential centralizing and destabilizing force.

## Design

### Aux POW intermediate block

Auxiliary POW blocks are introduced between normal blocks - i.e. the chain
alternates between the two POWs.
Each aux-POW block points to the previous normal block and contains
transactions just like a normal block.
Each normal block points to the previous aux-POW block and must contain all
transactions from the aux-POW block.
Block space is not increased.

The new intermediate block and the pointers are introduced via a soft-fork
restriction.

### Reward for aux POW miners

The reward for the aux POW smoothly increases from zero to a target value
(e.g. 1/2 of the total reward) over time.
The reward is transferred via a soft-fork restriction requiring a coinbase
output to an address published in the
aux-POW block.

### Aux POW difficulty adjustment

Difficulty adjustments remain independent for the two POWs.

The difficulty of the aux POW is adjusted based on the average time between
normal block found
to aux block found.

Further details are dependent on the specific POW.

### Heaviest chain rule change

This is a semi-hard change, because non-upgraded nodes can get on the wrong
chain in case of attack.  However,
it might be possible to construct an alert system that notifies
non-upgraded nodes of an upcoming rule change.
All blocks are still valid, so this is not a hardforking change.

The heaviest chain definition changes from sum of `difficulty` to sum of:

    mainDifficulty ^ x * auxDifficulty ^ y

where we start at:

    x = 1; y = 0

and end at values of x and y that are related to the target relative
rewards.  For example, if the target rewards
are equally distributed, we will want ot end up at:

    x = 1/2; y = 1/2

so that both POWs have equal weight.  If the aux POW is to become dominant,
x should end small relative to y.


## Questions and Answers

- What should be the parameters if we want the aux POW to have equal
weight? A: 1/2 of the reward should be transferred
to aux miners and x = 1/2, y = 1/2.

- What should be the parameters if we want to deprecate the main POW?  A:
most of the reward should be transferred to
aux miners and x = 0, y = 1.  The main difficulty will tend to zero, and
aux miners will just trivially generate the
main block immediately after finding an aux block, with identical content.

- Wasted bandwidth to transfer transactions twice?  A: this can be
optimized by skipping transactions already
transferred.

- Why would miners agree to soft-fork away some of their reward?  A: they
would agree if they believe that
the coins will increase in value due to improved security properties.

## Open Questions

- After a block of one type is found, we can naively assume that POW will
become idle while a block of the other type is being mined.  In practice,
the spare capacity can be used to find alternative ("attacking") blocks or
mine other coins.  Is that a problem?
- Is selfish mining amplified by this scheme for miners that have both
types of hardware?

## POW candidates

- SHA256 (i.e. use same POW, but introduce an intermediate block for faster
confirmation)
- Proof of Space and Time (Bram Cohen)
- Equihash
- Ethash

## Next Steps

- evaluate POW candidates
- evaluate difficulty adjustment rules
- simulate miner behavior to identify if there are incentives for
detrimental behavior patterns (e.g. block withholding / selfish mining)
- Protocol details

## Credits

Bram Cohen came up with a similar idea back in March:
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-March/013744.html
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171101/9dc7ba4e/attachment.html>

From wordsgalore at gmail.com  Thu Nov  2 23:31:55 2017
From: wordsgalore at gmail.com (Scott Roberts)
Date: Thu, 2 Nov 2017 19:31:55 -0400
Subject: [bitcoin-dev] Bitcoin Cash's new difficulty algorithm
Message-ID: <CADtTMvn8=uqCwwtvrqjLuN_6ADt+65YpEffSqnBozmWXWO--9A@mail.gmail.com>

Bitcoin cash will hard fork on Nov 13 to implement a new difficulty
algorithm.  Bitcoin itself might need to hard fork to employ a similar
algorithm. It's about as good as they come because it followed the
"simplest is best" route. Their averaging window is probably
significantly too long (N=144). It's:

next_D = sum (past 144 D's) * T / sum(past 144 solvetimes)

They correctly did not use max(timestamp) - min(timestamp) in the
denominator like others do.

They've written the code and they're about to use it live, so Bitcoin
will have a clear, simple, and tested path if it suddenly needs to
hard fork due to having 20x delays for the next 2000 blocks (taking it
a year to get unstuck).

Details on it and the decision process:
https://www.bitcoinabc.org/november

It uses a nice median of 3 for the beginning and end of the window to
help alleviate bad timestamp problems. It's nice, helps a little, but
will also slow its response by 1 block.  They also have 2x and 1/2
limits on the adjustment per block, which is a lot more than they will
ever need.

I recommend bitcoin consider using it and making it N=50 instead of 144.

I have seen that any attempts to modify the above with things like a
low pass filter, starting the window at MTP, or preventing negative
timestamps will only reduce its effectiveness. Bitcoin's +12 and -6
limits on the timestamps are sufficient and well chosen, although
something a bit smaller than the +12 might have been better.

One of the contenders to the above is new and actually better, devised
by Degnr8 and they call it D622 or wt-144.It's a little better than
they realize. It's the only real improvement in difficulty algorithms
since the rolling average.  It gives a linearly higher weight to the
more recent timestamps. Otherwise it is the same. Others have probably
come across it, but there is too much noise in difficulty algorithms
to find the good ones.

# Degnr8's D622 difficulty algorithm
# T=TargetTime, S=Solvetime
# modified by zawy
for i = 1 to N  (from oldest to most recent block)
    t += T[i] / D[i] * i
    j += i
next i
next_D = j / t * T

I believe any modification to the above strict mathematical weighted
average will reduce it's effectiveness. It does not oscillate anymore
than regular algos and rises faster and drops faster, when needed.

From jose.femenias at gmail.com  Wed Nov  1 10:34:40 2017
From: jose.femenias at gmail.com (=?utf-8?Q?JOSE_FEMENIAS_CA=C3=91UELO?=)
Date: Wed, 1 Nov 2017 11:34:40 +0100
Subject: [bitcoin-dev] Simplicity proposal - Jets?
In-Reply-To: <mailman.5469.1509483670.27509.bitcoin-dev@lists.linuxfoundation.org>
References: <mailman.5469.1509483670.27509.bitcoin-dev@lists.linuxfoundation.org>
Message-ID: <052D6E20-7194-4645-B628-1B7B7FECF330@gmail.com>

Hi,

I am trying to follow this Simplicity proposal and I am seeing all over references to ?jets?, but I haven?t been able to find any good reference to it.
Can anyone give me a brief explanation and or a link pointing to this feature?
Thanks

> On 31 Oct 2017, at 22:01, bitcoin-dev-request at lists.linuxfoundation.org wrote:
> 
> The plan is that discounted jets will be explicitly labeled as jets in the
> commitment.  If you can provide a Merkle path from the root to a node that
> is an explicit jet, but that jet isn't among the finite number of known
> discounted jets,

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171101/ab3d6aa3/attachment.html>

From greg at xiph.org  Thu Nov  2 23:37:29 2017
From: greg at xiph.org (Gregory Maxwell)
Date: Thu, 2 Nov 2017 23:37:29 +0000
Subject: [bitcoin-dev] Bitcoin Cash's new difficulty algorithm
In-Reply-To: <CADtTMvn8=uqCwwtvrqjLuN_6ADt+65YpEffSqnBozmWXWO--9A@mail.gmail.com>
References: <CADtTMvn8=uqCwwtvrqjLuN_6ADt+65YpEffSqnBozmWXWO--9A@mail.gmail.com>
Message-ID: <CAAS2fgT9aM=koBv4PxJFSrHfTRU4TrGCPOE8Ej7T8oTLhGmubA@mail.gmail.com>

On Thu, Nov 2, 2017 at 11:31 PM, Scott Roberts via bitcoin-dev
<bitcoin-dev at lists.linuxfoundation.org> wrote:
> Bitcoin cash will hard fork on Nov 13 to implement a new difficulty
> algorithm.  Bitcoin itself might need to hard fork to employ a similar
> algorithm. It's about as good as they come because it followed the

This is the bitcoin development mailing list, not the "give free
review to the obviously defective proposals of adversarial competing
systems" mailing list. Your posting is off-topic.

From cryptaxe at gmail.com  Thu Nov  2 23:39:41 2017
From: cryptaxe at gmail.com (CryptAxe)
Date: Thu, 2 Nov 2017 16:39:41 -0700
Subject: [bitcoin-dev] Bitcoin Cash's new difficulty algorithm
In-Reply-To: <CADtTMvn8=uqCwwtvrqjLuN_6ADt+65YpEffSqnBozmWXWO--9A@mail.gmail.com>
References: <CADtTMvn8=uqCwwtvrqjLuN_6ADt+65YpEffSqnBozmWXWO--9A@mail.gmail.com>
Message-ID: <CAF5CFkhTU9j6wWv+-wKkCaX65fwZSYsMNGf_nAwb+vwPtsbkYQ@mail.gmail.com>

Is there an issue with the current difficulty adjustment algorithm? It's
worked very well as far as I can tell. Introducing a new one seems pretty
risky, what would the benefit be?

On Nov 2, 2017 4:34 PM, "Scott Roberts via bitcoin-dev" <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Bitcoin cash will hard fork on Nov 13 to implement a new difficulty
> algorithm.  Bitcoin itself might need to hard fork to employ a similar
> algorithm. It's about as good as they come because it followed the
> "simplest is best" route. Their averaging window is probably
> significantly too long (N=144). It's:
>
> next_D = sum (past 144 D's) * T / sum(past 144 solvetimes)
>
> They correctly did not use max(timestamp) - min(timestamp) in the
> denominator like others do.
>
> They've written the code and they're about to use it live, so Bitcoin
> will have a clear, simple, and tested path if it suddenly needs to
> hard fork due to having 20x delays for the next 2000 blocks (taking it
> a year to get unstuck).
>
> Details on it and the decision process:
> https://www.bitcoinabc.org/november
>
> It uses a nice median of 3 for the beginning and end of the window to
> help alleviate bad timestamp problems. It's nice, helps a little, but
> will also slow its response by 1 block.  They also have 2x and 1/2
> limits on the adjustment per block, which is a lot more than they will
> ever need.
>
> I recommend bitcoin consider using it and making it N=50 instead of 144.
>
> I have seen that any attempts to modify the above with things like a
> low pass filter, starting the window at MTP, or preventing negative
> timestamps will only reduce its effectiveness. Bitcoin's +12 and -6
> limits on the timestamps are sufficient and well chosen, although
> something a bit smaller than the +12 might have been better.
>
> One of the contenders to the above is new and actually better, devised
> by Degnr8 and they call it D622 or wt-144.It's a little better than
> they realize. It's the only real improvement in difficulty algorithms
> since the rolling average.  It gives a linearly higher weight to the
> more recent timestamps. Otherwise it is the same. Others have probably
> come across it, but there is too much noise in difficulty algorithms
> to find the good ones.
>
> # Degnr8's D622 difficulty algorithm
> # T=TargetTime, S=Solvetime
> # modified by zawy
> for i = 1 to N  (from oldest to most recent block)
>     t += T[i] / D[i] * i
>     j += i
> next i
> next_D = j / t * T
>
> I believe any modification to the above strict mathematical weighted
> average will reduce it's effectiveness. It does not oscillate anymore
> than regular algos and rises faster and drops faster, when needed.
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171102/080f5543/attachment.html>

From greg at xiph.org  Fri Nov  3 00:00:07 2017
From: greg at xiph.org (Gregory Maxwell)
Date: Fri, 3 Nov 2017 00:00:07 +0000
Subject: [bitcoin-dev] Bitcoin Cash's new difficulty algorithm
In-Reply-To: <CADtTMvnOtaq-AsvBOMxPWAHJcSFU+qNXye5+Nu1hB4YP06r3ng@mail.gmail.com>
References: <CADtTMvn8=uqCwwtvrqjLuN_6ADt+65YpEffSqnBozmWXWO--9A@mail.gmail.com>
	<CAAS2fgT9aM=koBv4PxJFSrHfTRU4TrGCPOE8Ej7T8oTLhGmubA@mail.gmail.com>
	<CADtTMvnOtaq-AsvBOMxPWAHJcSFU+qNXye5+Nu1hB4YP06r3ng@mail.gmail.com>
Message-ID: <CAAS2fgSaS9r_H=o2ygKK=ayiNYrDHiZG9ge3a7vXsdEY-CiS7A@mail.gmail.com>

On Thu, Nov 2, 2017 at 11:53 PM, Scott Roberts <wordsgalore at gmail.com> wrote:
> Whatever their failings from their previous code or their adversarial
> nature, they got this code right and I'm only presenting it as a real and
> excellent solution for the impending threat to bitcoin. As a big core fan, I
> really wanted to delete the word Cash from my post because I was afraid
> someone would turn this technical discussion into a political football.

I urge my colleagues here to not fall for the obvious xkcd386 bait.

The competitive advantage of prudence and competence is diminished if
competitors are able to divert our efforts into reviewing their
proposals.

From wordsgalore at gmail.com  Thu Nov  2 23:53:25 2017
From: wordsgalore at gmail.com (Scott Roberts)
Date: Thu, 2 Nov 2017 19:53:25 -0400
Subject: [bitcoin-dev] Bitcoin Cash's new difficulty algorithm
In-Reply-To: <CAAS2fgT9aM=koBv4PxJFSrHfTRU4TrGCPOE8Ej7T8oTLhGmubA@mail.gmail.com>
References: <CADtTMvn8=uqCwwtvrqjLuN_6ADt+65YpEffSqnBozmWXWO--9A@mail.gmail.com>
	<CAAS2fgT9aM=koBv4PxJFSrHfTRU4TrGCPOE8Ej7T8oTLhGmubA@mail.gmail.com>
Message-ID: <CADtTMvnOtaq-AsvBOMxPWAHJcSFU+qNXye5+Nu1hB4YP06r3ng@mail.gmail.com>

Whatever their failings from their previous code or their adversarial
nature, they got this code right and I'm only presenting it as a real and
excellent solution for the impending threat to bitcoin. As a big core fan,
I really wanted to delete the word Cash from my post because I was afraid
someone would turn this technical discussion into a political football.

On Nov 2, 2017 7:37 PM, "Gregory Maxwell" <greg at xiph.org> wrote:

On Thu, Nov 2, 2017 at 11:31 PM, Scott Roberts via bitcoin-dev
<bitcoin-dev at lists.linuxfoundation.org> wrote:
> Bitcoin cash will hard fork on Nov 13 to implement a new difficulty
> algorithm.  Bitcoin itself might need to hard fork to employ a similar
> algorithm. It's about as good as they come because it followed the

This is the bitcoin development mailing list, not the "give free
review to the obviously defective proposals of adversarial competing
systems" mailing list. Your posting is off-topic.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171102/64dbe338/attachment.html>

From contact at taoeffect.com  Thu Nov  2 23:55:55 2017
From: contact at taoeffect.com (Tao Effect)
Date: Thu, 2 Nov 2017 16:55:55 -0700
Subject: [bitcoin-dev] Introducing a POW through a soft-fork
In-Reply-To: <CAB0O3SVjhG19R61B78hFCPwfwWemTXj=tOsvgAgoNbjFYXXAtg@mail.gmail.com>
References: <CAB0O3SVjhG19R61B78hFCPwfwWemTXj=tOsvgAgoNbjFYXXAtg@mail.gmail.com>
Message-ID: <D075DBB7-1C8A-4F83-9C0E-CC2321A8C5A7@taoeffect.com>

Just going to throw in my support for a POW change, not any particular implementation, but the idea.

Bitcoin is technically owned by China now. That's not acceptable.

- Greg

--
Please do not email me anything that you are not comfortable also sharing with the NSA.

> On Oct 31, 2017, at 10:48 PM, Devrandom via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:
> 
> Hi all,
> 
> Feedback is welcome on the draft below.  In particular, I want to see if there is interest in further development of the idea and also interested in any attack vectors or undesirable dynamics.
> 
> (Formatted version available here: https://github.com/devrandom/btc-papers/blob/master/aux-pow.md <https://github.com/devrandom/btc-papers/blob/master/aux-pow.md> )
> 
> # Soft-fork Introduction of a New POW
> 
> ## Motivation:
> 
> - Mitigate mining centralization pressures by introducing a POW that does not have economies of scale
> - Introduce an intermediary confirmation point, reducing the impact of mining power fluctuations
> 
> Note however that choice of a suitable POW will require deep analysis.  Some pitfalls include: botnet mining, POWs that seem ASIC resistant but are not, unexpected/covert optimization.
> 
> In particular, unexpected/covert optimizations, such as ASCIBOOST, present a potential centralizing and destabilizing force.
> 
> ## Design
> 
> ### Aux POW intermediate block
> 
> Auxiliary POW blocks are introduced between normal blocks - i.e. the chain alternates between the two POWs.
> Each aux-POW block points to the previous normal block and contains transactions just like a normal block.
> Each normal block points to the previous aux-POW block and must contain all transactions from the aux-POW block.
> Block space is not increased.
> 
> The new intermediate block and the pointers are introduced via a soft-fork restriction.
> 
> ### Reward for aux POW miners
> 
> The reward for the aux POW smoothly increases from zero to a target value (e.g. 1/2 of the total reward) over time.
> The reward is transferred via a soft-fork restriction requiring a coinbase output to an address published in the
> aux-POW block.
> 
> ### Aux POW difficulty adjustment
> 
> Difficulty adjustments remain independent for the two POWs.
> 
> The difficulty of the aux POW is adjusted based on the average time between normal block found
> to aux block found.
> 
> Further details are dependent on the specific POW.
> 
> ### Heaviest chain rule change
> 
> This is a semi-hard change, because non-upgraded nodes can get on the wrong chain in case of attack.  However,
> it might be possible to construct an alert system that notifies non-upgraded nodes of an upcoming rule change.
> All blocks are still valid, so this is not a hardforking change.
> 
> The heaviest chain definition changes from sum of `difficulty` to sum of:
> 
>     mainDifficulty ^ x * auxDifficulty ^ y
> 
> where we start at:
> 
>     x = 1; y = 0
> 
> and end at values of x and y that are related to the target relative rewards.  For example, if the target rewards
> are equally distributed, we will want ot end up at:
> 
>     x = 1/2; y = 1/2
> 
> so that both POWs have equal weight.  If the aux POW is to become dominant, x should end small relative to y.
> 
> 
> ## Questions and Answers
> 
> - What should be the parameters if we want the aux POW to have equal weight? A: 1/2 of the reward should be transferred
> to aux miners and x = 1/2, y = 1/2.
> 
> - What should be the parameters if we want to deprecate the main POW?  A: most of the reward should be transferred to
> aux miners and x = 0, y = 1.  The main difficulty will tend to zero, and aux miners will just trivially generate the
> main block immediately after finding an aux block, with identical content.
> 
> - Wasted bandwidth to transfer transactions twice?  A: this can be optimized by skipping transactions already
> transferred.
> 
> - Why would miners agree to soft-fork away some of their reward?  A: they would agree if they believe that
> the coins will increase in value due to improved security properties.
> 
> ## Open Questions
> 
> - After a block of one type is found, we can naively assume that POW will become idle while a block of the other type is being mined.  In practice, the spare capacity can be used to find alternative ("attacking") blocks or mine other coins.  Is that a problem?
> - Is selfish mining amplified by this scheme for miners that have both types of hardware?
> 
> ## POW candidates
> 
> - SHA256 (i.e. use same POW, but introduce an intermediate block for faster confirmation)
> - Proof of Space and Time (Bram Cohen)
> - Equihash
> - Ethash
> 
> ## Next Steps
> 
> - evaluate POW candidates
> - evaluate difficulty adjustment rules
> - simulate miner behavior to identify if there are incentives for detrimental behavior patterns (e.g. block withholding / selfish mining)
> - Protocol details
> 
> ## Credits
> 
> Bram Cohen came up with a similar idea back in March:
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-March/013744.html <https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-March/013744.html>_______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171102/7d5311c6/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: Message signed with OpenPGP
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171102/7d5311c6/attachment-0001.sig>

From roconnor at blockstream.io  Fri Nov  3 01:10:42 2017
From: roconnor at blockstream.io (Russell O'Connor)
Date: Thu, 2 Nov 2017 21:10:42 -0400
Subject: [bitcoin-dev] Simplicity proposal - Jets?
In-Reply-To: <052D6E20-7194-4645-B628-1B7B7FECF330@gmail.com>
References: <mailman.5469.1509483670.27509.bitcoin-dev@lists.linuxfoundation.org>
	<052D6E20-7194-4645-B628-1B7B7FECF330@gmail.com>
Message-ID: <CAMZUoKk+8MFLywQB3jQFkk7BYZ4Rw3Paj=ErQe8pZ0beGwu0RA@mail.gmail.com>

Hi Jose,

Jets are briefly discussed in section 3.4 of
https://blockstream.com/simplicity.pdf

The idea is that we can recognize some set of popular Simplicity
expressions, and when the Simplicity interpreter encounters one of these
expressions it can skip over the Simplicity interpreter and instead
directly evaluate the function using specialized C or assembly code.

For example, when the Simplicity interpreter encounters the Simplicity
expression for ECDSA verification, it might directly call into libsecp
rather than continuing the ECDSA verification using interpreted Simplicity.

HTH.


On Nov 2, 2017 18:35, "JOSE FEMENIAS CA?UELO via bitcoin-dev" <
bitcoin-dev at lists.linuxfoundation.org> wrote:

Hi,

I am trying to follow this Simplicity proposal and I am seeing all over
references to ?jets?, but I haven?t been able to find any good reference to
it.
Can anyone give me a brief explanation and or a link pointing to this
feature?
Thanks

On 31 Oct 2017, at 22:01, bitcoin-dev-request at lists.linuxfoundation.org
wrote:

The plan is that discounted jets will be explicitly labeled as jets in the
commitment.  If you can provide a Merkle path from the root to a node that
is an explicit jet, but that jet isn't among the finite number of known
discounted jets,



_______________________________________________
bitcoin-dev mailing list
bitcoin-dev at lists.linuxfoundation.org
https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171102/47a8dfe5/attachment.html>

From c1.bitcoin at niftybox.net  Fri Nov  3 01:02:25 2017
From: c1.bitcoin at niftybox.net (Devrandom)
Date: Fri, 03 Nov 2017 01:02:25 +0000
Subject: [bitcoin-dev] Introducing a POW through a soft-fork
In-Reply-To: <D075DBB7-1C8A-4F83-9C0E-CC2321A8C5A7@taoeffect.com>
References: <CAB0O3SVjhG19R61B78hFCPwfwWemTXj=tOsvgAgoNbjFYXXAtg@mail.gmail.com>
	<D075DBB7-1C8A-4F83-9C0E-CC2321A8C5A7@taoeffect.com>
Message-ID: <CAB0O3SU56tGzKMZtfQWohi9vggij9U07uNJrvGQTSo7g4Mh4HQ@mail.gmail.com>

I am also concerned.  However, this proposal allows two POWs to coexist and
allows for gradual transitions. This is hopefully a less disruptive
approach since it allows cooperative miners to migrate over time.  And of
course, as a soft-fork it keeps backwards compatibility with existing
software.

On Thu, Nov 2, 2017 at 4:55 PM Tao Effect <contact at taoeffect.com> wrote:

> Just going to throw in my support for a POW change, not any particular
> implementation, but the idea.
>
> Bitcoin is technically owned by China now. That's not acceptable.
>
> - Greg
>
> --
> Please do not email me anything that you are not comfortable also sharing with
> the NSA.
>
> On Oct 31, 2017, at 10:48 PM, Devrandom via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
> Hi all,
>
> Feedback is welcome on the draft below.  In particular, I want to see if
> there is interest in further development of the idea and also interested in
> any attack vectors or undesirable dynamics.
>
> (Formatted version available here:
> https://github.com/devrandom/btc-papers/blob/master/aux-pow.md )
>
> # Soft-fork Introduction of a New POW
>
> ## Motivation:
>
> - Mitigate mining centralization pressures by introducing a POW that does
> not have economies of scale
> - Introduce an intermediary confirmation point, reducing the impact of
> mining power fluctuations
>
> Note however that choice of a suitable POW will require deep analysis.
> Some pitfalls include: botnet mining, POWs that seem ASIC resistant but are
> not, unexpected/covert optimization.
>
> In particular, unexpected/covert optimizations, such as ASCIBOOST, present
> a potential centralizing and destabilizing force.
>
> ## Design
>
> ### Aux POW intermediate block
>
> Auxiliary POW blocks are introduced between normal blocks - i.e. the chain
> alternates between the two POWs.
> Each aux-POW block points to the previous normal block and contains
> transactions just like a normal block.
> Each normal block points to the previous aux-POW block and must contain
> all transactions from the aux-POW block.
> Block space is not increased.
>
> The new intermediate block and the pointers are introduced via a soft-fork
> restriction.
>
> ### Reward for aux POW miners
>
> The reward for the aux POW smoothly increases from zero to a target value
> (e.g. 1/2 of the total reward) over time.
> The reward is transferred via a soft-fork restriction requiring a coinbase
> output to an address published in the
> aux-POW block.
>
> ### Aux POW difficulty adjustment
>
> Difficulty adjustments remain independent for the two POWs.
>
> The difficulty of the aux POW is adjusted based on the average time
> between normal block found
> to aux block found.
>
> Further details are dependent on the specific POW.
>
> ### Heaviest chain rule change
>
> This is a semi-hard change, because non-upgraded nodes can get on the
> wrong chain in case of attack.  However,
> it might be possible to construct an alert system that notifies
> non-upgraded nodes of an upcoming rule change.
> All blocks are still valid, so this is not a hardforking change.
>
> The heaviest chain definition changes from sum of `difficulty` to sum of:
>
>     mainDifficulty ^ x * auxDifficulty ^ y
>
> where we start at:
>
>     x = 1; y = 0
>
> and end at values of x and y that are related to the target relative
> rewards.  For example, if the target rewards
> are equally distributed, we will want ot end up at:
>
>     x = 1/2; y = 1/2
>
> so that both POWs have equal weight.  If the aux POW is to become
> dominant, x should end small relative to y.
>
>
> ## Questions and Answers
>
> - What should be the parameters if we want the aux POW to have equal
> weight? A: 1/2 of the reward should be transferred
> to aux miners and x = 1/2, y = 1/2.
>
> - What should be the parameters if we want to deprecate the main POW?  A:
> most of the reward should be transferred to
> aux miners and x = 0, y = 1.  The main difficulty will tend to zero, and
> aux miners will just trivially generate the
> main block immediately after finding an aux block, with identical content.
>
> - Wasted bandwidth to transfer transactions twice?  A: this can be
> optimized by skipping transactions already
> transferred.
>
> - Why would miners agree to soft-fork away some of their reward?  A: they
> would agree if they believe that
> the coins will increase in value due to improved security properties.
>
> ## Open Questions
>
> - After a block of one type is found, we can naively assume that POW will
> become idle while a block of the other type is being mined.  In practice,
> the spare capacity can be used to find alternative ("attacking") blocks or
> mine other coins.  Is that a problem?
> - Is selfish mining amplified by this scheme for miners that have both
> types of hardware?
>
> ## POW candidates
>
> - SHA256 (i.e. use same POW, but introduce an intermediate block for
> faster confirmation)
> - Proof of Space and Time (Bram Cohen)
> - Equihash
> - Ethash
>
> ## Next Steps
>
> - evaluate POW candidates
> - evaluate difficulty adjustment rules
> - simulate miner behavior to identify if there are incentives for
> detrimental behavior patterns (e.g. block withholding / selfish mining)
> - Protocol details
>
> ## Credits
>
> Bram Cohen came up with a similar idea back in March:
>
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-March/013744.html
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171103/d8fa3100/attachment.html>

From adan at stampery.co  Fri Nov  3 00:45:40 2017
From: adan at stampery.co (=?UTF-8?Q?Ad=c3=a1n_S=c3=a1nchez_de_Pedro_Crespo?=)
Date: Fri, 3 Nov 2017 01:45:40 +0100
Subject: [bitcoin-dev] Simplicity proposal - Jets?
In-Reply-To: <052D6E20-7194-4645-B628-1B7B7FECF330@gmail.com>
References: <mailman.5469.1509483670.27509.bitcoin-dev@lists.linuxfoundation.org>
	<052D6E20-7194-4645-B628-1B7B7FECF330@gmail.com>
Message-ID: <76afed77-dd30-7a6d-8ee7-90b1396460d1@stampery.com>

Hi everyone,

I agree that the paper could use some more details on the rationale
behind "jets". After a couple of reads, I think I can "ELI5 them":

As far as I understand, jets are a smart optimization that makes complex
Simplicity contracts way cheaper to compute (ideally, comparable to
Script or EVM).

For this purpose, jets leverage the most important element of the
Simplicity Bit Machine: the frames stack.

In a Simplicity program, every expression or sub-expression can be
thought of as a pure function that when applied on a certain initial
read frame, results in the active write frame having a different value.
This happens deterministically and without any side effects.

So, if the Simplicity interpreter finds some expression whose result
when applied upon a certain read frame is already known (because it has
already been executed or it was somehow precomputed), it doesn't need to
execute such expression step-by-step once again. Instead, it just need
to write the known result to the active write frame.

The paper suggests that at all times the interpreter knows the result of
applying many common operations on all possible combinations of inputs
in the range of 8 to 256 bits. In other words, the interpreter won't
need to calculate "123 + 321" or compare "456 > 654 because the results
of those expressions will be already known to it. These are stupid
examples, but the savings are real for hash functions internals,
elliptic curve calculations or even validation of signatures.

As said before, this can help making Simplicity programs lighter on CPU
usage, but it has many other benefits too:

+ Jets can replicate the behavior of complex chunks of Simplicity code
with the guarantee that they can't introduce side effects.

+ Interpreter-bundled jets are formally proven. The more a Simplicity
program relies on jets, the more it benefits from their safety. When
proving the soundness of your program, you can just ignore the jets,
assume they are valid and focus on your own logic.

The paper also suggests that different sets of jets could make up
different single purpose dialects, just like domain-specific languages
bring richer vocabulary and semantics to the bare syntax and grammar of
general-purpose languages.

I hope Russel or Mark can correct me if I got something totally wrong. I
must admit I really like this proposal and hereby declare myself a huge
fan of their work :)

-- 
Ad?n S?nchez de Pedro Crespo
CTO, Stampery Inc.
San Francisco - Madrid

From kiwigb at yahoo.com  Fri Nov  3 00:47:27 2017
From: kiwigb at yahoo.com (gb)
Date: Fri, 03 Nov 2017 13:47:27 +1300
Subject: [bitcoin-dev] Bitcoin Cash's new difficulty algorithm
In-Reply-To: <CADtTMvnOtaq-AsvBOMxPWAHJcSFU+qNXye5+Nu1hB4YP06r3ng@mail.gmail.com>
References: <CADtTMvn8=uqCwwtvrqjLuN_6ADt+65YpEffSqnBozmWXWO--9A@mail.gmail.com>
	<CAAS2fgT9aM=koBv4PxJFSrHfTRU4TrGCPOE8Ej7T8oTLhGmubA@mail.gmail.com>
	<CADtTMvnOtaq-AsvBOMxPWAHJcSFU+qNXye5+Nu1hB4YP06r3ng@mail.gmail.com>
Message-ID: <1509670047.5034.3.camel@yahoo.com>

You launched the political football by coming here with a verbose
'recommendation'. Without a code submission in form of pull request to
the core repo on github this was never a technical discussion.

On Thu, 2017-11-02 at 19:53 -0400, Scott Roberts via bitcoin-dev wrote:
> Whatever their failings from their previous code or their adversarial
> nature, they got this code right and I'm only presenting it as a real
> and excellent solution for the impending threat to bitcoin. As a big
> core fan, I really wanted to delete the word Cash from my post because
> I was afraid someone would turn this technical discussion into a
> political football.
> 
> On Nov 2, 2017 7:37 PM, "Gregory Maxwell" <greg at xiph.org> wrote:
>         On Thu, Nov 2, 2017 at 11:31 PM, Scott Roberts via bitcoin-dev
>         <bitcoin-dev at lists.linuxfoundation.org> wrote:
>         > Bitcoin cash will hard fork on Nov 13 to implement a new
>         difficulty
>         > algorithm.  Bitcoin itself might need to hard fork to employ
>         a similar
>         > algorithm. It's about as good as they come because it
>         followed the
>         
>         
>         This is the bitcoin development mailing list, not the "give
>         free
>         review to the obviously defective proposals of adversarial
>         competing
>         systems" mailing list. Your posting is off-topic.
> 
> 
> 
> 
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev



From adan at stampery.co  Fri Nov  3 08:46:16 2017
From: adan at stampery.co (=?UTF-8?Q?Ad=c3=a1n_S=c3=a1nchez_de_Pedro_Crespo?=)
Date: Fri, 3 Nov 2017 09:46:16 +0100
Subject: [bitcoin-dev] Simplicity proposal - Jets?
In-Reply-To: <CAMZUoKk+8MFLywQB3jQFkk7BYZ4Rw3Paj=ErQe8pZ0beGwu0RA@mail.gmail.com>
References: <mailman.5469.1509483670.27509.bitcoin-dev@lists.linuxfoundation.org>
	<052D6E20-7194-4645-B628-1B7B7FECF330@gmail.com>
	<CAMZUoKk+8MFLywQB3jQFkk7BYZ4Rw3Paj=ErQe8pZ0beGwu0RA@mail.gmail.com>
Message-ID: <7d3a97f7-37c0-3eb6-6f39-00bd99c36132@stampery.com>

Oops. That makes much more sense than what I said. Thanks a lot for the
clarification.

On 03.11.2017 02:10, Russell O'Connor via bitcoin-dev wrote:
> Hi Jose,
> 
> Jets are briefly discussed in section 3.4 of
> https://blockstream.com/simplicity.pdf
> 
> The idea is that we can recognize some set of popular Simplicity
> expressions, and when the Simplicity interpreter encounters one of these
> expressions it can skip over the Simplicity interpreter and instead
> directly evaluate the function using specialized C or assembly code.
> 
> For example, when the Simplicity interpreter encounters the Simplicity
> expression for ECDSA verification, it might directly call into libsecp
> rather than continuing the ECDSA verification using interpreted Simplicity.
> 
> HTH.
> 
> 
> On Nov 2, 2017 18:35, "JOSE FEMENIAS CA?UELO via bitcoin-dev"
> <bitcoin-dev at lists.linuxfoundation.org
> <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:
> 
>     Hi,
> 
>     I am trying to follow this Simplicity proposal and I am seeing all
>     over references to ?jets?, but I haven?t been able to find any good
>     reference to it.
>     Can anyone give me a brief explanation and or a link pointing to
>     this feature?
>     Thanks
> 
>>     On 31 Oct 2017, at 22:01,
>>     bitcoin-dev-request at lists.linuxfoundation.org
>>     <mailto:bitcoin-dev-request at lists.linuxfoundation.org> wrote:
>>
>>     The plan is that discounted jets will be explicitly labeled as
>>     jets in the
>>     commitment.? If you can provide a Merkle path from the root to a
>>     node that
>>     is an explicit jet, but that jet isn't among the finite number of
>>     known
>>     discounted jets,
> 
> 
>     _______________________________________________
>     bitcoin-dev mailing list
>     bitcoin-dev at lists.linuxfoundation.org
>     <mailto:bitcoin-dev at lists.linuxfoundation.org>
>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>     <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>
> 
> 
> 
> 
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> 

-- 
Ad?n S?nchez de Pedro Crespo
CTO, Stampery Inc.
San Francisco - Madrid

From sjors at sprovoost.nl  Fri Nov  3 09:50:15 2017
From: sjors at sprovoost.nl (Sjors Provoost)
Date: Fri, 3 Nov 2017 10:50:15 +0100
Subject: [bitcoin-dev] Proposal: allocate Github issue instead of wiki page
 to BIP discussion
Message-ID: <FBA2AA31-D63C-479C-B890-A14E6F08B3A4@sprovoost.nl>

I often find myself wanting to leave relatively small comments on BIP's that are IMO not worth bothering this list.

By default each BIP has a wiki page for discussion, e.g. https://github.com/bitcoin/bips/wiki/Comments:BIP-0150
This is linked to from the Comments-URI field in the BIP.

In order to leave a comment, you have to edit the wiki page. This process seems a bit clunky.

I think it would be better to use Github issues, with one Github issue for each BIP.

One concern might be that the ease of use of Github issues would move discussion away from this list. The issue could be temporarily locked to prevent that. The issue description could contain a standard text explaining what should be discussed there and what would be more appropriate to post on the mailinglist.

Another concern might be confusing between PR's which create and update a BIP, and the discussion issue.

If people think this a good idea, would the next step be to propose a change to the process here?
https://github.com/bitcoin/bips/blob/master/bip-0002.mediawiki#BIP_comments

Or would this be a new BIP?

Sjors
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: Message signed with OpenPGP
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171103/fdb12e98/attachment.sig>

From wordsgalore at gmail.com  Fri Nov  3 01:59:47 2017
From: wordsgalore at gmail.com (Scott Roberts)
Date: Thu, 2 Nov 2017 21:59:47 -0400
Subject: [bitcoin-dev] Bitcoin Cash's new difficulty algorithm
In-Reply-To: <CAF5CFkhTU9j6wWv+-wKkCaX65fwZSYsMNGf_nAwb+vwPtsbkYQ@mail.gmail.com>
References: <CADtTMvn8=uqCwwtvrqjLuN_6ADt+65YpEffSqnBozmWXWO--9A@mail.gmail.com>
	<CAF5CFkhTU9j6wWv+-wKkCaX65fwZSYsMNGf_nAwb+vwPtsbkYQ@mail.gmail.com>
Message-ID: <CADtTMvmffNZMrrxvBjc=_4+LDRvvXJuz84bFCESgB5LjCGnpKg@mail.gmail.com>

The current DA is only sufficient if the coin has the highest
hashpower. It's also just really slow.  If miners somehow stick with
SegWit2x despite the higher rewards in defecting back to bitcoin, then
bitcoin will have long block delays. High transaction fees will
probably help them defect back to us. But if SegWit2x manages to be
more comparable in price than BCH (despite the futures), hashpower
could very well oscillate back and forth between the two coins,
causing delays in both of them. The first one to hard fork to fix the
difficulty problem will have a large advantage, as evidenced by what
happens in alts.   In any event someday BTC may not be the biggest kid
on the block and will need a difficulty algorithm that alts would find
acceptable. Few alts use anything like BTC's because they are not able
to survive the resulting long delays.   I am recommending BTC
developers watch what happens as BCH goes live with a much better
algorithm, in case BTC needs to hard fork for the same reason and
needs a similar fix. Ignore the trolls.

On Thu, Nov 2, 2017 at 7:39 PM, CryptAxe <cryptaxe at gmail.com> wrote:
> Is there an issue with the current difficulty adjustment algorithm? It's
> worked very well as far as I can tell. Introducing a new one seems pretty
> risky, what would the benefit be?
>
> On Nov 2, 2017 4:34 PM, "Scott Roberts via bitcoin-dev"
> <bitcoin-dev at lists.linuxfoundation.org> wrote:
>>
>> Bitcoin cash will hard fork on Nov 13 to implement a new difficulty
>> algorithm.  Bitcoin itself might need to hard fork to employ a similar
>> algorithm. It's about as good as they come because it followed the
>> "simplest is best" route. Their averaging window is probably
>> significantly too long (N=144). It's:
>>
>> next_D = sum (past 144 D's) * T / sum(past 144 solvetimes)
>>
>> They correctly did not use max(timestamp) - min(timestamp) in the
>> denominator like others do.
>>
>> They've written the code and they're about to use it live, so Bitcoin
>> will have a clear, simple, and tested path if it suddenly needs to
>> hard fork due to having 20x delays for the next 2000 blocks (taking it
>> a year to get unstuck).
>>
>> Details on it and the decision process:
>> https://www.bitcoinabc.org/november
>>
>> It uses a nice median of 3 for the beginning and end of the window to
>> help alleviate bad timestamp problems. It's nice, helps a little, but
>> will also slow its response by 1 block.  They also have 2x and 1/2
>> limits on the adjustment per block, which is a lot more than they will
>> ever need.
>>
>> I recommend bitcoin consider using it and making it N=50 instead of 144.
>>
>> I have seen that any attempts to modify the above with things like a
>> low pass filter, starting the window at MTP, or preventing negative
>> timestamps will only reduce its effectiveness. Bitcoin's +12 and -6
>> limits on the timestamps are sufficient and well chosen, although
>> something a bit smaller than the +12 might have been better.
>>
>> One of the contenders to the above is new and actually better, devised
>> by Degnr8 and they call it D622 or wt-144.It's a little better than
>> they realize. It's the only real improvement in difficulty algorithms
>> since the rolling average.  It gives a linearly higher weight to the
>> more recent timestamps. Otherwise it is the same. Others have probably
>> come across it, but there is too much noise in difficulty algorithms
>> to find the good ones.
>>
>> # Degnr8's D622 difficulty algorithm
>> # T=TargetTime, S=Solvetime
>> # modified by zawy
>> for i = 1 to N  (from oldest to most recent block)
>>     t += T[i] / D[i] * i
>>     j += i
>> next i
>> next_D = j / t * T
>>
>> I believe any modification to the above strict mathematical weighted
>> average will reduce it's effectiveness. It does not oscillate anymore
>> than regular algos and rises faster and drops faster, when needed.
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

From hampus.sjoberg at gmail.com  Fri Nov  3 12:59:46 2017
From: hampus.sjoberg at gmail.com (=?UTF-8?Q?Hampus_Sj=C3=B6berg?=)
Date: Fri, 3 Nov 2017 13:59:46 +0100
Subject: [bitcoin-dev] Simplicity proposal - Jets?
In-Reply-To: <CAMZUoKk+8MFLywQB3jQFkk7BYZ4Rw3Paj=ErQe8pZ0beGwu0RA@mail.gmail.com>
References: <mailman.5469.1509483670.27509.bitcoin-dev@lists.linuxfoundation.org>
	<052D6E20-7194-4645-B628-1B7B7FECF330@gmail.com>
	<CAMZUoKk+8MFLywQB3jQFkk7BYZ4Rw3Paj=ErQe8pZ0beGwu0RA@mail.gmail.com>
Message-ID: <CAFMkqK_rXb9fAiGC_qNf5nj_cShJgAB4qTUsCM+R07DSAau2TA@mail.gmail.com>

Thank you for your answer, Russel.

When a code path takes advantage of a jet, does the Simplicity code still
need to be publicly available/visible in the blockchain? I imagine that for
big algorithms (say for example EDCA verification/SHA256 hashing etc), it
would take up a lot of space in the blockchain.
Is there any way to mitigate this?

I guess in a softfork for a jet, the Simplicity code for a jet could be
defined as "consensus", instead of needed to be provided within every
script output.
When the Simplicity interpretor encounters an expression that has a jet, it
would run the C/Assembly code instead of interpreting the Simplicity code.
By formal verification we would be sure they match.

Greetings
Hampus

2017-11-03 2:10 GMT+01:00 Russell O'Connor via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org>:

> Hi Jose,
>
> Jets are briefly discussed in section 3.4 of https://blockstream.com/
> simplicity.pdf
>
> The idea is that we can recognize some set of popular Simplicity
> expressions, and when the Simplicity interpreter encounters one of these
> expressions it can skip over the Simplicity interpreter and instead
> directly evaluate the function using specialized C or assembly code.
>
> For example, when the Simplicity interpreter encounters the Simplicity
> expression for ECDSA verification, it might directly call into libsecp
> rather than continuing the ECDSA verification using interpreted Simplicity.
>
> HTH.
>
>
> On Nov 2, 2017 18:35, "JOSE FEMENIAS CA?UELO via bitcoin-dev" <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
> Hi,
>
> I am trying to follow this Simplicity proposal and I am seeing all over
> references to ?jets?, but I haven?t been able to find any good reference to
> it.
> Can anyone give me a brief explanation and or a link pointing to this
> feature?
> Thanks
>
> On 31 Oct 2017, at 22:01, bitcoin-dev-request at lists.linuxfoundation.org
> wrote:
>
> The plan is that discounted jets will be explicitly labeled as jets in the
> commitment.  If you can provide a Merkle path from the root to a node that
> is an explicit jet, but that jet isn't among the finite number of known
> discounted jets,
>
>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171103/e9a5e8b1/attachment-0001.html>

From mark at friedenbach.org  Fri Nov  3 16:19:39 2017
From: mark at friedenbach.org (Mark Friedenbach)
Date: Fri, 3 Nov 2017 09:19:39 -0700
Subject: [bitcoin-dev] Simplicity proposal - Jets?
In-Reply-To: <CAFMkqK_rXb9fAiGC_qNf5nj_cShJgAB4qTUsCM+R07DSAau2TA@mail.gmail.com>
References: <mailman.5469.1509483670.27509.bitcoin-dev@lists.linuxfoundation.org>
	<052D6E20-7194-4645-B628-1B7B7FECF330@gmail.com>
	<CAMZUoKk+8MFLywQB3jQFkk7BYZ4Rw3Paj=ErQe8pZ0beGwu0RA@mail.gmail.com>
	<CAFMkqK_rXb9fAiGC_qNf5nj_cShJgAB4qTUsCM+R07DSAau2TA@mail.gmail.com>
Message-ID: <4F2B4652-BEB4-4202-AA30-0E8D0BEBDD17@friedenbach.org>

To reiterate, none of the current work focuses on Bitcoin integration, and many architectures are possible.

However the Jets would have to be specified and agreed to upfront for costing reasons, and so they would be known to all validators. There would be no reason to include anything more then the identifying hash in any contract using the jet.

> On Nov 3, 2017, at 5:59 AM, Hampus Sj?berg via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
> 
> Thank you for your answer, Russel.
> 
> When a code path takes advantage of a jet, does the Simplicity code still need to be publicly available/visible in the blockchain? I imagine that for big algorithms (say for example EDCA verification/SHA256 hashing etc), it would take up a lot of space in the blockchain.
> Is there any way to mitigate this?
> 
> I guess in a softfork for a jet, the Simplicity code for a jet could be defined as "consensus", instead of needed to be provided within every script output.
> When the Simplicity interpretor encounters an expression that has a jet, it would run the C/Assembly code instead of interpreting the Simplicity code. By formal verification we would be sure they match.
> 
> Greetings
> Hampus
> 
> 2017-11-03 2:10 GMT+01:00 Russell O'Connor via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>:
>> Hi Jose,
>> 
>> Jets are briefly discussed in section 3.4 of https://blockstream.com/simplicity.pdf
>> 
>> The idea is that we can recognize some set of popular Simplicity expressions, and when the Simplicity interpreter encounters one of these expressions it can skip over the Simplicity interpreter and instead directly evaluate the function using specialized C or assembly code.
>> 
>> For example, when the Simplicity interpreter encounters the Simplicity expression for ECDSA verification, it might directly call into libsecp rather than continuing the ECDSA verification using interpreted Simplicity.
>> 
>> HTH.
>> 
>> 
>> On Nov 2, 2017 18:35, "JOSE FEMENIAS CA?UELO via bitcoin-dev" <bitcoin-dev at lists.linuxfoundation.org> wrote:
>> Hi,
>> 
>> I am trying to follow this Simplicity proposal and I am seeing all over references to ?jets?, but I haven?t been able to find any good reference to it.
>> Can anyone give me a brief explanation and or a link pointing to this feature?
>> Thanks
>> 
>>> On 31 Oct 2017, at 22:01, bitcoin-dev-request at lists.linuxfoundation.org wrote:
>>> 
>>> The plan is that discounted jets will be explicitly labeled as jets in the
>>> commitment.  If you can provide a Merkle path from the root to a node that
>>> is an explicit jet, but that jet isn't among the finite number of known
>>> discounted jets,
>> 
>> 
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>> 
>> 
>> 
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>> 
> 
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171103/cffee143/attachment.html>

From adan at stampery.co  Fri Nov  3 16:42:38 2017
From: adan at stampery.co (=?UTF-8?Q?Ad=c3=a1n_S=c3=a1nchez_de_Pedro_Crespo?=)
Date: Fri, 3 Nov 2017 17:42:38 +0100
Subject: [bitcoin-dev] Simplicity proposal - Jets?
In-Reply-To: <CAFMkqK_rXb9fAiGC_qNf5nj_cShJgAB4qTUsCM+R07DSAau2TA@mail.gmail.com>
References: <mailman.5469.1509483670.27509.bitcoin-dev@lists.linuxfoundation.org>
	<052D6E20-7194-4645-B628-1B7B7FECF330@gmail.com>
	<CAMZUoKk+8MFLywQB3jQFkk7BYZ4Rw3Paj=ErQe8pZ0beGwu0RA@mail.gmail.com>
	<CAFMkqK_rXb9fAiGC_qNf5nj_cShJgAB4qTUsCM+R07DSAau2TA@mail.gmail.com>
Message-ID: <8540b26e-d6a9-3e3c-2ff6-6edb7e1e03df@stampery.com>

If I did understand it right, you don't need to publish the Simplicity
code for the "jetable" expression.

That's the whole point of MAST. Each Simplicity expression can be
identified by its MAST root (the Merkle root of all branches in its
Abstract Syntax Tree).

Imagine you want to write a Simplicity script that is roughly equivalent
to P2PKH. Regardless of directly writing such script or using a higher
level smart contract language, you won't likely write for yourself the
part in which you compute the hash of the public key. Instead, you are
expected to include some external library providing hash functions or at
least copy and paste such function into your code.

As everyone is expected to use the same, let's say, RIPEMD160
implementation, it doesn't matter how you included such function in your
program. The point is that once you build the MAST for your program,
such function will be completely replaced by its MAST root---which is
nothing but a hash.

This way, when the Simplicity interpreter (the BitMachine) bumps into
the hash, it can look for it in a predefined jets dictionary and find
the binary for a precompiled, formally proven implementation of a
function that is perfectly equivalent to the original Simplicity code.


On 03.11.2017 13:59, Hampus Sj?berg via bitcoin-dev wrote:
> Thank you for your answer, Russel.
> 
> When a code path takes advantage of a jet, does the Simplicity code
> still need to be publicly available/visible in the blockchain? I imagine
> that for big algorithms (say for example EDCA verification/SHA256
> hashing etc), it would take up a lot of space in the blockchain.
> Is there any way to mitigate this?
> 
> I guess in a softfork for a jet, the Simplicity code for a jet could be
> defined as "consensus", instead of needed to be provided within every
> script output.
> When the Simplicity interpretor encounters an expression that has a jet,
> it would run the C/Assembly code instead of interpreting the Simplicity
> code. By formal verification we would be sure they match.
> 
> Greetings
> Hampus
> 
> 2017-11-03 2:10 GMT+01:00 Russell O'Connor via bitcoin-dev
> <bitcoin-dev at lists.linuxfoundation.org
> <mailto:bitcoin-dev at lists.linuxfoundation.org>>:
> 
>     Hi Jose,
> 
>     Jets are briefly discussed in section 3.4 of
>     https://blockstream.com/simplicity.pdf
>     <https://blockstream.com/simplicity.pdf>
> 
>     The idea is that we can recognize some set of popular Simplicity
>     expressions, and when the Simplicity interpreter encounters one of
>     these expressions it can skip over the Simplicity interpreter and
>     instead directly evaluate the function using specialized C or
>     assembly code.
> 
>     For example, when the Simplicity interpreter encounters the
>     Simplicity expression for ECDSA verification, it might directly call
>     into libsecp rather than continuing the ECDSA verification using
>     interpreted Simplicity.
> 
>     HTH.
> 
> 
>     On Nov 2, 2017 18:35, "JOSE FEMENIAS CA?UELO via bitcoin-dev"
>     <bitcoin-dev at lists.linuxfoundation.org
>     <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:
> 
>         Hi,
> 
>         I am trying to follow this Simplicity proposal and I am seeing
>         all over references to ?jets?, but I haven?t been able to find
>         any good reference to it.
>         Can anyone give me a brief explanation and or a link pointing to
>         this feature?
>         Thanks
> 
>>         On 31 Oct 2017, at 22:01,
>>         bitcoin-dev-request at lists.linuxfoundation.org
>>         <mailto:bitcoin-dev-request at lists.linuxfoundation.org> wrote:
>>
>>         The plan is that discounted jets will be explicitly labeled as
>>         jets in the
>>         commitment.? If you can provide a Merkle path from the root to
>>         a node that
>>         is an explicit jet, but that jet isn't among the finite number
>>         of known
>>         discounted jets,
> 
> 
>         _______________________________________________
>         bitcoin-dev mailing list
>         bitcoin-dev at lists.linuxfoundation.org
>         <mailto:bitcoin-dev at lists.linuxfoundation.org>
>         https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>         <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>
> 
> 
> 
>     _______________________________________________
>     bitcoin-dev mailing list
>     bitcoin-dev at lists.linuxfoundation.org
>     <mailto:bitcoin-dev at lists.linuxfoundation.org>
>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>     <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>
> 
> 
> 
> 
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> 

-- 
Ad?n S?nchez de Pedro Crespo
CTO, Stampery Inc.
San Francisco - Madrid

From vitteaymeric at gmail.com  Fri Nov  3 18:15:10 2017
From: vitteaymeric at gmail.com (Aymeric Vitte)
Date: Fri, 3 Nov 2017 19:15:10 +0100
Subject: [bitcoin-dev] Proposal: allocate Github issue instead of wiki
 page to BIP discussion
In-Reply-To: <FBA2AA31-D63C-479C-B890-A14E6F08B3A4@sprovoost.nl>
References: <FBA2AA31-D63C-479C-B890-A14E6F08B3A4@sprovoost.nl>
Message-ID: <551f3289-48cf-a819-5d45-59249498e8c1@gmail.com>

+10k

Indeed, as any project Github issues should be enabled for BIPs,
wondering too since some time why this is not the case, and then if an
issue is worth discussing here it can be redirected to the list


Le 03/11/2017 ? 10:50, Sjors Provoost via bitcoin-dev a ?crit?:
> I often find myself wanting to leave relatively small comments on BIP's that are IMO not worth bothering this list.
>
> By default each BIP has a wiki page for discussion, e.g. https://github.com/bitcoin/bips/wiki/Comments:BIP-0150
> This is linked to from the Comments-URI field in the BIP.
>
> In order to leave a comment, you have to edit the wiki page. This process seems a bit clunky.
>
> I think it would be better to use Github issues, with one Github issue for each BIP.
>
> One concern might be that the ease of use of Github issues would move discussion away from this list. The issue could be temporarily locked to prevent that. The issue description could contain a standard text explaining what should be discussed there and what would be more appropriate to post on the mailinglist.
>
> Another concern might be confusing between PR's which create and update a BIP, and the discussion issue.
>
> If people think this a good idea, would the next step be to propose a change to the process here?
> https://github.com/bitcoin/bips/blob/master/bip-0002.mediawiki#BIP_comments
>
> Or would this be a new BIP?
>
> Sjors
>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

-- 
Zcash wallets made simple: https://github.com/Ayms/zcash-wallets
Bitcoin wallets made simple: https://github.com/Ayms/bitcoin-wallets
Get the torrent dynamic blocklist: http://peersm.com/getblocklist
Check the 10 M passwords list: http://peersm.com/findmyass
Anti-spies and private torrents, dynamic blocklist: http://torrent-live.org
Peersm : http://www.peersm.com
torrent-live: https://github.com/Ayms/torrent-live
node-Tor : https://www.github.com/Ayms/node-Tor
GitHub : https://www.github.com/Ayms

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171103/d53bc45e/attachment-0001.html>

From jacob.eliosoff at gmail.com  Sat Nov  4 03:37:06 2017
From: jacob.eliosoff at gmail.com (Jacob Eliosoff)
Date: Fri, 3 Nov 2017 23:37:06 -0400
Subject: [bitcoin-dev] Bitcoin Cash's new difficulty algorithm
In-Reply-To: <CADtTMvmffNZMrrxvBjc=_4+LDRvvXJuz84bFCESgB5LjCGnpKg@mail.gmail.com>
References: <CADtTMvn8=uqCwwtvrqjLuN_6ADt+65YpEffSqnBozmWXWO--9A@mail.gmail.com>
	<CAF5CFkhTU9j6wWv+-wKkCaX65fwZSYsMNGf_nAwb+vwPtsbkYQ@mail.gmail.com>
	<CADtTMvmffNZMrrxvBjc=_4+LDRvvXJuz84bFCESgB5LjCGnpKg@mail.gmail.com>
Message-ID: <CAAUaCyjzAHDndcWr07hbVrXS5Y8Cz7Dq_B7p7NqZ7i0VS=fM7Q@mail.gmail.com>

I'm no BCH fan, but I agree with Scott that changes to the DAA may be of
more than purely theoretical interest for BTC.  Anyway just for those
interested, below is an algo I've been playing with that adjusts difficulty
every block, based only on the previous block's time and difficulty.  I
tested it a bit and it seems to adapt to hashrate swings pretty well.

weight_n = 1 - e^-(blocktime_n / 1 hr)    # 1 hr = exp moving avg window -
too short?
adj_n = (10 min / blocktime_n) - 1
difficulty_(n+1) = difficulty_n * (1 + weight_n * adj_n)

It could also be tweaked to make the *historical* avg block time ~exactly
10 minutes, ie, to target > 10 min if past blocks were < 10 min.  This
would, eg, make mapping future block numbers to calendar times much more
exact.


On Nov 3, 2017 7:24 AM, "Scott Roberts via bitcoin-dev" <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> The current DA is only sufficient if the coin has the highest
> hashpower. It's also just really slow.  If miners somehow stick with
> SegWit2x despite the higher rewards in defecting back to bitcoin, then
> bitcoin will have long block delays. High transaction fees will
> probably help them defect back to us. But if SegWit2x manages to be
> more comparable in price than BCH (despite the futures), hashpower
> could very well oscillate back and forth between the two coins,
> causing delays in both of them. The first one to hard fork to fix the
> difficulty problem will have a large advantage, as evidenced by what
> happens in alts.   In any event someday BTC may not be the biggest kid
> on the block and will need a difficulty algorithm that alts would find
> acceptable. Few alts use anything like BTC's because they are not able
> to survive the resulting long delays.   I am recommending BTC
> developers watch what happens as BCH goes live with a much better
> algorithm, in case BTC needs to hard fork for the same reason and
> needs a similar fix. Ignore the trolls.
>
> On Thu, Nov 2, 2017 at 7:39 PM, CryptAxe <cryptaxe at gmail.com> wrote:
> > Is there an issue with the current difficulty adjustment algorithm? It's
> > worked very well as far as I can tell. Introducing a new one seems pretty
> > risky, what would the benefit be?
> >
> > On Nov 2, 2017 4:34 PM, "Scott Roberts via bitcoin-dev"
> > <bitcoin-dev at lists.linuxfoundation.org> wrote:
> >>
> >> Bitcoin cash will hard fork on Nov 13 to implement a new difficulty
> >> algorithm.  Bitcoin itself might need to hard fork to employ a similar
> >> algorithm. It's about as good as they come because it followed the
> >> "simplest is best" route. Their averaging window is probably
> >> significantly too long (N=144). It's:
> >>
> >> next_D = sum (past 144 D's) * T / sum(past 144 solvetimes)
> >>
> >> They correctly did not use max(timestamp) - min(timestamp) in the
> >> denominator like others do.
> >>
> >> They've written the code and they're about to use it live, so Bitcoin
> >> will have a clear, simple, and tested path if it suddenly needs to
> >> hard fork due to having 20x delays for the next 2000 blocks (taking it
> >> a year to get unstuck).
> >>
> >> Details on it and the decision process:
> >> https://www.bitcoinabc.org/november
> >>
> >> It uses a nice median of 3 for the beginning and end of the window to
> >> help alleviate bad timestamp problems. It's nice, helps a little, but
> >> will also slow its response by 1 block.  They also have 2x and 1/2
> >> limits on the adjustment per block, which is a lot more than they will
> >> ever need.
> >>
> >> I recommend bitcoin consider using it and making it N=50 instead of 144.
> >>
> >> I have seen that any attempts to modify the above with things like a
> >> low pass filter, starting the window at MTP, or preventing negative
> >> timestamps will only reduce its effectiveness. Bitcoin's +12 and -6
> >> limits on the timestamps are sufficient and well chosen, although
> >> something a bit smaller than the +12 might have been better.
> >>
> >> One of the contenders to the above is new and actually better, devised
> >> by Degnr8 and they call it D622 or wt-144.It's a little better than
> >> they realize. It's the only real improvement in difficulty algorithms
> >> since the rolling average.  It gives a linearly higher weight to the
> >> more recent timestamps. Otherwise it is the same. Others have probably
> >> come across it, but there is too much noise in difficulty algorithms
> >> to find the good ones.
> >>
> >> # Degnr8's D622 difficulty algorithm
> >> # T=TargetTime, S=Solvetime
> >> # modified by zawy
> >> for i = 1 to N  (from oldest to most recent block)
> >>     t += T[i] / D[i] * i
> >>     j += i
> >> next i
> >> next_D = j / t * T
> >>
> >> I believe any modification to the above strict mathematical weighted
> >> average will reduce it's effectiveness. It does not oscillate anymore
> >> than regular algos and rises faster and drops faster, when needed.
> >> _______________________________________________
> >> bitcoin-dev mailing list
> >> bitcoin-dev at lists.linuxfoundation.org
> >> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171103/2e7123e2/attachment.html>

From luke at dashjr.org  Sat Nov  4 07:59:07 2017
From: luke at dashjr.org (Luke Dashjr)
Date: Sat, 4 Nov 2017 07:59:07 +0000
Subject: [bitcoin-dev] Merkle branch verification & tail-call semantics
	for generalized MAST
In-Reply-To: <4F328120-94E0-4EFF-A76D-99E6007FA906@friedenbach.org>
References: <5B6756D0-6BEF-4A01-BDB8-52C646916E29@friedenbach.org>
	<201711010843.49771.luke@dashjr.org>
	<4F328120-94E0-4EFF-A76D-99E6007FA906@friedenbach.org>
Message-ID: <201711040759.09710.luke@dashjr.org>

How about using for the first stage, `<...> OP_CALCMERKLEROOT <root> OP_EQUAL` 
instead of `<root...> OP_CHECKMERKLEBRANCH`? There's maybe 1 or 2 bytes extra, 
but it seems more future-proof (since there could more easily be alternatives 
to `<root> OP_EQUAL` in future script versions).

OTOH, OP_ADDTOSCRIPTHASH may be fatally incompatible with script versioning... 
Old nodes won't know how to check the witness program, which means an 
undefined version could be used to bypass the correct script entirely.
Need to think more on this still.

Luke


On Wednesday 01 November 2017 3:08:46 PM Mark Friedenbach wrote:
> Yes, if you use a witness script version you can save about 40 witness
> bytes by templating the MBV script, which I think is equivalent to what
> you are suggesting. 32 bytes from the saved hash, plus another 8 bytes or
> so from script templates and more efficient serialization.
> 
> I believe the conservatively correct approach is to do this in stages,
> however. First roll out MBV and tail call to witness v0. Then once there
> is experience with people using it in production, design and deploy a
> hashing template for script v1. It might be that we learn more and think
> of something better in the meantime.
> 
> > On Nov 1, 2017, at 1:43 AM, Luke Dashjr <luke at dashjr.org> wrote:
> > 
> > Mark,
> > 
> > I think I have found an improvement that can be made.
> > 
> > As you recall, a downside to this approach is that one must make two
> > commitments: first, to the particular "membership-checking script"; and
> > then in that script, to the particular merkle root of possible scripts.
> > 
> > Would there be any harm in, instead of checking membership, *calculating*
> > the root? If not, then we could define that instead of the witness
> > program committing to H(membership-check script), it rather commits to
> > H(membership- calculation script | data added by an OP_ADDTOSCRIPTHASH).
> > This would, I believe, securely reduce the commitment of both to a
> > single hash.
> > 
> > It also doesn't reduce flexibility, since one could omit
> > OP_ADDTOSCRIPTHASH from their "membership-calculation" script to get the
> > previous membership- check behaviour, and use <hash> OP_EQUAL in its
> > place.
> > 
> > What do you think?
> > 
> > Luke
> > 
> >> On Saturday 28 October 2017 4:40:01 AM Mark Friedenbach wrote:
> >> I have completed updating the three BIPs with all the feedback that I
> >> have received so far. In short summary, here is an incomplete list of
> >> the changes that were made:
> >> 
> >> * Modified the hashing function fast-SHA256 so that an internal node
> >> cannot be interpreted simultaneously as a leaf. * Changed
> >> MERKLEBRANCHVERIFY to verify a configurable number of elements from the
> >> tree, instead of just one. * Changed MERKLEBRANCHVERIFY to have two
> >> modes: one where the inputs are assumed to be hashes, and one where
> >> they are run through double-SHA256 first. * Made tail-call eval
> >> compatible with BIP141?s CLEANSTACK consensus rule by allowing
> >> parameters to be passed on the alt-stack. * Restricted tail-call eval
> >> to segwit scripts only, so that checking sigop and opcode limits of the
> >> policy script would not be necessary.
> >> 
> >> There were a bunch of other small modifications, typo fixes, and
> >> optimizations that were made as well.
> >> 
> >> I am now ready to submit these BIPs as a PR against the bitcoin/bips
> >> repo, and I request that the BIP editor assign numbers.
> >> 
> >> Thank you,
> >> Mark Friedenbach
> >> 
> >>> On Sep 6, 2017, at 5:38 PM, Mark Friedenbach <mark at friedenbach.org>
> >>> wrote:
> >>> 
> >>> I would like to propose two new script features to be added to the
> >>> bitcoin protocol by means of soft-fork activation. These features are
> >>> a new opcode, MERKLE-BRANCH-VERIFY (MBV) and tail-call execution
> >>> semantics.
> >>> 
> >>> In brief summary, MERKLE-BRANCH-VERIFY allows script authors to force
> >>> redemption to use values selected from a pre-determined set committed
> >>> to in the scriptPubKey, but without requiring revelation of unused
> >>> elements in the set for both enhanced privacy and smaller script
> >>> sizes. Tail-call execution semantics allows a single level of
> >>> recursion into a subscript, providing properties similar to P2SH while
> >>> at the same time more flexible.
> >>> 
> >>> These two features together are enough to enable a range of
> >>> applications such as tree signatures (minus Schnorr aggregation) as
> >>> described by Pieter Wuille [1], and a generalized MAST useful for
> >>> constructing private smart contracts. It also brings privacy and
> >>> fungibility improvements to users of counter-signing wallet/vault
> >>> services as unique redemption policies need only be revealed if/when
> >>> exceptional circumstances demand it, leaving most transactions looking
> >>> the same as any other MAST-enabled multi-sig script.
> >>> 
> >>> I believe that the implementation of these features is simple enough,
> >>> and the use cases compelling enough that we could BIP 8/9 rollout of
> >>> these features in relatively short order, perhaps before the end of
> >>> the year.
> >>> 
> >>> I have written three BIPs to describe these features, and their
> >>> associated implementation, for which I now invite public review and
> >>> discussion:
> >>> 
> >>> Fast Merkle Trees
> >>> BIP: https://gist.github.com/maaku/41b0054de0731321d23e9da90ba4ee0a
> >>> Code: https://github.com/maaku/bitcoin/tree/fast-merkle-tree
> >>> 
> >>> MERKLEBRANCHVERIFY
> >>> BIP: https://gist.github.com/maaku/bcf63a208880bbf8135e453994c0e431
> >>> Code: https://github.com/maaku/bitcoin/tree/merkle-branch-verify
> >>> 
> >>> Tail-call execution semantics
> >>> BIP: https://gist.github.com/maaku/f7b2e710c53f601279549aa74eeb5368
> >>> Code: https://github.com/maaku/bitcoin/tree/tail-call-semantics
> >>> 
> >>> Note: I have circulated this idea privately among a few people, and I
> >>> will note that there is one piece of feedback which I agree with but
> >>> is not incorporated yet: there should be a multi-element MBV opcode
> >>> that allows verifying multiple items are extracted from a single
> >>> tree. It is not obvious how MBV could be modified to support this
> >>> without sacrificing important properties, or whether should be a
> >>> separate multi-MBV opcode instead.
> >>> 
> >>> Kind regards,
> >>> Mark Friedenbach

From aj at erisian.com.au  Sun Nov  5 17:50:33 2017
From: aj at erisian.com.au (Anthony Towns)
Date: Mon, 6 Nov 2017 03:50:33 +1000
Subject: [bitcoin-dev] "Changes without unanimous consent" talk at Scaling
	Bitcoin
Message-ID: <20171105175033.GB23915@erisian.com.au>

Hi,

Paper (and slides) for my talk in the Consensus stream of Scaling Bitcoin
this morning are at:

   https://github.com/ajtowns/sc-btc-2017/releases

Some analysis for split-related consensus changes, and (code-less)
proposals for generic replay protection (a la BIP 115) and providing a
better level of price discovery for proposals that could cause splits.

Cheers,
aj


From mats at blockchain.com  Sun Nov  5 23:48:43 2017
From: mats at blockchain.com (Mats Jerratsch)
Date: Sun, 5 Nov 2017 23:48:43 +0000
Subject: [bitcoin-dev] Generalised Replay Protection for Future Hard Forks
Message-ID: <7601C2CD-8544-4501-80CE-CAEB402A72D2@blockchain.com>


Presented is a generalised way of providing replay protection for future hard forks. On top of replay protection, this schema also allows for fork-distinct addresses and potentially a way to opt-out of replay protection of any fork, where deemed necessary (can be beneficial for some L2 applications).

## Rationale

Currently when a hard fork happens, there is ad-hoc replay protection built within days with little review at best, or no replay protection at all. Often this is either resource problem, where not enough time and developers are available to sufficiently address replay protection, or the idea that not breaking compatibility is favourable. Furthermore, this is potentially a recurring problem with no generally accepted solution yet. Services that want to deal in multiple forks are expected to closely follow all projects. Since there is no standard, the solutions differ for each project, requiring custom code for every fork. By integrating replay protection into the protocol, we advocate the notion of non-hostile forks.

Users are protected against accidentally sending coins on the wrong chain through the introduction of a fork-specific incompatible address space. The coin/token type is encoded in the address itself, removing some of the importance around the question _What is Bitcoin?_. By giving someone an address, it is explicitly stated _I will only honour a payment of token X_, enforcing the idea of validating the payment under the rules chosen by the payee.

## Iterative Forks

In this schema, any hard fork is given an incremented id, `nForkId`. `nForkId` starts at `1`, with `0` being reserved as a wildcard. When project X decides to make an incompatible change to the protocol, it will get assigned a new unique `nForkId` for this fork. A similar approach like for BIP43 can be taken here. Potentially `nForkId` can be reused if a project has not gained any amount of traction.

When preparing the transaction for signing or validation, `nForkId` is appended to the final template as a 4B integer (similar to [1]). Amending BIP143, this would result in

```
 Double SHA256 of the serialization of:
     1. nVersion of the transaction (4-byte little endian)
     2. hashPrevouts (32-byte hash)
     3. hashSequence (32-byte hash)
     4. outpoint (32-byte hash + 4-byte little endian)
     5. scriptCode of the input (serialized as scripts inside CTxOuts)
     6. value of the output spent by this input (8-byte little endian)
     7. nSequence of the input (4-byte little endian)
     8. hashOutputs (32-byte hash)
     9. nLocktime of the transaction (4-byte little endian)
    10. sighash type of the signature (4-byte little endian)
    11. nForkId (4-byte little endian)
```


For `nForkId=0` this step is ommitted. This will immediately invalidate signatures for any other branch of the blockchain than this specific fork. To distinguish between `nForkId=0` and `nForkId` hardcoded into the software, another bit has to be set in the 1B SigHashId present at the end of signatures.

To make this approach more generic, payment addresses will contain the fork id, depending on which tokens a payee expects payments in. This would require a change on bech32 addresses, maybe to use a similar format used in lightning-rfc [2]. A wallet will parse the address, it will extract `nForkId`, and it displays which token the user is about to spend. When signing the transaction, it will use `nForkId`, such that the transaction is only valid for this specific token. This can be generalised in software to the point where replay protection *and* a new address space can be introduced for forks without breaking existing clients.

For light clients, this can be extended by enforcing the coinbase/block header to contain the `nForkId` of the block. Then the client can distinguish between different chains and tokens it received on each. Alternatively, a new P2P message type for sending transactions could be introduced, where prevOut and `nForkId` is transmitted, such that the lite client can check for himself, which token he received.

Allowing signatures with `nForkId=1` can be achieved with a soft fork by incrementing the script version of SegWit, making this a fully backwards compatible change.

[1]
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-February/013542.html <https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-February/013542.html>
[2]
https://github.com/lightningnetwork/lightning-rfc/blob/master/11-payment-encoding.md <https://github.com/lightningnetwork/lightning-rfc/blob/master/11-payment-encoding.md>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171105/41f5276f/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 842 bytes
Desc: Message signed with OpenPGP
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171105/41f5276f/attachment.sig>

From pete at petertodd.org  Mon Nov  6 19:50:00 2017
From: pete at petertodd.org (Peter Todd)
Date: Mon, 6 Nov 2017 14:50:00 -0500
Subject: [bitcoin-dev] Introducing a POW through a soft-fork
In-Reply-To: <CAB0O3SVjhG19R61B78hFCPwfwWemTXj=tOsvgAgoNbjFYXXAtg@mail.gmail.com>
References: <CAB0O3SVjhG19R61B78hFCPwfwWemTXj=tOsvgAgoNbjFYXXAtg@mail.gmail.com>
Message-ID: <20171106195000.GA7245@fedora-23-dvm>

On Wed, Nov 01, 2017 at 05:48:27AM +0000, Devrandom via bitcoin-dev wrote:

Some quick thoughts...

> Hi all,
> 
> Feedback is welcome on the draft below.  In particular, I want to see if
> there is interest in further development of the idea and also interested in
> any attack vectors or undesirable dynamics.
> 
> (Formatted version available here:
> https://github.com/devrandom/btc-papers/blob/master/aux-pow.md )
> 
> # Soft-fork Introduction of a New POW

First of all, I don't think you can really call this a soft-fork; I'd call it a
"pseudo-soft-fork"

My reasoning being that after implementation, a chain with less total work than
the main chain - but more total SHA256^2 work than the main chain - might be
followed by non-supporting clients. It's got some properties of a soft-fork,
but it's security model is definitely different.

> ### Aux POW intermediate block
> 
> Auxiliary POW blocks are introduced between normal blocks - i.e. the chain
> alternates between the two POWs.
> Each aux-POW block points to the previous normal block and contains
> transactions just like a normal block.
> Each normal block points to the previous aux-POW block and must contain all
> transactions from the aux-POW block.

Note how you're basically proposing for the block interval to be decreased,
which has security implications due to increased orphan rates.

> ### Heaviest chain rule change
> 
> This is a semi-hard change, because non-upgraded nodes can get on the wrong
> chain in case of attack.  However,

Exactly! Not really a soft-fork.

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 488 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171106/daf2333b/attachment-0001.sig>

From truthcoin at gmail.com  Mon Nov  6 20:30:30 2017
From: truthcoin at gmail.com (Paul Sztorc)
Date: Mon, 6 Nov 2017 15:30:30 -0500
Subject: [bitcoin-dev] Introducing a POW through a soft-fork
In-Reply-To: <20171106195000.GA7245@fedora-23-dvm>
References: <CAB0O3SVjhG19R61B78hFCPwfwWemTXj=tOsvgAgoNbjFYXXAtg@mail.gmail.com>
	<20171106195000.GA7245@fedora-23-dvm>
Message-ID: <CA+XQW1j2vNNswEQ-HVWF9MpyGBzmq3ij+v=2NGH2VicQ63=v6A@mail.gmail.com>

+1 to all of Peter Todd's comments

On Nov 6, 2017 11:50 AM, "Peter Todd via bitcoin-dev" <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> On Wed, Nov 01, 2017 at 05:48:27AM +0000, Devrandom via bitcoin-dev wrote:
>
> Some quick thoughts...
>
> > Hi all,
> >
> > Feedback is welcome on the draft below.  In particular, I want to see if
> > there is interest in further development of the idea and also interested
> in
> > any attack vectors or undesirable dynamics.
> >
> > (Formatted version available here:
> > https://github.com/devrandom/btc-papers/blob/master/aux-pow.md )
> >
> > # Soft-fork Introduction of a New POW
>
> First of all, I don't think you can really call this a soft-fork; I'd call
> it a
> "pseudo-soft-fork"
>
> My reasoning being that after implementation, a chain with less total work
> than
> the main chain - but more total SHA256^2 work than the main chain - might
> be
> followed by non-supporting clients. It's got some properties of a
> soft-fork,
> but it's security model is definitely different.
>
> > ### Aux POW intermediate block
> >
> > Auxiliary POW blocks are introduced between normal blocks - i.e. the
> chain
> > alternates between the two POWs.
> > Each aux-POW block points to the previous normal block and contains
> > transactions just like a normal block.
> > Each normal block points to the previous aux-POW block and must contain
> all
> > transactions from the aux-POW block.
>
> Note how you're basically proposing for the block interval to be decreased,
> which has security implications due to increased orphan rates.
>
> > ### Heaviest chain rule change
> >
> > This is a semi-hard change, because non-upgraded nodes can get on the
> wrong
> > chain in case of attack.  However,
>
> Exactly! Not really a soft-fork.
>
> --
> https://petertodd.org 'peter'[:-1]@petertodd.org
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171106/4c91278d/attachment.html>

From c1.bitcoin at niftybox.net  Mon Nov  6 22:39:02 2017
From: c1.bitcoin at niftybox.net (Devrandom)
Date: Mon, 06 Nov 2017 22:39:02 +0000
Subject: [bitcoin-dev] Introducing a POW through a soft-fork
In-Reply-To: <20171106195000.GA7245@fedora-23-dvm>
References: <CAB0O3SVjhG19R61B78hFCPwfwWemTXj=tOsvgAgoNbjFYXXAtg@mail.gmail.com>
	<20171106195000.GA7245@fedora-23-dvm>
Message-ID: <CAB0O3SVsXL_zVBs-OFEaFuKTXoyYAiB8TEZStOfou7mMkHLMnA@mail.gmail.com>

Hi Peter, thank you for the review.  See below

On Mon, Nov 6, 2017 at 11:50 AM Peter Todd <pete at petertodd.org> wrote:

> On Wed, Nov 01, 2017 at 05:48:27AM +0000, Devrandom via bitcoin-dev wrote:
>
> Some quick thoughts...
>
> > Hi all,
> >
> > Feedback is welcome on the draft below.  In particular, I want to see if
> > there is interest in further development of the idea and also interested
> in
> > any attack vectors or undesirable dynamics.
> >
> > (Formatted version available here:
> > https://github.com/devrandom/btc-papers/blob/master/aux-pow.md )
> >
> > # Soft-fork Introduction of a New POW
>
> First of all, I don't think you can really call this a soft-fork; I'd call
> it a
> "pseudo-soft-fork"
>
> My reasoning being that after implementation, a chain with less total work
> than
> the main chain - but more total SHA256^2 work than the main chain - might
> be
> followed by non-supporting clients. It's got some properties of a
> soft-fork,
> but it's security model is definitely different.
>

The interesting thing is that the cost of attack varies smoothly as you
vary the POW weights.
To attack non-upgraded nodes, you still have to "51%" the original POW.
The reward going to that POW will vary smoothly between 1.0 * block_reward
and whatever
target value (e.g. 0.5 * block_reward) and the difficulty of attack will
tend to be proportional to that.

In a real hard-fork, your software just breaks at the fork point.  In this
case, it's just the non-upgraded
node security level declining from 100% to 50% over a long period of time.

I envision the transition of POW weights will be over 1-3 years, which
leaves plenty of time to
upgrade after the fork activates.


>
> > ### Aux POW intermediate block
> >
> > Auxiliary POW blocks are introduced between normal blocks - i.e. the
> chain
> > alternates between the two POWs.
> > Each aux-POW block points to the previous normal block and contains
> > transactions just like a normal block.
> > Each normal block points to the previous aux-POW block and must contain
> all
> > transactions from the aux-POW block.
>
> Note how you're basically proposing for the block interval to be decreased,
> which has security implications due to increased orphan rates.
>

Note that the total transaction rate and block size don't materially
change, so I don't
see why the orphan rate will change.  Normal blocks are constrained to have
all of the txs of the aux blocks, so propagation time should stay the
same.  Am I missing
something?


>
> > ### Heaviest chain rule change
> >
> > This is a semi-hard change, because non-upgraded nodes can get on the
> wrong
> > chain in case of attack.  However,
>
> Exactly! Not really a soft-fork.
>

"smooth-fork" perhaps? :)


>
> --
> https://petertodd.org 'peter'[:-1]@petertodd.org
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171106/69e6bc4e/attachment.html>

From c1.bitcoin at niftybox.net  Mon Nov  6 23:38:20 2017
From: c1.bitcoin at niftybox.net (Devrandom)
Date: Mon, 06 Nov 2017 23:38:20 +0000
Subject: [bitcoin-dev] Introducing a POW through a soft-fork
In-Reply-To: <CAB0O3SVsXL_zVBs-OFEaFuKTXoyYAiB8TEZStOfou7mMkHLMnA@mail.gmail.com>
References: <CAB0O3SVjhG19R61B78hFCPwfwWemTXj=tOsvgAgoNbjFYXXAtg@mail.gmail.com>
	<20171106195000.GA7245@fedora-23-dvm>
	<CAB0O3SVsXL_zVBs-OFEaFuKTXoyYAiB8TEZStOfou7mMkHLMnA@mail.gmail.com>
Message-ID: <CAB0O3SXHyQhqoKtDZacWOUjzKp+3GimGABGToWrvRQgcBRE6EA@mail.gmail.com>

>
> Note how you're basically proposing for the block interval to be decreased,
>> which has security implications due to increased orphan rates.
>>
>
> Note that the total transaction rate and block size don't materially
> change, so I don't
> see why the orphan rate will change.  Normal blocks are constrained to have
> all of the txs of the aux blocks, so propagation time should stay the
> same.  Am I missing
> something?
>

Ah, yes, I'm missing that the expected time to find each type of block is
halved, so the orphan rate doubles.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171106/ebea9284/attachment.html>

From eric at voskuil.org  Mon Nov  6 20:55:29 2017
From: eric at voskuil.org (Eric Voskuil)
Date: Mon, 6 Nov 2017 12:55:29 -0800
Subject: [bitcoin-dev] Introducing a POW through a soft-fork
In-Reply-To: <CA+XQW1j2vNNswEQ-HVWF9MpyGBzmq3ij+v=2NGH2VicQ63=v6A@mail.gmail.com>
References: <CAB0O3SVjhG19R61B78hFCPwfwWemTXj=tOsvgAgoNbjFYXXAtg@mail.gmail.com>
	<20171106195000.GA7245@fedora-23-dvm>
	<CA+XQW1j2vNNswEQ-HVWF9MpyGBzmq3ij+v=2NGH2VicQ63=v6A@mail.gmail.com>
Message-ID: <61253DDB-A045-4346-A39C-F5C4E07396C7@voskuil.org>

If a block that would be discarded under previous rules becomes accepted after a rule addition, there is no reason to not simply call the new rule a hard fork. IOW it's perfectly rational to consider a weaker block as "invalid" relative to the strong chain. As such I don't see any reason to qualify the term, it's a hard fork. But Peter's observation (the specific behavior) is ultimately what matters.

e

> On Nov 6, 2017, at 12:30, Paul Sztorc via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
> 
> +1 to all of Peter Todd's comments
> 
>> On Nov 6, 2017 11:50 AM, "Peter Todd via bitcoin-dev" <bitcoin-dev at lists.linuxfoundation.org> wrote:
>> On Wed, Nov 01, 2017 at 05:48:27AM +0000, Devrandom via bitcoin-dev wrote:
>> 
>> Some quick thoughts...
>> 
>> > Hi all,
>> >
>> > Feedback is welcome on the draft below.  In particular, I want to see if
>> > there is interest in further development of the idea and also interested in
>> > any attack vectors or undesirable dynamics.
>> >
>> > (Formatted version available here:
>> > https://github.com/devrandom/btc-papers/blob/master/aux-pow.md )
>> >
>> > # Soft-fork Introduction of a New POW
>> 
>> First of all, I don't think you can really call this a soft-fork; I'd call it a
>> "pseudo-soft-fork"
>> 
>> My reasoning being that after implementation, a chain with less total work than
>> the main chain - but more total SHA256^2 work than the main chain - might be
>> followed by non-supporting clients. It's got some properties of a soft-fork,
>> but it's security model is definitely different.
>> 
>> > ### Aux POW intermediate block
>> >
>> > Auxiliary POW blocks are introduced between normal blocks - i.e. the chain
>> > alternates between the two POWs.
>> > Each aux-POW block points to the previous normal block and contains
>> > transactions just like a normal block.
>> > Each normal block points to the previous aux-POW block and must contain all
>> > transactions from the aux-POW block.
>> 
>> Note how you're basically proposing for the block interval to be decreased,
>> which has security implications due to increased orphan rates.
>> 
>> > ### Heaviest chain rule change
>> >
>> > This is a semi-hard change, because non-upgraded nodes can get on the wrong
>> > chain in case of attack.  However,
>> 
>> Exactly! Not really a soft-fork.
>> 
>> --
>> https://petertodd.org 'peter'[:-1]@petertodd.org
>> 
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>> 
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171106/08da67fe/attachment-0001.html>

From jacob.eliosoff at gmail.com  Mon Nov  6 19:21:28 2017
From: jacob.eliosoff at gmail.com (Jacob Eliosoff)
Date: Mon, 6 Nov 2017 14:21:28 -0500
Subject: [bitcoin-dev] Generalised Replay Protection for Future Hard
	Forks
In-Reply-To: <CAAUaCyii2U5VBLS+Va+F3h4Hka0OWDnFFmjtsvyaaD4TKVzV3Q@mail.gmail.com>
References: <7601C2CD-8544-4501-80CE-CAEB402A72D2@blockchain.com>
	<CAAUaCyii2U5VBLS+Va+F3h4Hka0OWDnFFmjtsvyaaD4TKVzV3Q@mail.gmail.com>
Message-ID: <CAAUaCyiZ0bmWZLZc-yDvVHupzbdRR=Kdq4P8VkWqpU1L3G-u3A@mail.gmail.com>

Thanks Mats, this proposal makes sense to me (especially the idea of
fork-specific addresses).  It prevents replay across forks, and makes it
easy for client software, and thus potentially users, to specify which fork
a tx is for.  But, like other (rougher) past proposals I've seen, it does
little to prevent users from accidentally sending on the wrong fork.

Take the specific and common case of non-upgraded wallet software.  Suppose
a HF happens, and becomes the network used by 90% of users.  Will old
wallets still default to the old nForkId (10% legacy chain)?  If so, I'd
expect a lot of accidental mis-sends on that chain.

This is just a gap in your proposal, not a flaw, but it's worth thinking
about less hazard-prone ways wallets could default nForkId.  Perhaps they
could listen to all forks, and default to the one whose last (recent) block
had the highest difficulty?  Or just check those blocks to see if multiple
forks are (nontrivially) active, and if so warn the user and force them to
confirm?  Something like that.


On Nov 6, 2017 7:05 AM, "Mats Jerratsch via bitcoin-dev" <
bitcoin-dev at lists.linuxfoundation.org> wrote:


Presented is a generalised way of providing replay protection for future
hard forks. On top of replay protection, this schema also allows for
fork-distinct addresses and potentially a way to opt-out of replay
protection of any fork, where deemed necessary (can be beneficial for some
L2 applications).

## Rationale

Currently when a hard fork happens, there is ad-hoc replay protection built
within days with little review at best, or no replay protection at all.
Often this is either resource problem, where not enough time and developers
are available to sufficiently address replay protection, or the idea that
not breaking compatibility is favourable. Furthermore, this is potentially
a recurring problem with no generally accepted solution yet. Services that
want to deal in multiple forks are expected to closely follow all projects.
Since there is no standard, the solutions differ for each project,
requiring custom code for every fork. By integrating replay protection into
the protocol, we advocate the notion of non-hostile forks.

Users are protected against accidentally sending coins on the wrong chain
through the introduction of a fork-specific incompatible address space. The
coin/token type is encoded in the address itself, removing some of the
importance around the question _What is Bitcoin?_. By giving someone an
address, it is explicitly stated _I will only honour a payment of token X_,
enforcing the idea of validating the payment under the rules chosen by the
payee.

## Iterative Forks

In this schema, any hard fork is given an incremented id, `nForkId`.
`nForkId` starts at `1`, with `0` being reserved as a wildcard. When
project X decides to make an incompatible change to the protocol, it will
get assigned a new unique `nForkId` for this fork. A similar approach like
for BIP43 can be taken here. Potentially `nForkId` can be reused if a
project has not gained any amount of traction.

When preparing the transaction for signing or validation, `nForkId` is
appended to the final template as a 4B integer (similar to [1]). Amending
BIP143, this would result in

```
Double SHA256 of the serialization of:
    1. nVersion of the transaction (4-byte little endian)
    2. hashPrevouts (32-byte hash)
    3. hashSequence (32-byte hash)
    4. outpoint (32-byte hash + 4-byte little endian)
    5. scriptCode of the input (serialized as scripts inside CTxOuts)
    6. value of the output spent by this input (8-byte little endian)
    7. nSequence of the input (4-byte little endian)
    8. hashOutputs (32-byte hash)
    9. nLocktime of the transaction (4-byte little endian)
   10. sighash type of the signature (4-byte little endian)
   11. nForkId (4-byte little endian)
```


For `nForkId=0` this step is ommitted. This will immediately invalidate
signatures for any other branch of the blockchain than this specific fork.
To distinguish between `nForkId=0` and `nForkId` hardcoded into the
software, another bit has to be set in the 1B SigHashId present at the end
of signatures.

To make this approach more generic, payment addresses will contain the fork
id, depending on which tokens a payee expects payments in. This would
require a change on bech32 addresses, maybe to use a similar format used in
lightning-rfc [2]. A wallet will parse the address, it will extract
`nForkId`, and it displays which token the user is about to spend. When
signing the transaction, it will use `nForkId`, such that the transaction
is only valid for this specific token. This can be generalised in software
to the point where replay protection *and* a new address space can be
introduced for forks without breaking existing clients.

For light clients, this can be extended by enforcing the coinbase/block
header to contain the `nForkId` of the block. Then the client can
distinguish between different chains and tokens it received on each.
Alternatively, a new P2P message type for sending transactions could be
introduced, where prevOut and `nForkId` is transmitted, such that the lite
client can check for himself, which token he received.

Allowing signatures with `nForkId=1` can be achieved with a soft fork by
incrementing the script version of SegWit, making this a fully backwards
compatible change.

[1]
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/
2017-February/013542.html

[2]
https://github.com/lightningnetwork/lightning-rfc/blob/master/11-payment-
encoding.md

_______________________________________________
bitcoin-dev mailing list
bitcoin-dev at lists.linuxfoundation.org
https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171106/91e3799f/attachment.html>

From roberttaylorgen at gmail.com  Tue Nov  7 03:55:59 2017
From: roberttaylorgen at gmail.com (Robert Taylor)
Date: Tue, 7 Nov 2017 10:55:59 +0700
Subject: [bitcoin-dev] Centralizing mining by force
Message-ID: <CAArA6tURLo0yiM+js=KJEo8i1FTwOKV7V+qjC8yGd8q2PgvewQ@mail.gmail.com>

Forgive me if this has been asked elsewhere before, but I am trying to
understand a potential failure mode of Bitcoin mining.

A majority of miners can decide which valid blocks extend the chain. But
what would happen if a majority of miners, in the form of a cartel decided
to validly orphan any blocks made by miners outside of their group? For
example, they could soft fork a new rule where the block number is signed
by set of keys known only to the cartel, and that signature placed in the
coinbase. Miners outside of the cartel would not be able to extend the
chain.

It would be immediately obvious but still valid under the consensus rules.
What are the disincentives for such behavior and what countermeasures could
be done to stop it and ensure mining remained permissionless? I think this
is a valid concern because while it may not be feasible for one actor to
gain a majority of hash alone, it is certainly possible with collusion.

Robert
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171107/aff7454b/attachment-0001.html>

From c1.bitcoin at niftybox.net  Tue Nov  7 04:38:51 2017
From: c1.bitcoin at niftybox.net (Devrandom)
Date: Tue, 07 Nov 2017 04:38:51 +0000
Subject: [bitcoin-dev] Introducing a POW through a soft-fork
In-Reply-To: <61253DDB-A045-4346-A39C-F5C4E07396C7@voskuil.org>
References: <CAB0O3SVjhG19R61B78hFCPwfwWemTXj=tOsvgAgoNbjFYXXAtg@mail.gmail.com>
	<20171106195000.GA7245@fedora-23-dvm>
	<CA+XQW1j2vNNswEQ-HVWF9MpyGBzmq3ij+v=2NGH2VicQ63=v6A@mail.gmail.com>
	<61253DDB-A045-4346-A39C-F5C4E07396C7@voskuil.org>
Message-ID: <CAB0O3SX-m1Uw8Ga-ddzyU6oYdM2QRXn2OetgPmPBT+-5wGmjKQ@mail.gmail.com>

A hard-fork is a situation where non-upgraded nodes reject a block mined
and relayed by upgraded nodes.  This creates a fork that cannot heal
regardless of what follows.

This proposal is not a hard-fork, because the non-upgraded node *will heal*
if the attack has less than 1/2 of the original-POW power in the long term.

The cost of such an attack is the cost of a normal "51%" attack, multiplied
by the fractional weight of the original POW (e.g. 0.75 or 0.5).

So rather than saying this is a hard-fork, I would say that this is a
soft-fork with reduced security for non-upgraded nodes. I would also say
that the reduction in security is proportional to the reduction in weight
of the original POW at the time of attack.

As mentioned before, the original-POW weight starts at 1.0 and is reduced
over a long period of time.  I would set up the transition curve so that
all nodes upgrade by the time the weight is, say, 0.75.  In reality, nodes
protecting high economic value would upgrade early.

On Mon, Nov 6, 2017 at 3:55 PM Eric Voskuil via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> If a block that would be discarded under previous rules becomes accepted
> after a rule addition, there is no reason to not simply call the new rule a
> hard fork. IOW it's perfectly rational to consider a weaker block as
> "invalid" relative to the strong chain. As such I don't see any reason to
> qualify the term, it's a hard fork. But Peter's observation (the specific
> behavior) is ultimately what matters.
>
> e
>
> On Nov 6, 2017, at 12:30, Paul Sztorc via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
> +1 to all of Peter Todd's comments
>
> On Nov 6, 2017 11:50 AM, "Peter Todd via bitcoin-dev" <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>> On Wed, Nov 01, 2017 at 05:48:27AM +0000, Devrandom via bitcoin-dev wrote:
>>
>> Some quick thoughts...
>>
>> > Hi all,
>> >
>> > Feedback is welcome on the draft below.  In particular, I want to see if
>> > there is interest in further development of the idea and also
>> interested in
>> > any attack vectors or undesirable dynamics.
>> >
>> > (Formatted version available here:
>> > https://github.com/devrandom/btc-papers/blob/master/aux-pow.md )
>> >
>> > # Soft-fork Introduction of a New POW
>>
>> First of all, I don't think you can really call this a soft-fork; I'd
>> call it a
>> "pseudo-soft-fork"
>>
>> My reasoning being that after implementation, a chain with less total
>> work than
>> the main chain - but more total SHA256^2 work than the main chain - might
>> be
>> followed by non-supporting clients. It's got some properties of a
>> soft-fork,
>> but it's security model is definitely different.
>>
>> > ### Aux POW intermediate block
>> >
>> > Auxiliary POW blocks are introduced between normal blocks - i.e. the
>> chain
>> > alternates between the two POWs.
>> > Each aux-POW block points to the previous normal block and contains
>> > transactions just like a normal block.
>> > Each normal block points to the previous aux-POW block and must contain
>> all
>> > transactions from the aux-POW block.
>>
>> Note how you're basically proposing for the block interval to be
>> decreased,
>> which has security implications due to increased orphan rates.
>>
>> > ### Heaviest chain rule change
>> >
>> > This is a semi-hard change, because non-upgraded nodes can get on the
>> wrong
>> > chain in case of attack.  However,
>>
>> Exactly! Not really a soft-fork.
>>
>> --
>> https://petertodd.org 'peter'[:-1]@petertodd.org
>>
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
>> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171107/81f53507/attachment.html>

From m.bevand at gmail.com  Wed Nov  8 05:04:07 2017
From: m.bevand at gmail.com (Marc Bevand)
Date: Wed, 08 Nov 2017 05:04:07 +0000
Subject: [bitcoin-dev] Centralizing mining by force
In-Reply-To: <CAArA6tURLo0yiM+js=KJEo8i1FTwOKV7V+qjC8yGd8q2PgvewQ@mail.gmail.com>
References: <CAArA6tURLo0yiM+js=KJEo8i1FTwOKV7V+qjC8yGd8q2PgvewQ@mail.gmail.com>
Message-ID: <CADH-5r3YqvO4rbS5PEc86LB-CGsrMnARUj7Vbfi0opBB_EuMQA@mail.gmail.com>

What you describe is an example of a majority attack ("51% attack"). No
technical mechanism in Bitcoin prevents this. However in practice, miners
are not incentivized to perform this attack as it would destroy confidence
in Bitcoin, and would ultimately impact their revenues.

-Marc

On Mon, Nov 6, 2017, 22:32 Robert Taylor via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Forgive me if this has been asked elsewhere before, but I am trying to
> understand a potential failure mode of Bitcoin mining.
>
> A majority of miners can decide which valid blocks extend the chain. But
> what would happen if a majority of miners, in the form of a cartel decided
> to validly orphan any blocks made by miners outside of their group? For
> example, they could soft fork a new rule where the block number is signed
> by set of keys known only to the cartel, and that signature placed in the
> coinbase. Miners outside of the cartel would not be able to extend the
> chain.
>
> It would be immediately obvious but still valid under the consensus rules.
> What are the disincentives for such behavior and what countermeasures could
> be done to stop it and ensure mining remained permissionless? I think this
> is a valid concern because while it may not be feasible for one actor to
> gain a majority of hash alone, it is certainly possible with collusion.
>
> Robert
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171108/46545fe7/attachment.html>

From ZmnSCPxj at protonmail.com  Wed Nov  8 05:37:39 2017
From: ZmnSCPxj at protonmail.com (ZmnSCPxj)
Date: Wed, 08 Nov 2017 00:37:39 -0500
Subject: [bitcoin-dev] Centralizing mining by force
In-Reply-To: <CAArA6tURLo0yiM+js=KJEo8i1FTwOKV7V+qjC8yGd8q2PgvewQ@mail.gmail.com>
References: <CAArA6tURLo0yiM+js=KJEo8i1FTwOKV7V+qjC8yGd8q2PgvewQ@mail.gmail.com>
Message-ID: <3lQrEWAXGaWFeAuMR_DCfyO6i_5p8pI3aLdW2BCFPSgxD1fqL-dVvkaJ1miUREAYqB7MEBerXRqsveFQICtSW1k1_UzZBMku0P5jB1an8W4=@protonmail.com>

Good morning Robert,

What you describe is precisely one possible result of a 51% attack.

At below the 50% threshold, miners outside the cartel will on average outrace miners inside the cartel, so fullnodes which do not follow cartel rules will reject them as per Nakamoto Consensus.  At some point, the chain split becomes permanent, with miners outside the cartel pulling above the cartel miners.

However, above the 50% threshold, miners outside the cartel will be unable to keep up with the cartel and be unable to build on top of the cartel chain (as presumably they are not valid signatories).  Outside-cartel miners, however, may institute an opposing cartel, or an anti-cartel (blocks must have a fixed, invalid with high probability, 00000 signature).

In the end, what matters is what fullnodes accept.  If fullnodes do not care, then the group of miners that is larger wins.  If fullnodes do check one or the other set of rules, then that set of rules will win.

Given current politics, it is likely that fullnodes will institute an anti-cartel rule in this case, and reject the cartel and suffer low hashrate.  Eventually, the cartel will be betrayed by one of its members mining the anti-cartel chain in return for fees and valuable block rewards.

Regards,
ZmnSCPxj

Sent with [ProtonMail](https://protonmail.com) Secure Email.

> -------- Original Message --------
> Subject: [bitcoin-dev] Centralizing mining by force
> Local Time: November 7, 2017 11:55 AM
> UTC Time: November 7, 2017 3:55 AM
> From: bitcoin-dev at lists.linuxfoundation.org
> To: bitcoin-dev at lists.linuxfoundation.org
>
> Forgive me if this has been asked elsewhere before, but I am trying to understand a potential failure mode of Bitcoin mining.
>
> A majority of miners can decide which valid blocks extend the chain. But what would happen if a majority of miners, in the form of a cartel decided to validly orphan any blocks made by miners outside of their group? For example, they could soft fork a new rule where the block number is signed by set of keys known only to the cartel, and that signature placed in the coinbase. Miners outside of the cartel would not be able to extend the chain.
>
> It would be immediately obvious but still valid under the consensus rules. What are the disincentives for such behavior and what countermeasures could be done to stop it and ensure mining remained permissionless? I think this is a valid concern because while it may not be feasible for one actor to gain a majority of hash alone, it is certainly possible with collusion.
>
> Robert
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171108/e5c30ecd/attachment.html>

From mats at blockchain.com  Wed Nov  8 16:45:01 2017
From: mats at blockchain.com (Mats Jerratsch)
Date: Wed, 8 Nov 2017 16:45:01 +0000
Subject: [bitcoin-dev] Generalised Replay Protection for Future Hard
	Forks
In-Reply-To: <CAAUaCyiZ0bmWZLZc-yDvVHupzbdRR=Kdq4P8VkWqpU1L3G-u3A@mail.gmail.com>
References: <7601C2CD-8544-4501-80CE-CAEB402A72D2@blockchain.com>
	<CAAUaCyii2U5VBLS+Va+F3h4Hka0OWDnFFmjtsvyaaD4TKVzV3Q@mail.gmail.com>
	<CAAUaCyiZ0bmWZLZc-yDvVHupzbdRR=Kdq4P8VkWqpU1L3G-u3A@mail.gmail.com>
Message-ID: <C9A47922-5777-44AC-871A-6C27A22054AC@blockchain.com>

Hey Jacob!

> Take the specific and common case of non-upgraded wallet software.  Suppose a HF happens, and becomes the network used by 90% of users.  Will old wallets still default to the old nForkId (10% legacy chain)?  If so, I'd expect a lot of accidental mis-sends on that chain.

With this proposal implemented, a 'mis-send' is fundamentally impossible. The address contains the identifier of the token that should be sent.

If anything, it's possible to 'mis-receive'.
That is, the receiving wallet was not aware of a newer chain, and the receiver actually wanted to receive the newer token, but instead his wallet created an address for the old token. It is the responsibility of the receiver to write a correct invoice. This is the case everywhere else in the world too, so this seems like a reasonable trade-off.

I would even argue that this should hold in a legal case, where the receiver cannot claim that he was expecting a payment in another token (contrary to how it is today, like when users send BTC to a BCH address, losing their funds with potentially no legal right for reimbursement). If I sent someone an invoice over 100?, I cannot later proclaim that I actually expected $100.

With this proposal, wallets are finally able to distinguish between different tokens. With this ability, I expect to see different implementations, some wallets which advertise staying conservative, following a strict ruleset, and other wallets being more experimental, following hashing rate or other metrics.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 842 bytes
Desc: Message signed with OpenPGP
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171108/eef251dc/attachment.sig>

From eric at voskuil.org  Thu Nov  9 18:18:17 2017
From: eric at voskuil.org (Eric Voskuil)
Date: Thu, 9 Nov 2017 10:18:17 -0800
Subject: [bitcoin-dev] Centralizing mining by force
In-Reply-To: <CADH-5r3YqvO4rbS5PEc86LB-CGsrMnARUj7Vbfi0opBB_EuMQA@mail.gmail.com>
References: <CAArA6tURLo0yiM+js=KJEo8i1FTwOKV7V+qjC8yGd8q2PgvewQ@mail.gmail.com>
	<CADH-5r3YqvO4rbS5PEc86LB-CGsrMnARUj7Vbfi0opBB_EuMQA@mail.gmail.com>
Message-ID: <2C582743-F143-4778-970F-ED934A0706A0@voskuil.org>

It is not the case in practice that there exists no incentive to disrupt the market for transaction confirmation. Statism is profitable, and a primary source of revenue is seigniorage. Given Bitcoin's threat to that privilege, its destruction presents a hefty incentive.

The security model of Bitcoin is not based on balancing power between miners (those who confirm) and merchants (those who validate). It is based on these parties defending their mutually-beneficial market from the state.

Neither technology nor incentives resolve this conflict. People must be willing to defend their mines and their economic nodes. This requires personal risk. The risk to each individual is mitigated by broad decentralization, but remains nonetheless.

Even in a highly-decentralized system, overpowering taxpayer-funded disruption of the confirmation market will require that merchants pay aggregate fees exceeding the mining subsidy expended by the taxpayer to disrupt it. Who prevails in that tug of war is unclear, but working on Bitcoin implies one believes it is possible for individuals to do so.

e

> On Nov 7, 2017, at 21:04, Marc Bevand via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
> 
> What you describe is an example of a majority attack ("51% attack"). No technical mechanism in Bitcoin prevents this. However in practice, miners are not incentivized to perform this attack as it would destroy confidence in Bitcoin, and would ultimately impact their revenues.
> 
> -Marc
> 
> 
>> On Mon, Nov 6, 2017, 22:32 Robert Taylor via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
>> Forgive me if this has been asked elsewhere before, but I am trying to understand a potential failure mode of Bitcoin mining.
>> 
>> A majority of miners can decide which valid blocks extend the chain. But what would happen if a majority of miners, in the form of a cartel decided to validly orphan any blocks made by miners outside of their group? For example, they could soft fork a new rule where the block number is signed by set of keys known only to the cartel, and that signature placed in the coinbase. Miners outside of the cartel would not be able to extend the chain.
>> 
>> It would be immediately obvious but still valid under the consensus rules. What are the disincentives for such behavior and what countermeasures could be done to stop it and ensure mining remained permissionless? I think this is a valid concern because while it may not be feasible for one actor to gain a majority of hash alone, it is certainly possible with collusion.
>> 
>> Robert
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171109/176bab43/attachment.html>

From jacob.eliosoff at gmail.com  Thu Nov  9 20:45:43 2017
From: jacob.eliosoff at gmail.com (Jacob Eliosoff)
Date: Thu, 9 Nov 2017 15:45:43 -0500
Subject: [bitcoin-dev] Generalised Replay Protection for Future Hard
	Forks
In-Reply-To: <C9A47922-5777-44AC-871A-6C27A22054AC@blockchain.com>
References: <7601C2CD-8544-4501-80CE-CAEB402A72D2@blockchain.com>
	<CAAUaCyii2U5VBLS+Va+F3h4Hka0OWDnFFmjtsvyaaD4TKVzV3Q@mail.gmail.com>
	<CAAUaCyiZ0bmWZLZc-yDvVHupzbdRR=Kdq4P8VkWqpU1L3G-u3A@mail.gmail.com>
	<C9A47922-5777-44AC-871A-6C27A22054AC@blockchain.com>
Message-ID: <CAAUaCyjVxJbPrbBUdb9irK5CNnuqUSnzSjywpozhLqONcb_m_w@mail.gmail.com>

OK, I see.  On the whole this is the best replay protection solution I've
seen.  In particular, I hope developers of Bech32 and other new address
formats will take a close look at incorporating a fork ID this way.

As I understand you, a private key in cold storage would (of course) remain
valid across HFs, but an *address* would be valid only for the nForkId it
was generated for.  There may be cold-storage-type cases where it's
important for an address to be valid across all chains, ie, to
intentionally allow replay?  But I guess this could just be a special
nForkId value, say -1?


On Nov 8, 2017 9:45 AM, "Mats Jerratsch" <mats at blockchain.com> wrote:

> Hey Jacob!
>
> > Take the specific and common case of non-upgraded wallet software.
> Suppose a HF happens, and becomes the network used by 90% of users.  Will
> old wallets still default to the old nForkId (10% legacy chain)?  If so,
> I'd expect a lot of accidental mis-sends on that chain.
>
> With this proposal implemented, a 'mis-send' is fundamentally impossible.
> The address contains the identifier of the token that should be sent.
>
> If anything, it's possible to 'mis-receive'.
> That is, the receiving wallet was not aware of a newer chain, and the
> receiver actually wanted to receive the newer token, but instead his wallet
> created an address for the old token. It is the responsibility of the
> receiver to write a correct invoice. This is the case everywhere else in
> the world too, so this seems like a reasonable trade-off.
>
> I would even argue that this should hold in a legal case, where the
> receiver cannot claim that he was expecting a payment in another token
> (contrary to how it is today, like when users send BTC to a BCH address,
> losing their funds with potentially no legal right for reimbursement). If I
> sent someone an invoice over 100?, I cannot later proclaim that I actually
> expected $100.
>
> With this proposal, wallets are finally able to distinguish between
> different tokens. With this ability, I expect to see different
> implementations, some wallets which advertise staying conservative,
> following a strict ruleset, and other wallets being more experimental,
> following hashing rate or other metrics.
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171109/b20d9108/attachment.html>

From sjors at sprovoost.nl  Thu Nov  9 21:01:10 2017
From: sjors at sprovoost.nl (Sjors Provoost)
Date: Thu, 9 Nov 2017 22:01:10 +0100
Subject: [bitcoin-dev] Generalised Replay Protection for Future Hard
	Forks
In-Reply-To: <CAAUaCyjVxJbPrbBUdb9irK5CNnuqUSnzSjywpozhLqONcb_m_w@mail.gmail.com>
References: <7601C2CD-8544-4501-80CE-CAEB402A72D2@blockchain.com>
	<CAAUaCyii2U5VBLS+Va+F3h4Hka0OWDnFFmjtsvyaaD4TKVzV3Q@mail.gmail.com>
	<CAAUaCyiZ0bmWZLZc-yDvVHupzbdRR=Kdq4P8VkWqpU1L3G-u3A@mail.gmail.com>
	<C9A47922-5777-44AC-871A-6C27A22054AC@blockchain.com>
	<CAAUaCyjVxJbPrbBUdb9irK5CNnuqUSnzSjywpozhLqONcb_m_w@mail.gmail.com>
Message-ID: <45C2D68B-BA8E-47DE-BFA5-643922395B2A@sprovoost.nl>


> Op 9 nov. 2017, om 21:45 heeft Jacob Eliosoff via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> het volgende geschreven:
> 
> As I understand you, a private key in cold storage would (of course) remain valid across HFs, but an address would be valid only for the nForkId it was generated for.  There may be cold-storage-type cases where it's important for an address to be valid across all chains, ie, to intentionally allow replay?  But I guess this could just be a special nForkId value, say -1?

If I understand the proposal correctly, you can always spend coins; it's the next transaction that is replay protected.

I like the idea of specifying the fork in bech32 [0]. On the other hand, the standard already has a human readable part. Perhaps the human readable part can be used as the fork id?

Note that in your currently proposal nForkId is only in the transaction signature pre-image. It's not in the serialized transaction, so a node would just have to try to see if the signature is valid. I don't know if that's a problem.

Can you clarify what you mean with:
> Allowing signatures with `nForkId=1` can be achieved with a soft fork by incrementing the script version of SegWit, making this a fully backwards compatible change.

What's the purpose of nForkId 1?

>  potentially a way to opt-out of replay protection of any fork, where deemed necessary (can be beneficial for some L2 applications).

Can you give an example of where this opt-out would be useful? Why wouldn't it be enough to just sign one transaction for each fork?

In Spoonnet, the version number is added to the SIGHASH_TYPE in the pre-image. Your solution of just adding another field seems easier, but maybe there's a downside?

Sjors

[0] https://github.com/bitcoin/bips/blob/master/bip-0173.mediawiki#Bech32
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: Message signed with OpenPGP
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171109/e5a52b05/attachment.sig>

From laolu32 at gmail.com  Thu Nov  9 23:44:07 2017
From: laolu32 at gmail.com (Olaoluwa Osuntokun)
Date: Thu, 09 Nov 2017 23:44:07 +0000
Subject: [bitcoin-dev] BIP Proposal: Compact Client Side Filtering for
	Light Clients
In-Reply-To: <CAO3Pvs8-GAwUNZ9Fc7DAb9ZCwP4p5Wh0sD1O0n5NSLVcY2nJtg@mail.gmail.com>
References: <CAO3Pvs8ccTkgrecJG6KFbBW+9moHF-FTU+4qNfayeE3hM9uRrg@mail.gmail.com>
	<CAO3Pvs-nNQR_53_wjS4rPU8W20kePnrSdBvCXMwpaOG7gpUNJQ@mail.gmail.com>
	<CAO3Pvs8-GAwUNZ9Fc7DAb9ZCwP4p5Wh0sD1O0n5NSLVcY2nJtg@mail.gmail.com>
Message-ID: <CAO3Pvs8r_Ftha7RKUDtrVqd6SzqODH0PC5o8tUH1EH2UqMMecw@mail.gmail.com>

Hi y'all,

Since my last email we've made a number of changes to the BIP. The changes
made
were driven by the feedback we've received so far in this thread, and also
as a
result of real-world testing using this new proposal as the basis for our
light
weight LN node which powers the demo Lightning desktop application we
recently
released.

A highlight of the changes made between this version and the last follows:

  * We've removed the modulus operation in the inner loop when constructing
    filters. This has been replaced with an alternative, more efficient
    mapping[1] as suggested by gmaxwell and sipa. In our implementation, we
    perform the operation in a piece-wise fashion by hand. Alternative
    implementations can take advantage of 128-bit arithmetic extensions on
    supporting CPU's.

  * The txid has been moved from the extended filter to the regular filter.
    During out testing of the new light client with our LN node
implementation,
    we found that we were able to reduce network traffic as we only need the
    extended filter for rare on-chain events.

  * We now use the 6th service bit. We realized that the bit we had chosen
    prior was already being used to signal support of x-thin block syncing.
To
    select this bit number, we ran a scanner on the addrman of our nodes and
    also the network to fin da bit that wasn't used widely.

  * An error in the BIP that didn't include the public key script of
coinbase
    transactions in the filter has been fixed.

  * An error in the BIP when constructing the initial "genesis" filter has
been
    fixed.

  * We no longer use the ProtocolVersion field in the getcfheaders message
or
    its response.

  * The specification of several newly defined messages were incorrect and
have
    been fixed.

  * A number of typos spotted by several reviewers have been fixed.

The full commit history of the BIP draft can be found here:
https://github.com/Roasbeef/bips/commits/gcs-bip-draft

At this point, we're ready to make a PR against the official BIP repo and to
request a number to be assigned to our proposal. Thanks to all those that
have
reviewed, and contributed to the proposal!

[1]:
https://lemire.me/blog/2016/06/27/a-fast-alternative-to-the-modulo-reduction/

-- Laolu


On Thu, Jun 8, 2017 at 8:59 PM Olaoluwa Osuntokun <laolu32 at gmail.com> wrote:

> Hi y'all,
>
> Thanks for all the comments so far!
>
> I've pushed a series of updates to the text of the BIP repo linked in the
> OP.
> The fixes include: typos, components of the specification which were
> incorrect
> (N is the total number of items, NOT the number of txns in the block), and
> a
> few sections have been clarified.
>
> The latest version also includes a set of test vectors (as CSV files),
> which
> for a series of fp rates (1/2 to 1/2^32) includes (for 6 testnet blocks,
> one of
> which generates a "null" filter):
>
>    * The block height
>    * The block hash
>    * The raw block itself
>    * The previous basic+extended filter header
>    * The basic+extended filter header for the block
>    * The basic+extended filter for the block
>
> The size of the test vectors was too large to include in-line within the
> document, so we put them temporarily in a distinct folder [1]. The code
> used to
> generate the test vectors has also been included.
>
> -- Laolu
>
> [1]: https://github.com/Roasbeef/bips/tree/master/gcs_light_client
>
>
> On Thu, Jun 1, 2017 at 9:49 PM Olaoluwa Osuntokun <laolu32 at gmail.com>
> wrote:
>
>> > In order to consider the average+median filter sizes in a world worth
>> larger
>> > blocks, I also ran the index for testnet:
>> >
>> >     * total size:  2753238530
>> >     * total avg:  5918.95736054141
>> >     * total median:  60202
>> >     * total max:  74983
>> >     * regular size:  1165148878
>> >     * regular avg:  2504.856172982827
>> >     * regular median:  24812
>> >     * regular max:  64554
>> >     * extended size:  1588089652
>> >     * extended avg:  3414.1011875585823
>> >     * extended median:  35260
>> >     * extended max:  41731
>> >
>>
>> Oops, realized I made a mistake. These are the stats for Feb 2016 until
>> about a
>> month ago (since height 400k iirc).
>>
>> -- Laolu
>>
>>
>> On Thu, Jun 1, 2017 at 12:01 PM Olaoluwa Osuntokun <laolu32 at gmail.com>
>> wrote:
>>
>>> Hi y'all,
>>>
>>> Alex Akselrod and I would like to propose a new light client BIP for
>>> consideration:
>>>    *
>>> https://github.com/Roasbeef/bips/blob/master/gcs_light_client.mediawiki
>>>
>>> This BIP proposal describes a concrete specification (along with a
>>> reference implementations[1][2][3]) for the much discussed client-side
>>> filtering reversal of BIP-37. The precise details are described in the
>>> BIP, but as a summary: we've implemented a new light-client mode that
>>> uses
>>> client-side filtering based off of Golomb-Rice coded sets. Full-nodes
>>> maintain an additional index of the chain, and serve this compact filter
>>> (the index) to light clients which request them. Light clients then fetch
>>> these filters, query the locally and _maybe_ fetch the block if a
>>> relevant
>>> item matches. The cool part is that blocks can be fetched from _any_
>>> source, once the light client deems it necessary. Our primary motivation
>>> for this work was enabling a light client mode for lnd[4] in order to
>>> support a more light-weight back end paving the way for the usage of
>>> Lightning on mobile phones and other devices. We've integrated neutrino
>>> as a back end for lnd, and will be making the updated code public very
>>> soon.
>>>
>>> One specific area we'd like feedback on is the parameter selection.
>>> Unlike
>>> BIP-37 which allows clients to dynamically tune their false positive
>>> rate,
>>> our proposal uses a _fixed_ false-positive. Within the document, it's
>>> currently specified as P = 1/2^20. We've done a bit of analysis and
>>> optimization attempting to optimize the following sum:
>>> filter_download_bandwidth + expected_block_false_positive_bandwidth. Alex
>>> has made a JS calculator that allows y'all to explore the affect of
>>> tweaking the false positive rate in addition to the following variables:
>>> the number of items the wallet is scanning for, the size of the blocks,
>>> number of blocks fetched, and the size of the filters themselves. The
>>> calculator calculates the expected bandwidth utilization using the CDF of
>>> the Geometric Distribution. The calculator can be found here:
>>> https://aakselrod.github.io/gcs_calc.html. Alex also has an empirical
>>> script he's been running on actual data, and the results seem to match up
>>> rather nicely.
>>>
>>> We we're excited to see that Karl Johan Alm (kallewoof) has done some
>>> (rather extensive!) analysis of his own, focusing on a distinct encoding
>>> type [5]. I haven't had the time yet to dig into his report yet, but I
>>> think I've read enough to extract the key difference in our encodings:
>>> his
>>> filters use a binomial encoding _directly_ on the filter contents, will
>>> we
>>> instead create a Golomb-Coded set with the contents being _hashes_ (we
>>> use
>>> siphash) of the filter items.
>>>
>>> Using a fixed fp=20, I have some stats detailing the total index size, as
>>> well as averages for both mainnet and testnet. For mainnet, using the
>>> filter contents as currently described in the BIP (basic + extended), the
>>> total size of the index comes out to 6.9GB. The break down is as follows:
>>>
>>>     * total size:  6976047156
>>>     * total avg:  14997.220622758816
>>>     * total median:  3801
>>>     * total max:  79155
>>>     * regular size:  3117183743
>>>     * regular avg:  6701.372750217131
>>>     * regular median:  1734
>>>     * regular max:  67533
>>>     * extended size:  3858863413 <(385)%20886-3413>
>>>     * extended avg:  8295.847872541684
>>>     * extended median:  2041
>>>     * extended max:  52508
>>>
>>> In order to consider the average+median filter sizes in a world worth
>>> larger blocks, I also ran the index for testnet:
>>>
>>>     * total size:  2753238530
>>>     * total avg:  5918.95736054141
>>>     * total median:  60202
>>>     * total max:  74983
>>>     * regular size:  1165148878
>>>     * regular avg:  2504.856172982827
>>>     * regular median:  24812
>>>     * regular max:  64554
>>>     * extended size:  1588089652
>>>     * extended avg:  3414.1011875585823
>>>     * extended median:  35260
>>>     * extended max:  41731
>>>
>>> Finally, here are the testnet stats which take into account the increase
>>> in the maximum filter size due to segwit's block-size increase. The max
>>> filter sizes are a bit larger due to some of the habitual blocks I
>>> created last year when testing segwit (transactions with 30k inputs, 30k
>>> outputs, etc).
>>>
>>>      * total size:  585087597
>>>      * total avg:  520.8839608674402
>>>      * total median:  20
>>>      * total max:  164598
>>>      * regular size:  299325029
>>>      * regular avg:  266.4790836307566
>>>      * regular median:  13
>>>      * regular max:  164583
>>>      * extended size:  285762568
>>>      * extended avg:  254.4048772366836
>>>      * extended median:  7
>>>      * extended max:  127631
>>>
>>> For those that are interested in the raw data, I've uploaded a CSV file
>>> of raw data for each block (mainnet + testnet), which can be found here:
>>>      * mainnet: (14MB):
>>> https://www.dropbox.com/s/4yk2u8dj06njbuv/mainnet-gcs-stats.csv?dl=0
>>>      * testnet: (25MB):
>>> https://www.dropbox.com/s/w7dmmcbocnmjfbo/gcs-stats-testnet.csv?dl=0
>>>
>>>
>>> We look forward to getting feedback from all of y'all!
>>>
>>> -- Laolu
>>>
>>>
>>> [1]: https://github.com/lightninglabs/neutrino
>>> [2]: https://github.com/Roasbeef/btcd/tree/segwit-cbf
>>> [3]: https://github.com/Roasbeef/btcutil/tree/gcs/gcs
>>> [4]: https://github.com/lightningnetwork/lnd/
>>>
>>> -- Laolu
>>>
>>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171109/9c95b929/attachment-0001.html>

From rusty at rustcorp.com.au  Fri Nov 10 01:31:14 2017
From: rusty at rustcorp.com.au (Rusty Russell)
Date: Fri, 10 Nov 2017 12:01:14 +1030
Subject: [bitcoin-dev] Covenants through merkelized txids.
Message-ID: <87lgjex6l9.fsf@rustcorp.com.au>

Hi all,

        This is an alternative to jl2012's BIPZZZ (OP_PUSHTXDATA[1]).
It riffs on the (ab)use of OP_CHECKSIGFROMSTACK that Russell[2]
used to implement covenants[3].  I've been talking about it to random
people for a while, but haven't taken time to write it up.

The idea is to provide a OP_TXMERKLEVERIFY that compares the top stack
element against a merkle tree of the current tx constructed like so[4]:

        TXMERKLE = merkle(nVersion | nLockTime | fee, inputs & outputs)
        inputs & outputs = merkle(inputmerkle, outputmerkle)
        input = merkle(prevoutpoint, nSequence | inputAmount)
        output = merkle(nValue, scriptPubkey)

Many variants are possible, but if we have OP_CAT, this makes it fairly
easy to test a particular tx property.  A dedicated OP_MERKLE would make
it even easier, of course.

If we one day HF and add merklized TXIDs[5], we could also use this method
to inspect the tx *being spent* (which was what I was originally trying to
do).

Thanks for reading!
Rusty.

[1] https://github.com/jl2012/bips/blob/vault/bip-0ZZZ.mediawiki
[2] Aka Dr. "Not Rusty" O'Connor.  Of course both of us in the same thread will
    probably break the internet.
[3] https://blockstream.com/2016/11/02/covenants-in-elements-alpha.html
[4] You could put every element in a leaf, but that's less compact to
    use: cheaper to supply the missing parts with OP_CAT than add another level.
[5] Eg. use the high nVersion bit to say "make my txid a merkle".

From mats at blockchain.com  Fri Nov 10 11:28:06 2017
From: mats at blockchain.com (Mats Jerratsch)
Date: Fri, 10 Nov 2017 11:28:06 +0000
Subject: [bitcoin-dev] Generalised Replay Protection for Future Hard
	Forks
In-Reply-To: <CAAUaCyibOEHqw1J5O8yEp8v=j8t9sovn2vn=S8bZPZCzCY-gRw@mail.gmail.com>
References: <7601C2CD-8544-4501-80CE-CAEB402A72D2@blockchain.com>
	<CAAUaCyii2U5VBLS+Va+F3h4Hka0OWDnFFmjtsvyaaD4TKVzV3Q@mail.gmail.com>
	<CAAUaCyiZ0bmWZLZc-yDvVHupzbdRR=Kdq4P8VkWqpU1L3G-u3A@mail.gmail.com>
	<C9A47922-5777-44AC-871A-6C27A22054AC@blockchain.com>
	<CAAUaCyjVxJbPrbBUdb9irK5CNnuqUSnzSjywpozhLqONcb_m_w@mail.gmail.com>
	<45C2D68B-BA8E-47DE-BFA5-643922395B2A@sprovoost.nl>
	<CAAUaCygeOxAK=EpzfWndx6uVvVO9B+=YTs1m-jHa3BFp82jA4w@mail.gmail.com>
	<95ECB451-56AE-45E5-AAE6-10058C4B7FD7@sprovoost.nl>
	<CAAUaCyg_PGT0F=RHfX89T54j-vuyz5wcbXaYoikJv95WKgsNPg@mail.gmail.com>
	<55467A01-A8B2-4E73-8331-38C0A7CD90EF@sprovoost.nl>
	<CAAUaCyhncyCt_ao9i0=33LswDOkCf6o-+36zrGxKWD+WranmZw@mail.gmail.com>
	<46E317DF-C97C-4797-B989-594298BC6030@sprovoost.nl>
	<CAAUaCyibOEHqw1J5O8yEp8v=j8t9sovn2vn=S8bZPZCzCY-gRw@mail.gmail.com>
Message-ID: <3FBEE883-A15E-425C-8BF1-F7792FA63961@blockchain.com>

I guess I wasn't clear on the wildcard, `nForkId=0`

This proposal puts Bitcoin at `nForkId=1`, with the purpose of having `nForkId=0` valid on *all* future forks. This means you can create a `nLockTime` transaction, delete the private key and still be assured to not lose potential future tokens.

In theory `nForkId=0` could be used for an address too, the sending wallet should display a warning message about unknown side effects though. This address would be future-safe, and you can put it into a safe-deposit box (even though I see little reason to back up an _address_. You would always back up a _private key_, which translates into funds on any fork.)

Furthermore, `nForkId=0` can be used for L2 applications. Let's say Alice and Bob open a payment channel. One week later, project X decides to fork the network into a new token, implementing a custom way of providing strong two-way replay protection. The protocol Alice and Bob use for the payment channel has not implemented this new form of replay protection. Alice and Bob now have to make a choice:

(1) Ignore this new token. This comes with an evaluation of how much this new token could be worth in the future. They will continue normal channel operation, knowing that their funds on the other branch will be locked up until eternity. When they close their payment channel, the closing transaction will get rejected from the other network, because it's not following the format for replay protected transactions.

(2) Close the payment channel before the fork. The transaction, which closes the payment channel has to be mined before the fork, potentially paying a higher-than-normal fee.

With this proposal implemented, there are two additional choices

(3) Create the commitment transactions with `nForkId=0`. This ensures that when the channel gets closed, funds on other chains are released accordingly. This also means that after the fork, payments on the channel move both, the original token and the new token. Potentially, Alice and Bob want to wait before further transacting on the channel, to see if the token has substantial value. If it has, they can *then* close the channel and open a new channel again. (Note: The funding transaction can use a specific `nForkId`, preventing you from locking up multiple coins when funding the channel, but you can choose to settle with `nForkId=0` to not lock up future coins)

(4) Make the protocol aware of different `nForkId`. After the fork, the participants can chose to *only* close the payment channel on the new token, making the payment channel Bitcoin-only again. This is the preferred option, as it means no disruption to the original network.

> I like the idea of specifying the fork in bech32 [0]. On the other hand, the standard already has a human readable part. Perhaps the human readable part can be used as the fork id?

I was considering this too. On the other hand, it's only _human readable_ because thy bytes used currently encode 'bc'. For future forks, this would just be two random letters than, but potentially acceptable.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171110/ada18c4a/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 842 bytes
Desc: Message signed with OpenPGP
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171110/ada18c4a/attachment-0001.sig>

From ZmnSCPxj at protonmail.com  Fri Nov 10 23:33:31 2017
From: ZmnSCPxj at protonmail.com (ZmnSCPxj)
Date: Fri, 10 Nov 2017 18:33:31 -0500
Subject: [bitcoin-dev] OP_CHECKHARDFORKVERIFY - replay protection and fork
	futures on off-chain payment channels
Message-ID: <Nkh-LxiWyBgU4UwQlAnbIWB4PkI60pRPRMF7LAx_btNVbrq1lvSRbZ6HPPRVCRVI_MPIVvoFldGaUJAwwQfcQ5guHG8h_anIZ1FxiX4DDV4=@protonmail.com>

Good morning list,

I would like to speculate on the addition of an opcode which would provide replay protection and allow chain-backed trustless creation of hardfork futures payment channels.

Note however that in order to work, the hardfork must "cooperate" by changing the operation of OP_CHECKHARDFORKVERIFY in the hardfork.

The opcode is simple.  If the top stack is not the exact value 1, it fails.

The intent is that a hardfork must "cooperate" by also changing OP_CHECKHARDFORKVERIFY so that the top stack must be some other, non-1 value after the hardfork date.  This is a consensus break, but as a hardfork is defined by the fact that it is a consensus break, this is deliberate.

--

In the below, I assume the creation of a future hardfork with a new "consensus version" value (<hardforkVersion>, the value required by OP_CHECKHARDFORKVERIFY) and a fork height (<hardforkHeight>, the block height at which the hardfork will diverge from legacy).

It should be noted, that an "uncooperative" hardfork would not change its consensus version, and in that regard, OP_CHECKBLOCKATHEIGHTVERIFY is superior.

--

In order to prepare my funds for splitting.  I pay to the below P2SH/P2WSH script:

OP_IF
  1 OP_CHECKHARDFORKVERIFY OP_DROP <myPubKey1> OP_CHECKSIG
OP_ELSE
  <hardforkVersion> OP_CHECKHARDFORKVERIFY OP_DROP <myPubKey2> OP_CHECKSIG
OP_END

In the above, I can then create transactions that spend the first branch on legacy chain post fork, and create transactions that spend the second branch on the hardfork chain post fork.  In addition, if I suddenly need to access the fund before the fork date, I can use the first branch to recover my funds before the fork date.

--

Suppose I wish to make a bet with another randomly generated Internet person, MX06fRH.  I am of the opinion, that the hardfork will not have economic consensus, whereas MX06fRH is of the opinion that it will.  We resolve to each bet 1 BTC.

We create a transaction spending our funds and paying a single combined output to the below P2SH/P2WSH:

OP_DUP
OP_IF
  1 OP_EQUAL
  OP_IF
    <hardforkHeight> OP_CHECKLOCKTIMEVERIFY OP_DROP
    1 OP_CHECKHARDFORKVERIFY OP_DROP
    <ZmnSCPxjWinPubKey> OP_CHECKSIG
  OP_ELSE
    <hardforkVersion> OP_CHECKHARDFORKVERIFY OP_DROP
    <MRX06fRHWinPubKey> OP_CHECKSIG
  OP_ENDIF
OP_ELSE
  OP_DROP
  2 <ZmnSCPxjExitPubKey> <MX06fRHExitPubKey> 2 OP_CHECKMULTISIG
OP_ENDIF

In the above, I can use <ZmnSCPxjWinPubKey> and an nLockTime transaction after the fork date to claim my legacy coin, if the legacy coin has value, wheres MRX06fRH can use <MRX06fRHWinPubKey> on the hardfork chain if it has value.  Alternatively, we can both agree to cancel the bet.

--

While the above is workable, it does not form a market where price discovery of legacy and hardfork future coins can be performed to determine consensus.  For that, we will need to use payment channel techniques.

I and MRX06fRH can form a payment channel that can trade fork futures by creating an anchor transaction paying to:

OP_DUP
OP_IF
  1 OP_EQUAL
  OP_IF
    <hardforkHeight> OP_CHECKLOCKTIMEVERIFY OP_DROP
    1 OP_CHECKHARDFORKVERIFY OP_DROP
    2 <ZmnSCPxjLegacyPubKey> <MX06fRHLegacyPubKey> 2 OP_CHECKMULTISIG
  OP_ELSE
    <hardforkVersion> OP_CHECKHARDFORKVERIFY OP_DROP
    2 <ZmnSCPxjHardforkPubKey> <MX06fRHHardforkPubKey> 2 OP_CHECKMULTISIG
  OP_ENDIF
OP_ELSE
  OP_DROP
  2 <ZmnSCPxjExitPubKey> <MX06fRHExitPubKey> 2 OP_CHECKMULTISIG
OP_ENDIF

Of course, before the anchor transaction is signed, we should create commitment transactions first.  For a Poon-Drjya channel, we should create two commitment transactions, one for me and one for MX06fRH, but in fact we should create two versions of both, one for the legacy token and one for the hardfork token (four commitment transactions).  The contracts are differentiated by which branch of the above we activate.  Commitment transactions can only be claimed after the fork, but we can update them continuously using normal Poon-Dryja channel operations.

If I have the same amount of legacy and hardfork tokens, then MX06fRH also has equal legacy and hardfork tokens, so we can agree to exit.

--

Unfortunately this can only reach up to payment channels.  To create a futures market we should have a payment channel network.  For Lightning we use HTLCs to create atomic swaps of coins in different payment channels.  However, the difference here is that commitment transactions can only be claimed after the fork, so any HTLCs on top of that will have expired before the commitment transactions can be claimed and the HTLCs enforced.  Unfortunately, I know of no other construction that would allow creation of a payment channel network on top of a payment channel primitive.  So much for OP_CHECKHARDFORKVERIFY.

Regards,
ZmnSCPxj
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171110/58bf0a84/attachment-0001.html>

From laanwj at gmail.com  Sat Nov 11 14:35:19 2017
From: laanwj at gmail.com (Wladimir J. van der Laan)
Date: Sat, 11 Nov 2017 15:35:19 +0100
Subject: [bitcoin-dev] Bitcoin Core 0.15.1 released
Message-ID: <20171111143519.GA21428@amethyst.visucore.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

Bitcoin Core version *0.15.1* is now available from:

  <https://bitcoincore.org/bin/bitcoin-core-0.15.1/>

or

  <https://bitcoin.org/bin/bitcoin-core-0.15.1/>

Or through bittorrent:

  magnet:?xt=urn:btih:e83dfdfca54def4e29f5355e8c3f9a7aa45ecbaf&dn=bitcoin-core-0.15.1&tr=udp%3A%2F%2Ftracker.openbittorrent.com%3A80&tr=udp%3A%2F%2Ftracker.opentrackr.org%3A1337&tr=udp%3A%2F%2Ftracker.coppersurfer.tk%3A6969&tr=udp%3A%2F%2Ftracker.leechers-paradise.org%3A6969&tr=udp%3A%2F%2Fzer0day.ch%3A1337&tr=udp%3A%2F%2Fexplodie.org%3A6969

This is a new minor version release, including various bugfixes and
performance improvements, as well as updated translations.

Please report bugs using the issue tracker at GitHub:

  <https://github.com/bitcoin/bitcoin/issues>

To receive security and update notifications, please subscribe to:

  <https://bitcoincore.org/en/list/announcements/join/>

How to Upgrade
==============

If you are running an older version, shut it down. Wait until it has completely
shut down (which might take a few minutes for older versions), then run the 
installer (on Windows) or just copy over `/Applications/Bitcoin-Qt` (on Mac)
or `bitcoind`/`bitcoin-qt` (on Linux).

The first time you run version 0.15.0 or higher, your chainstate database will
be converted to a new format, which will take anywhere from a few minutes to
half an hour, depending on the speed of your machine.

The file format of `fee_estimates.dat` changed in version 0.15.0. Hence, a
downgrade from version 0.15 or upgrade to version 0.15 will cause all fee
estimates to be discarded.

Note that the block database format also changed in version 0.8.0 and there is no
automatic upgrade code from before version 0.8 to version 0.15.0. Upgrading
directly from 0.7.x and earlier without redownloading the blockchain is not supported.
However, as usual, old wallet versions are still supported.

Downgrading warning
- -------------------

The chainstate database for this release is not compatible with previous
releases, so if you run 0.15 and then decide to switch back to any
older version, you will need to run the old release with the `-reindex-chainstate`
option to rebuild the chainstate data structures in the old format.

If your node has pruning enabled, this will entail re-downloading and
processing the entire blockchain.

Compatibility
==============

Bitcoin Core is extensively tested on multiple operating systems using
the Linux kernel, macOS 10.8+, and Windows Vista and later. Windows XP is not supported.

Bitcoin Core should also work on most other Unix-like systems but is not
frequently tested on them.


Notable changes
===============

Network fork safety enhancements
- --------------------------------

A number of changes to the way Bitcoin Core deals with peer connections and invalid blocks
have been made, as a safety precaution against blockchain forks and misbehaving peers.

- - Unrequested blocks with less work than the minimum-chain-work are now no longer processed even
if they have more work than the tip (a potential issue during IBD where the tip may have low-work).
This prevents peers wasting the resources of a node. 

- - Peers which provide a chain with less work than the minimum-chain-work during IBD will now be disconnected.

- - For a given outbound peer, we now check whether their best known block has at least as much work as our tip. If it
doesn't, and if we still haven't heard about a block with sufficient work after a 20 minute timeout, then we send
a single getheaders message, and wait 2 more minutes. If after two minutes their best known block has insufficient
work, we disconnect that peer. We protect 4 of our outbound peers from being disconnected by this logic to prevent
excessive network topology changes as a result of this algorithm, while still ensuring that we have a reasonable
number of nodes not known to be on bogus chains.

- - Outbound (non-manual) peers that serve us block headers that are already known to be invalid (other than compact
block announcements, because BIP 152 explicitly permits nodes to relay compact blocks before fully validating them)
will now be disconnected.

- - If the chain tip has not been advanced for over 30 minutes, we now assume the tip may be stale and will try to connect
to an additional outbound peer. A periodic check ensures that if this extra peer connection is in use, we will disconnect
the peer that least recently announced a new block.

- - The set of all known invalid-themselves blocks (i.e. blocks which we attempted to connect but which were found to be
invalid) are now tracked and used to check if new headers build on an invalid chain. This ensures that everything that
descends from an invalid block is marked as such.


Miner block size limiting deprecated
- ------------------------------------

Though blockmaxweight has been preferred for limiting the size of blocks returned by
getblocktemplate since 0.13.0, blockmaxsize remained as an option for those who wished
to limit their block size directly. Using this option resulted in a few UI issues as
well as non-optimal fee selection and ever-so-slightly worse performance, and has thus
now been deprecated. Further, the blockmaxsize option is now used only to calculate an
implied blockmaxweight, instead of limiting block size directly. Any miners who wish
to limit their blocks by size, instead of by weight, will have to do so manually by
removing transactions from their block template directly.


GUI settings backed up on reset
- -------------------------------

The GUI settings will now be written to `guisettings.ini.bak` in the data directory before wiping them when
the `-resetguisettings` argument is used. This can be used to retroactively troubleshoot issues due to the
GUI settings.


Duplicate wallets disallowed
- ----------------------------

Previously, it was possible to open the same wallet twice by manually copying the wallet file, causing
issues when both were opened simultaneously. It is no longer possible to open copies of the same wallet.


Debug `-minimumchainwork` argument added
- ----------------------------------------

A hidden debug argument `-minimumchainwork` has been added to allow a custom minimum work value to be used
when validating a chain.


Low-level RPC changes
- ----------------------

- - The "currentblocksize" value in getmininginfo has been removed.

- - `dumpwallet` no longer allows overwriting files. This is a security measure
  as well as prevents dangerous user mistakes.

- - `backupwallet` will now fail when attempting to backup to source file, rather than
  destroying the wallet.

- - `listsinceblock` will now throw an error if an unknown `blockhash` argument
  value is passed, instead of returning a list of all wallet transactions since
  the genesis block. The behaviour is unchanged when an empty string is provided.

0.15.1 Change log
=================

### Mining
- - #11100 `7871a7d` Fix confusing blockmax{size,weight} options, dont default to throwing away money (TheBlueMatt)

### RPC and other APIs
- - #10859 `2a5d099` gettxout: Slightly improve doc and tests (jtimon)
- - #11267 `b1a6c94` update cli for estimate\*fee argument rename (laanwj)
- - #11483 `20cdc2b` Fix importmulti bug when importing an already imported key (pedrobranco)
- - #9937 `a43be5b` Prevent `dumpwallet` from overwriting files (laanwj)
- - #11465 `405e069` Update named args documentation for importprivkey (dusty-wil)
- - #11131 `b278a43` Write authcookie atomically (laanwj)
- - #11565 `7d4546f` Make listsinceblock refuse unknown block hash (ryanofsky)
- - #11593 `8195cb0` Work-around an upstream libevent bug (theuni)

### P2P protocol and network code
- - #11397 `27e861a` Improve and document SOCKS code (laanwj)
- - #11252 `0fe2a9a` When clearing addrman clear mapInfo and mapAddr (instagibbs)
- - #11527 `a2bd86a` Remove my testnet DNS seed (schildbach)
- - #10756 `0a5477c` net processing: swap out signals for an interface class (theuni)
- - #11531 `55b7abf` Check that new headers are not a descendant of an invalid block (more effeciently) (TheBlueMatt)
- - #11560 `49bf090` Connect to a new outbound peer if our tip is stale (sdaftuar)
- - #11568 `fc966bb` Disconnect outbound peers on invalid chains (sdaftuar)
- - #11578 `ec8dedf` Add missing lock in ProcessHeadersMessage(...) (practicalswift)
- - #11456 `6f27965` Replace relevant services logic with a function suite (TheBlueMatt)
- - #11490 `bf191a7` Disconnect from outbound peers with bad headers chains (sdaftuar)

### Validation
- - #10357 `da4908c` Allow setting nMinimumChainWork on command line (sdaftuar)
- - #11458 `2df65ee` Don't process unrequested, low-work blocks (sdaftuar)

### Build system
- - #11440 `b6c0209` Fix validationinterface build on super old boost/clang (TheBlueMatt)
- - #11530 `265bb21` Add share/rpcuser to dist. source code archive (MarcoFalke)

### GUI
- - #11334 `19d63e8` Remove custom fee radio group and remove nCustomFeeRadio setting (achow101)
- - #11198 `7310f1f` Fix display of package name on 'open config file' tooltip (esotericnonsense)
- - #11015 `6642558` Add delay before filtering transactions (lclc)
- - #11338 `6a62c74` Backup former GUI settings on `-resetguisettings` (laanwj)
- - #11335 `8d13b42` Replace save|restoreWindowGeometry with Qt functions (MeshCollider)
- - #11237 `2e31b1d` Fixing division by zero in time remaining (MeshCollider)
- - #11247 `47c02a8` Use IsMine to validate custom change address (MarcoFalke)

### Wallet
- - #11017 `9e8aae3` Close DB on error (kallewoof)
- - #11225 `6b4d9f2` Update stored witness in AddToWallet (sdaftuar)
- - #11126 `2cb720a` Acquire cs_main lock before cs_wallet during wallet initialization (ryanofsky)
- - #11476 `9c8006d` Avoid opening copied wallet databases simultaneously (ryanofsky)
- - #11492 `de7053f` Fix leak in CDB constructor (promag)
- - #11376 `fd79ed6` Ensure backupwallet fails when attempting to backup to source file (tomasvdw)
- - #11326 `d570aa4` Fix crash on shutdown with invalid wallet (MeshCollider)

### Tests and QA
- - #11399 `a825d4a` Fix bip68-sequence rpc test (jl2012)
- - #11150 `847c75e` Add getmininginfo test (mess110)
- - #11407 `806c78f` add functional test for mempoolreplacement command line arg (instagibbs)
- - #11433 `e169349` Restore bitcoin-util-test py2 compatibility (MarcoFalke)
- - #11308 `2e1ac70` zapwallettxes: Wait up to 3s for mempool reload (MarcoFalke)
- - #10798 `716066d` test bitcoin-cli (jnewbery)
- - #11443 `019c492` Allow "make cov" out-of-tree; Fix rpc mapping check (MarcoFalke)
- - #11445 `51bad91` 0.15.1 Backports (MarcoFalke)
- - #11319 `2f0b30a` Fix error introduced into p2p-segwit.py, and prevent future similar errors (sdaftuar)
- - #10552 `e4605d9` Tests for zmqpubrawtx and zmqpubrawblock (achow101)
- - #11067 `eeb24a3` TestNode: Add wait_until_stopped helper method (MarcoFalke)
- - #11068 `5398f20` Move wait_until to util (MarcoFalke)
- - #11125 `812c870` Add bitcoin-cli -stdin and -stdinrpcpass functional tests (promag)
- - #11077 `1d80d1e` fix timeout issues from TestNode (jnewbery)
- - #11078 `f1ced0d` Make p2p-leaktests.py more robust (jnewbery)
- - #11210 `f3f7891` Stop test_bitcoin-qt touching ~/.bitcoin (MeshCollider)
- - #11234 `f0b6795` Remove redundant testutil.cpp|h files (MeshCollider)
- - #11215 `cef0319` fixups from set_test_params() (jnewbery)
- - #11345 `f9cf7b5` Check connectivity before sending in assumevalid.py (jnewbery)
- - #11091 `c276c1e` Increase initial RPC timeout to 60 seconds (laanwj)
- - #10711 `fc2aa09` Introduce TestNode (jnewbery)
- - #11230 `d8dd8e7` Fixup dbcrash interaction with add_nodes() (jnewbery)
- - #11241 `4424176` Improve signmessages functional test (mess110)
- - #11116 `2c4ff35` Unit tests for script/standard and IsMine functions (jimpo)
- - #11422 `a36f332` Verify DBWrapper iterators are taking snapshots (TheBlueMatt)
- - #11121 `bb5e7cb` TestNode tidyups (jnewbery)
- - #11521 `ca0f3f7` travis: move back to the minimal image (theuni)
- - #11538 `adbc9d1` Fix race condition failures in replace-by-fee.py, sendheaders.py (sdaftuar)
- - #11472 `4108879` Make tmpdir option an absolute path, misc cleanup (MarcoFalke)
- - #10853 `5b728c8` Fix RPC failure testing (again) (jnewbery)
- - #11310 `b6468d3` Test listwallets RPC (mess110)

### Miscellaneous
- - #11377 `75997c3` Disallow uncompressed pubkeys in bitcoin-tx [multisig] output adds (TheBlueMatt)
- - #11437 `dea3b87` [Docs] Update Windows build instructions for using WSL and Ubuntu 17.04 (fanquake)
- - #11318 `8b61aee` Put back inadvertently removed copyright notices (gmaxwell)
- - #11442 `cf18f42` [Docs] Update OpenBSD Build Instructions for OpenBSD 6.2 (fanquake)
- - #10957 `50bd3f6` Avoid returning a BIP9Stats object with uninitialized values (practicalswift)
- - #11539 `01223a0` [verify-commits] Allow revoked keys to expire (TheBlueMatt)


Credits
=======

Thanks to everyone who directly contributed to this release:

- - Andreas Schildbach
- - Andrew Chow
- - Chris Moore
- - Cory Fields
- - Cristian Mircea Messel
- - Daniel Edgecumbe
- - Donal OConnor
- - Dusty Williams
- - fanquake
- - Gregory Sanders
- - Jim Posen
- - John Newbery
- - Johnson Lau
- - Jo?o Barbosa
- - Jorge Tim?n
- - Karl-Johan Alm
- - Lucas Betschart
- - MarcoFalke
- - Matt Corallo
- - Paul Berg
- - Pedro Branco
- - Pieter Wuille
- - practicalswift
- - Russell Yanofsky
- - Samuel Dobson
- - Suhas Daftuar
- - Tomas van der Wansem
- - Wladimir J. van der Laan

As well as everyone that helped translating on [Transifex](https://www.transifex.com/projects/p/bitcoin/).

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBCgAGBQJaBwnSAAoJEB5K7WKYbNJdAhIIAL6y/9IM1cdvt6Wob9yDMawv
it2iL5pS0HIWbcqXTfnf+52JMw9SNmTX356U8B9q9l6V8EiFKMN8y1wu/A921kKb
n1BREmVKD0JtawK368LiFt9x0eYV3q0MTww9dOCPp5HoIEt8TTLGFIOwzAvscxNi
IQMZRE5ejtm9Yjs0VHeKBrAXNA9zt8BKzmuwGi/JHoWda8nUnAhnaL/asAaYQ1zB
IpqZHJo4k7GxxXUFIm1hiQkqT7uDZ5iehT706Su3qY7ATtaByPq8aHsPDEZFfUJO
PoW7nqzCzkyTofIIE7+ejviBruL7EYFZiq+oUzOt4byGJvgaRyBXo8rn+druvEI=
=8PAn
-----END PGP SIGNATURE-----

From jacob.eliosoff at gmail.com  Sat Nov 11 05:18:11 2017
From: jacob.eliosoff at gmail.com (Jacob Eliosoff)
Date: Sat, 11 Nov 2017 00:18:11 -0500
Subject: [bitcoin-dev] Generalised Replay Protection for Future Hard
	Forks
In-Reply-To: <3FBEE883-A15E-425C-8BF1-F7792FA63961@blockchain.com>
References: <7601C2CD-8544-4501-80CE-CAEB402A72D2@blockchain.com>
	<CAAUaCyii2U5VBLS+Va+F3h4Hka0OWDnFFmjtsvyaaD4TKVzV3Q@mail.gmail.com>
	<CAAUaCyiZ0bmWZLZc-yDvVHupzbdRR=Kdq4P8VkWqpU1L3G-u3A@mail.gmail.com>
	<C9A47922-5777-44AC-871A-6C27A22054AC@blockchain.com>
	<CAAUaCyjVxJbPrbBUdb9irK5CNnuqUSnzSjywpozhLqONcb_m_w@mail.gmail.com>
	<45C2D68B-BA8E-47DE-BFA5-643922395B2A@sprovoost.nl>
	<CAAUaCygeOxAK=EpzfWndx6uVvVO9B+=YTs1m-jHa3BFp82jA4w@mail.gmail.com>
	<95ECB451-56AE-45E5-AAE6-10058C4B7FD7@sprovoost.nl>
	<CAAUaCyg_PGT0F=RHfX89T54j-vuyz5wcbXaYoikJv95WKgsNPg@mail.gmail.com>
	<55467A01-A8B2-4E73-8331-38C0A7CD90EF@sprovoost.nl>
	<CAAUaCyhncyCt_ao9i0=33LswDOkCf6o-+36zrGxKWD+WranmZw@mail.gmail.com>
	<46E317DF-C97C-4797-B989-594298BC6030@sprovoost.nl>
	<CAAUaCyibOEHqw1J5O8yEp8v=j8t9sovn2vn=S8bZPZCzCY-gRw@mail.gmail.com>
	<3FBEE883-A15E-425C-8BF1-F7792FA63961@blockchain.com>
Message-ID: <CAAUaCyg70uUnUp1Q0a6kEoQ1Js68VFLgthyfwyMQaaEqO8R-UQ@mail.gmail.com>

OK, so nForkId 0 is exactly the "valid on all chains" specifier I was
asking about, cool.  And your LN example (and nLockTime txs in general)
illustrate why it's preferable to implement a generic replay protection
scheme like yours *in advance*, rather than before each fork: all ad hoc RP
schemes I know of break old txs on one of the chains, even when that's not
desirable - ie, they offer no wildcard like nForkId 0.

One comment on your LN example: users would have to take note that nForkId
0 txs would be valid not only on future forks, but on *past* forks too.
Eg, if BCH had been deployed with nForkId 2, then a user setting up BTC LN
txs now with nForkId 0 would have to be aware that those txs would be valid
for BCH too.  Of course the user could avoid this by funding from a
BTC-only address, but it is a potential minor pitfall of nForkId 0.  (Which
I don't see any clean way around.)


On Fri, Nov 10, 2017 at 6:28 AM, Mats Jerratsch <mats at blockchain.com> wrote:

> I guess I wasn't clear on the wildcard, `nForkId=0`
>
> This proposal puts Bitcoin at `nForkId=1`, with the purpose of having
> `nForkId=0` valid on *all* future forks. This means you can create a
> `nLockTime` transaction, delete the private key and still be assured to not
> lose potential future tokens.
>
> In theory `nForkId=0` could be used for an address too, the sending wallet
> should display a warning message about unknown side effects though. This
> address would be future-safe, and you can put it into a safe-deposit box
> (even though I see little reason to back up an _address_. You would always
> back up a _private key_, which translates into funds on any fork.)
>
> Furthermore, `nForkId=0` can be used for L2 applications. Let's say Alice
> and Bob open a payment channel. One week later, project X decides to fork
> the network into a new token, implementing a custom way of providing strong
> two-way replay protection. The protocol Alice and Bob use for the payment
> channel has not implemented this new form of replay protection. Alice and
> Bob now have to make a choice:
>
> (1) Ignore this new token. This comes with an evaluation of how much this
> new token could be worth in the future. They will continue normal channel
> operation, knowing that their funds on the other branch will be locked up
> until eternity. When they close their payment channel, the closing
> transaction will get rejected from the other network, because it's not
> following the format for replay protected transactions.
>
> (2) Close the payment channel before the fork. The transaction, which
> closes the payment channel has to be mined before the fork, potentially
> paying a higher-than-normal fee.
>
> With this proposal implemented, there are two additional choices
>
> (3) Create the commitment transactions with `nForkId=0`. This ensures that
> when the channel gets closed, funds on other chains are released
> accordingly. This also means that after the fork, payments on the channel
> move both, the original token and the new token. Potentially, Alice and Bob
> want to wait before further transacting on the channel, to see if the token
> has substantial value. If it has, they can *then* close the channel and
> open a new channel again. (Note: The funding transaction can use a specific
> `nForkId`, preventing you from locking up multiple coins when funding the
> channel, but you can choose to settle with `nForkId=0` to not lock up
> future coins)
>
> (4) Make the protocol aware of different `nForkId`. After the fork, the
> participants can chose to *only* close the payment channel on the new
> token, making the payment channel Bitcoin-only again. This is the preferred
> option, as it means no disruption to the original network.
>
> > I like the idea of specifying the fork in bech32 [0]. On the other hand,
> the standard already has a human readable part. Perhaps the human readable
> part can be used as the fork id?
>
> I was considering this too. On the other hand, it's only _human readable_
> because thy bytes used currently encode 'bc'. For future forks, this would
> just be two random letters than, but potentially acceptable.
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171111/9fb7d5ba/attachment-0001.html>

From eric at voskuil.org  Sat Nov 11 19:51:04 2017
From: eric at voskuil.org (Eric Voskuil)
Date: Sat, 11 Nov 2017 11:51:04 -0800
Subject: [bitcoin-dev] Introducing a POW through a soft-fork
In-Reply-To: <CAB0O3SX-m1Uw8Ga-ddzyU6oYdM2QRXn2OetgPmPBT+-5wGmjKQ@mail.gmail.com>
References: <CAB0O3SVjhG19R61B78hFCPwfwWemTXj=tOsvgAgoNbjFYXXAtg@mail.gmail.com>
	<20171106195000.GA7245@fedora-23-dvm>
	<CA+XQW1j2vNNswEQ-HVWF9MpyGBzmq3ij+v=2NGH2VicQ63=v6A@mail.gmail.com>
	<61253DDB-A045-4346-A39C-F5C4E07396C7@voskuil.org>
	<CAB0O3SX-m1Uw8Ga-ddzyU6oYdM2QRXn2OetgPmPBT+-5wGmjKQ@mail.gmail.com>
Message-ID: <795D69CA-1591-4B69-96EE-BAF14CAAD71B@voskuil.org>


> On Nov 6, 2017, at 20:38, Devrandom <c1.bitcoin at niftybox.net> wrote:
> 
> A hard-fork is a situation where non-upgraded nodes reject a block mined and relayed by upgraded nodes.

As Peter pointed out, that is the case here.

> This creates a fork that cannot heal regardless of what follows.

That is not a condition of the hard fork concept.

https://github.com/bitcoin/bips/blob/master/bip-0099.mediawiki
Softfork
A consensus fork wherein everything that was previously invalid remains invalid while blocks that would have previously considered valid become invalid. A hashrate majority of miners can impose the new rules. They have some deployment advantages like backward compatibility.
Hardfork
A consensus fork that makes previously invalid blocks valid. Hardforks require all users to upgrade.

The essential element of a hard fork is that the new rule may cause rejection of blocks that are not rejected by old rules (thereby requiring that all users adopt the new rule in order to avoid a split). The reason a hard fork is interesting is that it can create a chain split even if it is enforced by majority hash power.

That is not the case with a soft fork and it is not the case here. A split can occur. The fact that it is possible for the split to also eventually orphan the old nodes does not make it a soft fork. A soft fork requires that a hash power majority can impose the rule. However, under the proposed new rule the hash power majority (according to the new rule) cannot impose the rule on existing nodes.

> This proposal is not a hard-fork, because the non-upgraded node *will heal* if the attack has less than 1/2 of the original-POW power in the long term.

Nothing about this proposal implies an attack. From the Motivation section:

Mitigate centralization pressures by introducing a POW that does not have economies of scale
Introduce an intermediary confirmation point, reducing the impact of mining power fluctuations

> The cost of such an attack is the cost of a normal "51%" attack, multiplied by the fractional weight of the original POW (e.g. 0.75 or 0.5).
> 
> So rather than saying this is a hard-fork, I would say that this is a soft-fork with reduced security for non-upgraded nodes.

Presumably this preference exists because it implies the new rule would not cause a chain split, making it more acceptable to a risk-averse economy. This is precisely why it should be described correctly.

> I would also say that the reduction in security is proportional to the reduction in weight of the original POW at the time of attack.
> 
> As mentioned before, the original-POW weight starts at 1.0 and is reduced over a long period of time.  I would set up the transition curve so that all nodes upgrade by the time the weight is, say, 0.75.  In reality, nodes protecting high economic value would upgrade early.

In reality you have no way to know if/when people would adopt this rule. What matters in the proposal is that people who do adopt it are well aware of its ability to split them from the existing economy.

e

>> On Mon, Nov 6, 2017 at 3:55 PM Eric Voskuil via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
>> If a block that would be discarded under previous rules becomes accepted after a rule addition, there is no reason to not simply call the new rule a hard fork. IOW it's perfectly rational to consider a weaker block as "invalid" relative to the strong chain. As such I don't see any reason to qualify the term, it's a hard fork. But Peter's observation (the specific behavior) is ultimately what matters.
>> 
>> e
>> 
>>> On Nov 6, 2017, at 12:30, Paul Sztorc via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
>>> 
>>> +1 to all of Peter Todd's comments
>>> 
>>>> On Nov 6, 2017 11:50 AM, "Peter Todd via bitcoin-dev" <bitcoin-dev at lists.linuxfoundation.org> wrote:
>>>> On Wed, Nov 01, 2017 at 05:48:27AM +0000, Devrandom via bitcoin-dev wrote:
>>>> 
>>>> Some quick thoughts...
>>>> 
>>>> > Hi all,
>>>> >
>>>> > Feedback is welcome on the draft below.  In particular, I want to see if
>>>> > there is interest in further development of the idea and also interested in
>>>> > any attack vectors or undesirable dynamics.
>>>> >
>>>> > (Formatted version available here:
>>>> > https://github.com/devrandom/btc-papers/blob/master/aux-pow.md )
>>>> >
>>>> > # Soft-fork Introduction of a New POW
>>>> 
>>>> First of all, I don't think you can really call this a soft-fork; I'd call it a
>>>> "pseudo-soft-fork"
>>>> 
>>>> My reasoning being that after implementation, a chain with less total work than
>>>> the main chain - but more total SHA256^2 work than the main chain - might be
>>>> followed by non-supporting clients. It's got some properties of a soft-fork,
>>>> but it's security model is definitely different.
>>>> 
>>>> > ### Aux POW intermediate block
>>>> >
>>>> > Auxiliary POW blocks are introduced between normal blocks - i.e. the chain
>>>> > alternates between the two POWs.
>>>> > Each aux-POW block points to the previous normal block and contains
>>>> > transactions just like a normal block.
>>>> > Each normal block points to the previous aux-POW block and must contain all
>>>> > transactions from the aux-POW block.
>>>> 
>>>> Note how you're basically proposing for the block interval to be decreased,
>>>> which has security implications due to increased orphan rates.
>>>> 
>>>> > ### Heaviest chain rule change
>>>> >
>>>> > This is a semi-hard change, because non-upgraded nodes can get on the wrong
>>>> > chain in case of attack.  However,
>>>> 
>>>> Exactly! Not really a soft-fork.
>>>> 
>>>> --
>>>> https://petertodd.org 'peter'[:-1]@petertodd.org
>>>> 
>>>> _______________________________________________
>>>> bitcoin-dev mailing list
>>>> bitcoin-dev at lists.linuxfoundation.org
>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>> _______________________________________________
>>> bitcoin-dev mailing list
>>> bitcoin-dev at lists.linuxfoundation.org
>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171111/1ce6f87b/attachment.html>

From mats at blockchain.com  Mon Nov 13 10:03:04 2017
From: mats at blockchain.com (Mats Jerratsch)
Date: Mon, 13 Nov 2017 10:03:04 +0000
Subject: [bitcoin-dev] Generalised Replay Protection for Future Hard
	Forks
In-Reply-To: <CAAUaCyg70uUnUp1Q0a6kEoQ1Js68VFLgthyfwyMQaaEqO8R-UQ@mail.gmail.com>
References: <7601C2CD-8544-4501-80CE-CAEB402A72D2@blockchain.com>
	<CAAUaCyii2U5VBLS+Va+F3h4Hka0OWDnFFmjtsvyaaD4TKVzV3Q@mail.gmail.com>
	<CAAUaCyiZ0bmWZLZc-yDvVHupzbdRR=Kdq4P8VkWqpU1L3G-u3A@mail.gmail.com>
	<C9A47922-5777-44AC-871A-6C27A22054AC@blockchain.com>
	<CAAUaCyjVxJbPrbBUdb9irK5CNnuqUSnzSjywpozhLqONcb_m_w@mail.gmail.com>
	<45C2D68B-BA8E-47DE-BFA5-643922395B2A@sprovoost.nl>
	<CAAUaCygeOxAK=EpzfWndx6uVvVO9B+=YTs1m-jHa3BFp82jA4w@mail.gmail.com>
	<95ECB451-56AE-45E5-AAE6-10058C4B7FD7@sprovoost.nl>
	<CAAUaCyg_PGT0F=RHfX89T54j-vuyz5wcbXaYoikJv95WKgsNPg@mail.gmail.com>
	<55467A01-A8B2-4E73-8331-38C0A7CD90EF@sprovoost.nl>
	<CAAUaCyhncyCt_ao9i0=33LswDOkCf6o-+36zrGxKWD+WranmZw@mail.gmail.com>
	<46E317DF-C97C-4797-B989-594298BC6030@sprovoost.nl>
	<CAAUaCyibOEHqw1J5O8yEp8v=j8t9sovn2vn=S8bZPZCzCY-gRw@mail.gmail.com>
	<3FBEE883-A15E-425C-8BF1-F7792FA63961@blockchain.com>
	<CAAUaCyg70uUnUp1Q0a6kEoQ1Js68VFLgthyfwyMQaaEqO8R-UQ@mail.gmail.com>
Message-ID: <24A6C651-272B-4452-8A81-31651D9A2694@blockchain.com>


> OK, so nForkId 0 is exactly the "valid on all chains" specifier I was asking about, cool.  And your LN example (and nLockTime txs in general) illustrate why it's preferable to implement a generic replay protection scheme like yours in advance, rather than before each fork: all ad hoc RP schemes I know of break old txs on one of the chains, even when that's not desirable - ie, they offer no wildcard like nForkId 0.

Exactly!

> One comment on your LN example: users would have to take note that nForkId 0 txs would be valid not only on future forks, but on past forks too.  Eg, if BCH had been deployed with nForkId 2, then a user setting up BTC LN txs now with nForkId 0 would have to be aware that those txs would be valid for BCH too.  Of course the user could avoid this by funding from a BTC-only address, but it is a potential minor pitfall of nForkId 0.  (Which I don't see any clean way around.)

This is actually incorrect. There are two transactions involved in LN. The funding transaction, which opens a payment channel, and a commitment transaction, which closes the channel when broadcasted to the network (the cooperative closing transaction can be considered a commitment transaction in a loose sense).

Now you want to protect the funding transaction, as otherwise you would be subject to a replay-attack on all *past* forks. So you will set `nForkId>=1` for the funding transaction, making this payment channel non-existent on any *past* forks. However, if during the lifetime of the payment channel another fork happens, the payment channel exists for both tokens. So for the commitment transaction, you will have `nForkId=0`, making it valid on both of these chains. While this `nForkId` is valid on all chains, the parent transaction it tries to spend (the funding transaction) does only exist on two chains, the original one you created the channel for and the one that forked away.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171113/6fca842c/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 842 bytes
Desc: Message signed with OpenPGP
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171113/6fca842c/attachment.sig>

From vance.turner at sbcglobal.net  Mon Nov 13 05:57:42 2017
From: vance.turner at sbcglobal.net (Vance Turner)
Date: Sun, 12 Nov 2017 21:57:42 -0800
Subject: [bitcoin-dev] Intersection of file system work based on Mandelbrot
	with Bitcoin Block Chain.
Message-ID: <029801d35c44$52dbbba0$f89332e0$@turner@sbcglobal.net>

I have been working on filesystem based on Mandelbrots formula, and it seems
that it is a prime candidate for extending the bitcoin algorithm.

 

Would like to run some of this by you folks. 

 

The key is that the Mandelbrot workers could help to modify the verification
work so that the brute force work in the current hash.

 

It would allow the hash results to reign in the next iteration.

 

Also the hash results could help to build a fast lookup table of future
variations of the block chain.

 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171112/50b2924f/attachment.html>

From jacob.eliosoff at gmail.com  Mon Nov 13 15:31:55 2017
From: jacob.eliosoff at gmail.com (Jacob Eliosoff)
Date: Mon, 13 Nov 2017 10:31:55 -0500
Subject: [bitcoin-dev] Generalised Replay Protection for Future Hard
	Forks
In-Reply-To: <24A6C651-272B-4452-8A81-31651D9A2694@blockchain.com>
References: <7601C2CD-8544-4501-80CE-CAEB402A72D2@blockchain.com>
	<CAAUaCyii2U5VBLS+Va+F3h4Hka0OWDnFFmjtsvyaaD4TKVzV3Q@mail.gmail.com>
	<CAAUaCyiZ0bmWZLZc-yDvVHupzbdRR=Kdq4P8VkWqpU1L3G-u3A@mail.gmail.com>
	<C9A47922-5777-44AC-871A-6C27A22054AC@blockchain.com>
	<CAAUaCyjVxJbPrbBUdb9irK5CNnuqUSnzSjywpozhLqONcb_m_w@mail.gmail.com>
	<45C2D68B-BA8E-47DE-BFA5-643922395B2A@sprovoost.nl>
	<CAAUaCygeOxAK=EpzfWndx6uVvVO9B+=YTs1m-jHa3BFp82jA4w@mail.gmail.com>
	<95ECB451-56AE-45E5-AAE6-10058C4B7FD7@sprovoost.nl>
	<CAAUaCyg_PGT0F=RHfX89T54j-vuyz5wcbXaYoikJv95WKgsNPg@mail.gmail.com>
	<55467A01-A8B2-4E73-8331-38C0A7CD90EF@sprovoost.nl>
	<CAAUaCyhncyCt_ao9i0=33LswDOkCf6o-+36zrGxKWD+WranmZw@mail.gmail.com>
	<46E317DF-C97C-4797-B989-594298BC6030@sprovoost.nl>
	<CAAUaCyibOEHqw1J5O8yEp8v=j8t9sovn2vn=S8bZPZCzCY-gRw@mail.gmail.com>
	<3FBEE883-A15E-425C-8BF1-F7792FA63961@blockchain.com>
	<CAAUaCyg70uUnUp1Q0a6kEoQ1Js68VFLgthyfwyMQaaEqO8R-UQ@mail.gmail.com>
	<24A6C651-272B-4452-8A81-31651D9A2694@blockchain.com>
Message-ID: <CAAUaCygjVDuqmVPS-1thnEbKgKYM9LW-7CsuAAnn7vqntMnWxA@mail.gmail.com>

>
> This is actually incorrect. There are two transactions involved in LN. The
> funding transaction, which opens a payment channel, and a commitment
> transaction, which closes the channel when broadcasted to the network (the
> cooperative closing transaction can be considered a commitment transaction
> in a loose sense).
>
> Now you want to protect the funding transaction, as otherwise you would be
> subject to a replay-attack on all *past* forks. So you will set
> `nForkId>=1` for the funding transaction, making this payment channel
> non-existent on any *past* forks. However, if during the lifetime of the
> payment channel another fork happens, the payment channel exists for both
> tokens. So for the commitment transaction, you will have `nForkId=0`,
> making it valid on both of these chains. While this `nForkId` is valid on
> all chains, the parent transaction it tries to spend (the funding
> transaction) does only exist on two chains, the original one you created
> the channel for and the one that forked away.
>

Thanks for the clarification.  How would a tx specify a constraint like
"nForkId>=1"?  I was thinking of it just as a number set on the tx.

Also note that since forks form a partial order, but IDs (numbers) form a
total order, ">=" will miss some cases.  Eg, suppose BCH had forked with
nForkId 2, and then you set up a LN funding tx on BCH with nForkId>=2, and
then Segwit2x forked (from BTC!) with nForkId 3.  The BCH funding tx would
be valid on Segwit2x.  This is more of a fundamental problem than a bug -
to avoid it you'd have to get into stuff like making each fork reference
its parent-fork's first block or something, someone has written about
this...


On Mon, Nov 13, 2017 at 5:03 AM, Mats Jerratsch <mats at blockchain.com> wrote:

>
> OK, so nForkId 0 is exactly the "valid on all chains" specifier I was
> asking about, cool.  And your LN example (and nLockTime txs in general)
> illustrate why it's preferable to implement a generic replay protection
> scheme like yours *in advance*, rather than before each fork: all ad hoc
> RP schemes I know of break old txs on one of the chains, even when that's
> not desirable - ie, they offer no wildcard like nForkId 0.
>
>
> Exactly!
>
> One comment on your LN example: users would have to take note that nForkId
> 0 txs would be valid not only on future forks, but on *past* forks too.
> Eg, if BCH had been deployed with nForkId 2, then a user setting up BTC LN
> txs now with nForkId 0 would have to be aware that those txs would be valid
> for BCH too.  Of course the user could avoid this by funding from a
> BTC-only address, but it is a potential minor pitfall of nForkId 0.  (Which
> I don't see any clean way around.)
>
>
> This is actually incorrect. There are two transactions involved in LN. The
> funding transaction, which opens a payment channel, and a commitment
> transaction, which closes the channel when broadcasted to the network (the
> cooperative closing transaction can be considered a commitment transaction
> in a loose sense).
>
> Now you want to protect the funding transaction, as otherwise you would be
> subject to a replay-attack on all *past* forks. So you will set
> `nForkId>=1` for the funding transaction, making this payment channel
> non-existent on any *past* forks. However, if during the lifetime of the
> payment channel another fork happens, the payment channel exists for both
> tokens. So for the commitment transaction, you will have `nForkId=0`,
> making it valid on both of these chains. While this `nForkId` is valid on
> all chains, the parent transaction it tries to spend (the funding
> transaction) does only exist on two chains, the original one you created
> the channel for and the one that forked away.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171113/ae5bea73/attachment-0001.html>

From greg at xiph.org  Tue Nov 14 01:21:14 2017
From: greg at xiph.org (Gregory Maxwell)
Date: Tue, 14 Nov 2017 01:21:14 +0000
Subject: [bitcoin-dev] Updates on Confidential Transactions efficiency
Message-ID: <CAAS2fgQ0Cb2B=Ye2TnpfQqP4=kpZCxMWRXYB0CcFa71sQJaGuw@mail.gmail.com>

Jump to "New things here" if you're already up to speed on CT and just
want the big news.

Back in 2013 Adam Back proposed that Bitcoin and related systems could
use additive homomorphic commitments instead of explicit amounts in
place of values in transactions for improved privacy.     (
https://bitcointalk.org/index.php?topic=305791.0 )

We've since adopted the name 'confidential transactions' for this
particular approach to transaction privacy.

This approach makes transaction amounts private--known only to the
sender, the receiver, and whichever parties they choose to share the
information with through sharing watching keys or through revealing
single transactions. While that, combined with pseudonymous addresses,
is a pretty nice privacy improvement in itself, it turns out that
these blinded commitments also perfectly complement CoinJoin (
https://bitcointalk.org/index.php?topic=279249.0 ) by avoiding the
issue of joins being decoded due to different amounts being used. Tim
Ruffing and Pedro Moreno-Sanchez went on to show that CJ can be
dropped into distributed private protocols for CoinJoin (
http://fc17.ifca.ai/bitcoin/papers/bitcoin17-final6.pdf ) which
achieve the property where no participant learns which output
corresponds to which other participant.

The primary advantage of this approach is that it can be constructed
without any substantial new cryptographic assumptions (e.g., only
discrete log security in our existing curve), that it can be high
performance compared to alternatives, that it has no trusted setup,
and that it doesn't involve the creation of any forever-growing
unprunable accumulators.  All major alternative schemes fail multiple
of these criteria (e.g., arguably Zcash's scheme fails every one of
them).

I made an informal write-up that gives an overview of how CT works
without assuming much crypto background:
https://people.xiph.org/~greg/confidential_values.txt

The main sticking point with confidential transactions is that each
confidential output usually requires a witness which shows that the
output value is in range.  Prior to our work, the smallest range
proofs without trusted setup for the 0-51 bit proofs needed for values
in Bitcoin would take up 160 bytes per bit of range proved, or 8160
bytes needed for 51 bits--something like a 60x increase in transaction
size for a typical transaction usage.

I took Adam's suggestion and invented a number of new optimizations,
and created a high performance implementation. (
https://github.com/ElementsProject/secp256k1-zkp/tree/secp256k1-zkp/src/modules/rangeproof
). With these optimizations the size is reduced to 128 bytes per two
bits plus 32 bytes; about 40% of the prior size.  My approach also
allowed a public exponent and minimum value so that you could use a
smaller range (e.g., 32 bits) and have it cover a useful range of
values (though with a little privacy trade-off). The result could give
proof sizes of about 2.5KB per output under realistic usage.  But this
is still a 20x increase in transaction size under typical usage--
though some in the Bitcoin space seem to believe that 20x larger
blocks would be no big deal, this isn't a view well supported by the
evidence in my view.

Subsequent work has been focused on reducing the range proof size further.

In our recent publication on confidential assets (
https://blockstream.com/bitcoin17-final41.pdf ) we reduce the size to
96*log3(2)*bits + 32, which still leaves us at ~16x size for typical
usage. (The same optimizations support proofs whose soundness doesn't
even depend on the discrete log assumption with the same size as the
original CT publication).

-- New things here --

The exciting recent update is that Benedikt B?nz at Standford was able
to apply and optimize the inner product argument of Jonathan Bootle to
achieve an aggregate range proof for CT with size 64 * (log2(bits *
num_outputs)) + 288, which is ~736 bytes for the 64-bit 2-output case.

This cuts the bloat factor down to ~3x for today's traffic patterns.
Since the scaling of this approach is logarithmic with the number of
outputs, use of CoinJoin can make the bloat factor arbitrarily small.
E.g., combining 64 transactions still only results in a proof under
1.1KB, so in that case the space overhead from the range proof is
basically negligible.

The log scaling in the number of range-bits also means that unlike the
prior construction there is little reason to be skimpy with the number
of bits of range at the potential expense of privacy: covering the
full range of possible values takes only slightly longer proofs than
covering a short range. This scheme also has a straightforward and
efficient method for multi-party computation, which means that the
aggregates can be used in all-party-private coinjoins like the value
shuffle work mentioned above.

Unlike prior optimizations, verification in this new work requires
computation which is more than linear in the size of the proof (the
work is linear in the size of the statement being proved).  So it's
likely that in spite of the small proofs the verification will be
similar in speed to the prior version, and likely that computation
will be the bottleneck.  Andrew, Pieter, Jonas Nick, and I are working
on an optimized implementation based on libsecp256k1 so we'll know
more precise performance numbers soon.

This work also allows arbitrarily complex conditions to be proven in
the values, not just simple ranges, with proofs logarithmic in the
size of the arithmetic circuit representing the conditions being
proved--and still with no trusted setup. As a result it potentially
opens up many other interesting applications as well.

The pre-print on this new work is available at https://eprint.iacr.org/2017/1066

From pete at petertodd.org  Tue Nov 14 09:11:23 2017
From: pete at petertodd.org (Peter Todd)
Date: Tue, 14 Nov 2017 04:11:23 -0500
Subject: [bitcoin-dev] Updates on Confidential Transactions efficiency
In-Reply-To: <CAAS2fgQ0Cb2B=Ye2TnpfQqP4=kpZCxMWRXYB0CcFa71sQJaGuw@mail.gmail.com>
References: <CAAS2fgQ0Cb2B=Ye2TnpfQqP4=kpZCxMWRXYB0CcFa71sQJaGuw@mail.gmail.com>
Message-ID: <20171114091123.GA29286@savin.petertodd.org>

On Tue, Nov 14, 2017 at 01:21:14AM +0000, Gregory Maxwell via bitcoin-dev wrote:
> Jump to "New things here" if you're already up to speed on CT and just
> want the big news.

<snip>

> This work also allows arbitrarily complex conditions to be proven in
> the values, not just simple ranges, with proofs logarithmic in the
> size of the arithmetic circuit representing the conditions being
> proved--and still with no trusted setup. As a result it potentially
> opens up many other interesting applications as well.
> 
> The pre-print on this new work is available at https://eprint.iacr.org/2017/1066

Re: section 4.6, "For cryptocurrencies, the binding property is more important
than the hiding property. An adversary that can break the binding property of
the commitment scheme or the soundness of the proof system can generate coins
out of thin air and thus create uncontrolled but undetectable inflation
rendering the currency useless.  Giving up the privacy of a transaction is much
less harmful as the sender of the transaction or the owner of an account is
harmed at worst."

I _strongly_ disagree with this statement and urge you to remove it from the
paper.

The worst-case risk of undetected inflation leading to the destruction of a
currency is an easily quantified risk: at worst any given participant loses
whatever they have invested in that currency. While unfortunate, this isn't a
unique or unexpected risk: cryptocurrencies regularly lose 50% - or even 90% -
of their value due to fickle markets alone. But cryptocurrency owners shrug
these risks off. After all, it's just money, and diversification is an easy way
to mitigate that risk.

But a privacy break? For many users _that_ threatens their very freedom,
something that's difficult to even put a price on.

Furthermore, the risk of inflation is a risk that's easily avoided: at a
personal level, sell your holdings in exchange for a less risky system; at a
system-wide level, upgrade the crypto.

But a privacy leak? Once I publish a transaction to the world, there's no easy
way to undo that act. I've committed myself to trusting the crypto
indefinitely, without even a sure knowledge of what kind of world I'll live in
ten years down the road. Sure, my donation to Planned Parenthood or the NRA
might be legal now, but will it come back to haunt me in ten years?


Fortunately, as section 4.6 goes on to note, Bulletproofs *are* perfectly
hiding. But that's a feature we should celebrate! The fact that quantum
computing may force us to give up that essential privacy is just another
example of quantum computing ruining everything, nothing more.

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 455 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171114/8a02b949/attachment.sig>

From pete at petertodd.org  Tue Nov 14 10:07:28 2017
From: pete at petertodd.org (Peter Todd)
Date: Tue, 14 Nov 2017 05:07:28 -0500
Subject: [bitcoin-dev] Updates on Confidential Transactions efficiency
In-Reply-To: <CAAS2fgQ0Cb2B=Ye2TnpfQqP4=kpZCxMWRXYB0CcFa71sQJaGuw@mail.gmail.com>
References: <CAAS2fgQ0Cb2B=Ye2TnpfQqP4=kpZCxMWRXYB0CcFa71sQJaGuw@mail.gmail.com>
Message-ID: <20171114100728.GA29749@savin.petertodd.org>

On Tue, Nov 14, 2017 at 01:21:14AM +0000, Gregory Maxwell via bitcoin-dev wrote:
> The primary advantage of this approach is that it can be constructed
> without any substantial new cryptographic assumptions (e.g., only
> discrete log security in our existing curve), that it can be high
> performance compared to alternatives, that it has no trusted setup,
> and that it doesn't involve the creation of any forever-growing
> unprunable accumulators.  All major alternative schemes fail multiple
> of these criteria (e.g., arguably Zcash's scheme fails every one of
> them).

Re: the unprunable accumulators, that doesn't need to be an inherent property
of Zcash/Monero style systems.

It'd be quite feasible to use accumulator epochs and either make unspent coins
in a previous epoch unspendable after some expiry time is reached - allowing
the spent coin accumulator data to be discarded - or make use of a merkelized
key-value scheme with transaction provided proofs to shift the costs of
maintaining the accumulator to wallets.

The disadvantage of epoch schemes is of course a reduced k-anonymity set, but
if I understand the Confidential Transactions proposals correctly, they already
have a significantly reduced k-anonymity set per transaction than Zcash
theoretically could (modulo it's in practice low anonymity set due to lack of
actual usage). In that respect, epoch size is simply a tradeoff between state
size and k-anonymity set size.

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 455 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171114/cef7d4fb/attachment.sig>

From greg at xiph.org  Tue Nov 14 10:38:33 2017
From: greg at xiph.org (Gregory Maxwell)
Date: Tue, 14 Nov 2017 10:38:33 +0000
Subject: [bitcoin-dev] Updates on Confidential Transactions efficiency
In-Reply-To: <20171114091123.GA29286@savin.petertodd.org>
References: <CAAS2fgQ0Cb2B=Ye2TnpfQqP4=kpZCxMWRXYB0CcFa71sQJaGuw@mail.gmail.com>
	<20171114091123.GA29286@savin.petertodd.org>
Message-ID: <CAAS2fgQVJU659NsX054YTTB1MCDWtSk9PXJo5+EgrBRRG+VDsw@mail.gmail.com>

On Tue, Nov 14, 2017 at 9:11 AM, Peter Todd <pete at petertodd.org> wrote:
> I _strongly_ disagree with this statement and urge you to remove it from the
> paper.

I very strongly disagree with your strong disagreement.

> The worst-case risk of undetected inflation leading to the destruction of a
> currency is an easily quantified risk: at worst any given participant loses
> whatever they have invested in that currency. While unfortunate, this isn't a
> unique or unexpected risk: cryptocurrencies regularly lose 50% - or even 90% -
> of their value due to fickle markets alone. But cryptocurrency owners shrug
> these risks off. After all, it's just money, and diversification is an easy way
> to mitigate that risk.
>
> But a privacy break? For many users _that_ threatens their very freedom,
> something that's difficult to even put a price on.

Its important that people know and understand what properties a system has.

Perhaps one distinction you miss is that perfectly hiding systems
don't even exist in practice: I would take a bet that no software on
your system that you can use with other people actually implements a
perfectly hiding protocol (much less find on most other people's
system system :)).

In the case of practical use with CT perfect hiding is destroyed by
scalability-- the obvious construction is a stealth address like one
where a DH public key is in the address and that is used to scan for
your payments against a nonce pubkey in the transactions.   The
existence of that mechanism destroys perfect hiding.  No scheme that
can be scanned using an asymmetric key is going to provide perfect
hiding.

Now, perhaps what you'd like is a system which is not perfect hiding
but where the hiding rests on less "risky" assumptions.  That is
something that can plausibly be constructed, but it's not itself
incompatible with unconditional soundness.

As referenced in the paper, there is also the possibility of having a
your cake and eating it too-- switch commitments for example allow
having computational-hiding-depending-on-the-hardness-of-inverting-hashes
 (which I would argue is functionally as good as perfect hiding, esp
since hiding is ultimately limited by the asymmetric crypto used for
discovery)  and yet it retains an option to upgrade or block spending
via unsound mechanisms in the event of a crypto break.

> Furthermore, the risk of inflation is a risk that's easily avoided:

Sounds like you are assuming that you know when there is a problem, if
you do then the switch commitments scheme works and doesn't require
any selling of anything. Selling also has the problem that everyone
would want to do it at once if there was a concern; this would not
have good effects. :) Without switch commitments though, you are just
hosed.  And you cannot have something like switch commitments without
abandoning perfect hiding ( though you get hiding which is good enough
(tm), as mentioned above).

On Tue, Nov 14, 2017 at 10:07 AM, Peter Todd <pete at petertodd.org> wrote:
> Re: the unprunable accumulators, that doesn't need to be an inherent property
> of Zcash/Monero style systems.
>
> It'd be quite feasible to use accumulator epochs and either make unspent coins
> in a previous epoch unspendable after some expiry time is reached - allowing

Miners to reduce coin supply, enhancing the value of their own
holdings, by simply not letting near-expiry ones get spent...
(This can be partially mediated by constructing proofs to hide if a
coins in near expiration or not.)

> or make use of a merkelized key-value scheme with transaction provided proofs to shift the costs of
> maintaining the accumulator to wallets.

Yes, that they can do-- though with the trade-offs inherent in that.
It is worse than what you were imagining in the Bitcoin case because
you cannot use one or two time-ordered trees, the spent coins list
needs search-insertion; so maintaining it over time is harder. :(  The
single time ordered tree trick doesn't work because you can't mutate
the entries without blowing anonymity.

I think it's still fair to say that ring-in and tree-in approaches
(monero, and zcash) are fundamentally less scalable than
CT+valueshuffle, but more private-- though given observations of Zcash
behavior perhaps not that much more private.  With the right smart
tricks the scalablity loss might be more inconvenient than fatal, but
they're still a loss even if they're one that makes for a good
tradeoff.

As an aside, you shouldn't see Monero as entirely distinct now that
we're talking about a framework which is fully general:  Extending
this to a traceable 1 of N input for monero is simple-- and will add
size log() in the number of ring inputs with good constant factors.
One could also store inputs in a hash tree, and then have a
bulletproof that verified membership in the tree.  This would provide
tree-in style transactions with proofs that grow with the log() of the
size of the tree (and a spent coins accumulator); the challenge there
would be choosing a hash function that had a compact representation in
the arithmetic circuit so that the constant factors aren't terrible.
Effectively that's what bulletproofs does:   It takes a general scheme
for ZKP of arbitrary computation, which could implement a range proof
by opening the commitments (e.g. a circuit for EC point scalar
multiply) and checking the value, and optimizes it to handle the
commitments more directly. If you're free to choose the hash function
there may be a way to make a hash tree check ultra efficient inside
the proof, in which case this work could implement a tree-in scheme
like zcash-- but with larger proofs and slower verification in
exchange for much better crypto assumptions and no trusted setup.
This is part of what I meant by it opening up "many other interesting
applications".

But as above, I think that the interactive-sparse-in (CJ) has its own
attractiveness, even though it is not the strongest for privacy.

From greg at xiph.org  Tue Nov 14 10:51:13 2017
From: greg at xiph.org (Gregory Maxwell)
Date: Tue, 14 Nov 2017 10:51:13 +0000
Subject: [bitcoin-dev] Updates on Confidential Transactions efficiency
In-Reply-To: <CAAS2fgQVJU659NsX054YTTB1MCDWtSk9PXJo5+EgrBRRG+VDsw@mail.gmail.com>
References: <CAAS2fgQ0Cb2B=Ye2TnpfQqP4=kpZCxMWRXYB0CcFa71sQJaGuw@mail.gmail.com>
	<20171114091123.GA29286@savin.petertodd.org>
	<CAAS2fgQVJU659NsX054YTTB1MCDWtSk9PXJo5+EgrBRRG+VDsw@mail.gmail.com>
Message-ID: <CAAS2fgQSyzZ_1Cf+DQ4Vrs4wUHKe7Kk93p0ixq1xXXbFY8YXGQ@mail.gmail.com>

On Tue, Nov 14, 2017 at 10:38 AM, Gregory Maxwell <greg at xiph.org> wrote:
> I think it's still fair to say that ring-in and tree-in approaches
> (monero, and zcash) are fundamentally less scalable than
> CT+valueshuffle, but more private-- though given observations of Zcash

While I'm enumerating private transaction topologies there is fourth
one I'm aware of (most closely related to ring-in):

take N inputs,  write >= N outputs,  where some coins are spent and
replaced with a new output, or an encrypted dummy... and other coins
are simply reencrypted in a way that their owner can still decode.
Provide a proof that shows you did this faithfully. So this one avoids
the spent coins list by being able to malleiate the inputs.

We never previously found an efficient way to construct that one in a
plain DL setting, but it's probably possible w/ bulletproofs, at least
for some definition of efficient.

From creighto at sdf.org  Wed Nov 15 02:13:31 2017
From: creighto at sdf.org (creighto at sdf.org)
Date: Wed, 15 Nov 2017 02:13:31 -0000
Subject: [bitcoin-dev] Con-peg sidechain model
Message-ID: <5d7cceb34b3d49a0fc9822450e42c750.squirrel@mx.sdf.org>

I posted the following on bitcointalk.org and slack bitcoinunlimited. 
This isn't a technical paper, just fleshing out my thoughts and hoping for
some help & feedback.  I understand bitcoin as well as any non-programer
realisticly could, but I am not a programmer, so if this isn't feasible,
someone please let me know why.

-MoonShadow

Con-Peg Sidechain Model

I know that this is going to sound similar to the Fed-Peg model, so don't
whine about that. It's not the Fed-Peg model, not quite, and the
differences are critical, I believe.

Every proposal that I've seen so far require some kind of soft or hard
fork to the current bitcoin model, but I think that I've come up with a
way to make a sidechain work without new modifications to the running
bitcoin protocol.

I think I will call it the Confederation-Peg model.

Imagine a confederation of large corporations, all of which would benefit
from the ability to process a large number of bitcoin transactions for net
zero or near zero transaction fees.
These corporations would, most likely, have to have the following
characteristics...

1) Multi-national in scope, with employee bases in several different
nations using several different fiat currencies.
2) Have a rather large employee base.
3) Not in direct competition with each other
4) and not dependent upon any particular government.
With just a bit of google-fu, I will use the following corporations in
this example...

Wal-Mart, with more than 2 million employees worldwide.
Volkswagon, with more than half a million employees worldwide.
General Electric, with about 300K employees worldwide.
and Johnson & Johnson, with More than 100K.

Let's call these corporations the confederation sponsors. These sponsors
would decide most of the sidechain's rules by consensus amongst
themselves, but let me lay out, in general, how I think that such a
sidechain can be set up so that the sidechain is secure while also
contributing to the overall security of the main blockchain.

First, these sponsors agree upon a deposit/escrow amount that they will
each commit to a multi-sig address on the main blockchain; for a round
number, let's say they all contribute 10 BTC to the cause. Next, they all
agree that they must each either build or contract out bitcoin mining
capability of a minimum standard; high enough that the collection of
sponsors can mine a block on a regular interval. Let's say once each day.
But when they mine a main blockchain block, they place into the 100 byte
large "2nd nonce" space of the coinbase transaction the following data.

1) a code that identifies the sponsor who mined this block to the other
sponsors,
2) the merkle tree root hash of the sidechain block that the sponsor is
about to release on the sidechain network.
3) a cryptographic signing of the two prior pieces of data. (this might be
unnecessary, I'm not sure)

Once a sponsor's mining agent releases this block to the network, and it's
accepted as valid by the main blockchain, The sponsor then releases the
sidechain block to the other sponsors. This block can be of an arbitrarily
large size; enough to accommodate all of the transactions that all of the
sponsors (and their clients) have produced in the past day. Since it's
likely that every sponsor has seen every valid transaction, this block
might only include the merkle tree created by the most recent mining
sponsor.

This looks a lot like merged mining, but it's not, because the side chain
doesn't use proof-of-work, and doesn't require it. It uses
proof-of-authority. Specifically, releasing a valid block onto the main
blockchain is the proof of the authority to release the next sidechain
block. This achieves several things for the sponsors.

1) It contributes mining power to the main blockchain, thus supporting
main chain security regardless of the profitability for those sponsor
miners, since their incentive is to reduce the costs of their own
transactions, not win mining rewards or fees.
2) It creates a definate timeline of the blockchain of the sidechain,
without need for cryptographic proof-of-work, by tying each sidechain
block to a known main chain block. Thus leveraging the main chain's
security model without needing to attract miners willing to drop the main
chain work to mine the sidechain.
3) It establishes a definitive authority amonst the sponsors about who has
the right to publish the next block, as well as claim any sidechain
transaction fees.
4) It allows all sponsors to keep each other honest, because if any
sponsor were to cut back on their main chain mining responsibilities, they
would all be able to tell.
5) It allows the sponsors to chose to accept as many free transactions as
they like, which may or may not benefit themselves,
6) as well as keep any transaction fees that might have been issued on the
sidechain, for which odds are high that they would have had to pay. Thus
transaction fees most likely travel in a circle (for the sponsors, not the
clients)

In order to add btc to this sidechain, a main chain bitcoiner would have
to send funds to one of the sponsors, after acquiring their agreement to
issue sidechain coins using a special sidechain coinbase transaction
that...

1) creates or destroys sidechain bitcoins
2) references the main chain transaction that would permit it
3) and identifies the sponsor creating the sidechain funds

In this way, bitcoins can flow into the sidechain, and each of the
sponsors can watch the other sponsors to make certain that they aren't
creating more sidechain funds than their main chain holding would permit.
I would imagine that the rule would be that a sponsor can't issue more
side chain bitcoins than it has in it's public main chain addresses, and
if that were to be violated, the other sponsors would automatically ignore
their (otherwise valid) sidechain blocks.

This security model requires more trust than the trustless model of the
main blockchain, but permits the sidechain to structure itself in any way
necessary to permit safe referencing of unconfirmed transactions, thereby
permitting nearly instant follow-up transactions. Sponsors could also
detect, and potentially punish, double spend attemps. Any other rapid
transaction model, such as the Lightening Network, could be permitted to
work on the sidechain; but I doubt they would be necessary.
Sponsors could attract "clients" by a number of incentives. For example,
Wal-mart could offer free sidechain transactions to any paying customer,
as well as a limited number of main chain transactions to their own
employees; whereas Johnson & Johnson might only offer free transactions to
their employees and associated businesses. I can even imagine a deposit &
(fully BTC reserve backed) sidechain credit system, complete with interest
rates.

Paid for transaction fees could be based upon whatever the sponsors agree
to, including a transaction fee based upon a percentage of the transfer
value instead of the byte-size of a transaction. This would make the fee
model much closer to how current day credit card transfer fees work, but
would almost certainly be less.

Getting BTC back out of the sidechain (via the main chain) would work like
a sponsor's coinbase transaction with a negative value, also referencing a
valid transaction (which may or may not be confirmed yet) that can be seen
on the main bitcoin network. Alternatively, in a world where several such
sidechains exist, sponsors of one sidechain could be clients on another,
potentially permitting value to transfer from one sidechain directly to
another without creating a main blockchain transaction at all. The details
of the rules of both sidechains would matter in this possibility.

Since declaring weeknesses of one's own ideas is a convention in the
cryptocurrency world, let me begin...

Since this is a some-trust model; i.e. individuals have to trust an
institution, at least a little bit, in order to get onto the sidechain.
It's possible that a sponsor might take your main chain BTC and claim you
never sent them, but you'd still have the transaction you produced, so
you'd still have recourse through traditional courts.

Moving funds in the other direction, it's possible for your leaving
transaction to be blocked, but only if all of the sponsors refuse to deal
with you. Likewise, as a client, your ability to transact on the sidechain
could be hindered or blocked by the sponsors, but only if all of them
blacklist you. But that only risks the possibility that you can't spend
your bitcoins on the sidechain, not that the sponsors could take them from
you without your participation.

This is a move towards some centralization, yes; but not for bitcoin as a
whole. For the most part, "clients" choose whether the lower transaction
costs & convenience at these institutions is worth the re-addition of
trust to some portion of their bitcoin activities. Perhaps employees don't
get a choice about being a client on this sidechain, but they still get to
choose if they work for a sponsor.

This low-trust model depends upon the idea that the sponsors don't
entirely trust one another, and will keep an eye on each other for bad
behavior; much in the same way that the banks of the free banking era
would occasionally challenge one another to produce the gold for the
currencies they issued, either driving them out of business or harming
their businesses should they misbehave. It also depends upon the idea
that, for the "clients", no one on the sidechain has more to lose from
getting caught defrauding a client than the sponsors themselves, because
the integrity of the sidechain and of their own reputations are of great
value to the sponsors. It's possible that all sponsors turn to the dark
side at once, crash the sidechain & steal all of the main chain bitcoins
in their reserve addresses. Since this isn't one trusted authority, but
many in a trust-distrust relationship (and in different industries) this
possibility seems remote to me.

I could also imagine sidechains that were explicitly not worldwide in
scope, such as those limited to a particular nation or economic block.

I.E., there might be a Eurozone specific sidechain, a United States
specific sidechain (but would that be redundant?) and a Francophone
sidechain. There might be a sidechain for Portuguese speaking nations
around the world, or a sidechain just for nations in South America that
don't speak Portuguese.

There could be a sidechain that exists entirely on Tor, using high
anonymity rules; or a sidechain sponsored by governments for the expressed
purpose of paying taxes (but who would join this voluntarily?)

Many people have complained that Bitcoin isn't anonymous, because the
entire transaction history is visible. Sidechains would fix that
immediately, even without improved anonymity rules.

For that matter, since the extra-nonce space available in the coinbase
transaction is 100 bytes, that's enough to record an entire sidechain
block header anyway, so there might not be any reason to record the
headers anyplace else.







From mats at blockchain.com  Tue Nov 14 13:49:56 2017
From: mats at blockchain.com (Mats Jerratsch)
Date: Tue, 14 Nov 2017 13:49:56 +0000
Subject: [bitcoin-dev] Generalised Replay Protection for Future Hard
	Forks
In-Reply-To: <CA+Cf5AZT6KtRXmt3X6UiF0tP_hCtbUiUsS3XMXDdoaa0T1tepQ@mail.gmail.com>
References: <7601C2CD-8544-4501-80CE-CAEB402A72D2@blockchain.com>
	<CAAUaCyii2U5VBLS+Va+F3h4Hka0OWDnFFmjtsvyaaD4TKVzV3Q@mail.gmail.com>
	<CAAUaCyiZ0bmWZLZc-yDvVHupzbdRR=Kdq4P8VkWqpU1L3G-u3A@mail.gmail.com>
	<C9A47922-5777-44AC-871A-6C27A22054AC@blockchain.com>
	<CAAUaCyjVxJbPrbBUdb9irK5CNnuqUSnzSjywpozhLqONcb_m_w@mail.gmail.com>
	<45C2D68B-BA8E-47DE-BFA5-643922395B2A@sprovoost.nl>
	<CAAUaCygeOxAK=EpzfWndx6uVvVO9B+=YTs1m-jHa3BFp82jA4w@mail.gmail.com>
	<95ECB451-56AE-45E5-AAE6-10058C4B7FD7@sprovoost.nl>
	<CAAUaCyg_PGT0F=RHfX89T54j-vuyz5wcbXaYoikJv95WKgsNPg@mail.gmail.com>
	<55467A01-A8B2-4E73-8331-38C0A7CD90EF@sprovoost.nl>
	<CAAUaCyhncyCt_ao9i0=33LswDOkCf6o-+36zrGxKWD+WranmZw@mail.gmail.com>
	<46E317DF-C97C-4797-B989-594298BC6030@sprovoost.nl>
	<CAAUaCyibOEHqw1J5O8yEp8v=j8t9sovn2vn=S8bZPZCzCY-gRw@mail.gmail.com>
	<3FBEE883-A15E-425C-8BF1-F7792FA63961@blockchain.com>
	<CAAUaCyg70uUnUp1Q0a6kEoQ1Js68VFLgthyfwyMQaaEqO8R-UQ@mail.gmail.com>
	<24A6C651-272B-4452-8A81-31651D9A2694@blockchain.com>
	<CAAUaCygjVDuqmVPS-1thnEbKgKYM9LW-7CsuAAnn7vqntMnWxA@mail.gmail.com>
	<CA+Cf5AZT6KtRXmt3X6UiF0tP_hCtbUiUsS3XMXDdoaa0T1tepQ@mail.gmail.com>
Message-ID: <71A64D11-DE57-4AA2-A635-F2AA4DC04909@blockchain.com>


> But I like the 'old' idea of putting the hash of a block that MUST be on the chain that this txn can eventually be added to. If the hash is not a valid block on the chain, the txn can't be added.
> 
> It means you can choose exactly which forks you want to allow your txn on, pre-fork for both, post-fork for only one, and gets round the issue of who gets to decide the nForkid value.. since you don't need one. Also, all the old outputs work fine, and LN not an issue.
> 
> I'm missing why this scheme would be better ?

I do agree that solutions like `SIGHASH_BLOCKCOMMIT` are superior in the sense that they are very difficult to circumvent. However, a fork could also follow the original chain in SPV mode and allow transactions protected with these mechanism. Since it's fundamentally impossible to disallow transactions in future projects, the goal shouldn't be to make this overly complicated.

Furthermore, this schema is not just adding replay protection. It makes transacting safer overall (due to a dedicated address format per fork) and allows light clients to differentiate between multiple forks. In the past three months, at least $600k has been lost by users sending BCH to a BTC address [1].

> Thanks for the clarification.  How would a tx specify a constraint like "nForkId>=1"?  I was thinking of it just as a number set on the tx.

Whether the transaction is replay protected or not is specified by setting a bit in the `SigHashId`. If this bit is set, then the signature *preimage* MUST have `nForkId` appended. `nForkId` is not part of the final transaction, someone who wants to verify the transaction must know which `nForkId` it was created with.

If the bit isn't set, it means `nForkId=0`, which allows other forks to validate the signature.

> Also note that since forks form a partial order, but IDs (numbers) form a total order, ">=" will miss some cases.  Eg, suppose BCH had forked with nForkId 2, and then you set up a LN funding tx on BCH with nForkId>=2, and then Segwit2x forked (from BTC!) with nForkId 3.  The BCH funding tx would be valid on Segwit2x.  This is more of a fundamental problem than a bug - to avoid it you'd have to get into stuff like making each fork reference its parent-fork's first block or something, someone has written about this...

Sorry, I was careless with the use of `>=` there. You are correct, forks form a tree. For this proposal, every leaf must be assigned a unique `nForkId`. The relationship between `nForkId` is irrelevant (e.g. which number is bigger), as long as they are unique. Transactions are only valid IFF `nForkId` matches exactly the `nForkId` of the software validating it. As described above, the transaction doesn't even contain `nForkId`, and the node surely is not starting to guess which one it could be.

[1]
https://twitter.com/khannib/status/930223617744437253 <https://twitter.com/khannib/status/930223617744437253>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171114/8a6b0269/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 842 bytes
Desc: Message signed with OpenPGP
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171114/8a6b0269/attachment.sig>

From spartacusrex99 at gmail.com  Mon Nov 13 17:02:07 2017
From: spartacusrex99 at gmail.com (Spartacus Rex)
Date: Mon, 13 Nov 2017 17:02:07 +0000
Subject: [bitcoin-dev] Generalised Replay Protection for Future Hard
	Forks
In-Reply-To: <CAAUaCygjVDuqmVPS-1thnEbKgKYM9LW-7CsuAAnn7vqntMnWxA@mail.gmail.com>
References: <7601C2CD-8544-4501-80CE-CAEB402A72D2@blockchain.com>
	<CAAUaCyii2U5VBLS+Va+F3h4Hka0OWDnFFmjtsvyaaD4TKVzV3Q@mail.gmail.com>
	<CAAUaCyiZ0bmWZLZc-yDvVHupzbdRR=Kdq4P8VkWqpU1L3G-u3A@mail.gmail.com>
	<C9A47922-5777-44AC-871A-6C27A22054AC@blockchain.com>
	<CAAUaCyjVxJbPrbBUdb9irK5CNnuqUSnzSjywpozhLqONcb_m_w@mail.gmail.com>
	<45C2D68B-BA8E-47DE-BFA5-643922395B2A@sprovoost.nl>
	<CAAUaCygeOxAK=EpzfWndx6uVvVO9B+=YTs1m-jHa3BFp82jA4w@mail.gmail.com>
	<95ECB451-56AE-45E5-AAE6-10058C4B7FD7@sprovoost.nl>
	<CAAUaCyg_PGT0F=RHfX89T54j-vuyz5wcbXaYoikJv95WKgsNPg@mail.gmail.com>
	<55467A01-A8B2-4E73-8331-38C0A7CD90EF@sprovoost.nl>
	<CAAUaCyhncyCt_ao9i0=33LswDOkCf6o-+36zrGxKWD+WranmZw@mail.gmail.com>
	<46E317DF-C97C-4797-B989-594298BC6030@sprovoost.nl>
	<CAAUaCyibOEHqw1J5O8yEp8v=j8t9sovn2vn=S8bZPZCzCY-gRw@mail.gmail.com>
	<3FBEE883-A15E-425C-8BF1-F7792FA63961@blockchain.com>
	<CAAUaCyg70uUnUp1Q0a6kEoQ1Js68VFLgthyfwyMQaaEqO8R-UQ@mail.gmail.com>
	<24A6C651-272B-4452-8A81-31651D9A2694@blockchain.com>
	<CAAUaCygjVDuqmVPS-1thnEbKgKYM9LW-7CsuAAnn7vqntMnWxA@mail.gmail.com>
Message-ID: <CA+Cf5AZT6KtRXmt3X6UiF0tP_hCtbUiUsS3XMXDdoaa0T1tepQ@mail.gmail.com>

Totally agree something like this required..

I've been burned.

But I like the 'old' idea of putting the hash of a block that MUST be on
the chain that this txn can eventually be added to. If the hash is not a
valid block on the chain, the txn can't be added.

It means you can choose exactly which forks you want to allow your txn on,
pre-fork for both, post-fork for only one, and gets round the issue of who
gets to decide the nForkid value.. since you don't need one. Also, all the
old outputs work fine, and LN not an issue.

I'm missing why this scheme would be better ?


On Nov 13, 2017 15:35, "Jacob Eliosoff via bitcoin-dev" <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> This is actually incorrect. There are two transactions involved in LN. The
>> funding transaction, which opens a payment channel, and a commitment
>> transaction, which closes the channel when broadcasted to the network (the
>> cooperative closing transaction can be considered a commitment transaction
>> in a loose sense).
>>
>> Now you want to protect the funding transaction, as otherwise you would
>> be subject to a replay-attack on all *past* forks. So you will set
>> `nForkId>=1` for the funding transaction, making this payment channel
>> non-existent on any *past* forks. However, if during the lifetime of the
>> payment channel another fork happens, the payment channel exists for both
>> tokens. So for the commitment transaction, you will have `nForkId=0`,
>> making it valid on both of these chains. While this `nForkId` is valid on
>> all chains, the parent transaction it tries to spend (the funding
>> transaction) does only exist on two chains, the original one you created
>> the channel for and the one that forked away.
>>
>
> Thanks for the clarification.  How would a tx specify a constraint like
> "nForkId>=1"?  I was thinking of it just as a number set on the tx.
>
> Also note that since forks form a partial order, but IDs (numbers) form a
> total order, ">=" will miss some cases.  Eg, suppose BCH had forked with
> nForkId 2, and then you set up a LN funding tx on BCH with nForkId>=2, and
> then Segwit2x forked (from BTC!) with nForkId 3.  The BCH funding tx would
> be valid on Segwit2x.  This is more of a fundamental problem than a bug -
> to avoid it you'd have to get into stuff like making each fork reference
> its parent-fork's first block or something, someone has written about
> this...
>
>
> On Mon, Nov 13, 2017 at 5:03 AM, Mats Jerratsch <mats at blockchain.com>
> wrote:
>
>>
>> OK, so nForkId 0 is exactly the "valid on all chains" specifier I was
>> asking about, cool.  And your LN example (and nLockTime txs in general)
>> illustrate why it's preferable to implement a generic replay protection
>> scheme like yours *in advance*, rather than before each fork: all ad hoc
>> RP schemes I know of break old txs on one of the chains, even when that's
>> not desirable - ie, they offer no wildcard like nForkId 0.
>>
>>
>> Exactly!
>>
>> One comment on your LN example: users would have to take note that
>> nForkId 0 txs would be valid not only on future forks, but on *past*
>> forks too.  Eg, if BCH had been deployed with nForkId 2, then a user
>> setting up BTC LN txs now with nForkId 0 would have to be aware that those
>> txs would be valid for BCH too.  Of course the user could avoid this by
>> funding from a BTC-only address, but it is a potential minor pitfall of
>> nForkId 0.  (Which I don't see any clean way around.)
>>
>>
>> This is actually incorrect. There are two transactions involved in LN.
>> The funding transaction, which opens a payment channel, and a commitment
>> transaction, which closes the channel when broadcasted to the network (the
>> cooperative closing transaction can be considered a commitment transaction
>> in a loose sense).
>>
>> Now you want to protect the funding transaction, as otherwise you would
>> be subject to a replay-attack on all *past* forks. So you will set
>> `nForkId>=1` for the funding transaction, making this payment channel
>> non-existent on any *past* forks. However, if during the lifetime of the
>> payment channel another fork happens, the payment channel exists for both
>> tokens. So for the commitment transaction, you will have `nForkId=0`,
>> making it valid on both of these chains. While this `nForkId` is valid on
>> all chains, the parent transaction it tries to spend (the funding
>> transaction) does only exist on two chains, the original one you created
>> the channel for and the one that forked away.
>>
>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171113/452ebe4c/attachment-0001.html>

From jacob.eliosoff at gmail.com  Wed Nov 15 05:02:48 2017
From: jacob.eliosoff at gmail.com (Jacob Eliosoff)
Date: Wed, 15 Nov 2017 00:02:48 -0500
Subject: [bitcoin-dev] Generalised Replay Protection for Future Hard
	Forks
In-Reply-To: <71A64D11-DE57-4AA2-A635-F2AA4DC04909@blockchain.com>
References: <7601C2CD-8544-4501-80CE-CAEB402A72D2@blockchain.com>
	<CAAUaCyii2U5VBLS+Va+F3h4Hka0OWDnFFmjtsvyaaD4TKVzV3Q@mail.gmail.com>
	<CAAUaCyiZ0bmWZLZc-yDvVHupzbdRR=Kdq4P8VkWqpU1L3G-u3A@mail.gmail.com>
	<C9A47922-5777-44AC-871A-6C27A22054AC@blockchain.com>
	<CAAUaCyjVxJbPrbBUdb9irK5CNnuqUSnzSjywpozhLqONcb_m_w@mail.gmail.com>
	<45C2D68B-BA8E-47DE-BFA5-643922395B2A@sprovoost.nl>
	<CAAUaCygeOxAK=EpzfWndx6uVvVO9B+=YTs1m-jHa3BFp82jA4w@mail.gmail.com>
	<95ECB451-56AE-45E5-AAE6-10058C4B7FD7@sprovoost.nl>
	<CAAUaCyg_PGT0F=RHfX89T54j-vuyz5wcbXaYoikJv95WKgsNPg@mail.gmail.com>
	<55467A01-A8B2-4E73-8331-38C0A7CD90EF@sprovoost.nl>
	<CAAUaCyhncyCt_ao9i0=33LswDOkCf6o-+36zrGxKWD+WranmZw@mail.gmail.com>
	<46E317DF-C97C-4797-B989-594298BC6030@sprovoost.nl>
	<CAAUaCyibOEHqw1J5O8yEp8v=j8t9sovn2vn=S8bZPZCzCY-gRw@mail.gmail.com>
	<3FBEE883-A15E-425C-8BF1-F7792FA63961@blockchain.com>
	<CAAUaCyg70uUnUp1Q0a6kEoQ1Js68VFLgthyfwyMQaaEqO8R-UQ@mail.gmail.com>
	<24A6C651-272B-4452-8A81-31651D9A2694@blockchain.com>
	<CAAUaCygjVDuqmVPS-1thnEbKgKYM9LW-7CsuAAnn7vqntMnWxA@mail.gmail.com>
	<CA+Cf5AZT6KtRXmt3X6UiF0tP_hCtbUiUsS3XMXDdoaa0T1tepQ@mail.gmail.com>
	<71A64D11-DE57-4AA2-A635-F2AA4DC04909@blockchain.com>
Message-ID: <CAAUaCyjpH0hAxS7pUzZihft3KDtgB3nkZdT_6JUhmE9hJ7T4sA@mail.gmail.com>

>
> Sorry, I was careless with the use of `>=` there. You are correct, forks
> form a tree. For this proposal, every leaf must be assigned a unique
> `nForkId`. The relationship between `nForkId` is irrelevant (e.g. which
> number is bigger), as long as they are unique. Transactions are only valid
> IFF `nForkId` matches exactly the `nForkId` of the software validating it.
> As described above, the transaction doesn't even contain `nForkId`, and the
> node surely is not starting to guess which one it could be.
>

OK, but then it seems to me you have a dilemma for, eg, your LN commitment
tx.  You either give it the specific nForkId of the fork it's created on -
making it invalid on *all* other forks (eg, any future "non-contentious
upgrade" HF that replaces that fork).  Or you give it nForkId 0 - which has
the "BCH tx valid on Segwit2x (& vice versa)" flaw.

It may make sense to revise your proposal to incorporate Luke's
OP_CHECKBLOCKATHEIGHT
<https://github.com/bitcoin/bips/blob/master/bip-0115.mediawiki>, and make
the fork ID a (block height, hash) pair rather than just a number.  But I
still think the idea of fork-specific addresses is a keeper!


On Tue, Nov 14, 2017 at 8:49 AM, Mats Jerratsch <mats at blockchain.com> wrote:

>
> But I like the 'old' idea of putting the hash of a block that MUST be on
> the chain that this txn can eventually be added to. If the hash is not a
> valid block on the chain, the txn can't be added.
>
> It means you can choose exactly which forks you want to allow your txn on,
> pre-fork for both, post-fork for only one, and gets round the issue of who
> gets to decide the nForkid value.. since you don't need one. Also, all the
> old outputs work fine, and LN not an issue.
>
> I'm missing why this scheme would be better ?
>
>
> I do agree that solutions like `SIGHASH_BLOCKCOMMIT` are superior in the
> sense that they are very difficult to circumvent. However, a fork could
> also follow the original chain in SPV mode and allow transactions protected
> with these mechanism. Since it's fundamentally impossible to disallow
> transactions in future projects, the goal shouldn't be to make this overly
> complicated.
>
> Furthermore, this schema is not just adding replay protection. It makes
> transacting safer overall (due to a dedicated address format per fork) and
> allows light clients to differentiate between multiple forks. In the past
> three months, at least $600k has been lost by users sending BCH to a BTC
> address [1].
>
> Thanks for the clarification.  How would a tx specify a constraint like
>> "nForkId>=1"?  I was thinking of it just as a number set on the tx.
>>
>
> Whether the transaction is replay protected or not is specified by setting
> a bit in the `SigHashId`. If this bit is set, then the signature *preimage*
> MUST have `nForkId` appended. `nForkId` is not part of the final
> transaction, someone who wants to verify the transaction must know which
> `nForkId` it was created with.
>
> If the bit isn't set, it means `nForkId=0`, which allows other forks to
> validate the signature.
>
> Also note that since forks form a partial order, but IDs (numbers) form a
>> total order, ">=" will miss some cases.  Eg, suppose BCH had forked with
>> nForkId 2, and then you set up a LN funding tx on BCH with nForkId>=2, and
>> then Segwit2x forked (from BTC!) with nForkId 3.  The BCH funding tx would
>> be valid on Segwit2x.  This is more of a fundamental problem than a bug -
>> to avoid it you'd have to get into stuff like making each fork reference
>> its parent-fork's first block or something, someone has written about
>> this...
>>
>
> Sorry, I was careless with the use of `>=` there. You are correct, forks
> form a tree. For this proposal, every leaf must be assigned a unique
> `nForkId`. The relationship between `nForkId` is irrelevant (e.g. which
> number is bigger), as long as they are unique. Transactions are only valid
> IFF `nForkId` matches exactly the `nForkId` of the software validating it.
> As described above, the transaction doesn't even contain `nForkId`, and the
> node surely is not starting to guess which one it could be.
>
> [1]
> https://twitter.com/khannib/status/930223617744437253
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171115/83057847/attachment.html>

From jl2012 at xbt.hk  Wed Nov 15 18:02:48 2017
From: jl2012 at xbt.hk (Johnson Lau)
Date: Thu, 16 Nov 2017 02:02:48 +0800
Subject: [bitcoin-dev] Making OP_CODESEPARATOR and FindAndDelete in
 non-segwit scripts non-standard
Message-ID: <53A587C3-DAC1-4055-875F-96B61717ACE6@xbt.hk>

In https://github.com/bitcoin/bitcoin/pull/11423 <https://github.com/bitcoin/bitcoin/pull/11423> I propose to make OP_CODESEPARATOR and FindAndDelete in non-segwit scripts non-standard

I think FindAndDelete() is one of the most useless and complicated functions in the script language. It is omitted from segwit (BIP143), but we still need to support it in non-segwit scripts. Actually, FindAndDelete() would only be triggered in some weird edge cases like using out-of-range SIGHASH_SINGLE.

Non-segwit scripts also use a FindAndDelete()-like function to remove OP_CODESEPARATOR from scriptCode. Note that in BIP143, only executed OP_CODESEPARATOR are removed so it doesn?t have the FindAndDelete()-like function. OP_CODESEPARATOR in segwit scripts are useful for Tumblebit so it is not disabled in this proposal

By disabling both, it guarantees that scriptCode serialized inside SignatureHash() must be constant

If we use a softfork to remove FindAndDelete() and OP_CODESEPARATOR from non-segwit scripts, we could completely remove FindAndDelete() from the consensus code later by whitelisting all blocks before the softfork block. The first step is to make them non-standard in the next release.


 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171116/2af44e77/attachment.html>

From mark at friedenbach.org  Wed Nov 15 19:54:17 2017
From: mark at friedenbach.org (Mark Friedenbach)
Date: Wed, 15 Nov 2017 09:54:17 -1000
Subject: [bitcoin-dev] Making OP_CODESEPARATOR and FindAndDelete in
	non-segwit scripts non-standard
In-Reply-To: <53A587C3-DAC1-4055-875F-96B61717ACE6@xbt.hk>
References: <53A587C3-DAC1-4055-875F-96B61717ACE6@xbt.hk>
Message-ID: <081A517B-B730-43AB-9D4E-4F696EFD91A3@friedenbach.org>

As good of an idea as it may or may not be to remove this feature from the code base, actually doing so would be crossing a boundary that we have not previously been willing to do except under extraordinary duress. The nature of bitcoin is such that we do not know and cannot know what transactions exist out there pre-signed and making use of these features.

It may be a good idea to make these features non standard to further discourage their use, but I object to doing so with the justification of eventually disabling them for all transactions. Taking that step has the potential of destroying value and is something that we have only done in the past either because we didn?t understand forks and best practices very well, or because the features (now disabled) were fundamentally insecure and resulted in other people?s coins being vulnerable. This latter concern does not apply here as far as I?m aware.

> On Nov 15, 2017, at 8:02 AM, Johnson Lau via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
> 
> In https://github.com/bitcoin/bitcoin/pull/11423 I propose to make OP_CODESEPARATOR and FindAndDelete in non-segwit scripts non-standard
> 
> I think FindAndDelete() is one of the most useless and complicated functions in the script language. It is omitted from segwit (BIP143), but we still need to support it in non-segwit scripts. Actually, FindAndDelete() would only be triggered in some weird edge cases like using out-of-range SIGHASH_SINGLE.
> 
> Non-segwit scripts also use a FindAndDelete()-like function to remove OP_CODESEPARATOR from scriptCode. Note that in BIP143, only executed OP_CODESEPARATOR are removed so it doesn?t have the FindAndDelete()-like function. OP_CODESEPARATOR in segwit scripts are useful for Tumblebit so it is not disabled in this proposal
> 
> By disabling both, it guarantees that scriptCode serialized inside SignatureHash() must be constant
> 
> If we use a softfork to remove FindAndDelete() and OP_CODESEPARATOR from non-segwit scripts, we could completely remove FindAndDelete() from the consensus code later by whitelisting all blocks before the softfork block. The first step is to make them non-standard in the next release.
> 
> 
>  
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171115/04190c4f/attachment.html>

From sjors at sprovoost.nl  Thu Nov 16 09:27:18 2017
From: sjors at sprovoost.nl (Sjors Provoost)
Date: Thu, 16 Nov 2017 10:27:18 +0100
Subject: [bitcoin-dev] Making OP_CODESEPARATOR and FindAndDelete in
 non-segwit scripts non-standard
In-Reply-To: <081A517B-B730-43AB-9D4E-4F696EFD91A3@friedenbach.org>
References: <53A587C3-DAC1-4055-875F-96B61717ACE6@xbt.hk>
	<081A517B-B730-43AB-9D4E-4F696EFD91A3@friedenbach.org>
Message-ID: <3A5BFD5E-A92D-4BDA-985A-09D86BBA848F@sprovoost.nl>

Can you clarify what you mean by "whitelisting all blocks before the softfork block"?

The most conservative approach could be to leave the code in place until the very last non-segwit P2SH UTXO from before the soft fork block has been spent. But this would never happen if even a single private key is lost.

After making these transactions non-standard and removing the code, transactions containing these OP-codes could be considered valid (perhaps still checking the signature, etc). Some miners would still run the code and mine those transactions, but others wouldn't verify them. This is strictly less bad than losing those funds forever, but doesn't seem acceptable either.

Is there a variant of the above scenario where a miner puts up some very large deposit (e.g. 10x the size of the UTXO) if they mine such a legacy transaction, and can lose that if someone else runs the code and finds the transaction invalid?

Sjors

> Op 15 nov. 2017, om 20:54 heeft Mark Friedenbach via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> het volgende geschreven:
> 
> As good of an idea as it may or may not be to remove this feature from the code base, actually doing so would be crossing a boundary that we have not previously been willing to do except under extraordinary duress. The nature of bitcoin is such that we do not know and cannot know what transactions exist out there pre-signed and making use of these features.
> 
> It may be a good idea to make these features non standard to further discourage their use, but I object to doing so with the justification of eventually disabling them for all transactions. Taking that step has the potential of destroying value and is something that we have only done in the past either because we didn?t understand forks and best practices very well, or because the features (now disabled) were fundamentally insecure and resulted in other people?s coins being vulnerable. This latter concern does not apply here as far as I?m aware.
> 
> On Nov 15, 2017, at 8:02 AM, Johnson Lau via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:
> 
>> In https://github.com/bitcoin/bitcoin/pull/11423 <https://github.com/bitcoin/bitcoin/pull/11423> I propose to make OP_CODESEPARATOR and FindAndDelete in non-segwit scripts non-standard
>> 
>> I think FindAndDelete() is one of the most useless and complicated functions in the script language. It is omitted from segwit (BIP143), but we still need to support it in non-segwit scripts. Actually, FindAndDelete() would only be triggered in some weird edge cases like using out-of-range SIGHASH_SINGLE.
>> 
>> Non-segwit scripts also use a FindAndDelete()-like function to remove OP_CODESEPARATOR from scriptCode. Note that in BIP143, only executed OP_CODESEPARATOR are removed so it doesn?t have the FindAndDelete()-like function. OP_CODESEPARATOR in segwit scripts are useful for Tumblebit so it is not disabled in this proposal
>> 
>> By disabling both, it guarantees that scriptCode serialized inside SignatureHash() must be constant
>> 
>> If we use a softfork to remove FindAndDelete() and OP_CODESEPARATOR from non-segwit scripts, we could completely remove FindAndDelete() from the consensus code later by whitelisting all blocks before the softfork block. The first step is to make them non-standard in the next release.
>> 
>> 
>> 
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171116/c69edb2d/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: Message signed with OpenPGP
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171116/c69edb2d/attachment.sig>

From stikkan83 at protonmail.com  Wed Nov 15 19:59:45 2017
From: stikkan83 at protonmail.com (Stikkan83)
Date: Wed, 15 Nov 2017 14:59:45 -0500
Subject: [bitcoin-dev] POW - Miner's choice?
Message-ID: <9F5Nn3Qq7o0CLHPD22ictAEX5uwWGpk8uZhdwfP0BaTCKULM5jYOSL_tLU7JVIF1nax0CMpi1UGerVH50Cjf-_A-4n8rz6GoZlGsyc__lyg=@protonmail.com>

hello list,

would it be possible to have two available POW mining algorithms (like
for example "Double-SHA256" and "Cuckoo Cycle"), and let the miner
choose which one to use for POW?

the two algorithms would have independent difficulties, and after each
difficulty period, the difficulty would be adjusted to aim for 50/50
distribution of the two algorithms (in addition to aim for 10 minutes
block time).

this could be done by only adjusting up difficulty for the algorithm
used in most blocks last period, or only adjusting down difficulty for
the algorithm with the least number of blocks last period (depending
on whether the combined difficulty was to be adjusted up or down).  or
maybe a more sophisticated variant, where both difficulties are
adjusted, based on the relative difference of the number of blocks
where they are used.

the main motivation for this would be:

- increase mining distribution
- continue mining even when one type of miners suddenly jump to mine a
  more profitable altcoin.

not sure if this has been proposed (and rejected) before, but I can't
remember seeing it discussed.

would probably require a hard fork.

SA
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171115/e66394e8/attachment.html>

From m.bevand at gmail.com  Thu Nov 16 16:56:46 2017
From: m.bevand at gmail.com (Marc Bevand)
Date: Thu, 16 Nov 2017 10:56:46 -0600
Subject: [bitcoin-dev] Protocol-Level Pruning
Message-ID: <CADH-5r0m0zUP545hN=Or3v8ujixeKZpLqqja0M+5wuZZOWhO4A@mail.gmail.com>

It occurred to me that we could push the classic concept of pruning even
further: we could significantly shrink the blockchain as well as reduce the
amount of network traffic during initial block download by doing something
I would call protocol-level pruning. This would, as of today, reduce the
size of the blockchain by a factor of 50, hence enabling massive on-chain
scaling.

The idea behind PLP is to serialize the UTXO set in a standardized way, and
publish a hash of it in the block header so that the blockchain commits to
it. Since hashing and verifying it is a moderately intensive operation,
perhaps the UTXO set hash should be published only once every 576 blocks (4
days).

When a new Bitcoin node joins the network, it would download the block
headers only (not the block data), it would identify the most recent block
containing the UTXO set hash, and download the UTXO set from peers. From
that point on, it downloads and verifies all blocks as normal.

Every 576 blocks, nodes serialize and verify that their UTXO set hash
matches the one published in the blockchain. Doing so becomes a new part of
consensus rules. The last 576 blocks could then be permanently discarded as
they are no longer useful.

Today the serialized UTXO set is about 3GB and the blockchain is about
150GB. Therefore PLP would cut down the amount of data stored by full nodes
by a factor of ~50 as they would have to store only the UTXO set plus at
most 576 blocks.

One trivial optimization is possible: to avoid hashing the entire UTXO set
every 576 blocks (which would take multiple seconds even on a fast
machine), the UTXO set serialization could be a sparse merkle tree
<https://eprint.iacr.org/2016/683.pdf> which would allow on-the fly
recomputation of the hash as new blocks are mined: when a UTXO is added to
(or removed from) the tree, only a small number of hash operations are
needed to recalculate the UTXO set merkle tree root hash.

Maybe we don't even need sparse merkle trees, but a regular merkle tree
would suffice: the tree leaves would be small groups of UTXOs (some bits in
the ID/hash of a UTXO would determine which leaf it belongs to.)

Unlike classic pruning mode, *ALL* full nodes on the network could switch
to PLP. There is no need for any node to archive the entire blockchain any
more.

I can think of one downside of PLP: nodes would no longer be able to handle
reorgs that go further back than the last UTXO set hash published on the
chain (since previous blocks have been discarded). So, perhaps keeping
around the last N*576 blocks (N=10?) would be a sufficient workaround.

Thoughts?

-Marc
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171116/aa078a42/attachment-0001.html>

From kanzure at gmail.com  Thu Nov 16 17:14:47 2017
From: kanzure at gmail.com (Bryan Bishop)
Date: Thu, 16 Nov 2017 11:14:47 -0600
Subject: [bitcoin-dev] Protocol-Level Pruning
In-Reply-To: <CADH-5r0m0zUP545hN=Or3v8ujixeKZpLqqja0M+5wuZZOWhO4A@mail.gmail.com>
References: <CADH-5r0m0zUP545hN=Or3v8ujixeKZpLqqja0M+5wuZZOWhO4A@mail.gmail.com>
Message-ID: <CABaSBaw_1WfCEiBXtVxPgJ=UMWji=MwxkVTeKX-BbuVb9N_h5g@mail.gmail.com>

It's not clear to me if you are have looked at the previous UTXO set
commitment proposals.

some utxo set commitment bookmarks (a little old)
http://diyhpl.us/~bryan/irc/bitcoin/utxo-commitments-or-fraud-proofs.stdout.txt

TXO bitfields
http://diyhpl.us/wiki/transcripts/sf-bitcoin-meetup/2017-07-08-bram-cohen-merkle-sets/

delayed TXO commitments
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-May/012715.html

TXO commitments do not need a soft-fork to be useful
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-February/013591.html

rolling UTXO set hashes
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-May/014337.html

lotta other resources available, including source code proposals..

- Bryan
http://heybryan.org/
1 512 203 0507
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171116/a4eb94c8/attachment.html>

From m.bevand at gmail.com  Thu Nov 16 17:19:13 2017
From: m.bevand at gmail.com (Marc Bevand)
Date: Thu, 16 Nov 2017 11:19:13 -0600
Subject: [bitcoin-dev] Protocol-Level Pruning
In-Reply-To: <CABaSBaw_1WfCEiBXtVxPgJ=UMWji=MwxkVTeKX-BbuVb9N_h5g@mail.gmail.com>
References: <CADH-5r0m0zUP545hN=Or3v8ujixeKZpLqqja0M+5wuZZOWhO4A@mail.gmail.com>
	<CABaSBaw_1WfCEiBXtVxPgJ=UMWji=MwxkVTeKX-BbuVb9N_h5g@mail.gmail.com>
Message-ID: <CADH-5r0D0Xhuy0TF=avA9z6cEbfa+jAhJ=cN3HvERn3GiqF3rA@mail.gmail.com>

Ah, thanks, I suspected the idea was too simple and must have been
discussed before, but somehow I missed these proposals. I've got some
reading to do.

-Marc

On Thu, Nov 16, 2017 at 11:14 AM, Bryan Bishop <kanzure at gmail.com> wrote:

> It's not clear to me if you are have looked at the previous UTXO set
> commitment proposals.
>
> some utxo set commitment bookmarks (a little old)
> http://diyhpl.us/~bryan/irc/bitcoin/utxo-commitments-or-
> fraud-proofs.stdout.txt
>
> TXO bitfields
> http://diyhpl.us/wiki/transcripts/sf-bitcoin-meetup/
> 2017-07-08-bram-cohen-merkle-sets/
>
> delayed TXO commitments
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/
> 2016-May/012715.html
>
> TXO commitments do not need a soft-fork to be useful
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/
> 2017-February/013591.html
>
> rolling UTXO set hashes
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/
> 2017-May/014337.html
>
> lotta other resources available, including source code proposals..
>
> - Bryan
> http://heybryan.org/
> 1 512 203 0507 <(512)%20203-0507>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171116/c700c912/attachment.html>

From jb55 at jb55.com  Fri Nov 17 19:07:04 2017
From: jb55 at jb55.com (William Casarin)
Date: Fri, 17 Nov 2017 11:07:04 -0800
Subject: [bitcoin-dev] Protocol-Level Pruning
In-Reply-To: <CABaSBaw_1WfCEiBXtVxPgJ=UMWji=MwxkVTeKX-BbuVb9N_h5g@mail.gmail.com>
References: <CADH-5r0m0zUP545hN=Or3v8ujixeKZpLqqja0M+5wuZZOWhO4A@mail.gmail.com>
	<CABaSBaw_1WfCEiBXtVxPgJ=UMWji=MwxkVTeKX-BbuVb9N_h5g@mail.gmail.com>
Message-ID: <87k1yobu7b.fsf@jb55.com>

Bryan Bishop via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>
writes:

> It's not clear to me if you are have looked at the previous UTXO set
> commitment proposals.
>
> some utxo set commitment bookmarks (a little old)
> http://diyhpl.us/~bryan/irc/bitcoin/utxo-commitments-or-fraud-proofs.stdout.txt
>
> TXO bitfields
> http://diyhpl.us/wiki/transcripts/sf-bitcoin-meetup/2017-07-08-bram-cohen-merkle-sets/
>
> delayed TXO commitments
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-May/012715.html
>
> TXO commitments do not need a soft-fork to be useful
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-February/013591.html
>
> rolling UTXO set hashes
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-May/014337.html
>
> lotta other resources available, including source code proposals..

Thanks!

Has anyone categoried list discussions by topic like this? It seems a
lot of this stuff is scattered between mailing lists, irc conversations,
etc and can be hard to know whats floating out there.

-- 
https://jb55.com

From praveen.baratam at gmail.com  Mon Nov 20 17:24:33 2017
From: praveen.baratam at gmail.com (Praveen Baratam)
Date: Mon, 20 Nov 2017 22:54:33 +0530
Subject: [bitcoin-dev] Why SegWit Anyway?
Message-ID: <CAAQs3wuDPktHc6kiZXqTaatOheX4KP=TRgje0_-ED5h8iNs-MA@mail.gmail.com>

Bitcoin Noob here. Please forgive my ignorance.

>From what I understand, in SegWit, the transaction needs to be serialized
into a data structure that is different from the current one where
signatures are separated from the rest of the transaction data.

Why change the format at all? Why cant we just compute the Transaction ID
the same way the hash for signing the transaction is computed?

-- 
Dr. Praveen Baratam

about.me <http://about.me/praveen.baratam>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171120/2fc6d1a3/attachment.html>

From arielluaces at gmail.com  Mon Nov 20 17:39:11 2017
From: arielluaces at gmail.com (Ariel Lorenzo-Luaces)
Date: Mon, 20 Nov 2017 09:39:11 -0800
Subject: [bitcoin-dev] Why SegWit Anyway?
In-Reply-To: <CAAQs3wuDPktHc6kiZXqTaatOheX4KP=TRgje0_-ED5h8iNs-MA@mail.gmail.com>
References: <CAAQs3wuDPktHc6kiZXqTaatOheX4KP=TRgje0_-ED5h8iNs-MA@mail.gmail.com>
Message-ID: <3cf690cf-5918-4779-b4f0-a05f7ca5cc93@gmail.com>

Hello Praveen

You're absolutely right. We could refer to transactions by the hash that gets signed.

However the way that bitcoin transactions reference each other has already been established to be hash of transaction+signature. Changing this would require a hard fork.

Segwit is the realization that this could be done as a soft fork if we simply extract the signature outside of what the old client considers a transaction. And into a new transaction format where we do exactly what you're describing.

In my opinion the way it originally worked with the sig inside the transaction was simply an oversight by satoshi. No different than a bug.

Cheers
Ariel Lorenzo-Luaces


On Nov 20, 2017, 9:29 AM, at 9:29 AM, Praveen Baratam via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
>Bitcoin Noob here. Please forgive my ignorance.
>
>From what I understand, in SegWit, the transaction needs to be
>serialized
>into a data structure that is different from the current one where
>signatures are separated from the rest of the transaction data.
>
>Why change the format at all? Why cant we just compute the Transaction
>ID
>the same way the hash for signing the transaction is computed?
>
>-- 
>Dr. Praveen Baratam
>
>about.me <http://about.me/praveen.baratam>
>
>
>------------------------------------------------------------------------
>
>_______________________________________________
>bitcoin-dev mailing list
>bitcoin-dev at lists.linuxfoundation.org
>https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171120/292a25d9/attachment.html>

From jl2012 at xbt.hk  Mon Nov 20 17:45:18 2017
From: jl2012 at xbt.hk (Johnson Lau)
Date: Tue, 21 Nov 2017 01:45:18 +0800
Subject: [bitcoin-dev] Why SegWit Anyway?
In-Reply-To: <CAAQs3wuDPktHc6kiZXqTaatOheX4KP=TRgje0_-ED5h8iNs-MA@mail.gmail.com>
References: <CAAQs3wuDPktHc6kiZXqTaatOheX4KP=TRgje0_-ED5h8iNs-MA@mail.gmail.com>
Message-ID: <F392E62C-00CF-4D91-BB6B-706F2A59C63B@xbt.hk>

We can?t ?just compute the Transaction ID the same way the hash for signing the transaction is computed? because with different SIGHASH flags, there are 6 (actually 256) ways to hash a transaction.

Also, changing the definition of TxID is a hardfork change, i.e. everyone are required to upgrade or a chain split will happen.

It is possible to use ?normalised TxID? (BIP140) to fix malleability issue. As a softfork, BIP140 doesn?t change the definition of TxID. Instead, the normalised txid (i.e. txid with scriptSig removed) is used when making signature. Comparing with segwit (BIP141), BIP140 does not have the side-effect of block size increase, and doesn?t provide any incentive to control the size of UTXO set. Also, BIP140 makes the UTXO set permanently bigger, as the database needs to store both txid and normalised txid

> On 21 Nov 2017, at 1:24 AM, Praveen Baratam via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
> 
> Bitcoin Noob here. Please forgive my ignorance.
> 
> From what I understand, in SegWit, the transaction needs to be serialized into a data structure that is different from the current one where signatures are separated from the rest of the transaction data.
> 
> Why change the format at all? Why cant we just compute the Transaction ID the same way the hash for signing the transaction is computed?
> 
> -- 
> Dr. Praveen Baratam
> 
> about.me <http://about.me/praveen.baratam>_______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171121/f53f93f9/attachment.html>

From greg at xiph.org  Mon Nov 20 18:59:34 2017
From: greg at xiph.org (Gregory Maxwell)
Date: Mon, 20 Nov 2017 18:59:34 +0000
Subject: [bitcoin-dev] Why SegWit Anyway?
In-Reply-To: <CAAQs3wuDPktHc6kiZXqTaatOheX4KP=TRgje0_-ED5h8iNs-MA@mail.gmail.com>
References: <CAAQs3wuDPktHc6kiZXqTaatOheX4KP=TRgje0_-ED5h8iNs-MA@mail.gmail.com>
Message-ID: <CAAS2fgSX9XKtwzJ9z5SLJGQHHv+4jUDCKHpcb7V8XEhFuxL=Nw@mail.gmail.com>

On Mon, Nov 20, 2017 at 5:24 PM, Praveen Baratam via bitcoin-dev
<bitcoin-dev at lists.linuxfoundation.org> wrote:
> Bitcoin Noob here. Please forgive my ignorance.
>
> From what I understand, in SegWit, the transaction needs to be serialized
> into a data structure that is different from the current one where
> signatures are separated from the rest of the transaction data.
>
> Why change the format at all? Why cant we just compute the Transaction ID
> the same way the hash for signing the transaction is computed?

That is effectively what segwit does, upto engineering minutia and
compatibility details.

Segwit does not serialize transactions in to a data structure where
signatures are separated from the rest of the transaction data; this
is a misunderstanding.  The "segregated" refers to them being excluded
from the TXID.   The serialization of segwit on the p2p network in
transactions and in blocks encodes the witness field inside the
transactions, immediately prior to the nlocktime field.

From jl2012 at xbt.hk  Mon Nov 20 19:58:57 2017
From: jl2012 at xbt.hk (Johnson Lau)
Date: Tue, 21 Nov 2017 03:58:57 +0800
Subject: [bitcoin-dev] Why SegWit Anyway?
In-Reply-To: <CAAQs3wth=04PxDL6XzjTVYyZBiM1ZYHTK9-qRP8W+DAb53xMGg@mail.gmail.com>
References: <CAAQs3wuDPktHc6kiZXqTaatOheX4KP=TRgje0_-ED5h8iNs-MA@mail.gmail.com>
	<F392E62C-00CF-4D91-BB6B-706F2A59C63B@xbt.hk>
	<CAAQs3wth=04PxDL6XzjTVYyZBiM1ZYHTK9-qRP8W+DAb53xMGg@mail.gmail.com>
Message-ID: <24ADB268-7F46-4451-A53F-23D78CE66274@xbt.hk>

Not really. BIP140 might be easier to implement, but in longterm the UTXO overhead is significant and unnecessary. There are also other benefits of segwit written in BIP141. Some of those are applicable even if you are making a new coin.

> On 21 Nov 2017, at 2:07 AM, Praveen Baratam <praveen.baratam at gmail.com> wrote:
> 
> BIP 140 looks like it solves Tx Malleability with least impact on current practices. It is still a soft fork though.
> 
> Finally, if we were to create an alternative cyptocurrency similar to Bitcoin, a Normalized Tx ID approach would be a better choice if I get it right!
> ?
> 
> On Mon, Nov 20, 2017 at 11:15 PM, Johnson Lau <jl2012 at xbt.hk <mailto:jl2012 at xbt.hk>> wrote:
> We can?t ?just compute the Transaction ID the same way the hash for signing the transaction is computed? because with different SIGHASH flags, there are 6 (actually 256) ways to hash a transaction.
> 
> Also, changing the definition of TxID is a hardfork change, i.e. everyone are required to upgrade or a chain split will happen.
> 
> It is possible to use ?normalised TxID? (BIP140) to fix malleability issue. As a softfork, BIP140 doesn?t change the definition of TxID. Instead, the normalised txid (i.e. txid with scriptSig removed) is used when making signature. Comparing with segwit (BIP141), BIP140 does not have the side-effect of block size increase, and doesn?t provide any incentive to control the size of UTXO set. Also, BIP140 makes the UTXO set permanently bigger, as the database needs to store both txid and normalised txid
> 
>> On 21 Nov 2017, at 1:24 AM, Praveen Baratam via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:
>> 
>> Bitcoin Noob here. Please forgive my ignorance.
>> 
>> From what I understand, in SegWit, the transaction needs to be serialized into a data structure that is different from the current one where signatures are separated from the rest of the transaction data.
>> 
>> Why change the format at all? Why cant we just compute the Transaction ID the same way the hash for signing the transaction is computed?
>> 
>> -- 
>> Dr. Praveen Baratam
>> 
>> about.me <http://about.me/praveen.baratam>_______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>
> 
> 
> 
> 
> -- 
> Dr. Praveen Baratam
> 
> about.me <http://about.me/praveen.baratam>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171121/27d81473/attachment-0001.html>

From dkbryant at gmail.com  Mon Nov 20 18:04:09 2017
From: dkbryant at gmail.com (Dan Bryant)
Date: Mon, 20 Nov 2017 12:04:09 -0600
Subject: [bitcoin-dev] Why SegWit Anyway?
In-Reply-To: <CAAUFj11_Vh2K4MrmuBre5KaX6F16Jg3PYAsj6SSfzoYYRz_WyA@mail.gmail.com>
References: <CAAQs3wuDPktHc6kiZXqTaatOheX4KP=TRgje0_-ED5h8iNs-MA@mail.gmail.com>
	<F392E62C-00CF-4D91-BB6B-706F2A59C63B@xbt.hk>
	<CAAUFj10ZRQrtEzB_2wp-WS8Q-FGcSegpc_Z6kqvqnDLzNn=DrA@mail.gmail.com>
	<CAAUFj11_Vh2K4MrmuBre5KaX6F16Jg3PYAsj6SSfzoYYRz_WyA@mail.gmail.com>
Message-ID: <CAAUFj1091C3xXL+2j1EovE2j_2kDYsjP_O4ZOKBaxmHuKN=1Lg@mail.gmail.com>

Is there any incentive for miners to pick segwit transactions over
non-segwit transaction.  Do they require less, equal, or more compute to
process?

On Nov 20, 2017 11:46 AM, "Johnson Lau via bitcoin-dev" <
bitcoin-dev at lists.linuxfoundation.org> wrote:

We can?t ?just compute the Transaction ID the same way the hash for signing
the transaction is computed? because with different SIGHASH flags, there
are 6 (actually 256) ways to hash a transaction.

Also, changing the definition of TxID is a hardfork change, i.e. everyone
are required to upgrade or a chain split will happen.

It is possible to use ?normalised TxID? (BIP140) to fix malleability issue.
As a softfork, BIP140 doesn?t change the definition of TxID. Instead, the
normalised txid (i.e. txid with scriptSig removed) is used when making
signature. Comparing with segwit (BIP141), BIP140 does not have the
side-effect of block size increase, and doesn?t provide any incentive to
control the size of UTXO set. Also, BIP140 makes the UTXO set permanently
bigger, as the database needs to store both txid and normalised txid

On 21 Nov 2017, at 1:24 AM, Praveen Baratam via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

Bitcoin Noob here. Please forgive my ignorance.

>From what I understand, in SegWit, the transaction needs to be serialized
into a data structure that is different from the current one where
signatures are separated from the rest of the transaction data.

Why change the format at all? Why cant we just compute the Transaction ID
the same way the hash for signing the transaction is computed?

-- 
Dr. Praveen Baratam

about.me <http://about.me/praveen.baratam>
_______________________________________________

bitcoin-dev mailing list
bitcoin-dev at lists.linuxfoundation.org
https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev



_______________________________________________
bitcoin-dev mailing list
bitcoin-dev at lists.linuxfoundation.org
https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171120/7fe1e946/attachment.html>

From praveen.baratam at gmail.com  Mon Nov 20 18:07:40 2017
From: praveen.baratam at gmail.com (Praveen Baratam)
Date: Mon, 20 Nov 2017 23:37:40 +0530
Subject: [bitcoin-dev] Why SegWit Anyway?
In-Reply-To: <F392E62C-00CF-4D91-BB6B-706F2A59C63B@xbt.hk>
References: <CAAQs3wuDPktHc6kiZXqTaatOheX4KP=TRgje0_-ED5h8iNs-MA@mail.gmail.com>
	<F392E62C-00CF-4D91-BB6B-706F2A59C63B@xbt.hk>
Message-ID: <CAAQs3wth=04PxDL6XzjTVYyZBiM1ZYHTK9-qRP8W+DAb53xMGg@mail.gmail.com>

BIP 140 looks like it solves Tx Malleability with least impact on current
practices. It is still a soft fork though.

Finally, if we were to create an alternative cyptocurrency similar to
Bitcoin, a Normalized Tx ID approach would be a better choice if I get it
right!
?

On Mon, Nov 20, 2017 at 11:15 PM, Johnson Lau <jl2012 at xbt.hk> wrote:

> We can?t ?just compute the Transaction ID the same way the hash for
> signing the transaction is computed? because with different SIGHASH flags,
> there are 6 (actually 256) ways to hash a transaction.
>
> Also, changing the definition of TxID is a hardfork change, i.e. everyone
> are required to upgrade or a chain split will happen.
>
> It is possible to use ?normalised TxID? (BIP140) to fix malleability
> issue. As a softfork, BIP140 doesn?t change the definition of TxID.
> Instead, the normalised txid (i.e. txid with scriptSig removed) is used
> when making signature. Comparing with segwit (BIP141), BIP140 does not have
> the side-effect of block size increase, and doesn?t provide any incentive
> to control the size of UTXO set. Also, BIP140 makes the UTXO set
> permanently bigger, as the database needs to store both txid and normalised
> txid
>
> On 21 Nov 2017, at 1:24 AM, Praveen Baratam via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
> Bitcoin Noob here. Please forgive my ignorance.
>
> From what I understand, in SegWit, the transaction needs to be serialized
> into a data structure that is different from the current one where
> signatures are separated from the rest of the transaction data.
>
> Why change the format at all? Why cant we just compute the Transaction ID
> the same way the hash for signing the transaction is computed?
>
> --
> Dr. Praveen Baratam
>
> about.me <http://about.me/praveen.baratam>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
>


-- 
Dr. Praveen Baratam

about.me <http://about.me/praveen.baratam>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171120/35d7fb17/attachment.html>

From shadders.del at gmail.com  Tue Nov 21 13:10:28 2017
From: shadders.del at gmail.com (Steve Shadders)
Date: Tue, 21 Nov 2017 23:10:28 +1000
Subject: [bitcoin-dev] Why SegWit Anyway?
In-Reply-To: <CAAUFj1091C3xXL+2j1EovE2j_2kDYsjP_O4ZOKBaxmHuKN=1Lg@mail.gmail.com>
References: <CAAQs3wuDPktHc6kiZXqTaatOheX4KP=TRgje0_-ED5h8iNs-MA@mail.gmail.com>
	<F392E62C-00CF-4D91-BB6B-706F2A59C63B@xbt.hk>
	<CAAUFj10ZRQrtEzB_2wp-WS8Q-FGcSegpc_Z6kqvqnDLzNn=DrA@mail.gmail.com>
	<CAAUFj11_Vh2K4MrmuBre5KaX6F16Jg3PYAsj6SSfzoYYRz_WyA@mail.gmail.com>
	<CAAUFj1091C3xXL+2j1EovE2j_2kDYsjP_O4ZOKBaxmHuKN=1Lg@mail.gmail.com>
Message-ID: <CAOPxoMtPvKm0t1ih8vw5YmiGUYjR5Y5a8ZLvjaKo06mH+iHjoA@mail.gmail.com>

There is incentive because of artificially distorted block weight rules. It
is favourable for a miner to choose a segwit tx over a non segwit tx as
they can fit more of them into a block and earn more fees.

On Nov 21, 2017 11:06 PM, "Dan Bryant via bitcoin-dev" <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Is there any incentive for miners to pick segwit transactions over
> non-segwit transaction.  Do they require less, equal, or more compute to
> process?
>
> On Nov 20, 2017 11:46 AM, "Johnson Lau via bitcoin-dev" <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
> We can?t ?just compute the Transaction ID the same way the hash for
> signing the transaction is computed? because with different SIGHASH flags,
> there are 6 (actually 256) ways to hash a transaction.
>
> Also, changing the definition of TxID is a hardfork change, i.e. everyone
> are required to upgrade or a chain split will happen.
>
> It is possible to use ?normalised TxID? (BIP140) to fix malleability
> issue. As a softfork, BIP140 doesn?t change the definition of TxID.
> Instead, the normalised txid (i.e. txid with scriptSig removed) is used
> when making signature. Comparing with segwit (BIP141), BIP140 does not have
> the side-effect of block size increase, and doesn?t provide any incentive
> to control the size of UTXO set. Also, BIP140 makes the UTXO set
> permanently bigger, as the database needs to store both txid and normalised
> txid
>
> On 21 Nov 2017, at 1:24 AM, Praveen Baratam via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
> Bitcoin Noob here. Please forgive my ignorance.
>
> From what I understand, in SegWit, the transaction needs to be serialized
> into a data structure that is different from the current one where
> signatures are separated from the rest of the transaction data.
>
> Why change the format at all? Why cant we just compute the Transaction ID
> the same way the hash for signing the transaction is computed?
>
> --
> Dr. Praveen Baratam
>
> about.me <http://about.me/praveen.baratam>
> _______________________________________________
>
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171121/27e2b472/attachment-0001.html>

From adan at stampery.co  Tue Nov 21 13:16:48 2017
From: adan at stampery.co (=?UTF-8?Q?Ad=c3=a1n_S=c3=a1nchez_de_Pedro_Crespo?=)
Date: Tue, 21 Nov 2017 14:16:48 +0100
Subject: [bitcoin-dev] Why SegWit Anyway?
In-Reply-To: <CAAUFj1091C3xXL+2j1EovE2j_2kDYsjP_O4ZOKBaxmHuKN=1Lg@mail.gmail.com>
References: <CAAQs3wuDPktHc6kiZXqTaatOheX4KP=TRgje0_-ED5h8iNs-MA@mail.gmail.com>
	<F392E62C-00CF-4D91-BB6B-706F2A59C63B@xbt.hk>
	<CAAUFj10ZRQrtEzB_2wp-WS8Q-FGcSegpc_Z6kqvqnDLzNn=DrA@mail.gmail.com>
	<CAAUFj11_Vh2K4MrmuBre5KaX6F16Jg3PYAsj6SSfzoYYRz_WyA@mail.gmail.com>
	<CAAUFj1091C3xXL+2j1EovE2j_2kDYsjP_O4ZOKBaxmHuKN=1Lg@mail.gmail.com>
Message-ID: <15502d41-61f2-9a17-a4cf-03cd20a87368@stampery.com>

Yes.

1. SegWit transactions spend less "weight", which is limited for every
block. Base transaction data weights as much as 4x the witness data.

2. SegWit signatures can be cheaper to verify (linear instead of
quadratic). Prior to this, DoS attacks were possible by using forged
transactions including signatures which could take several minutes to
verify.

The immediate result of this is that miners can fit more transactions
into a block and at the same time spend less power building the blocks.

On 20.11.2017 19:04, Dan Bryant via bitcoin-dev wrote:
> Is there any incentive for miners to pick segwit transactions over
> non-segwit transaction.? Do they require less, equal, or more compute to
> process?
> 
> On Nov 20, 2017 11:46 AM, "Johnson Lau via bitcoin-dev"
> <bitcoin-dev at lists.linuxfoundation.org
> <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:
> 
>     We can?t ?just compute the Transaction ID the same way the hash for
>     signing the transaction is computed? because with different SIGHASH
>     flags, there are 6 (actually 256) ways to hash a transaction.
> 
>     Also, changing the definition of TxID is a hardfork change, i.e.
>     everyone are required to upgrade or a chain split will happen.
> 
>     It is possible to use ?normalised TxID? (BIP140) to fix malleability
>     issue. As a softfork, BIP140 doesn?t change the definition of TxID.
>     Instead, the normalised txid (i.e. txid with scriptSig removed) is
>     used when making signature. Comparing with segwit (BIP141), BIP140
>     does not have the side-effect of block size increase, and doesn?t
>     provide any incentive to control the size of UTXO set. Also, BIP140
>     makes the UTXO set permanently bigger, as the database needs to
>     store both txid and normalised txid
> 
>>     On 21 Nov 2017, at 1:24 AM, Praveen Baratam via bitcoin-dev
>>     <bitcoin-dev at lists.linuxfoundation.org
>>     <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:
>>
>>     Bitcoin Noob here. Please forgive my ignorance.
>>
>>     From what I understand, in SegWit, the transaction needs to be
>>     serialized into a data structure that is different from the
>>     current one where signatures are separated from the rest of the
>>     transaction data.
>>
>>     Why change the format at all? Why cant we just compute the
>>     Transaction ID the same way the hash for signing the transaction
>>     is computed?
>>
>>     -- 
>>     Dr. Praveen Baratam
>>
>>     about.me <http://about.me/praveen.baratam>
>>     _______________________________________________
>>
>>     bitcoin-dev mailing list
>>     bitcoin-dev at lists.linuxfoundation.org
>>     <mailto:bitcoin-dev at lists.linuxfoundation.org>
>>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>     <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>
> 
> 
>     _______________________________________________
>     bitcoin-dev mailing list
>     bitcoin-dev at lists.linuxfoundation.org
>     <mailto:bitcoin-dev at lists.linuxfoundation.org>
>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>     <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>
> 
> 
> 
> 
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> 

-- 
Ad?n S?nchez de Pedro Crespo
CTO, Stampery Inc.
San Francisco - Madrid

From sjors at sprovoost.nl  Tue Nov 21 14:03:46 2017
From: sjors at sprovoost.nl (Sjors Provoost)
Date: Tue, 21 Nov 2017 15:03:46 +0100
Subject: [bitcoin-dev] BIP159 - NODE_NETWORK_LIMITED service bits,
	extendability
Message-ID: <BF359C7E-7FEF-43A6-8ED9-05BED8E0EB64@sprovoost.nl>

I came across the proposed Bitcoin Core implementation of BIP159 [0] in this PR [1]. The goal is to allow pruned nodes to "serve a limited number of historical blocks" (as opposed to none at all).

It contains a counter-measure for peer fingerprinting. I'm trying to understand how that impacts extendibility.

> Peers may have different prune depths (depending on the peers configuration,
> disk space, etc.) which can result in a fingerprinting weakness (finding the
> prune depth through getdata requests). NODE_NETWORK_LIMITED
> supporting peers SHOULD avoid leaking the prune depth and therefore
> not serve blocks deeper then the signaled NODE_NETWORK_LIMITED
> thresholds.

This means pruned nodes can only serve the last 288 blocks:

> If signaled, the peer MUST be capable of serving at least the last 288 blocks (~2 day

As the blockchain keeps growing there will be ever more pruned nodes (perhaps offset by new nodes with more storage).  Although a strict improvement over todays situation, it seems a bit wasteful to have a node with 10-100 GB of storage only be able to share the most recent 288 blocks.

It would be nice if a future extension of this BIP allows more flexibility. To limit the ability to fingerprint nodes, we could limit the number of choices to e.g. 288 + 1000 * 2^n. That yields only 8 possibilities at the current chain size. A slightly better formula could take into account typical hard drive size increments, leaving enough space for the OS and other data. Node operators could opt-in to this if they think the increased fingerprint risk outweighs their desire to share archived blocks.

I can also imagine - but not implement :-) - a future scenario where nodes prune a random subset of their chain, meaning that even nodes with little storage can be of help during Initial Blockchain Download (IBD) of other nodes.


How would such extension be signaled for? Would we need a whole new version bit?

Would upgraded nodes need a new message type to communicate the chosen prune depth? Or can that information tag along some existing message?

Jonas Schnelli pointed out on the Github discussion that waiting for BIP150 would be appropriate. Can you explain how this is related? Although I can see why whitelisted peers can be exempted from the anti-fingerprinting measure, I would not want to restrict it to just those.


Some minor suggestions for improving the BIP itself:
* add link to mailinglist discussion(s) in reference section
* explain that 288 is not just the minimum limit for Bitcoin Core, but also the bulk of traffic (as I understand from earlier discussion [2])

Cheers,

Sjors

[0] https://github.com/bitcoin/bips/blob/master/bip-0159.mediawiki
[1] https://github.com/bitcoin/bitcoin/pull/10387
[2] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-May/thread.html#14315
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: Message signed with OpenPGP
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171121/0bd335ba/attachment.sig>

From greg at xiph.org  Tue Nov 21 18:45:33 2017
From: greg at xiph.org (Gregory Maxwell)
Date: Tue, 21 Nov 2017 18:45:33 +0000
Subject: [bitcoin-dev] BIP159 - NODE_NETWORK_LIMITED service bits,
	extendability
In-Reply-To: <BF359C7E-7FEF-43A6-8ED9-05BED8E0EB64@sprovoost.nl>
References: <BF359C7E-7FEF-43A6-8ED9-05BED8E0EB64@sprovoost.nl>
Message-ID: <CAAS2fgRZT6mStLa-PhpDOhccGvQ4jhD2m1PtzTd0_gfvtwBm7A@mail.gmail.com>

With the way pruning works today my expirence is that virtually no one
sets any parameter other than the minimum, though even with that set a
few more blocks can be available.

In the future we would set further pruning identifying bits, with
those set node would (obviously) answer for their blocks.  An earlier
version of this BIP had such a bit defined but it appeared that we
lacked sufficient experience from practice to usefully specify what
height it should mean exactly and the proposals sounded like they
would likely interact poorly with other future proposals, so we
thought it better to delay defining any additional levels for the
time.

Part of your concern is mooted by the logistics of actually fetching
those additional blocks.  At least in the network today we have a
superabundance of nodes that serve anything, to handle them being rare
will require very different approaches than we have now.  We have no
reason to believe that "like the pruning thing but more blocks" is
actually all that useful-- and some reason to expect that its not:
once you go back more than a handful of weeks the probably of fetching
get pretty close to uniform, those fetches are only be newly
initializing nodes that need all the blocks.



On Tue, Nov 21, 2017 at 2:03 PM, Sjors Provoost via bitcoin-dev
<bitcoin-dev at lists.linuxfoundation.org> wrote:
> I came across the proposed Bitcoin Core implementation of BIP159 [0] in this PR [1]. The goal is to allow pruned nodes to "serve a limited number of historical blocks" (as opposed to none at all).
>
> It contains a counter-measure for peer fingerprinting. I'm trying to understand how that impacts extendibility.
>
>> Peers may have different prune depths (depending on the peers configuration,
>> disk space, etc.) which can result in a fingerprinting weakness (finding the
>> prune depth through getdata requests). NODE_NETWORK_LIMITED
>> supporting peers SHOULD avoid leaking the prune depth and therefore
>> not serve blocks deeper then the signaled NODE_NETWORK_LIMITED
>> thresholds.
>
> This means pruned nodes can only serve the last 288 blocks:
>
>> If signaled, the peer MUST be capable of serving at least the last 288 blocks (~2 day
>
> As the blockchain keeps growing there will be ever more pruned nodes (perhaps offset by new nodes with more storage).  Although a strict improvement over todays situation, it seems a bit wasteful to have a node with 10-100 GB of storage only be able to share the most recent 288 blocks.
>
> It would be nice if a future extension of this BIP allows more flexibility. To limit the ability to fingerprint nodes, we could limit the number of choices to e.g. 288 + 1000 * 2^n. That yields only 8 possibilities at the current chain size. A slightly better formula could take into account typical hard drive size increments, leaving enough space for the OS and other data. Node operators could opt-in to this if they think the increased fingerprint risk outweighs their desire to share archived blocks.
>
> I can also imagine - but not implement :-) - a future scenario where nodes prune a random subset of their chain, meaning that even nodes with little storage can be of help during Initial Blockchain Download (IBD) of other nodes.
>
>
> How would such extension be signaled for? Would we need a whole new version bit?
>
> Would upgraded nodes need a new message type to communicate the chosen prune depth? Or can that information tag along some existing message?
>
> Jonas Schnelli pointed out on the Github discussion that waiting for BIP150 would be appropriate. Can you explain how this is related? Although I can see why whitelisted peers can be exempted from the anti-fingerprinting measure, I would not want to restrict it to just those.
>
>
> Some minor suggestions for improving the BIP itself:
> * add link to mailinglist discussion(s) in reference section
> * explain that 288 is not just the minimum limit for Bitcoin Core, but also the bulk of traffic (as I understand from earlier discussion [2])
>
> Cheers,
>
> Sjors
>
> [0] https://github.com/bitcoin/bips/blob/master/bip-0159.mediawiki
> [1] https://github.com/bitcoin/bitcoin/pull/10387
> [2] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-May/thread.html#14315
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>

From dev at jonasschnelli.ch  Tue Nov 21 19:00:21 2017
From: dev at jonasschnelli.ch (Jonas Schnelli)
Date: Tue, 21 Nov 2017 09:00:21 -1000
Subject: [bitcoin-dev] BIP159 - NODE_NETWORK_LIMITED service bits,
 extendability
In-Reply-To: <BF359C7E-7FEF-43A6-8ED9-05BED8E0EB64@sprovoost.nl>
References: <BF359C7E-7FEF-43A6-8ED9-05BED8E0EB64@sprovoost.nl>
Message-ID: <A226065E-A9FE-4BDC-BE4F-1D205D298C0F@jonasschnelli.ch>

Hi Sjors

Thanks for picking this up.

There where some previous discussions about this [1] [2].
Initially, the idea was to have two service bits to signal (up to three) states.
But, since it is not clear what use-cases the bits signalling >288 blocks would fulfil, I have limited BIP159 to a single 288blocks-available signalling.

Therefore, BIP159 aims to improve the block relay state around the tip (24h) which seems to be the most significant request peak (peers out of IBD).
Also, it takes an acceptable transition for pruned node operators into account. Once BIP159 gets active on the network, pruned peer operators may see an increase in CPU and bandwidth usage.

SPV peers may also connect to BIP159 nodes, scan the mempool and wait for unconfirmed transactions (they don?t do this now because pruned nodes don't signal any service).

Future extensions are possible. Maybe a p2p command that could tell more infos about the pruning state would be useful.

BIP159 also recommends to fix the fingerprinting weakness by fix limiting it to 288 blocks, making it impossible for an attacker to fingerprint your peer by scanning how deep the peer can serve blocks. This may be a reduction for possible use cases with todays pruned peers and an idea would be to relax this limit for whitelisted peers (or peers connecting via BIP150 [not implemented], and this is the only connection between BIP150 and BIP159).

However, I think the scope of BIP159 should be kept as it is. More flexibility can be added later when we have gathered more information during BIP159 deployment.
Also, the implementations is an advanced stage [3][4]

?
</jonas>

[1] https://botbot.me/freenode/bitcoin-core-dev/2017-04-27/?msg=84827228&page=3
[2] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-May/thread.html#14314
[3] https://github.com/bitcoin/bitcoin/pull/10387
[4] https://github.com/bitcoin/bitcoin/pull/11740


> Am 21.11.2017 um 04:03 schrieb Sjors Provoost via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>:
> 
> I came across the proposed Bitcoin Core implementation of BIP159 [0] in this PR [1]. The goal is to allow pruned nodes to "serve a limited number of historical blocks" (as opposed to none at all).
> 
> It contains a counter-measure for peer fingerprinting. I'm trying to understand how that impacts extendibility.
> 
>> Peers may have different prune depths (depending on the peers configuration,
>> disk space, etc.) which can result in a fingerprinting weakness (finding the
>> prune depth through getdata requests). NODE_NETWORK_LIMITED
>> supporting peers SHOULD avoid leaking the prune depth and therefore
>> not serve blocks deeper then the signaled NODE_NETWORK_LIMITED
>> thresholds.
> 
> This means pruned nodes can only serve the last 288 blocks:
> 
>> If signaled, the peer MUST be capable of serving at least the last 288 blocks (~2 day
> 
> As the blockchain keeps growing there will be ever more pruned nodes (perhaps offset by new nodes with more storage).  Although a strict improvement over todays situation, it seems a bit wasteful to have a node with 10-100 GB of storage only be able to share the most recent 288 blocks.
> 
> It would be nice if a future extension of this BIP allows more flexibility. To limit the ability to fingerprint nodes, we could limit the number of choices to e.g. 288 + 1000 * 2^n. That yields only 8 possibilities at the current chain size. A slightly better formula could take into account typical hard drive size increments, leaving enough space for the OS and other data. Node operators could opt-in to this if they think the increased fingerprint risk outweighs their desire to share archived blocks.
> 
> I can also imagine - but not implement :-) - a future scenario where nodes prune a random subset of their chain, meaning that even nodes with little storage can be of help during Initial Blockchain Download (IBD) of other nodes.
> 
> 
> How would such extension be signaled for? Would we need a whole new version bit?
> 
> Would upgraded nodes need a new message type to communicate the chosen prune depth? Or can that information tag along some existing message?
> 
> Jonas Schnelli pointed out on the Github discussion that waiting for BIP150 would be appropriate. Can you explain how this is related? Although I can see why whitelisted peers can be exempted from the anti-fingerprinting measure, I would not want to restrict it to just those.
> 
> 
> Some minor suggestions for improving the BIP itself:
> * add link to mailinglist discussion(s) in reference section
> * explain that 288 is not just the minimum limit for Bitcoin Core, but also the bulk of traffic (as I understand from earlier discussion [2])
> 
> Cheers,
> 
> Sjors
> 
> [0] https://github.com/bitcoin/bips/blob/master/bip-0159.mediawiki
> [1] https://github.com/bitcoin/bitcoin/pull/10387
> [2] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-May/thread.html#14315
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: Message signed with OpenPGP
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171121/31852331/attachment-0001.sig>

From vitteaymeric at gmail.com  Fri Nov 24 15:13:04 2017
From: vitteaymeric at gmail.com (Aymeric Vitte)
Date: Fri, 24 Nov 2017 16:13:04 +0100
Subject: [bitcoin-dev] pubkey or not pubkey?
Message-ID: <bd154803-2734-243d-c694-87d70879131c@gmail.com>

I released https://github.com/Ayms/bitcoin-transactions

As you can see the restart of this project (started one year ago) was
motivated by the epic launch of bitcoin gold and many people still
desperately trying to sync, not understanding there was no need to
'transfer' their bitcoins to btg, getting robbed, etc, but there is more
some long term intent

This is somewhere bitcoin-cli outside of bitcoin-qt with a non
synced/outside wallet (where https://github.com/Ayms/bitcoin-wallets can
be used), not only for btg but for any network based on bitcoin

While implementing BIP143 I noticed during the tests/doublechecks with
cli that scriptSig was <signature>< pubkey>

This was not the case one year ago, scriptSig was <signature> since you
can get the <pubkey> from the signature, that's what I did thinking of
some lack of optimization in the bgold client, but this behavior is very
the same for bitcoin core

Then my first transactions did not include the pubkey and I was
immediately banned by my own node (who btw did not realize that it was
banning itself...), I got a reject message stating that OP_EQUALVERIFY
failed

So, the questions are: for basic p2pkh transactions why is pubkey back,
since when and why txs without it are rejected?

At this time where everything is made to reduce the tx's size while the
fees/byte are quite high, this adds 34 useless bytes in each input

-- 
Bitcoin transactions made simple: https://github.com/Ayms/bitcoin-transactions
Zcash wallets made simple: https://github.com/Ayms/zcash-wallets
Bitcoin wallets made simple: https://github.com/Ayms/bitcoin-wallets
Get the torrent dynamic blocklist: http://peersm.com/getblocklist
Check the 10 M passwords list: http://peersm.com/findmyass
Anti-spies and private torrents, dynamic blocklist: http://torrent-live.org
Peersm : http://www.peersm.com
torrent-live: https://github.com/Ayms/torrent-live
node-Tor : https://www.github.com/Ayms/node-Tor
GitHub : https://www.github.com/Ayms


From kanzure at gmail.com  Sat Nov 25 19:21:55 2017
From: kanzure at gmail.com (Bryan Bishop)
Date: Sat, 25 Nov 2017 13:21:55 -0600
Subject: [bitcoin-dev] Fwd: [Lightning-dev] General question on routing
	difficulties
In-Reply-To: <CAO3Pvs-bxAQKcfsXo+-uA9XbFtYZxT8qVM-5pFeYvEGEqk_scw@mail.gmail.com>
References: <CAEbFcLv_Eye-Z9mHCEuRt70mWMFL9a_659cFJ0DwuJjvOYE7yQ@mail.gmail.com>
	<CANVuFb3bL9v2Cs8-jPqFXAZ-=sr2F5d8oXZwaQaxa-nyVB55Kw@mail.gmail.com>
	<CALxbBHWJk+VY8LtJNQ5PVcByXabx5YkxdcH+Vg9o8sCyNgoUBg@mail.gmail.com>
	<CANVuFb1Fm21R48KOunAqRopSLYFqYfMndy9fzjzZVL7U+wXPPA@mail.gmail.com>
	<CALxbBHXQaenE36zgwiWv1ntQHk+Y=f5MqcZ0A06n3REEYaWcnA@mail.gmail.com>
	<CACHbmQ3DdFHj5qFShZ6cO0UBRf8hHMFGUnawfvgSiYZkO+NPmw@mail.gmail.com>
	<49e10ec4-83ef-df0e-ae87-598bbf7e0784@purdue.edu>
	<CAO3Pvs-bxAQKcfsXo+-uA9XbFtYZxT8qVM-5pFeYvEGEqk_scw@mail.gmail.com>
Message-ID: <CABaSBaz9zUb5OD8Gu-FJaY1SBmYM86b_Gjr0kdjqkN0ubF8ukQ@mail.gmail.com>

---------- Forwarded message ----------
From: Olaoluwa Osuntokun <laolu32 at gmail.com>
Date: Sat, Nov 25, 2017 at 1:16 PM
Subject: Re: [Lightning-dev] General question on routing difficulties
To: Pedro Moreno Sanchez <pmorenos at purdue.edu>
Cc: lightning-dev at lists.linuxfoundation.org


(final try as the prior mail hit the size limit, sorry for the spam!)

Hi Pedro,

I came across this paper a few weeks ago, skimmed it lightly, and noted a
few interesting aspects I wanted to dig into later. Your email reminded me
to re-read the paper, so thanks for that! Before reading the paper, I
wasn't aware of the concept of coordinate embedding, nor how that could be
leveraged in order to provide sender+receiver privacy in a payment network
using a distance-vector-like routing system. Very cool technique!


After reading the paper again, my current conclusion is that while the
protocol presents some novel traits in the design a routing system for
payment channel based networks, it lends much better to a
closed-membership, credit network, such as Ripple (which is the focus of
the paper).


In Ripple, there are only a handful of gateways, and clients that seek to
interact with the network must chose their gateways *very* carefully,
otherwise consensus faults can occur, violating safety properties of the
network. It would appear that this gateway model nicely translates well to
the concept of landmarks that the protocol is strongly dependant on.
Ideally, each gateway would be a landmark, and as there are a very small
number of gateways within Ripple (as you must be admitted to be a verified
gateway in the network), then parameter L (the total number of landmarks)
is kept small which minimizes routing overhead, the average path-length,
etc.


When we compare Ripple to LN, we find that the two networks are nearly
polar opposites of each other. LN is an open-membership network that
requires zero initial configuration by central administrators(s). It more
closely resembles *debit* network (a series of tubes of money), as the
funds within channels must be pre-committed in order to establish a link
between two nodes, and cannot be increased without an additional on-chain
control transaction (to add or remove funds). Additionally, AFAIK (I'm no
expert on Ripple of course), there's no concept of fees within the
network. While within LN, the fee structure is a critical component of the
inventive for node operators to lift their coins onto this new layer to
provider payment routing services.  Finally, in LN we rely on time-locks
in order to ensure that all transactions are atomic which adds another set
of constraints. Ripple has no such constraint as transfers are based on
bi-lateral trust.


With that said, the primary difference between this protocol is that
currently we utilize a source-routed system which requires the sender to
know "most" of the path to the destination. I say "most" as currently,
it's possible for the receiver of a payment to use a poor man's rendezvous
system to provide the sender with a set of suffix paths form what one can
consider ad-hoc landmarks. The sender can then concatenate these with
their own paths, and construct the Sphinx routing package which encodes
the full route. This itself only gives sender privacy, and the receiver
doesn't know the identity of the sender, but the sender learns the
identity of the receiver.

We have plans to achieve proper sender/receiver privacy by extending our
Sphinx usage to leverage HORNET, such that the payment descriptor (payment
request containing details of the payment) also includes several paths
from rendezvous nodes (Rodrigo's) to the receiver. The rendezvous route
itself will be nested as a further Anonymous Header (AHDR) which includes
the information necessary to complete the onion circuit from Rodrigo to
the receiver. As onion routing is used, only Rodrigo can decrypt the
payload and finalize the route. With such a structure, the only nodes that
need to advertise their channels are nodes which seek to actively serve as
channel routers. All other nodes (phones, laptops, etc), don't need to
advertise their channels to the greater network, reducing the size of the
visible network, and also the storage and validation overhead. This serves
to extend the "scale ceiling" a bit.


My first question is: is it possible to adapt the protocol to allow each
intermediate node to communicate their time lock and fee references to the
sender? Currently, as the full path isn't known ahead of time, the sender
is unable to properly craft the timelocks to ensure safety+atomicity of
the payment. This would mean they don't know what the total timelock
should be on the first outgoing link. Additionally, as they don't know the
total path and the fee schedule of each intermediate node, then once
again, they don't know how much to send on the first out going link. It
would seem that one could extend the probing phase to allow backwards
communication by each intermediate node back to the sender, such that they
can properly craft a valid HTLC. This would increase the set up costs of
the protocol however, and may also increase routing failures as it's
possible incompatibilities arise at run-time between the preferences of
intermediate nodes. Additionally, routes may fail as an intermediate node
consumes too many funds as their fee, causing the funds to be insufficient
when it reaches the destination. One countermeasure would maybe: the
sender always sends waaay more than necessary, and gives the receiver a
one-time payment identifier, requiring that they route the remainder of
the funds *back* to them.


To solve this issue presently, we extend the header in Sphinx to include a
per-hop payload which allows the sender to precisely dictate the
structure of the route, allows the intermediate nodes to authenticate the
information given to it, and also allow the intermediate node to verify
that their policies have properly been respected. These payloads can also
be utilized by applications to communicate a small-ish amount of data to
construct higher-level protocols on top of the system. Examples include:
cross-chain swaps, chance payment games, higher-level B2B protocols,
flavors of ZKCP's, media streaming, internet access proxying, etc.


>From my point-of-view, when extended to LN, the core component of the
protocol (landmarks), becomes the weakest component. From my reading,
*all* nodes need to be ware of an *identical* set of landmarks (more or
less similar to the desired homogeneity of Gateways), otherwise the
coordinate embedding scheme breaks down. Currently, there's no requirement
that all nodes have a globally consistent view of the network. So then an
important questions arises: who choose the landmarks? A desirable property
of a routing system for LN (IMO) is that is has close to zero required
initial set up by a central administrator. With this protocol, it would
seem that all nodes much ship with a hard coded set of global landmarks
for the path finding to succeed.  This itself pins a hard coordination
requirement amongst implementers to have something like this deployed.
Even ignoring this requirement for a minute, I see several other
downsides:

   * As *all* payments must flow through landmarks (since nodes break up
     their payment into L sub-flows), the landmarks must be very, very
     well capitalized. This would cause strong consolidation of the
     selection of landmarks, as they need extremely large channels in
     order to facilitate transfer within the network.

   * As landmarks must be globally known, this it seems this would
     introduce fragility in the network. If most of the landmarks go down
     (fails stop crashes) due to hardware issues, DoS, exploited bugs,
     etc, then the network's throughput instantly becomes crippled.

   * If all payment flow *must* go through landmarks, and the transfers
     within the network are relatively uni-directional (all payment going
     to Candy Crush Ultra: Lighting Strikes Twice), then their
     channels would become unbalanced very quickly.


The last point there invokes another component of the network: passive
channel rebalancing. With source routing, it's possible for nodes to
passive rebalance their channels, in order to keep the in equilibrium,
such that on average they'll be able to handle a payment flow coming from
any direction. This is possible as with source routing, it's easy for a
node to simply send a payment to himself incoming/outgoing from the pair
of channels they wish to adjust the available flow of. With
distance-vector-like protocols, this doesn't seem possible, as the node
doesn't have any control of the incoming channel that the payment will
arrive on.


Finally, the notion of value privacy within the scheme seems a bit weak.
>From this definition, any protocol that didn't broadcast intents to send
payments to the world would achieve this trait. The base Bitcoin
blockchain doesn't mask the values of transfers (yet), but even if it did
unconditionally maintaining value privacy of channel doesn't seem
compatible with multi-hop payment networks (nodes can simply perform
probing/tagging attacks to ascertain a range of the size of a channel). A
possible mitigation would be for nodes to probabilistically drop incoming
payments, with all nodes sampling from the same distribution. However,
this would dramatically increase routing failures by senders, removing the
"low-latency" trait of payment networks that many find desirable.


Personally, I've very excited to see additional research on the front of
routing within the network! Excellent work by all authors.


In the end, I don't think it'll be a one-size fits all solution, as each
routing protocol delivers with it a set of tradeoffs that should be
weighed depending on target characteristics, and use-cases. There's no
strong requirement that the network as a whole uses a *single* routing
protocol. Instead several distinct protocols can be deployed based on
use-case requirements, as we only need to share a single end-to-end
construct: the HTLC. I could see a future in a few years where we have
several deployed protocols, similar to the wide array of existing routing
protocols deployed on the Internet. What we have currently gets us from
Zero to One. We'll definitely need to experiment with additional
approaches as the size of the network grows, and the true economic flow
patterns emerge after we all deploy to mainnet.


-- Laolu


_______________________________________________
Lightning-dev mailing list
Lightning-dev at lists.linuxfoundation.org
https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev




-- 
- Bryan
http://heybryan.org/
1 512 203 0507
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171125/19c39055/attachment.html>

From cannon at cannon-ciota.info  Sat Nov 25 15:41:44 2017
From: cannon at cannon-ciota.info (CANNON)
Date: Sat, 25 Nov 2017 15:41:44 +0000
Subject: [bitcoin-dev] Why SegWit Anyway?
In-Reply-To: <15502d41-61f2-9a17-a4cf-03cd20a87368@stampery.com>
References: <CAAQs3wuDPktHc6kiZXqTaatOheX4KP=TRgje0_-ED5h8iNs-MA@mail.gmail.com>
	<F392E62C-00CF-4D91-BB6B-706F2A59C63B@xbt.hk>
	<CAAUFj10ZRQrtEzB_2wp-WS8Q-FGcSegpc_Z6kqvqnDLzNn=DrA@mail.gmail.com>
	<CAAUFj11_Vh2K4MrmuBre5KaX6F16Jg3PYAsj6SSfzoYYRz_WyA@mail.gmail.com>
	<CAAUFj1091C3xXL+2j1EovE2j_2kDYsjP_O4ZOKBaxmHuKN=1Lg@mail.gmail.com>
	<15502d41-61f2-9a17-a4cf-03cd20a87368@stampery.com>
Message-ID: <22ba8756-c661-8504-8de3-108626066df0@cannon-ciota.info>

On 11/21/2017 01:16 PM, Ad?n S?nchez de Pedro Crespo via bitcoin-dev wrote:
> 2. SegWit signatures can be cheaper to verify (linear instead of
> quadratic). Prior to this, DoS attacks were possible by using forged
> transactions including signatures which could take several minutes to
> verify.

Where can I find more resources on this described DoS attack?
And how does SegWit prevent this if using SegWit transactions are not enforced?

Thanks

From jjxtra at gmail.com  Mon Nov 27 02:11:27 2017
From: jjxtra at gmail.com (Jeff Johnson)
Date: Sun, 26 Nov 2017 19:11:27 -0700
Subject: [bitcoin-dev] Block compression
Message-ID: <CAHAcUENRbrz6pv_HSe4KDAY-onyMKnMJk8H6yUhqx4LoK0NeEw@mail.gmail.com>

I'm new to this mailing list and apologize if this has been suggested
before. I was directed from the Bitcoin core github to this mailing list
for suggestions.

I'd just like to post a possible solution that increases the amount of data
in a block without actually increasing the size on disk or the size in
memory or the size transmitted over the Internet. Simply applying various
compression algorithms, I was able to achieve about a 50% compression
ratio. Here are my findings on a recent Bitcoin block using max compression
for all methods:

Raw block
998,198 bytes

Gzip
521,212 bytes (52% ratio)
(needs 2MB to decompress).

LZMA
415,308 bytes (41% ratio)
(1MB dictionary, needs 3MB to decompress)

- ZStandard: 469,179 bytes (47% ratio)
(1MB memory to decompress)

- LZ4: 641,063 bytes (64% ratio)
(32-64K to decompress)

The compression time on my modest laptop (2 years old) was "instant". I ran
all from the command line and did not notice any lag as I pressed enter to
do the compression, so easily less than a second. But compression time
doesn't matter, decompression time is what matters as blocks will be
decompressed billions of times more than they will be compressed.
Decompression speed for LZ4 is the fastest of the above methods, at 3.3GB /
second, slightly less than half the speed of memcpy, see char at (
https://github.com/lz4/lz4).

If decompression speed, CPU and memory usage is a concern, LZ4 is a no
brainer. You basically get a 33% larger block size for "free". But
ZStandard, in my opinion, makes the most sense as it offers greater than
50% compression ratio with a very good decompression ratio of 900MB /
second.

If this were implemented in the Bitcoin protocol, there would need to be a
place to specify the compression type in a set of bits somewhere, so that
future compression algorithms could potentially be added.

Miners could do nothing and keep sending blocks as is, and these blocks
would have "no compression" as the type of compression, just as today. Or
they could opt in to compress blocks and choose how many transactions they
want to stuff into the block, keeping the compressed size under the limit.

The bitcoin client code would also need to be able to handle the
appropriate compression bits, and limits of signature data, etc. modified
to deal with the compression.

I understand schnorr signatures are on the roadmap as a 25% compression
gain which is great, I suspect that schnorr signatures would compress even
further when compressed with the above compression methods.

Here is a link to the block that I compressed:
https://mega.nz/#!YPIF2KTa!4FxxLvqzjqIftrkhXwSC2h4G4Dolk8dLteNUolEtq98

Thanks for reading, best wishes to all.

-- Jeff Johnson
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171126/41009558/attachment.html>

From aseaday at hotmail.com  Mon Nov 27 02:32:04 2017
From: aseaday at hotmail.com (lonsdale aseaday)
Date: Mon, 27 Nov 2017 02:32:04 +0000
Subject: [bitcoin-dev] =?gb2312?b?tPC4tDogIEJsb2NrIGNvbXByZXNzaW9u?=
In-Reply-To: <CAHAcUENRbrz6pv_HSe4KDAY-onyMKnMJk8H6yUhqx4LoK0NeEw@mail.gmail.com>
References: <CAHAcUENRbrz6pv_HSe4KDAY-onyMKnMJk8H6yUhqx4LoK0NeEw@mail.gmail.com>
Message-ID: <KL1PR06MB16235AF2C8255CECF98355F1A5250@KL1PR06MB1623.apcprd06.prod.outlook.com>

Hi, Block compression brings some problems witch need to check and you can visit:
https://bitcointalk.org/index.php?topic=88208.0 and https://bitcointalk.org/index.php?topic=204283.0

________________________________________
???: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> ?? Jeff Johnson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>
????: 2017?11?27? 10:11
???: bitcoin-dev at lists.linuxfoundation.org
??: [bitcoin-dev] Block compression

I'm new to this mailing list and apologize if this has been suggested before. I was directed from the Bitcoin core github to this mailing list for suggestions.

I'd just like to post a possible solution that increases the amount of data in a block without actually increasing the size on disk or the size in memory or the size transmitted over the Internet. Simply applying various compression algorithms, I was able to achieve about a 50% compression ratio. Here are my findings on a recent Bitcoin block using max compression for all methods:

Raw block
998,198 bytes

Gzip
521,212 bytes (52% ratio)
(needs 2MB to decompress).

LZMA
415,308 bytes (41% ratio)
(1MB dictionary, needs 3MB to decompress)

- ZStandard: 469,179 bytes (47% ratio)
(1MB memory to decompress)

- LZ4: 641,063 bytes (64% ratio)
(32-64K to decompress)

The compression time on my modest laptop (2 years old) was "instant". I ran all from the command line and did not notice any lag as I pressed enter to do the compression, so easily less than a second. But compression time doesn't matter, decompression time is what matters as blocks will be decompressed billions of times more than they will be compressed. Decompression speed for LZ4 is the fastest of the above methods, at 3.3GB / second, slightly less than half the speed of memcpy, see char at (https://github.com/lz4/lz4).

If decompression speed, CPU and memory usage is a concern, LZ4 is a no brainer. You basically get a 33% larger block size for "free". But ZStandard, in my opinion, makes the most sense as it offers greater than 50% compression ratio with a very good decompression ratio of 900MB / second.

If this were implemented in the Bitcoin protocol, there would need to be a place to specify the compression type in a set of bits somewhere, so that future compression algorithms could potentially be added.

Miners could do nothing and keep sending blocks as is, and these blocks would have "no compression" as the type of compression, just as today. Or they could opt in to compress blocks and choose how many transactions they want to stuff into the block, keeping the compressed size under the limit.

The bitcoin client code would also need to be able to handle the appropriate compression bits, and limits of signature data, etc. modified to deal with the compression.

I understand schnorr signatures are on the roadmap as a 25% compression gain which is great, I suspect that schnorr signatures would compress even further when compressed with the above compression methods.

Here is a link to the block that I compressed: https://mega.nz/#!YPIF2KTa!4FxxLvqzjqIftrkhXwSC2h4G4Dolk8dLteNUolEtq98

Thanks for reading, best wishes to all.

-- Jeff Johnson

From marcopon at gmail.com  Mon Nov 27 12:08:05 2017
From: marcopon at gmail.com (Marco Pontello)
Date: Mon, 27 Nov 2017 13:08:05 +0100
Subject: [bitcoin-dev] Block compression
In-Reply-To: <CAHAcUENRbrz6pv_HSe4KDAY-onyMKnMJk8H6yUhqx4LoK0NeEw@mail.gmail.com>
References: <CAHAcUENRbrz6pv_HSe4KDAY-onyMKnMJk8H6yUhqx4LoK0NeEw@mail.gmail.com>
Message-ID: <CAE0pACLYZihmVU6GMpONmcOKfAVa-DojuQsAXAiOpcN9CamcHA@mail.gmail.com>

Hi Jeff!


On Mon, Nov 27, 2017 at 3:11 AM, Jeff Johnson via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:


> Raw block
> 998,198 bytes
>
> Gzip
> 521,212 bytes (52% ratio)
> (needs 2MB to decompress).
>

I don't know how you got that raw block, but it seems a bit odd.
If you look at it in an hex editor, you'll notice that every odd byte is 0,
and that explain the unusual high compression ratio.

Bye!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171127/4d19aa95/attachment.html>

From lf-lists at mattcorallo.com  Mon Nov 27 16:33:07 2017
From: lf-lists at mattcorallo.com (Matt Corallo)
Date: Mon, 27 Nov 2017 11:33:07 -0500
Subject: [bitcoin-dev] Making OP_CODESEPARATOR and FindAndDelete in
 non-segwit scripts non-standard
In-Reply-To: <081A517B-B730-43AB-9D4E-4F696EFD91A3@friedenbach.org>
References: <53A587C3-DAC1-4055-875F-96B61717ACE6@xbt.hk>
	<081A517B-B730-43AB-9D4E-4F696EFD91A3@friedenbach.org>
Message-ID: <56ca1248-6427-46f7-1645-84349cc8facc@mattcorallo.com>

I strongly disagree here - we don't only soft-fork out transactions that
are "fundamentally insecure", that would be significantly too
restrictive. We have generally been willing to soft-fork out things
which clearly fall outside of best-practices, especially rather
"useless" fields in the protocol eg soft-forking behavior into OP_NOPs,
soft-forking behavior into nSequence, etc.

As a part of setting clear best-practices, making things non-standard is
the obvious step, though there has been active discussion of
soft-forking out FindAndDelete and OP_CODESEPARATOR for years now. I
obviously do not claim that we should be proposing a soft-fork to
blacklist FindAndDelete and OP_CODESEPARATOR usage any time soon, and
assume that it would take at least a year or three from when it was made
non-standard to when a soft-fork to finally remove them was proposed.
This should be more than sufficient time for folks using such weird (and
largely useless) parts of the protocol to object, which should be
sufficient to reconsider such a soft-fork.

Independently, making them non-standard is a good change on its own, and
if nothing else should better inform discussion about the possibility of
anyone using these things.

Matt

On 11/15/17 14:54, Mark Friedenbach via bitcoin-dev wrote:
> As good of an idea as it may or may not be to remove this feature from
> the code base, actually doing so?would be crossing a boundary that we
> have not previously been willing to do except under extraordinary
> duress. The nature of bitcoin is such that we do not know and cannot
> know what transactions exist out there pre-signed and making use of
> these features.
> 
> It may be a good idea to make these features non standard to further
> discourage their use, but I object to doing so with the justification of
> eventually disabling them for all transactions. Taking that step has the
> potential of destroying value and is something that we have only done in
> the past either because we didn?t understand forks and best practices
> very well, or because the features (now disabled) were fundamentally
> insecure and resulted in other people?s coins being vulnerable. This
> latter concern does not apply here as far as I?m aware.
> 
> On Nov 15, 2017, at 8:02 AM, Johnson Lau via bitcoin-dev
> <bitcoin-dev at lists.linuxfoundation.org
> <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:
> 
>> In?https://github.com/bitcoin/bitcoin/pull/11423?I propose to
>> make?OP_CODESEPARATOR and FindAndDelete in non-segwit scripts non-standard
>>
>> I think FindAndDelete() is one of the most useless and complicated
>> functions in the script language. It is omitted from segwit (BIP143),
>> but we still need to support it in non-segwit scripts. Actually,
>> FindAndDelete() would only be triggered in some weird edge cases like
>> using out-of-range SIGHASH_SINGLE.
>>
>> Non-segwit scripts also use a FindAndDelete()-like function to remove
>> OP_CODESEPARATOR from scriptCode. Note that in BIP143, only executed
>> OP_CODESEPARATOR are removed so it doesn?t have the
>> FindAndDelete()-like function. OP_CODESEPARATOR in segwit scripts are
>> useful for Tumblebit so it is not disabled in this proposal
>>
>> By disabling both, it guarantees that scriptCode serialized inside
>> SignatureHash() must be constant
>>
>> If we use a softfork to remove FindAndDelete() and OP_CODESEPARATOR
>> from non-segwit scripts, we could completely remove FindAndDelete()
>> from the consensus code later by whitelisting all blocks before the
>> softfork block. The first step is to make them non-standard in the
>> next release.
>>
>>
>> ?
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> <mailto:bitcoin-dev at lists.linuxfoundation.org>
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> 
> 
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> 

From dev at jonasschnelli.ch  Mon Nov 27 20:49:07 2017
From: dev at jonasschnelli.ch (Jonas Schnelli)
Date: Mon, 27 Nov 2017 10:49:07 -1000
Subject: [bitcoin-dev] Block compression
In-Reply-To: <CAHAcUENRbrz6pv_HSe4KDAY-onyMKnMJk8H6yUhqx4LoK0NeEw@mail.gmail.com>
References: <CAHAcUENRbrz6pv_HSe4KDAY-onyMKnMJk8H6yUhqx4LoK0NeEw@mail.gmail.com>
Message-ID: <A30B6CDA-21D7-4AA2-8BBB-9D2E9458B9F0@jonasschnelli.ch>

Hi Jeff

There where previous discussions about similar approaches [1] [2].

I?m not sure if compression should be built into the protocol.
My humble understanding of it, is, that it should be built into different layers.

If bandwidth is a concern, then on the fly gzip compression like apaches mod_deflate could be something. But I expect fast propagation is often more important then a ~30% bandwidth reduction.
Bandwidth may be a concern for historical blocks transmission. If you continue the proposal, I think you should focus on historical blocks.

If disk space is a concern, then the database layer should handle the compression.

Thanks
?
</jonas>


[1] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-November/011692.html <https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-November/011692.html>
[2] https://github.com/bitcoin/bitcoin/pull/6973 <https://github.com/bitcoin/bitcoin/pull/6973>



> Am 26.11.2017 um 16:11 schrieb Jeff Johnson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>:
> 
> I'm new to this mailing list and apologize if this has been suggested before. I was directed from the Bitcoin core github to this mailing list for suggestions.
> 
> I'd just like to post a possible solution that increases the amount of data in a block without actually increasing the size on disk or the size in memory or the size transmitted over the Internet. Simply applying various compression algorithms, I was able to achieve about a 50% compression ratio. Here are my findings on a recent Bitcoin block using max compression for all methods:
> 
> Raw block
> 998,198 bytes
> 
> Gzip
> 521,212 bytes (52% ratio)
> (needs 2MB to decompress).
> 
> LZMA
> 415,308 bytes (41% ratio)
> (1MB dictionary, needs 3MB to decompress)
> 
> - ZStandard: 469,179 bytes (47% ratio)
> (1MB memory to decompress)
> 
> - LZ4: 641,063 bytes (64% ratio)
> (32-64K to decompress)
> 
> The compression time on my modest laptop (2 years old) was "instant". I ran all from the command line and did not notice any lag as I pressed enter to do the compression, so easily less than a second. But compression time doesn't matter, decompression time is what matters as blocks will be decompressed billions of times more than they will be compressed. Decompression speed for LZ4 is the fastest of the above methods, at 3.3GB / second, slightly less than half the speed of memcpy, see char at (https://github.com/lz4/lz4 <https://github.com/lz4/lz4>).
> 
> If decompression speed, CPU and memory usage is a concern, LZ4 is a no brainer. You basically get a 33% larger block size for "free". But ZStandard, in my opinion, makes the most sense as it offers greater than 50% compression ratio with a very good decompression ratio of 900MB / second.
> 
> If this were implemented in the Bitcoin protocol, there would need to be a place to specify the compression type in a set of bits somewhere, so that future compression algorithms could potentially be added.
> 
> Miners could do nothing and keep sending blocks as is, and these blocks would have "no compression" as the type of compression, just as today. Or they could opt in to compress blocks and choose how many transactions they want to stuff into the block, keeping the compressed size under the limit.
> 
> The bitcoin client code would also need to be able to handle the appropriate compression bits, and limits of signature data, etc. modified to deal with the compression.
> 
> I understand schnorr signatures are on the roadmap as a 25% compression gain which is great, I suspect that schnorr signatures would compress even further when compressed with the above compression methods.
> 
> Here is a link to the block that I compressed: https://mega.nz/#!YPIF2KTa!4FxxLvqzjqIftrkhXwSC2h4G4Dolk8dLteNUolEtq98 <https://mega.nz/#!YPIF2KTa!4FxxLvqzjqIftrkhXwSC2h4G4Dolk8dLteNUolEtq98>
> 
> Thanks for reading, best wishes to all.
> 
> -- Jeff Johnson
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171127/59a99830/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: Message signed with OpenPGP
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171127/59a99830/attachment.sig>

From mark at friedenbach.org  Mon Nov 27 21:06:35 2017
From: mark at friedenbach.org (Mark Friedenbach)
Date: Mon, 27 Nov 2017 13:06:35 -0800
Subject: [bitcoin-dev] Making OP_CODESEPARATOR and FindAndDelete in
 non-segwit scripts non-standard
In-Reply-To: <56ca1248-6427-46f7-1645-84349cc8facc@mattcorallo.com>
References: <53A587C3-DAC1-4055-875F-96B61717ACE6@xbt.hk>
	<081A517B-B730-43AB-9D4E-4F696EFD91A3@friedenbach.org>
	<56ca1248-6427-46f7-1645-84349cc8facc@mattcorallo.com>
Message-ID: <44B74F02-D3D6-47B9-976E-A72042E5C84B@friedenbach.org>

It is relevant to note that BIP 117 makes an insecure form of CODESEPARATOR delegation possible, which could be made secure if some sort of CHECKSIGFROMSTACK opcode is added at a later point in time. It is not IMHO a very elegant way to achieve delegation, however, so I hope that one way or another this could be resolved quickly so it doesn?t hold up either one of those valuable additions.

I have no objections to making them nonstandard, or even to make them invalid if someone with a better grasp of history can attest that CODESEPARATOR was known to be entirely useless before the introduction of P2SH?not the same as saying it was useless, but that it was widely known to not accomplish what a early-days script author might think it was doing?and the UTXO set contains no scriptPubKeys making use of the opcode, even from the early days. Although a small handful could be special cased, if they exist.

> On Nov 27, 2017, at 8:33 AM, Matt Corallo <lf-lists at mattcorallo.com> wrote:
> 
> I strongly disagree here - we don't only soft-fork out transactions that
> are "fundamentally insecure", that would be significantly too
> restrictive. We have generally been willing to soft-fork out things
> which clearly fall outside of best-practices, especially rather
> "useless" fields in the protocol eg soft-forking behavior into OP_NOPs,
> soft-forking behavior into nSequence, etc.
> 
> As a part of setting clear best-practices, making things non-standard is
> the obvious step, though there has been active discussion of
> soft-forking out FindAndDelete and OP_CODESEPARATOR for years now. I
> obviously do not claim that we should be proposing a soft-fork to
> blacklist FindAndDelete and OP_CODESEPARATOR usage any time soon, and
> assume that it would take at least a year or three from when it was made
> non-standard to when a soft-fork to finally remove them was proposed.
> This should be more than sufficient time for folks using such weird (and
> largely useless) parts of the protocol to object, which should be
> sufficient to reconsider such a soft-fork.
> 
> Independently, making them non-standard is a good change on its own, and
> if nothing else should better inform discussion about the possibility of
> anyone using these things.
> 
> Matt
> 
> On 11/15/17 14:54, Mark Friedenbach via bitcoin-dev wrote:
>> As good of an idea as it may or may not be to remove this feature from
>> the code base, actually doing so would be crossing a boundary that we
>> have not previously been willing to do except under extraordinary
>> duress. The nature of bitcoin is such that we do not know and cannot
>> know what transactions exist out there pre-signed and making use of
>> these features.
>> 
>> It may be a good idea to make these features non standard to further
>> discourage their use, but I object to doing so with the justification of
>> eventually disabling them for all transactions. Taking that step has the
>> potential of destroying value and is something that we have only done in
>> the past either because we didn?t understand forks and best practices
>> very well, or because the features (now disabled) were fundamentally
>> insecure and resulted in other people?s coins being vulnerable. This
>> latter concern does not apply here as far as I?m aware.
>> 
>> On Nov 15, 2017, at 8:02 AM, Johnson Lau via bitcoin-dev
>> <bitcoin-dev at lists.linuxfoundation.org
>> <mailto:bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>>> wrote:
>> 
>>> In https://github.com/bitcoin/bitcoin/pull/11423 I propose to
>>> make OP_CODESEPARATOR and FindAndDelete in non-segwit scripts non-standard
>>> 
>>> I think FindAndDelete() is one of the most useless and complicated
>>> functions in the script language. It is omitted from segwit (BIP143),
>>> but we still need to support it in non-segwit scripts. Actually,
>>> FindAndDelete() would only be triggered in some weird edge cases like
>>> using out-of-range SIGHASH_SINGLE.
>>> 
>>> Non-segwit scripts also use a FindAndDelete()-like function to remove
>>> OP_CODESEPARATOR from scriptCode. Note that in BIP143, only executed
>>> OP_CODESEPARATOR are removed so it doesn?t have the
>>> FindAndDelete()-like function. OP_CODESEPARATOR in segwit scripts are
>>> useful for Tumblebit so it is not disabled in this proposal
>>> 
>>> By disabling both, it guarantees that scriptCode serialized inside
>>> SignatureHash() must be constant
>>> 
>>> If we use a softfork to remove FindAndDelete() and OP_CODESEPARATOR
>>> from non-segwit scripts, we could completely remove FindAndDelete()
>>> from the consensus code later by whitelisting all blocks before the
>>> softfork block. The first step is to make them non-standard in the
>>> next release.
>>> 
>>> 
>>>  
>>> _______________________________________________
>>> bitcoin-dev mailing list
>>> bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>
>>> <mailto:bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>>
>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>
>> 
>> 
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171127/8b6a2008/attachment-0001.html>

From lf-lists at mattcorallo.com  Mon Nov 27 21:33:37 2017
From: lf-lists at mattcorallo.com (Matt Corallo)
Date: Mon, 27 Nov 2017 16:33:37 -0500
Subject: [bitcoin-dev] Making OP_CODESEPARATOR and FindAndDelete in
 non-segwit scripts non-standard
In-Reply-To: <44B74F02-D3D6-47B9-976E-A72042E5C84B@friedenbach.org>
References: <53A587C3-DAC1-4055-875F-96B61717ACE6@xbt.hk>
	<081A517B-B730-43AB-9D4E-4F696EFD91A3@friedenbach.org>
	<56ca1248-6427-46f7-1645-84349cc8facc@mattcorallo.com>
	<44B74F02-D3D6-47B9-976E-A72042E5C84B@friedenbach.org>
Message-ID: <2c78e653-862d-afd3-0ae7-ebbbc9eec770@mattcorallo.com>

Indeed, the PR in question does *not* change the semantics of
OP_CODESEPARATOR within SegWit redeemScripts, where it is still allowed
(and Nicolas Dorier pointed out that he was using it in TumbleBit), so
there are still ways to use it, but only in places, like SegWit, where
the potential validation complexity blowup is massively reduced.

I am not sure that OP_CODESEPARATOR is entirely useless in pre-SegWit
scripts (I believe Nicolas' construction may still be relevant
pre-SegWit), though I strongly believe FindAndDelete is.

I don't think CODESEPARATOR rises to the threshold of it being "widely
known to be useless", but certainly the historical use of it (to
separate the scriptSig and the scriptPubKey in the scriptCode, which was
run as a single concatenated thing in the original design is no longer
relevant). FindAndDelete is equally irrelevant if not significantly more
irrelevant.

Matt

On 11/27/17 16:06, Mark Friedenbach wrote:
> It is relevant to note that BIP 117 makes an insecure form of
> CODESEPARATOR delegation possible, which could be made secure if some
> sort of CHECKSIGFROMSTACK opcode is added at a later point in time. It
> is not IMHO a very elegant way to achieve delegation, however, so I hope
> that one way or another this could be resolved quickly so it doesn?t
> hold up either one of those valuable additions.
> 
> I have no objections to making them nonstandard, or even to make them
> invalid if someone with a better grasp of history can attest that
> CODESEPARATOR was known to be entirely useless before the introduction
> of P2SH?not the same as saying it was useless, but that it was widely
> known to not accomplish what a early-days script author might think it
> was doing?and the UTXO set contains no scriptPubKeys making use of the
> opcode, even from the early days. Although a small handful could be
> special cased, if they exist.
> 
>> On Nov 27, 2017, at 8:33 AM, Matt Corallo <lf-lists at mattcorallo.com
>> <mailto:lf-lists at mattcorallo.com>> wrote:
>>
>> I strongly disagree here - we don't only soft-fork out transactions that
>> are "fundamentally insecure", that would be significantly too
>> restrictive. We have generally been willing to soft-fork out things
>> which clearly fall outside of best-practices, especially rather
>> "useless" fields in the protocol eg soft-forking behavior into OP_NOPs,
>> soft-forking behavior into nSequence, etc.
>>
>> As a part of setting clear best-practices, making things non-standard is
>> the obvious step, though there has been active discussion of
>> soft-forking out FindAndDelete and OP_CODESEPARATOR for years now. I
>> obviously do not claim that we should be proposing a soft-fork to
>> blacklist FindAndDelete and OP_CODESEPARATOR usage any time soon, and
>> assume that it would take at least a year or three from when it was made
>> non-standard to when a soft-fork to finally remove them was proposed.
>> This should be more than sufficient time for folks using such weird (and
>> largely useless) parts of the protocol to object, which should be
>> sufficient to reconsider such a soft-fork.
>>
>> Independently, making them non-standard is a good change on its own, and
>> if nothing else should better inform discussion about the possibility of
>> anyone using these things.
>>
>> Matt
>>
>> On 11/15/17 14:54, Mark Friedenbach via bitcoin-dev wrote:
>>> As good of an idea as it may or may not be to remove this feature from
>>> the code base, actually doing so?would be crossing a boundary that we
>>> have not previously been willing to do except under extraordinary
>>> duress. The nature of bitcoin is such that we do not know and cannot
>>> know what transactions exist out there pre-signed and making use of
>>> these features.
>>>
>>> It may be a good idea to make these features non standard to further
>>> discourage their use, but I object to doing so with the justification of
>>> eventually disabling them for all transactions. Taking that step has the
>>> potential of destroying value and is something that we have only done in
>>> the past either because we didn?t understand forks and best practices
>>> very well, or because the features (now disabled) were fundamentally
>>> insecure and resulted in other people?s coins being vulnerable. This
>>> latter concern does not apply here as far as I?m aware.
>>>
>>> On Nov 15, 2017, at 8:02 AM, Johnson Lau via bitcoin-dev
>>> <bitcoin-dev at lists.linuxfoundation.org
>>> <mailto:bitcoin-dev at lists.linuxfoundation.org>
>>> <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:
>>>
>>>> In?https://github.com/bitcoin/bitcoin/pull/11423?I propose to
>>>> make?OP_CODESEPARATOR and FindAndDelete in non-segwit scripts
>>>> non-standard
>>>>
>>>> I think FindAndDelete() is one of the most useless and complicated
>>>> functions in the script language. It is omitted from segwit (BIP143),
>>>> but we still need to support it in non-segwit scripts. Actually,
>>>> FindAndDelete() would only be triggered in some weird edge cases like
>>>> using out-of-range SIGHASH_SINGLE.
>>>>
>>>> Non-segwit scripts also use a FindAndDelete()-like function to remove
>>>> OP_CODESEPARATOR from scriptCode. Note that in BIP143, only executed
>>>> OP_CODESEPARATOR are removed so it doesn?t have the
>>>> FindAndDelete()-like function. OP_CODESEPARATOR in segwit scripts are
>>>> useful for Tumblebit so it is not disabled in this proposal
>>>>
>>>> By disabling both, it guarantees that scriptCode serialized inside
>>>> SignatureHash() must be constant
>>>>
>>>> If we use a softfork to remove FindAndDelete() and OP_CODESEPARATOR
>>>> from non-segwit scripts, we could completely remove FindAndDelete()
>>>> from the consensus code later by whitelisting all blocks before the
>>>> softfork block. The first step is to make them non-standard in the
>>>> next release.
>>>>
>>>>
>>>> ?
>>>> _______________________________________________
>>>> bitcoin-dev mailing list
>>>> bitcoin-dev at lists.linuxfoundation.org
>>>> <mailto:bitcoin-dev at lists.linuxfoundation.org>
>>>> <mailto:bitcoin-dev at lists.linuxfoundation.org>
>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>
>>>
>>> _______________________________________________
>>> bitcoin-dev mailing list
>>> bitcoin-dev at lists.linuxfoundation.org
>>> <mailto:bitcoin-dev at lists.linuxfoundation.org>
>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> 

From pete at petertodd.org  Tue Nov 28 10:48:28 2017
From: pete at petertodd.org (Peter Todd)
Date: Tue, 28 Nov 2017 05:48:28 -0500
Subject: [bitcoin-dev] BIP159 - NODE_NETWORK_LIMITED service bits,
 extendability
In-Reply-To: <CAAS2fgRZT6mStLa-PhpDOhccGvQ4jhD2m1PtzTd0_gfvtwBm7A@mail.gmail.com>
References: <BF359C7E-7FEF-43A6-8ED9-05BED8E0EB64@sprovoost.nl>
	<CAAS2fgRZT6mStLa-PhpDOhccGvQ4jhD2m1PtzTd0_gfvtwBm7A@mail.gmail.com>
Message-ID: <20171128104828.GA6115@fedora-23-dvm>

On Tue, Nov 21, 2017 at 06:45:33PM +0000, Gregory Maxwell via bitcoin-dev wrote:
> With the way pruning works today my expirence is that virtually no one
> sets any parameter other than the minimum, though even with that set a
> few more blocks can be available.

FWIW, I run all my pruned nodes with the prune parameter set to about a month
worth of blocks (a few GB). And come to think of it, I should bump that up even
higher now that segwit has increased the blocksize.

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 488 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171128/a581cf3a/attachment.sig>

From wjmelements at gmail.com  Thu Nov 30 00:47:43 2017
From: wjmelements at gmail.com (William Morriss)
Date: Wed, 29 Nov 2017 16:47:43 -0800
Subject: [bitcoin-dev] BIP Idea: Marginal Pricing
Message-ID: <CADpM8jr_RrbPXLx6Up8HMW-fv=noFLjy817dfsFdYTg216Pu7w@mail.gmail.com>

Comrades,

Long term, tx fees must support hash power by themselves. The following is
an economic approach to maximize total fee collection, and therefore
hashpower.

*Goals*
Maximize total transaction fees
Reduce pending transaction time
Reduce individual transaction fees

*Challenges*
Validators must agree on the maximum block size, else miners can cheat and
include extra transactions.
Allowing too many transactions per block will increase the cost of the
mining without collecting much income for the network.


*Problem*
In the transaction market, users are the demand curve, because they will
transact less when fees are higher, and prefer altcoins. The block size is
the supply curve, because it represents miners' willingness to accept
transactions.
Currently, the supply curve is inelastic:

?Increasing the block size will not affect the inelasticity for any fixed
block size. The downsides of a fixed block size limit are well-known:
- Unpredictable transaction settlement time
- Variable transaction fees depending on network congestion
- Frequent overpay

*Proposal*
1. Miners implicitly choose the market sat/byte rate with the cheapest-fee
transaction included in their block. Excess transaction fees are refunded
to the inputs.
2. Remove the block size limit, which is no longer necessary.

*Benefits*
- Dynamic block size limit regulated by profit motive
- Transaction fees maximized for every block
- No overpay; all fees are fair

?Miners individually will make decisions to maximize their block-reward
profit.
Miners are incentivized to ignore low-fee transactions because they would
shave the profits of their other transactions and increase their hash time.
Users and services are free to bid higher transaction fees in order to
reach the next block, since their excess bid will be refunded.

The block size limit was added as a spam-prevention measure, but in order
for an attacker to spam the network with low-fee transactions, they would
have to offset the marginal cost of reducing the price with their own
transaction fees. Anti-spam is thus built into the marginal system without
the need for an explicit limit.

Rarely, sections of the backlog would become large enough to be profitable.
This means every so many blocks, lower-fee transactions would be included
en masse after having been ignored long enough. Low-fee transactions thus
gain a liveness property not previously enjoyed: low-fee transactions will
eventually confirm. Miners targeting these transactions would be at a
noteworthy disadvantage because they would be hashing a larger block. I
predict that this scheme would result in two markets: a backlog market and
a real-time market. Users targeting the backlog market would match the
price of the largest backlog section in order to be included in the next
backlog block.

*Examples*

Scenario 1
Sat/byte Bytes Reward
400 500000 200000000
300 700000 210000000
200 1000000 200000000
100 1500000 150000000
50 5000000 250000000
20 10000000 200000000
A miner would create a 5MB block and receive 0.25 BTC

Scenario 2
Sat/byte Bytes Reward
400 600000 240000000
300 700000 210000000
200 1000000 200000000
100 1800000 180000000
50 4000000 200000000
20 10000000 200000000
A miner would create a 600KB block and receive 0.24 BTC

Thanks,
William Morriss
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171129/96ea6877/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: fixedblocksize.png
Type: image/png
Size: 18199 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171129/96ea6877/attachment-0003.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: fixedblocksize.png
Type: image/png
Size: 18199 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171129/96ea6877/attachment-0004.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: marginal.png
Type: image/png
Size: 21403 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171129/96ea6877/attachment-0005.png>

From benkloester at gmail.com  Thu Nov 30 02:38:25 2017
From: benkloester at gmail.com (Ben Kloester)
Date: Thu, 30 Nov 2017 13:38:25 +1100
Subject: [bitcoin-dev] BIP Idea: Marginal Pricing
In-Reply-To: <CADpM8jr_RrbPXLx6Up8HMW-fv=noFLjy817dfsFdYTg216Pu7w@mail.gmail.com>
References: <CADpM8jr_RrbPXLx6Up8HMW-fv=noFLjy817dfsFdYTg216Pu7w@mail.gmail.com>
Message-ID: <CANgJ=T8ZHbC4R3Rs5kZG8HfGs8810jj01WN4Ssiketej0md4kA@mail.gmail.com>

Something similar to this has been proposed  in this article by Ron Lavi,
Or Sattath, and Aviv Zohar, and discussed in this bitcoin-dev thread
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-September/015093.html

They only discussed changing the fee structure, not removing the block size
limit, as far as I know.

    "Redesigning Bitcoin's fee market"
    https://arxiv.org/abs/1709.08881



*Ben Kloester*

On 30 November 2017 at 11:47, William Morriss via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Comrades,
>
> Long term, tx fees must support hash power by themselves. The following is
> an economic approach to maximize total fee collection, and therefore
> hashpower.
>
> *Goals*
> Maximize total transaction fees
> Reduce pending transaction time
> Reduce individual transaction fees
>
> *Challenges*
> Validators must agree on the maximum block size, else miners can cheat and
> include extra transactions.
> Allowing too many transactions per block will increase the cost of the
> mining without collecting much income for the network.
>
>
> *Problem*
> In the transaction market, users are the demand curve, because they will
> transact less when fees are higher, and prefer altcoins. The block size is
> the supply curve, because it represents miners' willingness to accept
> transactions.
> Currently, the supply curve is inelastic:
>
> ?Increasing the block size will not affect the inelasticity for any fixed
> block size. The downsides of a fixed block size limit are well-known:
> - Unpredictable transaction settlement time
> - Variable transaction fees depending on network congestion
> - Frequent overpay
>
> *Proposal*
> 1. Miners implicitly choose the market sat/byte rate with the cheapest-fee
> transaction included in their block. Excess transaction fees are refunded
> to the inputs.
> 2. Remove the block size limit, which is no longer necessary.
>
> *Benefits*
> - Dynamic block size limit regulated by profit motive
> - Transaction fees maximized for every block
> - No overpay; all fees are fair
>
> ?Miners individually will make decisions to maximize their block-reward
> profit.
> Miners are incentivized to ignore low-fee transactions because they would
> shave the profits of their other transactions and increase their hash time.
> Users and services are free to bid higher transaction fees in order to
> reach the next block, since their excess bid will be refunded.
>
> The block size limit was added as a spam-prevention measure, but in order
> for an attacker to spam the network with low-fee transactions, they would
> have to offset the marginal cost of reducing the price with their own
> transaction fees. Anti-spam is thus built into the marginal system without
> the need for an explicit limit.
>
> Rarely, sections of the backlog would become large enough to be
> profitable. This means every so many blocks, lower-fee transactions would
> be included en masse after having been ignored long enough. Low-fee
> transactions thus gain a liveness property not previously enjoyed: low-fee
> transactions will eventually confirm. Miners targeting these transactions
> would be at a noteworthy disadvantage because they would be hashing a
> larger block. I predict that this scheme would result in two markets: a
> backlog market and a real-time market. Users targeting the backlog market
> would match the price of the largest backlog section in order to be
> included in the next backlog block.
>
> *Examples*
>
> Scenario 1
> Sat/byte Bytes Reward
> 400 500000 200000000
> 300 700000 210000000
> 200 1000000 200000000
> 100 1500000 150000000
> 50 5000000 250000000
> 20 10000000 200000000
> A miner would create a 5MB block and receive 0.25 BTC
>
> Scenario 2
> Sat/byte Bytes Reward
> 400 600000 240000000
> 300 700000 210000000
> 200 1000000 200000000
> 100 1800000 180000000
> 50 4000000 200000000
> 20 10000000 200000000
> A miner would create a 600KB block and receive 0.24 BTC
>
> Thanks,
> William Morriss
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/a56fd415/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: fixedblocksize.png
Type: image/png
Size: 18199 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/a56fd415/attachment-0003.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: marginal.png
Type: image/png
Size: 21403 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/a56fd415/attachment-0004.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: fixedblocksize.png
Type: image/png
Size: 18199 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/a56fd415/attachment-0005.png>

From greg at xiph.org  Thu Nov 30 09:12:48 2017
From: greg at xiph.org (Gregory Maxwell)
Date: Thu, 30 Nov 2017 09:12:48 +0000
Subject: [bitcoin-dev] BIP Idea: Marginal Pricing
In-Reply-To: <CAAS2fgS5jiNCmdwEt3YtZMJ0SfhC8Hw1eXr_0Vo5AQhYv7bJfg@mail.gmail.com>
References: <CADpM8jr_RrbPXLx6Up8HMW-fv=noFLjy817dfsFdYTg216Pu7w@mail.gmail.com>
	<CAAS2fgS5jiNCmdwEt3YtZMJ0SfhC8Hw1eXr_0Vo5AQhYv7bJfg@mail.gmail.com>
Message-ID: <CAAS2fgRtzjC6+ZZFPon_4nwjMoVjQkWQDQwMO4pfKhZqPfHZ9w@mail.gmail.com>

This idea presumes that the protocol has any ability to regulate fees. I
believe the locally optimal strategy for both miners and payers alike is to
accept (pay) zero fees natively in the protocol and instead accept (pay)
their actual fees out-of-band or via OP_TRUE outputs which the miner can
simply collect.  Then the miner sets the fee threshold to ~0 and selects
transactions on the basis of out of band fees.

Miners today already accept out-of-band fees, and as far back as at least
2011 there were miners that would also accept fees in the form of
additional transaction outputs which they were able to spend.

On Thu, Nov 30, 2017 at 9:11 AM, Gregory Maxwell <gmaxwell at gmail.com> wrote:

>
>
> This idea presumes that the protocol has any ability to regulate fees. I
> believe the locally optimal strategy for both miners and payers alike is to
> accept (pay) zero fees natively in the protocol and instead accept (pay)
> their actual fees out-of-band or via OP_TRUE outputs which the miner can
> simply collect.  Then the miner sets the fee threshold to ~0 and selects
> transactions on the basis of out of band fees.
>
> Miners today already accept out-of-band fees, and as far back as at least
> 2011 there were miners that would also accept fees in the form of
> additional transaction outputs which they were able to spend.
>
>
>
> On Thu, Nov 30, 2017 at 12:47 AM, William Morriss via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>> Comrades,
>>
>> Long term, tx fees must support hash power by themselves. The following
>> is an economic approach to maximize total fee collection, and therefore
>> hashpower.
>>
>> *Goals*
>> Maximize total transaction fees
>> Reduce pending transaction time
>> Reduce individual transaction fees
>>
>> *Challenges*
>> Validators must agree on the maximum block size, else miners can cheat
>> and include extra transactions.
>> Allowing too many transactions per block will increase the cost of the
>> mining without collecting much income for the network.
>>
>>
>> *Problem*
>> In the transaction market, users are the demand curve, because they will
>> transact less when fees are higher, and prefer altcoins. The block size is
>> the supply curve, because it represents miners' willingness to accept
>> transactions.
>> Currently, the supply curve is inelastic:
>>
>> ?Increasing the block size will not affect the inelasticity for any
>> fixed block size. The downsides of a fixed block size limit are well-known:
>> - Unpredictable transaction settlement time
>> - Variable transaction fees depending on network congestion
>> - Frequent overpay
>>
>> *Proposal*
>> 1. Miners implicitly choose the market sat/byte rate with the
>> cheapest-fee transaction included in their block. Excess transaction fees
>> are refunded to the inputs.
>> 2. Remove the block size limit, which is no longer necessary.
>>
>> *Benefits*
>> - Dynamic block size limit regulated by profit motive
>> - Transaction fees maximized for every block
>> - No overpay; all fees are fair
>>
>> ?Miners individually will make decisions to maximize their block-reward
>> profit.
>> Miners are incentivized to ignore low-fee transactions because they would
>> shave the profits of their other transactions and increase their hash time.
>> Users and services are free to bid higher transaction fees in order to
>> reach the next block, since their excess bid will be refunded.
>>
>> The block size limit was added as a spam-prevention measure, but in order
>> for an attacker to spam the network with low-fee transactions, they would
>> have to offset the marginal cost of reducing the price with their own
>> transaction fees. Anti-spam is thus built into the marginal system without
>> the need for an explicit limit.
>>
>> Rarely, sections of the backlog would become large enough to be
>> profitable. This means every so many blocks, lower-fee transactions would
>> be included en masse after having been ignored long enough. Low-fee
>> transactions thus gain a liveness property not previously enjoyed: low-fee
>> transactions will eventually confirm. Miners targeting these transactions
>> would be at a noteworthy disadvantage because they would be hashing a
>> larger block. I predict that this scheme would result in two markets: a
>> backlog market and a real-time market. Users targeting the backlog market
>> would match the price of the largest backlog section in order to be
>> included in the next backlog block.
>>
>> *Examples*
>>
>> Scenario 1
>> Sat/byte Bytes Reward
>> 400 500000 200000000
>> 300 700000 210000000
>> 200 1000000 200000000
>> 100 1500000 150000000
>> 50 5000000 250000000
>> 20 10000000 200000000
>> A miner would create a 5MB block and receive 0.25 BTC
>>
>> Scenario 2
>> Sat/byte Bytes Reward
>> 400 600000 240000000
>> 300 700000 210000000
>> 200 1000000 200000000
>> 100 1800000 180000000
>> 50 4000000 200000000
>> 20 10000000 200000000
>> A miner would create a 600KB block and receive 0.24 BTC
>>
>> Thanks,
>> William Morriss
>>
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/b113f2f5/attachment.html>

From Chenxi_Cai at live.com  Thu Nov 30 05:52:24 2017
From: Chenxi_Cai at live.com (Chenxi Cai)
Date: Thu, 30 Nov 2017 05:52:24 +0000
Subject: [bitcoin-dev] BIP Idea: Marginal Pricing
In-Reply-To: <CADpM8jr_RrbPXLx6Up8HMW-fv=noFLjy817dfsFdYTg216Pu7w@mail.gmail.com>
References: <CADpM8jr_RrbPXLx6Up8HMW-fv=noFLjy817dfsFdYTg216Pu7w@mail.gmail.com>
Message-ID: <CY4PR1201MB019720B8D7C7AE10182F893186380@CY4PR1201MB0197.namprd12.prod.outlook.com>

Hi All,


Auction theory is a well-studied problem in the economics literature. Currently what bitcoin has is Generalized first-price auction, where winning bidders pay their full bids. Alternatively, two approaches are potentially viable, which are Generalized second-price auction and Vickrey?Clarke?Groves auction. Generalized second-price auction, where winning bidders pay their next highest bids, reduces (but not eliminate) the need for bidders to strategize by allowing them to bid closer to their reservation price. Vickrey?Clarke?Groves auction, a more sophisticated system that considers all bids in relation to one another, elicit truthful bids from bidders, but may not maximize miners' fees as the other two systems will.


Due to one result called Revenue Equivalence, the choice of fee design will not impact miners' fees unless the outcomes of the auction changes (i.e, the highest bidders do not always win). In addition, the sole benefit of second-price auction over first-price auction is to spare people's mental troubles from strategizing, rather than actually saving mining fees, because in equilibrium the fees bidders pay remain the same. Therefore, in balance, I do not see substantial material benefits arising from switching to a different fee schedule.


Best,

Chenxi Cai


________________________________
From: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of William Morriss via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>
Sent: Wednesday, November 29, 2017 5:47 PM
To: bitcoin-dev at lists.linuxfoundation.org
Subject: [bitcoin-dev] BIP Idea: Marginal Pricing

Comrades,

Long term, tx fees must support hash power by themselves. The following is an economic approach to maximize total fee collection, and therefore hashpower.

Goals
Maximize total transaction fees
Reduce pending transaction time
Reduce individual transaction fees

Challenges
Validators must agree on the maximum block size, else miners can cheat and include extra transactions.
Allowing too many transactions per block will increase the cost of the mining without collecting much income for the network.

Problem
In the transaction market, users are the demand curve, because they will transact less when fees are higher, and prefer altcoins. The block size is the supply curve, because it represents miners' willingness to accept transactions.
Currently, the supply curve is inelastic:
[cid:ii_jalpxsnl1_1600a3d9def1eaff]
Increasing the block size will not affect the inelasticity for any fixed block size. The downsides of a fixed block size limit are well-known:
- Unpredictable transaction settlement time
- Variable transaction fees depending on network congestion
- Frequent overpay

Proposal
1. Miners implicitly choose the market sat/byte rate with the cheapest-fee transaction included in their block. Excess transaction fees are refunded to the inputs.
2. Remove the block size limit, which is no longer necessary.

Benefits
- Dynamic block size limit regulated by profit motive
- Transaction fees maximized for every block
- No overpay; all fees are fair
[cid:ii_jalqir4g2_1600a4c89811347a]
Miners individually will make decisions to maximize their block-reward profit.
Miners are incentivized to ignore low-fee transactions because they would shave the profits of their other transactions and increase their hash time.
Users and services are free to bid higher transaction fees in order to reach the next block, since their excess bid will be refunded.

The block size limit was added as a spam-prevention measure, but in order for an attacker to spam the network with low-fee transactions, they would have to offset the marginal cost of reducing the price with their own transaction fees. Anti-spam is thus built into the marginal system without the need for an explicit limit.

Rarely, sections of the backlog would become large enough to be profitable. This means every so many blocks, lower-fee transactions would be included en masse after having been ignored long enough. Low-fee transactions thus gain a liveness property not previously enjoyed: low-fee transactions will eventually confirm. Miners targeting these transactions would be at a noteworthy disadvantage because they would be hashing a larger block. I predict that this scheme would result in two markets: a backlog market and a real-time market. Users targeting the backlog market would match the price of the largest backlog section in order to be included in the next backlog block.

Examples

Scenario 1
Sat/byte        Bytes   Reward
400     500000  200000000
300     700000  210000000
200     1000000 200000000
100     1500000 150000000
50      5000000 250000000
20      10000000        200000000
A miner would create a 5MB block and receive 0.25 BTC

Scenario 2
Sat/byte        Bytes   Reward
400     600000  240000000
300     700000  210000000
200     1000000 200000000
100     1800000 180000000
50      4000000 200000000
20      10000000        200000000
A miner would create a 600KB block and receive 0.24 BTC

Thanks,
William Morriss
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/1134178c/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: fixedblocksize.png
Type: image/png
Size: 18199 bytes
Desc: fixedblocksize.png
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/1134178c/attachment-0003.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: fixedblocksize.png
Type: image/png
Size: 18199 bytes
Desc: fixedblocksize.png
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/1134178c/attachment-0004.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: marginal.png
Type: image/png
Size: 21403 bytes
Desc: marginal.png
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/1134178c/attachment-0005.png>

From wjmelements at gmail.com  Thu Nov 30 06:13:15 2017
From: wjmelements at gmail.com (William Morriss)
Date: Wed, 29 Nov 2017 22:13:15 -0800
Subject: [bitcoin-dev] BIP Idea: Marginal Pricing
In-Reply-To: <CANgJ=T8ZHbC4R3Rs5kZG8HfGs8810jj01WN4Ssiketej0md4kA@mail.gmail.com>
References: <CADpM8jr_RrbPXLx6Up8HMW-fv=noFLjy817dfsFdYTg216Pu7w@mail.gmail.com>
	<CANgJ=T8ZHbC4R3Rs5kZG8HfGs8810jj01WN4Ssiketej0md4kA@mail.gmail.com>
Message-ID: <CADpM8jq_-JxCmLiCPMG2ZVuYxZH7KOCyyMaQnBay18PQLPvmRg@mail.gmail.com>

On Wed, Nov 29, 2017 at 6:38 PM, Ben Kloester <benkloester at gmail.com> wrote:

> Something similar to this has been proposed  in this article by Ron Lavi,
> Or Sattath, and Aviv Zohar, and discussed in this bitcoin-dev thread
> https://lists.linuxfoundation.org/pipermail/bitcoin-
> dev/2017-September/015093.html
>
> They only discussed changing the fee structure, not removing the block
> size limit, as far as I know.
>
>     "Redesigning Bitcoin's fee market"
>     https://arxiv.org/abs/1709.08881
>
> *Ben Kloester*
>

Thanks. Marginal pricing is equivalent to the "Monopolistic Price
Mechanism" discussed in https://arxiv.org/abs/1709.08881. The mechanism is
the same, including the block size adjustment, but as you noted the prior
discussion only concerns the fee structure.

It looks like the prior proposal broke down because of Peter Todd's concern
with out-of-band payments (https://lists.linuxfoundation.org/pipermail/
bitcoin-dev/2017-September/015103.html). Restated, miners can circumvent
the system through out of band payments. Mark Friedenbach argues that
out-of-band payments are penalized in part because the end-user could have
just as easily bid higher instead of paying OOB. Peter Todd argues that a
miner could mine only out-of-band transactions. Such transactions could
have no on-chain fees and thus be disregarded by other miners.

I believe this OOB scenario is imaginary. Either it would be more
profitable for a miner to mine fairly, or cheaper for the end-user to pay
the fee in-band. Consider MINFEE to the the effective fee paid for the
block mined by the OOB-incentivized miner. Consider MARKFEE to the the
market fee collected by non-OOB-incentivized miners. Call the OOB effective
tx fee OOB. Then,
For a user to prefer OOB: MINFEE+OOB<MARKFEE
For a miner to prefer OOB: MINFEE+OOB>MARKFEE
It is impossible for both scenarios to be true. As previously argued by
Mark Friedenbach, the system disincentivizes OOB tx fees.

I don't think there is any more centralization pressure with marginal fees
than before. What prevents miners from colluding to move tx fees OOB is the
value of the on-band pending tx fees. The hashpower of individual miners is
not impressive compared to the entire network, so individual miners could
not offer a service to speed up confirmation that would be superior to
simply doing a RBP. OOB fees are perhaps a symptom of the current setup,
wherein there is no penalty for arbitrarily favoring individual
transactions with lower fees.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171129/e53585b8/attachment.html>

From federicotenga at gmail.com  Thu Nov 30 09:37:57 2017
From: federicotenga at gmail.com (Federico Tenga)
Date: Thu, 30 Nov 2017 10:37:57 +0100
Subject: [bitcoin-dev] BIP Idea: Marginal Pricing
In-Reply-To: <CANgJ=T8ZHbC4R3Rs5kZG8HfGs8810jj01WN4Ssiketej0md4kA@mail.gmail.com>
References: <CADpM8jr_RrbPXLx6Up8HMW-fv=noFLjy817dfsFdYTg216Pu7w@mail.gmail.com>
	<CANgJ=T8ZHbC4R3Rs5kZG8HfGs8810jj01WN4Ssiketej0md4kA@mail.gmail.com>
Message-ID: <CAP=-fx7gGhR1G+kGZuS8OLgRk1KWGcNz8EDX=6KuhRaOrpPCVA@mail.gmail.com>

The main issue that I see with this proposal is that miners can still spam
the network for free even with high sat/byte fee levels. They can first
choose the sat/byte rate that maximize their profit, and then include a lot
of spam transactions at that rate that will only pay fees to themselves,
effectively spamming the chain for free and increasing the cost of running
a node.

On 30 Nov 2017 03:40, "Ben Kloester via bitcoin-dev" <
bitcoin-dev at lists.linuxfoundation.org> wrote:

Something similar to this has been proposed  in this article by Ron Lavi,
Or Sattath, and Aviv Zohar, and discussed in this bitcoin-dev thread
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-September/
015093.html

They only discussed changing the fee structure, not removing the block size
limit, as far as I know.

    "Redesigning Bitcoin's fee market"
    https://arxiv.org/abs/1709.08881



*Ben Kloester*

On 30 November 2017 at 11:47, William Morriss via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Comrades,
>
> Long term, tx fees must support hash power by themselves. The following is
> an economic approach to maximize total fee collection, and therefore
> hashpower.
>
> *Goals*
> Maximize total transaction fees
> Reduce pending transaction time
> Reduce individual transaction fees
>
> *Challenges*
> Validators must agree on the maximum block size, else miners can cheat and
> include extra transactions.
> Allowing too many transactions per block will increase the cost of the
> mining without collecting much income for the network.
>
>
> *Problem*
> In the transaction market, users are the demand curve, because they will
> transact less when fees are higher, and prefer altcoins. The block size is
> the supply curve, because it represents miners' willingness to accept
> transactions.
> Currently, the supply curve is inelastic:
>
> ?Increasing the block size will not affect the inelasticity for any fixed
> block size. The downsides of a fixed block size limit are well-known:
> - Unpredictable transaction settlement time
> - Variable transaction fees depending on network congestion
> - Frequent overpay
>
> *Proposal*
> 1. Miners implicitly choose the market sat/byte rate with the cheapest-fee
> transaction included in their block. Excess transaction fees are refunded
> to the inputs.
> 2. Remove the block size limit, which is no longer necessary.
>
> *Benefits*
> - Dynamic block size limit regulated by profit motive
> - Transaction fees maximized for every block
> - No overpay; all fees are fair
>
> ?Miners individually will make decisions to maximize their block-reward
> profit.
> Miners are incentivized to ignore low-fee transactions because they would
> shave the profits of their other transactions and increase their hash time.
> Users and services are free to bid higher transaction fees in order to
> reach the next block, since their excess bid will be refunded.
>
> The block size limit was added as a spam-prevention measure, but in order
> for an attacker to spam the network with low-fee transactions, they would
> have to offset the marginal cost of reducing the price with their own
> transaction fees. Anti-spam is thus built into the marginal system without
> the need for an explicit limit.
>
> Rarely, sections of the backlog would become large enough to be
> profitable. This means every so many blocks, lower-fee transactions would
> be included en masse after having been ignored long enough. Low-fee
> transactions thus gain a liveness property not previously enjoyed: low-fee
> transactions will eventually confirm. Miners targeting these transactions
> would be at a noteworthy disadvantage because they would be hashing a
> larger block. I predict that this scheme would result in two markets: a
> backlog market and a real-time market. Users targeting the backlog market
> would match the price of the largest backlog section in order to be
> included in the next backlog block.
>
> *Examples*
>
> Scenario 1
> Sat/byte Bytes Reward
> 400 500000 200000000
> 300 700000 210000000
> 200 1000000 200000000
> 100 1500000 150000000
> 50 5000000 250000000
> 20 10000000 200000000
> A miner would create a 5MB block and receive 0.25 BTC
>
> Scenario 2
> Sat/byte Bytes Reward
> 400 600000 240000000
> 300 700000 210000000
> 200 1000000 200000000
> 100 1800000 180000000
> 50 4000000 200000000
> 20 10000000 200000000
> A miner would create a 600KB block and receive 0.24 BTC
>
> Thanks,
> William Morriss
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>

_______________________________________________
bitcoin-dev mailing list
bitcoin-dev at lists.linuxfoundation.org
https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/f185452e/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: fixedblocksize.png
Type: image/png
Size: 18199 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/f185452e/attachment-0003.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: fixedblocksize.png
Type: image/png
Size: 18199 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/f185452e/attachment-0004.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: marginal.png
Type: image/png
Size: 21403 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/f185452e/attachment-0005.png>

From wjmelements at gmail.com  Thu Nov 30 06:05:02 2017
From: wjmelements at gmail.com (William Morriss)
Date: Wed, 29 Nov 2017 22:05:02 -0800
Subject: [bitcoin-dev] BIP Idea: Marginal Pricing
In-Reply-To: <CY4PR1201MB019720B8D7C7AE10182F893186380@CY4PR1201MB0197.namprd12.prod.outlook.com>
References: <CADpM8jr_RrbPXLx6Up8HMW-fv=noFLjy817dfsFdYTg216Pu7w@mail.gmail.com>
	<CY4PR1201MB019720B8D7C7AE10182F893186380@CY4PR1201MB0197.namprd12.prod.outlook.com>
Message-ID: <CADpM8jrOfjCaHAu97MGaaAouYootyBCwuBw1fvay0zK8pnwRVg@mail.gmail.com>

On Wed, Nov 29, 2017 at 9:52 PM, Chenxi Cai <Chenxi_Cai at live.com> wrote:

> Hi All,
>
>
> Auction theory is a well-studied problem in the economics literature.
> Currently what bitcoin has is Generalized first-price auction, where
> winning bidders pay their full bids. Alternatively, two approaches are
> potentially viable, which are Generalized second-price auction and Vickrey?Clarke?Groves
> auction. Generalized second-price auction, where winning bidders pay their
> next highest bids, reduces (but not eliminate) the need for bidders to
> strategize by allowing them to bid closer to their reservation
> price. Vickrey?Clarke?Groves auction, a more sophisticated system that
> considers all bids in relation to one another, elicit truthful bids from
> bidders, but may not maximize miners' fees as the other two systems will.
>
>
> Due to one result called Revenue Equivalence, the choice of fee design
> will not impact miners' fees unless the outcomes of the auction changes
> (i.e, the highest bidders do not always win). In addition, the sole benefit
> of second-price auction over first-price auction is to spare people's
> mental troubles from strategizing, rather than actually saving mining fees,
> because in equilibrium the fees bidders pay remain the same. Therefore, in
> balance, I do not see substantial material benefits arising from switching
> to a different fee schedule.
>
>
> Best,
>
> Chenxi Cai
>
>
Changing the bidding system to the marginal price allows us to supersede
the block size limit, which changes the outcome of the auction, as
different transactions are included.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171129/e5fd0f84/attachment.html>

From greg at xiph.org  Thu Nov 30 11:40:54 2017
From: greg at xiph.org (Gregory Maxwell)
Date: Thu, 30 Nov 2017 11:40:54 +0000
Subject: [bitcoin-dev] BIP Idea: Marginal Pricing
In-Reply-To: <CADpM8jq_-JxCmLiCPMG2ZVuYxZH7KOCyyMaQnBay18PQLPvmRg@mail.gmail.com>
References: <CADpM8jr_RrbPXLx6Up8HMW-fv=noFLjy817dfsFdYTg216Pu7w@mail.gmail.com>
	<CANgJ=T8ZHbC4R3Rs5kZG8HfGs8810jj01WN4Ssiketej0md4kA@mail.gmail.com>
	<CADpM8jq_-JxCmLiCPMG2ZVuYxZH7KOCyyMaQnBay18PQLPvmRg@mail.gmail.com>
Message-ID: <CAAS2fgRbEeUa-CB3NTN-kSZBPBbzax+72iou1uShcJ6=i7mJ2g@mail.gmail.com>

On Thu, Nov 30, 2017 at 6:13 AM, William Morriss via bitcoin-dev
<bitcoin-dev at lists.linuxfoundation.org> wrote:
> I believe this OOB scenario is imaginary. Either it would be more profitable

Out of band fees are a reality even today-- and have for most of
Bitcoin's life--, without a system that has any particular incentive
for them.

> for a miner to mine fairly, or cheaper for the end-user to pay the fee
> in-band. Consider MINFEE to the the effective fee paid for the block mined
> by the OOB-incentivized miner. Consider MARKFEE to the the market fee
> collected by non-OOB-incentivized miners. Call the OOB effective tx fee OOB.
> Then,
> For a user to prefer OOB: MINFEE+OOB<MARKFEE
> For a miner to prefer OOB: MINFEE+OOB>MARKFEE
> It is impossible for both scenarios to be true. As previously argued by Mark
> Friedenbach, the system disincentivizes OOB tx fees.

This kind of analysis seems to imagine that a single decision maker is
making a globally optimal decision and that also people are somehow
forced to only make one choice. Both are untrue in this case (and most
other economic circumstances). Instead, participants can take the best
of multiple choices and will often act locally for their own best
interest even when it reduces revenue for their industry in total.

Concretely: as a user with competent wallet software, I would be
automatically drafting two transactions-- one paying OOB and one
paying min fee, at equivalent expected rates.  Miners would construct
blocks which locally maximized their revenue.   It is far from clear
that use of the minfee scheme is an equilibrium-- in fact I think it
is clearly not an equilibrium: a user that writes both transactions
will always pay equal or less fees for the transactions where they do
both (even if all users doing this causes users collectively to pay
higher fees), a miner who considers both will always make equal or
greater fee income on a block by block basis (even if it lowers miner
income collectively when all do this).

(If it were in fact preferred by users and miners alike: why doesn't
it already exist?  Since the existence of OOB fees cannot be
eliminated, as far as we know, any use of MINFEE would be inherently
voluntary-- so in one sense we already 'have' voluntary minfee, but no
one uses it.)


Ignoring the possibility of evasion, there are some other concerns
that you might want to consider:

I believe the idea converts variance in fee willingness into variance
in capacity for the network.  If rich uncle bill wants to waste money
with uneconomically high fees, with a constant flow of transactions,
he'll effectively knock out a large number of participants.  You could
argue that bill could spend those same fees in spam to displace the
same amount of transactions while also using more capacity; but I
UncleBill isn't trying to attack the capacity of the system. It's just
collateral damage.  I worry also about related strategies that arise
in that world: For example, lets imagine that world consisted of a
couple unclebill who will pay high fees, and the unwashed masses that
will not and pay a much lower consistent feerate.   Honest conformance
with your protocol would result in miners either processing only the
UncleBill txn or processing all of them at the lower rate, whichever
is more profitable.  Super-rational behavior might be for a majority
of hashpower to collude to only permit high fee-rate transactions
every other block and only permit low feerate in the others, and then
the network processes all unclebills in one block (at full rate), and
all the unwashed in the others.  From a fee perspective it arguably
isn't any worse than today, but I believe it significantly handicaps
your capacity limiting argument.

> wherein there is no penalty for arbitrarily favoring individual transactions with lower fees

Nor does a MINFEE system; since the user can near costlessly construct
as many variations of their transaction as they like.

> The hashpower of individual miners is not impressive compared to the entire network,

That is unfortunately not the reality of Bitcoin today.

From eric at voskuil.org  Thu Nov 30 12:03:30 2017
From: eric at voskuil.org (Eric Voskuil)
Date: Thu, 30 Nov 2017 04:03:30 -0800
Subject: [bitcoin-dev] BIP Idea: Marginal Pricing
In-Reply-To: <CADpM8jq_-JxCmLiCPMG2ZVuYxZH7KOCyyMaQnBay18PQLPvmRg@mail.gmail.com>
References: <CADpM8jr_RrbPXLx6Up8HMW-fv=noFLjy817dfsFdYTg216Pu7w@mail.gmail.com>
	<CANgJ=T8ZHbC4R3Rs5kZG8HfGs8810jj01WN4Ssiketej0md4kA@mail.gmail.com>
	<CADpM8jq_-JxCmLiCPMG2ZVuYxZH7KOCyyMaQnBay18PQLPvmRg@mail.gmail.com>
Message-ID: <61fa604f-29c8-c1f2-fc49-45a5e8263bfa@voskuil.org>

On 11/29/2017 10:13 PM, William Morriss via bitcoin-dev wrote:
> On Wed, Nov 29, 2017 at 6:38 PM, Ben Kloester <benkloester at gmail.com
> <mailto:benkloester at gmail.com>> wrote:
> 
>     Something similar to this has been proposed  in this article by Ron
>     Lavi, Or Sattath, and Aviv Zohar, and discussed in this bitcoin-dev
>     thread https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-September/015093.html
> 
>     They only discussed changing the fee structure, not removing the
>     block size limit, as far as I know.
> 
>         "Redesigning Bitcoin's fee market"
>         https://arxiv.org/abs/1709.08881 <https://arxiv.org/abs/1709.08881>
> 
>     *Ben Kloester*
> 
> Thanks. Marginal pricing is equivalent to the "Monopolistic Price
> Mechanism" discussed in https://arxiv.org/abs/1709.08881
> The mechanism is the same, including
> the block size adjustment, but as you noted the prior discussion only
> concerns the fee structure.
> 
> It looks like the prior proposal broke down because of Peter Todd's
> concern with out-of-band payments
> (https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-September/015103.html).
> Restated, miners can circumvent the system through out of band payments.
> Mark Friedenbach argues that out-of-band payments are penalized in part
> because the end-user could have just as easily bid higher instead of
> paying OOB. Peter Todd argues that a miner could mine only out-of-band
> transactions. Such transactions could have no on-chain fees and thus be
> disregarded by other miners.
> 
> I believe this OOB scenario is imaginary. Either it would be more
> profitable for a miner to mine fairly, or cheaper for the end-user to
> pay the fee in-band. 
> Consider MINFEE to the the effective fee paid for
> the block mined by the OOB-incentivized miner. Consider MARKFEE to the
> the market fee collected by non-OOB-incentivized miners. Call the OOB
> effective tx fee OOB. Then,
> For a user to prefer OOB: MINFEE+OOB<MARKFEE
> For a miner to prefer OOB: MINFEE+OOB>MARKFEE
> It is impossible for both scenarios to be true. As previously argued by
> Mark Friedenbach, the system disincentivizes OOB tx fees.

Bitcoin is neutral on how miners are paid. The benefit of on-chain fee
payment is that a fee can be paid with no communication between the
miner and the merchant, preserving anonymity. It also serves as a
convenience that anonymous fees are published, as it provides a basis
for anonymous fee estimation. There is no centralization pressure that
arises from side fees.

https://github.com/libbitcoin/libbitcoin/wiki/Side-Fee-Fallacy

> I don't think there is any more centralization pressure with marginal
> fees than before. What prevents miners from colluding to move tx fees
> OOB is the value of the on-band pending tx fees. The hashpower of
> individual miners is not impressive compared to the entire network, so
> individual miners could not offer a service to speed up confirmation
> that would be superior to simply doing a RBP. OOB fees are perhaps a
> symptom of the current setup, wherein there is no penalty for
> arbitrarily favoring individual transactions with lower fees.


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/2e64e116/attachment.sig>

From Chenxi_Cai at live.com  Thu Nov 30 16:15:01 2017
From: Chenxi_Cai at live.com (Chenxi Cai)
Date: Thu, 30 Nov 2017 16:15:01 +0000
Subject: [bitcoin-dev] BIP Idea: Marginal Pricing
In-Reply-To: <CY4PR1201MB0197936CBE467B38DCC26DC986380@CY4PR1201MB0197.namprd12.prod.outlook.com>
References: <CADpM8jr_RrbPXLx6Up8HMW-fv=noFLjy817dfsFdYTg216Pu7w@mail.gmail.com>
	<CY4PR1201MB019720B8D7C7AE10182F893186380@CY4PR1201MB0197.namprd12.prod.outlook.com>,
	<CADpM8jrOfjCaHAu97MGaaAouYootyBCwuBw1fvay0zK8pnwRVg@mail.gmail.com>,
	<CY4PR1201MB0197936CBE467B38DCC26DC986380@CY4PR1201MB0197.namprd12.prod.outlook.com>
Message-ID: <CY4PR1201MB019798D1013AE2296AC0F30086380@CY4PR1201MB0197.namprd12.prod.outlook.com>




It is clear that charging min fee won't maximize total miner's fees because it ignores heterogeneity in willingness to pay among bidders within the same block. Also, spamming can still occur by setting a large number of transactions to the min fee. Competition between spammers might drive up the min fee, which is really where the positive effect comes from in this model.


A two-part pricing scheme involving a fixed fee per transaction plus variable fee per byte is likely to work much better. The fixed fee component raises the cost of micro-transactions substantially and deters spamming of the mempool.  Also, revenue is not lost from people with higher willingness to pay.


Chenxi

________________________________
From: William Morriss <wjmelements at gmail.com>
Sent: Wednesday, November 29, 2017 11:05 PM
To: Chenxi Cai
Cc: Bitcoin Protocol Discussion
Subject: Re: [bitcoin-dev] BIP Idea: Marginal Pricing

On Wed, Nov 29, 2017 at 9:52 PM, Chenxi Cai <Chenxi_Cai at live.com<mailto:Chenxi_Cai at live.com>> wrote:

Hi All,


Auction theory is a well-studied problem in the economics literature. Currently what bitcoin has is Generalized first-price auction, where winning bidders pay their full bids. Alternatively, two approaches are potentially viable, which are Generalized second-price auction and Vickrey?Clarke?Groves auction. Generalized second-price auction, where winning bidders pay their next highest bids, reduces (but not eliminate) the need for bidders to strategize by allowing them to bid closer to their reservation price. Vickrey?Clarke?Groves auction, a more sophisticated system that considers all bids in relation to one another, elicit truthful bids from bidders, but may not maximize miners' fees as the other two systems will.


Due to one result called Revenue Equivalence, the choice of fee design will not impact miners' fees unless the outcomes of the auction changes (i.e, the highest bidders do not always win). In addition, the sole benefit of second-price auction over first-price auction is to spare people's mental troubles from strategizing, rather than actually saving mining fees, because in equilibrium the fees bidders pay remain the same. Therefore, in balance, I do not see substantial material benefits arising from switching to a different fee schedule.


Best,

Chenxi Cai


Changing the bidding system to the marginal price allows us to supersede the block size limit, which changes the outcome of the auction, as different transactions are included.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/e0abb4a7/attachment.html>

From mandar.mulherkar at gmail.com  Thu Nov 30 22:20:10 2017
From: mandar.mulherkar at gmail.com (mandar mulherkar)
Date: Thu, 30 Nov 2017 14:20:10 -0800
Subject: [bitcoin-dev] A DNS-like decentralized mapping for wallet addresses?
Message-ID: <CAHneDF3qH9OUxqLthY6hEzzFr21QJFLV5wOP8jw+p5eOtpb2oQ@mail.gmail.com>

Hello,

I am new, so apologies if this has been asked before.

Here are a few questions to start with -

I was wondering in terms of mass adoption, instead of long wallet
addresses, maybe there should be a DNS-like decentralized mapping service
to provide a user at crypto address?

This address translation can happen with confirmations from the network. So
instead of providing a long string, or a QR code that needs an app, you
simply type in a human readable address, and the wallet software converts
it to a wallet address.

Please let me know where I can research this more - if there already is
literature about this somewhere.

thanks!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/29177e88/attachment.html>

