From vjudeu at gazeta.pl  Sat Jan  1 15:45:11 2022
From: vjudeu at gazeta.pl (vjudeu at gazeta.pl)
Date: Sat, 01 Jan 2022 16:45:11 +0100
Subject: [bitcoin-dev] On the regularity of soft forks
Message-ID: <151636693-b9baa24a337b74e4b019a92e12c81eff@pmq4v.m5r2.onet>

> If you don't like the reduction of the block subsidy, well that's a much bigger problem.
It is reversible, because you can also increase the block subsidy by using another kind of soft-fork. For example, you can create spendable outputs with zero satoshis. In this way, old nodes will accept that silently, but new nodes can check something more, because you can specify somewhere else, what is the "real" amount. Finally, if all nodes will upgrade, you will end up in a network, where all transactions spend zero satoshi inputs, create zero satoshi outputs and have zero fee. Old nodes would accept all of that, but new nodes would really see, what is going on, and they will check that all rules are met, and the new subsidy is for example increased x1000 (that could lead to the same situation as moving from satoshis to millisatoshis with some hard-fork, but doing that kind of change with a soft-fork is safer).
On 2021-12-31 10:35:06 user Keagan McClelland via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
>??But whether or not it is a basic principle of general software engineering kind of misses the point. Security critical software clearly isn't engineered in the same way as a new social media app. Bugs are easily reverted in a new social media app.On top of that we aren't just dealing with security critical software. One of the most important objectives is to keep all the nodes on the network in consensus. Introducing a consensus change before we are comfortable there is community consensus for it is a massive effective bug in itself. The network can split in multiple ways e.g. part of the network disagrees on whether to activate the consensus change, part of the network disagrees on how to resist that consensus change, part of the network disagrees on how to activate that consensus change etc
?
>??A consensus change is extremely hard to revert and probably requires a hard fork, a level of central coordination we generally attempt to avoid and a speed of deployment that we also attempt to avoid.
?
This seems to assert the idea that soft forks are all the same: they are not. For instance a soft fork, lowering the block subsidy is completely different than changing the semantics of an OP_NOP to have semantics that may reject a subset of the witnesses that attest to the transactions permissibility. As a result, reversion means two entirely different things in these contexts. While a strict reversion of both soft forks is by definition a hard fork, the requirement of reversion as a result of undesired behavior is not the same. In the case of opcodes, there is almost never a requirement to revert it. If you don't like the way the opcodes behave, then you just don't use them. If you don't like the reduction of the block subsidy, well that's a much bigger problem.
?
I make this point to elucidate the idea that we cannot treat SoftForks? as a single monolithic idea. Perhaps we need to come up with better terminology to be specific about what each fork actually is. The soft vs. hard distinction is a critical one but it is not enough and treating soft forks that are noninvasive such as OP_NOP tightenings. This has been proposed before [1], and while I do not necessarily think the terms cited are necessarily complete, they admit the low resolution of our current terminology.
?
> Soft fork features can (and should) obviously be tested thoroughly on testnet, signet, custom signets, sidechains etc on a standalone basis and a bundled basis.
?
I vehemently disagree that any consensus changes should be bundled, especially when it comes to activation parameters. When we start to bundle things, we amplify the community resources needed to do review, not reduce them. I suspect your opinion here is largely informed by your frustration with the Taproot Activation procedure that you underwent earlier this year. This is understandable. However, let me present the alternative case. If we start to bundle features, the review of the features gets significantly harder. As the Bitcoin project scales, the ability of any one developer to understand the entire codebase declines. Bundling changes reduces the number of people who are qualified to review a particular proposal, and even worse, intimidates people who may be willing and able to review logically distinct portions of the proposal, resulting in lower amounts of review overall. This will likely have the opposite effect of what you seem to desire. BIP8 and BIP9 give us the ability to have multiple independent soft forks in flight at once. Choosing to bundle them instead makes little sense when we do not have to. Bundling them will inevitably degenerate into political horse trading and everyone will be worse off for it.
?
> part of the network disagrees on whether to activate the consensus change, part of the network disagrees on how to resist that consensus change, part of the network disagrees on how to activate that consensus change etc
?
Disagreements, and by extension, forks are a part of Bitcoin. What is important is that they are well defined and clean. This is the reason why the mandatory signaling period exists in BIP8/9, so that clients that intend to reject the soft fork change have a very easy means of doing so in a clean break where consensus is clearly divergent. In accordance with this, consensus changes should be sequenced so that people can decide which sides of the forks they want to follow and that the economic reality can reorganize around that. If choose to bundle them, you have one of two outcomes: either consensus atomizes into a mist where people have different ideas of which subsets of a soft fork bundle they want to adopt, or what likely comes after is a reconvergence on the old client with none of the soft fork rules in place. This will lead to significantly more confusion as well given that with sufficient miner consensus some of the rules may stick anyway even if the rest of the user base reconverges on the old client.
?
It is quite likely less damaging to consensus to have frequent but strictly sequenced soft forks so that if one of the new rules is contentious the break can happen cleanly. That said, if Core or any other client wishes to cut a release of the software with the parameters bundled into a single release, that is a significantly?more palatable state of affairs, as you can still pipeline signaling and activation. However, the protocol itself adopting a tendency to activate unrelated proposals in bundles is a recipe for disaster.
?
?
Respectfully,
Keagan
?
?
[1]?https://www.truthcoin.info/blog/protocol-upgrade-terminology
On Sat, Oct 16, 2021 at 12:57 PM Michael Folkson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
> Interesting discussion.?Correct me if I'm wrong: but putting too many features together in one shot just can't make things harder to debug in production if something very unexpected happens.?It's a basic principle of software engineering.
?
Soft fork features can (and should) obviously be tested thoroughly on testnet, signet, custom signets, sidechains etc on a standalone basis and a bundled basis. But whether or not it is a basic principle of general software engineering kind of misses the point. Security critical software clearly isn't engineered in the same way as a new social media app. Bugs are easily reverted in a new social media app. A consensus change is extremely hard to revert and probably requires a hard fork, a level of central coordination we generally attempt to avoid and a speed of deployment that we also attempt to avoid. On top of that we aren't just dealing with security critical software. One of the most important objectives is to keep all the nodes on the network in consensus. Introducing a consensus change before we are comfortable there is community consensus for it is a massive effective bug in itself. The network can split in multiple ways e.g. part of the network disagrees on whether to activate the consensus change, part of the network disagrees on how to resist that consensus change, part of the network disagrees on how to activate that consensus change etc
?
In addition, a social media app can experiment in production whether Feature A works, whether Feature B works or whether Feature A and B work best together. In Bitcoin if we activate consensus Feature A, later decide we want consensus Feature B but find out that by previously activating Feature A we can't have Feature B (it is now unsafe to activate it) or its design now has to be suboptimal because we have to ensure it can safely work in the presence of Feature A we have made a mistake by activating Feature A in the first place. Decentralized security critical consensus changes are an emerging field in itself and really can't be treated like any other software project. This will become universally understood I'm sure over time.
?
?
-- Michael Folkson Email: michaelfolkson at protonmail.com Keybase: michaelfolkson PGP:?43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3
?
??????? Original Message ???????
On Friday, October 15th, 2021 at 1:43 AM, Felipe Micaroni Lalli via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
Interesting discussion. Correct me if I'm wrong: but putting too many features together in one shot just can't make things harder to debug in production if something very unexpected happens. It's a basic principle of software engineering.
?
Change. Deploy. Nothing bad happened? Change it a little more. Deployment.
Or: Change, change, change. Deploy. Did something bad happen? What change caused the problem?
On Thu, Oct 14, 2021 at 8:53 PM Anthony Towns via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
On Mon, Oct 11, 2021 at 12:12:58PM -0700, Jeremy via bitcoin-dev wrote:
> > ...?in this post I will argue against frequent soft forks with a single or
> minimal
> > set of features and instead argue for infrequent soft forks with batches
> > of features.
> I think this type of development has been discussed in the past and has been
> rejected.
> AJ:?- improvements: changes might not make everyone better off, but we
> ? ?don't want changes to screw anyone over either -- pareto
> ? ?improvements in economics, "first, do no harm", etc. (if we get this
> ? ?right, there's no need to make compromises and bundle multiple
> ? ?flawed proposals so that everyone's an equal mix of happy and
> ? ?miserable)
I don't think your conclusion above matches my opinion, for what it's
worth.
If you've got two features, A and B, where the game theory is:
?If A happens, I'm +100, You're -50
?If B happens, I'm -50, You're +100
then even though A+B is +50, +50, then I do think the answer should
generally be "think harder and come up with better proposals" rather than
"implement A+B as a bundle that makes us both +50".
_But_ if the two features are more like:
? If C happens, I'm +100, You're +/- 0
? If D happens, I'm +/- 0, You're +100
then I don't have a problem with bundling them together as a single
simultaneous activation of both C and D.
Also, you can have situations where things are better together,
that is:
? If E happens, we're both at +100
? If F happens, we're both at +50
? If E+F both happen, we're both at +9000
In general, I think combining proposals when the combination is better
than the individual proposals were is obviously good; and combining
related proposals into a single activation can be good if it is easier
to think about the ideas as a set.
It's only when you'd be rejecting the proposal on its own merits that
I think combining it with others is a bad idea in principle.
For specific examples, we bundled schnorr, Taproot, MAST, OP_SUCCESSx
and CHECKSIGADD together because they do have synergies like that; we
didn't bundle ANYPREVOUT and graftroot despite the potential synergies
because those features needed substantially more study.
The nulldummy soft-fork (bip 147) was deployed concurrently with
the segwit soft-fork (bip 141, 143), but I don't think there was any
particular synergy or need for those things to be combined, it just
reduced the overhead of two sets of activation signalling to one.
Note that the implementation code for nulldummy had already been merged
and were applied as relay policy well before activation parameters were
defined (May 2014 via PR#3843 vs Sep 2016 for PR#8636) let alone becoming
an active soft fork.
Cheers,
aj
_______________________________________________
bitcoin-dev mailing list
bitcoin-dev at lists.linuxfoundation.org
https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
_______________________________________________
bitcoin-dev mailing list
bitcoin-dev at lists.linuxfoundation.org
https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220101/b88be538/attachment-0001.html>

From jlrubin at mit.edu  Sat Jan  1 20:04:00 2022
From: jlrubin at mit.edu (Jeremy)
Date: Sat, 1 Jan 2022 12:04:00 -0800
Subject: [bitcoin-dev] [Pre-BIP] Fee Accounts
Message-ID: <CAD5xwhik6jVQpP2_ss7d5o+pPLsqDCHuaXG41AMKHVYhZMXF1w@mail.gmail.com>

Happy new years devs,

I figured I would share some thoughts for conceptual review that have been
bouncing around my head as an opportunity to clean up the fee paying
semantics in bitcoin "for good". The design space is very wide on the
approach I'll share, so below is just a sketch of how it could work which
I'm sure could be improved greatly.

Transaction fees are an integral part of bitcoin.

However, due to quirks of Bitcoin's transaction design, fees are a part of
the transactions that they occur in.

While this works in a "Bitcoin 1.0" world, where all transactions are
simple on-chain transfers, real world use of Bitcoin requires support for
things like Fee Bumping stuck transactions, DoS resistant Payment Channels,
and other long lived Smart Contracts that can't predict future fee rates.
Having the fees paid in band makes writing these contracts much more
difficult as you can't merely express the logic you want for the
transaction, but also the fees.

Previously, I proposed a special type of transaction called a "Sponsor"
which has some special consensus + mempool rules to allow arbitrarily
appending fees to a transaction to bump it up in the mempool.

As an alternative, we could establish an account system in Bitcoin as an
"extension block".

*Here's how it might work:*

1. Define a special anyone can spend output type that is a "fee account"
(e.g. segwit V2). Such outputs have a redeeming key and an amount
associated with them, but are overall anyone can spend.
2. All deposits to these outputs get stored in a separate UTXO database for
fee accounts
3. Fee accounts can sign only two kinds of transaction: A: a fee amount and
a TXID (or Outpoint?); B: a withdraw amount, a fee, and an address
4. These transactions are committed in an extension block merkle tree.
While the actual signature must cover the TXID/Outpoint, the committed data
need only cover the index in the block of the transaction. The public key
for account lookup can be recovered from the message + signature.
5. In any block, any of the fee account deposits can be: released into fees
if there is a corresponding tx; consolidated together to reduce the number
of utxos (this can be just an OP_TRUE no metadata needed); or released into
fees *and paid back* into the requested withdrawal key (encumbering a 100
block timeout). Signatures must be unique in a block.
6. Mempool logic is updated to allow attaching of account fee spends to
transactions, the mempool can restrict that an account is not allowed more
spend more than it's balance.

*But aren't accounts "bad"?*

Yes, accounts are bad. But these accounts are not bad, because any funds
withdrawn from the fee extension are fundamentally locked for 100 blocks as
a coinbase output, so there should be no issues with any series of reorgs.
Further, since there is no "rich state" for these accounts, the state
updates can always be applied in a conflict-free way in any order.


*Improving the privacy of this design:*

This design could likely be modified to implement something like
Tornado.cash or something else so that the fee account paying can be
unlinked from the transaction being paid for, improving privacy at the
expense of being a bit more expensive.

Other operations could be added to allow a trustless mixing to be done by
miners automatically where groups of accounts with similar values are
trustlessly  split into a common denominator and change, and keys are
derived via a verifiable stealth address like protocol (so fee balances can
be discovered by tracing the updates posted). These updates could also be
produced by individuals rather than miners, and miners could simply honor
them with better privacy. While a miner generating an update would be able
to deanonymize their mixes, if you have your account mixed several times by
independent miners that could potentially add sufficient privacy.

The LN can also be used with PTLCs to, in theory, have another individual
paid to sponsor a transaction on your behalf only if they reveal a valid
sig from their fee paying account, although under this model it's hard to
ensure that the owner doesn't pay a fee and then 'cancel' by withdrawing
the rest. However, this could be partly solved by using reputable fee
accounts (reputation could be measured somewhat decentralized-ly by
longevity of the account and transactions paid for historically).

*Scalability*

This design is fundamentally 'decent' for scalability because adding fees
to a transaction does not require adding inputs or outputs and does not
require tracking substantial amounts of new state.

Paying someone else to pay for you via the LN also helps make this more
efficient if the withdrawal issues can be fixed.

*Lightning:*

This type of design works really well for channels because the addition of
fees to e.g. a channel state does not require any sort of pre-planning
(e.g. anchors) or transaction flexibility (SIGHASH flags). This sort of
design is naturally immune to pinning issues since you could offer to pay a
fee for any TXID and the number of fee adding offers does not need to be
restricted in the same way the descendant transactions would need to be.

*Without a fork?*

This type of design could be done as a federated network that bribes miners
-- potentially even retroactively after a block is formed. That might be
sufficient to prove the concept works before a consensus upgrade is
deployed, but such an approach does mean there is a centralizing layer
interfering with normal mining.


Happy new year!!

Jeremy

--
@JeremyRubin <https://twitter.com/JeremyRubin>
<https://twitter.com/JeremyRubin>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220101/4cd5c38b/attachment.html>

From prayank at tutanota.de  Sat Jan  1 21:03:11 2022
From: prayank at tutanota.de (Prayank)
Date: Sat, 1 Jan 2022 22:03:11 +0100 (CET)
Subject: [bitcoin-dev] Nuke *notify options from Bitcoin Core
Message-ID: <MsMS0F9--3-2@tutanota.de>

Hello World,

What?

Remove all *notify options from Bitcoin Core (full node implementation used by 99% nodes)

Or one of the below:

notifications.dat
not use system() in runCommand()
Use a new setting in settings.json file, notifypolicy which is 0 by default (restricted) and can be set to 1 (unrestricted)

Why?

They can help attackers in doing almost anything on machines running Bitcoin Core with some social engineering.

How?

Everything is explained several times in different issues, PRs etc. to different people including few reviewers who even NACKed a PR that would help in adding such options but with some documentation. I won't comment much about the reviewers but some of them were clueless about issue and how things work.

Example: Calling something misleading and ludicrous when you don't even know what works in Windows shortcut and could not share one example of financial application https://github.com/bitcoin/bitcoin/issues/23412#issuecomment-1003496126

TL;DR

https://github.com/bitcoin/bitcoin/pull/23395#issuecomment-956353035

https://github.com/bitcoin/bitcoin/issues/23412#issuecomment-970480769

To be honest, neither I have energy left to highlight the importance of these issues nor most of the people look interested in this space to address it. This email is a part of my efforts to share things with everyone which I even tried with documentation. There is something seriously wrong if few people including maintainers acknowledge the issues with *notify options but nobody wants to fix it or document it, I will leave it for people to form their own opinions about it.

Last but not least I was even asked to not review and comment in https://github.com/bitcoin/bitcoin/pull/23395 when I was just responding to others. 

This will be helpful in my security project which was already shared in mailing list to highlight what users expect from developers and future of money, review process etc. and what is the ground reality.

Happy New Year

-- 
Prayank

A3B1 E430 2298 178F
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220101/f8eafc5e/attachment-0001.html>

From email at esotericnonsense.com  Sat Jan  1 22:57:57 2022
From: email at esotericnonsense.com (Daniel Edgecumbe)
Date: Sat, 01 Jan 2022 22:57:57 +0000
Subject: [bitcoin-dev] Nuke *notify options from Bitcoin Core
In-Reply-To: <MsMS0F9--3-2@tutanota.de>
References: <MsMS0F9--3-2@tutanota.de>
Message-ID: <6bc18fea-e5f4-4136-928f-019ac44bf390@www.fastmail.com>

I've looked at these PR's and they seem, frankly, bizarre.

You've essentially noticed that if an attacker can run commands on your system, they can run commands on your system.

If you can convince someone to run arbitrary commands, which is what a desktop shortcut or a command argument _is_ at a fundamental level, you own their system. I fail to see how this has anything to do with Core at all.

Daniel Edgecumbe | esotericnonsense
email at esotericnonsense.com | https://esotericnonsense.com

On Sat, Jan 1, 2022, at 21:03, Prayank via bitcoin-dev wrote:
> Hello World,
>
> What?
>
> Remove all *notify options from Bitcoin Core (full node implementation 
> used by 99% nodes)
>
> Or one of the below:
>
> notifications.dat
> not use system() in runCommand()
> Use a new setting in settings.json file, notifypolicy which is 0 by 
> default (restricted) and can be set to 1 (unrestricted)
>
> Why?
>
> They can help attackers in doing almost anything on machines running 
> Bitcoin Core with some social engineering.
>
> How?
>
> Everything is explained several times in different issues, PRs etc. to 
> different people including few reviewers who even NACKed a PR that 
> would help in adding such options but with some documentation. I won't 
> comment much about the reviewers but some of them were clueless about 
> issue and how things work.
>
> Example: Calling something misleading and ludicrous when you don't even 
> know what works in Windows shortcut and could not share one example of 
> financial application 
> https://github.com/bitcoin/bitcoin/issues/23412#issuecomment-1003496126
>
> TL;DR
>
> https://github.com/bitcoin/bitcoin/pull/23395#issuecomment-956353035
>
> https://github.com/bitcoin/bitcoin/issues/23412#issuecomment-970480769
>
> To be honest, neither I have energy left to highlight the importance of 
> these issues nor most of the people look interested in this space to 
> address it. This email is a part of my efforts to share things with 
> everyone which I even tried with documentation. There is something 
> seriously wrong if few people including maintainers acknowledge the 
> issues with *notify options but nobody wants to fix it or document it, 
> I will leave it for people to form their own opinions about it.
>
> Last but not least I was even asked to not review and comment in 
> https://github.com/bitcoin/bitcoin/pull/23395 when I was just 
> responding to others. 
>
> This will be helpful in my security project which was already shared in 
> mailing list to highlight what users expect from developers and future 
> of money, review process etc. and what is the ground reality.
>
> Happy New Year
>
> -- 
> Prayank
>
> A3B1 E430 2298 178F
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

From prayank at tutanota.de  Sat Jan  1 23:29:15 2022
From: prayank at tutanota.de (Prayank)
Date: Sun, 2 Jan 2022 00:29:15 +0100 (CET)
Subject: [bitcoin-dev] Nuke *notify options from Bitcoin Core
Message-ID: <MsMyRuH--3-2@tutanota.de>

Hi Daniel,

Not sure which PRs are you talking about, maybe you missed these points based on your understanding:

Lot of fancy things won't work in windows shortcut target

It is more suspicious even if you try, compared to something wrapped in *notify options provided by bitcoin core

This will not provide me option to run a command based on events like received transaction in wallet

*notify options provide some options that every malware is looking for

There is enough time to research more about the issue and respond with something new or that helps in documentation.

-- 
Prayank

A3B1 E430 2298 178F
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220102/9873c9f6/attachment.html>

From michaelfolkson at protonmail.com  Mon Jan  3 02:05:20 2022
From: michaelfolkson at protonmail.com (Michael Folkson)
Date: Mon, 03 Jan 2022 02:05:20 +0000
Subject: [bitcoin-dev] Stumbling into a contentious soft fork activation
	attempt
Message-ID: <XuO20TMFGBqz53WYWxi9bgAdB3iGmqEIUE84AupRxCpHQVd3-YbGVzZUFz21dOgb_AgwlGWaruzE8NGxhes6HCKHpRZLmL1d1kNu1yobAIU=@protonmail.com>

I have already expressed my arguments on the regularity of soft forks [0]. Having spent months of my time on Taproot activation last year attempting to get at least rough community consensus on the activation method it seems crazy to me that some want to do that again so soon after Taproot activation and somehow this time it will be plain sailing. (Spoiler: it won?t. Although Taproot safely activated there remain outstanding views ranging on whether BIP 8 or 9 variants of Speedy Trial should be used in future to Speedy Trial only being a short term stopgap that should not be repeated.) If OP_CTV is ready to go now and has overwhelming community support (I don?t think either is true) it should surely have been included in the Taproot soft fork (perhaps delayed) rather than going through the months of activation wrangling and community outreach twice.

I stated in that post:

?A contentious or disputed soft fork can be merged into a Bitcoin implementation at any time but doing this is opening the door to the schism, disruption and waste of developer hours that we saw in 2017. Personally I think we?ll see an attempt to activate a contentious soft fork at some point in the long term future (Murphy?s Law) but any attempt to do so should be strongly discouraged. It should be made clear to any individual(s) that attempt this of the knock on impacts and potential short term damage they are inflicting on the entire ecosystem. Longer term I have confidence in Bitcoin?s ability to survive whatever happens but allocating significant community resources to resist an unnecessary contentious soft fork (or even regular contentious soft forks) is not an optimal use of those resources.?

I am getting increasingly concerned that we are stumbling into this scenario three months after I wrote that post. One of many future soft fork proposals (as many will know) is BIP 119 [1] which is the enabling of a new opcode OP_CHECKTEMPLATEVERIFY (OP_CTV). It seems to me like the author and primary promoter of this proposal (Jeremy Rubin) is pushing for an imminent attempted activation of a soft fork containing exclusively OP_CTV [2]. To contrast with his approach, the authors and contributors of another future soft fork proposal (BIP 118 [3], SIGHASH_ANYPREVOUT) aren?t promoting an imminent soft fork activation attempt and instead are building out and testing one of the speculated use cases, eltoo payment channels [4]. Similar work has not been done for any of the speculated use cases of OP_CTV. Instead Jeremy is encouraging people to ?soft signal? for soft fork activation of OP_CTV presumably in the hope that the building out and testing of use cases can be completed post activation.

This is totally irresponsible in my view. A long list of speculated use cases means nothing on its own. I can propose a new opcode OP_MAGIC and claim it will cure cancer with no potential downsides and hence we should have a soft fork activating it as soon as possible. I would hope there would be sufficient skepticism that this proposal wouldn?t see the light of day. It is true that Jeremy has some rudimentary proofs of concept built but as any software engineer will tell you the vast majority of the challenges are encountered once you attempt to build out that proof of concept. Once you do you may realize that the tool (or opcode) you are using isn?t the right one for the job. Unlike adjusting a feature on a social media app adjusting a consensus change once it has been activated is trickier to put it mildly.

There are a number of other more interesting technical discussions to be had later (what kind of covenants we want and are able to enable safely on Bitcoin etc, how CTV compares to other covenant enabling proposals, to what extent activating CTV would impact future proposals) but I feel the top priority is to bring some attention to the danger of us stumbling into an attempted contentious soft fork activation attempt.

Jeremy has put up this site (https://utxos.org/signals/) which is collecting so-called ?soft signals?. I very much doubt anyone has a problem with Jeremy engaging with the community on his proposal and receiving feedback. However, the site currently states:

?The following organizations, individuals, or pools have communicated preference for and intent to support a BIP-119 activation attempt using reasonable parameters. These ?soft signals? are non-binding until an actual concrete proposal has been formed, but are useful for measuring community consensus.?

There have been a number of ?soft signals?, many expressing enthusiasm for the speculated use cases of OP_CTV. Personally I share that enthusiasm like I do with the prospect of curing cancer. But these soft signals seem as if they are going to be used to attempt to justify an imminent contentious soft fork attempt. The devil is in the details both with regards to wording like ?reasonable parameters? and the utility and safety of a new opcode. Indeed if you share my concerns that there has not been sufficient scrutiny and research on the long implications of this proposal I encourage you to register a soft signal of ?No? on the site like I have. You can always change it to ?Yes? if and when you support an imminent soft fork activation attempt containing exclusively OP_CTV. Enabling covenants on Bitcoin is a big step change with barely any existing research on the topic and attempting to rush it through by the back door so soon after Taproot activation should be resisted. To look at the ~200 lines of code for the opcode exclusively (of course this should be done too) in a vacuum without considering the broader implications is also incredibly shortsighted. The only thing stopping a descent into Ethereum style seat of our pants consensus changes is community vigilance. If we ever lose that we lose the foundation of this industry.

[0]: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-October/019535.html

[1]: https://github.com/bitcoin/bips/blob/master/bip-0119.mediawiki

[2]: https://rubin.io/bitcoin/2021/12/24/advent-27/

[3]: https://github.com/bitcoin/bips/blob/master/bip-0118.mediawiki

[4]: https://yakshaver.org/bitcoin/#anyprevout

--

Michael Folkson
Email: michaelfolkson at protonmail.com
Keybase: michaelfolkson
PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220103/bccea39a/attachment.html>

From prayank at tutanota.de  Tue Jan  4 11:53:32 2022
From: prayank at tutanota.de (Prayank)
Date: Tue, 4 Jan 2022 12:53:32 +0100 (CET)
Subject: [bitcoin-dev] Stumbling into a contentious soft fork activation
 attempt
Message-ID: <MsZvyxN--7-2@tutanota.de>

Hi Michael,

> If OP_CTV is ready to go now and has overwhelming community support (I don?t think either is true) it should surely have been included in the Taproot soft fork (perhaps delayed) rather than going through the months of activation wrangling and community outreach twice.

It should be ready to go in a few months IMO and makes no sense to bundle everything with Taproot soft fork. Things can remain separate and still considered good enough based on the changes proposed.


> It should be made clear to any individual(s) that attempt this of the knock on impacts and potential short term damage they are inflicting on the entire ecosystem.

I don't see any damage with a soft fork that is being discussed since years, documented properly, includes code for implementation and examples, recently got crowdfunding to incentivize review process and improve security.


> It seems to me like the author and primary promoter of this proposal (Jeremy Rubin) is pushing for an imminent attempted activation of a soft fork containing exclusively OP_CTV [2].

He is doing nothing unexpected and got reasons to support OP_CTV being implemented soon.


> To contrast with his approach, the authors and contributors of another future soft fork proposal (BIP 118 [3], SIGHASH_ANYPREVOUT) aren?t promoting an imminent soft fork activation attempt and instead are building out and testing one of the speculated use cases, eltoo payment channels [4].

Because its not ready?


> Similar work has not been done for any of the speculated use cases of OP_CTV.

There is no comparison between the two. If someone has worked on one of the speculated uses cases, it makes no difference.

If we still compare something because of our bias, maybe Sapio is something that would be more helpful for Bitcoin developers.


> Instead Jeremy is encouraging people to ?soft signal? for soft fork activation of OP_CTV presumably in the hope that the building out and testing of use cases can be completed post activation.

We had soft signals from mining pools for Taproot as well and still waiting for projects to use Taproot. Even miners signaling with speedy trial was not a guarantee they would follow new consensus rules later. I don't see anything wrong in looking for people who support a proposal and documenting it.


> This is totally irresponsible in my view. A long list of speculated use cases means nothing on its own. I can propose a new opcode OP_MAGIC and claim it will cure cancer with no potential downsides and hence we should have a soft fork activating it as soon as possible.

If I had to select between a soft fork without any use cases and one with use cases, I would go with the one that has some use cases with code, documentation etc. You should propose a new opcode but OP_CTV is not claiming to cure cancer.


> I would hope there would be sufficient skepticism that this proposal wouldn?t see the light of day.

I am confident this proposal will be used by lot of Bitcoin projects and improve privacy, security, decentralization, demand for block space etc.


> I feel the top priority is to bring some attention to the danger of us stumbling into an attempted contentious soft fork activation attempt.

I feel the danger is a few people able to stop soft forks that improve Bitcoin because of their bias and opinions which are mostly non-technical.


> Enabling covenants on Bitcoin is a big step change with barely any existing research on the topic and attempting to rush it through by the back door so soon after Taproot activation should be resisted.

Nobody has stopped anyone from doing research. There is no backdoor and everything is public. So soon? I am not sure if there are any issues with a soft fork in next few months if its ready.


-- 
Prayank

A3B1 E430 2298 178F
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220104/4987e2a4/attachment.html>

From decker.christian at gmail.com  Tue Jan  4 14:42:28 2022
From: decker.christian at gmail.com (Christian Decker)
Date: Tue, 04 Jan 2022 15:42:28 +0100
Subject: [bitcoin-dev] Stumbling into a contentious soft fork activation
	attempt
In-Reply-To: <MsZvyxN--7-2@tutanota.de>
References: <MsZvyxN--7-2@tutanota.de>
Message-ID: <87o84r7eaz.fsf@gmail.com>

Prayank via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> writes:
>> To contrast with his approach, the authors and contributors of
>> another future soft fork proposal (BIP 118 [3], SIGHASH_ANYPREVOUT)
>> aren?t promoting an imminent soft fork activation attempt and instead
>> are building out and testing one of the speculated use cases, eltoo
>> payment channels [4].
>
> Because its not ready?

Could you elaborate on this point? I keep seeing people mentioning this,
but I, as BIP co-author, have not seen any real pushback. For context
BIP118 was initially called `sighash_noinput` and it was mentioned at
least as far back as 2015 when Joseph and Tadje wrote about its
applications in the LN protocol. While writing eltoo we stumbled over an
alternative use, and decided to draft the formal proposal.

Once we saw that Taproot is likely to activate next, AJ started adapting
it to integrate nicely with Taproot, and renamed it to anyprevout.

I'd like to point out that the original noinput could be implemented
with as little as 3-5 lines of code in Bitcoin Core, and there are
experimental branches implementing APO, which isn't significantly more
complex than the original proposal.

In addition Richard Myers has implemented a PoC of eltoo on top of one
of these experimental branches. So with all this I don't see how APO
could be considered "not ready".

The reason that neither noinput nor APO have a section on activation is
that we want to allow bundling with other soft-forks, and we want to
minimize the surface for potential conflicts. Also as the Taproot
activation has shown activation is a whole another discussion, that is
mostly unrelated to the soft-fork being activated.

Why aren't we yelling about the advantages of APO over other soft-forks
or asking for immediate activation? Because we want to be respectful of
everyone's time. We know review capacity is very limited, and developer
time expensive. By now most devs will be aware of the many improvements
(on LN, eltoo, MPC, channel factories, statechains, spacechains, etc)
anyprevout would enable, so there is little point in annoying everyone
by constantly talking about it. The people interested in exploring this
venue are already working on it, and we just need to wait for an
opportune moment to start the activation discussion with other
soft-forks.

I also see people comparing OP_CTV with APO, which may or may not work
out in the end. It seems possible to emulate APO using OP_CTV, but at
what cost? APO does not have any overhead in the transaction size, which
is not the case for OP_CTV, and I therefore consider the two proposals
complementary, and not competing (APO does best what APO does best,
while OP_CTV enables use-cases beyond APO's scope). While I'd prefer APO
for eltoo, due to its lack of overhead, I'm also happy to go wih OP_CTV
if only one gets activated (But then why would we? We've done much more
obscure things to save bytes in a TX).

Finally I see people mentioning that APO is insufficient to get
eltoo. That's also not true, since in fact we can implement a poor-man's
version of eltoo right now:

 - When updating:
   - Iterate through all prior update TXs
   - Bind the new update TX to each of the prior ones
   - Sign using `sighash_all`
   - Collect all sinatures and send to peer (message size O(n), but
     semantics are preserved, while APO enable O(1) making it actually
     reasonable to implement).

There may be some extensions, such as layered commitments that may be
added at a later stage, but they are not required to get the first
versions off the ground. Pretending that they're required would be like
saying that the protocol in the LN paper hasn't changed since it was
first written (definitely not the case).

Overall I agree with Michael's sentiment that soft-fork activations have
to be carefully planned, and kept at a reasonable pace. This is in order
to ensure that the activated features will work as expected (building
PoCs is important here) and that review time is kept efficient (bundling
may help here). For these reasons we omitted the activation discussion
in BIP118 and have trimmed the proposal to the bare minimum.

Sorry for the longish rant, but I felt I needed to clarify this
situation a bit.

Cheers,
Christian

From michaelfolkson at protonmail.com  Tue Jan  4 14:15:04 2022
From: michaelfolkson at protonmail.com (Michael Folkson)
Date: Tue, 04 Jan 2022 14:15:04 +0000
Subject: [bitcoin-dev] Stumbling into a contentious soft fork activation
	attempt
In-Reply-To: <MsZvyxN--7-2@tutanota.de>
References: <MsZvyxN--7-2@tutanota.de>
Message-ID: <mS9BiAhDjDaA8BeRzKIJy7DggiCYkRuIaYISjT-G0v3fd88HDIiWS6UxUghkp-kA99Us1wxkNOyunsBnRVRClZcvgAgOSALl3RB_8z6YY-A=@protonmail.com>

> It should be ready to go in a few months IMO

What is this assessment based on? I am assuming you haven't done a code review of the opcode, you haven't coded up a real world use case of OP_CTV (or even a primitive proof of concept), you haven't thought about alternative proposals for any particular use case (vaults for example have multiple current alternative proposals and most likely many future ones). A new programming language (Sapio) sounds great but do you you need it for your use case rather than an alternative high level language like Minsc? Sapio makes use of Miniscript which hasn't been finalized yet or updated for Taproot. Surely that needs to be done first otherwise Sapio is built on top of something that isn't ready? When you make the claims such as a consensus change is ready to go the burden is on you to convince me and other skeptics why. The status quo is the default. "I think it is ready or will be ready" doesn't mean much unless you have done the work.

You are well aware of the review process in Core for non-consensus changes. For consensus changes you really should be digging even deeper, the bar should be higher and all questions you and others have should be explored in depth. It is not enough for one individual to say it is ready to be activated, anyone who is expressing that view should understand why the opcode has been designed in the way it has and why it is so important that we should dedicate months of community time to getting a single opcode activated this year.

I have more sympathy for those who don't follow Bitcoin Core development and Bitcoin Core review on an ongoing basis (note as I said that the bar for consensus changes should be significantly higher than a non-consensus PR). The use cases sound cool and the work is genuinely interesting. But honestly for someone who has followed Bitcoin Core development, review for a while now you really should know better than bandy around statements like "it should be ready to go in a few months" when you currently haven't scratched the surface on the utility and safety of this opcode. You regularly NACK Core PRs yet you seem willing to wave a consensus change through with no outstanding questions and zero skepticism.

> If I had to select between a soft fork without any use cases and one with use cases, I would go with the one that has some use cases with code, documentation etc. You should propose a new opcode but OP_CTV is not claiming to cure cancer.

Multiple proven built out use cases, sure. Multiple is better than single when you have done the work to ensure they are actually the right tool for those multiple use cases. This work hasn't been done on any of these use cases. The curing cancer analogy was used to elucidate the point that claims should be deeply explored rather than just accepted as true.

>> To contrast with his approach, the authors and contributors of another future soft fork proposal (BIP 118 [3], SIGHASH_ANYPREVOUT) aren?t promoting an imminent soft fork activation attempt and instead are building out and testing one of the speculated use cases, eltoo payment channels [4].

> Because its not ready?

As I said it is not ready because the ANYPREVOUT contributors are building out and testing a use case. The high bar on readiness should be applied to all proposals not merely the ones where the authors/contributors decide to impose a high bar themselves.

I don't really want to spend my year imploring people to dig deeper on this before indicating they support an imminent activation attempt. Some people don't have the understanding to dig deeper, some people don't have the time and some don't have either. However, if an activation of OP_CTV is attempted this year I am sure it will be contentious [0]. Anyone who cares about Bitcoin development and the ongoing technical work in a multitude of areas should be strongly against a contentious soft fork activation attempt wasting the time of developers and the entire ecosystem even if they don't have the understanding or time to appreciate the reasons why it is contentious.

As I understand there are IRC workshops next week on BIP 119 [1] that I'd encourage you to join so you can start getting into a position where you can engage with the skeptics on technical concerns. Regrettably (as I said I find this work interesting) I don't feel like I can participate because deployment and activation is being included and I think it is irresponsible to be discussing those at this point. In my view activation should not even be speculated upon until it is clear there is overwhelming community support for a soft fork being activated.

[0]: https://gist.github.com/michaelfolkson/352a503f4f9fc5de89af528d86a1b718
[1]: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-December/019719.html

--

Michael Folkson
Email: michaelfolkson at protonmail.com
Keybase: michaelfolkson
PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3

??????? Original Message ???????
On Tuesday, January 4th, 2022 at 11:53 AM, Prayank via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:

> Hi Michael,
>
>> If OP_CTV is ready to go now and has overwhelming community support (I don?t think either is true) it should surely have been included in the Taproot soft fork (perhaps delayed) rather than going through the months of activation wrangling and community outreach twice.
>
> It should be ready to go in a few months IMO and makes no sense to bundle everything with Taproot soft fork. Things can remain separate and still considered good enough based on the changes proposed.
>
>> It should be made clear to any individual(s) that attempt this of the knock on impacts and potential short term damage they are inflicting on the entire ecosystem.
>
> I don't see any damage with a soft fork that is being discussed since years, documented properly, includes code for implementation and examples, recently got crowdfunding to incentivize review process and improve security.
>
>> It seems to me like the author and primary promoter of this proposal (Jeremy Rubin) is pushing for an imminent attempted activation of a soft fork containing exclusively OP_CTV [2].
>
> He is doing nothing unexpected and got reasons to support OP_CTV being implemented soon.
>
>> To contrast with his approach, the authors and contributors of another future soft fork proposal (BIP 118 [3], SIGHASH_ANYPREVOUT) aren?t promoting an imminent soft fork activation attempt and instead are building out and testing one of the speculated use cases, eltoo payment channels [4].
>
> Because its not ready?
>
>> Similar work has not been done for any of the speculated use cases of OP_CTV.
>
> There is no comparison between the two. If someone has worked on one of the speculated uses cases, it makes no difference.
>
> If we still compare something because of our bias, maybe Sapio is something that would be more helpful for Bitcoin developers.
>
>> Instead Jeremy is encouraging people to ?soft signal? for soft fork activation of OP_CTV presumably in the hope that the building out and testing of use cases can be completed post activation.
>
> We had soft signals from mining pools for Taproot as well and still waiting for projects to use Taproot. Even miners signaling with speedy trial was not a guarantee they would follow new consensus rules later. I don't see anything wrong in looking for people who support a proposal and documenting it.
>
>> This is totally irresponsible in my view. A long list of speculated use cases means nothing on its own. I can propose a new opcode OP_MAGIC and claim it will cure cancer with no potential downsides and hence we should have a soft fork activating it as soon as possible.
>
> If I had to select between a soft fork without any use cases and one with use cases, I would go with the one that has some use cases with code, documentation etc. You should propose a new opcode but OP_CTV is not claiming to cure cancer.
>
>> I would hope there would be sufficient skepticism that this proposal wouldn?t see the light of day.
>
> I am confident this proposal will be used by lot of Bitcoin projects and improve privacy, security, decentralization, demand for block space etc.
>
>> I feel the top priority is to bring some attention to the danger of us stumbling into an attempted contentious soft fork activation attempt.
>
> I feel the danger is a few people able to stop soft forks that improve Bitcoin because of their bias and opinions which are mostly non-technical.
>
>> Enabling covenants on Bitcoin is a big step change with barely any existing research on the topic and attempting to rush it through by the back door so soon after Taproot activation should be resisted.
>
> Nobody has stopped anyone from doing research. There is no backdoor and everything is public. So soon? I am not sure if there are any issues with a soft fork in next few months if its ready.
>
> --
> Prayank
>
> A3B1 E430 2298 178F
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220104/f5766936/attachment-0001.html>

From prayank at tutanota.de  Tue Jan  4 15:06:28 2022
From: prayank at tutanota.de (Prayank)
Date: Tue, 4 Jan 2022 16:06:28 +0100 (CET)
Subject: [bitcoin-dev] Stumbling into a contentious soft fork activation
 attempt
In-Reply-To: <mS9BiAhDjDaA8BeRzKIJy7DggiCYkRuIaYISjT-G0v3fd88HDIiWS6UxUghkp-kA99Us1wxkNOyunsBnRVRClZcvgAgOSALl3RB_8z6YY-A=@protonmail.com>
References: <MsZvyxN--7-2@tutanota.de>
 <mS9BiAhDjDaA8BeRzKIJy7DggiCYkRuIaYISjT-G0v3fd88HDIiWS6UxUghkp-kA99Us1wxkNOyunsBnRVRClZcvgAgOSALl3RB_8z6YY-A=@protonmail.com>
Message-ID: <Ms_c8Dw--3-2@tutanota.de>

What I have done related to OP_CTV?

https://twitter.com/prayankgahlot/status/1456643891885592579

What am I currently working on that is not shared publicly and will do in next few weeks?

Review pull request 21702 and write contracts using Sapio based on few ideas that I already have.

What is this assessment based on?

A few months are enough for the recent bounty to find bugs if possible and other things pending to be completed.

> you haven't thought about alternative proposals for any particular use case (vaults for example have multiple current alternative proposals and most likely many future ones)

I have read enough about alternative proposals and some of them don't even compete with OP_CTV, they can all be implemented and complement each other. Vaults is not the only thing that I care about and it would be better if we don't assume about research done by others.

> A new programming language (Sapio) sounds great but do you you need it for your use case rather than an alternative high level language like Minsc? Sapio makes use of Miniscript which hasn't been finalized yet or updated for Taproot. Surely that needs to be done first otherwise Sapio is built on top of something that isn't ready? When you make the claims such as a consensus change is ready to go the burden is on you to convince me and other skeptics why. The status quo is the default. "I think it is ready or will be ready" doesn't mean much unless you have done the work.

TBH I am not against Miniscript and still waiting for its support in Core which might take another few years. I would love to have multiple programming languages so that application developers can decide what works best for them.

I don't understand what work are you expecting me to do in this case to share my opinion about a soft fork.

> It is not enough for one individual to say it is ready to be activated, anyone who is expressing that view should understand why the opcode has been designed in the way it has and why it is so important that we should dedicate months of community time to getting a single opcode activated this year.

I have dedicated enough time reading everything related to OP_CTV and discuss things that were posted earlier here by Jeremy Rubin. Not sure how many skeptics did the same or even tried to discuss anything until recent bounty was announced.

> You regularly NACK Core PRs yet you seem willing to wave a consensus change through with no outstanding questions and zero skepticism.

I would NACK and write the reasons in this pull request as well if I find any issues and PR author is not addressing them. I had lots of questions at conceptual level which have been answered on different platforms and I cannot document each conversation. Its a Concept ACK from me and none of the contributors could find any issues with PR right now so I don't want to stop people from improving Bitcoin.

> As I understand there are IRC workshops next week on BIP 119 [1] that I'd encourage you to join so you can start getting into a position where you can engage with the skeptics on technical concerns. Regrettably (as I said I find this work interesting) I don't feel like I can participate because deployment and activation is being included and I think it is irresponsible to be discussing those at this point. In my view activation should not even be speculated upon until it is clear there is overwhelming community support for a soft fork being activated.

I would be attending the workshops and had even requested Jeremy to use Twitch because it would help more people understand things with audio, screen sharing etc. I would love to see skeptics participate and discuss technical things.

> I don't feel like I can participate because deployment and activation is being included and I think it is irresponsible to be discussing those at this point.

If you don't participate in the workshops you might miss few things. However, either Jeremy or one of the participants will ensure they share the summary here or even logs would be available.

-- 
Prayank

A3B1 E430 2298 178F



Jan 4, 2022, 19:45 by michaelfolkson at protonmail.com:

> >?> It should be ready to go in a few months IMO
>
> What is this assessment based on? I am assuming you haven't done a code review of the opcode, you haven't coded up a real world use case of OP_CTV (or even a primitive proof of concept), you haven't thought about alternative proposals for any particular use case (vaults for example have multiple current alternative proposals and most likely many future ones). A new programming language (Sapio) sounds great but do you you need it for your use case rather than an alternative high level language like Minsc? Sapio makes use of Miniscript which hasn't been finalized yet or updated for Taproot. Surely that needs to be done first otherwise Sapio is built on top of something that isn't ready? When you make the claims such as a consensus change is ready to go the burden is on you to convince me and other skeptics why. The status quo is the default. "I think it is ready or will be ready" doesn't mean much unless you have done the work.
>
> You are well aware of the review process in Core for non-consensus changes. For consensus changes you really should be digging even deeper, the bar should be higher and all questions you and others have should be explored in depth. It is not enough for one individual to say it is ready to be activated, anyone who is expressing that view should understand why the opcode has been designed in the way it has and why it is so important that we should dedicate months of community time to getting a single opcode activated this year.
>
> I have more sympathy for those who don't follow Bitcoin Core development and Bitcoin Core review on an ongoing basis (note as I said that the bar for consensus changes should be significantly higher than a non-consensus PR). The use cases sound cool and the work is genuinely interesting. But honestly for someone who has followed Bitcoin Core development, review for a while now you really should know better than bandy around statements like "it should be ready to go in a few months" when you currently haven't scratched the surface on the utility and safety of this opcode. You regularly NACK Core PRs yet you seem willing to wave a consensus change through with no outstanding questions and zero skepticism.
>
> >?If I had to select between a soft fork without any use cases and one with use cases, I would go with the one that has some use cases with code, documentation etc. You should propose a new opcode but OP_CTV is not claiming to cure cancer.
>
> Multiple proven built out use cases, sure. Multiple is better than single when you have done the work to ensure they are actually the right tool for those multiple use cases. This work hasn't been done on any of these use cases. The curing cancer analogy was used to elucidate the point that claims should be deeply explored rather than just accepted as true.
>
> >> To contrast with his approach, the authors and contributors of another future soft fork proposal (BIP 118 [3], SIGHASH_ANYPREVOUT) aren?t promoting an imminent soft fork activation attempt and instead are building out and testing one of the speculated use cases, eltoo payment channels [4].
>
> > Because its not ready?
>
> As I said it is not ready because the ANYPREVOUT contributors are building out and testing a use case. The high bar on readiness should be applied to all proposals not merely the ones where the authors/contributors decide to impose a high bar themselves.
>
> I don't really want to spend my year imploring people to dig deeper on this before indicating they support an imminent activation attempt. Some people don't have the understanding to dig deeper, some people don't have the time and some don't have either. However, if an activation of OP_CTV is attempted this year I am sure it will be contentious [0]. Anyone who cares about Bitcoin development and the ongoing technical work in a multitude of areas should be strongly against a contentious soft fork activation attempt wasting the time of developers and the entire ecosystem even if they don't have the understanding or time to appreciate the reasons why it is contentious.
>
> As I understand there are IRC workshops next week on BIP 119 [1] that I'd encourage you to join so you can start getting into a position where you can engage with the skeptics on technical concerns. Regrettably (as I said I find this work interesting) I don't feel like I can participate because deployment and activation is being included and I think it is irresponsible to be discussing those at this point. In my view activation should not even be speculated upon until it is clear there is overwhelming community support for a soft fork being activated.
>
> [0]:?> https://gist.github.com/michaelfolkson/352a503f4f9fc5de89af528d86a1b718
> [1]:?> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-December/019719.html
>
> --> Michael FolksonEmail: michaelfolkson at protonmail.comKeybase: michaelfolksonPGP:?43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3
>
> ??????? Original Message ???????
>  On Tuesday, January 4th, 2022 at 11:53 AM, Prayank via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
>  
>
>> Hi Michael,
>>
>> > If OP_CTV is ready to go now and has overwhelming community support (I don?t think either is true) it should surely have been included in the Taproot soft fork (perhaps delayed) rather than going through the months of activation wrangling and community outreach twice.
>>
>> It should be ready to go in a few months IMO and makes no sense to bundle everything with Taproot soft fork. Things can remain separate and still considered good enough based on the changes proposed.
>>
>>
>> > It should be made clear to any individual(s) that attempt this of the knock on impacts and potential short term damage they are inflicting on the entire ecosystem.
>>
>> I don't see any damage with a soft fork that is being discussed since years, documented properly, includes code for implementation and examples, recently got crowdfunding to incentivize review process and improve security.
>>
>>
>> > It seems to me like the author and primary promoter of this proposal (Jeremy Rubin) is pushing for an imminent attempted activation of a soft fork containing exclusively OP_CTV [2].
>>
>> He is doing nothing unexpected and got reasons to support OP_CTV being implemented soon.
>>
>>
>> > To contrast with his approach, the authors and contributors of another future soft fork proposal (BIP 118 [3], SIGHASH_ANYPREVOUT) aren?t promoting an imminent soft fork activation attempt and instead are building out and testing one of the speculated use cases, eltoo payment channels [4].
>>
>> Because its not ready?
>>
>>
>> > Similar work has not been done for any of the speculated use cases of OP_CTV.
>>
>> There is no comparison between the two. If someone has worked on one of the speculated uses cases, it makes no difference.
>>
>> If we still compare something because of our bias, maybe Sapio is something that would be more helpful for Bitcoin developers.
>>
>>
>> > Instead Jeremy is encouraging people to ?soft signal? for soft fork activation of OP_CTV presumably in the hope that the building out and testing of use cases can be completed post activation.
>>
>> We had soft signals from mining pools for Taproot as well and still waiting for projects to use Taproot. Even miners signaling with speedy trial was not a guarantee they would follow new consensus rules later. I don't see anything wrong in looking for people who support a proposal and documenting it.
>>
>>
>> > This is totally irresponsible in my view. A long list of speculated use cases means nothing on its own. I can propose a new opcode OP_MAGIC and claim it will cure cancer with no potential downsides and hence we should have a soft fork activating it as soon as possible.
>>
>> If I had to select between a soft fork without any use cases and one with use cases, I would go with the one that has some use cases with code, documentation etc. You should propose a new opcode but OP_CTV is not claiming to cure cancer.
>>
>>
>> > I would hope there would be sufficient skepticism that this proposal wouldn?t see the light of day.
>>
>> I am confident this proposal will be used by lot of Bitcoin projects and improve privacy, security, decentralization, demand for block space etc.
>>
>>
>> > I feel the top priority is to bring some attention to the danger of us stumbling into an attempted contentious soft fork activation attempt.
>>
>> I feel the danger is a few people able to stop soft forks that improve Bitcoin because of their bias and opinions which are mostly non-technical.
>>
>>
>> > Enabling covenants on Bitcoin is a big step change with barely any existing research on the topic and attempting to rush it through by the back door so soon after Taproot activation should be resisted.
>>
>> Nobody has stopped anyone from doing research. There is no backdoor and everything is public. So soon? I am not sure if there are any issues with a soft fork in next few months if its ready.
>>
>>
>> -- 
>> Prayank
>>
>> A3B1 E430 2298 178F
>>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220104/837014b9/attachment-0001.html>

From prayank at tutanota.de  Tue Jan  4 15:45:11 2022
From: prayank at tutanota.de (Prayank)
Date: Tue, 4 Jan 2022 16:45:11 +0100 (CET)
Subject: [bitcoin-dev] Stumbling into a contentious soft fork activation
 attempt
In-Reply-To: <87o84r7eaz.fsf@gmail.com>
References: <MsZvyxN--7-2@tutanota.de> <87o84r7eaz.fsf@gmail.com>
Message-ID: <Ms_l-H3--3-2@tutanota.de>

Hi Christian,

A few things are mentioned in these threads including unsolved research issues in which you were tagged and Richard Myers had even replied so I am assuming this is known:

https://twitter.com/JeremyRubin/status/1460349481518465025

https://twitter.com/ajtowns/status/1477586002252238850

> I also see people comparing OP_CTV with APO, which may or may not work
out in the end.

Michael Folkson did in the first email for this thread: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019728.html

> I therefore consider the two proposals complementary

Agree

> I'm also happy to go wih OP_CTV if only one gets activated (But then why would we? We've done much more obscure things to save bytes in a TX).

Maybe we can activate one that does more than just eltoo and see how things work. If APO is still required for eltoo, there would be clear consensus for APO.


-- 
Prayank

A3B1 E430 2298 178F



Jan 4, 2022, 20:12 by decker.christian at gmail.com:

> Prayank via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> writes:
>
>>> To contrast with his approach, the authors and contributors of
>>> another future soft fork proposal (BIP 118 [3], SIGHASH_ANYPREVOUT)
>>> aren?t promoting an imminent soft fork activation attempt and instead
>>> are building out and testing one of the speculated use cases, eltoo
>>> payment channels [4].
>>>
>>
>> Because its not ready?
>>
>
> Could you elaborate on this point? I keep seeing people mentioning this,
> but I, as BIP co-author, have not seen any real pushback. For context
> BIP118 was initially called `sighash_noinput` and it was mentioned at
> least as far back as 2015 when Joseph and Tadje wrote about its
> applications in the LN protocol. While writing eltoo we stumbled over an
> alternative use, and decided to draft the formal proposal.
>
> Once we saw that Taproot is likely to activate next, AJ started adapting
> it to integrate nicely with Taproot, and renamed it to anyprevout.
>
> I'd like to point out that the original noinput could be implemented
> with as little as 3-5 lines of code in Bitcoin Core, and there are
> experimental branches implementing APO, which isn't significantly more
> complex than the original proposal.
>
> In addition Richard Myers has implemented a PoC of eltoo on top of one
> of these experimental branches. So with all this I don't see how APO
> could be considered "not ready".
>
> The reason that neither noinput nor APO have a section on activation is
> that we want to allow bundling with other soft-forks, and we want to
> minimize the surface for potential conflicts. Also as the Taproot
> activation has shown activation is a whole another discussion, that is
> mostly unrelated to the soft-fork being activated.
>
> Why aren't we yelling about the advantages of APO over other soft-forks
> or asking for immediate activation? Because we want to be respectful of
> everyone's time. We know review capacity is very limited, and developer
> time expensive. By now most devs will be aware of the many improvements
> (on LN, eltoo, MPC, channel factories, statechains, spacechains, etc)
> anyprevout would enable, so there is little point in annoying everyone
> by constantly talking about it. The people interested in exploring this
> venue are already working on it, and we just need to wait for an
> opportune moment to start the activation discussion with other
> soft-forks.
>
> I also see people comparing OP_CTV with APO, which may or may not work
> out in the end. It seems possible to emulate APO using OP_CTV, but at
> what cost? APO does not have any overhead in the transaction size, which
> is not the case for OP_CTV, and I therefore consider the two proposals
> complementary, and not competing (APO does best what APO does best,
> while OP_CTV enables use-cases beyond APO's scope). While I'd prefer APO
> for eltoo, due to its lack of overhead, I'm also happy to go wih OP_CTV
> if only one gets activated (But then why would we? We've done much more
> obscure things to save bytes in a TX).
>
> Finally I see people mentioning that APO is insufficient to get
> eltoo. That's also not true, since in fact we can implement a poor-man's
> version of eltoo right now:
>
>  - When updating:
>  - Iterate through all prior update TXs
>  - Bind the new update TX to each of the prior ones
>  - Sign using `sighash_all`
>  - Collect all sinatures and send to peer (message size O(n), but
>  semantics are preserved, while APO enable O(1) making it actually
>  reasonable to implement).
>
> There may be some extensions, such as layered commitments that may be
> added at a later stage, but they are not required to get the first
> versions off the ground. Pretending that they're required would be like
> saying that the protocol in the LN paper hasn't changed since it was
> first written (definitely not the case).
>
> Overall I agree with Michael's sentiment that soft-fork activations have
> to be carefully planned, and kept at a reasonable pace. This is in order
> to ensure that the activated features will work as expected (building
> PoCs is important here) and that review time is kept efficient (bundling
> may help here). For these reasons we omitted the activation discussion
> in BIP118 and have trimmed the proposal to the bare minimum.
>
> Sorry for the longish rant, but I felt I needed to clarify this
> situation a bit.
>
> Cheers,
> Christian
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220104/033290d3/attachment.html>

From michaelfolkson at protonmail.com  Tue Jan  4 16:48:08 2022
From: michaelfolkson at protonmail.com (Michael Folkson)
Date: Tue, 04 Jan 2022 16:48:08 +0000
Subject: [bitcoin-dev] Stumbling into a contentious soft fork activation
	attempt
In-Reply-To: <Ms_c8Dw--3-2@tutanota.de>
References: <MsZvyxN--7-2@tutanota.de>
 <mS9BiAhDjDaA8BeRzKIJy7DggiCYkRuIaYISjT-G0v3fd88HDIiWS6UxUghkp-kA99Us1wxkNOyunsBnRVRClZcvgAgOSALl3RB_8z6YY-A=@protonmail.com>
 <Ms_c8Dw--3-2@tutanota.de>
Message-ID: <Em6eiOmLzenkLBlDBHquuiK4rE60qno3pHirzBQYHG9r9zqpK5nexun38eoRaC9wEDogPKVc4SPJ6ScNL-KDkx8CW4i4fuV9bB8x-G8bHq0=@protonmail.com>

You are working on a use case of OP_CTV now? Cool, you only recently announced you were working on Bitcoin Knots (and I think Wasabi before that) so I'm losing track of all the announcements. Regardless stick with it and build out more than a rudimentary proof of concept. That is one of the things that is severely lacking at this point for OP_CTV.

> TBH I am not against Miniscript and still waiting for its support in Core which might take another few years. I would love to have multiple programming languages so that application developers can decide what works best for them.

I would hope you weren't against Miniscript because Sapio is built on top of it :) But whatever have fun, I can't do this all day.

--

Michael Folkson
Email: michaelfolkson at protonmail.com
Keybase: michaelfolkson
PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3

??????? Original Message ???????
On Tuesday, January 4th, 2022 at 3:06 PM, Prayank <prayank at tutanota.de> wrote:

> What I have done related to OP_CTV?
>
> https://twitter.com/prayankgahlot/status/1456643891885592579
>
> What am I currently working on that is not shared publicly and will do in next few weeks?
>
> Review pull request 21702 and write contracts using Sapio based on few ideas that I already have.
>
> What is this assessment based on?
>
> A few months are enough for the recent bounty to find bugs if possible and other things pending to be completed.
>
>> you haven't thought about alternative proposals for any particular use case (vaults for example have multiple current alternative proposals and most likely many future ones)
>
> I have read enough about alternative proposals and some of them don't even compete with OP_CTV, they can all be implemented and complement each other. Vaults is not the only thing that I care about and it would be better if we don't assume about research done by others.
>
>> A new programming language (Sapio) sounds great but do you you need it for your use case rather than an alternative high level language like Minsc? Sapio makes use of Miniscript which hasn't been finalized yet or updated for Taproot. Surely that needs to be done first otherwise Sapio is built on top of something that isn't ready? When you make the claims such as a consensus change is ready to go the burden is on you to convince me and other skeptics why. The status quo is the default. "I think it is ready or will be ready" doesn't mean much unless you have done the work.
>
> TBH I am not against Miniscript and still waiting for its support in Core which might take another few years. I would love to have multiple programming languages so that application developers can decide what works best for them.
>
> I don't understand what work are you expecting me to do in this case to share my opinion about a soft fork.
>
>> It is not enough for one individual to say it is ready to be activated, anyone who is expressing that view should understand why the opcode has been designed in the way it has and why it is so important that we should dedicate months of community time to getting a single opcode activated this year.
>
> I have dedicated enough time reading everything related to OP_CTV and discuss things that were posted earlier here by Jeremy Rubin. Not sure how many skeptics did the same or even tried to discuss anything until recent bounty was announced.
>
>> You regularly NACK Core PRs yet you seem willing to wave a consensus change through with no outstanding questions and zero skepticism.
>
> I would NACK and write the reasons in this pull request as well if I find any issues and PR author is not addressing them. I had lots of questions at conceptual level which have been answered on different platforms and I cannot document each conversation. Its a Concept ACK from me and none of the contributors could find any issues with PR right now so I don't want to stop people from improving Bitcoin.
>
>> As I understand there are IRC workshops next week on BIP 119 [1] that I'd encourage you to join so you can start getting into a position where you can engage with the skeptics on technical concerns. Regrettably (as I said I find this work interesting) I don't feel like I can participate because deployment and activation is being included and I think it is irresponsible to be discussing those at this point. In my view activation should not even be speculated upon until it is clear there is overwhelming community support for a soft fork being activated.
>
> I would be attending the workshops and had even requested Jeremy to use Twitch because it would help more people understand things with audio, screen sharing etc. I would love to see skeptics participate and discuss technical things.
>
>> I don't feel like I can participate because deployment and activation is being included and I think it is irresponsible to be discussing those at this point.
>
> If you don't participate in the workshops you might miss few things. However, either Jeremy or one of the participants will ensure they share the summary here or even logs would be available.
>
> --
> Prayank
>
> A3B1 E430 2298 178F
>
> Jan 4, 2022, 19:45 by michaelfolkson at protonmail.com:
>
>>> It should be ready to go in a few months IMO
>>
>> What is this assessment based on? I am assuming you haven't done a code review of the opcode, you haven't coded up a real world use case of OP_CTV (or even a primitive proof of concept), you haven't thought about alternative proposals for any particular use case (vaults for example have multiple current alternative proposals and most likely many future ones). A new programming language (Sapio) sounds great but do you you need it for your use case rather than an alternative high level language like Minsc? Sapio makes use of Miniscript which hasn't been finalized yet or updated for Taproot. Surely that needs to be done first otherwise Sapio is built on top of something that isn't ready? When you make the claims such as a consensus change is ready to go the burden is on you to convince me and other skeptics why. The status quo is the default. "I think it is ready or will be ready" doesn't mean much unless you have done the work.
>>
>> You are well aware of the review process in Core for non-consensus changes. For consensus changes you really should be digging even deeper, the bar should be higher and all questions you and others have should be explored in depth. It is not enough for one individual to say it is ready to be activated, anyone who is expressing that view should understand why the opcode has been designed in the way it has and why it is so important that we should dedicate months of community time to getting a single opcode activated this year.
>>
>> I have more sympathy for those who don't follow Bitcoin Core development and Bitcoin Core review on an ongoing basis (note as I said that the bar for consensus changes should be significantly higher than a non-consensus PR). The use cases sound cool and the work is genuinely interesting. But honestly for someone who has followed Bitcoin Core development, review for a while now you really should know better than bandy around statements like "it should be ready to go in a few months" when you currently haven't scratched the surface on the utility and safety of this opcode. You regularly NACK Core PRs yet you seem willing to wave a consensus change through with no outstanding questions and zero skepticism.
>>
>>> If I had to select between a soft fork without any use cases and one with use cases, I would go with the one that has some use cases with code, documentation etc. You should propose a new opcode but OP_CTV is not claiming to cure cancer.
>>
>> Multiple proven built out use cases, sure. Multiple is better than single when you have done the work to ensure they are actually the right tool for those multiple use cases. This work hasn't been done on any of these use cases. The curing cancer analogy was used to elucidate the point that claims should be deeply explored rather than just accepted as true.
>>
>>>> To contrast with his approach, the authors and contributors of another future soft fork proposal (BIP 118 [3], SIGHASH_ANYPREVOUT) aren?t promoting an imminent soft fork activation attempt and instead are building out and testing one of the speculated use cases, eltoo payment channels [4].
>>
>>> Because its not ready?
>>
>> As I said it is not ready because the ANYPREVOUT contributors are building out and testing a use case. The high bar on readiness should be applied to all proposals not merely the ones where the authors/contributors decide to impose a high bar themselves.
>>
>> I don't really want to spend my year imploring people to dig deeper on this before indicating they support an imminent activation attempt. Some people don't have the understanding to dig deeper, some people don't have the time and some don't have either. However, if an activation of OP_CTV is attempted this year I am sure it will be contentious [0]. Anyone who cares about Bitcoin development and the ongoing technical work in a multitude of areas should be strongly against a contentious soft fork activation attempt wasting the time of developers and the entire ecosystem even if they don't have the understanding or time to appreciate the reasons why it is contentious.
>>
>> As I understand there are IRC workshops next week on BIP 119 [1] that I'd encourage you to join so you can start getting into a position where you can engage with the skeptics on technical concerns. Regrettably (as I said I find this work interesting) I don't feel like I can participate because deployment and activation is being included and I think it is irresponsible to be discussing those at this point. In my view activation should not even be speculated upon until it is clear there is overwhelming community support for a soft fork being activated.
>>
>> [0]: https://gist.github.com/michaelfolkson/352a503f4f9fc5de89af528d86a1b718
>> [1]: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-December/019719.html
>>
>> --
>>
>> Michael Folkson
>> Email: michaelfolkson at protonmail.com
>> Keybase: michaelfolkson
>> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3
>>
>> ??????? Original Message ???????
>> On Tuesday, January 4th, 2022 at 11:53 AM, Prayank via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
>>
>>> Hi Michael,
>>>
>>>> If OP_CTV is ready to go now and has overwhelming community support (I don?t think either is true) it should surely have been included in the Taproot soft fork (perhaps delayed) rather than going through the months of activation wrangling and community outreach twice.
>>>
>>> It should be ready to go in a few months IMO and makes no sense to bundle everything with Taproot soft fork. Things can remain separate and still considered good enough based on the changes proposed.
>>>
>>>> It should be made clear to any individual(s) that attempt this of the knock on impacts and potential short term damage they are inflicting on the entire ecosystem.
>>>
>>> I don't see any damage with a soft fork that is being discussed since years, documented properly, includes code for implementation and examples, recently got crowdfunding to incentivize review process and improve security.
>>>
>>>> It seems to me like the author and primary promoter of this proposal (Jeremy Rubin) is pushing for an imminent attempted activation of a soft fork containing exclusively OP_CTV [2].
>>>
>>> He is doing nothing unexpected and got reasons to support OP_CTV being implemented soon.
>>>
>>>> To contrast with his approach, the authors and contributors of another future soft fork proposal (BIP 118 [3], SIGHASH_ANYPREVOUT) aren?t promoting an imminent soft fork activation attempt and instead are building out and testing one of the speculated use cases, eltoo payment channels [4].
>>>
>>> Because its not ready?
>>>
>>>> Similar work has not been done for any of the speculated use cases of OP_CTV.
>>>
>>> There is no comparison between the two. If someone has worked on one of the speculated uses cases, it makes no difference.
>>>
>>> If we still compare something because of our bias, maybe Sapio is something that would be more helpful for Bitcoin developers.
>>>
>>>> Instead Jeremy is encouraging people to ?soft signal? for soft fork activation of OP_CTV presumably in the hope that the building out and testing of use cases can be completed post activation.
>>>
>>> We had soft signals from mining pools for Taproot as well and still waiting for projects to use Taproot. Even miners signaling with speedy trial was not a guarantee they would follow new consensus rules later. I don't see anything wrong in looking for people who support a proposal and documenting it.
>>>
>>>> This is totally irresponsible in my view. A long list of speculated use cases means nothing on its own. I can propose a new opcode OP_MAGIC and claim it will cure cancer with no potential downsides and hence we should have a soft fork activating it as soon as possible.
>>>
>>> If I had to select between a soft fork without any use cases and one with use cases, I would go with the one that has some use cases with code, documentation etc. You should propose a new opcode but OP_CTV is not claiming to cure cancer.
>>>
>>>> I would hope there would be sufficient skepticism that this proposal wouldn?t see the light of day.
>>>
>>> I am confident this proposal will be used by lot of Bitcoin projects and improve privacy, security, decentralization, demand for block space etc.
>>>
>>>> I feel the top priority is to bring some attention to the danger of us stumbling into an attempted contentious soft fork activation attempt.
>>>
>>> I feel the danger is a few people able to stop soft forks that improve Bitcoin because of their bias and opinions which are mostly non-technical.
>>>
>>>> Enabling covenants on Bitcoin is a big step change with barely any existing research on the topic and attempting to rush it through by the back door so soon after Taproot activation should be resisted.
>>>
>>> Nobody has stopped anyone from doing research. There is no backdoor and everything is public. So soon? I am not sure if there are any issues with a soft fork in next few months if its ready.
>>>
>>> --
>>> Prayank
>>>
>>> A3B1 E430 2298 178F
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220104/db180a35/attachment-0001.html>

From prayank at tutanota.de  Tue Jan  4 17:07:34 2022
From: prayank at tutanota.de (Prayank)
Date: Tue, 4 Jan 2022 18:07:34 +0100 (CET)
Subject: [bitcoin-dev] Stumbling into a contentious soft fork activation
 attempt
In-Reply-To: <Em6eiOmLzenkLBlDBHquuiK4rE60qno3pHirzBQYHG9r9zqpK5nexun38eoRaC9wEDogPKVc4SPJ6ScNL-KDkx8CW4i4fuV9bB8x-G8bHq0=@protonmail.com>
References: <MsZvyxN--7-2@tutanota.de>
 <mS9BiAhDjDaA8BeRzKIJy7DggiCYkRuIaYISjT-G0v3fd88HDIiWS6UxUghkp-kA99Us1wxkNOyunsBnRVRClZcvgAgOSALl3RB_8z6YY-A=@protonmail.com>
 <Ms_c8Dw--3-2@tutanota.de>
 <Em6eiOmLzenkLBlDBHquuiK4rE60qno3pHirzBQYHG9r9zqpK5nexun38eoRaC9wEDogPKVc4SPJ6ScNL-KDkx8CW4i4fuV9bB8x-G8bHq0=@protonmail.com>
Message-ID: <Msa2rJm--3-2@tutanota.de>

> You are working on a use case of OP_CTV now?

I think I mentioned clearly what I would be doing: 1. Review pull request 2. Create contracts with Sapio. This would help me review OP_CTV and learn new things.

> Cool, you only recently announced you were working on Bitcoin Knots (and I think Wasabi before that) so I'm losing track of all the announcements.

You can read more about my involvement in Bitcoin Knots here: https://github.com/bitcoinknots/bitcoin/discussions/39

I started working for zkSNACKs Wasabi 2 months back which can be confirmed with the team.

There are no announcements and humans can work on multiple things. You might want to check my next project which involves discreet log contracts as I have learnt a few things in bitcoin-s slack as well: https://gok.one/

For my involvement in other projects you can email me privately and I can share my resume.

-- 
Prayank

A3B1 E430 2298 178F



Jan 4, 2022, 22:18 by michaelfolkson at protonmail.com:

> You are working on a use case of OP_CTV now? Cool, you only recently announced you were working on Bitcoin Knots (and I think Wasabi before that) so I'm losing track of all the announcements. Regardless stick with it and build out more than a rudimentary proof of concept. That is one of the things that is severely lacking at this point for OP_CTV.
>
> >?TBH I am not against Miniscript and still waiting for its support in Core which might take another few years. I would love to have multiple programming languages so that application developers can decide what works best for them.
>
> I would hope you weren't against Miniscript because Sapio is built on top of it :) But whatever have fun, I can't do this all day.
>
>
> --> Michael FolksonEmail: michaelfolkson at protonmail.comKeybase: michaelfolksonPGP:?43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3
>
>
> ??????? Original Message ???????
>  On Tuesday, January 4th, 2022 at 3:06 PM, Prayank <prayank at tutanota.de> wrote:
>  
>
>> What I have done related to OP_CTV?
>>
>> https://twitter.com/prayankgahlot/status/1456643891885592579
>>
>> What am I currently working on that is not shared publicly and will do in next few weeks?
>>
>> Review pull request 21702 and write contracts using Sapio based on few ideas that I already have.
>>
>> What is this assessment based on?
>>
>> A few months are enough for the recent bounty to find bugs if possible and other things pending to be completed.
>>
>> > you haven't thought about alternative proposals for any particular use case (vaults for example have multiple current alternative proposals and most likely many future ones)
>>
>> I have read enough about alternative proposals and some of them don't even compete with OP_CTV, they can all be implemented and complement each other. Vaults is not the only thing that I care about and it would be better if we don't assume about research done by others.
>>
>> > A new programming language (Sapio) sounds great but do you you need it for your use case rather than an alternative high level language like Minsc? Sapio makes use of Miniscript which hasn't been finalized yet or updated for Taproot. Surely that needs to be done first otherwise Sapio is built on top of something that isn't ready? When you make the claims such as a consensus change is ready to go the burden is on you to convince me and other skeptics why. The status quo is the default. "I think it is ready or will be ready" doesn't mean much unless you have done the work.
>>
>> TBH I am not against Miniscript and still waiting for its support in Core which might take another few years. I would love to have multiple programming languages so that application developers can decide what works best for them.
>>
>> I don't understand what work are you expecting me to do in this case to share my opinion about a soft fork.
>>
>> > It is not enough for one individual to say it is ready to be activated, anyone who is expressing that view should understand why the opcode has been designed in the way it has and why it is so important that we should dedicate months of community time to getting a single opcode activated this year.
>>
>> I have dedicated enough time reading everything related to OP_CTV and discuss things that were posted earlier here by Jeremy Rubin. Not sure how many skeptics did the same or even tried to discuss anything until recent bounty was announced.
>>
>> > You regularly NACK Core PRs yet you seem willing to wave a consensus change through with no outstanding questions and zero skepticism.
>>
>> I would NACK and write the reasons in this pull request as well if I find any issues and PR author is not addressing them. I had lots of questions at conceptual level which have been answered on different platforms and I cannot document each conversation. Its a Concept ACK from me and none of the contributors could find any issues with PR right now so I don't want to stop people from improving Bitcoin.
>>
>> > As I understand there are IRC workshops next week on BIP 119 [1] that I'd encourage you to join so you can start getting into a position where you can engage with the skeptics on technical concerns. Regrettably (as I said I find this work interesting) I don't feel like I can participate because deployment and activation is being included and I think it is irresponsible to be discussing those at this point. In my view activation should not even be speculated upon until it is clear there is overwhelming community support for a soft fork being activated.
>>
>> I would be attending the workshops and had even requested Jeremy to use Twitch because it would help more people understand things with audio, screen sharing etc. I would love to see skeptics participate and discuss technical things.
>>
>> > I don't feel like I can participate because deployment and activation is being included and I think it is irresponsible to be discussing those at this point.
>>
>> If you don't participate in the workshops you might miss few things. However, either Jeremy or one of the participants will ensure they share the summary here or even logs would be available.
>>
>> -- 
>> Prayank
>>
>> A3B1 E430 2298 178F
>>
>>
>>
>> Jan 4, 2022, 19:45 by michaelfolkson at protonmail.com:
>>
>>> >?>>> It should be ready to go in a few months IMO
>>>
>>> What is this assessment based on? I am assuming you haven't done a code review of the opcode, you haven't coded up a real world use case of OP_CTV (or even a primitive proof of concept), you haven't thought about alternative proposals for any particular use case (vaults for example have multiple current alternative proposals and most likely many future ones). A new programming language (Sapio) sounds great but do you you need it for your use case rather than an alternative high level language like Minsc? Sapio makes use of Miniscript which hasn't been finalized yet or updated for Taproot. Surely that needs to be done first otherwise Sapio is built on top of something that isn't ready? When you make the claims such as a consensus change is ready to go the burden is on you to convince me and other skeptics why. The status quo is the default. "I think it is ready or will be ready" doesn't mean much unless you have done the work.
>>>
>>> You are well aware of the review process in Core for non-consensus changes. For consensus changes you really should be digging even deeper, the bar should be higher and all questions you and others have should be explored in depth. It is not enough for one individual to say it is ready to be activated, anyone who is expressing that view should understand why the opcode has been designed in the way it has and why it is so important that we should dedicate months of community time to getting a single opcode activated this year.
>>>
>>> I have more sympathy for those who don't follow Bitcoin Core development and Bitcoin Core review on an ongoing basis (note as I said that the bar for consensus changes should be significantly higher than a non-consensus PR). The use cases sound cool and the work is genuinely interesting. But honestly for someone who has followed Bitcoin Core development, review for a while now you really should know better than bandy around statements like "it should be ready to go in a few months" when you currently haven't scratched the surface on the utility and safety of this opcode. You regularly NACK Core PRs yet you seem willing to wave a consensus change through with no outstanding questions and zero skepticism.
>>>
>>> >?If I had to select between a soft fork without any use cases and one with use cases, I would go with the one that has some use cases with code, documentation etc. You should propose a new opcode but OP_CTV is not claiming to cure cancer.
>>>
>>> Multiple proven built out use cases, sure. Multiple is better than single when you have done the work to ensure they are actually the right tool for those multiple use cases. This work hasn't been done on any of these use cases. The curing cancer analogy was used to elucidate the point that claims should be deeply explored rather than just accepted as true.
>>>
>>> >> To contrast with his approach, the authors and contributors of another future soft fork proposal (BIP 118 [3], SIGHASH_ANYPREVOUT) aren?t promoting an imminent soft fork activation attempt and instead are building out and testing one of the speculated use cases, eltoo payment channels [4].
>>>
>>> > Because its not ready?
>>>
>>> As I said it is not ready because the ANYPREVOUT contributors are building out and testing a use case. The high bar on readiness should be applied to all proposals not merely the ones where the authors/contributors decide to impose a high bar themselves.
>>>
>>> I don't really want to spend my year imploring people to dig deeper on this before indicating they support an imminent activation attempt. Some people don't have the understanding to dig deeper, some people don't have the time and some don't have either. However, if an activation of OP_CTV is attempted this year I am sure it will be contentious [0]. Anyone who cares about Bitcoin development and the ongoing technical work in a multitude of areas should be strongly against a contentious soft fork activation attempt wasting the time of developers and the entire ecosystem even if they don't have the understanding or time to appreciate the reasons why it is contentious.
>>>
>>> As I understand there are IRC workshops next week on BIP 119 [1] that I'd encourage you to join so you can start getting into a position where you can engage with the skeptics on technical concerns. Regrettably (as I said I find this work interesting) I don't feel like I can participate because deployment and activation is being included and I think it is irresponsible to be discussing those at this point. In my view activation should not even be speculated upon until it is clear there is overwhelming community support for a soft fork being activated.
>>>
>>> [0]:?>>> https://gist.github.com/michaelfolkson/352a503f4f9fc5de89af528d86a1b718
>>> [1]:?>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-December/019719.html
>>>
>>> -->>> Michael FolksonEmail: michaelfolkson at protonmail.comKeybase: michaelfolksonPGP:?43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3
>>>
>>> ??????? Original Message ???????
>>> On Tuesday, January 4th, 2022 at 11:53 AM, Prayank via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
>>>
>>>
>>>> Hi Michael,
>>>>
>>>> > If OP_CTV is ready to go now and has overwhelming community support (I don?t think either is true) it should surely have been included in the Taproot soft fork (perhaps delayed) rather than going through the months of activation wrangling and community outreach twice.
>>>>
>>>> It should be ready to go in a few months IMO and makes no sense to bundle everything with Taproot soft fork. Things can remain separate and still considered good enough based on the changes proposed.
>>>>
>>>>
>>>> > It should be made clear to any individual(s) that attempt this of the knock on impacts and potential short term damage they are inflicting on the entire ecosystem.
>>>>
>>>> I don't see any damage with a soft fork that is being discussed since years, documented properly, includes code for implementation and examples, recently got crowdfunding to incentivize review process and improve security.
>>>>
>>>>
>>>> > It seems to me like the author and primary promoter of this proposal (Jeremy Rubin) is pushing for an imminent attempted activation of a soft fork containing exclusively OP_CTV [2].
>>>>
>>>> He is doing nothing unexpected and got reasons to support OP_CTV being implemented soon.
>>>>
>>>>
>>>> > To contrast with his approach, the authors and contributors of another future soft fork proposal (BIP 118 [3], SIGHASH_ANYPREVOUT) aren?t promoting an imminent soft fork activation attempt and instead are building out and testing one of the speculated use cases, eltoo payment channels [4].
>>>>
>>>> Because its not ready?
>>>>
>>>>
>>>> > Similar work has not been done for any of the speculated use cases of OP_CTV.
>>>>
>>>> There is no comparison between the two. If someone has worked on one of the speculated uses cases, it makes no difference.
>>>>
>>>> If we still compare something because of our bias, maybe Sapio is something that would be more helpful for Bitcoin developers.
>>>>
>>>>
>>>> > Instead Jeremy is encouraging people to ?soft signal? for soft fork activation of OP_CTV presumably in the hope that the building out and testing of use cases can be completed post activation.
>>>>
>>>> We had soft signals from mining pools for Taproot as well and still waiting for projects to use Taproot. Even miners signaling with speedy trial was not a guarantee they would follow new consensus rules later. I don't see anything wrong in looking for people who support a proposal and documenting it.
>>>>
>>>>
>>>> > This is totally irresponsible in my view. A long list of speculated use cases means nothing on its own. I can propose a new opcode OP_MAGIC and claim it will cure cancer with no potential downsides and hence we should have a soft fork activating it as soon as possible.
>>>>
>>>> If I had to select between a soft fork without any use cases and one with use cases, I would go with the one that has some use cases with code, documentation etc. You should propose a new opcode but OP_CTV is not claiming to cure cancer.
>>>>
>>>>
>>>> > I would hope there would be sufficient skepticism that this proposal wouldn?t see the light of day.
>>>>
>>>> I am confident this proposal will be used by lot of Bitcoin projects and improve privacy, security, decentralization, demand for block space etc.
>>>>
>>>>
>>>> > I feel the top priority is to bring some attention to the danger of us stumbling into an attempted contentious soft fork activation attempt.
>>>>
>>>> I feel the danger is a few people able to stop soft forks that improve Bitcoin because of their bias and opinions which are mostly non-technical.
>>>>
>>>>
>>>> > Enabling covenants on Bitcoin is a big step change with barely any existing research on the topic and attempting to rush it through by the back door so soon after Taproot activation should be resisted.
>>>>
>>>> Nobody has stopped anyone from doing research. There is no backdoor and everything is public. So soon? I am not sure if there are any issues with a soft fork in next few months if its ready.
>>>>
>>>>
>>>> -- 
>>>> Prayank
>>>>
>>>> A3B1 E430 2298 178F
>>>>
>>
>>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220104/5a1f5ce4/attachment-0001.html>

From jlrubin at mit.edu  Wed Jan  5 22:44:54 2022
From: jlrubin at mit.edu (Jeremy)
Date: Wed, 5 Jan 2022 14:44:54 -0800
Subject: [bitcoin-dev] Why CTV,
 why now? Was RE: Stumbling into a contentious soft fork activation
 attempt
Message-ID: <CAD5xwhg-uxvJ4BCEeo5h2BxvCo87xwZ6r7cT-=u5PT9yskpbJQ@mail.gmail.com>

Hi Devs,

There's a lot of noise in the other thread and it's hard to parse out what
merits a response or not without getting into a messy quagmire, so I
figured a separate email with high level points was the best way to respond.

Covenants are an important part of Bitcoin's future, not for "adding use
cases" but for making the fundamental pillars underlying Bitcoin more
robust. For example, covenants play a central role in privacy, scalability,
self custody, and decentralization (as I attempted to show in
https://rubin.io/advent21).

Bitcoin researchers have known about covenants conceptually for a long
time, but the implications and problems with them led to them being viewed
with heavy skepticism and concern for many years.

CTV was an output of my personal "research program" on how to make simple
covenant types without undue validation burdens. It is designed to be the
simplest and least risky covenant specification you can do that still
delivers sufficient flexibility and power to build many useful applications.

CTV has been under development for multiple years and the spec has been
essentially unmodified for 2 years (since the BIP was assigned a number).

CTV's specification is highly design specific to being a pre-committed
transaction. It'd be difficult to engineer an alternative for what it does
in a substantially different way.

CTV composes with potential future upgrades, such as OP_AMOUNT, CAT, CSFS,
TLUV. (See https://rubin.io/blog/2021/07/02/covenants/ and
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019423.html
)

CTV is non-rival (that means "both can happen") with any other upgrade
(e.g. APO, TLUV).

During the last 2 years, CTV has been reviewed by a wide range of folks and
there have not been (any?) conceptual or concrete NACKs for CTV to have or
introduce any risk or vulnerability to Bitcoin.

The main complaints about CTV are that we might come up with something
better eventually, a better system of things, or that CTV is not flexible
or general enough to make interesting applications, and it would be
unfortunate to go through with using up the 32 byte argument version of an
OP_NOP and the pains of any soft fork for something that we may eventually
know how to do better, replacing CTV.

More general approaches (e.g., based on CAT+CSFS) while more capability
powerful, have limitations given large script sizes and difficulty in
manipulating transactions and their outputs (e.g., Taproot outs requires
some OP_TWEAK as well), and are harder to reason about given higher degrees
of malleability.

During the last 2 years, while some other interesting concepts have arisen
(such as IIDs or TLUV), nothing in particular has fully overlapped CTV's
functionality, the closest being APO and they would both be valuable tools
to have independently.

During the last 2 years, no other proposal has reached the level of
"technical maturity" as CTV in terms of spec, implementation, testing,
tooling (rust miniscript integration, Sapio, python-vaults), and the
variety of applications demonstrated possible. As the saying goes, one in
the hand is worth two in the bush.

Many current users (not just end users, but businesses and protocol
developers as well) see CTV as delivering useful functionality for existing
applications despite its limitations (and some of those limitations emerge
as strengths). In particular, CTV is helpful for Lightning Network
companies to deliver non-custodial channels to more users and generally
improving wallet vault custody software.

Applications that are improved/enabled by CTV and not used today, like
Payment Pools, deliver strong privacy benefits. Privacy is something that
the longer we exist in a worse state, the harder it becomes to improve.
This is unlike e.g. scalability or self custody where improvements can be
made independent of previous activity. On the other hand, information leaks
from records of transactions are forever. There is more benefit from
reducing privacy leaks sooner than later. In other words, privacy is a path
dependent property not immediately upgradable to whatever current
technology provides.

Software Development is also path dependent. Many have remarked that there
is not great alternative research on other covenant proposals, but not many
application builders or protocol researchers are investing deep time and
expertise on producing alternative paths to covenants either. Accepting an
upgrade for limited covenants, like CTV, will give rise to many application
builders including covenants in their stack (e.g. for batching or vaults or
other applications) and will encourage more developers to contribute to
generic tooling (Sapio can be improved!) and also to -- via market
processes -- determine what other types of covenant would be safe and high
value for those already using CTV.

In my advocacy, I published the essay "Roadmap or Load o' Crap" (
https://rubin.io/bitcoin/2021/12/24/advent-27/), which presents a
hypothetical path for 'completing' BIP-119 this year and analyzes some
possible future work as well as the timeline viability of some alternatives
based on my best understandings. In this essay, I say very plainly:

*More ?regular contributors? would need to spend time reviewing the code
> and BIP to assure themselves of correctness and safety. Nothing can move
> forward without, no matter the count of casual contributors. Many regular
> contributors don?t want to ?get political? and look at forks. Fortunately,
> while all consensus changes are complex, CTV is a very tiny and easy to
> review change in comparison with SegWit or Taproot (more similar to
> CheckLockTimeVerify ? a couple hundred lines of consensus code, a couple
> hundred lines of non consensus code, and a couple thousand lines of tests,
> no cryptographic primitives). NOTE: This is a big if! Every contributor has
> the right to review, and ACK or provide a reasoned NACK. Even if everyone
> else is excited about something doesn?t mean there isn?t space for new
> thought-through dissent. At the end of the article, I discuss some concrete
> next steps to ensure more developer review occurs.*


Nowhere have I called for an imminent contentious soft fork attempt. All I
am doing is agitating for other developers to perform reviews. I recognize
that developers have limited time and individual priorities that may lead
them to prefer to spend time on improving Bitcoin in other ways, and I
would not call the soft fork process to bear for an upgrade that I did not
believe would yield large cross cutting benefits across a multitude of
interest areas. I've also plainly described that while "*there could be a
UASF for it, since there is strong user demand for CTV, ... I wouldn?t
personally lead the charge on that**...*". In no way am I endeavoring to
cause the community to take sides.

Lastly, and finally, I would like to close this email with a quote from my
Twitter from April '21
https://twitter.com/JeremyRubin/status/1384689155465089025

worth clarifying: I don't give a single fuck if BIP-119 CTV specifically is
> activated or not.



I want the functionality, in whatever form (eg noinput), to fix critical
> gaps in #Bitcoin's armor:



Decentralization.
> Scaling.
> Self Custody.
> Privacy.



let's. fucking. go.


This isn't an ego driven journey about getting in a feature I worked hard
on.

I couldn't care less.

This is about finding a pragmatic and low risk path to reinforcing
Bitcoin's fundamentals for the coming year.

This is about not resting on our laurels while we see properties critical
to Bitcoin erode.

Agree or disagree with CTV as the right next step, but we are all united in
wanting Bitcoin to be the best that it can be.

Best,

Jeremy

--
@JeremyRubin <https://twitter.com/JeremyRubin>
<https://twitter.com/JeremyRubin>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220105/29613da2/attachment.html>

From jlrubin at mit.edu  Mon Jan 10 07:59:18 2022
From: jlrubin at mit.edu (Jeremy)
Date: Sun, 9 Jan 2022 23:59:18 -0800
Subject: [bitcoin-dev] BIP-119 Meeting Reminder and Prelim Agenda
Message-ID: <CAD5xwhiMN7CFLOB7=my3JiA4mpPfH+pGqmCnbk_npEsKMUJtEw@mail.gmail.com>

Hi all,

As a reminder the first meeting for CTV will be this Tuesday at 12:00PM PT.

Based on feedback, I have included a preliminary agenda and time allocation
for the meeting at the end of this email. The main part of the meeting will
run for 1.5 hours, and will be followed by a post meeting discussion of
length 30 minutes for discussing broader next steps and consensus seeking
processes (this is separate to break up the technical review from the
metaphysics of consensus discussion and allow those who do not wish to
discuss a polite exit).

The agenda does not thoroughly cover motivations or use cases for CTV, such
as congestion control, vaults, payment pools, or non-interactive contract
openings. Those can be found in a multitude of sources (such as
https://rubin.io/advent21, https://learn.sapio-lang.org, https://utxos.org,
or https://github.com/kanzure/python-vaults/tree/master/vaults). Specific
applications built on CTV will be best reviewed in follow up meetings as
technical evaluation of how well CTV works for use cases requires a deep
understanding of how the CTV primitive works.

For similar reasons, this agenda does not do a deep dive into alternatives
to CTV. That discussion can be best had following a thorough review of CTV
itself. Helpful links for depthening understanding on covenant properties,
proposals, and varieties included below in a (loosely) recommended reading
order:
https://rubin.io/bitcoin/2021/12/04/advent-7/
https://rubin.io/bitcoin/2021/12/05/advent-8/
https://rubin.io/blog/2021/07/02/covenants/
https://utxos.org/alternatives/
https://arxiv.org/abs/2006.16714
https://rubin.io/bitcoin/2021/12/24/advent-27/
https://github.com/bitcoin/bips/blob/master/bip-0119.mediawiki#feature-redundancy
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019424.html


If you feel particular topics important to you are not represented in this
agenda or if I can make any improvements otherwise, please drop me a note
and I will endeavor to ensure they are either slotted into this meeting or
included in a second meeting.

That the meeting is tightly scheduled is by design: I want to respect
everyone's time and ensure that the meeting is highly productive. There is
always room for follow ups or further exploration at future meetings or as
mailing list follow ups.

Looking forward to discussing with you on tuesday,

Jeremy




*#topic Overview of BIP & Q&A (40 Mins)*
#subtopic what does CTV do? (5 minutes)

#subtopic which fields are in the digest? (5 minutes)

#subtopic the order / structure of fields in the digest? (5 minutes)

#subtopic the half-spend problem/solution? (5 minutes)

#subtopic using a NOP v.s. successX / legacy script types? (5 minutes)

#subtopic using sha256 v.s. Ripemd160 (5 minutes)

#subtopic general q&a (10 minutes)


*#topic Overview of Implementation & Testing (30 Minutes)*
#subtopic implementation walkthrough (15 minutes)

#subsubtopic validation burdens & caching (5 minutes)

#subtopic vectors: tx_valid.json + tx_invalid.json + transaction hashes
checking (2 minutes)

#subtopic functional test walkthrough (8 minutes)

*#topic Proposed Timeline Technical Feasibility (not advisibility) (10
minutes)*


*#topic Feedback on how to Structure Bounty Program (10 minutes)*
#post-meeting


*#topic open-ended feedback (is this meeting helpful, what could be better,
etc) (10 minutes)#topic What's required to get consensus / next steps? (20
minutes)*
#subtopic Discussion of "soft signals" utxos.org/signals (10 minutes)
#subtopic Discussion of activation mechanisms (10 minutes)



--
@JeremyRubin <https://twitter.com/JeremyRubin>
<https://twitter.com/JeremyRubin>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220109/35bb8366/attachment.html>

From pete at petertodd.org  Sun Jan  9 11:38:15 2022
From: pete at petertodd.org (Peter Todd)
Date: Sun, 9 Jan 2022 06:38:15 -0500
Subject: [bitcoin-dev] Stumbling into a contentious soft fork activation
 attempt
In-Reply-To: <XuO20TMFGBqz53WYWxi9bgAdB3iGmqEIUE84AupRxCpHQVd3-YbGVzZUFz21dOgb_AgwlGWaruzE8NGxhes6HCKHpRZLmL1d1kNu1yobAIU=@protonmail.com>
References: <XuO20TMFGBqz53WYWxi9bgAdB3iGmqEIUE84AupRxCpHQVd3-YbGVzZUFz21dOgb_AgwlGWaruzE8NGxhes6HCKHpRZLmL1d1kNu1yobAIU=@protonmail.com>
Message-ID: <YdrJJ3VxoxHVgg7Y@petertodd.org>

On Mon, Jan 03, 2022 at 02:05:20AM +0000, Michael Folkson via bitcoin-dev wrote:
> There have been a number of ?soft signals?, many expressing enthusiasm for the speculated use cases of OP_CTV. Personally I share that enthusiasm like I do with the prospect of curing cancer. But these soft signals seem as if they are going to be used to attempt to justify an imminent contentious soft fork attempt. The devil is in the details both with regards to wording like ?reasonable parameters? and the utility and safety of a new opcode. Indeed if you share my concerns that there has not been sufficient scrutiny and research on the long implications of this proposal I encourage you to register a soft signal of ?No? on the site like I have. You can always change it to ?Yes? if and when you support an imminent soft fork activation attempt containing exclusively OP_CTV. Enabling covenants on Bitcoin is a big step change with barely any existing research on the topic and attempting to rush it through by the back door so soon after Taproot activation should be resisted. To look at the ~200 lines of code for the opcode exclusively (of course this should be done too) in a vacuum without considering the broader implications is also incredibly shortsighted. The only thing stopping a descent into Ethereum style seat of our pants consensus changes is community vigilance. If we ever lose that we lose the foundation of this industry.

I have to second your objections.

I spent a bit of time over the past week looking at the current state of
OP_CTV/BIP-0119, and I too think it's a premature idea with an insufficient BIP
and reference implementation, that current lacks compelling use-cases clearly
beneficial to all users.

Remember that Bitcoin is a nearly $1 trillion network with tens of millions of
users that has gotten to that point with careful, conservative engineering.
Every change to the protocol poses risks to those users. Previous feature
upgrades to the Bitcoin protocol have always been done with the intent of
improving the protocol for everyone: CSV/segwit benefit all users via
Lightning, because we can reasonably all users to directly take advantage of
those features. We expect _everyone_ to benefit from Taproot via improved
privacy. I don't think CTV in its current form makes that case sufficiently,
and the technical details are lacking.



As for some more detailed thoughts, for clarify, I'm referring to:

https://github.com/bitcoin/bips/blob/3693cdfd192dacdac89cd742f68cd1bb96bf7f7e/bip-0119.mediawiki
https://github.com/JeremyRubin/bitcoin/tree/8f313d292e426a74d9ce28e5130bbf0cd48f867e

By no means is this a complete list of issues:

# DoS Attacks

Note how above I cited the git hashes to make it clear what exactly I'm
referring too: the fact that the reference implementation is listed as
https://github.com/JeremyRubin/bitcoin/tree/checktemplateverify in the BIP is
an immediate problem, as it's not clear what exactly is the specification.

This in turn matters quite a lot, because the BIP itself glosses over the quite
serious DoS attack issues involved in adding more ways that opcodes can hash
txs. Strong resistance to DoS attacks is a _mandatory_ aspect of all Bitcoin
script proposals, so leaving those details to a mostly uncommented reference
implementation without a clear discussion of those trade-offs is insufficient.


# Use Cases

As Folkson notes, these are barely fleshed out:

## Congestion Controlled Transactions

While this section appears somewhat fleshed out, with even a simulation, it
completely ignores the numerous practical issues like the need for
communication channels between wallets to inform them of the existence of these
batches. It also raises an important question: who needs this? On-chain
transactions are clearly not the future of Bitcoin and this use-case will
likely impact a small % of users.


## Wallet Vaults

This use-case can be easily tested, even in production, right now with
additional "oracle" signers that simply verify the CTV rules have been
followed.


## Payment Channels

These use-cases sound promising. But they all need to be clearly fleshed out as
actually taking advantage of them is quite complex.


## CoinJoin

> because participants agree on a single output which pays all participants,
> which will be lower fee than before

It is not clear how the fee will be lower, given that taking advantage of CTV
means there are more transactions, not less.


# Covenant Design Trade-Offs and Risks

> Covenants have historically been controversial given their potential for
> fungibility risks -- coins could be minted which have a permanent restriction
> on how they may or may not be spent or required to propagate metadata.

Indeed, this is a significant risk with the potential to harm all Bitcoin
users.

> In the CHECKTEMPLATEVERIFY approach, the covenants are severely restricted to
> simple templates. The structure of CHECKTEMPLATEVERIFY template is such that
> the outputs must be known exactly at the time of construction. Based on a
> destructuring argument, it is only possible to create templates which expand
> in a finite number of steps. Thus templated transactions are in theory as
> safe as transactions which create all the inputs directly in this regard.

The "finite" number of steps could be millions of transactions - "infinitely
long" for any practical purpose.


# Test Vectors

Currently the testing is poorly documented, without clear goals as to what edge
cases are actually being tested:
https://github.com/JeremyRubin/bitcoin/commit/e026bae28a774d91effc32862d0246286c114c24

Also, we really need test _vectors_ rather than a Python test: for consenus,
you want to write down explicitly the *data* in the form of serialized
transactions that is being fed into the consensus engine, to avoid mistakes in
test coverage due to broken test harnesses.

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220109/73c067be/attachment.sig>

From jlrubin at mit.edu  Tue Jan 11 03:42:50 2022
From: jlrubin at mit.edu (Jeremy)
Date: Mon, 10 Jan 2022 19:42:50 -0800
Subject: [bitcoin-dev] Stumbling into a contentious soft fork activation
	attempt
In-Reply-To: <YdrJJ3VxoxHVgg7Y@petertodd.org>
References: <XuO20TMFGBqz53WYWxi9bgAdB3iGmqEIUE84AupRxCpHQVd3-YbGVzZUFz21dOgb_AgwlGWaruzE8NGxhes6HCKHpRZLmL1d1kNu1yobAIU=@protonmail.com>
 <YdrJJ3VxoxHVgg7Y@petertodd.org>
Message-ID: <CAD5xwhi=H0Nft4Jbqhd3=89BhAB2JLoTc=mPhdcQkoQxa1sAUg@mail.gmail.com>

Hi Peter,

Thank you for your review and feedback.

Apologies for the difficulties in reviewing. The branch linked from the BIP
is not the latest, the branch in the PR is what should be considered
https://github.com/bitcoin/bitcoin/pull/21702 for review and has more
thorough well documented tests and test vectors. The version you reviewed
should still be compatible with the current branch as there have not been
any spec changes, though.

I'm not sure what best practice is w.r.t. linking to BIPs and
implementations given need to rebase and respond to feedback with changes.
Appreciate any pointers on how to better solve this. For the time being, I
will suggest an edit to point it to the PR, although I recognize this is
not ideal. I understand your preference for a commit hash and can do one if
it helps. For what it's worth, the taproot BIPs do not link to a reference
implementation of Taproot so I'm not sure what best practice is considered
these days.

One note that is unfortunate in your review is that there is a
discrepancy between the BIP and the implementation (the original reference
or the current PR either) in that caching and DoS is not addressed. This
was an explicit design goal of CTV and for it not to be mentioned in the
BIP (and just the reference) is an oversight on my part to not aid
reviewers more explicitly. Compounding this, I accepted a third-party PR to
make the BIP more clear as to what is required to implement it that does
not have caching (functional correctness), that exposes the issue if
implemented by the BIP directly and not by the reference implementation. I
have explained this in a review last year to pyskell
<https://github.com/bitcoin/bitcoin/pull/21702#discussion_r616853690> on
the PR that caching is required for non-DoS. I will add a note to the BIP
about the importance of caching to avoid DoS as that should make third
party implementers aware of the issue.

That said, this is not a mis-considered part of CTV. The reference
implementation is specifically designed to not have quadratic hashing and
CTV is designed to be friendly to caching to avoid denial of service. It's
just a part of the BIP that can be more clear. I will make a PR to more
clearly describe how that should happen.

------
use cases
------

One thing that's not clear to me is the amount of work a BIP needs to do
within itself to fully describe all applications and use cases. I don't
think it's appropriate for most BIPs to do so, but in some cases it is a
good idea. However, for CTV the applications actually are relatively
fleshed out, just outside the BIP. Further, the availability of generic
tooling through Sapio and it's examples has demonstrated how one might
build a variety of applications. See rubin.io/advent21 for numerous worked
examples.


## Congestion Controlled Transactions

Generally, the existence of these transactions can be tracked using
existing wallets if the transaction is seen in the mempool, it will be
marked as "mine" and can even be marked as "trusted". See
https://utxos.org/analysis/taxes/ which covers the legal obligations of
senders with respect to payees under congestion control. Generally, a
legally identifiable party such as an exchange sending a congestion control
payment must retain and serve it to the user to prove that they made
payment to the user. Users of said exchanges can either download a list of
their transactions at the time of withdrawal or they can wait to see it
e.g. in the mempool. This was also discussed at
https://diyhpl.us/wiki/transcripts/ctv-bip-review-workshop/ where you can
see notes/videos of what was discussed if the notes are hard to parse.

Lightning specific wallets such as Muun and LND particularly plan to use
CTV to batch-open a multitude of channels for users, using both congestion
control and non-interactive batching. Channels have to be opened on-chain
and if channels are to be the future so will on-chain opening of them.
These wallets can be built out to track and receive these opening proofs.

## Wallet Vaults

There exists at least 3 implementations of Vaults using CTV (one by me in
C++, one by me in Sapio, another by Bryan Bishop in python), and there
exist oracles as you mention for emulating it.

## Payment Channels

Actually taking advantage of them is quite simple and has been discussed
and reviewed with a number of independent lightning developers.

You can see here a rudimentary implementation and description of how it can
work https://rubin.io/bitcoin/2021/12/11/advent-14/.

This is composable with any `impl Revokable` channel update specification
so generalizes to Lightning.

Of course, making it production grade requires a lot of work, but the
concept is sound.


## CoinJoin


CTV trees may mean more transactions, not less, but if feerates are not
monotonic and CTV allows you to defer the utilization of chainspace.

CTV CoinJoins also open the opportunity to cooperation through payment
pools (which can be opened via a coinjoin), which saves further space.

The opportunity to use embedded non-interactive channels (technically, this
is a part of payment pools) also further decreases the urgency of getting a
UTXO out.

Lastly, while it is a slight privacy leak, CTV also allows coin-joiners of
different fee-priority levels to batch together where previously they would
not have incentive to (see https://utxos.org/analysis/batching_sim/). This
does use overall less chainspace total than if it is not incentive
compatible to batch together. While this is a slight privacy leak, it is
not that large since the batches would otherwise be unable to join together
(worse) and priority is still unlinked from the inputs. Further, priority
already leaks through the observability of coins being spent anyways.


# Covenant Design Trade-Offs and Risks

The important part is the the covenant -- regardless of its length -- must
be entirely known in advance. CTV is a fully enumerated non-recursive
validation-only non-dynamic state covenant. This limits the types of issues
that can arise.

Useful links:
https://medium.com/block-digest-mempool/my-worries-about-too-generalized-covenants-5eff33affbb6
https://rubin.io/bitcoin/2021/12/04/advent-7/

--
@JeremyRubin <https://twitter.com/JeremyRubin>
<https://twitter.com/JeremyRubin>


On Mon, Jan 10, 2022 at 10:31 AM Peter Todd via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> On Mon, Jan 03, 2022 at 02:05:20AM +0000, Michael Folkson via bitcoin-dev
> wrote:
> > There have been a number of ?soft signals?, many expressing enthusiasm
> for the speculated use cases of OP_CTV. Personally I share that enthusiasm
> like I do with the prospect of curing cancer. But these soft signals seem
> as if they are going to be used to attempt to justify an imminent
> contentious soft fork attempt. The devil is in the details both with
> regards to wording like ?reasonable parameters? and the utility and safety
> of a new opcode. Indeed if you share my concerns that there has not been
> sufficient scrutiny and research on the long implications of this proposal
> I encourage you to register a soft signal of ?No? on the site like I have.
> You can always change it to ?Yes? if and when you support an imminent soft
> fork activation attempt containing exclusively OP_CTV. Enabling covenants
> on Bitcoin is a big step change with barely any existing research on the
> topic and attempting to rush it through by the back door so soon after
> Taproot activation should be resisted. To look at the ~200 lines of code
> for the opcode exclusively (of course this should be done too) in a vacuum
> without considering the broader implications is also incredibly
> shortsighted. The only thing stopping a descent into Ethereum style seat of
> our pants consensus changes is community vigilance. If we ever lose that we
> lose the foundation of this industry.
>
> I have to second your objections.
>
> I spent a bit of time over the past week looking at the current state of
> OP_CTV/BIP-0119, and I too think it's a premature idea with an
> insufficient BIP
> and reference implementation, that current lacks compelling use-cases
> clearly
> beneficial to all users.
>
> Remember that Bitcoin is a nearly $1 trillion network with tens of
> millions of
> users that has gotten to that point with careful, conservative engineering.
> Every change to the protocol poses risks to those users. Previous feature
> upgrades to the Bitcoin protocol have always been done with the intent of
> improving the protocol for everyone: CSV/segwit benefit all users via
> Lightning, because we can reasonably all users to directly take advantage
> of
> those features. We expect _everyone_ to benefit from Taproot via improved
> privacy. I don't think CTV in its current form makes that case
> sufficiently,
> and the technical details are lacking.
>
>
>
> As for some more detailed thoughts, for clarify, I'm referring to:
>
>
> https://github.com/bitcoin/bips/blob/3693cdfd192dacdac89cd742f68cd1bb96bf7f7e/bip-0119.mediawiki
>
> https://github.com/JeremyRubin/bitcoin/tree/8f313d292e426a74d9ce28e5130bbf0cd48f867e
>
> By no means is this a complete list of issues:
>
> # DoS Attacks
>
> Note how above I cited the git hashes to make it clear what exactly I'm
> referring too: the fact that the reference implementation is listed as
> https://github.com/JeremyRubin/bitcoin/tree/checktemplateverify in the
> BIP is
> an immediate problem, as it's not clear what exactly is the specification.
>
> This in turn matters quite a lot, because the BIP itself glosses over the
> quite
> serious DoS attack issues involved in adding more ways that opcodes can
> hash
> txs. Strong resistance to DoS attacks is a _mandatory_ aspect of all
> Bitcoin
> script proposals, so leaving those details to a mostly uncommented
> reference
> implementation without a clear discussion of those trade-offs is
> insufficient.
>
>
> # Use Cases
>
> As Folkson notes, these are barely fleshed out:
>
> ## Congestion Controlled Transactions
>
> While this section appears somewhat fleshed out, with even a simulation, it
> completely ignores the numerous practical issues like the need for
> communication channels between wallets to inform them of the existence of
> these
> batches. It also raises an important question: who needs this? On-chain
> transactions are clearly not the future of Bitcoin and this use-case will
> likely impact a small % of users.
>
>
> ## Wallet Vaults
>
> This use-case can be easily tested, even in production, right now with
> additional "oracle" signers that simply verify the CTV rules have been
> followed.
>
>
> ## Payment Channels
>
> These use-cases sound promising. But they all need to be clearly fleshed
> out as
> actually taking advantage of them is quite complex.
>
>
> ## CoinJoin
>
> > because participants agree on a single output which pays all
> participants,
> > which will be lower fee than before
>
> It is not clear how the fee will be lower, given that taking advantage of
> CTV
> means there are more transactions, not less.
>
>
> # Covenant Design Trade-Offs and Risks
>
> > Covenants have historically been controversial given their potential for
> > fungibility risks -- coins could be minted which have a permanent
> restriction
> > on how they may or may not be spent or required to propagate metadata.
>
> Indeed, this is a significant risk with the potential to harm all Bitcoin
> users.
>
> > In the CHECKTEMPLATEVERIFY approach, the covenants are severely
> restricted to
> > simple templates. The structure of CHECKTEMPLATEVERIFY template is such
> that
> > the outputs must be known exactly at the time of construction. Based on a
> > destructuring argument, it is only possible to create templates which
> expand
> > in a finite number of steps. Thus templated transactions are in theory as
> > safe as transactions which create all the inputs directly in this regard.
>
> The "finite" number of steps could be millions of transactions -
> "infinitely
> long" for any practical purpose.
>
>
> # Test Vectors
>
> Currently the testing is poorly documented, without clear goals as to what
> edge
> cases are actually being tested:
>
> https://github.com/JeremyRubin/bitcoin/commit/e026bae28a774d91effc32862d0246286c114c24
>
> Also, we really need test _vectors_ rather than a Python test: for
> consenus,
> you want to write down explicitly the *data* in the form of serialized
> transactions that is being fed into the consensus engine, to avoid
> mistakes in
> test coverage due to broken test harnesses.
>
> --
> https://petertodd.org 'peter'[:-1]@petertodd.org
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220110/563cc209/attachment-0001.html>

From jlrubin at mit.edu  Tue Jan 11 04:38:42 2022
From: jlrubin at mit.edu (Jeremy)
Date: Mon, 10 Jan 2022 20:38:42 -0800
Subject: [bitcoin-dev] Stumbling into a contentious soft fork activation
	attempt
In-Reply-To: <CAD5xwhi=H0Nft4Jbqhd3=89BhAB2JLoTc=mPhdcQkoQxa1sAUg@mail.gmail.com>
References: <XuO20TMFGBqz53WYWxi9bgAdB3iGmqEIUE84AupRxCpHQVd3-YbGVzZUFz21dOgb_AgwlGWaruzE8NGxhes6HCKHpRZLmL1d1kNu1yobAIU=@protonmail.com>
 <YdrJJ3VxoxHVgg7Y@petertodd.org>
 <CAD5xwhi=H0Nft4Jbqhd3=89BhAB2JLoTc=mPhdcQkoQxa1sAUg@mail.gmail.com>
Message-ID: <CAD5xwhi9gveSgAp2Vuswzq8hXNLaUGjHeOb7LbyWq5_A_n9GMw@mail.gmail.com>

Please see the following bips PRs which are follow ups to the concrete
actionables raised by Peter. Thanks for bringing these up, it certainly
improves the reviewability of the BIP.

https://github.com/bitcoin/bips/pull/1271
https://github.com/bitcoin/bips/pull/1272

--
@JeremyRubin <https://twitter.com/JeremyRubin>
<https://twitter.com/JeremyRubin>


On Mon, Jan 10, 2022 at 7:42 PM Jeremy <jlrubin at mit.edu> wrote:

> Hi Peter,
>
> Thank you for your review and feedback.
>
> Apologies for the difficulties in reviewing. The branch linked from the
> BIP is not the latest, the branch in the PR is what should be considered
> https://github.com/bitcoin/bitcoin/pull/21702 for review and has more
> thorough well documented tests and test vectors. The version you reviewed
> should still be compatible with the current branch as there have not been
> any spec changes, though.
>
> I'm not sure what best practice is w.r.t. linking to BIPs and
> implementations given need to rebase and respond to feedback with changes.
> Appreciate any pointers on how to better solve this. For the time being, I
> will suggest an edit to point it to the PR, although I recognize this is
> not ideal. I understand your preference for a commit hash and can do one
> if it helps. For what it's worth, the taproot BIPs do not link to a
> reference implementation of Taproot so I'm not sure what best practice is
> considered these days.
>
> One note that is unfortunate in your review is that there is a
> discrepancy between the BIP and the implementation (the original reference
> or the current PR either) in that caching and DoS is not addressed. This
> was an explicit design goal of CTV and for it not to be mentioned in the
> BIP (and just the reference) is an oversight on my part to not aid
> reviewers more explicitly. Compounding this, I accepted a third-party PR to
> make the BIP more clear as to what is required to implement it that does
> not have caching (functional correctness), that exposes the issue if
> implemented by the BIP directly and not by the reference implementation. I
> have explained this in a review last year to pyskell
> <https://github.com/bitcoin/bitcoin/pull/21702#discussion_r616853690> on
> the PR that caching is required for non-DoS. I will add a note to the BIP
> about the importance of caching to avoid DoS as that should make third
> party implementers aware of the issue.
>
> That said, this is not a mis-considered part of CTV. The reference
> implementation is specifically designed to not have quadratic hashing and
> CTV is designed to be friendly to caching to avoid denial of service. It's
> just a part of the BIP that can be more clear. I will make a PR to more
> clearly describe how that should happen.
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220110/409e4fae/attachment.html>

From jack at squareup.com  Wed Jan 12 00:13:45 2022
From: jack at squareup.com (jack)
Date: Wed, 12 Jan 2022 00:13:45 +0000
Subject: [bitcoin-dev] Bitcoin Legal Defense Fund
Message-ID: <282EF45D-78A4-45E6-BCA2-3ADE6C8D4E11@squareup.com>

To Bitcoin Developers:

The Bitcoin community is currently the subject of multi-front litigation. Litigation and continued threats are having their intended effect; individual defendants have chosen to capitulate in the absence of legal support. Open-source developers, who are often independent, are especially susceptible to legal pressure. In response, we propose a coordinated and formalized response to help defend developers. The Bitcoin Legal Defense Fund is a nonprofit entity that aims to minimize legal headaches that discourage software developers from actively developing Bitcoin and related projects such as the Lightning Network, Bitcoin privacy protocols, and the like.

The main purpose of this Fund is to defend developers from lawsuits regarding their activities in the Bitcoin ecosystem, including finding and retaining defense counsel, developing litigation strategy, and paying legal bills. This is a free and voluntary option for developers to take advantage of if they so wish. The Fund will start with a corps of volunteer and part-time lawyers. The board of the Fund will be responsible for determining which lawsuits and defendants it will help defend.

The Fund?s first activities will be to take over coordination of the existing defense of the Tulip Trading lawsuit against certain developers alleging breach of fiduciary duty and provide the source of funding for outside counsel. At this time, the Fund is not seeking to raise additional money for its operations but will do so at the direction of the board if needed for further legal action or to pay for staff.

If you have questions or concerns, you can email info at bitcoindefensefund.org. Will share more information in the near future.

Sincerely,
Jack Dorsey, Alex Morcos, and Martin White
(Bitcoin Legal Defense Fund Board)

From r.pickhardt at googlemail.com  Wed Jan 12 00:47:41 2022
From: r.pickhardt at googlemail.com (=?UTF-8?Q?Ren=C3=A9_Pickhardt?=)
Date: Wed, 12 Jan 2022 01:47:41 +0100
Subject: [bitcoin-dev] Bitcoin Legal Defense Fund
In-Reply-To: <282EF45D-78A4-45E6-BCA2-3ADE6C8D4E11@squareup.com>
References: <282EF45D-78A4-45E6-BCA2-3ADE6C8D4E11@squareup.com>
Message-ID: <CAJ5H3Z7LhFzM4rY=h0H_0t+tFO80SuQ321-a8B-tE3HeWUN1Gw@mail.gmail.com>

jack via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> schrieb am
Mi., 12. Jan. 2022, 01:35:

> To Bitcoin Developers:
>
> Open-source developers, who are often independent, are especially
> susceptible to legal pressure.


Will the fund eventually also help to educate developers about the risks
they are facing and which measures can be taken to reduce such risks so
that legal pressure might not even arise in the first place?

The main purpose of this Fund is to defend developers from lawsuits
> regarding their activities in the Bitcoin ecosystem, including finding and
> retaining defense counsel, developing litigation strategy, and paying legal
> bills. This is a free and voluntary option for developers to take advantage
> of if they so wish.


Thank you!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220112/f8dc7cf8/attachment.html>

From ChristopherA at lifewithalacrity.com  Wed Jan 12 01:42:57 2022
From: ChristopherA at lifewithalacrity.com (Christopher Allen)
Date: Tue, 11 Jan 2022 17:42:57 -0800
Subject: [bitcoin-dev] Bitcoin Legal Defense Fund
In-Reply-To: <CAJ5H3Z7LhFzM4rY=h0H_0t+tFO80SuQ321-a8B-tE3HeWUN1Gw@mail.gmail.com>
References: <282EF45D-78A4-45E6-BCA2-3ADE6C8D4E11@squareup.com>
 <CAJ5H3Z7LhFzM4rY=h0H_0t+tFO80SuQ321-a8B-tE3HeWUN1Gw@mail.gmail.com>
Message-ID: <CACrqygAZiVDWTrhaoGVeA8PpGuAkMu6401Vw6bYOuCkmp0Sv0Q@mail.gmail.com>

On Tue, Jan 11, 2022 at 5:02 PM Ren? Pickhardt via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Will the fund eventually also help to educate developers about the risks
> they are facing and which measures can be taken to reduce such risks so
> that legal pressure might not even arise in the first place?
>

We (Blockchain Commons) have also started a project to document
best-practices of pseudonymous development. A work-in-progress but an
important part of our 2022 roadmap. Led by Namcios & myself, but we welcome
issues, review & contributions!

https://github.com/BlockchainCommons/Pseudonymity-Guide

? Christopher Allen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220111/6b0006d4/attachment.html>

From jlrubin at mit.edu  Wed Jan 12 08:23:19 2022
From: jlrubin at mit.edu (Jeremy)
Date: Wed, 12 Jan 2022 00:23:19 -0800
Subject: [bitcoin-dev] Summary of BIP-119 Meeting #1 Tuesday January 11th
Message-ID: <CAD5xwhhjm6AHEdXYrfmG08x8Hft4Jehjppd7GLaudmBhQ_FH=A@mail.gmail.com>

Hi Devs,

Below you'll find my summary of the BIP-119 Meeting held earlier today.

Overall the meeting was pleasant although fast paced. Thank you all for
attending and participating. I look forward to seeing (more of) you next
time!

Meeting notes available here:
https://gnusha.org/ctv-bip-review/2022-01-11.log, please check my work that
I've accurately reflected the opinions expressed. You'll also find the
notes instructive to peruse if you wish to use it as a guide for reviewing
the BIP.

Cheers,

Jeremy

*In brief:*
- CTV's design seems relatively uncontroversial/easy to comprehend.
- The desirability / suitability of CTV for its use cases still seemed
uncertain to participants.
- Among participants, there seemed to be sentiment that if we are to stick
to taproot speedy-trial like timelines, Springtime ('22, '23, ...) seems to
make sense.
- For the next meeting, the sessions will focus more heavily on
applications and will be slower paced.

*Detailed summary:*

*First participants noted what they were excited for CTV to do.*

Among participants in the meeting:
There was strong interest expressed in the Vaults use case by a number of
individuals.
There was lighter interest in non-interactive channels and payment pools.
There was strong skepticism expressed about congestion control; it was
noted that non-interactive channels+congestion control was a strong
motivator.

*Then, BIP review began:*

While reviewing the BIP:
Quadratic hashing during validation, and how CTV should be immune to it via
caching, was reviewed.
The costs and lifetime of PrecomputedData caching was reviewed.
A question was asked as to why the witness data was not in the CTV hash,
which was explained that it could prevent signatures from being used with
CTV.
The half-spend problem was explained and CTV's mitigations against it were
reviewed.

CTV's usage of a NOP was reviewed; after CTV 6 upgradable NOPs would
remain, it was pointed out that multibyte <version number> NOP10 could
extend the NOP space indefinitely (since CTV only uses 32-byte arguments,
CTV's NOP is only partly used).
Only adding CTV to tapscript (and not segwit v0, bare script, p2sh) was
discussed; no one expressed strongly that presence in legacy script was
problematic if there was a use for it -- i.e., let the market decide (since
some scripts are cheapest in bare script), although there seemed to be
agreement that you'd usually want Taproot.

It was clearly preferred that CTV use SHA256 and not RIPEMD160.

How big interactive protocols can get without DoS was discussed. CTV makes
non-interactive protocols possible, open question of if it matters. The
bulk of the benefit of a batch is in the first 10 participants (90%),
additional may not matter as much. It was agreed upon that CTV did at least
seem to make protocols asynchronous and non-interactive, once participants
agreed on what that terminology meant. A desire was expressed to see more
batched openings done in Lightning to see if/how CTV might help. *bonus:
Alex tweeted after the meeting about currently operational LN batched
opens, without congestion control
**https://twitter.com/alexbosworth/status/1481104624085917699
<https://twitter.com/alexbosworth/status/1481104624085917699>.*

*Then, Code Review began.*

First, the "main" BIP functionality commits were reviewed.

The current state of code coverage was discussed & improvements on that.
HandleMissingData remains difficult to code cover.
CTV's policy discouraging rules before activation were discussed, and how
this improves on prior soft forks not discouraging spends.
The TODO in the caching heuristic was discussed. The history of the
PrecomputedData caching heuristics was discussed, and how they became more
aggressive under taproot and that this might be a minor regression. It was
explained by the author that "TODO" meant someone could do something in the
future, not that something must be done now.

The bare CTV script type was discussed. The difference between legacy
script validation and standardness was discussed.
Bare CTV script does not (yet?) get it's own address type, but a standard
output type is still needed for relaying from internal services.
That it could be removed and added later was discussed, but that it causes
difficulty for testing was also mentioned.

Tests and test vectors were discussed.
A non blocking action item was raised to make our hex json test vectors
(for all Bitcoin) human readable was raised (otherwise, how do we know what
they do?).

*Then, discussion of the bug bounty began.*

An offer was made to make the administration of the program through a tax
deductible 501c3, Lincoln Network.
Difficulties were discussed in practical administration of the program
funds.
Desire was expressed to reward more than just 'showstopping' bugs, but also
strong reviews/minor issues/longer term maintenance.
Desire was expressed for a covenants-only Scaling Bitcoin like event.
Some discussion was had about bounties based around mutation testing, but
it was not clear how that might work for CTV specifically.


*Then, discussion of a release timelines began.*

*this discussion was disclaimed to be about what might be feasible, less so
the advisability of CTV in general.*

Discussion was had around either merging unactivated consensus code for CTV
ahead of the next feature freeze, delaying the next feature freeze slightly
if that is too tight, or delaying CTV.
The importance of backporting and relationship to merging unactivated code
was discussed.
Discussion was had around 'launch windows', and how, presupposing something
like ST, late spring release, summer signaling, and early Nov activation
seemed to be ideal. Such that if it cannot be done for this year, it might
entail waiting +1 year to fit nicely with release schedules and major
holidays.
A preference for late spring/early summer signaling, similar to taproot,
seemed uncontroversial.


*Then, the main meeting ended. And the post-meeting began:*

Some developers shared what their personal next steps were.
A review of current tested ACKs was done.
Kanzure forgot he implemented CTV Vaults 2 years ago :p
A review of literature / resources to learn about alternative covenants.

Activation mechanisms were discussed:
Updates to BIP-119 make clear that deployment is through whatever has
consensus, not necessarily ST.
Participants during the meeting quite like UASF as an option, but not as a
first option as it can be done in a follow-up release.



--
@JeremyRubin <https://twitter.com/JeremyRubin>
<https://twitter.com/JeremyRubin>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220112/6f3ddc64/attachment-0001.html>

From SatoshiSingh at protonmail.com  Wed Jan 12 09:59:07 2022
From: SatoshiSingh at protonmail.com (SatoshiSingh)
Date: Wed, 12 Jan 2022 09:59:07 +0000
Subject: [bitcoin-dev] Bitcoin Legal Defense Fund
Message-ID: <PgkH7Jx4gVyX0MdONFmDYq5Mp8-zV43pnHMrlrW1ESDNAa03D9B4U0YhJcoH0aWPFs9Gg3jdwKpoJqL2LhE1q7xZkHI3ZOZK7Iv4g0Zadfc=@protonmail.com>

> The main purpose of this Fund is to defend developers from lawsuits regarding their activities in the Bitcoin ecosystem, including finding and retaining defense counsel, developing litigation strategy, and paying legal bills.

Here in India we have the Internet Freedom Foundation that does something similar but for digital freedom and privacy. They've been supportive to bitcoin and it would be cool if we can include them in this.

https://internetfreedom.in/

Sent with [ProtonMail](https://protonmail.com/) Secure Email.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220112/067e06e6/attachment.html>

From jlrubin at mit.edu  Thu Jan 13 00:35:19 2022
From: jlrubin at mit.edu (Jeremy)
Date: Wed, 12 Jan 2022 16:35:19 -0800
Subject: [bitcoin-dev] OP_PUSH_KEY_* & BIP-118 0x01 Pun
Message-ID: <CAD5xwhjBjuV_doqWUe4AFxWO0GdiUPkOj7rub8woB57cD4WYcg@mail.gmail.com>

Hi Devs,

Two small transaction introspection opcodes that are worth considering are
OP_PUSH_KEY_INTERNAL or OP_PUSH_KEY_EXTERNAL which can return the taproot
key for the current input.

While the internal key could be included in the tree already, and this is
just a performance improvement, the external key creates a hash cycle and
is not possible to include directly.

This came up as a potential nicety while looking at how BIP-118 "puns" a
single 0x01 byte as a key argument to refer to the Internal key for
compactness. It would be more general if instead of 0x01, there were an
opcode that actually put the Internal key on the stack.

There is a small incompatibility with BIP-118 with this approach, which is
that keys are not tagged for APO-enablement. Thus, there should either be a
version of this opcode for APO tagged or not, or, APO should instead define
some CheckSig2 which has APO if tagging is still desired. (Or we could
abandon tagging keys too...)

It might be worth pursuing simplifying APO to use these OP_PUSH_KEY opcodes
because future plans for more generalized covenant might benefit from being
able to get the current key off the stack. For example, TLUV might be able
to be decomposed into simpler (RISC) opcodes for getting the internal key,
getting the current merkel path, and then manipulating it, then tweaking
the internal key.

The internal key might be useful for signing in a path not just for APO,
but also because you might want to sign e.g. a transaction that is
contingent on a HTLC scriptcode being satisfied. Because it is cheaper to
use the 0x01 CHECKSIG than doing a separate key (<pk> CHECKSIG), it also
causes an unintended side effect from APO of incentivizing not using a
unique key per branch (privacy loss) and incentivizing enabling an APO
tagged key where one is not required (unless 0x00, as I've noted elsewhere
is added to the 118 spec as a pun for an untagged key).

Pushing the external key's use is less obvious, but with the development of
future opcodes it would be helpful for some recursive covenants.

Both opcodes are very design specific -- there's only one choice of what
data they could push.

Of course, we could keep 118 spec'd as is, and add these PUSH_KEYs later if
ever desired redundantly with the Checksig puns.

Cheers,

Jeremy







--
@JeremyRubin <https://twitter.com/JeremyRubin>
<https://twitter.com/JeremyRubin>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220112/8cfdab01/attachment.html>

From jlrubin at mit.edu  Thu Jan 13 01:45:30 2022
From: jlrubin at mit.edu (Jeremy)
Date: Wed, 12 Jan 2022 17:45:30 -0800
Subject: [bitcoin-dev] OP_PUSH_KEY_* & BIP-118 0x01 Pun
In-Reply-To: <CAD5xwhjBjuV_doqWUe4AFxWO0GdiUPkOj7rub8woB57cD4WYcg@mail.gmail.com>
References: <CAD5xwhjBjuV_doqWUe4AFxWO0GdiUPkOj7rub8woB57cD4WYcg@mail.gmail.com>
Message-ID: <CAD5xwhibK4wQGRMvBKjBX_vnFTZpmoNQVWEYkBOF8buJTkqafQ@mail.gmail.com>

Note:

BIP-118 as-is enables something similar to OP_PUSH_KEY_INTERNAL_TAGGED via
the following script fragment:

witness: <internal pk> <sig>
program: DUP 0x01 CHECKSIG SWAP DUP TOALTSTACK CHECKSIG FROMALTSTACK


It's unclear how useful this might be, since the signature already covers
the transaction.

--
@JeremyRubin <https://twitter.com/JeremyRubin>
<https://twitter.com/JeremyRubin>


On Wed, Jan 12, 2022 at 4:35 PM Jeremy <jlrubin at mit.edu> wrote:

> Hi Devs,
>
> Two small transaction introspection opcodes that are worth considering are
> OP_PUSH_KEY_INTERNAL or OP_PUSH_KEY_EXTERNAL which can return the taproot
> key for the current input.
>
> While the internal key could be included in the tree already, and this is
> just a performance improvement, the external key creates a hash cycle and
> is not possible to include directly.
>
> This came up as a potential nicety while looking at how BIP-118 "puns" a
> single 0x01 byte as a key argument to refer to the Internal key for
> compactness. It would be more general if instead of 0x01, there were an
> opcode that actually put the Internal key on the stack.
>
> There is a small incompatibility with BIP-118 with this approach, which is
> that keys are not tagged for APO-enablement. Thus, there should either be a
> version of this opcode for APO tagged or not, or, APO should instead define
> some CheckSig2 which has APO if tagging is still desired. (Or we could
> abandon tagging keys too...)
>
> It might be worth pursuing simplifying APO to use these OP_PUSH_KEY
> opcodes because future plans for more generalized covenant might benefit
> from being able to get the current key off the stack. For example, TLUV
> might be able to be decomposed into simpler (RISC) opcodes for getting the
> internal key, getting the current merkel path, and then manipulating it,
> then tweaking the internal key.
>
> The internal key might be useful for signing in a path not just for APO,
> but also because you might want to sign e.g. a transaction that is
> contingent on a HTLC scriptcode being satisfied. Because it is cheaper to
> use the 0x01 CHECKSIG than doing a separate key (<pk> CHECKSIG), it also
> causes an unintended side effect from APO of incentivizing not using a
> unique key per branch (privacy loss) and incentivizing enabling an APO
> tagged key where one is not required (unless 0x00, as I've noted elsewhere
> is added to the 118 spec as a pun for an untagged key).
>
> Pushing the external key's use is less obvious, but with the development
> of future opcodes it would be helpful for some recursive covenants.
>
> Both opcodes are very design specific -- there's only one choice of what
> data they could push.
>
> Of course, we could keep 118 spec'd as is, and add these PUSH_KEYs later
> if ever desired redundantly with the Checksig puns.
>
> Cheers,
>
> Jeremy
>
>
>
>
>
>
>
> --
> @JeremyRubin <https://twitter.com/JeremyRubin>
> <https://twitter.com/JeremyRubin>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220112/edd033c7/attachment-0001.html>

From prayank at tutanota.de  Thu Jan 13 10:13:11 2022
From: prayank at tutanota.de (Prayank)
Date: Thu, 13 Jan 2022 11:13:11 +0100 (CET)
Subject: [bitcoin-dev] Bitcoin Legal Defense Fund
Message-ID: <MtHvJYE--J-2@tutanota.de>

Hi Jack,


>?The main purpose of this Fund is to defend developers from lawsuits regarding their activities in the Bitcoin ecosystem, including finding and retaining defense counsel, developing litigation strategy, and paying legal bills. This is a free and voluntary option for developers to take advantage of if they so wish. The Fund will start with a corps of volunteer and part-time lawyers. The board of the Fund will be responsible for determining which lawsuits and defendants it will help defend.

Thanks for helping the developers in legal issues. Appreciate your efforts and I understand your intentions are to help Bitcoin in every possible way.


Positives that I see in this initiative:

1.Developers don't need to worry about rich scammers and can focus on development.

2.Financial help for developers as legal issues can end up in wasting lot of time and money.

3.People who have misused courts to affect bitcoin developers will get better response that they deserve.


I had few suggestions and feel free to ignore them if they do not make sense:

1.Name of this fund could be anything and 'The Bitcoin Legal Defense Fund' can be confusing or misleading for newbies. There is nothing official in Bitcoin however people believe things written in news articles and some of them might consider it as an official bitcoin legal fund.

2.It would be better if people involved in such important funds do not comment/influence soft fork related discussions. Example: Alex Morcos had some opinions about activation mechanism during Taproot soft fork IIRC.



-- 
Prayank

A3B1 E430 2298 178F
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220113/17a38cb8/attachment.html>

From jack at squareup.com  Thu Jan 13 18:20:40 2022
From: jack at squareup.com (jack)
Date: Thu, 13 Jan 2022 18:20:40 +0000
Subject: [bitcoin-dev] Bitcoin Legal Defense Fund
In-Reply-To: <MtHvJYE--J-2@tutanota.de>
References: <MtHvJYE--J-2@tutanota.de>
Message-ID: <F3DA4333-E4BB-4A3F-B050-AA142465F2C8@squareup.com>

Hi Prayank,

> On 13 Jan 2022, at 10:13, Prayank <prayank at tutanota.de> wrote:
> I had few suggestions and feel free to ignore them if they do not make sense:
> 
> 1.Name of this fund could be anything and 'The Bitcoin Legal Defense Fund' can be confusing or misleading for newbies. There is nothing official in Bitcoin however people believe things written in news articles and some of them might consider it as an official bitcoin legal fund.

Excellent point. Will come up with a better name.

> 2.It would be better if people involved in such important funds do not comment/influence soft fork related discussions. Example: Alex Morcos had some opinions about activation mechanism during Taproot soft fork IIRC.

Yes. Will think through this and board operating principles we can share publicly, which would probably include criteria for how cases are chosen, to protect against this board and fund influencing direction.

Open to ideas and suggestions on all.

jack

From steven.j.lee at gmail.com  Thu Jan 13 18:28:18 2022
From: steven.j.lee at gmail.com (Steve Lee)
Date: Thu, 13 Jan 2022 10:28:18 -0800
Subject: [bitcoin-dev] Bitcoin Legal Defense Fund
In-Reply-To: <MtHvJYE--J-2@tutanota.de>
References: <MtHvJYE--J-2@tutanota.de>
Message-ID: <CABu3BAdUhFeCYtbs4HCV+c5rhurLYbf8tebX1UgZp+DathwxDw@mail.gmail.com>

I think the word "The" is important. The title of the email and the name of
the fund is Bitcoin Legal Defense Fund. It is "a" legal defense fund; not
THE Bitcoin Legal Defense Fund. There is room for other funds and
strategies and anyone is welcome to create alternatives.

I also don't see why Alex or anyone should be denied the opportunity to
comment on future soft forks or anything about bitcoin. Alex should have no
more or less right to participate and his comments should be judged on
their merit, just like yours and mine.

On Thu, Jan 13, 2022 at 9:37 AM Prayank via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Hi Jack,
>
>
> > The main purpose of this Fund is to defend developers from lawsuits
> regarding their activities in the Bitcoin ecosystem, including finding and
> retaining defense counsel, developing litigation strategy, and paying legal
> bills. This is a free and voluntary option for developers to take advantage
> of if they so wish. The Fund will start with a corps of volunteer and
> part-time lawyers. The board of the Fund will be responsible for
> determining which lawsuits and defendants it will help defend.
>
> Thanks for helping the developers in legal issues. Appreciate your efforts
> and I understand your intentions are to help Bitcoin in every possible way.
>
>
> Positives that I see in this initiative:
>
> 1.Developers don't need to worry about rich scammers and can focus on
> development.
>
> 2.Financial help for developers as legal issues can end up in wasting lot
> of time and money.
>
> 3.People who have misused courts to affect bitcoin developers will get
> better response that they deserve.
>
>
> I had few suggestions and feel free to ignore them if they do not make
> sense:
>
> 1.Name of this fund could be anything and 'The Bitcoin Legal Defense Fund'
> can be confusing or misleading for newbies. There is nothing official in
> Bitcoin however people believe things written in news articles and some of
> them might consider it as an official bitcoin legal fund.
>
> 2.It would be better if people involved in such important funds do not
> comment/influence soft fork related discussions. Example: Alex Morcos had
> some opinions about activation mechanism during Taproot soft fork IIRC.
>
>
>
> --
> Prayank
>
> A3B1 E430 2298 178F
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220113/bd8698a1/attachment.html>

From jlrubin at mit.edu  Thu Jan 13 19:05:42 2022
From: jlrubin at mit.edu (Jeremy)
Date: Thu, 13 Jan 2022 11:05:42 -0800
Subject: [bitcoin-dev] Bitcoin Legal Defense Fund
In-Reply-To: <CABu3BAdUhFeCYtbs4HCV+c5rhurLYbf8tebX1UgZp+DathwxDw@mail.gmail.com>
References: <MtHvJYE--J-2@tutanota.de>
 <CABu3BAdUhFeCYtbs4HCV+c5rhurLYbf8tebX1UgZp+DathwxDw@mail.gmail.com>
Message-ID: <CAD5xwhhub2tBxQT7X0P_apNocABMQWXUcCO=1-Dc--W8_T8O5Q@mail.gmail.com>

A further point -- were it to be a norm if a contributor to something like
this be denied their full capacity for "free speech" by social convention,
it would either encourage anonymous funding (less accountable) or would
disincentivize creating such initiatives in the future.

Both of those outcomes would be potentially bad, so I don't see limiting
speech on an unrelated topic as a valid action.

However, I think the inverse could have merit -- perhaps funders can
somehow commit to 'abstracting' themselves from involvement in cases / the
process of accepting prospective clients. As neither Alex nor Jack are
lawyers (afaict?), this should already be true to an extent as the legal
counsel would be bound to attorney client privilege.

Of course we live in a free country and however Jack and Alex determine
they should spend their own money is their god-given right, as much as it
is unfortunately the right of anyone to sue a developer for some alleged
infringement. I'm personally glad that Jack and Alex are using their money
to help developers and not harass them -- many thanks for that!

One question I have is how you might describe the differences between what
BLDF can accomplish and what e.g. EFF can accomplish. Having been
represented by the EFF on more than one occasion, they are fantastic. Do
you feel that the Bitcoin-specific focus of BLDF outweighs the more general
(but deeper experience/track record) of an organization like the EFF (or
others, like Berkman Cyberlaw Clinic, etc)? My main opinion is "the more
the merrier", so don't consider it a critique, more a question so that you
have the opportunity to highlight the unique strengths of this approach.

Best,

Jeremy
--
@JeremyRubin <https://twitter.com/JeremyRubin>
<https://twitter.com/JeremyRubin>


On Thu, Jan 13, 2022 at 10:50 AM Steve Lee via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> I think the word "The" is important. The title of the email and the name
> of the fund is Bitcoin Legal Defense Fund. It is "a" legal defense fund;
> not THE Bitcoin Legal Defense Fund. There is room for other funds and
> strategies and anyone is welcome to create alternatives.
>
> I also don't see why Alex or anyone should be denied the opportunity to
> comment on future soft forks or anything about bitcoin. Alex should have no
> more or less right to participate and his comments should be judged on
> their merit, just like yours and mine.
>
> On Thu, Jan 13, 2022 at 9:37 AM Prayank via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>> Hi Jack,
>>
>>
>> > The main purpose of this Fund is to defend developers from lawsuits
>> regarding their activities in the Bitcoin ecosystem, including finding and
>> retaining defense counsel, developing litigation strategy, and paying legal
>> bills. This is a free and voluntary option for developers to take advantage
>> of if they so wish. The Fund will start with a corps of volunteer and
>> part-time lawyers. The board of the Fund will be responsible for
>> determining which lawsuits and defendants it will help defend.
>>
>> Thanks for helping the developers in legal issues. Appreciate your
>> efforts and I understand your intentions are to help Bitcoin in every
>> possible way.
>>
>>
>> Positives that I see in this initiative:
>>
>> 1.Developers don't need to worry about rich scammers and can focus on
>> development.
>>
>> 2.Financial help for developers as legal issues can end up in wasting lot
>> of time and money.
>>
>> 3.People who have misused courts to affect bitcoin developers will get
>> better response that they deserve.
>>
>>
>> I had few suggestions and feel free to ignore them if they do not make
>> sense:
>>
>> 1.Name of this fund could be anything and 'The Bitcoin Legal Defense
>> Fund' can be confusing or misleading for newbies. There is nothing official
>> in Bitcoin however people believe things written in news articles and some
>> of them might consider it as an official bitcoin legal fund.
>>
>> 2.It would be better if people involved in such important funds do not
>> comment/influence soft fork related discussions. Example: Alex Morcos had
>> some opinions about activation mechanism during Taproot soft fork IIRC.
>>
>>
>>
>> --
>> Prayank
>>
>> A3B1 E430 2298 178F
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220113/aafa20a6/attachment-0001.html>

From alex.schoof at gmail.com  Thu Jan 13 18:54:35 2022
From: alex.schoof at gmail.com (Alex Schoof)
Date: Thu, 13 Jan 2022 13:54:35 -0500
Subject: [bitcoin-dev] Bitcoin Legal Defense Fund
In-Reply-To: <CABu3BAdUhFeCYtbs4HCV+c5rhurLYbf8tebX1UgZp+DathwxDw@mail.gmail.com>
References: <MtHvJYE--J-2@tutanota.de>
 <CABu3BAdUhFeCYtbs4HCV+c5rhurLYbf8tebX1UgZp+DathwxDw@mail.gmail.com>
Message-ID: <CA+2b5C0wJuWvsdz1pTcJ_-+GnkAXyOCUVimVeDjLu8f1PhYu0w@mail.gmail.com>

> I also don't see why Alex or anyone should be denied the opportunity to
comment on future soft forks or anything about bitcoin. Alex should have no
more or less right to participate and his comments should be judged on
their merit, just like yours and mine.

I think the concern is something like: "I disagree with a board member of
the defense fund about [insert contentious issue]. If I disagree with them
publicly (especially if there are clear economic implications in that
disagreement), am I putting myself at risk in the future where I won't be
able to get support from the fund because I spoke out against a board
member?" That kind of concern can be mitigated through policy and
governance, but is the kind of thing you want to tackle before it becomes
an issue.

Cheers,

(a different) Alex

On Thu, Jan 13, 2022 at 1:49 PM Steve Lee via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> I think the word "The" is important. The title of the email and the name
> of the fund is Bitcoin Legal Defense Fund. It is "a" legal defense fund;
> not THE Bitcoin Legal Defense Fund. There is room for other funds and
> strategies and anyone is welcome to create alternatives.
>
> I also don't see why Alex or anyone should be denied the opportunity to
> comment on future soft forks or anything about bitcoin. Alex should have no
> more or less right to participate and his comments should be judged on
> their merit, just like yours and mine.
>
> On Thu, Jan 13, 2022 at 9:37 AM Prayank via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>> Hi Jack,
>>
>>
>> > The main purpose of this Fund is to defend developers from lawsuits
>> regarding their activities in the Bitcoin ecosystem, including finding and
>> retaining defense counsel, developing litigation strategy, and paying legal
>> bills. This is a free and voluntary option for developers to take advantage
>> of if they so wish. The Fund will start with a corps of volunteer and
>> part-time lawyers. The board of the Fund will be responsible for
>> determining which lawsuits and defendants it will help defend.
>>
>> Thanks for helping the developers in legal issues. Appreciate your
>> efforts and I understand your intentions are to help Bitcoin in every
>> possible way.
>>
>>
>> Positives that I see in this initiative:
>>
>> 1.Developers don't need to worry about rich scammers and can focus on
>> development.
>>
>> 2.Financial help for developers as legal issues can end up in wasting lot
>> of time and money.
>>
>> 3.People who have misused courts to affect bitcoin developers will get
>> better response that they deserve.
>>
>>
>> I had few suggestions and feel free to ignore them if they do not make
>> sense:
>>
>> 1.Name of this fund could be anything and 'The Bitcoin Legal Defense
>> Fund' can be confusing or misleading for newbies. There is nothing official
>> in Bitcoin however people believe things written in news articles and some
>> of them might consider it as an official bitcoin legal fund.
>>
>> 2.It would be better if people involved in such important funds do not
>> comment/influence soft fork related discussions. Example: Alex Morcos had
>> some opinions about activation mechanism during Taproot soft fork IIRC.
>>
>>
>>
>> --
>> Prayank
>>
>> A3B1 E430 2298 178F
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>


-- 


Alex Schoof
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220113/dbfb6d62/attachment.html>

From morcos at chaincode.com  Thu Jan 13 19:25:48 2022
From: morcos at chaincode.com (Alex Morcos)
Date: Thu, 13 Jan 2022 14:25:48 -0500
Subject: [bitcoin-dev] Bitcoin Legal Defense Fund
In-Reply-To: <CAJ5H3Z7LhFzM4rY=h0H_0t+tFO80SuQ321-a8B-tE3HeWUN1Gw@mail.gmail.com>
References: <282EF45D-78A4-45E6-BCA2-3ADE6C8D4E11@squareup.com>
 <CAJ5H3Z7LhFzM4rY=h0H_0t+tFO80SuQ321-a8B-tE3HeWUN1Gw@mail.gmail.com>
Message-ID: <CANvRQdVbKdFETiehfLOiaj=BkmHLvxxZm1-5+fzfXYoKxk15vw@mail.gmail.com>

To belatedly answer Rene's question:

Yes, we hope so. To start, the Fund will focus on the defense of the
pending litigation and new litigation that may arise. However, we intend to
build up the capacity to provide competent third-party advice to developers
on strategies to reduce their liability.

On Tue, Jan 11, 2022 at 7:47 PM Ren? Pickhardt <r.pickhardt at googlemail.com>
wrote:

>
>
> jack via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> schrieb am
> Mi., 12. Jan. 2022, 01:35:
>
>> To Bitcoin Developers:
>>
>> Open-source developers, who are often independent, are especially
>> susceptible to legal pressure.
>
>
> Will the fund eventually also help to educate developers about the risks
> they are facing and which measures can be taken to reduce such risks so
> that legal pressure might not even arise in the first place?
>
> The main purpose of this Fund is to defend developers from lawsuits
>> regarding their activities in the Bitcoin ecosystem, including finding and
>> retaining defense counsel, developing litigation strategy, and paying legal
>> bills. This is a free and voluntary option for developers to take advantage
>> of if they so wish.
>
>
> Thank you!
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220113/2ed1b619/attachment-0001.html>

From steven.j.lee at gmail.com  Thu Jan 13 19:28:32 2022
From: steven.j.lee at gmail.com (Steve Lee)
Date: Thu, 13 Jan 2022 11:28:32 -0800
Subject: [bitcoin-dev] Bitcoin Legal Defense Fund
In-Reply-To: <CA+2b5C0wJuWvsdz1pTcJ_-+GnkAXyOCUVimVeDjLu8f1PhYu0w@mail.gmail.com>
References: <MtHvJYE--J-2@tutanota.de>
 <CABu3BAdUhFeCYtbs4HCV+c5rhurLYbf8tebX1UgZp+DathwxDw@mail.gmail.com>
 <CA+2b5C0wJuWvsdz1pTcJ_-+GnkAXyOCUVimVeDjLu8f1PhYu0w@mail.gmail.com>
Message-ID: <CABu3BAdAGxp8ACfjQrzHtSP0kfxTOnGNVmab6B7AG9nd7EYXaQ@mail.gmail.com>

That's a good point. Agree!

On Thu, Jan 13, 2022 at 10:54 AM Alex Schoof <alex.schoof at gmail.com> wrote:

> > I also don't see why Alex or anyone should be denied the opportunity to
> comment on future soft forks or anything about bitcoin. Alex should have no
> more or less right to participate and his comments should be judged on
> their merit, just like yours and mine.
>
> I think the concern is something like: "I disagree with a board member of
> the defense fund about [insert contentious issue]. If I disagree with them
> publicly (especially if there are clear economic implications in that
> disagreement), am I putting myself at risk in the future where I won't be
> able to get support from the fund because I spoke out against a board
> member?" That kind of concern can be mitigated through policy and
> governance, but is the kind of thing you want to tackle before it becomes
> an issue.
>
> Cheers,
>
> (a different) Alex
>
> On Thu, Jan 13, 2022 at 1:49 PM Steve Lee via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>> I think the word "The" is important. The title of the email and the name
>> of the fund is Bitcoin Legal Defense Fund. It is "a" legal defense fund;
>> not THE Bitcoin Legal Defense Fund. There is room for other funds and
>> strategies and anyone is welcome to create alternatives.
>>
>> I also don't see why Alex or anyone should be denied the opportunity to
>> comment on future soft forks or anything about bitcoin. Alex should have no
>> more or less right to participate and his comments should be judged on
>> their merit, just like yours and mine.
>>
>> On Thu, Jan 13, 2022 at 9:37 AM Prayank via bitcoin-dev <
>> bitcoin-dev at lists.linuxfoundation.org> wrote:
>>
>>> Hi Jack,
>>>
>>>
>>> > The main purpose of this Fund is to defend developers from lawsuits
>>> regarding their activities in the Bitcoin ecosystem, including finding and
>>> retaining defense counsel, developing litigation strategy, and paying legal
>>> bills. This is a free and voluntary option for developers to take advantage
>>> of if they so wish. The Fund will start with a corps of volunteer and
>>> part-time lawyers. The board of the Fund will be responsible for
>>> determining which lawsuits and defendants it will help defend.
>>>
>>> Thanks for helping the developers in legal issues. Appreciate your
>>> efforts and I understand your intentions are to help Bitcoin in every
>>> possible way.
>>>
>>>
>>> Positives that I see in this initiative:
>>>
>>> 1.Developers don't need to worry about rich scammers and can focus on
>>> development.
>>>
>>> 2.Financial help for developers as legal issues can end up in wasting
>>> lot of time and money.
>>>
>>> 3.People who have misused courts to affect bitcoin developers will get
>>> better response that they deserve.
>>>
>>>
>>> I had few suggestions and feel free to ignore them if they do not make
>>> sense:
>>>
>>> 1.Name of this fund could be anything and 'The Bitcoin Legal Defense
>>> Fund' can be confusing or misleading for newbies. There is nothing official
>>> in Bitcoin however people believe things written in news articles and some
>>> of them might consider it as an official bitcoin legal fund.
>>>
>>> 2.It would be better if people involved in such important funds do not
>>> comment/influence soft fork related discussions. Example: Alex Morcos had
>>> some opinions about activation mechanism during Taproot soft fork IIRC.
>>>
>>>
>>>
>>> --
>>> Prayank
>>>
>>> A3B1 E430 2298 178F
>>> _______________________________________________
>>> bitcoin-dev mailing list
>>> bitcoin-dev at lists.linuxfoundation.org
>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
>
>
> --
>
>
> Alex Schoof
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220113/269236cd/attachment-0001.html>

From antoine.riard at gmail.com  Thu Jan 13 20:50:08 2022
From: antoine.riard at gmail.com (Antoine Riard)
Date: Thu, 13 Jan 2022 15:50:08 -0500
Subject: [bitcoin-dev] Bitcoin Legal Defense Fund
In-Reply-To: <CAD5xwhhub2tBxQT7X0P_apNocABMQWXUcCO=1-Dc--W8_T8O5Q@mail.gmail.com>
References: <MtHvJYE--J-2@tutanota.de>
 <CABu3BAdUhFeCYtbs4HCV+c5rhurLYbf8tebX1UgZp+DathwxDw@mail.gmail.com>
 <CAD5xwhhub2tBxQT7X0P_apNocABMQWXUcCO=1-Dc--W8_T8O5Q@mail.gmail.com>
Message-ID: <CALZpt+Fh+ZvaE+H3776=Zd=wDPMkoP4Qpxin4Qw27Y6_aJ74yw@mail.gmail.com>

> One question I have is how you might describe the differences between
what BLDF can accomplish and what e.g. EFF can accomplish. Having been
represented by the EFF on more than one occasion, they are fantastic. Do
you feel that the Bitcoin-specific focus of BLDF outweighs the more general
(but deeper experience/track record) of an organization like the EFF (or
others, like Berkman Cyberlaw Clinic, etc)? My main opinion is "the more
the merrier", so don't consider it a critique, more a question so that you
have the opportunity to highlight the unique strengths of this approach.

I think one opportunity could be building legal assistance in a diversity
of jurisdictions, beyond the US one.

I join the kudos about the EFF, though you won't find the institutional
equivalent in term of subjects expertise/readiness-to-assist in most of the
other countries.
Especially considering the growing number of developers located outside
US/Europe and a lot of great ecosystem initiatives nurturing that trend.

Cheers,
Antoine

Le jeu. 13 janv. 2022 ? 14:06, Jeremy via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> a ?crit :

> A further point -- were it to be a norm if a contributor to something like
> this be denied their full capacity for "free speech" by social convention,
> it would either encourage anonymous funding (less accountable) or would
> disincentivize creating such initiatives in the future.
>
> Both of those outcomes would be potentially bad, so I don't see limiting
> speech on an unrelated topic as a valid action.
>
> However, I think the inverse could have merit -- perhaps funders can
> somehow commit to 'abstracting' themselves from involvement in cases / the
> process of accepting prospective clients. As neither Alex nor Jack are
> lawyers (afaict?), this should already be true to an extent as the legal
> counsel would be bound to attorney client privilege.
>
> Of course we live in a free country and however Jack and Alex determine
> they should spend their own money is their god-given right, as much as it
> is unfortunately the right of anyone to sue a developer for some alleged
> infringement. I'm personally glad that Jack and Alex are using their money
> to help developers and not harass them -- many thanks for that!
>
> One question I have is how you might describe the differences between what
> BLDF can accomplish and what e.g. EFF can accomplish. Having been
> represented by the EFF on more than one occasion, they are fantastic. Do
> you feel that the Bitcoin-specific focus of BLDF outweighs the more general
> (but deeper experience/track record) of an organization like the EFF (or
> others, like Berkman Cyberlaw Clinic, etc)? My main opinion is "the more
> the merrier", so don't consider it a critique, more a question so that you
> have the opportunity to highlight the unique strengths of this approach.
>
> Best,
>
> Jeremy
> --
> @JeremyRubin <https://twitter.com/JeremyRubin>
> <https://twitter.com/JeremyRubin>
>
>
> On Thu, Jan 13, 2022 at 10:50 AM Steve Lee via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>> I think the word "The" is important. The title of the email and the name
>> of the fund is Bitcoin Legal Defense Fund. It is "a" legal defense fund;
>> not THE Bitcoin Legal Defense Fund. There is room for other funds and
>> strategies and anyone is welcome to create alternatives.
>>
>> I also don't see why Alex or anyone should be denied the opportunity to
>> comment on future soft forks or anything about bitcoin. Alex should have no
>> more or less right to participate and his comments should be judged on
>> their merit, just like yours and mine.
>>
>> On Thu, Jan 13, 2022 at 9:37 AM Prayank via bitcoin-dev <
>> bitcoin-dev at lists.linuxfoundation.org> wrote:
>>
>>> Hi Jack,
>>>
>>>
>>> > The main purpose of this Fund is to defend developers from lawsuits
>>> regarding their activities in the Bitcoin ecosystem, including finding and
>>> retaining defense counsel, developing litigation strategy, and paying legal
>>> bills. This is a free and voluntary option for developers to take advantage
>>> of if they so wish. The Fund will start with a corps of volunteer and
>>> part-time lawyers. The board of the Fund will be responsible for
>>> determining which lawsuits and defendants it will help defend.
>>>
>>> Thanks for helping the developers in legal issues. Appreciate your
>>> efforts and I understand your intentions are to help Bitcoin in every
>>> possible way.
>>>
>>>
>>> Positives that I see in this initiative:
>>>
>>> 1.Developers don't need to worry about rich scammers and can focus on
>>> development.
>>>
>>> 2.Financial help for developers as legal issues can end up in wasting
>>> lot of time and money.
>>>
>>> 3.People who have misused courts to affect bitcoin developers will get
>>> better response that they deserve.
>>>
>>>
>>> I had few suggestions and feel free to ignore them if they do not make
>>> sense:
>>>
>>> 1.Name of this fund could be anything and 'The Bitcoin Legal Defense
>>> Fund' can be confusing or misleading for newbies. There is nothing official
>>> in Bitcoin however people believe things written in news articles and some
>>> of them might consider it as an official bitcoin legal fund.
>>>
>>> 2.It would be better if people involved in such important funds do not
>>> comment/influence soft fork related discussions. Example: Alex Morcos had
>>> some opinions about activation mechanism during Taproot soft fork IIRC.
>>>
>>>
>>>
>>> --
>>> Prayank
>>>
>>> A3B1 E430 2298 178F
>>> _______________________________________________
>>> bitcoin-dev mailing list
>>> bitcoin-dev at lists.linuxfoundation.org
>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220113/53040768/attachment.html>

From jlrubin at mit.edu  Thu Jan 13 21:06:37 2022
From: jlrubin at mit.edu (Jeremy)
Date: Thu, 13 Jan 2022 13:06:37 -0800
Subject: [bitcoin-dev] Documenting the lifetime of a transaction during
 mempool congestion from the perspective of a rational user
Message-ID: <CAD5xwhjuHxdruCtOtHcSAc8EtW0O4HSLFdfPU1x8Y7Xa7LCnHQ@mail.gmail.com>

Devs,

This email is primarily about existing wallet behaviors and user
preferences, and not about CTV. However, towards the end I will describe
the relevance of CTV, but the email is worth reading even if you have no
interest in CTV as the problems described exist today.

One point of confusion I've seen while discussing CTV based congestion
control is that it requires a bunch of new wallet software.

Most of the software requirements that would make CTV work well are things
that either already exist in Bitcoin Core, or are 'bugs' (where bug is
defined as deviation from rational utility maximizing behavior) that should
be fixed *whether or not CTV exists.*

In this post, I am going to walk through what I expect rational behavior to
be for a not unlikely circumstance.

First, let's define what rational behavior for a wallet is. A rational
wallet should have a few goals:

1) Maximize 'fully trusted' balance (fully confirmed + unconfirmed change
outputs from our own txns)
2) Process payments requested by the owner within the "urgency budget"
requested by the user.
3) Maximize "privacy" (this is a vague goal, so we'll largely ignore it
here.).

Rational wallet behavior may not be possible without metadata. For example,
a rational wallet might prompt the user for things like "how much do you
trust the sender of this payment to not RBF this transaction?", or "how
much do you trust this sender to not double spend you?". For example, a
self-transfer from cold wallet to hot wallet could have a trust score of 1,
whereas a payment from an anonymous source would have a trust score of 0.
Exchanges where you have a legal agreement to not RBF might sit somewhere
in between. Other pieces of exogenous information that could inform wallet
behavior include "has hashrate decreased recently, making longer reorgs
likely".

In the model above, a user does not request transactions, they request
payments. The rational wallet serves as an agent to assist the user in
completing these payments. For example, if I have a wallet with a single
unconfirmed output, and I spend from it to pay Alice, if the unconfirmed
gets replaced, my wallet should track that it was replaced and prompt me to
re-sign a new transaction. Rational wallets that maximize balance should be
careful to ensure that replaced payments are exclusive, guaranteed either
through sufficient confirmations or 'impossibility proofs' by reusing an
input (preventing double-send behavior).

-----------------------------

Now that we've sketched out a basic framework for what a rational wallet
should be doing, we can describe what the process of receiving a payment is.

Suppose I have a wallet with a bevy of fully confirmed coins such that for
my future payments I am sufficiently funded.

Then, I receive a payment from a highly trusted source (e.g., self
transfer) that is unconfirmed.

I then seek to make an outgoing payment. I should have no preference
towards or against spending the unconfirmed transfer, I should simply
account for it's cost in coin selection of CPFP-ing the parent transaction.
If fees are presently historically low, I may have a preference to spend it
so as to not have a higher fee later (consolidation).

Later, I receive payment from an untrusted source (e.g., an anonymous
donation to me). I have no reason to trust this won't be double spent.
Perhaps I can even observe that this output has been RBF'd many times
previously. I do not count on this money arriving. The feerate on the
transaction suggests it won't be confirmed immediately.

In order to maximize balance, I should prioritize spending from this output
(even if I don't have a payment I desire to make) in order to CPFP it to
the top of the mempool and guarantee I am paid. This is inherently "free"
since my cost to CPFP would be checked to be lower than the funds I am
receiving, and I have no expected value to receive the payment if it is not
confirmed. If I do have a transaction I desire to do, I should prioritize
spending this output at that time. If not, I would do a CPFP just in favor
of balance maximizing. Perhaps I can piggyback something useful, like
speculatively opening a lightning channel.

If I just self-spend to CPFP, it is very simple since the only party set up
for disappointment is myself (note: I patched the behavior in this case to
accurately *not* count this as a trusted balance in
https://github.com/bitcoin/bitcoin/pull/16766, since a parent could disrupt
this). However, if I try to make a payment, my wallet agent must somehow
prompt me to re-sign or automatically sign an alternative payment once it
is proven (e.g. 6 blocks) I won't receive the output, or to re-sign on a
mutually exclusive output (e.g., fee bumping RBF) such that issuing two
payments will not causes a double-send error. This adds complexity to both
the user story and logic, but is still rational.

Now, suppose that I receive a new payment from  a **trusted** source that
is a part of a "long chain". A long chain is a series of transactions that
are all unconfirmed in the mempool. This long-chain is in the bottom of the
mempool, and is not expected to confirm any time soon.

My wallet should be configured such that it saves not only all ancestors of
the transaction paying me, but also all descendants of the root unconfirmed
transaction paying me. If I do not save all ancestor transactions, then it
would be impossible for me to claim this payment at a future date, and
would violate balance maximization. But why save descendants, if they do
not concern me? Descendant transactions are critical for balance
maximization. Someone else's spend of an output is a "free" CPFP subsidy
for driving my transaction to completion (perhaps "descendants that
increase the feerate of any parent" is the correct thing to save).
Therefore if I want to maximize balance, I would rather keep these
transactions around should I ever need to rebroadcast the transactions as
it should be cheaper than having to CPFP by myself.

Now, suppose that I receive a similar payment in a longchain from a series
of untrusted sources. The same arguments apply, but now I may have even
higher incentive to prioritize spending this coin since, if sender's trust
scores are independent, my total trust in that payment is decomposed
worst-case geometrically. It may not be a good assumption that trust scores
are independent, since a long chain might be generated as e.g. a series of
batch payments from one service provider.

Briefly mentioned above is rebroadcasting. This is sort of an orthogonal
behavior to the above, but it is "simple" to explain. Wallet agents should
retransmit txns to the network if they believe other nodes are not aware of
them and they are likely to go into a block. This encapsulates personal
transactions as well as arbitrary transactions from third parties. There
are many privacy implications of rebroadcasting that are out of scope for
this post.

-----------------

All of the behaviors documented above are things that should happen today
if you would like to have a rational wallet that maximizes your balance and
makes payments.

The reasons we don't do some of these things are, as far as I can tell:

1) Engineering Complexity
2) UX Complexity (simpler to make unconfirmed outputs "unspendable" to
minimize transaction reissuing)
3) Mempool backlog is low, things are confirmed quickly if a sender pays a
relatively low fee

Certain wallets already have parts of this functionality baked in to an
extent. For example, in Lightning Channels, you will drive payments to
completion to prevent HTLC timeouts during contested closes (HTLCs == low
trust score payments).

Should Bitcoin see development of a more robust fee market, it is highly
likely the rational behaviors described above would be emergent among all
bitcoin wallets (who would want to use a Bitcoin wallet that gets you less
money over time?). This email is not just a "Bitcoin Core" thing, hence not
being an issue on Bitcoin Core where there are currently deviations from
the above behaviors.

-----------------

What's CTV got to do with it?

A common critique of congestion control using CTV is that it complicates
wallet behavior because congestion control is designed to be useful in the
circumstances above. CTV and congestion control do not cause these
conditions. These conditions already exist whether or not we have
congestion control.

Where congestion control helps is that, in a world with a full mempool, you
have fewer payments that are *actually* unconfirmed because exchanges that
batch can fully confirm a constant sized root transaction and the sub-trees
of transactions locked in by CTV can be treated as fully trusted. This
helps reduce the need for the (rational) behavior of CPFP bumping your own
payments on receipt from lower trust senders. Further, the expansion of the
transaction tree can be done by other users receiving, so you have an
incentive to wait for funds to mature as someone else might pay for
expansion. These two factors mean that CTV congestion control can exert a
dramatic back pressure on transaction urgency by unbundling the blockspace
demand for spending and receiving coins. There are other synergies -- such
as non-interactive channel opens -- that further improve the amount of
reduction of time-preference in full on-chain resolution.

I hope this email helps clarify why CTV Congestion Control isn't
particularly creating a wallet architecture problem, it's helping to solve
an existing one.

Best,

Jeremy



--
@JeremyRubin <https://twitter.com/JeremyRubin>
<https://twitter.com/JeremyRubin>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220113/0cad9c8d/attachment-0001.html>

From aymeric at peersm.com  Fri Jan 14 13:21:42 2022
From: aymeric at peersm.com (Aymeric Vitte)
Date: Fri, 14 Jan 2022 14:21:42 +0100
Subject: [bitcoin-dev] Bitcoin Legal Defense Fund
In-Reply-To: <F3DA4333-E4BB-4A3F-B050-AA142465F2C8@squareup.com>
References: <MtHvJYE--J-2@tutanota.de>
 <F3DA4333-E4BB-4A3F-B050-AA142465F2C8@squareup.com>
Message-ID: <d1489dc9-e919-fc29-13ac-fcde96f34c50@peersm.com>

(P2P?) Electronic Cash (Defense?) Fund or Electronic Cash Foundation ?
More neutral, potentially covering others than Bitcoin, mimicking a bit
EFF (even if as stated US is not the only target), referring to
Satoshi's paper where everything started

Maybe I am not up to date but it would be good to know what are the
current procedures with the Tulip thing

Aymeric


Le 13/01/2022 ? 19:20, jack via bitcoin-dev a ?crit :
> Hi Prayank,
>
>> On 13 Jan 2022, at 10:13, Prayank <prayank at tutanota.de> wrote:
>> I had few suggestions and feel free to ignore them if they do not make sense:
>>
>> 1.Name of this fund could be anything and 'The Bitcoin Legal Defense Fund' can be confusing or misleading for newbies. There is nothing official in Bitcoin however people believe things written in news articles and some of them might consider it as an official bitcoin legal fund.
> Excellent point. Will come up with a better name.
>
>> 2.It would be better if people involved in such important funds do not comment/influence soft fork related discussions. Example: Alex Morcos had some opinions about activation mechanism during Taproot soft fork IIRC.
> Yes. Will think through this and board operating principles we can share publicly, which would probably include criteria for how cases are chosen, to protect against this board and fund influencing direction.
>
> Open to ideas and suggestions on all.
>
> jack
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev



From qmccormick13 at gmail.com  Fri Jan 14 18:18:40 2022
From: qmccormick13 at gmail.com (qmccormick13)
Date: Fri, 14 Jan 2022 19:18:40 +0100
Subject: [bitcoin-dev] Bitcoin Legal Defense Fund
In-Reply-To: <d1489dc9-e919-fc29-13ac-fcde96f34c50@peersm.com>
References: <MtHvJYE--J-2@tutanota.de>
 <F3DA4333-E4BB-4A3F-B050-AA142465F2C8@squareup.com>
 <d1489dc9-e919-fc29-13ac-fcde96f34c50@peersm.com>
Message-ID: <CAABBXbuxcw+SQz573bRxPdiVq3XYFged=TSmb32ABUfq8_4MoQ@mail.gmail.com>

I very much hope the fund will not finance lawsuits irrelevant to bitcoin.

On Fri, Jan 14, 2022 at 5:23 PM Aymeric Vitte via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> (P2P?) Electronic Cash (Defense?) Fund or Electronic Cash Foundation ?
> More neutral, potentially covering others than Bitcoin, mimicking a bit
> EFF (even if as stated US is not the only target), referring to
> Satoshi's paper where everything started
>
> Maybe I am not up to date but it would be good to know what are the
> current procedures with the Tulip thing
>
> Aymeric
>
>
> Le 13/01/2022 ? 19:20, jack via bitcoin-dev a ?crit :
> > Hi Prayank,
> >
> >> On 13 Jan 2022, at 10:13, Prayank <prayank at tutanota.de> wrote:
> >> I had few suggestions and feel free to ignore them if they do not make
> sense:
> >>
> >> 1.Name of this fund could be anything and 'The Bitcoin Legal Defense
> Fund' can be confusing or misleading for newbies. There is nothing official
> in Bitcoin however people believe things written in news articles and some
> of them might consider it as an official bitcoin legal fund.
> > Excellent point. Will come up with a better name.
> >
> >> 2.It would be better if people involved in such important funds do not
> comment/influence soft fork related discussions. Example: Alex Morcos had
> some opinions about activation mechanism during Taproot soft fork IIRC.
> > Yes. Will think through this and board operating principles we can share
> publicly, which would probably include criteria for how cases are chosen,
> to protect against this board and fund influencing direction.
> >
> > Open to ideas and suggestions on all.
> >
> > jack
> > _______________________________________________
> > bitcoin-dev mailing list
> > bitcoin-dev at lists.linuxfoundation.org
> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220114/a0a62882/attachment.html>

From jlrubin at mit.edu  Fri Jan 14 18:34:45 2022
From: jlrubin at mit.edu (Jeremy)
Date: Fri, 14 Jan 2022 10:34:45 -0800
Subject: [bitcoin-dev] Bitcoin Legal Defense Fund
In-Reply-To: <CAABBXbuxcw+SQz573bRxPdiVq3XYFged=TSmb32ABUfq8_4MoQ@mail.gmail.com>
References: <MtHvJYE--J-2@tutanota.de>
 <F3DA4333-E4BB-4A3F-B050-AA142465F2C8@squareup.com>
 <d1489dc9-e919-fc29-13ac-fcde96f34c50@peersm.com>
 <CAABBXbuxcw+SQz573bRxPdiVq3XYFged=TSmb32ABUfq8_4MoQ@mail.gmail.com>
Message-ID: <CAD5xwhjoYmTEXmvV6dYMXrOvyzQ9M6CUXZ-Uf8sQDKyRQC0Kpg@mail.gmail.com>

If I understand the intent of your message correctly, that's unfortunately
not how the law works.

If there is a case that is precedent setting, whether it directly involves
bitcoin or not, a bitcoin focused legal fund might want to either offer
representation or file an amicus brief to guide the court to making a
decision beneficial to Bitcoin Developers.

More than likely, some of these cases would involve developers of
alternative projects (as they might be "ahead of the curve" on legal
problems) and heading off a strong precedent for other communities would be
protective for Bitcoiners in general. As an example, were the developers
building Rollups on Ethereum to face a legal threat, since we might one day
want similar software for Bitcoin, ensuring a good outcome for them helps
Bitcoin.

That said, all organizations must at some point have a defined scope, and
it seems the BLDF is primarily focused for now on things impacting the
developers of Bitcoin or software for bitcoin specifically. I "trust" the
legal team behind BLDF will form a coherent strategy around what is
relevant to Bitcoin defense, even if the particulars of a case are not
directly about Bitcoin.

cheers,

Jeremy
--
@JeremyRubin <https://twitter.com/JeremyRubin>
<https://twitter.com/JeremyRubin>


On Fri, Jan 14, 2022 at 10:25 AM qmccormick13 via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> I very much hope the fund will not finance lawsuits irrelevant to bitcoin.
>
> On Fri, Jan 14, 2022 at 5:23 PM Aymeric Vitte via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>> (P2P?) Electronic Cash (Defense?) Fund or Electronic Cash Foundation ?
>> More neutral, potentially covering others than Bitcoin, mimicking a bit
>> EFF (even if as stated US is not the only target), referring to
>> Satoshi's paper where everything started
>>
>> Maybe I am not up to date but it would be good to know what are the
>> current procedures with the Tulip thing
>>
>> Aymeric
>>
>>
>> Le 13/01/2022 ? 19:20, jack via bitcoin-dev a ?crit :
>> > Hi Prayank,
>> >
>> >> On 13 Jan 2022, at 10:13, Prayank <prayank at tutanota.de> wrote:
>> >> I had few suggestions and feel free to ignore them if they do not make
>> sense:
>> >>
>> >> 1.Name of this fund could be anything and 'The Bitcoin Legal Defense
>> Fund' can be confusing or misleading for newbies. There is nothing official
>> in Bitcoin however people believe things written in news articles and some
>> of them might consider it as an official bitcoin legal fund.
>> > Excellent point. Will come up with a better name.
>> >
>> >> 2.It would be better if people involved in such important funds do not
>> comment/influence soft fork related discussions. Example: Alex Morcos had
>> some opinions about activation mechanism during Taproot soft fork IIRC.
>> > Yes. Will think through this and board operating principles we can
>> share publicly, which would probably include criteria for how cases are
>> chosen, to protect against this board and fund influencing direction.
>> >
>> > Open to ideas and suggestions on all.
>> >
>> > jack
>> > _______________________________________________
>> > bitcoin-dev mailing list
>> > bitcoin-dev at lists.linuxfoundation.org
>> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
>>
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220114/bbca9866/attachment-0001.html>

From prayank at tutanota.de  Sat Jan 15 17:19:36 2022
From: prayank at tutanota.de (Prayank)
Date: Sat, 15 Jan 2022 18:19:36 +0100 (CET)
Subject: [bitcoin-dev] CTV and ANYPREVOUT vault designs
Message-ID: <MtTk5Er--3-2@tutanota.de>

Everything shared in this email was earlier posted by Michael Folkson on Bitcoin Stackexchange (a site that allows people to close opinion based questions), cross posting here so that more developers could discuss and in a better way. I have just removed one paragraph.

At the time of writing (January 2022) there seems to be very little research with direct comparisons on the utility and safety of different ways to enable the construction of various vault designs. Indeed the covenant opcode TAPLEAF_UPDATE_VERIFY was only [proposed][1] to the bitcoin-dev mailing list in September 2021 and there are no implementations of it as yet let alone detailed analyses of how it compares to constructing vaults using SIGHASH_ANYPREVOUT or OP_CHECKTEMPLATEVERIFY. The mailing list post did suggest that it enables a vault design that matches a previous [vault design][2] of Bryan Bishop with additional benefits:

> It's fully recursive, allows withdrawals to vary rather than be the
> fixed amount L (due to not relying on pre-signed transactions), and
> generally seems a bit simpler to work with.

Jeremy Rubin initially [described][4] OP_CHECKOUTPUTSHASHVERIFY (which became OP_CHECKTEMPLATEVERIFY) as a "rudimentary, limited form of covenant which does not bear the same technical and social risks of prior covenant designs". This suggests that for vaults specifically the design space may be more limited using OP_CHECKTEMPLATEVERIFY.

Andrew Poelstra has blogged on how to use OP_CAT and OP_CHECKSIGFROMSTACK to construct covenants and vaults ([1][5], [2][3]). These would enable more generalized covenants than OP_CHECKTEMPLATEVERIFY potentially increasing the design space for vaults but with the downsides of being less efficient and arguably riskier. There does seem to be a direct risk/reward trade-off here when attempting to broaden the design space for vaults and it is difficult to assess where on the spectrum is the potential optimum given how few vault prototypes there are let alone fully built out implementations of those prototypes.?

The solitary [paper][6] that has compared building vaults using OP_CHECKTEMPLATEVERIFY and SIGHASH_ANYPREVOUT at the time of writing is **Bitcoin Covenants: Three Ways to Control the Future**.

This paper discussed three categories of vault design: deleted key (no consensus changes required but inferior security model), recovered key (requires BIP 118 consensus change, superior security model) and script based (requires BIP 119 consensus change, superior security model).

[![Bitcoin Covenants Paper][7]][7]

It stated:

> Recovered-key and script-based covenants are mostly functionally equivalent and
so the advantages that recovered-key covenants have over deleted-key covenants also applies to Script-based covenants. If
either were enabled by their required soft-fork upgrade then a new domain of practical covenant-based protocols could emerge.
Understanding precisely what utility is gained from such upgrades is key to their progress.

The paper concluded by stating:

> Bitcoin is a complex adaptive system with many interacting parts and
> there are systemic risks with every modification of bitcoin?s
> code-base and protocol. It is difficult to analyze those risks and it
> would be hubris to claim that there are no unknown risks being
> introduced.

? [1]: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019419.html
? [2]: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-August/017231.html
? [3]: https://www.wpsoftware.net/andrew/blog/cat-and-schnorr-tricks-ii.html
? [4]: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-May/016934.html
? [5]: https://www.wpsoftware.net/andrew/blog/cat-and-schnorr-tricks-i.html
? [6]: https://arxiv.org/pdf/2006.16714.pdf
? [7]: https://i.stack.imgur.com/Udey1.png

-- 
Prayank

A3B1 E430 2298 178F
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220115/01a82955/attachment.html>

From orlovsky at protonmail.com  Sun Jan 16 17:41:22 2022
From: orlovsky at protonmail.com (Dr Maxim Orlovsky)
Date: Sun, 16 Jan 2022 17:41:22 +0000
Subject: [bitcoin-dev] BIP proposal: Pay-to-contract tweak fields for PSBT
	(bip-psbt-p2c)
Message-ID: <89d7d76698de12dd7fdb8185130f4ace3bee9ef8.camel@protonmail.com>

Dear Bictoin dev community,


In Mar 2019 Andrew Poelstra sent to bitcoin dev mail list a proposal
for extending existing PSBT standard [6], which among other was suggesting adding a field for P2C tweaks:

> (c) a map from public keys to 32-byte "tweaks" that are used in the
>     pay-to-contract construction. Selfishly I'd like this to be a
>     variable-length bytestring with the semantics that (a) the first
>     33 bytes represent an untweaked pubkey; (b) the HMAC-SHA256 of
>     the whole thing, when multiplied by G and added to the untweaked
>     pubkey, result in the target key. This matches the algorithm in
>     [3] which is deployed in Blockstream's Liquid, but I'd be happy
>     with a more efficient scheme which e.g. used SHA256 rather than
>     HMAC-SHA256.

This BIP proposal is an attempt to structure that idea into a more
universal and standard form, following a discussion happened in https://github.com/bitcoin/bips/pull/1239. Specifically, it adds a PSBT input field for inputs spending UTXOs with previously created pay-to-contract (P2C) public key tweaks.


-----------------------------------------------------------------------

<pre>
  BIP: ?
  Layer: Applications
  Title: Pay-to-contract tweak fields for PSBT
  Author: Maxim Orlovsky <orlovsky at lnp-bp.org>,
          Andrew Poelstra <apoelstra at wpsoftware.net>
  Discussions-To: <bitcoin-dev at lists.linuxfoundation.org>
  Comments-URI: <to be assigned>
  Status: Draft
  Type: Standards Track
  Created: 2022-01-16
  License: BSD-2-Clause
  Requires: BIP-174
</pre>

==Introduction==

===Abstract===

This document proposes additional fields for BIP 174 PSBTv0 and BIP 370 PSBTv2
that allow for pay-to-contract key tweaking data data to be included in a PSBT
of any version. These will represent an extra-transaction information required
for the signer to produce valid signatures spending previous outputs.

===Copyright===

This BIP is licensed under the 2-clause BSD license.

===Background===

Key tweaking is a procedure for creating a cryptographic commitment to some
message using elliptic curve properties. The procedure uses the discrete log
problem (DLP) to commit to an extra-transaction message. This is done by adding
to a public key (for which the output owner knows the corresponding private key)
a hash of the message multiplied on the generator point G of the elliptic curve.
This produces a tweaked public key, containing the commitment. Later, in order
to spend an output containing P2C commitment, the same commitment should be
added to the corresponding private key.

This type of commitment was originally proposed as a part of the pay to contract
concept by Ilja Gerhardt and Timo Hanke in [1] and later used by Eternity Wall
[2] for the same purpose. Since that time multiple different protocols for P2C
has been developed, including OpenTimeStamps [3], Elements sidechain P2C tweaks
[4] and LNPBP-1 [5], used in for constructing Peter Todd's single-use-seals [6]
in client-side-validation protocols like RGB.

===Motivation===

P2C outputs can be detected onchain and spent only if the output owner
not just knowns the corresponding original private key, but also is aware about
P2C tweak applied to the public key. In order to produce a valid signature, the
same tweak value must be added (modulo group order) to the original private key
by a signer device. This represents a channelge for external signers, which may
not have any information about such commitment. This proposal addresses this
issue by adding relevant fields to the PSBT input information.

The proposal abstracts details of specific P2C protocols and provides universal
method for spending previous outpus containing P2C tweaks, applied to the public
key contained within any standard form of the <tt>scriptPubkey</tt>, including
bare scripts and P2PK, P2PKH, P2SH, witness v0 P2WPKH, P2WSH, nested witness v0
P2WPKH-P2SH, P2WSH-P2SH and witness v1 P2TR outputs.


==Design==

P2C-tweaked public keys are already exposed in the
<tt>PSBT_IN_REDEEM_SCRIPT</tt>, <tt>PSBT_IN_WITNESS_SCRIPT</tt>,
<tt>PSBT_IN_TAP_INTERNAL_KEY</tt> and <tt>PSBT_IN_TAP_LEAF_SCRIPT</tt> fields;
the only information signer is needed to recognize which keys it should sign
with is from which of the original keys they were generated. This is achieved by
introducing new `PSBT_IN_P2C_TWEAK` field which has the original key as a field
key and the tweak as a field value. The signer will recognize the keys which are
available to it, apply the tweak to them and see in which scripts it was used --
and use this information to apply tweaks for the corresponding private keys and
produce valid signatures.


==Specification==

The new per-input type is defined as follows:

{|
! Name
! <tt><keytype></tt>
! <tt><keydata></tt>
! <tt><keydata></tt> Description
! <tt><valuedata></tt>
! <tt><valuedata></tt> Description
! Versions Requiring Inclusion
! Versions Requiring Exclusion
! Versions Allowing Inclusion
|-
| P2C Key Tweak
| <tt>PSBT_IN_P2C_TWEAK = 0x19</tt>
| <tt><pubkey></tt>
| 33 bytes of compact public key serialization specifying to which of keys the
P2C tweak may be applied (i.e. this MUST be a value of a public key before the
tweak is applied). BIP-340 keys are serialized by appending `02`
byte.<ref>'''Why compressed public keys are not distinguished from BIP-340
public keys'''We follow the logic of BIP32 key derivation which does not
performs that distinguishment. The type of the key is defined by the input type,
and adding additional PSBT field type will just create the need for handling
errors when the input type does not match the provided key type.</ref>
| <tt><tweak></tt>
| The 32 byte value which MUST be added to a private key to produce correct
ECDSA and/or Schnorr signature ("key tweak"). Signers SHOULD remove this field
after <tt>PSBT_IN_PARTIAL_SIG</tt> is constructed.
|
|
| 0, 2
| BIP-P2C
|}


==Security considerations==

The scope of this proposal is deliberately kept narrow; it addresses
only spending of transaction outputs containing P2C tweaks - and does not addresses construction of a new P2C commitments or transactions containing them in their outputs.<ref>'''Why only spending of P2C tweaked outputs is covered'''P2C tweaks commit to external data, some of which may represent certain value (like in some sidechains, single-use-seal applications like RGB etc). Creation of such outputs much allow hardware devices to understand the structure of such extra-transaction data, which may be in different formats and constantly involve. Thus, this should be addresses with a separate standards (or be a vendor-based). The current proposal only touches the question of spending an output which contained previously created P2C commitment, which does not creates a new commitment and does not provides that kind of risk of extra-blockchain value loses.</ref>


==Rationale==

<references/>


==Compatibility==

The proposal is compatible with the existing consensus rules and does not
require any of their modifications.

The proposed P2C PSBT fields provides sufficient information for creating a
valid signatures for spendings of the following output types containing tweaked
public keys:
- bare scripts,
- P2PK,
- P2PKH,
- P2SH,
- witness v0 P2WPKH and P2WSH,
- nested witness v0 P2WPKH-P2SH and P2WSH-P2SH,
- witness v1 P2TR outputs.

Possible future witness versions, including witness v1 non-taproot outputs may
not be supported or covered by this BIP and may require addition of new fields
to the PSBT inputs.


==Reference implementation==

WIP


==Acknowledgements==

TBD


==Test vectors==

TBD


==References==

[1] Ilja Gerhardt, Timo Hanke. Homomorphic Payment Addresses and the
    Pay-to-Contract Protocol. arXiv:1212.3257 \[cs.CR\]
    <https://arxiv.org/pdf/1212.3257.pdf>
[2] Eternity Wall's "sign-to-contract" article.
    <https://blog.eternitywall.com/2018/04/13/sign-to-contract/>
[3] Peter Todd. OpenTimestamps: Scalable, Trust-Minimized, Distributed
    Timestamping with Bitcoin.
    <https://petertodd.org/2016/opentimestamps-announcement>
[4] Adam Back, Matt Corallo, Luke Dashjr, et al. Enabling Blockchain
    Innovations with Pegged Sidechains (commit5620e43). Appenxix A.
    <https://blockstream.com/sidechains.pdf>;.
[5] Maxim Orlovsky, Rene Pickhardt, Federico Tenga, et al. Key
    tweaking: collision- resistant elliptic curve-based commitments.
    LNPBP-1 Standard.
    <https://github.com/LNP-BP/LNPBPs/blob/master/lnpbp-0001.md>
[6] Peter Todd. Single-use-seals. LNPBP-8 Standard.
    <https://github.com/LNP-BP/LNPBPs/blob/master/lnpbp-0008.md>

--
Maxim Orlovsky
orlovsky at protonmail.com
GitHub: @dr-orlovsky
Twitter: @dr_orlovsky

LNP/BP Standards Association
orlovsky at lnp-bp.org
github.com/LNP-BP






From jlrubin at mit.edu  Mon Jan 17 05:55:00 2022
From: jlrubin at mit.edu (Jeremy)
Date: Sun, 16 Jan 2022 21:55:00 -0800
Subject: [bitcoin-dev] BIP proposal: Pay-to-contract tweak fields for
	PSBT (bip-psbt-p2c)
In-Reply-To: <89d7d76698de12dd7fdb8185130f4ace3bee9ef8.camel@protonmail.com>
References: <89d7d76698de12dd7fdb8185130f4ace3bee9ef8.camel@protonmail.com>
Message-ID: <CAD5xwhhd=CnGubyA3pqXkGz2fBJhRNBFCAegjXoqBhW4KY3r-g@mail.gmail.com>

High level feedback:

It would be nice if this field was not distinct from BIP32 derivation
descriptors so that you could have a single representation for the Extended
Key that doesn't need some additional field only in PSBT.

If I understood correctly, and this is just an arbitrary hash being
provably added (but has not direct cryptographic function), this can also
be done with no changes to BIP32 as I did in
https://github.com/sapio-lang/sapio/blob/master/ctv_emulators/src/lib.rs.

Best,

Jeremy


--
@JeremyRubin <https://twitter.com/JeremyRubin>
<https://twitter.com/JeremyRubin>


On Sun, Jan 16, 2022 at 1:00 PM Dr Maxim Orlovsky via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Dear Bictoin dev community,
>
>
> In Mar 2019 Andrew Poelstra sent to bitcoin dev mail list a proposal
> for extending existing PSBT standard [6], which among other was suggesting
> adding a field for P2C tweaks:
>
> > (c) a map from public keys to 32-byte "tweaks" that are used in the
> >     pay-to-contract construction. Selfishly I'd like this to be a
> >     variable-length bytestring with the semantics that (a) the first
> >     33 bytes represent an untweaked pubkey; (b) the HMAC-SHA256 of
> >     the whole thing, when multiplied by G and added to the untweaked
> >     pubkey, result in the target key. This matches the algorithm in
> >     [3] which is deployed in Blockstream's Liquid, but I'd be happy
> >     with a more efficient scheme which e.g. used SHA256 rather than
> >     HMAC-SHA256.
>
> This BIP proposal is an attempt to structure that idea into a more
> universal and standard form, following a discussion happened in
> https://github.com/bitcoin/bips/pull/1239. Specifically, it adds a PSBT
> input field for inputs spending UTXOs with previously created
> pay-to-contract (P2C) public key tweaks.
>
>
> -----------------------------------------------------------------------
>
> <pre>
>   BIP: ?
>   Layer: Applications
>   Title: Pay-to-contract tweak fields for PSBT
>   Author: Maxim Orlovsky <orlovsky at lnp-bp.org>,
>           Andrew Poelstra <apoelstra at wpsoftware.net>
>   Discussions-To: <bitcoin-dev at lists.linuxfoundation.org>
>   Comments-URI: <to be assigned>
>   Status: Draft
>   Type: Standards Track
>   Created: 2022-01-16
>   License: BSD-2-Clause
>   Requires: BIP-174
> </pre>
>
> ==Introduction==
>
> ===Abstract===
>
> This document proposes additional fields for BIP 174 PSBTv0 and BIP 370
> PSBTv2
> that allow for pay-to-contract key tweaking data data to be included in a
> PSBT
> of any version. These will represent an extra-transaction information
> required
> for the signer to produce valid signatures spending previous outputs.
>
> ===Copyright===
>
> This BIP is licensed under the 2-clause BSD license.
>
> ===Background===
>
> Key tweaking is a procedure for creating a cryptographic commitment to some
> message using elliptic curve properties. The procedure uses the discrete
> log
> problem (DLP) to commit to an extra-transaction message. This is done by
> adding
> to a public key (for which the output owner knows the corresponding
> private key)
> a hash of the message multiplied on the generator point G of the elliptic
> curve.
> This produces a tweaked public key, containing the commitment. Later, in
> order
> to spend an output containing P2C commitment, the same commitment should be
> added to the corresponding private key.
>
> This type of commitment was originally proposed as a part of the pay to
> contract
> concept by Ilja Gerhardt and Timo Hanke in [1] and later used by Eternity
> Wall
> [2] for the same purpose. Since that time multiple different protocols for
> P2C
> has been developed, including OpenTimeStamps [3], Elements sidechain P2C
> tweaks
> [4] and LNPBP-1 [5], used in for constructing Peter Todd's
> single-use-seals [6]
> in client-side-validation protocols like RGB.
>
> ===Motivation===
>
> P2C outputs can be detected onchain and spent only if the output owner
> not just knowns the corresponding original private key, but also is aware
> about
> P2C tweak applied to the public key. In order to produce a valid
> signature, the
> same tweak value must be added (modulo group order) to the original
> private key
> by a signer device. This represents a channelge for external signers,
> which may
> not have any information about such commitment. This proposal addresses
> this
> issue by adding relevant fields to the PSBT input information.
>
> The proposal abstracts details of specific P2C protocols and provides
> universal
> method for spending previous outpus containing P2C tweaks, applied to the
> public
> key contained within any standard form of the <tt>scriptPubkey</tt>,
> including
> bare scripts and P2PK, P2PKH, P2SH, witness v0 P2WPKH, P2WSH, nested
> witness v0
> P2WPKH-P2SH, P2WSH-P2SH and witness v1 P2TR outputs.
>
>
> ==Design==
>
> P2C-tweaked public keys are already exposed in the
> <tt>PSBT_IN_REDEEM_SCRIPT</tt>, <tt>PSBT_IN_WITNESS_SCRIPT</tt>,
> <tt>PSBT_IN_TAP_INTERNAL_KEY</tt> and <tt>PSBT_IN_TAP_LEAF_SCRIPT</tt>
> fields;
> the only information signer is needed to recognize which keys it should
> sign
> with is from which of the original keys they were generated. This is
> achieved by
> introducing new `PSBT_IN_P2C_TWEAK` field which has the original key as a
> field
> key and the tweak as a field value. The signer will recognize the keys
> which are
> available to it, apply the tweak to them and see in which scripts it was
> used --
> and use this information to apply tweaks for the corresponding private
> keys and
> produce valid signatures.
>
>
> ==Specification==
>
> The new per-input type is defined as follows:
>
> {|
> ! Name
> ! <tt><keytype></tt>
> ! <tt><keydata></tt>
> ! <tt><keydata></tt> Description
> ! <tt><valuedata></tt>
> ! <tt><valuedata></tt> Description
> ! Versions Requiring Inclusion
> ! Versions Requiring Exclusion
> ! Versions Allowing Inclusion
> |-
> | P2C Key Tweak
> | <tt>PSBT_IN_P2C_TWEAK = 0x19</tt>
> | <tt><pubkey></tt>
> | 33 bytes of compact public key serialization specifying to which of keys
> the
> P2C tweak may be applied (i.e. this MUST be a value of a public key before
> the
> tweak is applied). BIP-340 keys are serialized by appending `02`
> byte.<ref>'''Why compressed public keys are not distinguished from BIP-340
> public keys'''We follow the logic of BIP32 key derivation which does not
> performs that distinguishment. The type of the key is defined by the input
> type,
> and adding additional PSBT field type will just create the need for
> handling
> errors when the input type does not match the provided key type.</ref>
> | <tt><tweak></tt>
> | The 32 byte value which MUST be added to a private key to produce correct
> ECDSA and/or Schnorr signature ("key tweak"). Signers SHOULD remove this
> field
> after <tt>PSBT_IN_PARTIAL_SIG</tt> is constructed.
> |
> |
> | 0, 2
> | BIP-P2C
> |}
>
>
> ==Security considerations==
>
> The scope of this proposal is deliberately kept narrow; it addresses
> only spending of transaction outputs containing P2C tweaks - and does not
> addresses construction of a new P2C commitments or transactions containing
> them in their outputs.<ref>'''Why only spending of P2C tweaked outputs is
> covered'''P2C tweaks commit to external data, some of which may represent
> certain value (like in some sidechains, single-use-seal applications like
> RGB etc). Creation of such outputs much allow hardware devices to
> understand the structure of such extra-transaction data, which may be in
> different formats and constantly involve. Thus, this should be addresses
> with a separate standards (or be a vendor-based). The current proposal only
> touches the question of spending an output which contained previously
> created P2C commitment, which does not creates a new commitment and does
> not provides that kind of risk of extra-blockchain value loses.</ref>
>
>
> ==Rationale==
>
> <references/>
>
>
> ==Compatibility==
>
> The proposal is compatible with the existing consensus rules and does not
> require any of their modifications.
>
> The proposed P2C PSBT fields provides sufficient information for creating a
> valid signatures for spendings of the following output types containing
> tweaked
> public keys:
> - bare scripts,
> - P2PK,
> - P2PKH,
> - P2SH,
> - witness v0 P2WPKH and P2WSH,
> - nested witness v0 P2WPKH-P2SH and P2WSH-P2SH,
> - witness v1 P2TR outputs.
>
> Possible future witness versions, including witness v1 non-taproot outputs
> may
> not be supported or covered by this BIP and may require addition of new
> fields
> to the PSBT inputs.
>
>
> ==Reference implementation==
>
> WIP
>
>
> ==Acknowledgements==
>
> TBD
>
>
> ==Test vectors==
>
> TBD
>
>
> ==References==
>
> [1] Ilja Gerhardt, Timo Hanke. Homomorphic Payment Addresses and the
>     Pay-to-Contract Protocol. arXiv:1212.3257 \[cs.CR\]
>     <https://arxiv.org/pdf/1212.3257.pdf>
> [2] Eternity Wall's "sign-to-contract" article.
>     <https://blog.eternitywall.com/2018/04/13/sign-to-contract/>
> [3] Peter Todd. OpenTimestamps: Scalable, Trust-Minimized, Distributed
>     Timestamping with Bitcoin.
>     <https://petertodd.org/2016/opentimestamps-announcement>
> [4] Adam Back, Matt Corallo, Luke Dashjr, et al. Enabling Blockchain
>     Innovations with Pegged Sidechains (commit5620e43). Appenxix A.
>     <https://blockstream.com/sidechains.pdf>;.
> [5] Maxim Orlovsky, Rene Pickhardt, Federico Tenga, et al. Key
>     tweaking: collision- resistant elliptic curve-based commitments.
>     LNPBP-1 Standard.
>     <https://github.com/LNP-BP/LNPBPs/blob/master/lnpbp-0001.md>
> [6] Peter Todd. Single-use-seals. LNPBP-8 Standard.
>     <https://github.com/LNP-BP/LNPBPs/blob/master/lnpbp-0008.md>
>
> --
> Maxim Orlovsky
> orlovsky at protonmail.com
> GitHub: @dr-orlovsky
> Twitter: @dr_orlovsky
>
> LNP/BP Standards Association
> orlovsky at lnp-bp.org
> github.com/LNP-BP
>
>
>
>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220116/f4204300/attachment-0001.html>

From erik at q32.com  Mon Jan 17 21:51:55 2022
From: erik at q32.com (Erik Aronesty)
Date: Mon, 17 Jan 2022 16:51:55 -0500
Subject: [bitcoin-dev] bip39
Message-ID: <CAJowKg+Wr0agLLGfCB=yAJrUn0tXWieyuoz2TFv6W1Ahj8Td2w@mail.gmail.com>

really don't like that art, work, and artwork are 3 different words

would be nice to clean up adjacent ambiguity

it's not a big deal, but it can lead to confusion when writing things down


dup: ('canal', 'arm') ('can', 'alarm')
dup: ('canal', 'one') ('can', 'alone')
dup: ('canal', 'ready') ('can', 'already')
dup: ('card', 'anger') ('car', 'danger')
dup: ('card', 'ice') ('car', 'dice')
dup: ('card', 'inner') ('car', 'dinner')
dup: ('card', 'raw') ('car', 'draw')
dup: ('cart', 'able') ('car', 'table')
dup: ('cart', 'ask') ('car', 'task')
dup: ('cart', 'hat') ('car', 'that')
dup: ('cart', 'hen') ('car', 'then')
dup: ('cart', 'issue') ('car', 'tissue')
dup: ('cart', 'one') ('car', 'tone')
dup: ('cart', 'own') ('car', 'town')
dup: ('cart', 'rack') ('car', 'track')
dup: ('cart', 'rain') ('car', 'train')
dup: ('cart', 'win') ('car', 'twin')
dup: ('catch', 'air') ('cat', 'chair')
dup: ('erase', 'arch') ('era', 'search')
dup: ('fatal', 'arm') ('fat', 'alarm')
dup: ('fatal', 'one') ('fat', 'alone')
dup: ('fatal', 'ready') ('fat', 'already')
dup: ('feed', 'anger') ('fee', 'danger')
dup: ('feed', 'ice') ('fee', 'dice')
dup: ('feed', 'inner') ('fee', 'dinner')
dup: ('feed', 'raw') ('fee', 'draw')
dup: ('feel', 'earn') ('fee', 'learn')
dup: ('feel', 'end') ('fee', 'lend')
dup: ('gasp', 'act') ('gas', 'pact')
dup: ('gasp', 'age') ('gas', 'page')
dup: ('gasp', 'air') ('gas', 'pair')
dup: ('gasp', 'ill') ('gas', 'pill')
dup: ('gasp', 'raise') ('gas', 'praise')
dup: ('gasp', 'rice') ('gas', 'price')
dup: ('gasp', 'ride') ('gas', 'pride')
dup: ('gasp', 'roof') ('gas', 'proof')
dup: ('kite', 'merge') ('kit', 'emerge')
dup: ('kite', 'motion') ('kit', 'emotion')
dup: ('kite', 'state') ('kit', 'estate')
dup: ('lawn', 'arrow') ('law', 'narrow')
dup: ('lawn', 'either') ('law', 'neither')
dup: ('lawn', 'ice') ('law', 'nice')
dup: ('legal', 'arm') ('leg', 'alarm')
dup: ('legal', 'one') ('leg', 'alone')
dup: ('legal', 'ready') ('leg', 'already')
dup: ('seat', 'able') ('sea', 'table')
dup: ('seat', 'ask') ('sea', 'task')
dup: ('seat', 'hat') ('sea', 'that')
dup: ('seat', 'hen') ('sea', 'then')
dup: ('seat', 'issue') ('sea', 'tissue')
dup: ('seat', 'one') ('sea', 'tone')
dup: ('seat', 'own') ('sea', 'town')
dup: ('seat', 'rack') ('sea', 'track')
dup: ('seat', 'rain') ('sea', 'train')
dup: ('seat', 'win') ('sea', 'twin')
dup: ('skin', 'arrow') ('ski', 'narrow')
dup: ('skin', 'either') ('ski', 'neither')
dup: ('skin', 'ice') ('ski', 'nice')
dup: ('tent', 'able') ('ten', 'table')
dup: ('tent', 'ask') ('ten', 'task')
dup: ('tent', 'hat') ('ten', 'that')
dup: ('tent', 'hen') ('ten', 'then')
dup: ('tent', 'issue') ('ten', 'tissue')
dup: ('tent', 'one') ('ten', 'tone')
dup: ('tent', 'own') ('ten', 'town')
dup: ('tent', 'rack') ('ten', 'track')
dup: ('tent', 'rain') ('ten', 'train')
dup: ('tent', 'win') ('ten', 'twin')
dup: ('used', 'anger') ('use', 'danger')
dup: ('used', 'ice') ('use', 'dice')
dup: ('used', 'inner') ('use', 'dinner')
dup: ('used', 'raw') ('use', 'draw')
dup: ('wine', 'merge') ('win', 'emerge')
dup: ('wine', 'motion') ('win', 'emotion')
dup: ('wine', 'state') ('win', 'estate')
dup: ('wing', 'host') ('win', 'ghost')
dup: ('wing', 'love') ('win', 'glove')
dup: ('wing', 'old') ('win', 'gold')
dup: ('wing', 'own') ('win', 'gown')
dup: ('wing', 'race') ('win', 'grace')
dup: ('wing', 'rain') ('win', 'grain')
dup: ('wink', 'now') ('win', 'know')
dup: ('youth', 'under') ('you', 'thunder')

From jlrubin at mit.edu  Mon Jan 17 22:38:12 2022
From: jlrubin at mit.edu (Jeremy)
Date: Mon, 17 Jan 2022 14:38:12 -0800
Subject: [bitcoin-dev] bip39
In-Reply-To: <CAJowKg+Wr0agLLGfCB=yAJrUn0tXWieyuoz2TFv6W1Ahj8Td2w@mail.gmail.com>
References: <CAJowKg+Wr0agLLGfCB=yAJrUn0tXWieyuoz2TFv6W1Ahj8Td2w@mail.gmail.com>
Message-ID: <CAD5xwhhOP_evDPGhEWq6UL9_xuYUCAQs7CCttVCKcdf5V5CdFw@mail.gmail.com>

This is a good point, but can be addressed by having a non-void whitespace
character (e.g., win x estate).

changing BIP39 would be hard since software expects a standard list; it
would also be possible to rejection sample for seeds that do not contain
these pairs, unclear how much entropy would be lost from that.
--
@JeremyRubin <https://twitter.com/JeremyRubin>
<https://twitter.com/JeremyRubin>


On Mon, Jan 17, 2022 at 2:26 PM Erik Aronesty via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> really don't like that art, work, and artwork are 3 different words
>
> would be nice to clean up adjacent ambiguity
>
> it's not a big deal, but it can lead to confusion when writing things down
>
>
> dup: ('canal', 'arm') ('can', 'alarm')
> dup: ('canal', 'one') ('can', 'alone')
> dup: ('canal', 'ready') ('can', 'already')
> dup: ('card', 'anger') ('car', 'danger')
> dup: ('card', 'ice') ('car', 'dice')
> dup: ('card', 'inner') ('car', 'dinner')
> dup: ('card', 'raw') ('car', 'draw')
> dup: ('cart', 'able') ('car', 'table')
> dup: ('cart', 'ask') ('car', 'task')
> dup: ('cart', 'hat') ('car', 'that')
> dup: ('cart', 'hen') ('car', 'then')
> dup: ('cart', 'issue') ('car', 'tissue')
> dup: ('cart', 'one') ('car', 'tone')
> dup: ('cart', 'own') ('car', 'town')
> dup: ('cart', 'rack') ('car', 'track')
> dup: ('cart', 'rain') ('car', 'train')
> dup: ('cart', 'win') ('car', 'twin')
> dup: ('catch', 'air') ('cat', 'chair')
> dup: ('erase', 'arch') ('era', 'search')
> dup: ('fatal', 'arm') ('fat', 'alarm')
> dup: ('fatal', 'one') ('fat', 'alone')
> dup: ('fatal', 'ready') ('fat', 'already')
> dup: ('feed', 'anger') ('fee', 'danger')
> dup: ('feed', 'ice') ('fee', 'dice')
> dup: ('feed', 'inner') ('fee', 'dinner')
> dup: ('feed', 'raw') ('fee', 'draw')
> dup: ('feel', 'earn') ('fee', 'learn')
> dup: ('feel', 'end') ('fee', 'lend')
> dup: ('gasp', 'act') ('gas', 'pact')
> dup: ('gasp', 'age') ('gas', 'page')
> dup: ('gasp', 'air') ('gas', 'pair')
> dup: ('gasp', 'ill') ('gas', 'pill')
> dup: ('gasp', 'raise') ('gas', 'praise')
> dup: ('gasp', 'rice') ('gas', 'price')
> dup: ('gasp', 'ride') ('gas', 'pride')
> dup: ('gasp', 'roof') ('gas', 'proof')
> dup: ('kite', 'merge') ('kit', 'emerge')
> dup: ('kite', 'motion') ('kit', 'emotion')
> dup: ('kite', 'state') ('kit', 'estate')
> dup: ('lawn', 'arrow') ('law', 'narrow')
> dup: ('lawn', 'either') ('law', 'neither')
> dup: ('lawn', 'ice') ('law', 'nice')
> dup: ('legal', 'arm') ('leg', 'alarm')
> dup: ('legal', 'one') ('leg', 'alone')
> dup: ('legal', 'ready') ('leg', 'already')
> dup: ('seat', 'able') ('sea', 'table')
> dup: ('seat', 'ask') ('sea', 'task')
> dup: ('seat', 'hat') ('sea', 'that')
> dup: ('seat', 'hen') ('sea', 'then')
> dup: ('seat', 'issue') ('sea', 'tissue')
> dup: ('seat', 'one') ('sea', 'tone')
> dup: ('seat', 'own') ('sea', 'town')
> dup: ('seat', 'rack') ('sea', 'track')
> dup: ('seat', 'rain') ('sea', 'train')
> dup: ('seat', 'win') ('sea', 'twin')
> dup: ('skin', 'arrow') ('ski', 'narrow')
> dup: ('skin', 'either') ('ski', 'neither')
> dup: ('skin', 'ice') ('ski', 'nice')
> dup: ('tent', 'able') ('ten', 'table')
> dup: ('tent', 'ask') ('ten', 'task')
> dup: ('tent', 'hat') ('ten', 'that')
> dup: ('tent', 'hen') ('ten', 'then')
> dup: ('tent', 'issue') ('ten', 'tissue')
> dup: ('tent', 'one') ('ten', 'tone')
> dup: ('tent', 'own') ('ten', 'town')
> dup: ('tent', 'rack') ('ten', 'track')
> dup: ('tent', 'rain') ('ten', 'train')
> dup: ('tent', 'win') ('ten', 'twin')
> dup: ('used', 'anger') ('use', 'danger')
> dup: ('used', 'ice') ('use', 'dice')
> dup: ('used', 'inner') ('use', 'dinner')
> dup: ('used', 'raw') ('use', 'draw')
> dup: ('wine', 'merge') ('win', 'emerge')
> dup: ('wine', 'motion') ('win', 'emotion')
> dup: ('wine', 'state') ('win', 'estate')
> dup: ('wing', 'host') ('win', 'ghost')
> dup: ('wing', 'love') ('win', 'glove')
> dup: ('wing', 'old') ('win', 'gold')
> dup: ('wing', 'own') ('win', 'gown')
> dup: ('wing', 'race') ('win', 'grace')
> dup: ('wing', 'rain') ('win', 'grain')
> dup: ('wink', 'now') ('win', 'know')
> dup: ('youth', 'under') ('you', 'thunder')
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220117/2bbe5f2e/attachment.html>

From stick at satoshilabs.com  Mon Jan 17 22:45:20 2022
From: stick at satoshilabs.com (Pavol Rusnak)
Date: Mon, 17 Jan 2022 23:45:20 +0100
Subject: [bitcoin-dev] bip39
In-Reply-To: <CAD5xwhhOP_evDPGhEWq6UL9_xuYUCAQs7CCttVCKcdf5V5CdFw@mail.gmail.com>
References: <CAJowKg+Wr0agLLGfCB=yAJrUn0tXWieyuoz2TFv6W1Ahj8Td2w@mail.gmail.com>
 <CAD5xwhhOP_evDPGhEWq6UL9_xuYUCAQs7CCttVCKcdf5V5CdFw@mail.gmail.com>
Message-ID: <CAF90AvnLqyC=yDcT8yWORfQPKHPn06_YFffj9WGbP9+v5RZ1Fw@mail.gmail.com>

Trezor recovery cards look like this what addresses the issue:

https://wiki.trezor.io/images/Seed_card_example.jpg

1. Each word has a box around it.
2. You write the words one under the other, not next to each other.


On Mon, 17 Jan 2022 at 23:38, Jeremy via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> This is a good point, but can be addressed by having a non-void whitespace
> character (e.g., win x estate).
>
> changing BIP39 would be hard since software expects a standard list; it
> would also be possible to rejection sample for seeds that do not contain
> these pairs, unclear how much entropy would be lost from that.
> --
> @JeremyRubin <https://twitter.com/JeremyRubin>
> <https://twitter.com/JeremyRubin>
>
>
> On Mon, Jan 17, 2022 at 2:26 PM Erik Aronesty via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>> really don't like that art, work, and artwork are 3 different words
>>
>> would be nice to clean up adjacent ambiguity
>>
>> it's not a big deal, but it can lead to confusion when writing things down
>>
>>
>> dup: ('canal', 'arm') ('can', 'alarm')
>> dup: ('canal', 'one') ('can', 'alone')
>> dup: ('canal', 'ready') ('can', 'already')
>> dup: ('card', 'anger') ('car', 'danger')
>> dup: ('card', 'ice') ('car', 'dice')
>> dup: ('card', 'inner') ('car', 'dinner')
>> dup: ('card', 'raw') ('car', 'draw')
>> dup: ('cart', 'able') ('car', 'table')
>> dup: ('cart', 'ask') ('car', 'task')
>> dup: ('cart', 'hat') ('car', 'that')
>> dup: ('cart', 'hen') ('car', 'then')
>> dup: ('cart', 'issue') ('car', 'tissue')
>> dup: ('cart', 'one') ('car', 'tone')
>> dup: ('cart', 'own') ('car', 'town')
>> dup: ('cart', 'rack') ('car', 'track')
>> dup: ('cart', 'rain') ('car', 'train')
>> dup: ('cart', 'win') ('car', 'twin')
>> dup: ('catch', 'air') ('cat', 'chair')
>> dup: ('erase', 'arch') ('era', 'search')
>> dup: ('fatal', 'arm') ('fat', 'alarm')
>> dup: ('fatal', 'one') ('fat', 'alone')
>> dup: ('fatal', 'ready') ('fat', 'already')
>> dup: ('feed', 'anger') ('fee', 'danger')
>> dup: ('feed', 'ice') ('fee', 'dice')
>> dup: ('feed', 'inner') ('fee', 'dinner')
>> dup: ('feed', 'raw') ('fee', 'draw')
>> dup: ('feel', 'earn') ('fee', 'learn')
>> dup: ('feel', 'end') ('fee', 'lend')
>> dup: ('gasp', 'act') ('gas', 'pact')
>> dup: ('gasp', 'age') ('gas', 'page')
>> dup: ('gasp', 'air') ('gas', 'pair')
>> dup: ('gasp', 'ill') ('gas', 'pill')
>> dup: ('gasp', 'raise') ('gas', 'praise')
>> dup: ('gasp', 'rice') ('gas', 'price')
>> dup: ('gasp', 'ride') ('gas', 'pride')
>> dup: ('gasp', 'roof') ('gas', 'proof')
>> dup: ('kite', 'merge') ('kit', 'emerge')
>> dup: ('kite', 'motion') ('kit', 'emotion')
>> dup: ('kite', 'state') ('kit', 'estate')
>> dup: ('lawn', 'arrow') ('law', 'narrow')
>> dup: ('lawn', 'either') ('law', 'neither')
>> dup: ('lawn', 'ice') ('law', 'nice')
>> dup: ('legal', 'arm') ('leg', 'alarm')
>> dup: ('legal', 'one') ('leg', 'alone')
>> dup: ('legal', 'ready') ('leg', 'already')
>> dup: ('seat', 'able') ('sea', 'table')
>> dup: ('seat', 'ask') ('sea', 'task')
>> dup: ('seat', 'hat') ('sea', 'that')
>> dup: ('seat', 'hen') ('sea', 'then')
>> dup: ('seat', 'issue') ('sea', 'tissue')
>> dup: ('seat', 'one') ('sea', 'tone')
>> dup: ('seat', 'own') ('sea', 'town')
>> dup: ('seat', 'rack') ('sea', 'track')
>> dup: ('seat', 'rain') ('sea', 'train')
>> dup: ('seat', 'win') ('sea', 'twin')
>> dup: ('skin', 'arrow') ('ski', 'narrow')
>> dup: ('skin', 'either') ('ski', 'neither')
>> dup: ('skin', 'ice') ('ski', 'nice')
>> dup: ('tent', 'able') ('ten', 'table')
>> dup: ('tent', 'ask') ('ten', 'task')
>> dup: ('tent', 'hat') ('ten', 'that')
>> dup: ('tent', 'hen') ('ten', 'then')
>> dup: ('tent', 'issue') ('ten', 'tissue')
>> dup: ('tent', 'one') ('ten', 'tone')
>> dup: ('tent', 'own') ('ten', 'town')
>> dup: ('tent', 'rack') ('ten', 'track')
>> dup: ('tent', 'rain') ('ten', 'train')
>> dup: ('tent', 'win') ('ten', 'twin')
>> dup: ('used', 'anger') ('use', 'danger')
>> dup: ('used', 'ice') ('use', 'dice')
>> dup: ('used', 'inner') ('use', 'dinner')
>> dup: ('used', 'raw') ('use', 'draw')
>> dup: ('wine', 'merge') ('win', 'emerge')
>> dup: ('wine', 'motion') ('win', 'emotion')
>> dup: ('wine', 'state') ('win', 'estate')
>> dup: ('wing', 'host') ('win', 'ghost')
>> dup: ('wing', 'love') ('win', 'glove')
>> dup: ('wing', 'old') ('win', 'gold')
>> dup: ('wing', 'own') ('win', 'gown')
>> dup: ('wing', 'race') ('win', 'grace')
>> dup: ('wing', 'rain') ('win', 'grain')
>> dup: ('wink', 'now') ('win', 'know')
>> dup: ('youth', 'under') ('you', 'thunder')
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>


-- 
Best Regards / S pozdravom,

Pavol "stick" Rusnak
Co-Founder, SatoshiLabs
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220117/76b742a6/attachment-0001.html>

From jlrubin at mit.edu  Tue Jan 18 01:48:38 2022
From: jlrubin at mit.edu (Jeremy)
Date: Mon, 17 Jan 2022 17:48:38 -0800
Subject: [bitcoin-dev] SASE Invoices
Message-ID: <CAD5xwhiP=jYHqnBTmwqJZkKGzSbRpWG+TGoXvuZU=m6KKBKakg@mail.gmail.com>

Devs,

I was recently speaking with Casey R about some of the infrastructural
problems with addresses and felt it would be worth summarizing some notes
from that conversation for y'all to consider more broadly.

Currently, when you generate (e.g., a Taproot address):

- The key may or may not be a NUMS point
- Script paths might still be required for safety (e.g. a backup federation)
- There may be single use constructs (e.g. HTLC)
- The amount required to be sent might be specific (e.g., HTLC or a vault)

These issues exist in other address types as well, and covenants (such as
the kinds enabled by TLUV, APO, or CTV) make exact amounts also important.

As such, it may make sense to specify a new type of Invoice that's a bit
like a SASE, a "Self Addressed Stamped Envelope". SASEs simplify mail
processing because the processor just puts whatever was requested in the
exact envelope you provided, and that's "self authenticated".

A SASE Invoice for Bitcoin might look like an address *plus* a signature
covering that address and any metadata required for the payment to be
considered valid. For example, I might make a TR key and specify that it is
my hot wallet and therefore permitted for only between 0 to 1 Bitcoin. Or I
might specify for a covenant containing address it should only have 0.1234
Bitcoin exactly. Other use cases might include "good for one payment only"
or "please do not use after xxxx date, contact to renew". Some of these
might be perilous, so it's worth careful thought on what acceptable SASE
policies might be.

Businesses making payments might receive a SASE Invoice and save the SASE.
Then, in the future, a SASE can be used e.g. in dispute mediation to show
that the payment sent corresponded to the one requested by that address.
Businesses could even give users unique codes to put into their SASE
generator to bind the address for their own use / to ensure the usage right
of the address isn't transferrable.

if the top-level TR key is a NUMS point, and no signature can be produced
(as might happen for a covenant), then it could be a NUMS point derived
from the hash-to-curve of the SASE Invoice policy.

Such SASE Invoice standards would also go a long way towards
combating address reuse. If standard software does not produce reusable
SASE Invoices, then it would be clear to users that they should generate a
SASE with the expected amount per requested payment.

A well designed SASE spec could also cover things like EPKs and derivation
paths as well.

Previously, https://github.com/bitcoin/bips/blob/master/bip-0070.mediawiki
was designed in a similar problem space. A big part of SASE invoices would
be for it to be focused on generating fixed payment codes rather than
initiating an online protocol / complicated handshaking.

Cheers,

Jeremy

p.s.:

There's something that looks even *more* like a single use SASE where you
might use one of your existing UTXOs with anyonecanpay and single to pay to
an output which has the funds requested + the funds in the output. a payer
paying this transaction has no choice but to pay you the correct
amount/fees for the specific txn, and it clearly cannot be reused. This is
quite bizarre though, but is noted here if anyone wants something even
closer to a physical SASE.

--
@JeremyRubin <https://twitter.com/JeremyRubin>
<https://twitter.com/JeremyRubin>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220117/3ad89367/attachment.html>

From prayank at tutanota.de  Tue Jan 18 01:57:30 2022
From: prayank at tutanota.de (Prayank)
Date: Tue, 18 Jan 2022 02:57:30 +0100 (CET)
Subject: [bitcoin-dev] Stumbling into a contentious soft fork activation
 attempt
Message-ID: <MtetoOZ--3-2@tutanota.de>

Hi Peter,

> that current lacks compelling use-cases clearly beneficial to all users

All the use cases shared in below links look compelling enough to me and we can do anything that a programmer could think of using such restrictions:

 https://utxos.org/uses/

https://rubin.io/archive/

> I don't think CTV in its current form makes that case sufficiently, and the technical details are lacking.
CTV cannot be compared to segwit or taproot. We are expecting different things in that case. CTV is trying to do add basic covenants in Bitcoin that would help all Bitcoin users. Most important thing missing in lot of conversations is the low demand for block space which affects everyone who understands importance of fees in long term. Right now fee rates only spike during peak bull markets which indicate the only use case is speculation and this can be improved if developers could do better things with Bitcoin smart contracts.

This would also ensure that we don't end up with something really contentious in future that changes supply.

> DoS Attacks

I think this was already answered by Jeremy and pull request to add related information is also merged:

https://github.com/bitcoin/bips/pull/1272


-- 
Prayank

A3B1 E430 2298 178F
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/47c8c867/attachment.html>

From billy.tetrud at gmail.com  Tue Jan 18 15:10:33 2022
From: billy.tetrud at gmail.com (Billy Tetrud)
Date: Tue, 18 Jan 2022 09:10:33 -0600
Subject: [bitcoin-dev] Covenants and capabilities in the UTXO model
In-Reply-To: <CAHUJnBBFsS597ZRdAtwONMAz1r7gQbrXULzdNtEVxOPENx+tDg@mail.gmail.com>
References: <CAHUJnBBFsS597ZRdAtwONMAz1r7gQbrXULzdNtEVxOPENx+tDg@mail.gmail.com>
Message-ID: <CAGpPWDYvvtCJLsr1SqghugfntnmnKw+GOtufp07d8sN-5vKa0w@mail.gmail.com>

>  Since scriptpubkeys/scriptsigs continue to run ephemerally at validation
time full turing completeness is much less dangerous than people fear.

The covenant proposals I've seen that might give bitcoin turing
completeness require a turing complete process to be stepped such that each
step is a transaction paid for with a usual fee. This fact I think makes
the turing completeness a lot less scary. No single transaction would be
turing complete, while a sequence of them could be. But importantly, each
transaction has a strictly limited runtime and every script could continue
to have a calculable number of maximum runtime steps.

> The main thing missing from what's expressed in transactions themselves
is a coherent notion of a single parent of each output instead of the
all-inputs-lead-to-all-outputs approach of transactions currently.

I'm curious to hear more about specifically what you mean by this. I think
there are covenant proposals that do that. TLUV has the concept of
specifying which output should have a script that's "modified" in a
particular way. CTV basically specifies a specific output set. My own
OP_CONSTRAINDESTINATION
<https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/cd/bip-constraindestination.md>
also specifies what outputs the value of the input is transferred to. Is
this what you mean?

> It would also probably be a good idea to add in a bunch of special
purpose opcodes for making coherent statements about transactions since in
Bitcoin they're a very complex and hard to parse format.

What are some examples you're thinking of?

> Once you start implementing complex general purpose functionality it
tends to get very expensive very fast and is likely impractical unless
there's a way to compress or at least de-duplicate snippets of code which
are repeated on chain.

I like this idea. If there was a way to dedupe scripts in some way, it
could save a lot of bandwidth which would help bitcoin scale better. One
thing we could do is have a specific set of pre-ordained script snippets
that are given a shorthand that's stored in the software and explicitly
shouldn't be transmitted long-hand. That would help for very standard
widespread things. We could even add in a consensus rule where short-handed
scripts pay for their expanded vbytes, not the vbytes of the compressed
version. This would mean the incentives wouldn't be changed by this
approach.

We could also imagine a more dynamic approach, where nodes keep an index of
scripts or script snippets in some way, and keep around ones that it sees
most often. I'm not sure how this would work, since a script can contain a
lot of unique values and there's no clear way to split a script into
pieces. Perhaps script segments could be committed to the chain and nodes
could attempt to only store and reuse these paid-for segments, maybe only
the X most paid-for scripts (the scripts committed with the largest fee,
potentially across multiple explicit standalone commitments). However, this
dynamic approach would also have some scalability benefits, tho it would be
a bit more chaotic. Any node transmitting transactions would only need to
send the script segments when the node they're transmitting to requests
them. However, the extra script references also take up space, and so if
the ratio of how often the node has a script segment to how often they
don't is bad enough, this could a net negative scalability wise.

> For a payment to someone to come with a rider where they could accept it
and think their system was working properly for a while until you exercised
some kind of retroactive veto on new action or even clawback would
obviously be unacceptable behavior.

I definitely agree. A payment's covenant should be completely knowable to
the recipient, and recipients shouldn't accept random covenants they
haven't explicitly accepted on their own.

> for payments to come with covenants but the recipient not even be able to
parse them unless they're fully buying into that behavior is much more
reasonable.

The recipient not being able to parse them? Couldn't that result in exactly
the situation above you said was not acceptable? The recipient must be able
to know all the possibilities of the covenant or there might be some secret
retroactive clawback in there waiting to bite them.



On Fri, Dec 31, 2021 at 6:41 PM Bram Cohen via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> There are a few different approaches to adding covenants and capabilities
> to the UTXO model with varying tradeoffs. It turns out that it can be done
> while making very few but not quite zero compromises to practices Bitcoin
> has been following so far.
>
> First, the good news: Full support for both capabilities and covenants can
> be added without changing the UTXO model whatsoever by adding some more
> programmatic capabilities to the language and doing some programmatic
> tricks. Since scriptpubkeys/scriptsigs continue to run ephemerally at
> validation time full turing completeness is much less dangerous than people
> fear. The main thing missing from what's expressed in transactions
> themselves is a coherent notion of a single parent of each output instead
> of the all-inputs-lead-to-all-outputs approach of transactions currently.
> It would also probably be a good idea to add in a bunch of special purpose
> opcodes for making coherent statements about transactions since in Bitcoin
> they're a very complex and hard to parse format.
>
> Now for the controversial stuff. Once you start implementing complex
> general purpose functionality it tends to get very expensive very fast and
> is likely impractical unless there's a way to compress or at least
> de-duplicate snippets of code which are repeated on chain. Currently
> Bitcoin has a strong policy that deciding which transactions to let into a
> block for maximum fee is a strictly linear optimization problem and while
> it's possible to keep things mostly that way making it completely strict is
> unlikely to workable. About as close as you can get is to make it so that
> each block can reference code snippets in previous blocks for
> deduplication, so at least the optimization is linear for each block by
> itself.
>
> Having covenants and capabilities at all is controversial in and of
> itself. With covenants the main issue is whether they're opt-in or opt-out.
> For a payment to someone to come with a rider where they could accept it
> and think their system was working properly for a while until you exercised
> some kind of retroactive veto on new action or even clawback would
> obviously be unacceptable behavior. But for payments to come with covenants
> but the recipient not even be able to parse them unless they're fully
> buying into that behavior is much more reasonable.
>
> The main issue which people have raised with capabilities is that if you
> were to have colored coins whose value was substantially greater than the
> chain they were tokenized on then that could potentially create a business
> model for attacking the underlying chain. While this is a real concern
> tokenized assets have been out for a while now and have never come close to
> causing this to happen, so maybe people aren't so worried about it now.
>
> Given all the above caveats it turns out one weird trick is all you need
> to support general purpose capabilities: for a UTXO to have a capability
> its scriptpubkey asserts that its parent must either be the originator of
> that capability or also conform to the same parent-asserting format. More
> complex functionality such as supporting on-chain verifiable colored coins
> can also be done but it follows the same pattern: Capabilities are
> implemented as backwards pointing covenants.
>
> If you'd like to see a fleshed out implementation of these ideas (albeit
> in a slightly different model) there's quite a bit of stuff on
> chialisp.com
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/ac735de0/attachment-0001.html>

From billy.tetrud at gmail.com  Tue Jan 18 16:00:06 2022
From: billy.tetrud at gmail.com (Billy Tetrud)
Date: Tue, 18 Jan 2022 10:00:06 -0600
Subject: [bitcoin-dev] On the regularity of soft forks
In-Reply-To: <151636693-b9baa24a337b74e4b019a92e12c81eff@pmq4v.m5r2.onet>
References: <151636693-b9baa24a337b74e4b019a92e12c81eff@pmq4v.m5r2.onet>
Message-ID: <CAGpPWDa8=kBV6ooayjpkqnsQnpv9V-iLe=ZqvLmGP=Zttjt0UA@mail.gmail.com>

I agree with you Michael, there is a risk to soft forks and we shouldn't do
them too often. We should do them as infrequently as practical. We should
strive to one day get to a point where the bitcoin consensus isn't updating
at all.

Perhaps we should come to a consensus as a consensus as a community what
the minimum time between soft forks should be, and just as importantly,
what the minimum time between finalized consensus-change implementation and
when we decide community consensus has been achieved.

How long do you think these minimums should be? I'm curious to know
everyone's answer to this. I would think of these like I think about
changes to how I think national law should be changed: slowly and
carefully. There should be sufficient time for everyone to have a chance in
their busy lives to take the time to look at it, if they care, so they can
raise objections. I think the minimum time between a soft fork
implementation finalization and determining consensus should be maybe a
year. And the minimum time between soft forks should probably be something
like 5 years. This would mean that people only have to worry about paying
attention to what might happen with bitcoin consensus once every 5 years,
and would get a year-long window to do it. And if there isn't sufficient
consensus, or people bring up objections at the last minute, that should be
acceptable and it should further delay the deployment.

I think a lot of folks on here are rightly concerned about compromise
bundles where multiple mediocre proposals are put together
to basically incentivize some people to accept something they don't want
in order to receive something they do want (eg what Jeremy quoted Matt
Corallo about). But I don't think that's what Michael was suggesting at
all. That kind of compromise happens in the *decision making process*. My
understanding of what Michael was saying is that releasing a soft fork
should *not* be within the decision making process at all. The decision
making process should have already happened.

If you have consensus changes A and B, Michael was saying that each
consensus change proposal should go through a community vetting process
that determines that there is widespread supermajority support for it
*before* it is even merged into the code (ie master, or some equivalent
this-will-be-deployed branch). It should have a final implementation that
has been tested at all levels *before* its merged to master. And only then
should it potentially be bundled. After all testing has already been done,
after sufficient consensus has already been determined.

@Keagan
> When we start to bundle things, we amplify the community resources needed
to do review, not reduce them.

I think my above 2 paragraphs address this. I agree we don't want to review
these proposals together, they should be reviewed separately. And I don't
think Michael was suggesting otherwise.

> the protocol itself adopting a tendency to activate unrelated proposals
in bundles is a recipe for disaster.

Activating multiple consensus changes in a bundle is far safer than having
multiple separate in-flight soft forks at once. With multiple in-flight
soft forks, you have many combinations of what might happen (and therefore
what needs to be tested beforehand). Just 3 in-flight soft forks means 9
cases: nine orders of what might happen. All those combinations must be
exhaustively tested as all consensus changes must be. This is far more
work, more complicated, and more error prone than bundling them together in
one soft fork.

@Prayank
> However I am sure there are lot of people who still think miners vote
during signaling. ... I could not think of any solution to solve this
problem.

One solution is that we could be a lot more direct about how decisions are
made. There's been a lot of rhetoric around UASF and how the economic
majority is really who's running the show. If that's the case, why not make
that explicitly? Why not actually ask users to sign a petition saying they
support a particular consensus change? This could be done with actual
signatures by keys connected to UTXOs so we can see the economic weight of
the petition. We would probably need to have a new address format to
prevent problems related to public key exposure (eg by having addresses
containing two public keys: `hash(hash(spendingkey)+hash(votingkey))` where
you can expose the voting key without exposing your spending key). Perhaps
this could be another tapleaf.

Doing this could make it very clear how much of the bitcoin world supports
a particular change without needing to put anything extra on chain. This
clarity would also help the actual miner activation of the software in
cases where miners might have incentives not to activate. If it were clear
that an overwhelming supermajority wants it activated, miners would be less
likely to play games that play off uncertainty. It would also dispel the
idea that miners or developers decide how bitcoin changes.


On Sat, Jan 1, 2022 at 10:00 AM vjudeu via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> > If you don't like the reduction of the block subsidy, well that's a much
> bigger problem.
>
> It is reversible, because you can also increase the block subsidy by using
> another kind of soft-fork. For example, you can create spendable outputs
> with zero satoshis. In this way, old nodes will accept that silently, but
> new nodes can check something more, because you can specify somewhere else,
> what is the "real" amount. Finally, if all nodes will upgrade, you will end
> up in a network, where all transactions spend zero satoshi inputs, create
> zero satoshi outputs and have zero fee. Old nodes would accept all of that,
> but new nodes would really see, what is going on, and they will check that
> all rules are met, and the new subsidy is for example increased x1000 (that
> could lead to the same situation as moving from satoshis to millisatoshis
> with some hard-fork, but doing that kind of change with a soft-fork is
> safer).
>
> On 2021-12-31 10:35:06 user Keagan McClelland via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
> >  But whether or not it is a basic principle of general software
> engineering kind of misses the point. Security critical software clearly
> isn't engineered in the same way as a new social media app. Bugs are easily
> reverted in a new social media app.On top of that we aren't just dealing
> with security critical software. One of the most important objectives is to
> keep all the nodes on the network in consensus. Introducing a consensus
> change before we are comfortable there is community consensus for it is a
> massive effective bug in itself. The network can split in multiple ways
> e.g. part of the network disagrees on whether to activate the consensus
> change, part of the network disagrees on how to resist that consensus
> change, part of the network disagrees on how to activate that consensus
> change etc
>
> >  A consensus change is extremely hard to revert and probably requires a
> hard fork, a level of central coordination we generally attempt to avoid
> and a speed of deployment that we also attempt to avoid.
>
> This seems to assert the idea that soft forks are all the same: they are
> not. For instance a soft fork, lowering the block subsidy is completely
> different than changing the semantics of an OP_NOP to have semantics that
> may reject a subset of the witnesses that attest to the transactions
> permissibility. As a result, reversion means two entirely different things
> in these contexts. While a strict reversion of both soft forks is by
> definition a hard fork, the requirement of reversion as a result of
> undesired behavior is not the same. In the case of opcodes, there is almost
> never a requirement to revert it. If you don't like the way the opcodes
> behave, then you just don't use them. If you don't like the reduction of
> the block subsidy, well that's a much bigger problem.
>
> I make this point to elucidate the idea that we cannot treat SoftForks? as
> a single monolithic idea. Perhaps we need to come up with better
> terminology to be specific about what each fork actually is. The soft vs.
> hard distinction is a critical one but it is not enough and treating soft
> forks that are noninvasive such as OP_NOP tightenings. This has been
> proposed before [1], and while I do not necessarily think the terms cited
> are necessarily complete, they admit the low resolution of our current
> terminology.
>
> > Soft fork features can (and should) obviously be tested thoroughly on
> testnet, signet, custom signets, sidechains etc on a standalone basis and a
> bundled basis.
>
> I vehemently disagree that any consensus changes should be bundled,
> especially when it comes to activation parameters. When we start to bundle
> things, we amplify the community resources needed to do review, not reduce
> them. I suspect your opinion here is largely informed by your frustration
> with the Taproot Activation procedure that you underwent earlier this year.
> This is understandable. However, let me present the alternative case. If we
> start to bundle features, the review of the features gets significantly
> harder. As the Bitcoin project scales, the ability of any one developer to
> understand the entire codebase declines. Bundling changes reduces the
> number of people who are qualified to review a particular proposal, and
> even worse, intimidates people who may be willing and able to review
> logically distinct portions of the proposal, resulting in lower amounts of
> review overall. This will likely have the opposite effect of what you seem
> to desire. BIP8 and BIP9 give us the ability to have multiple independent
> soft forks in flight at once. Choosing to bundle them instead makes little
> sense when we do not have to. Bundling them will inevitably degenerate into
> political horse trading and everyone will be worse off for it.
>
> > part of the network disagrees on whether to activate the consensus
> change, part of the network disagrees on how to resist that consensus
> change, part of the network disagrees on how to activate that consensus
> change etc
>
> Disagreements, and by extension, forks are a part of Bitcoin. What is
> important is that they are well defined and clean. This is the reason why
> the mandatory signaling period exists in BIP8/9, so that clients that
> intend to reject the soft fork change have a very easy means of doing so in
> a clean break where consensus is clearly divergent. In accordance with
> this, consensus changes should be sequenced so that people can decide which
> sides of the forks they want to follow and that the economic reality can
> reorganize around that. If choose to bundle them, you have one of two
> outcomes: either consensus atomizes into a mist where people have different
> ideas of which subsets of a soft fork bundle they want to adopt, or what
> likely comes after is a reconvergence on the old client with none of the
> soft fork rules in place. This will lead to significantly more confusion as
> well given that with sufficient miner consensus some of the rules may stick
> anyway even if the rest of the user base reconverges on the old client.
>
> It is quite likely less damaging to consensus to have frequent but
> strictly sequenced soft forks so that if one of the new rules is
> contentious the break can happen cleanly. That said, if Core or any other
> client wishes to cut a release of the software with the parameters bundled
> into a single release, that is a significantly more palatable state of
> affairs, as you can still pipeline signaling and activation. However, the
> protocol itself adopting a tendency to activate unrelated proposals in
> bundles is a recipe for disaster.
>
>
> Respectfully,
> Keagan
>
>
> [1] https://www.truthcoin.info/blog/protocol-upgrade-terminology
>
> On Sat, Oct 16, 2021 at 12:57 PM Michael Folkson via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org
> <http://../NowaWiadomosc/Do/QlIkBFQ6QUFhIVRZX192dnQBeCtCchE6GhA5LFpLCUc7EVZQVl9dQRIXXR8NCBMbCwIGChJXQFxcXEgcFh8UVVVDEyBdVkE9JVRdEwFhYXVlblhVIkosEAszLR5BQVV7U0MID0BAQUgIGh0RHgAMGAMXBQJfW1sdXRQUQUoDQlAiBFY8>>
> wrote:
>
>> > Interesting discussion. Correct me if I'm wrong: but putting too many
>> features together in one shot just can't make things harder to debug in
>> production if something very unexpected happens. It's a basic principle
>> of software engineering.
>>
>> Soft fork features can (and should) obviously be tested thoroughly on
>> testnet, signet, custom signets, sidechains etc on a standalone basis and a
>> bundled basis. But whether or not it is a basic principle of general
>> software engineering kind of misses the point. Security critical software
>> clearly isn't engineered in the same way as a new social media app. Bugs
>> are easily reverted in a new social media app. A consensus change is
>> extremely hard to revert and probably requires a hard fork, a level of
>> central coordination we generally attempt to avoid and a speed of
>> deployment that we also attempt to avoid. On top of that we aren't just
>> dealing with security critical software. One of the most important
>> objectives is to keep all the nodes on the network in consensus.
>> Introducing a consensus change before we are comfortable there is community
>> consensus for it is a massive effective bug in itself. The network can
>> split in multiple ways e.g. part of the network disagrees on whether to
>> activate the consensus change, part of the network disagrees on how to
>> resist that consensus change, part of the network disagrees on how to
>> activate that consensus change etc
>>
>> In addition, a social media app can experiment in production whether
>> Feature A works, whether Feature B works or whether Feature A and B work
>> best together. In Bitcoin if we activate consensus Feature A, later decide
>> we want consensus Feature B but find out that by previously activating
>> Feature A we can't have Feature B (it is now unsafe to activate it) or its
>> design now has to be suboptimal because we have to ensure it can safely
>> work in the presence of Feature A we have made a mistake by activating
>> Feature A in the first place. Decentralized security critical consensus
>> changes are an emerging field in itself and really can't be treated like
>> any other software project. This will become universally understood I'm
>> sure over time.
>>
>>
>>
>> --Michael Folkson
>> Email: michaelfolkson at protonmail.com
>> Keybase: michaelfolkson
>> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3
>>
>>
>> ??????? Original Message ???????
>> On Friday, October 15th, 2021 at 1:43 AM, Felipe Micaroni Lalli via
>> bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org
>> <http://../NowaWiadomosc/Do/QlIkBFQ6QUFhIVRZX192dnQBeCtCchE6GhA5LFpLCUc7EVZQVl9dQRIXXR8NCBMbCwIGChJXQFxcXEgcFh8UVVVDEyBdVkE9JVRdEwFhYXVlblhVIkosEAszLR5BQVV7U0MID0BAQUgIGh0RHgAMGAMXBQJfW1sdXRQUQUoDQlAiBFY8>>
>> wrote:
>>
>> Interesting discussion. Correct me if I'm wrong: but putting too many
>> features together in one shot just can't make things harder to debug in
>> production if something very unexpected happens. It's a basic principle
>> of software engineering.
>>
>> Change. Deploy. Nothing bad happened? Change it a little more. Deployment.
>> Or: Change, change, change. Deploy. Did something bad happen? What change
>> caused the problem?
>>
>> On Thu, Oct 14, 2021 at 8:53 PM Anthony Towns via bitcoin-dev <
>> bitcoin-dev at lists.linuxfoundation.org
>> <http://../NowaWiadomosc/Do/QlIkBFQ6QUFhIVRZX192dnQBeCtCchE6GhA5LFpLCUc7EVZQVl9dQRIXXR8NCBMbCwIGChJXQFxcXEgcFh8UVVVDEyBdVkE9JVRdEwFhYXVlblhVIkosEAszLR5BQVV7U0MID0BAQUgIGh0RHgAMGAMXBQJfW1sdXRQUQUoDQlAiBFY8>>
>> wrote:
>>
>>> On Mon, Oct 11, 2021 at 12:12:58PM -0700, Jeremy via bitcoin-dev wrote:
>>> > > ... in this post I will argue against frequent soft forks with a
>>> single or
>>> > minimal
>>> > > set of features and instead argue for infrequent soft forks with
>>> batches
>>> > > of features.
>>> > I think this type of development has been discussed in the past and
>>> has been
>>> > rejected.
>>>
>>> > AJ: - improvements: changes might not make everyone better off, but we
>>> >    don't want changes to screw anyone over either -- pareto
>>> >    improvements in economics, "first, do no harm", etc. (if we get this
>>> >    right, there's no need to make compromises and bundle multiple
>>> >    flawed proposals so that everyone's an equal mix of happy and
>>> >    miserable)
>>>
>>> I don't think your conclusion above matches my opinion, for what it's
>>> worth.
>>>
>>> If you've got two features, A and B, where the game theory is:
>>>
>>>  If A happens, I'm +100, You're -50
>>>  If B happens, I'm -50, You're +100
>>>
>>> then even though A+B is +50, +50, then I do think the answer should
>>> generally be "think harder and come up with better proposals" rather than
>>> "implement A+B as a bundle that makes us both +50".
>>>
>>> _But_ if the two features are more like:
>>>
>>>   If C happens, I'm +100, You're +/- 0
>>>   If D happens, I'm +/- 0, You're +100
>>>
>>> then I don't have a problem with bundling them together as a single
>>> simultaneous activation of both C and D.
>>>
>>> Also, you can have situations where things are better together,
>>> that is:
>>>
>>>   If E happens, we're both at +100
>>>   If F happens, we're both at +50
>>>   If E+F both happen, we're both at +9000
>>>
>>> In general, I think combining proposals when the combination is better
>>> than the individual proposals were is obviously good; and combining
>>> related proposals into a single activation can be good if it is easier
>>> to think about the ideas as a set.
>>>
>>> It's only when you'd be rejecting the proposal on its own merits that
>>> I think combining it with others is a bad idea in principle.
>>>
>>> For specific examples, we bundled schnorr, Taproot, MAST, OP_SUCCESSx
>>> and CHECKSIGADD together because they do have synergies like that; we
>>> didn't bundle ANYPREVOUT and graftroot despite the potential synergies
>>> because those features needed substantially more study.
>>>
>>> The nulldummy soft-fork (bip 147) was deployed concurrently with
>>> the segwit soft-fork (bip 141, 143), but I don't think there was any
>>> particular synergy or need for those things to be combined, it just
>>> reduced the overhead of two sets of activation signalling to one.
>>>
>>> Note that the implementation code for nulldummy had already been merged
>>> and were applied as relay policy well before activation parameters were
>>> defined (May 2014 via PR#3843 vs Sep 2016 for PR#8636) let alone becoming
>>> an active soft fork.
>>>
>>> Cheers,
>>> aj
>>>
>>> _______________________________________________
>>> bitcoin-dev mailing list
>>> bitcoin-dev at lists.linuxfoundation.org
>>> <http://../NowaWiadomosc/Do/QlIkBFQ6QUFhIVRZX192dnQBeCtCchE6GhA5LFpLCUc7EVZQVl9dQRIXXR8NCBMbCwIGChJXQFxcXEgcFh8UVVVDEyBdVkE9JVRdEwFhYXVlblhVIkosEAszLR5BQVV7U0MID0BAQUgIGh0RHgAMGAMXBQJfW1sdXRQUQUoDQlAiBFY8>
>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> <http://../NowaWiadomosc/Do/QlIkBFQ6QUFhIVRZX192dnQBeCtCchE6GhA5LFpLCUc7EVZQVl9dQRIXXR8NCBMbCwIGChJXQFxcXEgcFh8UVVVDEyBdVkE9JVRdEwFhYXVlblhVIkosEAszLR5BQVV7U0MID0BAQUgIGh0RHgAMGAMXBQJfW1sdXRQUQUoDQlAiBFY8>
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/6380a1e7/attachment-0001.html>

From billy.tetrud at gmail.com  Tue Jan 18 16:12:36 2022
From: billy.tetrud at gmail.com (Billy Tetrud)
Date: Tue, 18 Jan 2022 10:12:36 -0600
Subject: [bitcoin-dev] [Pre-BIP] Fee Accounts
In-Reply-To: <CAD5xwhik6jVQpP2_ss7d5o+pPLsqDCHuaXG41AMKHVYhZMXF1w@mail.gmail.com>
References: <CAD5xwhik6jVQpP2_ss7d5o+pPLsqDCHuaXG41AMKHVYhZMXF1w@mail.gmail.com>
Message-ID: <CAGpPWDb6HckAhX6p-=cK3fQXyMqivd+xFtiYJ7hKR2k-MWqKJA@mail.gmail.com>

Do you have any back-of-the-napkin math on quantifying how much this would
improve the situation vs existing methods (eg cpfp)?



On Sat, Jan 1, 2022 at 2:04 PM Jeremy via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Happy new years devs,
>
> I figured I would share some thoughts for conceptual review that have been
> bouncing around my head as an opportunity to clean up the fee paying
> semantics in bitcoin "for good". The design space is very wide on the
> approach I'll share, so below is just a sketch of how it could work which
> I'm sure could be improved greatly.
>
> Transaction fees are an integral part of bitcoin.
>
> However, due to quirks of Bitcoin's transaction design, fees are a part of
> the transactions that they occur in.
>
> While this works in a "Bitcoin 1.0" world, where all transactions are
> simple on-chain transfers, real world use of Bitcoin requires support for
> things like Fee Bumping stuck transactions, DoS resistant Payment Channels,
> and other long lived Smart Contracts that can't predict future fee rates.
> Having the fees paid in band makes writing these contracts much more
> difficult as you can't merely express the logic you want for the
> transaction, but also the fees.
>
> Previously, I proposed a special type of transaction called a "Sponsor"
> which has some special consensus + mempool rules to allow arbitrarily
> appending fees to a transaction to bump it up in the mempool.
>
> As an alternative, we could establish an account system in Bitcoin as an
> "extension block".
>
> *Here's how it might work:*
>
> 1. Define a special anyone can spend output type that is a "fee account"
> (e.g. segwit V2). Such outputs have a redeeming key and an amount
> associated with them, but are overall anyone can spend.
> 2. All deposits to these outputs get stored in a separate UTXO database
> for fee accounts
> 3. Fee accounts can sign only two kinds of transaction: A: a fee amount
> and a TXID (or Outpoint?); B: a withdraw amount, a fee, and an address
> 4. These transactions are committed in an extension block merkle tree.
> While the actual signature must cover the TXID/Outpoint, the committed data
> need only cover the index in the block of the transaction. The public key
> for account lookup can be recovered from the message + signature.
> 5. In any block, any of the fee account deposits can be: released into
> fees if there is a corresponding tx; consolidated together to reduce the
> number of utxos (this can be just an OP_TRUE no metadata needed); or
> released into fees *and paid back* into the requested withdrawal key
> (encumbering a 100 block timeout). Signatures must be unique in a block.
> 6. Mempool logic is updated to allow attaching of account fee spends to
> transactions, the mempool can restrict that an account is not allowed more
> spend more than it's balance.
>
> *But aren't accounts "bad"?*
>
> Yes, accounts are bad. But these accounts are not bad, because any funds
> withdrawn from the fee extension are fundamentally locked for 100 blocks as
> a coinbase output, so there should be no issues with any series of reorgs.
> Further, since there is no "rich state" for these accounts, the state
> updates can always be applied in a conflict-free way in any order.
>
>
> *Improving the privacy of this design:*
>
> This design could likely be modified to implement something like
> Tornado.cash or something else so that the fee account paying can be
> unlinked from the transaction being paid for, improving privacy at the
> expense of being a bit more expensive.
>
> Other operations could be added to allow a trustless mixing to be done by
> miners automatically where groups of accounts with similar values are
> trustlessly  split into a common denominator and change, and keys are
> derived via a verifiable stealth address like protocol (so fee balances can
> be discovered by tracing the updates posted). These updates could also be
> produced by individuals rather than miners, and miners could simply honor
> them with better privacy. While a miner generating an update would be able
> to deanonymize their mixes, if you have your account mixed several times by
> independent miners that could potentially add sufficient privacy.
>
> The LN can also be used with PTLCs to, in theory, have another individual
> paid to sponsor a transaction on your behalf only if they reveal a valid
> sig from their fee paying account, although under this model it's hard to
> ensure that the owner doesn't pay a fee and then 'cancel' by withdrawing
> the rest. However, this could be partly solved by using reputable fee
> accounts (reputation could be measured somewhat decentralized-ly by
> longevity of the account and transactions paid for historically).
>
> *Scalability*
>
> This design is fundamentally 'decent' for scalability because adding fees
> to a transaction does not require adding inputs or outputs and does not
> require tracking substantial amounts of new state.
>
> Paying someone else to pay for you via the LN also helps make this more
> efficient if the withdrawal issues can be fixed.
>
> *Lightning:*
>
> This type of design works really well for channels because the addition of
> fees to e.g. a channel state does not require any sort of pre-planning
> (e.g. anchors) or transaction flexibility (SIGHASH flags). This sort of
> design is naturally immune to pinning issues since you could offer to pay a
> fee for any TXID and the number of fee adding offers does not need to be
> restricted in the same way the descendant transactions would need to be.
>
> *Without a fork?*
>
> This type of design could be done as a federated network that bribes
> miners -- potentially even retroactively after a block is formed. That
> might be sufficient to prove the concept works before a consensus upgrade
> is deployed, but such an approach does mean there is a centralizing layer
> interfering with normal mining.
>
>
> Happy new year!!
>
> Jeremy
>
> --
> @JeremyRubin <https://twitter.com/JeremyRubin>
> <https://twitter.com/JeremyRubin>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/655b3d36/attachment.html>

From billy.tetrud at gmail.com  Tue Jan 18 16:33:04 2022
From: billy.tetrud at gmail.com (Billy Tetrud)
Date: Tue, 18 Jan 2022 10:33:04 -0600
Subject: [bitcoin-dev] bip39
In-Reply-To: <CAF90AvnLqyC=yDcT8yWORfQPKHPn06_YFffj9WGbP9+v5RZ1Fw@mail.gmail.com>
References: <CAJowKg+Wr0agLLGfCB=yAJrUn0tXWieyuoz2TFv6W1Ahj8Td2w@mail.gmail.com>
 <CAD5xwhhOP_evDPGhEWq6UL9_xuYUCAQs7CCttVCKcdf5V5CdFw@mail.gmail.com>
 <CAF90AvnLqyC=yDcT8yWORfQPKHPn06_YFffj9WGbP9+v5RZ1Fw@mail.gmail.com>
Message-ID: <CAGpPWDbMH5VbLPVfrySvJLJjxWUvbphtCJFQUYvCOw++hvwDCw@mail.gmail.com>

I agree removing any ambiguity would be good. I'd also like to see removal
of words that are a strict subset of another word. Words like add (which is
a subset of addict and address).

As far as entropy loss, I think even with an 1000 word list and a 12 word
seed, it would be unlikely in a time far longer than the age of the
universe to expect to come across one duplicate randomly generated seed.
Even if every person on the planet generated 1000 seeds per second. So I
don't really see this as a concern.

On Mon, Jan 17, 2022 at 4:45 PM Pavol Rusnak via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Trezor recovery cards look like this what addresses the issue:
>
> https://wiki.trezor.io/images/Seed_card_example.jpg
>
> 1. Each word has a box around it.
> 2. You write the words one under the other, not next to each other.
>
>
> On Mon, 17 Jan 2022 at 23:38, Jeremy via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>> This is a good point, but can be addressed by having a non-void
>> whitespace character (e.g., win x estate).
>>
>> changing BIP39 would be hard since software expects a standard list; it
>> would also be possible to rejection sample for seeds that do not contain
>> these pairs, unclear how much entropy would be lost from that.
>> --
>> @JeremyRubin <https://twitter.com/JeremyRubin>
>> <https://twitter.com/JeremyRubin>
>>
>>
>> On Mon, Jan 17, 2022 at 2:26 PM Erik Aronesty via bitcoin-dev <
>> bitcoin-dev at lists.linuxfoundation.org> wrote:
>>
>>> really don't like that art, work, and artwork are 3 different words
>>>
>>> would be nice to clean up adjacent ambiguity
>>>
>>> it's not a big deal, but it can lead to confusion when writing things
>>> down
>>>
>>>
>>> dup: ('canal', 'arm') ('can', 'alarm')
>>> dup: ('canal', 'one') ('can', 'alone')
>>> dup: ('canal', 'ready') ('can', 'already')
>>> dup: ('card', 'anger') ('car', 'danger')
>>> dup: ('card', 'ice') ('car', 'dice')
>>> dup: ('card', 'inner') ('car', 'dinner')
>>> dup: ('card', 'raw') ('car', 'draw')
>>> dup: ('cart', 'able') ('car', 'table')
>>> dup: ('cart', 'ask') ('car', 'task')
>>> dup: ('cart', 'hat') ('car', 'that')
>>> dup: ('cart', 'hen') ('car', 'then')
>>> dup: ('cart', 'issue') ('car', 'tissue')
>>> dup: ('cart', 'one') ('car', 'tone')
>>> dup: ('cart', 'own') ('car', 'town')
>>> dup: ('cart', 'rack') ('car', 'track')
>>> dup: ('cart', 'rain') ('car', 'train')
>>> dup: ('cart', 'win') ('car', 'twin')
>>> dup: ('catch', 'air') ('cat', 'chair')
>>> dup: ('erase', 'arch') ('era', 'search')
>>> dup: ('fatal', 'arm') ('fat', 'alarm')
>>> dup: ('fatal', 'one') ('fat', 'alone')
>>> dup: ('fatal', 'ready') ('fat', 'already')
>>> dup: ('feed', 'anger') ('fee', 'danger')
>>> dup: ('feed', 'ice') ('fee', 'dice')
>>> dup: ('feed', 'inner') ('fee', 'dinner')
>>> dup: ('feed', 'raw') ('fee', 'draw')
>>> dup: ('feel', 'earn') ('fee', 'learn')
>>> dup: ('feel', 'end') ('fee', 'lend')
>>> dup: ('gasp', 'act') ('gas', 'pact')
>>> dup: ('gasp', 'age') ('gas', 'page')
>>> dup: ('gasp', 'air') ('gas', 'pair')
>>> dup: ('gasp', 'ill') ('gas', 'pill')
>>> dup: ('gasp', 'raise') ('gas', 'praise')
>>> dup: ('gasp', 'rice') ('gas', 'price')
>>> dup: ('gasp', 'ride') ('gas', 'pride')
>>> dup: ('gasp', 'roof') ('gas', 'proof')
>>> dup: ('kite', 'merge') ('kit', 'emerge')
>>> dup: ('kite', 'motion') ('kit', 'emotion')
>>> dup: ('kite', 'state') ('kit', 'estate')
>>> dup: ('lawn', 'arrow') ('law', 'narrow')
>>> dup: ('lawn', 'either') ('law', 'neither')
>>> dup: ('lawn', 'ice') ('law', 'nice')
>>> dup: ('legal', 'arm') ('leg', 'alarm')
>>> dup: ('legal', 'one') ('leg', 'alone')
>>> dup: ('legal', 'ready') ('leg', 'already')
>>> dup: ('seat', 'able') ('sea', 'table')
>>> dup: ('seat', 'ask') ('sea', 'task')
>>> dup: ('seat', 'hat') ('sea', 'that')
>>> dup: ('seat', 'hen') ('sea', 'then')
>>> dup: ('seat', 'issue') ('sea', 'tissue')
>>> dup: ('seat', 'one') ('sea', 'tone')
>>> dup: ('seat', 'own') ('sea', 'town')
>>> dup: ('seat', 'rack') ('sea', 'track')
>>> dup: ('seat', 'rain') ('sea', 'train')
>>> dup: ('seat', 'win') ('sea', 'twin')
>>> dup: ('skin', 'arrow') ('ski', 'narrow')
>>> dup: ('skin', 'either') ('ski', 'neither')
>>> dup: ('skin', 'ice') ('ski', 'nice')
>>> dup: ('tent', 'able') ('ten', 'table')
>>> dup: ('tent', 'ask') ('ten', 'task')
>>> dup: ('tent', 'hat') ('ten', 'that')
>>> dup: ('tent', 'hen') ('ten', 'then')
>>> dup: ('tent', 'issue') ('ten', 'tissue')
>>> dup: ('tent', 'one') ('ten', 'tone')
>>> dup: ('tent', 'own') ('ten', 'town')
>>> dup: ('tent', 'rack') ('ten', 'track')
>>> dup: ('tent', 'rain') ('ten', 'train')
>>> dup: ('tent', 'win') ('ten', 'twin')
>>> dup: ('used', 'anger') ('use', 'danger')
>>> dup: ('used', 'ice') ('use', 'dice')
>>> dup: ('used', 'inner') ('use', 'dinner')
>>> dup: ('used', 'raw') ('use', 'draw')
>>> dup: ('wine', 'merge') ('win', 'emerge')
>>> dup: ('wine', 'motion') ('win', 'emotion')
>>> dup: ('wine', 'state') ('win', 'estate')
>>> dup: ('wing', 'host') ('win', 'ghost')
>>> dup: ('wing', 'love') ('win', 'glove')
>>> dup: ('wing', 'old') ('win', 'gold')
>>> dup: ('wing', 'own') ('win', 'gown')
>>> dup: ('wing', 'race') ('win', 'grace')
>>> dup: ('wing', 'rain') ('win', 'grain')
>>> dup: ('wink', 'now') ('win', 'know')
>>> dup: ('youth', 'under') ('you', 'thunder')
>>> _______________________________________________
>>> bitcoin-dev mailing list
>>> bitcoin-dev at lists.linuxfoundation.org
>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
>
>
> --
> Best Regards / S pozdravom,
>
> Pavol "stick" Rusnak
> Co-Founder, SatoshiLabs
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/e738bc94/attachment-0001.html>

From jlrubin at mit.edu  Tue Jan 18 17:43:07 2022
From: jlrubin at mit.edu (Jeremy)
Date: Tue, 18 Jan 2022 09:43:07 -0800
Subject: [bitcoin-dev] [Pre-BIP] Fee Accounts
In-Reply-To: <CAGpPWDb6HckAhX6p-=cK3fQXyMqivd+xFtiYJ7hKR2k-MWqKJA@mail.gmail.com>
References: <CAD5xwhik6jVQpP2_ss7d5o+pPLsqDCHuaXG41AMKHVYhZMXF1w@mail.gmail.com>
 <CAGpPWDb6HckAhX6p-=cK3fQXyMqivd+xFtiYJ7hKR2k-MWqKJA@mail.gmail.com>
Message-ID: <CAD5xwhhuvHL2_-ZY1ygZ6WahRi9eg9rk2eHDUODNoJCQX6wL+A@mail.gmail.com>

Can you clarify what you mean by "improve the situation"?

There's a potential mild bytes savings, but the bigger deal is that the API
should be much less vulnerable to pinning issues, fix dust leakage for
eltoo like protocols, and just generally allow protocol designs to be fully
abstracted from paying fees. You can't easily mathematically quantify API
improvements like that.
--
@JeremyRubin <https://twitter.com/JeremyRubin>
<https://twitter.com/JeremyRubin>


On Tue, Jan 18, 2022 at 8:13 AM Billy Tetrud <billy.tetrud at gmail.com> wrote:

> Do you have any back-of-the-napkin math on quantifying how much this would
> improve the situation vs existing methods (eg cpfp)?
>
>
>
> On Sat, Jan 1, 2022 at 2:04 PM Jeremy via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>> Happy new years devs,
>>
>> I figured I would share some thoughts for conceptual review that have
>> been bouncing around my head as an opportunity to clean up the fee paying
>> semantics in bitcoin "for good". The design space is very wide on the
>> approach I'll share, so below is just a sketch of how it could work which
>> I'm sure could be improved greatly.
>>
>> Transaction fees are an integral part of bitcoin.
>>
>> However, due to quirks of Bitcoin's transaction design, fees are a part
>> of the transactions that they occur in.
>>
>> While this works in a "Bitcoin 1.0" world, where all transactions are
>> simple on-chain transfers, real world use of Bitcoin requires support for
>> things like Fee Bumping stuck transactions, DoS resistant Payment Channels,
>> and other long lived Smart Contracts that can't predict future fee rates.
>> Having the fees paid in band makes writing these contracts much more
>> difficult as you can't merely express the logic you want for the
>> transaction, but also the fees.
>>
>> Previously, I proposed a special type of transaction called a "Sponsor"
>> which has some special consensus + mempool rules to allow arbitrarily
>> appending fees to a transaction to bump it up in the mempool.
>>
>> As an alternative, we could establish an account system in Bitcoin as an
>> "extension block".
>>
>> *Here's how it might work:*
>>
>> 1. Define a special anyone can spend output type that is a "fee account"
>> (e.g. segwit V2). Such outputs have a redeeming key and an amount
>> associated with them, but are overall anyone can spend.
>> 2. All deposits to these outputs get stored in a separate UTXO database
>> for fee accounts
>> 3. Fee accounts can sign only two kinds of transaction: A: a fee amount
>> and a TXID (or Outpoint?); B: a withdraw amount, a fee, and an address
>> 4. These transactions are committed in an extension block merkle tree.
>> While the actual signature must cover the TXID/Outpoint, the committed data
>> need only cover the index in the block of the transaction. The public key
>> for account lookup can be recovered from the message + signature.
>> 5. In any block, any of the fee account deposits can be: released into
>> fees if there is a corresponding tx; consolidated together to reduce the
>> number of utxos (this can be just an OP_TRUE no metadata needed); or
>> released into fees *and paid back* into the requested withdrawal key
>> (encumbering a 100 block timeout). Signatures must be unique in a block.
>> 6. Mempool logic is updated to allow attaching of account fee spends to
>> transactions, the mempool can restrict that an account is not allowed more
>> spend more than it's balance.
>>
>> *But aren't accounts "bad"?*
>>
>> Yes, accounts are bad. But these accounts are not bad, because any funds
>> withdrawn from the fee extension are fundamentally locked for 100 blocks as
>> a coinbase output, so there should be no issues with any series of reorgs.
>> Further, since there is no "rich state" for these accounts, the state
>> updates can always be applied in a conflict-free way in any order.
>>
>>
>> *Improving the privacy of this design:*
>>
>> This design could likely be modified to implement something like
>> Tornado.cash or something else so that the fee account paying can be
>> unlinked from the transaction being paid for, improving privacy at the
>> expense of being a bit more expensive.
>>
>> Other operations could be added to allow a trustless mixing to be done by
>> miners automatically where groups of accounts with similar values are
>> trustlessly  split into a common denominator and change, and keys are
>> derived via a verifiable stealth address like protocol (so fee balances can
>> be discovered by tracing the updates posted). These updates could also be
>> produced by individuals rather than miners, and miners could simply honor
>> them with better privacy. While a miner generating an update would be able
>> to deanonymize their mixes, if you have your account mixed several times by
>> independent miners that could potentially add sufficient privacy.
>>
>> The LN can also be used with PTLCs to, in theory, have another individual
>> paid to sponsor a transaction on your behalf only if they reveal a valid
>> sig from their fee paying account, although under this model it's hard to
>> ensure that the owner doesn't pay a fee and then 'cancel' by withdrawing
>> the rest. However, this could be partly solved by using reputable fee
>> accounts (reputation could be measured somewhat decentralized-ly by
>> longevity of the account and transactions paid for historically).
>>
>> *Scalability*
>>
>> This design is fundamentally 'decent' for scalability because adding fees
>> to a transaction does not require adding inputs or outputs and does not
>> require tracking substantial amounts of new state.
>>
>> Paying someone else to pay for you via the LN also helps make this more
>> efficient if the withdrawal issues can be fixed.
>>
>> *Lightning:*
>>
>> This type of design works really well for channels because the addition
>> of fees to e.g. a channel state does not require any sort of pre-planning
>> (e.g. anchors) or transaction flexibility (SIGHASH flags). This sort of
>> design is naturally immune to pinning issues since you could offer to pay a
>> fee for any TXID and the number of fee adding offers does not need to be
>> restricted in the same way the descendant transactions would need to be.
>>
>> *Without a fork?*
>>
>> This type of design could be done as a federated network that bribes
>> miners -- potentially even retroactively after a block is formed. That
>> might be sufficient to prove the concept works before a consensus upgrade
>> is deployed, but such an approach does mean there is a centralizing layer
>> interfering with normal mining.
>>
>>
>> Happy new year!!
>>
>> Jeremy
>>
>> --
>> @JeremyRubin <https://twitter.com/JeremyRubin>
>> <https://twitter.com/JeremyRubin>
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/d8324802/attachment.html>

From bram at chia.net  Tue Jan 18 17:16:25 2022
From: bram at chia.net (Bram Cohen)
Date: Tue, 18 Jan 2022 09:16:25 -0800
Subject: [bitcoin-dev] Covenants and capabilities in the UTXO model
In-Reply-To: <CAGpPWDYvvtCJLsr1SqghugfntnmnKw+GOtufp07d8sN-5vKa0w@mail.gmail.com>
References: <CAHUJnBBFsS597ZRdAtwONMAz1r7gQbrXULzdNtEVxOPENx+tDg@mail.gmail.com>
 <CAGpPWDYvvtCJLsr1SqghugfntnmnKw+GOtufp07d8sN-5vKa0w@mail.gmail.com>
Message-ID: <CAHUJnBAfnmfs2nY3HFRhzNL6ztpZT3dgqe5wCxuO3qpk0OsgRg@mail.gmail.com>

On Tue, Jan 18, 2022 at 7:10 AM Billy Tetrud <billy.tetrud at gmail.com> wrote:

> >  Since scriptpubkeys/scriptsigs continue to run ephemerally at
> validation time full turing completeness is much less dangerous than people
> fear.
>
> The covenant proposals I've seen that might give bitcoin turing
> completeness require a turing complete process to be stepped such that each
> step is a transaction paid for with a usual fee. This fact I think makes
> the turing completeness a lot less scary. No single transaction would be
> turing complete, while a sequence of them could be. But importantly, each
> transaction has a strictly limited runtime and every script could continue
> to have a calculable number of maximum runtime steps.
>

This flows naturally out of the UTXO model. In ETH you don't know how much
transactions will cost in advance because things don't declare their state
up front, but with all dependencies declared up front execution can be made
completely deterministic.

 > It would also probably be a good idea to add in a bunch of special
purpose opcodes for making coherent statements about transactions since in
Bitcoin they're a very complex and hard to parse format.

>
> What are some examples you're thinking of?
>

What's needed from a programming perspective is the ability to say 'assert
that my parent has a scriptpubkey of X'. That way you can, for example,
have a UTXO which only allows itself to be absorbed by a transaction also
involving a UTXO with a particular capability ('pay to singleton' is a term
for this) and that capability can be enforced by the scriptpubkey asserting
that either its parent is the originator of it or that its parent also has
the same type of scriptpubkey. This allows capabilities to be added without
gunking up on chain state with things other than UTXOs.



>
> > Once you start implementing complex general purpose functionality it
> tends to get very expensive very fast and is likely impractical unless
> there's a way to compress or at least de-duplicate snippets of code which
> are repeated on chain.
>
> I like this idea. If there was a way to dedupe scripts in some way, it
> could save a lot of bandwidth which would help bitcoin scale better. One
> thing we could do is have a specific set of pre-ordained script snippets
> that are given a shorthand that's stored in the software and explicitly
> shouldn't be transmitted long-hand. That would help for very standard
> widespread things. We could even add in a consensus rule where short-handed
> scripts pay for their expanded vbytes, not the vbytes of the compressed
> version. This would mean the incentives wouldn't be changed by this
> approach.
>

One approach is to allow references to old blocks so code snippets can be
pulled out of them. That avoids having to define the 'common sections' up
front. Charging for virtual vbytes unfortunately keeps smart functionality
very expensive and the point is to make it not so expensive.


> > For a payment to someone to come with a rider where they could accept it
> and think their system was working properly for a while until you exercised
> some kind of retroactive veto on new action or even clawback would
> obviously be unacceptable behavior.
>
> I definitely agree. A payment's covenant should be completely knowable to
> the recipient, and recipients shouldn't accept random covenants they
> haven't explicitly accepted on their own.
>
> > for payments to come with covenants but the recipient not even be able
> to parse them unless they're fully buying into that behavior is much more
> reasonable.
>
> The recipient not being able to parse them? Couldn't that result in
> exactly the situation above you said was not acceptable? The recipient must
> be able to know all the possibilities of the covenant or there might be
> some secret retroactive clawback in there waiting to bite them.
>

Not sure what you're saying. If the recipient can't parse a UTXO the
defined behavior should be that they assume it's bricked.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/5d93153e/attachment-0001.html>

From billy.tetrud at gmail.com  Tue Jan 18 18:15:15 2022
From: billy.tetrud at gmail.com (Billy Tetrud)
Date: Tue, 18 Jan 2022 12:15:15 -0600
Subject: [bitcoin-dev] [Bitcoin Advent Calendar] Decentralized
 Coordination Free Mining Pools
In-Reply-To: <CAD5xwhhNgVp1wb3+CEAnGmCoYHFKQPPqRg-WvkCuaD+8WAAG_Q@mail.gmail.com>
References: <CAGpPWDbGTET27Hq8kKrQQoOavtOUEGzYkohVurSqZJ5r+o4gpQ@mail.gmail.com>
 <151161119-8858833d76ec6beed19cf87cc542dc62@pmq3v.m5r2.onet>
 <CAD5xwhhNgVp1wb3+CEAnGmCoYHFKQPPqRg-WvkCuaD+8WAAG_Q@mail.gmail.com>
Message-ID: <CAGpPWDaTb0+jbWzC46K9jnS6-DRb5opDXnmA83P5SeTzACBuaA@mail.gmail.com>

@vjudeu
>  If you introduce signing into mining, then you will have cases, where
someone is powerful enough to produce blocks, but cannot, because signing
is needed..  your consensus is no longer "the heaviest chain"

You've misunderstood my suggestion. This would not be possible with what I
suggested. Why do you think of the signature as some kind of barrier? What
I was suggesting was that, when a miner participating in this protocol
mines a valid bitcoin block, they then sign a superblock with a public key
that can be verified alongside the coinbase output (eg say with data in the
first tapleaf of the output address). The block is still connected to
something secured by PoW. You really made a lot of incorrect assumptions
about what I suggested.

On Thu, Dec 23, 2021 at 1:05 PM Jeremy <jlrubin at mit.edu> wrote:

> If you introduce signing into mining, then you will have cases, where
>> someone is powerful enough to produce blocks, but cannot, because signing
>> is needed. Then, your consensus is no longer "the heaviest chain", but "the
>> heaviest signed chain". That means, your computing power is no longer
>> enough by itself (as today), because to make a block, you also need some
>> kind of "permission to mine", because first you sign things (like in
>> signet) and then you mine them. That kind of being "reliably unreliable"
>> may be ok for testing, but not for the main network.
>
>
> this is a really great point worth underscoring. this is the 'key
> ingredient' for DCFMP, which is that there is no signing or other network
> system that is 'in the way' of normal bitcoin mining, just an opt-in set of
> rules for sharing the bounties of your block in exchange for future shares.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/99bfa566/attachment.html>

From prayank at tutanota.de  Tue Jan 18 17:22:05 2022
From: prayank at tutanota.de (Prayank)
Date: Tue, 18 Jan 2022 18:22:05 +0100 (CET)
Subject: [bitcoin-dev] On the regularity of soft forks
Message-ID: <MtiCR2x--7-2@tutanota.de>

> We should strive to one day get to a point where the bitcoin consensus isn't updating at all.

That day is nowhere near IMO and maybe we won't see it in my lifetime.

> Perhaps we should come to a consensus as a consensus as a community what the minimum time between soft forks should be, and just as importantly, what the minimum time between finalized consensus-change implementation and when we decide community consensus has been achieved.

This is not possible in a decentralized network like Bitcoin and makes no sense. Soft forks can/should be done as and when required. This does not mean we do them often but if a change makes sense, looks ready, got enough consensus, reviewed properly etc. then timing doesn't really matter in every case.

> Activating multiple consensus changes in a bundle is far safer than having multiple separate in-flight soft forks at once.

This is not true. More changes bundled require more review and still more probability to have bugs. Security is always about keeping things simple.

> One solution is that we could be a lot more direct about how decisions are made. There's been a lot of rhetoric around UASF and how the economic majority is really who's running the show.

BIP 8 with LOT=TRUE was a better activation mechanism option in Taproot but some influential developers wrote its misleading, unsafe etc. on social media so you can call me negative at this moment however I have realized the truth is really sad and we can't blindly follow some people. There are lot of people who will tell you bad things about UASF and how speedy trial is the best thing Bitcoin has ever experienced.

Michael Folkson also had some opinion in activation mechanism IIRC,


-- 
Prayank

A3B1 E430 2298 178F
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/839b7bfc/attachment.html>

From luke at dashjr.org  Tue Jan 18 21:19:02 2022
From: luke at dashjr.org (Luke Dashjr)
Date: Tue, 18 Jan 2022 21:19:02 +0000
Subject: [bitcoin-dev] CTV BIP review
Message-ID: <202201182119.02687.luke@dashjr.org>

tl;dr: I don't think CTV is ready yet (but probably close), and in any case 
definitely not worth reviving BIP 9 with its known flaws and vulnerability.

My review here is based solely on the BIP, with no outside context (aside from 
current consensus rules, of course). In particular, I have _not_ looked at 
the CTV code proposed for Bitcoin Core yet.

>Covenants are restrictions on how a coin may be spent beyond key ownership. 

nit: Poorly phrased. Even simple scripts can do that already.

>A few examples are described below, which should be the subject of future 
non-consensus standardization efforts.

I would ideally like to see fully implemented BIPs for at least one of these 
(preferably the claimed CoinJoin improvements) before we move toward 
activation.

>Congestion Controlled Transactions

I think this use case hasn't been fully thought through yet. It seems like it 
would be desirable for this purpose, to allow any of the recipients to claim 
their portion of the payment without footing the fee for every other payment 
included in the batch. This is still a covenant-type solution, but one that 
BIP 119 cannot support as-is.

(I realise this may be a known and accepted limitation, but I think it should 
be addressed in the BIP)

>Payment Channels

Why batch mere channel creation? Seems like the spending transaction should 
really be the channel closing.

>CHECKTEMPLATEVERIFY makes it much easier to set up trustless CoinJoins than 
previously because participants agree on a single output which pays all 
participants, which will be lower fee than before.

I don't see how. They still have to agree in advance on the outputs, and the 
total fees will logically be higher than not using CTV...?

>Further Each participant doesn't need to know the totality of the outputs 
committed to by that output, they only have to verify their own sub-tree will 
pay them.

I don't see any way to do this with the provided implementation.

>Deployment could be done via BIP 9 VersionBits deployed through Speedy Trial.

Hard NACK on this. BIP 9 at this point represents developers attempting to 
disregard and impose their will over community consensus, as well as an 
attempt to force a miner veto backdoor/vulnerability on deployment. It should 
never be used again.

Speedy Trial implemented with BIP 8 made sense* as a possible neutral 
compromise between LOT=True and LOT=False (which could be deployed prior to 
or in parallel), but using BIP 9 would destroy this.

As with Taproot, any future deployments should use BIP 8 again, until a better 
solution is developed. Reverting back to a known flawed and vulnerable 
activation method should not be done, and it would be better not to deploy 
CTV at all at such an expense.

The fact that certain developers attempted to deploy a BIP 9 alternative 
activation for Taproot against community consensus, and that even managed to 
get released as "Bitcoin Core", makes it all the more important that the 
community firmly rejects any further action to force this regression.

* it is my opinion a BIP 8 ST would be an okay compromise under those 
circumstances; others do disagree that ST is acceptable at all

> This ensures that for a given known input, the TXIDs can also be known ahead 
of time. Otherwise, CHECKTEMPLATEVERIFY would not be usable for Batched 
Channel Creation constructions as the redemption TXID could be malleated and 
pre-signed transactions invalidated, unless the channels are built using an 
Eltoo-like protocol.

Why is it a problem for them to use an Eltoo-like protocol?

Why not just commit to the txid itself if that's the goal?

>P2SH is incompatible with CHECKTEMPLATEVERIFY 

Maybe the CTV opcode should only be defined/enforced within witness scripts?

>nLockTime should generally be fixed to 0 (in the case of a payment tree, only 
the *first* lock time is needed to prevent fee-sniping the root)

Your "Congestion Controlled Transactions" example would only make sense with 
the spending transaction much later than the "root", and so could benefit 
from fee sniping malleability. (In fact, in that example, it would be better 
not to commit to locktime at all.)

>In the CHECKTEMPLATEVERIFY approach, the covenants are severely restricted to 
simple templates. The structure of CHECKTEMPLATEVERIFY template is such that 
the outputs must be known exactly at the time of construction. Based on a 
destructuring argument, it is only possible to create templates which expand 
in a finite number of steps.

It's not clear to me that this holds if OP_CAT or OP_SHA256STREAM get added.

>For example, a exchange's hot wallet might use an address which can 
automatically be moved to a cold storage address after a relative timeout.

Wouldn't it make more sense to just have a UTXO both cold+hot can spend, then 
throw away the hot key?

>In contrast to previous forks, OP_CHECKTEMPLATEVERIFY will not make scripts 
valid for policy until the new rule is active.

Policy isn't validity, and cannot be dictated by BIPs (or anyone/anything, for 
that matter).

Luke

From eric at voskuil.org  Tue Jan 18 22:02:24 2022
From: eric at voskuil.org (eric at voskuil.org)
Date: Tue, 18 Jan 2022 14:02:24 -0800
Subject: [bitcoin-dev] CTV BIP review
In-Reply-To: <202201182119.02687.luke@dashjr.org>
References: <202201182119.02687.luke@dashjr.org>
Message-ID: <02cc01d80cb7$1339c050$39ad40f0$@voskuil.org>

I won't comment on CTV at this point, but these comments on BIP9 and BIP8
deserve a response, given the intense obfuscation below.

The only material distinction between BIP9 and BIP8 is that the latter may
activate without signaled support of hash power enforcement.

As unenforced soft forks are not "backward compatible" they produce a chain
split. It was for this reason alone that BIP8 never gained sufficient
support.

Taproot activation was in no way a compromise between enforced and
unenforced activation. Unenforced activation was wholly rejected.

> BIP 9 at this point represents developers attempting to disregard and
impose their will over community consensus, as well as an attempt to force a
miner veto backdoor/vulnerability on deployment. It should never be used
again."

This appears to be the start of another marketing campaign, an attempt to
reclaim Taproot activation as some sort of "win" over the "miner backdoor".
The same sort of misleading campaign was waged in the wake of segwit, and
led directly to the conflict around Taproot activation.

The differences between ST and BIP9 are inconsequential in this regard. The
criticism you are making of BIP9 above applies equally to ST.

> As with Taproot, any future deployments should use BIP 8 again

This is one of the most misleading statements I've seen here. It's not
technically a lie, because it states what "should" happen. But it is clearly
intended to lead people to believe that BIP8 was actually used ("again") -
it was not. ST was some technical tweaks to BIP9.

I am making no statement whatsoever on what "should" happen. My interest is
in providing accurate information so that people can make informed
decisions.

The outright deception around this one topic has led to significant
unnecessary conflict in the community. Make your argument, but make it
honestly.

e

> -----Original Message-----
> From: bitcoin-dev <bitcoin-dev-bounces at lists.linuxfoundation.org> On
Behalf
> Of Luke Dashjr via bitcoin-dev
> Sent: Tuesday, January 18, 2022 1:19 PM
> To: bitcoin-dev at lists.linuxfoundation.org
> Subject: [bitcoin-dev] CTV BIP review
> 
> tl;dr: I don't think CTV is ready yet (but probably close), and in any
case
> definitely not worth reviving BIP 9 with its known flaws and
vulnerability.
...
> >Deployment could be done via BIP 9 VersionBits deployed through Speedy
> Trial.
> 
> Hard NACK on this. BIP 9 at this point represents developers attempting to
> disregard and impose their will over community consensus, as well as an
> attempt to force a miner veto backdoor/vulnerability on deployment. It
> should never be used again.
> 
> Speedy Trial implemented with BIP 8 made sense* as a possible neutral
> compromise between LOT=True and LOT=False (which could be deployed
> prior to or in parallel), but using BIP 9 would destroy this.
> 
> As with Taproot, any future deployments should use BIP 8 again, until a
better
> solution is developed. Reverting back to a known flawed and vulnerable
> activation method should not be done, and it would be better not to deploy
> CTV at all at such an expense.
> 
> The fact that certain developers attempted to deploy a BIP 9 alternative
> activation for Taproot against community consensus, and that even managed
> to get released as "Bitcoin Core", makes it all the more important that
the
> community firmly rejects any further action to force this regression.
> 
> * it is my opinion a BIP 8 ST would be an okay compromise under those
> circumstances; others do disagree that ST is acceptable at all


From luke at dashjr.org  Tue Jan 18 22:09:45 2022
From: luke at dashjr.org (Luke Dashjr)
Date: Tue, 18 Jan 2022 22:09:45 +0000
Subject: [bitcoin-dev] CTV BIP review
In-Reply-To: <02cc01d80cb7$1339c050$39ad40f0$@voskuil.org>
References: <202201182119.02687.luke@dashjr.org>
 <02cc01d80cb7$1339c050$39ad40f0$@voskuil.org>
Message-ID: <202201182209.46044.luke@dashjr.org>

On Tuesday 18 January 2022 22:02:24 eric at voskuil.org wrote:
> The only material distinction between BIP9 and BIP8 is that the latter may
> activate without signaled support of hash power enforcement.
>
> As unenforced soft forks are not "backward compatible" they produce a chain
> split.

Enforcement of the Bitcoin consensus protocol is by users, not miners.

Softforks never produce a chain split. Miners can, and might try to do it to 
cause disruption in retaliation, but the softfork itself does not.

> It was for this reason alone that BIP8 never gained sufficient 
> support.

BIP 8 in fact achieved consensus for Taproot activation.

> This is one of the most misleading statements I've seen here. It's not
> technically a lie, because it states what "should" happen. But it is
> clearly intended to lead people to believe that BIP8 was actually used
> ("again") - it was not. ST was some technical tweaks to BIP9.

BIP 8 was used to activate Taproot.

> The outright deception around this one topic has led to significant
> unnecessary conflict in the community. Make your argument, but make it
> honestly.

You are the one attempting to deceive here.

Luke

From eric at voskuil.org  Tue Jan 18 23:00:27 2022
From: eric at voskuil.org (eric at voskuil.org)
Date: Tue, 18 Jan 2022 15:00:27 -0800
Subject: [bitcoin-dev] CTV BIP review
In-Reply-To: <202201182209.46044.luke@dashjr.org>
References: <202201182119.02687.luke@dashjr.org>
 <02cc01d80cb7$1339c050$39ad40f0$@voskuil.org>
 <202201182209.46044.luke@dashjr.org>
Message-ID: <000601d80cbf$2f6a1d80$8e3e5880$@voskuil.org>

> -----Original Message-----
> From: Luke Dashjr <luke at dashjr.org>
> Sent: Tuesday, January 18, 2022 2:10 PM
> To: eric at voskuil.org
> Cc: 'Bitcoin Protocol Discussion' <bitcoin-dev at lists.linuxfoundation.org>
> Subject: Re: [bitcoin-dev] CTV BIP review
> 
> On Tuesday 18 January 2022 22:02:24 eric at voskuil.org wrote:
> > The only material distinction between BIP9 and BIP8 is that the latter
> > may activate without signaled support of hash power enforcement.
> >
> > As unenforced soft forks are not "backward compatible" they produce a
> > chain split.
> 
> Enforcement of the Bitcoin consensus protocol is by users, not miners.

Given that I stated "hash power enforcement" it is quite clear that this is
in fact only produced by mining. You are misrepresenting my statement to
make an emotional appeal. Without "hash power enforcement", a soft fork is
NOT backward compatible.

"[enforcement of] consensus protocol" is of course by merchants, but that is
not the question at hand. The question is explicitly compatibility. Anyone
can activate a soft fork at any time, but without "hash power enforcement"
soft forks are NOT backward compatible.

> Softforks never produce a chain split. Miners can, and might try to do it
to cause disruption in retaliation, but the softfork itself does not.

Maybe you are trying to split hairs given the fact that blocks are produced
only by miners, so only miners can "cause" a split.

But through not intention ("disruption in retaliation") whatsoever by
mining, a soft fork will result in those activating the rule being split off
the original chain unless majority hash power enforces the rule. The fact
that doing nothing apart from deploying the rule will result in a split is
the very definition of NOT compatible.

I assume you will argue that the original chain is not "valid" and therefore
irrelevant (as if no chain split occurred). But again the point is about
compatibility. The appearance of multiple chains, which appear valid
according to either the previous or new rules, is obviously the
incompatibility.

I shouldn't have to point this out, but observed chain splits have occurred
in more the one large scale soft fork deployment. These splits have only
been resolved through hash power enforcement. In 2010 it took 51 blocks
before the current chain took the lead. In 2012 minority chains persisted
for months. The deployment of soft forks caused these splits, NOT the
actions of miners. And unless majority hash power eventually enforces it,
the soft fork branch necessarily dies.

> > It was for this reason alone that BIP8 never gained sufficient
> > support.
> 
> BIP 8 in fact achieved consensus for Taproot activation.

Please define "achieved consensus", because by any definition I can imagine,
this is simply untrue.

> > This is one of the most misleading statements I've seen here. It's not
> > technically a lie, because it states what "should" happen. But it is
> > clearly intended to lead people to believe that BIP8 was actually used
> > ("again") - it was not. ST was some technical tweaks to BIP9.
> 
> BIP 8 was used to activate Taproot.

No, it wasn't. I find it hard to imaging how you rationalize such grossly
misleading statements.

> > The outright deception around this one topic has led to significant
> > unnecessary conflict in the community. Make your argument, but make it
> > honestly.
> 
> You are the one attempting to deceive here.

That is for others to decide. I appreciate your responses above, since they
certainly help clarify what is happening here.

e


From prayank at tutanota.de  Tue Jan 18 22:20:45 2022
From: prayank at tutanota.de (Prayank)
Date: Tue, 18 Jan 2022 23:20:45 +0100 (CET)
Subject: [bitcoin-dev] CTV BIP review
Message-ID: <MtjGn81--7-2@tutanota.de>

Hi Luke,

This is the first competent review for CTV based on my understanding. I would not mention controversial things in this email but nobody cares about scammers and we will review everything irrespective of personal or legal attacks on developers because some people are prepared for it and capable, competent and healthy.

> nit: Poorly phrased. Even simple scripts can do that already.

Agree

> I would ideally like to see fully implemented BIPs for at least one of these (preferably the claimed CoinJoin improvements) before we move toward activation.

Agree

> Hard NACK on this. BIP 9 at this point represents developers attempting to disregard and impose their will over community consensus, as well as an attempt to force a miner veto backdoor/vulnerability on deployment. It should never be used again.

Agree

Other technical comments on BIP are appreciated however they would be better answered by Jeremy at this point or other as I am still researching and not confident to comment.

-- 
Prayank

A3B1 E430 2298 178F
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/47a7823e/attachment.html>

From jlrubin at mit.edu  Tue Jan 18 23:54:21 2022
From: jlrubin at mit.edu (Jeremy)
Date: Tue, 18 Jan 2022 15:54:21 -0800
Subject: [bitcoin-dev] CTV BIP review
In-Reply-To: <202201182119.02687.luke@dashjr.org>
References: <202201182119.02687.luke@dashjr.org>
Message-ID: <CAD5xwhh3d1=KXEJOPVuYm3UqNKovrojqJS-c6r6ficsKf6S_7g@mail.gmail.com>

Thanks for the detailed review.

I'll withhold comment around activation logic and leave that for others to
discuss.

w.r.t. the language cleanups I'll make a PR that (I hope) clears up the
small nits later today or tomorrow. Some of it's kind of annoying because
the legal definition of covenant is "A formal agreement or promise, usually
included in a contract or deed, to do or not do a particular act; a compact
or stipulation made in writing or by parol." so I do think things like
CLTV/CSV are covenants since it's a binding promise to not spend before a
certain time... it might be out of scope for the BIP to fully define these
terms because it doesn't really matter what a covenant could be as much as
it matters what CTV is specifically.

On the topic of drafting BIPs for specific use cases, I agree that would be
valuable and can consider it.

However, I'm a bit skeptical of that approach overall as I don't
necessarily think that the applications *must be* standard, and I view BIPs
as primarily for standardization whereas part of the flexibility of
CTV/Sapio allows users to figure out how they want to use it.

E.g., we do not yet have a BIP for MuSig or even Multisig in Taproot,
although there are some papers and example implementations but nothing
formal yet
https://bitcoin.stackexchange.com/questions/111666/support-for-taproot-multisig-descriptors).
Perhaps this is an opportunity for CTV to lead on the amount of formal
application designs available before 'release'.

As a starting point, maybe you could review some of the application focused
posts in rubin.io/advent21 and let me know where they seem deficient?

Also a BIP describing how to build something like Sapio (and less so Sapio
itself, since it's still early days for that) might help for folks to be
able to think through how to compile to CTV contracts? But again, I'm
skeptical of the value of a BIP v.s. the documentation and examples
available in the code and https://learn.sapio-lang.org.

I think it's an interesting discussion too because as we've just seen the
LN ecosystem start the BLIP standards, would an example of non-interactive
channels be best written up as a BIP, a BLIP, or a descriptive blog/mailing
list post?

--
@JeremyRubin <https://twitter.com/JeremyRubin>
<https://twitter.com/JeremyRubin>


On Tue, Jan 18, 2022 at 1:19 PM Luke Dashjr via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> tl;dr: I don't think CTV is ready yet (but probably close), and in any
> case
> definitely not worth reviving BIP 9 with its known flaws and vulnerability.
>
> My review here is based solely on the BIP, with no outside context (aside
> from
> current consensus rules, of course). In particular, I have _not_ looked at
> the CTV code proposed for Bitcoin Core yet.
>
> >Covenants are restrictions on how a coin may be spent beyond key
> ownership.
>
> nit: Poorly phrased. Even simple scripts can do that already.
>
> >A few examples are described below, which should be the subject of future
> non-consensus standardization efforts.
>
> I would ideally like to see fully implemented BIPs for at least one of
> these
> (preferably the claimed CoinJoin improvements) before we move toward
> activation.
>
> >Congestion Controlled Transactions
>
> I think this use case hasn't been fully thought through yet. It seems like
> it
> would be desirable for this purpose, to allow any of the recipients to
> claim
> their portion of the payment without footing the fee for every other
> payment
> included in the batch. This is still a covenant-type solution, but one
> that
> BIP 119 cannot support as-is.
>
> (I realise this may be a known and accepted limitation, but I think it
> should
> be addressed in the BIP)
>
> >Payment Channels
>
> Why batch mere channel creation? Seems like the spending transaction
> should
> really be the channel closing.
>
> >CHECKTEMPLATEVERIFY makes it much easier to set up trustless CoinJoins
> than
> previously because participants agree on a single output which pays all
> participants, which will be lower fee than before.
>
> I don't see how. They still have to agree in advance on the outputs, and
> the
> total fees will logically be higher than not using CTV...?
>
> >Further Each participant doesn't need to know the totality of the outputs
> committed to by that output, they only have to verify their own sub-tree
> will
> pay them.
>
> I don't see any way to do this with the provided implementation.
>
> >Deployment could be done via BIP 9 VersionBits deployed through Speedy
> Trial.
>
> Hard NACK on this. BIP 9 at this point represents developers attempting to
> disregard and impose their will over community consensus, as well as an
> attempt to force a miner veto backdoor/vulnerability on deployment. It
> should
> never be used again.
>
> Speedy Trial implemented with BIP 8 made sense* as a possible neutral
> compromise between LOT=True and LOT=False (which could be deployed prior
> to
> or in parallel), but using BIP 9 would destroy this.
>
> As with Taproot, any future deployments should use BIP 8 again, until a
> better
> solution is developed. Reverting back to a known flawed and vulnerable
> activation method should not be done, and it would be better not to deploy
> CTV at all at such an expense.
>
> The fact that certain developers attempted to deploy a BIP 9 alternative
> activation for Taproot against community consensus, and that even managed
> to
> get released as "Bitcoin Core", makes it all the more important that the
> community firmly rejects any further action to force this regression.
>
> * it is my opinion a BIP 8 ST would be an okay compromise under those
> circumstances; others do disagree that ST is acceptable at all
>
> > This ensures that for a given known input, the TXIDs can also be known
> ahead
> of time. Otherwise, CHECKTEMPLATEVERIFY would not be usable for Batched
> Channel Creation constructions as the redemption TXID could be malleated
> and
> pre-signed transactions invalidated, unless the channels are built using
> an
> Eltoo-like protocol.
>
> Why is it a problem for them to use an Eltoo-like protocol?
>
> Why not just commit to the txid itself if that's the goal?
>
> >P2SH is incompatible with CHECKTEMPLATEVERIFY
>
> Maybe the CTV opcode should only be defined/enforced within witness
> scripts?
>
> >nLockTime should generally be fixed to 0 (in the case of a payment tree,
> only
> the *first* lock time is needed to prevent fee-sniping the root)
>
> Your "Congestion Controlled Transactions" example would only make sense
> with
> the spending transaction much later than the "root", and so could benefit
> from fee sniping malleability. (In fact, in that example, it would be
> better
> not to commit to locktime at all.)
>
> >In the CHECKTEMPLATEVERIFY approach, the covenants are severely
> restricted to
> simple templates. The structure of CHECKTEMPLATEVERIFY template is such
> that
> the outputs must be known exactly at the time of construction. Based on a
> destructuring argument, it is only possible to create templates which
> expand
> in a finite number of steps.
>
> It's not clear to me that this holds if OP_CAT or OP_SHA256STREAM get
> added.
>
> >For example, a exchange's hot wallet might use an address which can
> automatically be moved to a cold storage address after a relative timeout.
>
> Wouldn't it make more sense to just have a UTXO both cold+hot can spend,
> then
> throw away the hot key?
>
> >In contrast to previous forks, OP_CHECKTEMPLATEVERIFY will not make
> scripts
> valid for policy until the new rule is active.
>
> Policy isn't validity, and cannot be dictated by BIPs (or anyone/anything,
> for
> that matter).
>
> Luke
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/84498a7e/attachment-0001.html>

From jlrubin at mit.edu  Wed Jan 19 02:51:42 2022
From: jlrubin at mit.edu (Jeremy)
Date: Tue, 18 Jan 2022 18:51:42 -0800
Subject: [bitcoin-dev] [Pre-BIP] Fee Accounts
In-Reply-To: <CAGpPWDaQAxEfyFs_g9p=PTUNAkSiQKwPiHJbBaLmzfNTjFeucA@mail.gmail.com>
References: <CAD5xwhik6jVQpP2_ss7d5o+pPLsqDCHuaXG41AMKHVYhZMXF1w@mail.gmail.com>
 <CAGpPWDb6HckAhX6p-=cK3fQXyMqivd+xFtiYJ7hKR2k-MWqKJA@mail.gmail.com>
 <CAD5xwhhuvHL2_-ZY1ygZ6WahRi9eg9rk2eHDUODNoJCQX6wL+A@mail.gmail.com>
 <CAGpPWDaQAxEfyFs_g9p=PTUNAkSiQKwPiHJbBaLmzfNTjFeucA@mail.gmail.com>
Message-ID: <CAD5xwhjUkey+VD=u+69+5eirLCCoLgDgAR_4d20hwHo-eyZr6w@mail.gmail.com>

The issue with sighash flags is that because you make transactions third
party malleable it becomes possible to bundle and unbundle transactions.

This means there are circumstances where an attacker could e.g. see your
txn, and then add a lot of junk change/inputs + 25 descendants and strongly
anchor your transaction to the bottom of the mempool.

because of rbf rules requiring more fee and feerate, this means you have to
bump across the whole package and that can get really messy.

more generally speaking, you could imagine a future where mempools track
many alternative things that might want to be in a transaction.

suppose there are N inputs each with a weight and an amount of fee being
added and the sighash flags let me pick any subset of them. However, for a
txn to be standard it must be < 100k bytes and for it to be consensus <
1mb. Now it is possible you have to solve a knapsack problem in order to
rationally bundle this transaction out of all possibilities.

This problem can get even thornier, suppose that the inputs I'm adding
themselves are the outputs of another txn in the mempool, now i have to
track and propagate the feerates of that child back up to the parent txn
and track all these dependencies.

perhaps with very careful engineering these issues can be tamed. however it
seems with sponsors or fee accounts, by separating the pays-for from the
participates-in concerns we can greatly simplify it to something like:
compute effective feerate for a txn, including all sponsors that pay more
than the feerate of the base txn. Mine that txn and it's subsidies using
the normal algo. If you run out of space, all subsidies are same-sized so
just take the ones that pay the highest amount up until the added marginal
feerate is less than the next eligible txn.


--
@JeremyRubin <https://twitter.com/JeremyRubin>
<https://twitter.com/JeremyRubin>


On Tue, Jan 18, 2022 at 6:38 PM Billy Tetrud <billy.tetrud at gmail.com> wrote:

> I see, its not primarily to make it cheaper to append fees, but also
> allows appending fees in cases that aren't possible now. Is that right? I
> can certainly see the benefit of a more general way to add a fee to any
> transaction, regardless of whether you're related to that transaction or
> not.
>
> How would you compare the pros and cons of your account-based approach to
> something like a new sighash flag? Eg a sighash flag that says "I'm signing
> this transaction, but the signature is only valid if mined in the same
> block as transaction X (or maybe transactions LIST)". This could be named
> SIGHASH_EXTERNAL. Doing this would be a lot more similar to other bitcoin
> transactions, and no special account would need to be created. Any
> transaction could specify this. At least that's the first thought I would
> have in designing a way to arbitrarily bump fees. Have you compared your
> solution to something more familiar like that?
>
> On Tue, Jan 18, 2022 at 11:43 AM Jeremy <jlrubin at mit.edu> wrote:
>
>> Can you clarify what you mean by "improve the situation"?
>>
>> There's a potential mild bytes savings, but the bigger deal is that the
>> API should be much less vulnerable to pinning issues, fix dust leakage for
>> eltoo like protocols, and just generally allow protocol designs to be fully
>> abstracted from paying fees. You can't easily mathematically quantify API
>> improvements like that.
>> --
>> @JeremyRubin <https://twitter.com/JeremyRubin>
>> <https://twitter.com/JeremyRubin>
>>
>>
>> On Tue, Jan 18, 2022 at 8:13 AM Billy Tetrud <billy.tetrud at gmail.com>
>> wrote:
>>
>>> Do you have any back-of-the-napkin math on quantifying how much this
>>> would improve the situation vs existing methods (eg cpfp)?
>>>
>>>
>>>
>>> On Sat, Jan 1, 2022 at 2:04 PM Jeremy via bitcoin-dev <
>>> bitcoin-dev at lists.linuxfoundation.org> wrote:
>>>
>>>> Happy new years devs,
>>>>
>>>> I figured I would share some thoughts for conceptual review that have
>>>> been bouncing around my head as an opportunity to clean up the fee paying
>>>> semantics in bitcoin "for good". The design space is very wide on the
>>>> approach I'll share, so below is just a sketch of how it could work which
>>>> I'm sure could be improved greatly.
>>>>
>>>> Transaction fees are an integral part of bitcoin.
>>>>
>>>> However, due to quirks of Bitcoin's transaction design, fees are a part
>>>> of the transactions that they occur in.
>>>>
>>>> While this works in a "Bitcoin 1.0" world, where all transactions are
>>>> simple on-chain transfers, real world use of Bitcoin requires support for
>>>> things like Fee Bumping stuck transactions, DoS resistant Payment Channels,
>>>> and other long lived Smart Contracts that can't predict future fee rates.
>>>> Having the fees paid in band makes writing these contracts much more
>>>> difficult as you can't merely express the logic you want for the
>>>> transaction, but also the fees.
>>>>
>>>> Previously, I proposed a special type of transaction called a "Sponsor"
>>>> which has some special consensus + mempool rules to allow arbitrarily
>>>> appending fees to a transaction to bump it up in the mempool.
>>>>
>>>> As an alternative, we could establish an account system in Bitcoin as
>>>> an "extension block".
>>>>
>>>> *Here's how it might work:*
>>>>
>>>> 1. Define a special anyone can spend output type that is a "fee
>>>> account" (e.g. segwit V2). Such outputs have a redeeming key and an amount
>>>> associated with them, but are overall anyone can spend.
>>>> 2. All deposits to these outputs get stored in a separate UTXO database
>>>> for fee accounts
>>>> 3. Fee accounts can sign only two kinds of transaction: A: a fee amount
>>>> and a TXID (or Outpoint?); B: a withdraw amount, a fee, and an address
>>>> 4. These transactions are committed in an extension block merkle tree.
>>>> While the actual signature must cover the TXID/Outpoint, the committed data
>>>> need only cover the index in the block of the transaction. The public key
>>>> for account lookup can be recovered from the message + signature.
>>>> 5. In any block, any of the fee account deposits can be: released into
>>>> fees if there is a corresponding tx; consolidated together to reduce the
>>>> number of utxos (this can be just an OP_TRUE no metadata needed); or
>>>> released into fees *and paid back* into the requested withdrawal key
>>>> (encumbering a 100 block timeout). Signatures must be unique in a block.
>>>> 6. Mempool logic is updated to allow attaching of account fee spends to
>>>> transactions, the mempool can restrict that an account is not allowed more
>>>> spend more than it's balance.
>>>>
>>>> *But aren't accounts "bad"?*
>>>>
>>>> Yes, accounts are bad. But these accounts are not bad, because any
>>>> funds withdrawn from the fee extension are fundamentally locked for 100
>>>> blocks as a coinbase output, so there should be no issues with any series
>>>> of reorgs. Further, since there is no "rich state" for these accounts, the
>>>> state updates can always be applied in a conflict-free way in any order.
>>>>
>>>>
>>>> *Improving the privacy of this design:*
>>>>
>>>> This design could likely be modified to implement something like
>>>> Tornado.cash or something else so that the fee account paying can be
>>>> unlinked from the transaction being paid for, improving privacy at the
>>>> expense of being a bit more expensive.
>>>>
>>>> Other operations could be added to allow a trustless mixing to be done
>>>> by miners automatically where groups of accounts with similar values are
>>>> trustlessly  split into a common denominator and change, and keys are
>>>> derived via a verifiable stealth address like protocol (so fee balances can
>>>> be discovered by tracing the updates posted). These updates could also be
>>>> produced by individuals rather than miners, and miners could simply honor
>>>> them with better privacy. While a miner generating an update would be able
>>>> to deanonymize their mixes, if you have your account mixed several times by
>>>> independent miners that could potentially add sufficient privacy.
>>>>
>>>> The LN can also be used with PTLCs to, in theory, have another
>>>> individual paid to sponsor a transaction on your behalf only if they reveal
>>>> a valid sig from their fee paying account, although under this model it's
>>>> hard to ensure that the owner doesn't pay a fee and then 'cancel' by
>>>> withdrawing the rest. However, this could be partly solved by using
>>>> reputable fee accounts (reputation could be measured somewhat
>>>> decentralized-ly by longevity of the account and transactions paid for
>>>> historically).
>>>>
>>>> *Scalability*
>>>>
>>>> This design is fundamentally 'decent' for scalability because adding
>>>> fees to a transaction does not require adding inputs or outputs and does
>>>> not require tracking substantial amounts of new state.
>>>>
>>>> Paying someone else to pay for you via the LN also helps make this more
>>>> efficient if the withdrawal issues can be fixed.
>>>>
>>>> *Lightning:*
>>>>
>>>> This type of design works really well for channels because the addition
>>>> of fees to e.g. a channel state does not require any sort of pre-planning
>>>> (e.g. anchors) or transaction flexibility (SIGHASH flags). This sort of
>>>> design is naturally immune to pinning issues since you could offer to pay a
>>>> fee for any TXID and the number of fee adding offers does not need to be
>>>> restricted in the same way the descendant transactions would need to be.
>>>>
>>>> *Without a fork?*
>>>>
>>>> This type of design could be done as a federated network that bribes
>>>> miners -- potentially even retroactively after a block is formed. That
>>>> might be sufficient to prove the concept works before a consensus upgrade
>>>> is deployed, but such an approach does mean there is a centralizing layer
>>>> interfering with normal mining.
>>>>
>>>>
>>>> Happy new year!!
>>>>
>>>> Jeremy
>>>>
>>>> --
>>>> @JeremyRubin <https://twitter.com/JeremyRubin>
>>>> <https://twitter.com/JeremyRubin>
>>>> _______________________________________________
>>>> bitcoin-dev mailing list
>>>> bitcoin-dev at lists.linuxfoundation.org
>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>>
>>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/bde037b2/attachment-0001.html>

From jlrubin at mit.edu  Wed Jan 19 07:32:36 2022
From: jlrubin at mit.edu (Jeremy)
Date: Tue, 18 Jan 2022 23:32:36 -0800
Subject: [bitcoin-dev] [Pre-BIP] Fee Accounts
In-Reply-To: <CAGpPWDYxCGkpbiiHFgFrY3=oCwRBY7c_vLQfQg3a_Dwx7pEUTA@mail.gmail.com>
References: <CAD5xwhik6jVQpP2_ss7d5o+pPLsqDCHuaXG41AMKHVYhZMXF1w@mail.gmail.com>
 <CAGpPWDb6HckAhX6p-=cK3fQXyMqivd+xFtiYJ7hKR2k-MWqKJA@mail.gmail.com>
 <CAD5xwhhuvHL2_-ZY1ygZ6WahRi9eg9rk2eHDUODNoJCQX6wL+A@mail.gmail.com>
 <CAGpPWDaQAxEfyFs_g9p=PTUNAkSiQKwPiHJbBaLmzfNTjFeucA@mail.gmail.com>
 <CAD5xwhjUkey+VD=u+69+5eirLCCoLgDgAR_4d20hwHo-eyZr6w@mail.gmail.com>
 <CAGpPWDYxCGkpbiiHFgFrY3=oCwRBY7c_vLQfQg3a_Dwx7pEUTA@mail.gmail.com>
Message-ID: <CAD5xwhhbXZPg+rQjdaygv_6ZsNuuVpibu=LTZBNU4g_naBOWyw@mail.gmail.com>

Ah my bad i misread what you were saying as being about SIGHASH_BUNDLE like
proposals.

For what you're discussing, I previously proposed
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-September/018168.html
which is similar.

The benefit of the OP_VER output is that SIGHASH_EXTERNAL has the issue
that unless you're binding a WTXID (which is maybe too specific?) then you
can have fee bumping cycles. Doing OP_VER output w/ TXID guarantees that
you are acyclic.

The difference between a fee account and this approach basically boils down
to the impact on e.g. reorg stability, where the deposit/withdraw mechanism
is a bit more "robust" for reorderings in reorgs than the in-band
transaction approach, although they are very similar.

--
@JeremyRubin <https://twitter.com/JeremyRubin>
<https://twitter.com/JeremyRubin>


On Tue, Jan 18, 2022 at 8:53 PM Billy Tetrud <billy.tetrud at gmail.com> wrote:

> >  because you make transactions third party malleable it becomes
> possible to bundle and unbundle transactions.
>
> What I was suggesting doesn't make it possible to malleate someone else's
> transaction. I guess maybe my proposal of using a sighash flag might have
> been unclear. Imagine it as a script opcode that just says "this
> transaction must be mined with this other transaction" - the only
> difference being that you can use any output with any encumberance as an
> input for fee bumping. It doesn't prevent the original transaction from
> being mined on its own. So adding junk inputs would be no more of a problem
> than dust attacks already are. It would be used exactly like cpfp, except
> it doesn't spend the parent.
>
> I don't think what I was suggesting is as different from your proposal.
> All the problems of fee revenue optimization and feerate rules that you
> mentioned seem like they'd also exist for your proposal, or for cpfp. Let
> me know if I should clarify further.
>
> On Tue, Jan 18, 2022 at 8:51 PM Jeremy <jlrubin at mit.edu> wrote:
>
>> The issue with sighash flags is that because you make transactions third
>> party malleable it becomes possible to bundle and unbundle transactions.
>>
>> This means there are circumstances where an attacker could e.g. see your
>> txn, and then add a lot of junk change/inputs + 25 descendants and strongly
>> anchor your transaction to the bottom of the mempool.
>>
>> because of rbf rules requiring more fee and feerate, this means you have
>> to bump across the whole package and that can get really messy.
>>
>> more generally speaking, you could imagine a future where mempools track
>> many alternative things that might want to be in a transaction.
>>
>> suppose there are N inputs each with a weight and an amount of fee being
>> added and the sighash flags let me pick any subset of them. However, for a
>> txn to be standard it must be < 100k bytes and for it to be consensus <
>> 1mb. Now it is possible you have to solve a knapsack problem in order to
>> rationally bundle this transaction out of all possibilities.
>>
>> This problem can get even thornier, suppose that the inputs I'm adding
>> themselves are the outputs of another txn in the mempool, now i have to
>> track and propagate the feerates of that child back up to the parent txn
>> and track all these dependencies.
>>
>> perhaps with very careful engineering these issues can be tamed. however
>> it seems with sponsors or fee accounts, by separating the pays-for from the
>> participates-in concerns we can greatly simplify it to something like:
>> compute effective feerate for a txn, including all sponsors that pay more
>> than the feerate of the base txn. Mine that txn and it's subsidies using
>> the normal algo. If you run out of space, all subsidies are same-sized so
>> just take the ones that pay the highest amount up until the added marginal
>> feerate is less than the next eligible txn.
>>
>>
>> --
>> @JeremyRubin <https://twitter.com/JeremyRubin>
>> <https://twitter.com/JeremyRubin>
>>
>>
>> On Tue, Jan 18, 2022 at 6:38 PM Billy Tetrud <billy.tetrud at gmail.com>
>> wrote:
>>
>>> I see, its not primarily to make it cheaper to append fees, but also
>>> allows appending fees in cases that aren't possible now. Is that right? I
>>> can certainly see the benefit of a more general way to add a fee to any
>>> transaction, regardless of whether you're related to that transaction or
>>> not.
>>>
>>> How would you compare the pros and cons of your account-based approach
>>> to something like a new sighash flag? Eg a sighash flag that says "I'm
>>> signing this transaction, but the signature is only valid if mined in the
>>> same block as transaction X (or maybe transactions LIST)". This could be
>>> named SIGHASH_EXTERNAL. Doing this would be a lot more similar to other
>>> bitcoin transactions, and no special account would need to be created. Any
>>> transaction could specify this. At least that's the first thought I would
>>> have in designing a way to arbitrarily bump fees. Have you compared your
>>> solution to something more familiar like that?
>>>
>>> On Tue, Jan 18, 2022 at 11:43 AM Jeremy <jlrubin at mit.edu> wrote:
>>>
>>>> Can you clarify what you mean by "improve the situation"?
>>>>
>>>> There's a potential mild bytes savings, but the bigger deal is that the
>>>> API should be much less vulnerable to pinning issues, fix dust leakage for
>>>> eltoo like protocols, and just generally allow protocol designs to be fully
>>>> abstracted from paying fees. You can't easily mathematically quantify API
>>>> improvements like that.
>>>> --
>>>> @JeremyRubin <https://twitter.com/JeremyRubin>
>>>> <https://twitter.com/JeremyRubin>
>>>>
>>>>
>>>> On Tue, Jan 18, 2022 at 8:13 AM Billy Tetrud <billy.tetrud at gmail.com>
>>>> wrote:
>>>>
>>>>> Do you have any back-of-the-napkin math on quantifying how much this
>>>>> would improve the situation vs existing methods (eg cpfp)?
>>>>>
>>>>>
>>>>>
>>>>> On Sat, Jan 1, 2022 at 2:04 PM Jeremy via bitcoin-dev <
>>>>> bitcoin-dev at lists.linuxfoundation.org> wrote:
>>>>>
>>>>>> Happy new years devs,
>>>>>>
>>>>>> I figured I would share some thoughts for conceptual review that have
>>>>>> been bouncing around my head as an opportunity to clean up the fee paying
>>>>>> semantics in bitcoin "for good". The design space is very wide on the
>>>>>> approach I'll share, so below is just a sketch of how it could work which
>>>>>> I'm sure could be improved greatly.
>>>>>>
>>>>>> Transaction fees are an integral part of bitcoin.
>>>>>>
>>>>>> However, due to quirks of Bitcoin's transaction design, fees are a
>>>>>> part of the transactions that they occur in.
>>>>>>
>>>>>> While this works in a "Bitcoin 1.0" world, where all transactions are
>>>>>> simple on-chain transfers, real world use of Bitcoin requires support for
>>>>>> things like Fee Bumping stuck transactions, DoS resistant Payment Channels,
>>>>>> and other long lived Smart Contracts that can't predict future fee rates.
>>>>>> Having the fees paid in band makes writing these contracts much more
>>>>>> difficult as you can't merely express the logic you want for the
>>>>>> transaction, but also the fees.
>>>>>>
>>>>>> Previously, I proposed a special type of transaction called a
>>>>>> "Sponsor" which has some special consensus + mempool rules to allow
>>>>>> arbitrarily appending fees to a transaction to bump it up in the mempool.
>>>>>>
>>>>>> As an alternative, we could establish an account system in Bitcoin as
>>>>>> an "extension block".
>>>>>>
>>>>>> *Here's how it might work:*
>>>>>>
>>>>>> 1. Define a special anyone can spend output type that is a "fee
>>>>>> account" (e.g. segwit V2). Such outputs have a redeeming key and an amount
>>>>>> associated with them, but are overall anyone can spend.
>>>>>> 2. All deposits to these outputs get stored in a separate UTXO
>>>>>> database for fee accounts
>>>>>> 3. Fee accounts can sign only two kinds of transaction: A: a fee
>>>>>> amount and a TXID (or Outpoint?); B: a withdraw amount, a fee, and
>>>>>> an address
>>>>>> 4. These transactions are committed in an extension block merkle
>>>>>> tree. While the actual signature must cover the TXID/Outpoint, the
>>>>>> committed data need only cover the index in the block of the transaction.
>>>>>> The public key for account lookup can be recovered from the message +
>>>>>> signature.
>>>>>> 5. In any block, any of the fee account deposits can be: released
>>>>>> into fees if there is a corresponding tx; consolidated together to reduce
>>>>>> the number of utxos (this can be just an OP_TRUE no metadata needed); or
>>>>>> released into fees *and paid back* into the requested withdrawal key
>>>>>> (encumbering a 100 block timeout). Signatures must be unique in a block.
>>>>>> 6. Mempool logic is updated to allow attaching of account fee spends
>>>>>> to transactions, the mempool can restrict that an account is not allowed
>>>>>> more spend more than it's balance.
>>>>>>
>>>>>> *But aren't accounts "bad"?*
>>>>>>
>>>>>> Yes, accounts are bad. But these accounts are not bad, because any
>>>>>> funds withdrawn from the fee extension are fundamentally locked for 100
>>>>>> blocks as a coinbase output, so there should be no issues with any series
>>>>>> of reorgs. Further, since there is no "rich state" for these accounts, the
>>>>>> state updates can always be applied in a conflict-free way in any order.
>>>>>>
>>>>>>
>>>>>> *Improving the privacy of this design:*
>>>>>>
>>>>>> This design could likely be modified to implement something like
>>>>>> Tornado.cash or something else so that the fee account paying can be
>>>>>> unlinked from the transaction being paid for, improving privacy at the
>>>>>> expense of being a bit more expensive.
>>>>>>
>>>>>> Other operations could be added to allow a trustless mixing to be
>>>>>> done by miners automatically where groups of accounts with similar values
>>>>>> are trustlessly  split into a common denominator and change, and keys are
>>>>>> derived via a verifiable stealth address like protocol (so fee balances can
>>>>>> be discovered by tracing the updates posted). These updates could also be
>>>>>> produced by individuals rather than miners, and miners could simply honor
>>>>>> them with better privacy. While a miner generating an update would be able
>>>>>> to deanonymize their mixes, if you have your account mixed several times by
>>>>>> independent miners that could potentially add sufficient privacy.
>>>>>>
>>>>>> The LN can also be used with PTLCs to, in theory, have another
>>>>>> individual paid to sponsor a transaction on your behalf only if they reveal
>>>>>> a valid sig from their fee paying account, although under this model it's
>>>>>> hard to ensure that the owner doesn't pay a fee and then 'cancel' by
>>>>>> withdrawing the rest. However, this could be partly solved by using
>>>>>> reputable fee accounts (reputation could be measured somewhat
>>>>>> decentralized-ly by longevity of the account and transactions paid for
>>>>>> historically).
>>>>>>
>>>>>> *Scalability*
>>>>>>
>>>>>> This design is fundamentally 'decent' for scalability because adding
>>>>>> fees to a transaction does not require adding inputs or outputs and does
>>>>>> not require tracking substantial amounts of new state.
>>>>>>
>>>>>> Paying someone else to pay for you via the LN also helps make this
>>>>>> more efficient if the withdrawal issues can be fixed.
>>>>>>
>>>>>> *Lightning:*
>>>>>>
>>>>>> This type of design works really well for channels because the
>>>>>> addition of fees to e.g. a channel state does not require any sort of
>>>>>> pre-planning (e.g. anchors) or transaction flexibility (SIGHASH flags).
>>>>>> This sort of design is naturally immune to pinning issues since you could
>>>>>> offer to pay a fee for any TXID and the number of fee adding offers does
>>>>>> not need to be restricted in the same way the descendant transactions would
>>>>>> need to be.
>>>>>>
>>>>>> *Without a fork?*
>>>>>>
>>>>>> This type of design could be done as a federated network that bribes
>>>>>> miners -- potentially even retroactively after a block is formed. That
>>>>>> might be sufficient to prove the concept works before a consensus upgrade
>>>>>> is deployed, but such an approach does mean there is a centralizing layer
>>>>>> interfering with normal mining.
>>>>>>
>>>>>>
>>>>>> Happy new year!!
>>>>>>
>>>>>> Jeremy
>>>>>>
>>>>>> --
>>>>>> @JeremyRubin <https://twitter.com/JeremyRubin>
>>>>>> <https://twitter.com/JeremyRubin>
>>>>>> _______________________________________________
>>>>>> bitcoin-dev mailing list
>>>>>> bitcoin-dev at lists.linuxfoundation.org
>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>>>>
>>>>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/862ed586/attachment-0001.html>

From billy.tetrud at gmail.com  Wed Jan 19 02:24:47 2022
From: billy.tetrud at gmail.com (Billy Tetrud)
Date: Tue, 18 Jan 2022 20:24:47 -0600
Subject: [bitcoin-dev] Covenants and capabilities in the UTXO model
In-Reply-To: <CAHUJnBAfnmfs2nY3HFRhzNL6ztpZT3dgqe5wCxuO3qpk0OsgRg@mail.gmail.com>
References: <CAHUJnBBFsS597ZRdAtwONMAz1r7gQbrXULzdNtEVxOPENx+tDg@mail.gmail.com>
 <CAGpPWDYvvtCJLsr1SqghugfntnmnKw+GOtufp07d8sN-5vKa0w@mail.gmail.com>
 <CAHUJnBAfnmfs2nY3HFRhzNL6ztpZT3dgqe5wCxuO3qpk0OsgRg@mail.gmail.com>
Message-ID: <CAGpPWDabAbY3nS-1QATrzLj+O4dxfs4Fo0EuYFftNdjw_gwRPw@mail.gmail.com>

> 'assert that my parent has a scriptpubkey of X'... That way you can, for
example, have a UTXO which only allows itself to be absorbed by a
transaction also involving a UTXO with a particular capability

I'm not sure I fully follow. I usually think about covenants as having the
reverse form, that a parent would assert "my children must have a script of
the form XYZ". Are you saying you want to be able to specify that a UTXO
can only be spent if the resulting outputs of that transaction all share
the same script? I see this page
<https://chialisp.com/docs/puzzles/singletons/> but i don't understand how
those concepts relate to covenants.

>  allow references to old blocks so code snippets can be pulled out of them

Nodes currently aren't required to keep around the whole blockchain, but
your proposal sounds like it would require them to. I think this could be
pretty detrimental to future scalability. Monero, for example, has a
situation where its UTXO set is the whole blockchain because you can't
generally know what has been spent and what hasn't been. Allowing
references to old blocks would pull in all this old block data into the
UTXO set. So unless you're very careful about how or when you can reference
old blocks, this could cause issues.

> If the recipient can't parse a UTXO the defined behavior should be that
they assume it's bricked.

I must have misunderstood you. I think that's the appropriate response: if
you don't know everything about how a UTXO sent "to you" can be spent, you
can't really treat it as yours.


On Tue, Jan 18, 2022 at 11:16 AM Bram Cohen <bram at chia.net> wrote:

> On Tue, Jan 18, 2022 at 7:10 AM Billy Tetrud <billy.tetrud at gmail.com>
> wrote:
>
>> >  Since scriptpubkeys/scriptsigs continue to run ephemerally at
>> validation time full turing completeness is much less dangerous than people
>> fear.
>>
>> The covenant proposals I've seen that might give bitcoin turing
>> completeness require a turing complete process to be stepped such that each
>> step is a transaction paid for with a usual fee. This fact I think makes
>> the turing completeness a lot less scary. No single transaction would be
>> turing complete, while a sequence of them could be. But importantly, each
>> transaction has a strictly limited runtime and every script could continue
>> to have a calculable number of maximum runtime steps.
>>
>
> This flows naturally out of the UTXO model. In ETH you don't know how much
> transactions will cost in advance because things don't declare their state
> up front, but with all dependencies declared up front execution can be made
> completely deterministic.
>
>  > It would also probably be a good idea to add in a bunch of special
> purpose opcodes for making coherent statements about transactions since in
> Bitcoin they're a very complex and hard to parse format.
>
>>
>> What are some examples you're thinking of?
>>
>
> What's needed from a programming perspective is the ability to say 'assert
> that my parent has a scriptpubkey of X'. That way you can, for example,
> have a UTXO which only allows itself to be absorbed by a transaction also
> involving a UTXO with a particular capability ('pay to singleton' is a term
> for this) and that capability can be enforced by the scriptpubkey asserting
> that either its parent is the originator of it or that its parent also has
> the same type of scriptpubkey. This allows capabilities to be added without
> gunking up on chain state with things other than UTXOs.
>
>
>
>>
>> > Once you start implementing complex general purpose functionality it
>> tends to get very expensive very fast and is likely impractical unless
>> there's a way to compress or at least de-duplicate snippets of code which
>> are repeated on chain.
>>
>> I like this idea. If there was a way to dedupe scripts in some way, it
>> could save a lot of bandwidth which would help bitcoin scale better. One
>> thing we could do is have a specific set of pre-ordained script snippets
>> that are given a shorthand that's stored in the software and explicitly
>> shouldn't be transmitted long-hand. That would help for very standard
>> widespread things. We could even add in a consensus rule where short-handed
>> scripts pay for their expanded vbytes, not the vbytes of the compressed
>> version. This would mean the incentives wouldn't be changed by this
>> approach.
>>
>
> One approach is to allow references to old blocks so code snippets can be
> pulled out of them. That avoids having to define the 'common sections' up
> front. Charging for virtual vbytes unfortunately keeps smart functionality
> very expensive and the point is to make it not so expensive.
>
>
>> > For a payment to someone to come with a rider where they could accept
>> it and think their system was working properly for a while until you
>> exercised some kind of retroactive veto on new action or even clawback
>> would obviously be unacceptable behavior.
>>
>> I definitely agree. A payment's covenant should be completely knowable to
>> the recipient, and recipients shouldn't accept random covenants they
>> haven't explicitly accepted on their own.
>>
>> > for payments to come with covenants but the recipient not even be able
>> to parse them unless they're fully buying into that behavior is much more
>> reasonable.
>>
>> The recipient not being able to parse them? Couldn't that result in
>> exactly the situation above you said was not acceptable? The recipient must
>> be able to know all the possibilities of the covenant or there might be
>> some secret retroactive clawback in there waiting to bite them.
>>
>
> Not sure what you're saying. If the recipient can't parse a UTXO the
> defined behavior should be that they assume it's bricked.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/b4029e1a/attachment-0001.html>

From billy.tetrud at gmail.com  Wed Jan 19 02:26:12 2022
From: billy.tetrud at gmail.com (Billy Tetrud)
Date: Tue, 18 Jan 2022 20:26:12 -0600
Subject: [bitcoin-dev] On the regularity of soft forks
In-Reply-To: <MtiCR2x--7-2@tutanota.de>
References: <MtiCR2x--7-2@tutanota.de>
Message-ID: <CAGpPWDYzVyjfKNL4thxCwAcZgfpdrjRcffu=HL4aUL9b4pG+PA@mail.gmail.com>

>  That day is nowhere near IMO and maybe we won't see it in my lifetime.

I think there is a reasonable argument to be made that maybe bitcoin needs
to move faster now than it should in the future, and the cost of having the
community remain vigilant against harmful changes is worth the extra speed.
The question then becomes, does doing soft forks more often make things go
faster? Its not clear to me that the answer is yes.

> This is not possible in a decentralized network like Bitcoin and makes no
sense.

Why do you think that its not possible? I completely disagree. The bitcoin
community has already come up with cultural norms like this, like the idea
of doing soft forks instead of hardforks wherever possible. Its impossible
to prevent others from doing otherwise, but its completely possible and
desirable for the bitcoin community to adopt standards that we attempt to
adhere to.

> More changes bundled require more review and still more probability to
have bugs.

I already addressed this in my previous email. Why do you think there is
more to review in a soft fork with two bundled changes than in two separate
concurrent soft-fork activations using BIP8 or BIP9? Both require both
changes to be in the software and both require testing to ensure that the
changes interact appropriately. The difference is that in the second case,
you have to test all combinations of which order the proposals activate in.

And let's consider the easiest case of change A, then soft fork 1, then
change B, and soft fork 2. Change A needs to be tested all on its own, and
change B when it comes along also then needs to be tested on code that
already has change A. If the changes are bundled, the same procedure needs
to happen. You just avoid having to do soft fork 1.

> BIP 8 with LOT=TRUE was a better activation mechanism

I completely disagree, but that's not relevant to this topic.

On Tue, Jan 18, 2022 at 11:22 AM Prayank <prayank at tutanota.de> wrote:

> > We should strive to one day get to a point where the bitcoin consensus
> isn't updating at all.
>
> That day is nowhere near IMO and maybe we won't see it in my lifetime.
>
> > Perhaps we should come to a consensus as a consensus as a community what
> the minimum time between soft forks should be, and just as importantly,
> what the minimum time between finalized consensus-change implementation and
> when we decide community consensus has been achieved.
>
> This is not possible in a decentralized network like Bitcoin and makes no
> sense. Soft forks can/should be done as and when required. This does not
> mean we do them often but if a change makes sense, looks ready, got enough
> consensus, reviewed properly etc. then timing doesn't really matter in
> every case.
>
> > Activating multiple consensus changes in a bundle is far safer than
> having multiple separate in-flight soft forks at once.
>
> This is not true. More changes bundled require more review and still more
> probability to have bugs. Security is always about keeping things simple.
>
> > One solution is that we could be a lot more direct about how decisions
> are made. There's been a lot of rhetoric around UASF and how the economic
> majority is really who's running the show.
>
> BIP 8 with LOT=TRUE was a better activation mechanism option in Taproot
> but some influential developers wrote its misleading, unsafe etc. on social
> media so you can call me negative at this moment however I have realized
> the truth is really sad and we can't blindly follow some people. There are
> lot of people who will tell you bad things about UASF and how speedy trial
> is the best thing Bitcoin has ever experienced.
>
> Michael Folkson also had some opinion in activation mechanism IIRC,
>
>
> --
> Prayank
>
> A3B1 E430 2298 178F
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/29a2fa78/attachment-0001.html>

From billy.tetrud at gmail.com  Wed Jan 19 02:37:39 2022
From: billy.tetrud at gmail.com (Billy Tetrud)
Date: Tue, 18 Jan 2022 20:37:39 -0600
Subject: [bitcoin-dev] [Pre-BIP] Fee Accounts
In-Reply-To: <CAD5xwhhuvHL2_-ZY1ygZ6WahRi9eg9rk2eHDUODNoJCQX6wL+A@mail.gmail.com>
References: <CAD5xwhik6jVQpP2_ss7d5o+pPLsqDCHuaXG41AMKHVYhZMXF1w@mail.gmail.com>
 <CAGpPWDb6HckAhX6p-=cK3fQXyMqivd+xFtiYJ7hKR2k-MWqKJA@mail.gmail.com>
 <CAD5xwhhuvHL2_-ZY1ygZ6WahRi9eg9rk2eHDUODNoJCQX6wL+A@mail.gmail.com>
Message-ID: <CAGpPWDaQAxEfyFs_g9p=PTUNAkSiQKwPiHJbBaLmzfNTjFeucA@mail.gmail.com>

I see, its not primarily to make it cheaper to append fees, but also allows
appending fees in cases that aren't possible now. Is that right? I can
certainly see the benefit of a more general way to add a fee to any
transaction, regardless of whether you're related to that transaction or
not.

How would you compare the pros and cons of your account-based approach to
something like a new sighash flag? Eg a sighash flag that says "I'm signing
this transaction, but the signature is only valid if mined in the same
block as transaction X (or maybe transactions LIST)". This could be named
SIGHASH_EXTERNAL. Doing this would be a lot more similar to other bitcoin
transactions, and no special account would need to be created. Any
transaction could specify this. At least that's the first thought I would
have in designing a way to arbitrarily bump fees. Have you compared your
solution to something more familiar like that?

On Tue, Jan 18, 2022 at 11:43 AM Jeremy <jlrubin at mit.edu> wrote:

> Can you clarify what you mean by "improve the situation"?
>
> There's a potential mild bytes savings, but the bigger deal is that the
> API should be much less vulnerable to pinning issues, fix dust leakage for
> eltoo like protocols, and just generally allow protocol designs to be fully
> abstracted from paying fees. You can't easily mathematically quantify API
> improvements like that.
> --
> @JeremyRubin <https://twitter.com/JeremyRubin>
> <https://twitter.com/JeremyRubin>
>
>
> On Tue, Jan 18, 2022 at 8:13 AM Billy Tetrud <billy.tetrud at gmail.com>
> wrote:
>
>> Do you have any back-of-the-napkin math on quantifying how much this
>> would improve the situation vs existing methods (eg cpfp)?
>>
>>
>>
>> On Sat, Jan 1, 2022 at 2:04 PM Jeremy via bitcoin-dev <
>> bitcoin-dev at lists.linuxfoundation.org> wrote:
>>
>>> Happy new years devs,
>>>
>>> I figured I would share some thoughts for conceptual review that have
>>> been bouncing around my head as an opportunity to clean up the fee paying
>>> semantics in bitcoin "for good". The design space is very wide on the
>>> approach I'll share, so below is just a sketch of how it could work which
>>> I'm sure could be improved greatly.
>>>
>>> Transaction fees are an integral part of bitcoin.
>>>
>>> However, due to quirks of Bitcoin's transaction design, fees are a part
>>> of the transactions that they occur in.
>>>
>>> While this works in a "Bitcoin 1.0" world, where all transactions are
>>> simple on-chain transfers, real world use of Bitcoin requires support for
>>> things like Fee Bumping stuck transactions, DoS resistant Payment Channels,
>>> and other long lived Smart Contracts that can't predict future fee rates.
>>> Having the fees paid in band makes writing these contracts much more
>>> difficult as you can't merely express the logic you want for the
>>> transaction, but also the fees.
>>>
>>> Previously, I proposed a special type of transaction called a "Sponsor"
>>> which has some special consensus + mempool rules to allow arbitrarily
>>> appending fees to a transaction to bump it up in the mempool.
>>>
>>> As an alternative, we could establish an account system in Bitcoin as an
>>> "extension block".
>>>
>>> *Here's how it might work:*
>>>
>>> 1. Define a special anyone can spend output type that is a "fee account"
>>> (e.g. segwit V2). Such outputs have a redeeming key and an amount
>>> associated with them, but are overall anyone can spend.
>>> 2. All deposits to these outputs get stored in a separate UTXO database
>>> for fee accounts
>>> 3. Fee accounts can sign only two kinds of transaction: A: a fee amount
>>> and a TXID (or Outpoint?); B: a withdraw amount, a fee, and an address
>>> 4. These transactions are committed in an extension block merkle tree.
>>> While the actual signature must cover the TXID/Outpoint, the committed data
>>> need only cover the index in the block of the transaction. The public key
>>> for account lookup can be recovered from the message + signature.
>>> 5. In any block, any of the fee account deposits can be: released into
>>> fees if there is a corresponding tx; consolidated together to reduce the
>>> number of utxos (this can be just an OP_TRUE no metadata needed); or
>>> released into fees *and paid back* into the requested withdrawal key
>>> (encumbering a 100 block timeout). Signatures must be unique in a block.
>>> 6. Mempool logic is updated to allow attaching of account fee spends to
>>> transactions, the mempool can restrict that an account is not allowed more
>>> spend more than it's balance.
>>>
>>> *But aren't accounts "bad"?*
>>>
>>> Yes, accounts are bad. But these accounts are not bad, because any funds
>>> withdrawn from the fee extension are fundamentally locked for 100 blocks as
>>> a coinbase output, so there should be no issues with any series of reorgs.
>>> Further, since there is no "rich state" for these accounts, the state
>>> updates can always be applied in a conflict-free way in any order.
>>>
>>>
>>> *Improving the privacy of this design:*
>>>
>>> This design could likely be modified to implement something like
>>> Tornado.cash or something else so that the fee account paying can be
>>> unlinked from the transaction being paid for, improving privacy at the
>>> expense of being a bit more expensive.
>>>
>>> Other operations could be added to allow a trustless mixing to be done
>>> by miners automatically where groups of accounts with similar values are
>>> trustlessly  split into a common denominator and change, and keys are
>>> derived via a verifiable stealth address like protocol (so fee balances can
>>> be discovered by tracing the updates posted). These updates could also be
>>> produced by individuals rather than miners, and miners could simply honor
>>> them with better privacy. While a miner generating an update would be able
>>> to deanonymize their mixes, if you have your account mixed several times by
>>> independent miners that could potentially add sufficient privacy.
>>>
>>> The LN can also be used with PTLCs to, in theory, have another
>>> individual paid to sponsor a transaction on your behalf only if they reveal
>>> a valid sig from their fee paying account, although under this model it's
>>> hard to ensure that the owner doesn't pay a fee and then 'cancel' by
>>> withdrawing the rest. However, this could be partly solved by using
>>> reputable fee accounts (reputation could be measured somewhat
>>> decentralized-ly by longevity of the account and transactions paid for
>>> historically).
>>>
>>> *Scalability*
>>>
>>> This design is fundamentally 'decent' for scalability because adding
>>> fees to a transaction does not require adding inputs or outputs and does
>>> not require tracking substantial amounts of new state.
>>>
>>> Paying someone else to pay for you via the LN also helps make this more
>>> efficient if the withdrawal issues can be fixed.
>>>
>>> *Lightning:*
>>>
>>> This type of design works really well for channels because the addition
>>> of fees to e.g. a channel state does not require any sort of pre-planning
>>> (e.g. anchors) or transaction flexibility (SIGHASH flags). This sort of
>>> design is naturally immune to pinning issues since you could offer to pay a
>>> fee for any TXID and the number of fee adding offers does not need to be
>>> restricted in the same way the descendant transactions would need to be.
>>>
>>> *Without a fork?*
>>>
>>> This type of design could be done as a federated network that bribes
>>> miners -- potentially even retroactively after a block is formed. That
>>> might be sufficient to prove the concept works before a consensus upgrade
>>> is deployed, but such an approach does mean there is a centralizing layer
>>> interfering with normal mining.
>>>
>>>
>>> Happy new year!!
>>>
>>> Jeremy
>>>
>>> --
>>> @JeremyRubin <https://twitter.com/JeremyRubin>
>>> <https://twitter.com/JeremyRubin>
>>> _______________________________________________
>>> bitcoin-dev mailing list
>>> bitcoin-dev at lists.linuxfoundation.org
>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/3c72c1c7/attachment-0001.html>

From billy.tetrud at gmail.com  Wed Jan 19 04:53:21 2022
From: billy.tetrud at gmail.com (Billy Tetrud)
Date: Tue, 18 Jan 2022 22:53:21 -0600
Subject: [bitcoin-dev] [Pre-BIP] Fee Accounts
In-Reply-To: <CAD5xwhjUkey+VD=u+69+5eirLCCoLgDgAR_4d20hwHo-eyZr6w@mail.gmail.com>
References: <CAD5xwhik6jVQpP2_ss7d5o+pPLsqDCHuaXG41AMKHVYhZMXF1w@mail.gmail.com>
 <CAGpPWDb6HckAhX6p-=cK3fQXyMqivd+xFtiYJ7hKR2k-MWqKJA@mail.gmail.com>
 <CAD5xwhhuvHL2_-ZY1ygZ6WahRi9eg9rk2eHDUODNoJCQX6wL+A@mail.gmail.com>
 <CAGpPWDaQAxEfyFs_g9p=PTUNAkSiQKwPiHJbBaLmzfNTjFeucA@mail.gmail.com>
 <CAD5xwhjUkey+VD=u+69+5eirLCCoLgDgAR_4d20hwHo-eyZr6w@mail.gmail.com>
Message-ID: <CAGpPWDYxCGkpbiiHFgFrY3=oCwRBY7c_vLQfQg3a_Dwx7pEUTA@mail.gmail.com>

>  because you make transactions third party malleable it becomes possible
to bundle and unbundle transactions.

What I was suggesting doesn't make it possible to malleate someone else's
transaction. I guess maybe my proposal of using a sighash flag might have
been unclear. Imagine it as a script opcode that just says "this
transaction must be mined with this other transaction" - the only
difference being that you can use any output with any encumberance as an
input for fee bumping. It doesn't prevent the original transaction from
being mined on its own. So adding junk inputs would be no more of a problem
than dust attacks already are. It would be used exactly like cpfp, except
it doesn't spend the parent.

I don't think what I was suggesting is as different from your proposal. All
the problems of fee revenue optimization and feerate rules that you
mentioned seem like they'd also exist for your proposal, or for cpfp. Let
me know if I should clarify further.

On Tue, Jan 18, 2022 at 8:51 PM Jeremy <jlrubin at mit.edu> wrote:

> The issue with sighash flags is that because you make transactions third
> party malleable it becomes possible to bundle and unbundle transactions.
>
> This means there are circumstances where an attacker could e.g. see your
> txn, and then add a lot of junk change/inputs + 25 descendants and strongly
> anchor your transaction to the bottom of the mempool.
>
> because of rbf rules requiring more fee and feerate, this means you have
> to bump across the whole package and that can get really messy.
>
> more generally speaking, you could imagine a future where mempools track
> many alternative things that might want to be in a transaction.
>
> suppose there are N inputs each with a weight and an amount of fee being
> added and the sighash flags let me pick any subset of them. However, for a
> txn to be standard it must be < 100k bytes and for it to be consensus <
> 1mb. Now it is possible you have to solve a knapsack problem in order to
> rationally bundle this transaction out of all possibilities.
>
> This problem can get even thornier, suppose that the inputs I'm adding
> themselves are the outputs of another txn in the mempool, now i have to
> track and propagate the feerates of that child back up to the parent txn
> and track all these dependencies.
>
> perhaps with very careful engineering these issues can be tamed. however
> it seems with sponsors or fee accounts, by separating the pays-for from the
> participates-in concerns we can greatly simplify it to something like:
> compute effective feerate for a txn, including all sponsors that pay more
> than the feerate of the base txn. Mine that txn and it's subsidies using
> the normal algo. If you run out of space, all subsidies are same-sized so
> just take the ones that pay the highest amount up until the added marginal
> feerate is less than the next eligible txn.
>
>
> --
> @JeremyRubin <https://twitter.com/JeremyRubin>
> <https://twitter.com/JeremyRubin>
>
>
> On Tue, Jan 18, 2022 at 6:38 PM Billy Tetrud <billy.tetrud at gmail.com>
> wrote:
>
>> I see, its not primarily to make it cheaper to append fees, but also
>> allows appending fees in cases that aren't possible now. Is that right? I
>> can certainly see the benefit of a more general way to add a fee to any
>> transaction, regardless of whether you're related to that transaction or
>> not.
>>
>> How would you compare the pros and cons of your account-based approach to
>> something like a new sighash flag? Eg a sighash flag that says "I'm signing
>> this transaction, but the signature is only valid if mined in the same
>> block as transaction X (or maybe transactions LIST)". This could be named
>> SIGHASH_EXTERNAL. Doing this would be a lot more similar to other bitcoin
>> transactions, and no special account would need to be created. Any
>> transaction could specify this. At least that's the first thought I would
>> have in designing a way to arbitrarily bump fees. Have you compared your
>> solution to something more familiar like that?
>>
>> On Tue, Jan 18, 2022 at 11:43 AM Jeremy <jlrubin at mit.edu> wrote:
>>
>>> Can you clarify what you mean by "improve the situation"?
>>>
>>> There's a potential mild bytes savings, but the bigger deal is that the
>>> API should be much less vulnerable to pinning issues, fix dust leakage for
>>> eltoo like protocols, and just generally allow protocol designs to be fully
>>> abstracted from paying fees. You can't easily mathematically quantify API
>>> improvements like that.
>>> --
>>> @JeremyRubin <https://twitter.com/JeremyRubin>
>>> <https://twitter.com/JeremyRubin>
>>>
>>>
>>> On Tue, Jan 18, 2022 at 8:13 AM Billy Tetrud <billy.tetrud at gmail.com>
>>> wrote:
>>>
>>>> Do you have any back-of-the-napkin math on quantifying how much this
>>>> would improve the situation vs existing methods (eg cpfp)?
>>>>
>>>>
>>>>
>>>> On Sat, Jan 1, 2022 at 2:04 PM Jeremy via bitcoin-dev <
>>>> bitcoin-dev at lists.linuxfoundation.org> wrote:
>>>>
>>>>> Happy new years devs,
>>>>>
>>>>> I figured I would share some thoughts for conceptual review that have
>>>>> been bouncing around my head as an opportunity to clean up the fee paying
>>>>> semantics in bitcoin "for good". The design space is very wide on the
>>>>> approach I'll share, so below is just a sketch of how it could work which
>>>>> I'm sure could be improved greatly.
>>>>>
>>>>> Transaction fees are an integral part of bitcoin.
>>>>>
>>>>> However, due to quirks of Bitcoin's transaction design, fees are a
>>>>> part of the transactions that they occur in.
>>>>>
>>>>> While this works in a "Bitcoin 1.0" world, where all transactions are
>>>>> simple on-chain transfers, real world use of Bitcoin requires support for
>>>>> things like Fee Bumping stuck transactions, DoS resistant Payment Channels,
>>>>> and other long lived Smart Contracts that can't predict future fee rates.
>>>>> Having the fees paid in band makes writing these contracts much more
>>>>> difficult as you can't merely express the logic you want for the
>>>>> transaction, but also the fees.
>>>>>
>>>>> Previously, I proposed a special type of transaction called a
>>>>> "Sponsor" which has some special consensus + mempool rules to allow
>>>>> arbitrarily appending fees to a transaction to bump it up in the mempool.
>>>>>
>>>>> As an alternative, we could establish an account system in Bitcoin as
>>>>> an "extension block".
>>>>>
>>>>> *Here's how it might work:*
>>>>>
>>>>> 1. Define a special anyone can spend output type that is a "fee
>>>>> account" (e.g. segwit V2). Such outputs have a redeeming key and an amount
>>>>> associated with them, but are overall anyone can spend.
>>>>> 2. All deposits to these outputs get stored in a separate UTXO
>>>>> database for fee accounts
>>>>> 3. Fee accounts can sign only two kinds of transaction: A: a fee
>>>>> amount and a TXID (or Outpoint?); B: a withdraw amount, a fee, and
>>>>> an address
>>>>> 4. These transactions are committed in an extension block merkle tree.
>>>>> While the actual signature must cover the TXID/Outpoint, the committed data
>>>>> need only cover the index in the block of the transaction. The public key
>>>>> for account lookup can be recovered from the message + signature.
>>>>> 5. In any block, any of the fee account deposits can be: released into
>>>>> fees if there is a corresponding tx; consolidated together to reduce the
>>>>> number of utxos (this can be just an OP_TRUE no metadata needed); or
>>>>> released into fees *and paid back* into the requested withdrawal key
>>>>> (encumbering a 100 block timeout). Signatures must be unique in a block.
>>>>> 6. Mempool logic is updated to allow attaching of account fee spends
>>>>> to transactions, the mempool can restrict that an account is not allowed
>>>>> more spend more than it's balance.
>>>>>
>>>>> *But aren't accounts "bad"?*
>>>>>
>>>>> Yes, accounts are bad. But these accounts are not bad, because any
>>>>> funds withdrawn from the fee extension are fundamentally locked for 100
>>>>> blocks as a coinbase output, so there should be no issues with any series
>>>>> of reorgs. Further, since there is no "rich state" for these accounts, the
>>>>> state updates can always be applied in a conflict-free way in any order.
>>>>>
>>>>>
>>>>> *Improving the privacy of this design:*
>>>>>
>>>>> This design could likely be modified to implement something like
>>>>> Tornado.cash or something else so that the fee account paying can be
>>>>> unlinked from the transaction being paid for, improving privacy at the
>>>>> expense of being a bit more expensive.
>>>>>
>>>>> Other operations could be added to allow a trustless mixing to be done
>>>>> by miners automatically where groups of accounts with similar values are
>>>>> trustlessly  split into a common denominator and change, and keys are
>>>>> derived via a verifiable stealth address like protocol (so fee balances can
>>>>> be discovered by tracing the updates posted). These updates could also be
>>>>> produced by individuals rather than miners, and miners could simply honor
>>>>> them with better privacy. While a miner generating an update would be able
>>>>> to deanonymize their mixes, if you have your account mixed several times by
>>>>> independent miners that could potentially add sufficient privacy.
>>>>>
>>>>> The LN can also be used with PTLCs to, in theory, have another
>>>>> individual paid to sponsor a transaction on your behalf only if they reveal
>>>>> a valid sig from their fee paying account, although under this model it's
>>>>> hard to ensure that the owner doesn't pay a fee and then 'cancel' by
>>>>> withdrawing the rest. However, this could be partly solved by using
>>>>> reputable fee accounts (reputation could be measured somewhat
>>>>> decentralized-ly by longevity of the account and transactions paid for
>>>>> historically).
>>>>>
>>>>> *Scalability*
>>>>>
>>>>> This design is fundamentally 'decent' for scalability because adding
>>>>> fees to a transaction does not require adding inputs or outputs and does
>>>>> not require tracking substantial amounts of new state.
>>>>>
>>>>> Paying someone else to pay for you via the LN also helps make this
>>>>> more efficient if the withdrawal issues can be fixed.
>>>>>
>>>>> *Lightning:*
>>>>>
>>>>> This type of design works really well for channels because the
>>>>> addition of fees to e.g. a channel state does not require any sort of
>>>>> pre-planning (e.g. anchors) or transaction flexibility (SIGHASH flags).
>>>>> This sort of design is naturally immune to pinning issues since you could
>>>>> offer to pay a fee for any TXID and the number of fee adding offers does
>>>>> not need to be restricted in the same way the descendant transactions would
>>>>> need to be.
>>>>>
>>>>> *Without a fork?*
>>>>>
>>>>> This type of design could be done as a federated network that bribes
>>>>> miners -- potentially even retroactively after a block is formed. That
>>>>> might be sufficient to prove the concept works before a consensus upgrade
>>>>> is deployed, but such an approach does mean there is a centralizing layer
>>>>> interfering with normal mining.
>>>>>
>>>>>
>>>>> Happy new year!!
>>>>>
>>>>> Jeremy
>>>>>
>>>>> --
>>>>> @JeremyRubin <https://twitter.com/JeremyRubin>
>>>>> <https://twitter.com/JeremyRubin>
>>>>> _______________________________________________
>>>>> bitcoin-dev mailing list
>>>>> bitcoin-dev at lists.linuxfoundation.org
>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>>>
>>>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/59a75bc9/attachment-0001.html>

From alex.schoof at gmail.com  Wed Jan 19 00:37:02 2022
From: alex.schoof at gmail.com (Alex Schoof)
Date: Tue, 18 Jan 2022 19:37:02 -0500
Subject: [bitcoin-dev] CTV BIP review
In-Reply-To: <CAD5xwhh3d1=KXEJOPVuYm3UqNKovrojqJS-c6r6ficsKf6S_7g@mail.gmail.com>
References: <202201182119.02687.luke@dashjr.org>
 <CAD5xwhh3d1=KXEJOPVuYm3UqNKovrojqJS-c6r6ficsKf6S_7g@mail.gmail.com>
Message-ID: <CA+2b5C31jcDZaeov5_2kmcfRbMCr2nmdJd0UphGR_2PaGB3y5Q@mail.gmail.com>

Hey Jeremy,

> On the topic of drafting BIPs for specific use cases, I agree that would
be valuable and can consider it.
> However, I'm a bit skeptical of that approach overall as I don't
necessarily think that the applications *must be* standard, and I view BIPs
as primarily for standardization whereas part of the flexibility of
CTV/Sapio allows users to figure out how they want to use it.

Electronic components (think an integrated circuit or a capacitor) usually
have both a "data sheet" and a set of "application notes". The data sheet
is like a spec or the formal documentation: how the thing works (or is
intended to work), precise dimensions and tolerances, etc. On the other
hand, the Application Notes are either a separate document or an appendix
to the data sheet with specific details about using that component in a
specific application: things like schematics for an example implementation,
things to watch out for (edge cases or unexpected application-specific
behavior, etc.). I appreciate the balance you're trying to strike between
having the BIP for CTV have enough details about how you think it might be
used and having it exclusively be a spec to help drive standardization.
Maybe the solution here is to have some explicit application notes that
have enough details to give people a sense of how these uses could be built
out, but still have it be clear that they are a use of, not a part of CTV
itself by having it either in a linked document or an appendix or
something.

Just a suggestion.

Cheers,

Alex

On Tue, Jan 18, 2022 at 6:54 PM Jeremy via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Thanks for the detailed review.
>
> I'll withhold comment around activation logic and leave that for others to
> discuss.
>
> w.r.t. the language cleanups I'll make a PR that (I hope) clears up the
> small nits later today or tomorrow. Some of it's kind of annoying because
> the legal definition of covenant is "A formal agreement or promise,
> usually included in a contract or deed, to do or not do a particular act; a
> compact or stipulation made in writing or by parol." so I do think things
> like CLTV/CSV are covenants since it's a binding promise to not spend
> before a certain time... it might be out of scope for the BIP to fully
> define these terms because it doesn't really matter what a covenant could
> be as much as it matters what CTV is specifically.
>
> On the topic of drafting BIPs for specific use cases, I agree that would
> be valuable and can consider it.
>
> However, I'm a bit skeptical of that approach overall as I don't
> necessarily think that the applications *must be* standard, and I view BIPs
> as primarily for standardization whereas part of the flexibility of
> CTV/Sapio allows users to figure out how they want to use it.
>
> E.g., we do not yet have a BIP for MuSig or even Multisig in Taproot,
> although there are some papers and example implementations but nothing
> formal yet
> https://bitcoin.stackexchange.com/questions/111666/support-for-taproot-multisig-descriptors).
> Perhaps this is an opportunity for CTV to lead on the amount of formal
> application designs available before 'release'.
>
> As a starting point, maybe you could review some of the application
> focused posts in rubin.io/advent21 and let me know where they seem
> deficient?
>
> Also a BIP describing how to build something like Sapio (and less so Sapio
> itself, since it's still early days for that) might help for folks to be
> able to think through how to compile to CTV contracts? But again, I'm
> skeptical of the value of a BIP v.s. the documentation and examples
> available in the code and https://learn.sapio-lang.org.
>
> I think it's an interesting discussion too because as we've just seen the
> LN ecosystem start the BLIP standards, would an example of non-interactive
> channels be best written up as a BIP, a BLIP, or a descriptive blog/mailing
> list post?
>
> --
> @JeremyRubin <https://twitter.com/JeremyRubin>
> <https://twitter.com/JeremyRubin>
>
>
> On Tue, Jan 18, 2022 at 1:19 PM Luke Dashjr via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>> tl;dr: I don't think CTV is ready yet (but probably close), and in any
>> case
>> definitely not worth reviving BIP 9 with its known flaws and
>> vulnerability.
>>
>> My review here is based solely on the BIP, with no outside context (aside
>> from
>> current consensus rules, of course). In particular, I have _not_ looked
>> at
>> the CTV code proposed for Bitcoin Core yet.
>>
>> >Covenants are restrictions on how a coin may be spent beyond key
>> ownership.
>>
>> nit: Poorly phrased. Even simple scripts can do that already.
>>
>> >A few examples are described below, which should be the subject of
>> future
>> non-consensus standardization efforts.
>>
>> I would ideally like to see fully implemented BIPs for at least one of
>> these
>> (preferably the claimed CoinJoin improvements) before we move toward
>> activation.
>>
>> >Congestion Controlled Transactions
>>
>> I think this use case hasn't been fully thought through yet. It seems
>> like it
>> would be desirable for this purpose, to allow any of the recipients to
>> claim
>> their portion of the payment without footing the fee for every other
>> payment
>> included in the batch. This is still a covenant-type solution, but one
>> that
>> BIP 119 cannot support as-is.
>>
>> (I realise this may be a known and accepted limitation, but I think it
>> should
>> be addressed in the BIP)
>>
>> >Payment Channels
>>
>> Why batch mere channel creation? Seems like the spending transaction
>> should
>> really be the channel closing.
>>
>> >CHECKTEMPLATEVERIFY makes it much easier to set up trustless CoinJoins
>> than
>> previously because participants agree on a single output which pays all
>> participants, which will be lower fee than before.
>>
>> I don't see how. They still have to agree in advance on the outputs, and
>> the
>> total fees will logically be higher than not using CTV...?
>>
>> >Further Each participant doesn't need to know the totality of the
>> outputs
>> committed to by that output, they only have to verify their own sub-tree
>> will
>> pay them.
>>
>> I don't see any way to do this with the provided implementation.
>>
>> >Deployment could be done via BIP 9 VersionBits deployed through Speedy
>> Trial.
>>
>> Hard NACK on this. BIP 9 at this point represents developers attempting
>> to
>> disregard and impose their will over community consensus, as well as an
>> attempt to force a miner veto backdoor/vulnerability on deployment. It
>> should
>> never be used again.
>>
>> Speedy Trial implemented with BIP 8 made sense* as a possible neutral
>> compromise between LOT=True and LOT=False (which could be deployed prior
>> to
>> or in parallel), but using BIP 9 would destroy this.
>>
>> As with Taproot, any future deployments should use BIP 8 again, until a
>> better
>> solution is developed. Reverting back to a known flawed and vulnerable
>> activation method should not be done, and it would be better not to
>> deploy
>> CTV at all at such an expense.
>>
>> The fact that certain developers attempted to deploy a BIP 9 alternative
>> activation for Taproot against community consensus, and that even managed
>> to
>> get released as "Bitcoin Core", makes it all the more important that the
>> community firmly rejects any further action to force this regression.
>>
>> * it is my opinion a BIP 8 ST would be an okay compromise under those
>> circumstances; others do disagree that ST is acceptable at all
>>
>> > This ensures that for a given known input, the TXIDs can also be known
>> ahead
>> of time. Otherwise, CHECKTEMPLATEVERIFY would not be usable for Batched
>> Channel Creation constructions as the redemption TXID could be malleated
>> and
>> pre-signed transactions invalidated, unless the channels are built using
>> an
>> Eltoo-like protocol.
>>
>> Why is it a problem for them to use an Eltoo-like protocol?
>>
>> Why not just commit to the txid itself if that's the goal?
>>
>> >P2SH is incompatible with CHECKTEMPLATEVERIFY
>>
>> Maybe the CTV opcode should only be defined/enforced within witness
>> scripts?
>>
>> >nLockTime should generally be fixed to 0 (in the case of a payment tree,
>> only
>> the *first* lock time is needed to prevent fee-sniping the root)
>>
>> Your "Congestion Controlled Transactions" example would only make sense
>> with
>> the spending transaction much later than the "root", and so could benefit
>> from fee sniping malleability. (In fact, in that example, it would be
>> better
>> not to commit to locktime at all.)
>>
>> >In the CHECKTEMPLATEVERIFY approach, the covenants are severely
>> restricted to
>> simple templates. The structure of CHECKTEMPLATEVERIFY template is such
>> that
>> the outputs must be known exactly at the time of construction. Based on a
>> destructuring argument, it is only possible to create templates which
>> expand
>> in a finite number of steps.
>>
>> It's not clear to me that this holds if OP_CAT or OP_SHA256STREAM get
>> added.
>>
>> >For example, a exchange's hot wallet might use an address which can
>> automatically be moved to a cold storage address after a relative timeout.
>>
>> Wouldn't it make more sense to just have a UTXO both cold+hot can spend,
>> then
>> throw away the hot key?
>>
>> >In contrast to previous forks, OP_CHECKTEMPLATEVERIFY will not make
>> scripts
>> valid for policy until the new rule is active.
>>
>> Policy isn't validity, and cannot be dictated by BIPs (or
>> anyone/anything, for
>> that matter).
>>
>> Luke
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>


-- 


Alex Schoof
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/942a40cd/attachment.html>

From michaelfolkson at protonmail.com  Wed Jan 19 12:02:18 2022
From: michaelfolkson at protonmail.com (Michael Folkson)
Date: Wed, 19 Jan 2022 12:02:18 +0000
Subject: [bitcoin-dev] CTV BIP review
In-Reply-To: <000601d80cbf$2f6a1d80$8e3e5880$@voskuil.org>
References: <202201182119.02687.luke@dashjr.org>
 <02cc01d80cb7$1339c050$39ad40f0$@voskuil.org>
 <202201182209.46044.luke@dashjr.org>
 <000601d80cbf$2f6a1d80$8e3e5880$@voskuil.org>
Message-ID: <up51VtT2s-vcSvah3qiIm8G3KHjcnE5AwZLpTpe_CwRUgrWNJC8BvKFK0vHtYqzh1kTFtVVVLE0lXqBBBVhRR2Rkm3uFbp-Xmqs0KZ4gTUo=@protonmail.com>

Eric, Luke

Can I request that you don't discuss activation methods for future soft forks on a thread for CTV BIP review? I (and a number of others [0]) do not support an upcoming activation attempt of standalone OP_CTV. If you want to discuss activation methods for soft forks generally it would be much better if you set up a separate thread. OP_CTV is not the only current soft fork proposal and there will likely be more.

The activation discussion for Taproot was deliberately kept separate from the review of the Taproot BIPs and implementation. It only commenced once there was overwhelming community consensus for the soft fork to be activated (months after in fact). Though you are free to discuss whatever topics you wish (obviously) discussing soft fork activation methods on a OP_CTV thread might give the mistaken impression that OP_CTV is the next soft fork to be activated which is mere speculation at this point. In an ideal world the promoters of OP_CTV would follow the strong precedent set by the authors and contributors to the Taproot BIPs but regrettably that seems to have gone out the window at this point.

Thanks
Michael

[0]: https://gist.github.com/michaelfolkson/352a503f4f9fc5de89af528d86a1b718
--
Michael Folkson
Email: michaelfolkson at protonmail.com
Keybase: michaelfolkson
PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3

??????? Original Message ???????

On Tuesday, January 18th, 2022 at 11:00 PM, Eric Voskuil via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:

> -----Original Message-----
>
> From: Luke Dashjr luke at dashjr.org
>
> Sent: Tuesday, January 18, 2022 2:10 PM
>
> To: eric at voskuil.org
>
> Cc: 'Bitcoin Protocol Discussion' bitcoin-dev at lists.linuxfoundation.org
>
> Subject: Re: [bitcoin-dev] CTV BIP review
>
> On Tuesday 18 January 2022 22:02:24 eric at voskuil.org wrote:
>
> > The only material distinction between BIP9 and BIP8 is that the latter
> >
> > may activate without signaled support of hash power enforcement.
> >
> > As unenforced soft forks are not "backward compatible" they produce a
> >
> > chain split.
>
> Enforcement of the Bitcoin consensus protocol is by users, not miners.

Given that I stated "hash power enforcement" it is quite clear that this is

in fact only produced by mining. You are misrepresenting my statement to

make an emotional appeal. Without "hash power enforcement", a soft fork is

NOT backward compatible.

"[enforcement of] consensus protocol" is of course by merchants, but that is

not the question at hand. The question is explicitly compatibility. Anyone

can activate a soft fork at any time, but without "hash power enforcement"

soft forks are NOT backward compatible.

> Softforks never produce a chain split. Miners can, and might try to do it

to cause disruption in retaliation, but the softfork itself does not.

Maybe you are trying to split hairs given the fact that blocks are produced

only by miners, so only miners can "cause" a split.

But through not intention ("disruption in retaliation") whatsoever by

mining, a soft fork will result in those activating the rule being split off

the original chain unless majority hash power enforces the rule. The fact

that doing nothing apart from deploying the rule will result in a split is

the very definition of NOT compatible.

I assume you will argue that the original chain is not "valid" and therefore

irrelevant (as if no chain split occurred). But again the point is about

compatibility. The appearance of multiple chains, which appear valid

according to either the previous or new rules, is obviously the

incompatibility.

I shouldn't have to point this out, but observed chain splits have occurred

in more the one large scale soft fork deployment. These splits have only

been resolved through hash power enforcement. In 2010 it took 51 blocks

before the current chain took the lead. In 2012 minority chains persisted

for months. The deployment of soft forks caused these splits, NOT the

actions of miners. And unless majority hash power eventually enforces it,

the soft fork branch necessarily dies.

> > It was for this reason alone that BIP8 never gained sufficient
> >
> > support.
>
> BIP 8 in fact achieved consensus for Taproot activation.

Please define "achieved consensus", because by any definition I can imagine,

this is simply untrue.

> > This is one of the most misleading statements I've seen here. It's not
> >
> > technically a lie, because it states what "should" happen. But it is
> >
> > clearly intended to lead people to believe that BIP8 was actually used
> >
> > ("again") - it was not. ST was some technical tweaks to BIP9.
>
> BIP 8 was used to activate Taproot.

No, it wasn't. I find it hard to imaging how you rationalize such grossly

misleading statements.

> > The outright deception around this one topic has led to significant
> >
> > unnecessary conflict in the community. Make your argument, but make it
> >
> > honestly.
>
> You are the one attempting to deceive here.

That is for others to decide. I appreciate your responses above, since they

certainly help clarify what is happening here.

e

bitcoin-dev mailing list

bitcoin-dev at lists.linuxfoundation.org

https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

From billy.tetrud at gmail.com  Wed Jan 19 16:51:48 2022
From: billy.tetrud at gmail.com (Billy Tetrud)
Date: Wed, 19 Jan 2022 10:51:48 -0600
Subject: [bitcoin-dev] [Pre-BIP] Fee Accounts
In-Reply-To: <CAD5xwhhbXZPg+rQjdaygv_6ZsNuuVpibu=LTZBNU4g_naBOWyw@mail.gmail.com>
References: <CAD5xwhik6jVQpP2_ss7d5o+pPLsqDCHuaXG41AMKHVYhZMXF1w@mail.gmail.com>
 <CAGpPWDb6HckAhX6p-=cK3fQXyMqivd+xFtiYJ7hKR2k-MWqKJA@mail.gmail.com>
 <CAD5xwhhuvHL2_-ZY1ygZ6WahRi9eg9rk2eHDUODNoJCQX6wL+A@mail.gmail.com>
 <CAGpPWDaQAxEfyFs_g9p=PTUNAkSiQKwPiHJbBaLmzfNTjFeucA@mail.gmail.com>
 <CAD5xwhjUkey+VD=u+69+5eirLCCoLgDgAR_4d20hwHo-eyZr6w@mail.gmail.com>
 <CAGpPWDYxCGkpbiiHFgFrY3=oCwRBY7c_vLQfQg3a_Dwx7pEUTA@mail.gmail.com>
 <CAD5xwhhbXZPg+rQjdaygv_6ZsNuuVpibu=LTZBNU4g_naBOWyw@mail.gmail.com>
Message-ID: <CAGpPWDbPptac9UPM45_eWnmgDgeoyc=KxuQs1x7_vk37uarsLA@mail.gmail.com>

Hmm, I don't know anything about  SIGHASH_BUNDLE. The only references
online I can find are just mentions (mostly from you). What is
SIGHASH_BUNDLE?

> unless you're binding a WTXID

That could work, but it would exclude cases where you have a transaction
that has already been partially signed and someone wants to, say, only sign
that transaction if some 3rd party signs a transaction paying part of the
fee for it. Kind of a niche use case, but it would be nice to support it if
possible. If the transaction hasn't been signed at all yet, a new
transaction can just be created that includes the prospective fee-payer,
and if the transaction is fully signed then it has a WTXID to use.

> then you can have fee bumping cycles

What kind of cycles do you mean? You're saying these cycles would make it
less robust to reorgs?

> OP_VER

I assume you mean something other than pushing the version onto the stack
<https://bitcoin.stackexchange.com/questions/97258/given-op-ver-was-never-used-is-disabled-and-not-considered-useful-can-its-meani>?
Is that related to your fee account idea?


On Wed, Jan 19, 2022 at 1:32 AM Jeremy <jlrubin at mit.edu> wrote:

> Ah my bad i misread what you were saying as being about SIGHASH_BUNDLE
> like proposals.
>
> For what you're discussing, I previously proposed
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-September/018168.html
> which is similar.
>
> The benefit of the OP_VER output is that SIGHASH_EXTERNAL has the issue
> that unless you're binding a WTXID (which is maybe too specific?) then you
> can have fee bumping cycles. Doing OP_VER output w/ TXID guarantees that
> you are acyclic.
>
> The difference between a fee account and this approach basically boils
> down to the impact on e.g. reorg stability, where the deposit/withdraw
> mechanism is a bit more "robust" for reorderings in reorgs than the in-band
> transaction approach, although they are very similar.
>
> --
> @JeremyRubin <https://twitter.com/JeremyRubin>
> <https://twitter.com/JeremyRubin>
>
>
> On Tue, Jan 18, 2022 at 8:53 PM Billy Tetrud <billy.tetrud at gmail.com>
> wrote:
>
>> >  because you make transactions third party malleable it becomes
>> possible to bundle and unbundle transactions.
>>
>> What I was suggesting doesn't make it possible to malleate someone else's
>> transaction. I guess maybe my proposal of using a sighash flag might
>> have been unclear. Imagine it as a script opcode that just says "this
>> transaction must be mined with this other transaction" - the only
>> difference being that you can use any output with any encumberance as an
>> input for fee bumping. It doesn't prevent the original transaction from
>> being mined on its own. So adding junk inputs would be no more of a problem
>> than dust attacks already are. It would be used exactly like cpfp, except
>> it doesn't spend the parent.
>>
>> I don't think what I was suggesting is as different from your proposal.
>> All the problems of fee revenue optimization and feerate rules that you
>> mentioned seem like they'd also exist for your proposal, or for cpfp. Let
>> me know if I should clarify further.
>>
>> On Tue, Jan 18, 2022 at 8:51 PM Jeremy <jlrubin at mit.edu> wrote:
>>
>>> The issue with sighash flags is that because you make transactions third
>>> party malleable it becomes possible to bundle and unbundle transactions.
>>>
>>> This means there are circumstances where an attacker could e.g. see your
>>> txn, and then add a lot of junk change/inputs + 25 descendants and strongly
>>> anchor your transaction to the bottom of the mempool.
>>>
>>> because of rbf rules requiring more fee and feerate, this means you have
>>> to bump across the whole package and that can get really messy.
>>>
>>> more generally speaking, you could imagine a future where mempools track
>>> many alternative things that might want to be in a transaction.
>>>
>>> suppose there are N inputs each with a weight and an amount of fee being
>>> added and the sighash flags let me pick any subset of them. However, for a
>>> txn to be standard it must be < 100k bytes and for it to be consensus <
>>> 1mb. Now it is possible you have to solve a knapsack problem in order to
>>> rationally bundle this transaction out of all possibilities.
>>>
>>> This problem can get even thornier, suppose that the inputs I'm adding
>>> themselves are the outputs of another txn in the mempool, now i have to
>>> track and propagate the feerates of that child back up to the parent txn
>>> and track all these dependencies.
>>>
>>> perhaps with very careful engineering these issues can be tamed. however
>>> it seems with sponsors or fee accounts, by separating the pays-for from the
>>> participates-in concerns we can greatly simplify it to something like:
>>> compute effective feerate for a txn, including all sponsors that pay more
>>> than the feerate of the base txn. Mine that txn and it's subsidies using
>>> the normal algo. If you run out of space, all subsidies are same-sized so
>>> just take the ones that pay the highest amount up until the added marginal
>>> feerate is less than the next eligible txn.
>>>
>>>
>>> --
>>> @JeremyRubin <https://twitter.com/JeremyRubin>
>>> <https://twitter.com/JeremyRubin>
>>>
>>>
>>> On Tue, Jan 18, 2022 at 6:38 PM Billy Tetrud <billy.tetrud at gmail.com>
>>> wrote:
>>>
>>>> I see, its not primarily to make it cheaper to append fees, but also
>>>> allows appending fees in cases that aren't possible now. Is that right? I
>>>> can certainly see the benefit of a more general way to add a fee to any
>>>> transaction, regardless of whether you're related to that transaction or
>>>> not.
>>>>
>>>> How would you compare the pros and cons of your account-based approach
>>>> to something like a new sighash flag? Eg a sighash flag that says "I'm
>>>> signing this transaction, but the signature is only valid if mined in the
>>>> same block as transaction X (or maybe transactions LIST)". This could be
>>>> named SIGHASH_EXTERNAL. Doing this would be a lot more similar to other
>>>> bitcoin transactions, and no special account would need to be created. Any
>>>> transaction could specify this. At least that's the first thought I would
>>>> have in designing a way to arbitrarily bump fees. Have you compared your
>>>> solution to something more familiar like that?
>>>>
>>>> On Tue, Jan 18, 2022 at 11:43 AM Jeremy <jlrubin at mit.edu> wrote:
>>>>
>>>>> Can you clarify what you mean by "improve the situation"?
>>>>>
>>>>> There's a potential mild bytes savings, but the bigger deal is that
>>>>> the API should be much less vulnerable to pinning issues, fix dust leakage
>>>>> for eltoo like protocols, and just generally allow protocol designs to be
>>>>> fully abstracted from paying fees. You can't easily mathematically
>>>>> quantify API improvements like that.
>>>>> --
>>>>> @JeremyRubin <https://twitter.com/JeremyRubin>
>>>>> <https://twitter.com/JeremyRubin>
>>>>>
>>>>>
>>>>> On Tue, Jan 18, 2022 at 8:13 AM Billy Tetrud <billy.tetrud at gmail.com>
>>>>> wrote:
>>>>>
>>>>>> Do you have any back-of-the-napkin math on quantifying how much this
>>>>>> would improve the situation vs existing methods (eg cpfp)?
>>>>>>
>>>>>>
>>>>>>
>>>>>> On Sat, Jan 1, 2022 at 2:04 PM Jeremy via bitcoin-dev <
>>>>>> bitcoin-dev at lists.linuxfoundation.org> wrote:
>>>>>>
>>>>>>> Happy new years devs,
>>>>>>>
>>>>>>> I figured I would share some thoughts for conceptual review that
>>>>>>> have been bouncing around my head as an opportunity to clean up the fee
>>>>>>> paying semantics in bitcoin "for good". The design space is very wide on
>>>>>>> the approach I'll share, so below is just a sketch of how it could work
>>>>>>> which I'm sure could be improved greatly.
>>>>>>>
>>>>>>> Transaction fees are an integral part of bitcoin.
>>>>>>>
>>>>>>> However, due to quirks of Bitcoin's transaction design, fees are a
>>>>>>> part of the transactions that they occur in.
>>>>>>>
>>>>>>> While this works in a "Bitcoin 1.0" world, where all transactions
>>>>>>> are simple on-chain transfers, real world use of Bitcoin requires support
>>>>>>> for things like Fee Bumping stuck transactions, DoS resistant Payment
>>>>>>> Channels, and other long lived Smart Contracts that can't predict future
>>>>>>> fee rates. Having the fees paid in band makes writing these contracts much
>>>>>>> more difficult as you can't merely express the logic you want for the
>>>>>>> transaction, but also the fees.
>>>>>>>
>>>>>>> Previously, I proposed a special type of transaction called a
>>>>>>> "Sponsor" which has some special consensus + mempool rules to allow
>>>>>>> arbitrarily appending fees to a transaction to bump it up in the mempool.
>>>>>>>
>>>>>>> As an alternative, we could establish an account system in Bitcoin
>>>>>>> as an "extension block".
>>>>>>>
>>>>>>> *Here's how it might work:*
>>>>>>>
>>>>>>> 1. Define a special anyone can spend output type that is a "fee
>>>>>>> account" (e.g. segwit V2). Such outputs have a redeeming key and an amount
>>>>>>> associated with them, but are overall anyone can spend.
>>>>>>> 2. All deposits to these outputs get stored in a separate UTXO
>>>>>>> database for fee accounts
>>>>>>> 3. Fee accounts can sign only two kinds of transaction: A: a fee
>>>>>>> amount and a TXID (or Outpoint?); B: a withdraw amount, a fee, and
>>>>>>> an address
>>>>>>> 4. These transactions are committed in an extension block merkle
>>>>>>> tree. While the actual signature must cover the TXID/Outpoint, the
>>>>>>> committed data need only cover the index in the block of the transaction.
>>>>>>> The public key for account lookup can be recovered from the message +
>>>>>>> signature.
>>>>>>> 5. In any block, any of the fee account deposits can be: released
>>>>>>> into fees if there is a corresponding tx; consolidated together to reduce
>>>>>>> the number of utxos (this can be just an OP_TRUE no metadata needed); or
>>>>>>> released into fees *and paid back* into the requested withdrawal key
>>>>>>> (encumbering a 100 block timeout). Signatures must be unique in a block.
>>>>>>> 6. Mempool logic is updated to allow attaching of account fee spends
>>>>>>> to transactions, the mempool can restrict that an account is not allowed
>>>>>>> more spend more than it's balance.
>>>>>>>
>>>>>>> *But aren't accounts "bad"?*
>>>>>>>
>>>>>>> Yes, accounts are bad. But these accounts are not bad, because any
>>>>>>> funds withdrawn from the fee extension are fundamentally locked for 100
>>>>>>> blocks as a coinbase output, so there should be no issues with any series
>>>>>>> of reorgs. Further, since there is no "rich state" for these accounts, the
>>>>>>> state updates can always be applied in a conflict-free way in any order.
>>>>>>>
>>>>>>>
>>>>>>> *Improving the privacy of this design:*
>>>>>>>
>>>>>>> This design could likely be modified to implement something like
>>>>>>> Tornado.cash or something else so that the fee account paying can be
>>>>>>> unlinked from the transaction being paid for, improving privacy at the
>>>>>>> expense of being a bit more expensive.
>>>>>>>
>>>>>>> Other operations could be added to allow a trustless mixing to be
>>>>>>> done by miners automatically where groups of accounts with similar values
>>>>>>> are trustlessly  split into a common denominator and change, and keys are
>>>>>>> derived via a verifiable stealth address like protocol (so fee balances can
>>>>>>> be discovered by tracing the updates posted). These updates could also be
>>>>>>> produced by individuals rather than miners, and miners could simply honor
>>>>>>> them with better privacy. While a miner generating an update would be able
>>>>>>> to deanonymize their mixes, if you have your account mixed several times by
>>>>>>> independent miners that could potentially add sufficient privacy.
>>>>>>>
>>>>>>> The LN can also be used with PTLCs to, in theory, have another
>>>>>>> individual paid to sponsor a transaction on your behalf only if they reveal
>>>>>>> a valid sig from their fee paying account, although under this model it's
>>>>>>> hard to ensure that the owner doesn't pay a fee and then 'cancel' by
>>>>>>> withdrawing the rest. However, this could be partly solved by using
>>>>>>> reputable fee accounts (reputation could be measured somewhat
>>>>>>> decentralized-ly by longevity of the account and transactions paid for
>>>>>>> historically).
>>>>>>>
>>>>>>> *Scalability*
>>>>>>>
>>>>>>> This design is fundamentally 'decent' for scalability because adding
>>>>>>> fees to a transaction does not require adding inputs or outputs and does
>>>>>>> not require tracking substantial amounts of new state.
>>>>>>>
>>>>>>> Paying someone else to pay for you via the LN also helps make this
>>>>>>> more efficient if the withdrawal issues can be fixed.
>>>>>>>
>>>>>>> *Lightning:*
>>>>>>>
>>>>>>> This type of design works really well for channels because the
>>>>>>> addition of fees to e.g. a channel state does not require any sort of
>>>>>>> pre-planning (e.g. anchors) or transaction flexibility (SIGHASH flags).
>>>>>>> This sort of design is naturally immune to pinning issues since you could
>>>>>>> offer to pay a fee for any TXID and the number of fee adding offers does
>>>>>>> not need to be restricted in the same way the descendant transactions would
>>>>>>> need to be.
>>>>>>>
>>>>>>> *Without a fork?*
>>>>>>>
>>>>>>> This type of design could be done as a federated network that bribes
>>>>>>> miners -- potentially even retroactively after a block is formed. That
>>>>>>> might be sufficient to prove the concept works before a consensus upgrade
>>>>>>> is deployed, but such an approach does mean there is a centralizing layer
>>>>>>> interfering with normal mining.
>>>>>>>
>>>>>>>
>>>>>>> Happy new year!!
>>>>>>>
>>>>>>> Jeremy
>>>>>>>
>>>>>>> --
>>>>>>> @JeremyRubin <https://twitter.com/JeremyRubin>
>>>>>>> <https://twitter.com/JeremyRubin>
>>>>>>> _______________________________________________
>>>>>>> bitcoin-dev mailing list
>>>>>>> bitcoin-dev at lists.linuxfoundation.org
>>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>>>>>
>>>>>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220119/c587953e/attachment-0001.html>

From jlrubin at mit.edu  Wed Jan 19 20:08:23 2022
From: jlrubin at mit.edu (Jeremy)
Date: Wed, 19 Jan 2022 12:08:23 -0800
Subject: [bitcoin-dev] [Pre-BIP] Fee Accounts
In-Reply-To: <CAGpPWDbPptac9UPM45_eWnmgDgeoyc=KxuQs1x7_vk37uarsLA@mail.gmail.com>
References: <CAD5xwhik6jVQpP2_ss7d5o+pPLsqDCHuaXG41AMKHVYhZMXF1w@mail.gmail.com>
 <CAGpPWDb6HckAhX6p-=cK3fQXyMqivd+xFtiYJ7hKR2k-MWqKJA@mail.gmail.com>
 <CAD5xwhhuvHL2_-ZY1ygZ6WahRi9eg9rk2eHDUODNoJCQX6wL+A@mail.gmail.com>
 <CAGpPWDaQAxEfyFs_g9p=PTUNAkSiQKwPiHJbBaLmzfNTjFeucA@mail.gmail.com>
 <CAD5xwhjUkey+VD=u+69+5eirLCCoLgDgAR_4d20hwHo-eyZr6w@mail.gmail.com>
 <CAGpPWDYxCGkpbiiHFgFrY3=oCwRBY7c_vLQfQg3a_Dwx7pEUTA@mail.gmail.com>
 <CAD5xwhhbXZPg+rQjdaygv_6ZsNuuVpibu=LTZBNU4g_naBOWyw@mail.gmail.com>
 <CAGpPWDbPptac9UPM45_eWnmgDgeoyc=KxuQs1x7_vk37uarsLA@mail.gmail.com>
Message-ID: <CAD5xwhgtpQNZbk1VfWs+P51FOYR4ibgucVBWVt_Z++vLwN7Fdw@mail.gmail.com>

SIGHASH_BUNDLE
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-April/015862.html

By cycles I meant that if you commit to the sponsors by TXID from the
witness, you could "sponsor yourself" directly or through a cycle involving
> 1 txn.

With OP_VER I was talking about the proposal I linked here
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-September/018168.html
which used OP_VER to indicate a txn sponsoring txn. Because the OP_VER is
in the output space, and uses TXIDs, it is cycle-free.


--
@JeremyRubin <https://twitter.com/JeremyRubin>
<https://twitter.com/JeremyRubin>


On Wed, Jan 19, 2022 at 8:52 AM Billy Tetrud <billy.tetrud at gmail.com> wrote:

> Hmm, I don't know anything about  SIGHASH_BUNDLE. The only references
> online I can find are just mentions (mostly from you). What is
> SIGHASH_BUNDLE?
>
> > unless you're binding a WTXID
>
> That could work, but it would exclude cases where you have a transaction
> that has already been partially signed and someone wants to, say, only sign
> that transaction if some 3rd party signs a transaction paying part of the
> fee for it. Kind of a niche use case, but it would be nice to support it if
> possible. If the transaction hasn't been signed at all yet, a new
> transaction can just be created that includes the prospective fee-payer,
> and if the transaction is fully signed then it has a WTXID to use.
>
> > then you can have fee bumping cycles
>
> What kind of cycles do you mean? You're saying these cycles would make it
> less robust to reorgs?
>
> > OP_VER
>
> I assume you mean something other than pushing the version onto the stack
> <https://bitcoin.stackexchange.com/questions/97258/given-op-ver-was-never-used-is-disabled-and-not-considered-useful-can-its-meani>?
> Is that related to your fee account idea?
>
>
> On Wed, Jan 19, 2022 at 1:32 AM Jeremy <jlrubin at mit.edu> wrote:
>
>> Ah my bad i misread what you were saying as being about SIGHASH_BUNDLE
>> like proposals.
>>
>> For what you're discussing, I previously proposed
>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-September/018168.html
>> which is similar.
>>
>> The benefit of the OP_VER output is that SIGHASH_EXTERNAL has the issue
>> that unless you're binding a WTXID (which is maybe too specific?) then you
>> can have fee bumping cycles. Doing OP_VER output w/ TXID guarantees that
>> you are acyclic.
>>
>> The difference between a fee account and this approach basically boils
>> down to the impact on e.g. reorg stability, where the deposit/withdraw
>> mechanism is a bit more "robust" for reorderings in reorgs than the in-band
>> transaction approach, although they are very similar.
>>
>> --
>> @JeremyRubin <https://twitter.com/JeremyRubin>
>> <https://twitter.com/JeremyRubin>
>>
>>
>> On Tue, Jan 18, 2022 at 8:53 PM Billy Tetrud <billy.tetrud at gmail.com>
>> wrote:
>>
>>> >  because you make transactions third party malleable it becomes
>>> possible to bundle and unbundle transactions.
>>>
>>> What I was suggesting doesn't make it possible to malleate someone
>>> else's transaction. I guess maybe my proposal of using a sighash flag
>>> might have been unclear. Imagine it as a script opcode that just says "this
>>> transaction must be mined with this other transaction" - the only
>>> difference being that you can use any output with any encumberance as an
>>> input for fee bumping. It doesn't prevent the original transaction from
>>> being mined on its own. So adding junk inputs would be no more of a problem
>>> than dust attacks already are. It would be used exactly like cpfp, except
>>> it doesn't spend the parent.
>>>
>>> I don't think what I was suggesting is as different from your proposal.
>>> All the problems of fee revenue optimization and feerate rules that you
>>> mentioned seem like they'd also exist for your proposal, or for cpfp. Let
>>> me know if I should clarify further.
>>>
>>> On Tue, Jan 18, 2022 at 8:51 PM Jeremy <jlrubin at mit.edu> wrote:
>>>
>>>> The issue with sighash flags is that because you make transactions
>>>> third party malleable it becomes possible to bundle and unbundle
>>>> transactions.
>>>>
>>>> This means there are circumstances where an attacker could e.g. see
>>>> your txn, and then add a lot of junk change/inputs + 25 descendants and
>>>> strongly anchor your transaction to the bottom of the mempool.
>>>>
>>>> because of rbf rules requiring more fee and feerate, this means you
>>>> have to bump across the whole package and that can get really messy.
>>>>
>>>> more generally speaking, you could imagine a future where mempools
>>>> track many alternative things that might want to be in a transaction.
>>>>
>>>> suppose there are N inputs each with a weight and an amount of fee
>>>> being added and the sighash flags let me pick any subset of them. However,
>>>> for a txn to be standard it must be < 100k bytes and for it to be consensus
>>>> < 1mb. Now it is possible you have to solve a knapsack problem in order to
>>>> rationally bundle this transaction out of all possibilities.
>>>>
>>>> This problem can get even thornier, suppose that the inputs I'm adding
>>>> themselves are the outputs of another txn in the mempool, now i have to
>>>> track and propagate the feerates of that child back up to the parent txn
>>>> and track all these dependencies.
>>>>
>>>> perhaps with very careful engineering these issues can be tamed.
>>>> however it seems with sponsors or fee accounts, by separating the pays-for
>>>> from the participates-in concerns we can greatly simplify it to something
>>>> like: compute effective feerate for a txn, including all sponsors that pay
>>>> more than the feerate of the base txn. Mine that txn and it's subsidies
>>>> using the normal algo. If you run out of space, all subsidies are
>>>> same-sized so just take the ones that pay the highest amount up until the
>>>> added marginal feerate is less than the next eligible txn.
>>>>
>>>>
>>>> --
>>>> @JeremyRubin <https://twitter.com/JeremyRubin>
>>>> <https://twitter.com/JeremyRubin>
>>>>
>>>>
>>>> On Tue, Jan 18, 2022 at 6:38 PM Billy Tetrud <billy.tetrud at gmail.com>
>>>> wrote:
>>>>
>>>>> I see, its not primarily to make it cheaper to append fees, but also
>>>>> allows appending fees in cases that aren't possible now. Is that right? I
>>>>> can certainly see the benefit of a more general way to add a fee to any
>>>>> transaction, regardless of whether you're related to that transaction or
>>>>> not.
>>>>>
>>>>> How would you compare the pros and cons of your account-based approach
>>>>> to something like a new sighash flag? Eg a sighash flag that says "I'm
>>>>> signing this transaction, but the signature is only valid if mined in the
>>>>> same block as transaction X (or maybe transactions LIST)". This could be
>>>>> named SIGHASH_EXTERNAL. Doing this would be a lot more similar to other
>>>>> bitcoin transactions, and no special account would need to be created. Any
>>>>> transaction could specify this. At least that's the first thought I would
>>>>> have in designing a way to arbitrarily bump fees. Have you compared your
>>>>> solution to something more familiar like that?
>>>>>
>>>>> On Tue, Jan 18, 2022 at 11:43 AM Jeremy <jlrubin at mit.edu> wrote:
>>>>>
>>>>>> Can you clarify what you mean by "improve the situation"?
>>>>>>
>>>>>> There's a potential mild bytes savings, but the bigger deal is that
>>>>>> the API should be much less vulnerable to pinning issues, fix dust leakage
>>>>>> for eltoo like protocols, and just generally allow protocol designs to be
>>>>>> fully abstracted from paying fees. You can't easily mathematically
>>>>>> quantify API improvements like that.
>>>>>> --
>>>>>> @JeremyRubin <https://twitter.com/JeremyRubin>
>>>>>> <https://twitter.com/JeremyRubin>
>>>>>>
>>>>>>
>>>>>> On Tue, Jan 18, 2022 at 8:13 AM Billy Tetrud <billy.tetrud at gmail.com>
>>>>>> wrote:
>>>>>>
>>>>>>> Do you have any back-of-the-napkin math on quantifying how much this
>>>>>>> would improve the situation vs existing methods (eg cpfp)?
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> On Sat, Jan 1, 2022 at 2:04 PM Jeremy via bitcoin-dev <
>>>>>>> bitcoin-dev at lists.linuxfoundation.org> wrote:
>>>>>>>
>>>>>>>> Happy new years devs,
>>>>>>>>
>>>>>>>> I figured I would share some thoughts for conceptual review that
>>>>>>>> have been bouncing around my head as an opportunity to clean up the fee
>>>>>>>> paying semantics in bitcoin "for good". The design space is very wide on
>>>>>>>> the approach I'll share, so below is just a sketch of how it could work
>>>>>>>> which I'm sure could be improved greatly.
>>>>>>>>
>>>>>>>> Transaction fees are an integral part of bitcoin.
>>>>>>>>
>>>>>>>> However, due to quirks of Bitcoin's transaction design, fees are a
>>>>>>>> part of the transactions that they occur in.
>>>>>>>>
>>>>>>>> While this works in a "Bitcoin 1.0" world, where all transactions
>>>>>>>> are simple on-chain transfers, real world use of Bitcoin requires support
>>>>>>>> for things like Fee Bumping stuck transactions, DoS resistant Payment
>>>>>>>> Channels, and other long lived Smart Contracts that can't predict future
>>>>>>>> fee rates. Having the fees paid in band makes writing these contracts much
>>>>>>>> more difficult as you can't merely express the logic you want for the
>>>>>>>> transaction, but also the fees.
>>>>>>>>
>>>>>>>> Previously, I proposed a special type of transaction called a
>>>>>>>> "Sponsor" which has some special consensus + mempool rules to allow
>>>>>>>> arbitrarily appending fees to a transaction to bump it up in the mempool.
>>>>>>>>
>>>>>>>> As an alternative, we could establish an account system in Bitcoin
>>>>>>>> as an "extension block".
>>>>>>>>
>>>>>>>> *Here's how it might work:*
>>>>>>>>
>>>>>>>> 1. Define a special anyone can spend output type that is a "fee
>>>>>>>> account" (e.g. segwit V2). Such outputs have a redeeming key and an amount
>>>>>>>> associated with them, but are overall anyone can spend.
>>>>>>>> 2. All deposits to these outputs get stored in a separate UTXO
>>>>>>>> database for fee accounts
>>>>>>>> 3. Fee accounts can sign only two kinds of transaction: A: a fee
>>>>>>>> amount and a TXID (or Outpoint?); B: a withdraw amount, a fee, and
>>>>>>>> an address
>>>>>>>> 4. These transactions are committed in an extension block merkle
>>>>>>>> tree. While the actual signature must cover the TXID/Outpoint, the
>>>>>>>> committed data need only cover the index in the block of the transaction.
>>>>>>>> The public key for account lookup can be recovered from the message +
>>>>>>>> signature.
>>>>>>>> 5. In any block, any of the fee account deposits can be: released
>>>>>>>> into fees if there is a corresponding tx; consolidated together to reduce
>>>>>>>> the number of utxos (this can be just an OP_TRUE no metadata needed); or
>>>>>>>> released into fees *and paid back* into the requested withdrawal key
>>>>>>>> (encumbering a 100 block timeout). Signatures must be unique in a block.
>>>>>>>> 6. Mempool logic is updated to allow attaching of account fee
>>>>>>>> spends to transactions, the mempool can restrict that an account is not
>>>>>>>> allowed more spend more than it's balance.
>>>>>>>>
>>>>>>>> *But aren't accounts "bad"?*
>>>>>>>>
>>>>>>>> Yes, accounts are bad. But these accounts are not bad, because any
>>>>>>>> funds withdrawn from the fee extension are fundamentally locked for 100
>>>>>>>> blocks as a coinbase output, so there should be no issues with any series
>>>>>>>> of reorgs. Further, since there is no "rich state" for these accounts, the
>>>>>>>> state updates can always be applied in a conflict-free way in any order.
>>>>>>>>
>>>>>>>>
>>>>>>>> *Improving the privacy of this design:*
>>>>>>>>
>>>>>>>> This design could likely be modified to implement something like
>>>>>>>> Tornado.cash or something else so that the fee account paying can be
>>>>>>>> unlinked from the transaction being paid for, improving privacy at the
>>>>>>>> expense of being a bit more expensive.
>>>>>>>>
>>>>>>>> Other operations could be added to allow a trustless mixing to be
>>>>>>>> done by miners automatically where groups of accounts with similar values
>>>>>>>> are trustlessly  split into a common denominator and change, and keys are
>>>>>>>> derived via a verifiable stealth address like protocol (so fee balances can
>>>>>>>> be discovered by tracing the updates posted). These updates could also be
>>>>>>>> produced by individuals rather than miners, and miners could simply honor
>>>>>>>> them with better privacy. While a miner generating an update would be able
>>>>>>>> to deanonymize their mixes, if you have your account mixed several times by
>>>>>>>> independent miners that could potentially add sufficient privacy.
>>>>>>>>
>>>>>>>> The LN can also be used with PTLCs to, in theory, have another
>>>>>>>> individual paid to sponsor a transaction on your behalf only if they reveal
>>>>>>>> a valid sig from their fee paying account, although under this model it's
>>>>>>>> hard to ensure that the owner doesn't pay a fee and then 'cancel' by
>>>>>>>> withdrawing the rest. However, this could be partly solved by using
>>>>>>>> reputable fee accounts (reputation could be measured somewhat
>>>>>>>> decentralized-ly by longevity of the account and transactions paid for
>>>>>>>> historically).
>>>>>>>>
>>>>>>>> *Scalability*
>>>>>>>>
>>>>>>>> This design is fundamentally 'decent' for scalability because
>>>>>>>> adding fees to a transaction does not require adding inputs or outputs and
>>>>>>>> does not require tracking substantial amounts of new state.
>>>>>>>>
>>>>>>>> Paying someone else to pay for you via the LN also helps make this
>>>>>>>> more efficient if the withdrawal issues can be fixed.
>>>>>>>>
>>>>>>>> *Lightning:*
>>>>>>>>
>>>>>>>> This type of design works really well for channels because the
>>>>>>>> addition of fees to e.g. a channel state does not require any sort of
>>>>>>>> pre-planning (e.g. anchors) or transaction flexibility (SIGHASH flags).
>>>>>>>> This sort of design is naturally immune to pinning issues since you could
>>>>>>>> offer to pay a fee for any TXID and the number of fee adding offers does
>>>>>>>> not need to be restricted in the same way the descendant transactions would
>>>>>>>> need to be.
>>>>>>>>
>>>>>>>> *Without a fork?*
>>>>>>>>
>>>>>>>> This type of design could be done as a federated network that
>>>>>>>> bribes miners -- potentially even retroactively after a block is formed.
>>>>>>>> That might be sufficient to prove the concept works before a consensus
>>>>>>>> upgrade is deployed, but such an approach does mean there is a centralizing
>>>>>>>> layer interfering with normal mining.
>>>>>>>>
>>>>>>>>
>>>>>>>> Happy new year!!
>>>>>>>>
>>>>>>>> Jeremy
>>>>>>>>
>>>>>>>> --
>>>>>>>> @JeremyRubin <https://twitter.com/JeremyRubin>
>>>>>>>> <https://twitter.com/JeremyRubin>
>>>>>>>> _______________________________________________
>>>>>>>> bitcoin-dev mailing list
>>>>>>>> bitcoin-dev at lists.linuxfoundation.org
>>>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>>>>>>
>>>>>>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220119/3457bd53/attachment-0001.html>

From billy.tetrud at gmail.com  Thu Jan 20 05:23:12 2022
From: billy.tetrud at gmail.com (Billy Tetrud)
Date: Wed, 19 Jan 2022 23:23:12 -0600
Subject: [bitcoin-dev] [Pre-BIP] Fee Accounts
In-Reply-To: <CAD5xwhgtpQNZbk1VfWs+P51FOYR4ibgucVBWVt_Z++vLwN7Fdw@mail.gmail.com>
References: <CAD5xwhik6jVQpP2_ss7d5o+pPLsqDCHuaXG41AMKHVYhZMXF1w@mail.gmail.com>
 <CAGpPWDb6HckAhX6p-=cK3fQXyMqivd+xFtiYJ7hKR2k-MWqKJA@mail.gmail.com>
 <CAD5xwhhuvHL2_-ZY1ygZ6WahRi9eg9rk2eHDUODNoJCQX6wL+A@mail.gmail.com>
 <CAGpPWDaQAxEfyFs_g9p=PTUNAkSiQKwPiHJbBaLmzfNTjFeucA@mail.gmail.com>
 <CAD5xwhjUkey+VD=u+69+5eirLCCoLgDgAR_4d20hwHo-eyZr6w@mail.gmail.com>
 <CAGpPWDYxCGkpbiiHFgFrY3=oCwRBY7c_vLQfQg3a_Dwx7pEUTA@mail.gmail.com>
 <CAD5xwhhbXZPg+rQjdaygv_6ZsNuuVpibu=LTZBNU4g_naBOWyw@mail.gmail.com>
 <CAGpPWDbPptac9UPM45_eWnmgDgeoyc=KxuQs1x7_vk37uarsLA@mail.gmail.com>
 <CAD5xwhgtpQNZbk1VfWs+P51FOYR4ibgucVBWVt_Z++vLwN7Fdw@mail.gmail.com>
Message-ID: <CAGpPWDZW=HRA5TPQsO=miSZpXB7kRf80B_xmhZmqVS=0tf76+Q@mail.gmail.com>

Thanks for the info.

> you could "sponsor yourself" directly or through a cycle involving > 1
txn.

Ah I see, because the sighash flags aren't used to create the TXID. I don't
really see the problem with cycles tho. Could a cycle cause problems for
anyone? Seems like it would be a harmless waste of bytes. The
fee-sponsoring OP_VER looks good too tho.

On Wed, Jan 19, 2022 at 2:08 PM Jeremy <jlrubin at mit.edu> wrote:

> SIGHASH_BUNDLE
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-April/015862.html
>
> By cycles I meant that if you commit to the sponsors by TXID from the
> witness, you could "sponsor yourself" directly or through a cycle involving
> > 1 txn.
>
> With OP_VER I was talking about the proposal I linked here
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-September/018168.html
> which used OP_VER to indicate a txn sponsoring txn. Because the OP_VER is
> in the output space, and uses TXIDs, it is cycle-free.
>
>
> --
> @JeremyRubin <https://twitter.com/JeremyRubin>
> <https://twitter.com/JeremyRubin>
>
>
> On Wed, Jan 19, 2022 at 8:52 AM Billy Tetrud <billy.tetrud at gmail.com>
> wrote:
>
>> Hmm, I don't know anything about  SIGHASH_BUNDLE. The only references
>> online I can find are just mentions (mostly from you). What is
>> SIGHASH_BUNDLE?
>>
>> > unless you're binding a WTXID
>>
>> That could work, but it would exclude cases where you have a transaction
>> that has already been partially signed and someone wants to, say, only sign
>> that transaction if some 3rd party signs a transaction paying part of the
>> fee for it. Kind of a niche use case, but it would be nice to support it if
>> possible. If the transaction hasn't been signed at all yet, a new
>> transaction can just be created that includes the prospective fee-payer,
>> and if the transaction is fully signed then it has a WTXID to use.
>>
>> > then you can have fee bumping cycles
>>
>> What kind of cycles do you mean? You're saying these cycles would make it
>> less robust to reorgs?
>>
>> > OP_VER
>>
>> I assume you mean something other than pushing the version onto the stack
>> <https://bitcoin.stackexchange.com/questions/97258/given-op-ver-was-never-used-is-disabled-and-not-considered-useful-can-its-meani>?
>> Is that related to your fee account idea?
>>
>>
>> On Wed, Jan 19, 2022 at 1:32 AM Jeremy <jlrubin at mit.edu> wrote:
>>
>>> Ah my bad i misread what you were saying as being about SIGHASH_BUNDLE
>>> like proposals.
>>>
>>> For what you're discussing, I previously proposed
>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-September/018168.html
>>> which is similar.
>>>
>>> The benefit of the OP_VER output is that SIGHASH_EXTERNAL has the issue
>>> that unless you're binding a WTXID (which is maybe too specific?) then you
>>> can have fee bumping cycles. Doing OP_VER output w/ TXID guarantees that
>>> you are acyclic.
>>>
>>> The difference between a fee account and this approach basically boils
>>> down to the impact on e.g. reorg stability, where the deposit/withdraw
>>> mechanism is a bit more "robust" for reorderings in reorgs than the in-band
>>> transaction approach, although they are very similar.
>>>
>>> --
>>> @JeremyRubin <https://twitter.com/JeremyRubin>
>>> <https://twitter.com/JeremyRubin>
>>>
>>>
>>> On Tue, Jan 18, 2022 at 8:53 PM Billy Tetrud <billy.tetrud at gmail.com>
>>> wrote:
>>>
>>>> >  because you make transactions third party malleable it becomes
>>>> possible to bundle and unbundle transactions.
>>>>
>>>> What I was suggesting doesn't make it possible to malleate someone
>>>> else's transaction. I guess maybe my proposal of using a sighash flag
>>>> might have been unclear. Imagine it as a script opcode that just says "this
>>>> transaction must be mined with this other transaction" - the only
>>>> difference being that you can use any output with any encumberance as an
>>>> input for fee bumping. It doesn't prevent the original transaction from
>>>> being mined on its own. So adding junk inputs would be no more of a problem
>>>> than dust attacks already are. It would be used exactly like cpfp, except
>>>> it doesn't spend the parent.
>>>>
>>>> I don't think what I was suggesting is as different from your proposal.
>>>> All the problems of fee revenue optimization and feerate rules that you
>>>> mentioned seem like they'd also exist for your proposal, or for cpfp. Let
>>>> me know if I should clarify further.
>>>>
>>>> On Tue, Jan 18, 2022 at 8:51 PM Jeremy <jlrubin at mit.edu> wrote:
>>>>
>>>>> The issue with sighash flags is that because you make transactions
>>>>> third party malleable it becomes possible to bundle and unbundle
>>>>> transactions.
>>>>>
>>>>> This means there are circumstances where an attacker could e.g. see
>>>>> your txn, and then add a lot of junk change/inputs + 25 descendants and
>>>>> strongly anchor your transaction to the bottom of the mempool.
>>>>>
>>>>> because of rbf rules requiring more fee and feerate, this means you
>>>>> have to bump across the whole package and that can get really messy.
>>>>>
>>>>> more generally speaking, you could imagine a future where mempools
>>>>> track many alternative things that might want to be in a transaction.
>>>>>
>>>>> suppose there are N inputs each with a weight and an amount of fee
>>>>> being added and the sighash flags let me pick any subset of them. However,
>>>>> for a txn to be standard it must be < 100k bytes and for it to be consensus
>>>>> < 1mb. Now it is possible you have to solve a knapsack problem in order to
>>>>> rationally bundle this transaction out of all possibilities.
>>>>>
>>>>> This problem can get even thornier, suppose that the inputs I'm adding
>>>>> themselves are the outputs of another txn in the mempool, now i have to
>>>>> track and propagate the feerates of that child back up to the parent txn
>>>>> and track all these dependencies.
>>>>>
>>>>> perhaps with very careful engineering these issues can be tamed.
>>>>> however it seems with sponsors or fee accounts, by separating the pays-for
>>>>> from the participates-in concerns we can greatly simplify it to something
>>>>> like: compute effective feerate for a txn, including all sponsors that pay
>>>>> more than the feerate of the base txn. Mine that txn and it's subsidies
>>>>> using the normal algo. If you run out of space, all subsidies are
>>>>> same-sized so just take the ones that pay the highest amount up until the
>>>>> added marginal feerate is less than the next eligible txn.
>>>>>
>>>>>
>>>>> --
>>>>> @JeremyRubin <https://twitter.com/JeremyRubin>
>>>>> <https://twitter.com/JeremyRubin>
>>>>>
>>>>>
>>>>> On Tue, Jan 18, 2022 at 6:38 PM Billy Tetrud <billy.tetrud at gmail.com>
>>>>> wrote:
>>>>>
>>>>>> I see, its not primarily to make it cheaper to append fees, but also
>>>>>> allows appending fees in cases that aren't possible now. Is that right? I
>>>>>> can certainly see the benefit of a more general way to add a fee to any
>>>>>> transaction, regardless of whether you're related to that transaction or
>>>>>> not.
>>>>>>
>>>>>> How would you compare the pros and cons of your account-based
>>>>>> approach to something like a new sighash flag? Eg a sighash flag that says
>>>>>> "I'm signing this transaction, but the signature is only valid if mined in
>>>>>> the same block as transaction X (or maybe transactions LIST)". This could
>>>>>> be named SIGHASH_EXTERNAL. Doing this would be a lot more similar to other
>>>>>> bitcoin transactions, and no special account would need to be created. Any
>>>>>> transaction could specify this. At least that's the first thought I would
>>>>>> have in designing a way to arbitrarily bump fees. Have you compared your
>>>>>> solution to something more familiar like that?
>>>>>>
>>>>>> On Tue, Jan 18, 2022 at 11:43 AM Jeremy <jlrubin at mit.edu> wrote:
>>>>>>
>>>>>>> Can you clarify what you mean by "improve the situation"?
>>>>>>>
>>>>>>> There's a potential mild bytes savings, but the bigger deal is that
>>>>>>> the API should be much less vulnerable to pinning issues, fix dust leakage
>>>>>>> for eltoo like protocols, and just generally allow protocol designs to be
>>>>>>> fully abstracted from paying fees. You can't easily mathematically
>>>>>>> quantify API improvements like that.
>>>>>>> --
>>>>>>> @JeremyRubin <https://twitter.com/JeremyRubin>
>>>>>>> <https://twitter.com/JeremyRubin>
>>>>>>>
>>>>>>>
>>>>>>> On Tue, Jan 18, 2022 at 8:13 AM Billy Tetrud <billy.tetrud at gmail.com>
>>>>>>> wrote:
>>>>>>>
>>>>>>>> Do you have any back-of-the-napkin math on quantifying how much
>>>>>>>> this would improve the situation vs existing methods (eg cpfp)?
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> On Sat, Jan 1, 2022 at 2:04 PM Jeremy via bitcoin-dev <
>>>>>>>> bitcoin-dev at lists.linuxfoundation.org> wrote:
>>>>>>>>
>>>>>>>>> Happy new years devs,
>>>>>>>>>
>>>>>>>>> I figured I would share some thoughts for conceptual review that
>>>>>>>>> have been bouncing around my head as an opportunity to clean up the fee
>>>>>>>>> paying semantics in bitcoin "for good". The design space is very wide on
>>>>>>>>> the approach I'll share, so below is just a sketch of how it could work
>>>>>>>>> which I'm sure could be improved greatly.
>>>>>>>>>
>>>>>>>>> Transaction fees are an integral part of bitcoin.
>>>>>>>>>
>>>>>>>>> However, due to quirks of Bitcoin's transaction design, fees are a
>>>>>>>>> part of the transactions that they occur in.
>>>>>>>>>
>>>>>>>>> While this works in a "Bitcoin 1.0" world, where all transactions
>>>>>>>>> are simple on-chain transfers, real world use of Bitcoin requires support
>>>>>>>>> for things like Fee Bumping stuck transactions, DoS resistant Payment
>>>>>>>>> Channels, and other long lived Smart Contracts that can't predict future
>>>>>>>>> fee rates. Having the fees paid in band makes writing these contracts much
>>>>>>>>> more difficult as you can't merely express the logic you want for the
>>>>>>>>> transaction, but also the fees.
>>>>>>>>>
>>>>>>>>> Previously, I proposed a special type of transaction called a
>>>>>>>>> "Sponsor" which has some special consensus + mempool rules to allow
>>>>>>>>> arbitrarily appending fees to a transaction to bump it up in the mempool.
>>>>>>>>>
>>>>>>>>> As an alternative, we could establish an account system in Bitcoin
>>>>>>>>> as an "extension block".
>>>>>>>>>
>>>>>>>>> *Here's how it might work:*
>>>>>>>>>
>>>>>>>>> 1. Define a special anyone can spend output type that is a "fee
>>>>>>>>> account" (e.g. segwit V2). Such outputs have a redeeming key and an amount
>>>>>>>>> associated with them, but are overall anyone can spend.
>>>>>>>>> 2. All deposits to these outputs get stored in a separate UTXO
>>>>>>>>> database for fee accounts
>>>>>>>>> 3. Fee accounts can sign only two kinds of transaction: A: a fee
>>>>>>>>> amount and a TXID (or Outpoint?); B: a withdraw amount, a fee, and
>>>>>>>>> an address
>>>>>>>>> 4. These transactions are committed in an extension block merkle
>>>>>>>>> tree. While the actual signature must cover the TXID/Outpoint, the
>>>>>>>>> committed data need only cover the index in the block of the transaction.
>>>>>>>>> The public key for account lookup can be recovered from the message +
>>>>>>>>> signature.
>>>>>>>>> 5. In any block, any of the fee account deposits can be: released
>>>>>>>>> into fees if there is a corresponding tx; consolidated together to reduce
>>>>>>>>> the number of utxos (this can be just an OP_TRUE no metadata needed); or
>>>>>>>>> released into fees *and paid back* into the requested withdrawal key
>>>>>>>>> (encumbering a 100 block timeout). Signatures must be unique in a block.
>>>>>>>>> 6. Mempool logic is updated to allow attaching of account fee
>>>>>>>>> spends to transactions, the mempool can restrict that an account is not
>>>>>>>>> allowed more spend more than it's balance.
>>>>>>>>>
>>>>>>>>> *But aren't accounts "bad"?*
>>>>>>>>>
>>>>>>>>> Yes, accounts are bad. But these accounts are not bad, because any
>>>>>>>>> funds withdrawn from the fee extension are fundamentally locked for 100
>>>>>>>>> blocks as a coinbase output, so there should be no issues with any series
>>>>>>>>> of reorgs. Further, since there is no "rich state" for these accounts, the
>>>>>>>>> state updates can always be applied in a conflict-free way in any order.
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> *Improving the privacy of this design:*
>>>>>>>>>
>>>>>>>>> This design could likely be modified to implement something like
>>>>>>>>> Tornado.cash or something else so that the fee account paying can be
>>>>>>>>> unlinked from the transaction being paid for, improving privacy at the
>>>>>>>>> expense of being a bit more expensive.
>>>>>>>>>
>>>>>>>>> Other operations could be added to allow a trustless mixing to be
>>>>>>>>> done by miners automatically where groups of accounts with similar values
>>>>>>>>> are trustlessly  split into a common denominator and change, and keys are
>>>>>>>>> derived via a verifiable stealth address like protocol (so fee balances can
>>>>>>>>> be discovered by tracing the updates posted). These updates could also be
>>>>>>>>> produced by individuals rather than miners, and miners could simply honor
>>>>>>>>> them with better privacy. While a miner generating an update would be able
>>>>>>>>> to deanonymize their mixes, if you have your account mixed several times by
>>>>>>>>> independent miners that could potentially add sufficient privacy.
>>>>>>>>>
>>>>>>>>> The LN can also be used with PTLCs to, in theory, have another
>>>>>>>>> individual paid to sponsor a transaction on your behalf only if they reveal
>>>>>>>>> a valid sig from their fee paying account, although under this model it's
>>>>>>>>> hard to ensure that the owner doesn't pay a fee and then 'cancel' by
>>>>>>>>> withdrawing the rest. However, this could be partly solved by using
>>>>>>>>> reputable fee accounts (reputation could be measured somewhat
>>>>>>>>> decentralized-ly by longevity of the account and transactions paid for
>>>>>>>>> historically).
>>>>>>>>>
>>>>>>>>> *Scalability*
>>>>>>>>>
>>>>>>>>> This design is fundamentally 'decent' for scalability because
>>>>>>>>> adding fees to a transaction does not require adding inputs or outputs and
>>>>>>>>> does not require tracking substantial amounts of new state.
>>>>>>>>>
>>>>>>>>> Paying someone else to pay for you via the LN also helps make this
>>>>>>>>> more efficient if the withdrawal issues can be fixed.
>>>>>>>>>
>>>>>>>>> *Lightning:*
>>>>>>>>>
>>>>>>>>> This type of design works really well for channels because the
>>>>>>>>> addition of fees to e.g. a channel state does not require any sort of
>>>>>>>>> pre-planning (e.g. anchors) or transaction flexibility (SIGHASH flags).
>>>>>>>>> This sort of design is naturally immune to pinning issues since you could
>>>>>>>>> offer to pay a fee for any TXID and the number of fee adding offers does
>>>>>>>>> not need to be restricted in the same way the descendant transactions would
>>>>>>>>> need to be.
>>>>>>>>>
>>>>>>>>> *Without a fork?*
>>>>>>>>>
>>>>>>>>> This type of design could be done as a federated network that
>>>>>>>>> bribes miners -- potentially even retroactively after a block is formed.
>>>>>>>>> That might be sufficient to prove the concept works before a consensus
>>>>>>>>> upgrade is deployed, but such an approach does mean there is a centralizing
>>>>>>>>> layer interfering with normal mining.
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> Happy new year!!
>>>>>>>>>
>>>>>>>>> Jeremy
>>>>>>>>>
>>>>>>>>> --
>>>>>>>>> @JeremyRubin <https://twitter.com/JeremyRubin>
>>>>>>>>> <https://twitter.com/JeremyRubin>
>>>>>>>>> _______________________________________________
>>>>>>>>> bitcoin-dev mailing list
>>>>>>>>> bitcoin-dev at lists.linuxfoundation.org
>>>>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>>>>>>>
>>>>>>>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220119/1724e2e9/attachment-0001.html>

From michaelfolkson at protonmail.com  Thu Jan 20 12:58:24 2022
From: michaelfolkson at protonmail.com (Michael Folkson)
Date: Thu, 20 Jan 2022 12:58:24 +0000
Subject: [bitcoin-dev] Highlighting Taproot implementation gotchas
Message-ID: <bXRFHm8T6pJCTcztUF0MpmTpm_dsneur1m8qS3qqFCD2Po1DynQz47tvOsFVvwAv5oPYk3wBGJaCqMh098LYnekk5wEG_3gvDGyLzDuYR-Y=@protonmail.com>

Hi

I'd just like to bring some attention to this blog post from the Suredbits team who when implementing Taproot in bitcoin-s found a mainnet output that did not conform to the BIP 340 specification [0] (invalid x coordinate) and hence were burned.

https://suredbits.com/taproot-funds-burned-on-the-bitcoin-blockchain/

To be clear this is was an error made by an unknown developer rather than a bug in the Taproot BIPs or Core implementation.

I'd certainly encourage the community to share with this list mistakes they make or things they find confusing (i.e. stump them for long periods of time) when re-implementing Taproot or supporting Taproot in wallets. I suspect things like eliminating the key path [1] or eliminating the script path [2] will end up being common sources of confusion for wallets.

I'm also open to ideas on how there can be greater information sharing so Taproot implementers don't end up making the same mistakes or spending hours confused over the same things.

I've heard some feedback on a number of occasions now that the Taproot BIPs although thorough and exhaustive aren't geared directly towards implementers and adopters. We discussed this at an online Socratic last year [3] with Craig Raw an early Taproot adopter with Sparrow Wallet. The transcript of that links to a bunch of existing resources (StackExchange posts, the Optech series "Preparing for Taproot", Optech workshop etc) that may be useful for implementers.

wumpus also suggested that a new informational BIP might be a good idea as a first port of call for Taproot implementers who find BIP 340-342 dense and difficult to parse. This is certainly something we can do once it becomes clearer what that informational BIP should contain.

Of course the Libera IRC channels #bitcoin-dev (for general Bitcoin development) and #bitcoin-core-dev (for Core related development) are there for discussion and questions. And as many will already know Murch is tracking P2TR support on the Bitcoin wiki [4].

Thanks
Michael

[0]: https://github.com/bitcoin/bips/blob/master/bip-0340.mediawiki#design
[1]: https://bitcoin.stackexchange.com/questions/99722/taproot-eliminating-key-path
[2]: https://bitcoin.stackexchange.com/questions/99325/how-do-i-construct-a-p2tr-address-if-i-just-want-to-use-the-key-path
[3]: https://btctranscripts.com/london-bitcoin-devs/2021-07-20-socratic-seminar-taproot-rollout/
[4]: https://en.bitcoin.it/wiki/Bech32_adoption

-- Michael Folkson Email: michaelfolkson at [protonmail.com](http://protonmail.com/)
Keybase: michaelfolkson PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220120/3e6a6d5a/attachment.html>

From billy.tetrud at gmail.com  Thu Jan 20 15:23:09 2022
From: billy.tetrud at gmail.com (Billy Tetrud)
Date: Thu, 20 Jan 2022 09:23:09 -0600
Subject: [bitcoin-dev] CTV BIP review
In-Reply-To: <up51VtT2s-vcSvah3qiIm8G3KHjcnE5AwZLpTpe_CwRUgrWNJC8BvKFK0vHtYqzh1kTFtVVVLE0lXqBBBVhRR2Rkm3uFbp-Xmqs0KZ4gTUo=@protonmail.com>
References: <202201182119.02687.luke@dashjr.org>
 <02cc01d80cb7$1339c050$39ad40f0$@voskuil.org>
 <202201182209.46044.luke@dashjr.org>
 <000601d80cbf$2f6a1d80$8e3e5880$@voskuil.org>
 <up51VtT2s-vcSvah3qiIm8G3KHjcnE5AwZLpTpe_CwRUgrWNJC8BvKFK0vHtYqzh1kTFtVVVLE0lXqBBBVhRR2Rkm3uFbp-Xmqs0KZ4gTUo=@protonmail.com>
Message-ID: <CAGpPWDZiNiBoq9KNh8TsZC8fQTNsP5iVZnX2NHwN9x7dSPZmFQ@mail.gmail.com>

I'm curious to hear clarification on most of Luke's non-activation related
comments.

> I would ideally like to see fully implemented BIPs for at least one of
these

While that would be interesting, I think that's a heavy burden to be placed
on this BIP. More in depth exploration would be helpful, but a fully
implemented BIP I think is more than necessary.

> Why is it a problem for them to use an Eltoo-like protocol?

I think he was saying it is a problem *unless* its an eltoo-like protocol.
Why I'm not sure. Maybe you can clarify Jeremy?

> It's not clear to me that this holds if OP_CAT or OP_SHA256STREAM get
added.

Even were these opcodes to be implemented in bitcoin, a script writer could
choose to not use them, making it still possible to use CTV to create
covenant chains with a finite number of steps.

>  w.r.t. the language cleanups... the legal definition of covenant ... I
do think things like CLTV/CSV are covenants

Maybe it would be useful to specify that these are "child covenants" or
"inherited covenants" or something like that, since unlike things like
CLTV, CTV and similar proposed opcodes place restrictions on the child
output of the output containing the opcode call, which is the interesting
unique behavior. Tho I don't think we need to be bound to the legal or
dictionary definition in usage of the word covenant in the realm of bitcoin
- its gonna have its own definition in this context anyway.

Thank you Eric for pointing out the factual errors in LukeJr's mention and
implications around BIP8. The fact is that the ST pull request was
described as "BIP9-based" <https://github.com/bitcoin/bitcoin/pull/21377>.
TBH BIP8 is also BIP9 based, and ST is its own thing that's neither BIP8
nor BIP9, so characterization one way or another is moot IMO. In any case,
I also agree with Michael that this isn't the place to have a long
discussion about activation method. That discussion should be kept
separate. I'd go so far to say that BIPs should not advocate for any
particular activation method, but should only go so far as to mention what
types of activation methods are possible (if some types aren't possible for
some reason). Separation of concerns would be very useful on that front
to reduce noise in conversations.

Thanks,
BT


On Wed, Jan 19, 2022 at 6:37 AM Michael Folkson via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Eric, Luke
>
> Can I request that you don't discuss activation methods for future soft
> forks on a thread for CTV BIP review? I (and a number of others [0]) do not
> support an upcoming activation attempt of standalone OP_CTV. If you want to
> discuss activation methods for soft forks generally it would be much better
> if you set up a separate thread. OP_CTV is not the only current soft fork
> proposal and there will likely be more.
>
> The activation discussion for Taproot was deliberately kept separate from
> the review of the Taproot BIPs and implementation. It only commenced once
> there was overwhelming community consensus for the soft fork to be
> activated (months after in fact). Though you are free to discuss whatever
> topics you wish (obviously) discussing soft fork activation methods on a
> OP_CTV thread might give the mistaken impression that OP_CTV is the next
> soft fork to be activated which is mere speculation at this point. In an
> ideal world the promoters of OP_CTV would follow the strong precedent set
> by the authors and contributors to the Taproot BIPs but regrettably that
> seems to have gone out the window at this point.
>
> Thanks
> Michael
>
> [0]:
> https://gist.github.com/michaelfolkson/352a503f4f9fc5de89af528d86a1b718
> --
> Michael Folkson
> Email: michaelfolkson at protonmail.com
> Keybase: michaelfolkson
> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3
>
> ??????? Original Message ???????
>
> On Tuesday, January 18th, 2022 at 11:00 PM, Eric Voskuil via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
> > -----Original Message-----
> >
> > From: Luke Dashjr luke at dashjr.org
> >
> > Sent: Tuesday, January 18, 2022 2:10 PM
> >
> > To: eric at voskuil.org
> >
> > Cc: 'Bitcoin Protocol Discussion' bitcoin-dev at lists.linuxfoundation.org
> >
> > Subject: Re: [bitcoin-dev] CTV BIP review
> >
> > On Tuesday 18 January 2022 22:02:24 eric at voskuil.org wrote:
> >
> > > The only material distinction between BIP9 and BIP8 is that the latter
> > >
> > > may activate without signaled support of hash power enforcement.
> > >
> > > As unenforced soft forks are not "backward compatible" they produce a
> > >
> > > chain split.
> >
> > Enforcement of the Bitcoin consensus protocol is by users, not miners.
>
> Given that I stated "hash power enforcement" it is quite clear that this is
>
> in fact only produced by mining. You are misrepresenting my statement to
>
> make an emotional appeal. Without "hash power enforcement", a soft fork is
>
> NOT backward compatible.
>
> "[enforcement of] consensus protocol" is of course by merchants, but that
> is
>
> not the question at hand. The question is explicitly compatibility. Anyone
>
> can activate a soft fork at any time, but without "hash power enforcement"
>
> soft forks are NOT backward compatible.
>
> > Softforks never produce a chain split. Miners can, and might try to do it
>
> to cause disruption in retaliation, but the softfork itself does not.
>
> Maybe you are trying to split hairs given the fact that blocks are produced
>
> only by miners, so only miners can "cause" a split.
>
> But through not intention ("disruption in retaliation") whatsoever by
>
> mining, a soft fork will result in those activating the rule being split
> off
>
> the original chain unless majority hash power enforces the rule. The fact
>
> that doing nothing apart from deploying the rule will result in a split is
>
> the very definition of NOT compatible.
>
> I assume you will argue that the original chain is not "valid" and
> therefore
>
> irrelevant (as if no chain split occurred). But again the point is about
>
> compatibility. The appearance of multiple chains, which appear valid
>
> according to either the previous or new rules, is obviously the
>
> incompatibility.
>
> I shouldn't have to point this out, but observed chain splits have occurred
>
> in more the one large scale soft fork deployment. These splits have only
>
> been resolved through hash power enforcement. In 2010 it took 51 blocks
>
> before the current chain took the lead. In 2012 minority chains persisted
>
> for months. The deployment of soft forks caused these splits, NOT the
>
> actions of miners. And unless majority hash power eventually enforces it,
>
> the soft fork branch necessarily dies.
>
> > > It was for this reason alone that BIP8 never gained sufficient
> > >
> > > support.
> >
> > BIP 8 in fact achieved consensus for Taproot activation.
>
> Please define "achieved consensus", because by any definition I can
> imagine,
>
> this is simply untrue.
>
> > > This is one of the most misleading statements I've seen here. It's not
> > >
> > > technically a lie, because it states what "should" happen. But it is
> > >
> > > clearly intended to lead people to believe that BIP8 was actually used
> > >
> > > ("again") - it was not. ST was some technical tweaks to BIP9.
> >
> > BIP 8 was used to activate Taproot.
>
> No, it wasn't. I find it hard to imaging how you rationalize such grossly
>
> misleading statements.
>
> > > The outright deception around this one topic has led to significant
> > >
> > > unnecessary conflict in the community. Make your argument, but make it
> > >
> > > honestly.
> >
> > You are the one attempting to deceive here.
>
> That is for others to decide. I appreciate your responses above, since they
>
> certainly help clarify what is happening here.
>
> e
>
> bitcoin-dev mailing list
>
> bitcoin-dev at lists.linuxfoundation.org
>
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220120/0a497b07/attachment-0001.html>

From aj at erisian.com.au  Thu Jan 20 18:38:22 2022
From: aj at erisian.com.au (Anthony Towns)
Date: Fri, 21 Jan 2022 04:38:22 +1000
Subject: [bitcoin-dev] CTV BIP review
In-Reply-To: <CAD5xwhh3d1=KXEJOPVuYm3UqNKovrojqJS-c6r6ficsKf6S_7g@mail.gmail.com>
References: <202201182119.02687.luke@dashjr.org>
 <CAD5xwhh3d1=KXEJOPVuYm3UqNKovrojqJS-c6r6ficsKf6S_7g@mail.gmail.com>
Message-ID: <20220120183822.GA1237@erisian.com.au>

On Tue, Jan 18, 2022 at 03:54:21PM -0800, Jeremy via bitcoin-dev wrote:
> Some of it's kind of annoying because
> the legal definition of covenant is [...]
> so I do think things like CLTV/CSV are covenants

I think that in the context of Bitcoin, the most useful definition of
covenant is that it's when the scriptPubKey of a utxo restricts the
scriptPubKey in the output(s) of a tx spending that utxo.

CTV, TLUV, etc do that; CSV, CLTV don't. ("checksig" per se doesn't
either, though of course the signature that checksig uses does -- if that
signature is in the scriptPubKey rather than the scriptSig or witness,
that potentially becomes a covenant too)

Cheers,
aj


From bram at chia.net  Thu Jan 20 19:23:30 2022
From: bram at chia.net (Bram Cohen)
Date: Thu, 20 Jan 2022 11:23:30 -0800
Subject: [bitcoin-dev] Covenants and capabilities in the UTXO model
In-Reply-To: <CAGpPWDabAbY3nS-1QATrzLj+O4dxfs4Fo0EuYFftNdjw_gwRPw@mail.gmail.com>
References: <CAHUJnBBFsS597ZRdAtwONMAz1r7gQbrXULzdNtEVxOPENx+tDg@mail.gmail.com>
 <CAGpPWDYvvtCJLsr1SqghugfntnmnKw+GOtufp07d8sN-5vKa0w@mail.gmail.com>
 <CAHUJnBAfnmfs2nY3HFRhzNL6ztpZT3dgqe5wCxuO3qpk0OsgRg@mail.gmail.com>
 <CAGpPWDabAbY3nS-1QATrzLj+O4dxfs4Fo0EuYFftNdjw_gwRPw@mail.gmail.com>
Message-ID: <CAHUJnBAFV6qFDjYkO_ByfDOp1rwz4S1xQc9hSJj5Jpsb7DdVwQ@mail.gmail.com>

On Tue, Jan 18, 2022 at 6:25 PM Billy Tetrud <billy.tetrud at gmail.com> wrote:

> > 'assert that my parent has a scriptpubkey of X'... That way you can, for
> example, have a UTXO which only allows itself to be absorbed by a
> transaction also involving a UTXO with a particular capability
>
> I'm not sure I fully follow. I usually think about covenants as having the
> reverse form, that a parent would assert "my children must have a script of
> the form XYZ". Are you saying you want to be able to specify that a UTXO
> can only be spent if the resulting outputs of that transaction all share
> the same script? I see this page
> <https://chialisp.com/docs/puzzles/singletons/> but i don't understand
> how those concepts relate to covenants.
>

Two concepts here. First of all Bitcoin doesn't have a strong single
concept of a 'parent', it just has transactions where all the parents lead
to all the children. For this sort of trickery to work more information
needs to be added to specify which of the inputs is the parent of each of
the outputs.

Second what in practice happens is that a coin can check what its own id
is, then verify the secure hash chain from its parent to itself so that it
knows what the parent looked like. For a Singleton it can then rely on the
fact that its ancestors enforced that they each only had one child to know
that it's the only descendant. In some sense this is like covenants which
point backwards in time although that information is already there in
principle because of the secure hash chain but hard to parse.


>
> >  allow references to old blocks so code snippets can be pulled out of
> them
>
> Nodes currently aren't required to keep around the whole blockchain, but
> your proposal sounds like it would require them to. I think this could be
> pretty detrimental to future scalability. Monero, for example, has a
> situation where its UTXO set is the whole blockchain because you can't
> generally know what has been spent and what hasn't been. Allowing
> references to old blocks would pull in all this old block data into the
> UTXO set. So unless you're very careful about how or when you can reference
> old blocks, this could cause issues.
>

Don't full nodes by definition have to have the whole chain? This does make
pruned nodes difficult, but it could also have rules like you can only
point back so far.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220120/a3cb9768/attachment.html>

From eric at voskuil.org  Thu Jan 20 22:03:14 2022
From: eric at voskuil.org (eric at voskuil.org)
Date: Thu, 20 Jan 2022 14:03:14 -0800
Subject: [bitcoin-dev] CTV BIP review
In-Reply-To: <CAGpPWDZiNiBoq9KNh8TsZC8fQTNsP5iVZnX2NHwN9x7dSPZmFQ@mail.gmail.com>
References: <202201182119.02687.luke@dashjr.org>
 <02cc01d80cb7$1339c050$39ad40f0$@voskuil.org>
 <202201182209.46044.luke@dashjr.org>
 <000601d80cbf$2f6a1d80$8e3e5880$@voskuil.org>
 <up51VtT2s-vcSvah3qiIm8G3KHjcnE5AwZLpTpe_CwRUgrWNJC8BvKFK0vHtYqzh1kTFtVVVLE0lXqBBBVhRR2Rkm3uFbp-Xmqs0KZ4gTUo=@protonmail.com>
 <CAGpPWDZiNiBoq9KNh8TsZC8fQTNsP5iVZnX2NHwN9x7dSPZmFQ@mail.gmail.com>
Message-ID: <017401d80e49$864fd550$92ef7ff0$@voskuil.org>

> BIP8 is also BIP9 based, and ST is its own thing that's neither BIP8 nor BIP9, so characterization one way or another is moot IMO.

 

For a selective definition of ?based? you can draw any conclusion you desire. However I was very clear, as was Luke, and the history on this issue is equally clear, that the *only* material distinction (and the one that we are discussing) is activation with or without majority hash power support. BIP9/ST requires this support, BIP8 does not. The characterization is not moot. It is the central issue and always has been. There was no compromise on this question made in Taproot.

 

e

 

From: Billy Tetrud <billy.tetrud at gmail.com> 
Sent: Thursday, January 20, 2022 7:23 AM



Thank you Eric for pointing out the factual errors in LukeJr's mention and implications around BIP8. The fact is that the ST pull request was described as  <https://github.com/bitcoin/bitcoin/pull/21377> "BIP9-based". TBH BIP8 is also BIP9 based, and ST is its own thing that's neither BIP8 nor BIP9, so characterization one way or another is moot IMO. In any case, I also agree with Michael that this isn't the place to have a long discussion about activation method. That discussion should be kept separate. I'd go so far to say that BIPs should not advocate for any particular activation method, but should only go so far as to mention what types of activation methods are possible (if some types aren't possible for some reason). Separation of concerns would be very useful on that front to reduce noise in conversations.

 

Thanks,

BT

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220120/05477ab0/attachment.html>

From pete at petertodd.org  Fri Jan 21 02:22:15 2022
From: pete at petertodd.org (Peter Todd)
Date: Thu, 20 Jan 2022 21:22:15 -0500
Subject: [bitcoin-dev] Covenants and capabilities in the UTXO model
In-Reply-To: <CAHUJnBAFV6qFDjYkO_ByfDOp1rwz4S1xQc9hSJj5Jpsb7DdVwQ@mail.gmail.com>
References: <CAHUJnBBFsS597ZRdAtwONMAz1r7gQbrXULzdNtEVxOPENx+tDg@mail.gmail.com>
 <CAGpPWDYvvtCJLsr1SqghugfntnmnKw+GOtufp07d8sN-5vKa0w@mail.gmail.com>
 <CAHUJnBAfnmfs2nY3HFRhzNL6ztpZT3dgqe5wCxuO3qpk0OsgRg@mail.gmail.com>
 <CAGpPWDabAbY3nS-1QATrzLj+O4dxfs4Fo0EuYFftNdjw_gwRPw@mail.gmail.com>
 <CAHUJnBAFV6qFDjYkO_ByfDOp1rwz4S1xQc9hSJj5Jpsb7DdVwQ@mail.gmail.com>
Message-ID: <YeoY12X1skxA8Lcy@petertodd.org>

On Thu, Jan 20, 2022 at 11:23:30AM -0800, Bram Cohen via bitcoin-dev wrote:
> > Nodes currently aren't required to keep around the whole blockchain, but
> > your proposal sounds like it would require them to. I think this could be
> > pretty detrimental to future scalability. Monero, for example, has a
> > situation where its UTXO set is the whole blockchain because you can't
> > generally know what has been spent and what hasn't been. Allowing
> > references to old blocks would pull in all this old block data into the
> > UTXO set. So unless you're very careful about how or when you can reference
> > old blocks, this could cause issues.
> >
> 
> Don't full nodes by definition have to have the whole chain? This does make
> pruned nodes difficult, but it could also have rules like you can only
> point back so far.

"you can only point back so far" leads to transactions becoming invalid, which
is something we've always strictly avoided because it can result in huge
problems during reorgs with transactions being unable to be included in a new
change. That's exactly why transaction expiry proposals have been shot down
over and over again.

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220120/33980dcf/attachment-0001.sig>

From shymaa.arafat at gmail.com  Fri Jan 21 12:16:35 2022
From: shymaa.arafat at gmail.com (shymaa arafat)
Date: Fri, 21 Jan 2022 14:16:35 +0200
Subject: [bitcoin-dev] Take 2: Removing the Dust Limit
Message-ID: <CAM98U8nLZBagE4L0TuyKkEtk_jqKJ_xDmAixAkLGR8axO86pmg@mail.gmail.com>

Dear Sir,
Regarding your message
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-December/019636.html
Specifically the part
*"Right now, lightning anchor outputs use a 330 sats amount. Each
commitment*
*transaction has two such outputs, and only one of them is spent"*
I was wondering *is there a way to distinguish those 2 dust UTXOs?*
I mean does(or could) the protocol force the user to always spend the first
not any of them at random?
-My point is to distinguish between them when inserted in the UTXO set to
know in advance which will be spent so fast in the next transaction, and
which is gonna stay there for a while?

-If you look at the number of addresses holding ?1$ here (by subtracting
total from >1$), you would find it doesn't change very much with days
https://bitinfocharts.com/top-100-richest-bitcoin-addresses.html
-Meaning not that just official dust value, but values ?1$ are rarely spent
unless one forced to. I always had the idea of storing them separately
(along with non-standard & burned ones at least from public addresses,
these should be separated too as they're not expected be spent ever)
.
So the answer may make a difference,
Thank you
Shymaa M Arafat
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220121/31a9ee74/attachment.html>

From zachgrw at gmail.com  Fri Jan 21 14:36:10 2022
From: zachgrw at gmail.com (Zac Greenwood)
Date: Fri, 21 Jan 2022 15:36:10 +0100
Subject: [bitcoin-dev] Bitcoin Legal Defense Fund
In-Reply-To: <F3DA4333-E4BB-4A3F-B050-AA142465F2C8@squareup.com>
References: <MtHvJYE--J-2@tutanota.de>
 <F3DA4333-E4BB-4A3F-B050-AA142465F2C8@squareup.com>
Message-ID: <CAJ4-pEC5tBpXOe_q+62ehAPNvo3aLNL8LK4TBgPDAH20akOeTg@mail.gmail.com>

The name of the fund should ideally unambiguously clarify its scope, i.e.,
Bitcoin & development. So maybe ?Bitcoin Developers Community LDF?. Or
perhaps ?Bitcoin Technical Community LDF? which nicely abbreviates to
BTCLDF.

Zac


On Thu, 13 Jan 2022 at 19:49, jack via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Hi Prayank,
>
> > On 13 Jan 2022, at 10:13, Prayank <prayank at tutanota.de> wrote:
> > I had few suggestions and feel free to ignore them if they do not make
> sense:
> >
> > 1.Name of this fund could be anything and 'The Bitcoin Legal Defense
> Fund' can be confusing or misleading for newbies. There is nothing official
> in Bitcoin however people believe things written in news articles and some
> of them might consider it as an official bitcoin legal fund.
>
> Excellent point. Will come up with a better name.
>
> Open to ideas and suggestions on all.
>
> jack
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220121/c16855a6/attachment.html>

From billy.tetrud at gmail.com  Fri Jan 21 17:32:27 2022
From: billy.tetrud at gmail.com (Billy Tetrud)
Date: Fri, 21 Jan 2022 11:32:27 -0600
Subject: [bitcoin-dev] Covenants and capabilities in the UTXO model
In-Reply-To: <YeoY12X1skxA8Lcy@petertodd.org>
References: <CAHUJnBBFsS597ZRdAtwONMAz1r7gQbrXULzdNtEVxOPENx+tDg@mail.gmail.com>
 <CAGpPWDYvvtCJLsr1SqghugfntnmnKw+GOtufp07d8sN-5vKa0w@mail.gmail.com>
 <CAHUJnBAfnmfs2nY3HFRhzNL6ztpZT3dgqe5wCxuO3qpk0OsgRg@mail.gmail.com>
 <CAGpPWDabAbY3nS-1QATrzLj+O4dxfs4Fo0EuYFftNdjw_gwRPw@mail.gmail.com>
 <CAHUJnBAFV6qFDjYkO_ByfDOp1rwz4S1xQc9hSJj5Jpsb7DdVwQ@mail.gmail.com>
 <YeoY12X1skxA8Lcy@petertodd.org>
Message-ID: <CAGpPWDYOJFkOdzkoq6XMB0Z9SEEP4nmdmcZDEZckWQL+BzPOZw@mail.gmail.com>

> Bitcoin doesn't have a strong single concept of a 'parent'

I'm using the term "parent" loosely in context here to mean a relationship
where an input has constraints applied to an output (or outputs).

>   verify the secure hash chain from its parent to itself so that it knows
what the parent looked like

I guess I just don't understand why you would want to do it this way. If
you send to an address that has such a reverse-looking script, you could
brick funds that came from the wrong parent. With the reverse mechanism,
the transaction creating the child, you can prevent this from happening by
defining the transaction creating such a child as invalid unless the child
matches the covenant in the parent.

> "you can only point back so far" leads to transactions becoming invalid,
which is something we've always strictly avoided because it can result in
huge problems during reorgs

I'm surprised to hear you say that. I have tried to learn why valid
transactions that can become invalid is seen as such a problem. I've been
unsuccessful in finding much information about this. I tried to document
the full extent of my understanding in my proposal here
<https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/bbv/bip-beforeblockverify.md#reorg-safety>
where
I actually have a quote from you where you said you don't think this is a
valid concern. Did something change your mind? Or did I misinterpret you?
What am I missing from that section I linked to?

On Thu, Jan 20, 2022 at 8:22 PM Peter Todd <pete at petertodd.org> wrote:

> On Thu, Jan 20, 2022 at 11:23:30AM -0800, Bram Cohen via bitcoin-dev wrote:
> > > Nodes currently aren't required to keep around the whole blockchain,
> but
> > > your proposal sounds like it would require them to. I think this could
> be
> > > pretty detrimental to future scalability. Monero, for example, has a
> > > situation where its UTXO set is the whole blockchain because you can't
> > > generally know what has been spent and what hasn't been. Allowing
> > > references to old blocks would pull in all this old block data into the
> > > UTXO set. So unless you're very careful about how or when you can
> reference
> > > old blocks, this could cause issues.
> > >
> >
> > Don't full nodes by definition have to have the whole chain? This does
> make
> > pruned nodes difficult, but it could also have rules like you can only
> > point back so far.
>
> "you can only point back so far" leads to transactions becoming invalid,
> which
> is something we've always strictly avoided because it can result in huge
> problems during reorgs with transactions being unable to be included in a
> new
> change. That's exactly why transaction expiry proposals have been shot down
> over and over again.
>
> --
> https://petertodd.org 'peter'[:-1]@petertodd.org
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220121/cd11d734/attachment-0001.html>

From billy.tetrud at gmail.com  Fri Jan 21 17:36:13 2022
From: billy.tetrud at gmail.com (Billy Tetrud)
Date: Fri, 21 Jan 2022 11:36:13 -0600
Subject: [bitcoin-dev] CTV BIP review
In-Reply-To: <017401d80e49$864fd550$92ef7ff0$@voskuil.org>
References: <202201182119.02687.luke@dashjr.org>
 <02cc01d80cb7$1339c050$39ad40f0$@voskuil.org>
 <202201182209.46044.luke@dashjr.org>
 <000601d80cbf$2f6a1d80$8e3e5880$@voskuil.org>
 <up51VtT2s-vcSvah3qiIm8G3KHjcnE5AwZLpTpe_CwRUgrWNJC8BvKFK0vHtYqzh1kTFtVVVLE0lXqBBBVhRR2Rkm3uFbp-Xmqs0KZ4gTUo=@protonmail.com>
 <CAGpPWDZiNiBoq9KNh8TsZC8fQTNsP5iVZnX2NHwN9x7dSPZmFQ@mail.gmail.com>
 <017401d80e49$864fd550$92ef7ff0$@voskuil.org>
Message-ID: <CAGpPWDa_A=DLW6cgGin0RjeQWOdDyhG8uz+3ZaegYyUFyp-=mw@mail.gmail.com>

>  the **only** material distinction (and the one that we are discussing)
is activation with or without majority hash power support

I agree that characterization specifically is not moot. But its also
orthogonal to the topic of the CTV opcode itself.

On Thu, Jan 20, 2022 at 4:03 PM <eric at voskuil.org> wrote:

> > BIP8 is also BIP9 based, and ST is its own thing that's neither BIP8
> nor BIP9, so characterization one way or another is moot IMO.
>
>
>
> For a selective definition of ?based? you can draw any conclusion you
> desire. However I was very clear, as was Luke, and the history on this
> issue is equally clear, that the **only** material distinction (and the
> one that we are discussing) is activation with or without majority hash
> power support. BIP9/ST requires this support, BIP8 does not. The
> characterization is not moot. It is the central issue and always has been.
> There was no compromise on this question made in Taproot.
>
>
>
> e
>
>
>
> *From:* Billy Tetrud <billy.tetrud at gmail.com>
> *Sent:* Thursday, January 20, 2022 7:23 AM
>
> Thank you Eric for pointing out the factual errors in LukeJr's mention and
> implications around BIP8. The fact is that the ST pull request was
> described as "BIP9-based" <https://github.com/bitcoin/bitcoin/pull/21377>.
> TBH BIP8 is also BIP9 based, and ST is its own thing that's neither BIP8
> nor BIP9, so characterization one way or another is moot IMO. In any case,
> I also agree with Michael that this isn't the place to have a long
> discussion about activation method. That discussion should be kept
> separate. I'd go so far to say that BIPs should not advocate for any
> particular activation method, but should only go so far as to mention what
> types of activation methods are possible (if some types aren't possible for
> some reason). Separation of concerns would be very useful on that front
> to reduce noise in conversations.
>
>
>
> Thanks,
>
> BT
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220121/67f2c1ed/attachment-0001.html>

From bram at chia.net  Sat Jan 22 00:19:07 2022
From: bram at chia.net (Bram Cohen)
Date: Fri, 21 Jan 2022 16:19:07 -0800
Subject: [bitcoin-dev] Covenants and capabilities in the UTXO model
In-Reply-To: <CAGpPWDYOJFkOdzkoq6XMB0Z9SEEP4nmdmcZDEZckWQL+BzPOZw@mail.gmail.com>
References: <CAHUJnBBFsS597ZRdAtwONMAz1r7gQbrXULzdNtEVxOPENx+tDg@mail.gmail.com>
 <CAGpPWDYvvtCJLsr1SqghugfntnmnKw+GOtufp07d8sN-5vKa0w@mail.gmail.com>
 <CAHUJnBAfnmfs2nY3HFRhzNL6ztpZT3dgqe5wCxuO3qpk0OsgRg@mail.gmail.com>
 <CAGpPWDabAbY3nS-1QATrzLj+O4dxfs4Fo0EuYFftNdjw_gwRPw@mail.gmail.com>
 <CAHUJnBAFV6qFDjYkO_ByfDOp1rwz4S1xQc9hSJj5Jpsb7DdVwQ@mail.gmail.com>
 <YeoY12X1skxA8Lcy@petertodd.org>
 <CAGpPWDYOJFkOdzkoq6XMB0Z9SEEP4nmdmcZDEZckWQL+BzPOZw@mail.gmail.com>
Message-ID: <CAHUJnBCy4Jbm+oJjGknCVEGzTqSshjgtf86egVX9D5TPxGDs=w@mail.gmail.com>

On Fri, Jan 21, 2022 at 9:32 AM Billy Tetrud <billy.tetrud at gmail.com> wrote:

> > Bitcoin doesn't have a strong single concept of a 'parent'
>
> I'm using the term "parent" loosely in context here to mean a relationship
> where an input has constraints applied to an output (or outputs).
>

Yes and I'm using it more specifically to mean a single parent because the
tricks for implementing capabilities I'm talking about don't work if you
don't have a way of talking about 'my parent' as an unambiguously defined
single UTXO.


>
> >   verify the secure hash chain from its parent to itself so that it
> knows what the parent looked like
>
> I guess I just don't understand why you would want to do it this way.
>

The idea here is to optimize for adding as little to the UXTO model as
possible and doing everything with Bitcoin script additions. Some optional
mappings of inputs to outputs in a transaction seem to be necessary but
beyond that the current model can remain unchanged.


> If you send to an address that has such a reverse-looking script, you
> could brick funds that came from the wrong parent. With the reverse
> mechanism, the transaction creating the child, you can prevent this from
> happening by defining the transaction creating such a child as invalid
> unless the child matches the covenant in the parent.
>

If you want to pay to a singleton you don't do it by paying to some
scriptpubkey which represents that singleton, you pay to a scriptpubkey
which says 'I can be spent in any transaction which includes singleton X'
and it does the validation of that other UTXO being the current incarnation
of the singleton using the capabilities validation tricks I mentioned
before.


>
> > "you can only point back so far" leads to transactions becoming invalid,
> which is something we've always strictly avoided because it can result in
> huge problems during reorgs
>
> I'm surprised to hear you say that. I have tried to learn why valid
> transactions that can become invalid is seen as such a problem. I've been
> unsuccessful in finding much information about this. I tried to document
> the full extent of my understanding in my proposal here
> <https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/bbv/bip-beforeblockverify.md#reorg-safety> where
> I actually have a quote from you where you said you don't think this is a
> valid concern. Did something change your mind? Or did I misinterpret you?
> What am I missing from that section I linked to?
>

It can be made so that if it goes past the time when the backpointer works
then the transaction is still valid but its vbytes goes up because the
referenced string needs to be repeated on the chain.

I too am a bit on the fence about whether strict transaction
monotinicity is absolutely necessary. The most plausible violation of it to
add would be some kind of max height/age condition to go with the current
min height/age restrictions. What scares me about that isn't so much the
ability to replay reorgs getting messed up (those can be derailed by double
spends anyway) but that either an intentional DOS or just a spike in
transaction fees could cause a deadline to be passed and something to be
bricked for completely technical reasons having nothing to do with its
intended logic. The same type of functionality can be hacked by having an
allowed spend whose only condition is a min height/age so that if the time
has passed as long as someone isn't asleep at the wheel the transaction
will switch to a new state which disallows whatever it is that was supposed
to be disallowed at that time.

Since there isn't any compelling bit of functionality which needs to
violate monotinicity to be implemented I don't see any need to call for an
end to it as a principle. It certainly makes mempool logic a lot simpler
and more reliable.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220121/84c724d7/attachment.html>

From prayank at tutanota.de  Fri Jan 21 23:45:34 2022
From: prayank at tutanota.de (Prayank)
Date: Sat, 22 Jan 2022 00:45:34 +0100 (CET)
Subject: [bitcoin-dev] Bob-Pays-For-Transaction
Message-ID: <Mtz0y_---3-2@tutanota.de>

I have rephrased things discussed in a [tweet thread][1] in 2020, added a few things and interested to know possible issues if we had an opt in policy based on CPFP in which recipients pay fees for transactions instead of senders or most of the wallets followed this:

## Bob-Pays-For-Transaction

==Motivation==

CPFP is less explored, payjoin did not get enough adoption, fee market can be improved,
recipients paying fees for the transactions sounds interesting and it can also be used
in projects that use market making (maker-taker model).

1.Recipient cares about the urgency and the security of the payment in lot of transactions.
2.It might affect fee market post subsidy era and resolve issues with miners revenue, security etc.

===Receiving wallet===

Provide easy options to use CPFP and pay fees that confirms the parent transaction.

[CPFP calculator][1] by djbooth07 or effective fee rate shown in explorers like https://mempool.space can be helpful.

===Spending wallet===

Broadcast all transactions with 1 sat/vB

==Issues==

Few issues shared by Sergej Kotliar:

1.Receiver can pay via CPFP, but if that?s known about them it gets exploitable, senders will consolidate lot of UTXOs by sending one output to receiver.
2.Receivers would send their unconfirmed coins onward expecting others to pay the fees until someone considers the transaction important enough to be confirmed soon.

Bitcoin Core does not allow you to spend [unconfirmed UTXO using GUI][2] and most of the RPC in CLI. However Kristaps made an interesting point in the linked issue that it could be allowed for transactions
 that do not signal RBF. It is not considered safe however lot of wallets allow this including Wasabi
in which I recently found [some UI/UX issues][3] related to unconfirmed UTXO.

The part which may require changes in protocol:

The whole fee paid for such transactions wouldn't be paid to the miner confirming the transaction but
it would be shared between the miners creating next N blocks.

? [1]: https://twitter.com/LaurentMT/status/1292100590462537733
? [2]: https://github.com/djbooth007/cpfp-calculator
? [3]: https://github.com/zkSNACKs/WalletWasabi/issues/7045
? [4]: https://github.com/bitcoin-core/gui/issues/242


-- 
Prayank

A3B1 E430 2298 178F
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220122/bfda255d/attachment.html>

From jamtlu at gmail.com  Sun Jan 23 02:44:14 2022
From: jamtlu at gmail.com (James Lu)
Date: Sat, 22 Jan 2022 21:44:14 -0500
Subject: [bitcoin-dev] Renaming full nodes
Message-ID: <CANQHGB0z2v-iK2FdD12dVsoK=grShiX191wnZ16Ai_NX2vahCg@mail.gmail.com>

Much of the confusion around the Bitcoin protocol is the concept that
mining nodes 'control' the network.

I suggest renaming full nodes- to something like "validator node" to
emphasize that full nodes check if blocks are valid.

Then we could say:

"Bitcoin is decentralized because anyone can run a validator node, even on
a low-end laptop."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220122/9468fd98/attachment.html>

From mm at mm-studios.com  Sun Jan 23 13:06:36 2022
From: mm at mm-studios.com (mm-studios)
Date: Sun, 23 Jan 2022 13:06:36 +0000
Subject: [bitcoin-dev] Renaming full nodes
In-Reply-To: <CANQHGB0z2v-iK2FdD12dVsoK=grShiX191wnZ16Ai_NX2vahCg@mail.gmail.com>
References: <CANQHGB0z2v-iK2FdD12dVsoK=grShiX191wnZ16Ai_NX2vahCg@mail.gmail.com>
Message-ID: <3iEa2xZax1zTSPKGXJVGwN75k42rkJESv6PuZhgRqDEWBuu4VabN5w1iL3xKP85Wb8sYlhrgM1ZBtkAZKHnEZa6Y2qM30qLd4tEsvF1qGTs=@mm-studios.com>

The problem are.miners, it is pretty.innaccessible to be a miner. That's a major isuue for me.
Block production is pretty much in hands of the wealthy.
Any correlation between be wealthy and run a honest node? Not any under my eyes. Skipping the part of the narrative saying 'they are honest bcs they have skin in the game'. That's not scientific to me.
Block validation yes, the network is pretty decentralized.
Thanks.

Sent from ProtonMail mobile

-------- Original Message --------
On 23 Jan 2022, 02:44, James Lu via bitcoin-dev wrote:

> Much of the confusion around the Bitcoin protocol is the concept that mining nodes 'control' the network.
>
> I suggest renaming full nodes- to something like "validator node" to emphasize that full nodes check if blocks are valid.
>
> Then we could say:
>
> "Bitcoin is decentralized because anyone can run a validator node, even on a low-end laptop."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220123/585e3257/attachment.html>

From jlrubin at mit.edu  Mon Jan 24 03:36:46 2022
From: jlrubin at mit.edu (Jeremy)
Date: Sun, 23 Jan 2022 19:36:46 -0800
Subject: [bitcoin-dev] BIP-119 CTV Meeting #2 Agenda for Tuesday January
	25th at 12:00 PT
Message-ID: <CAD5xwhgW0yv30=j_UR5_4iwpjePP8qMnusO03imwmcsX7GBdLg@mail.gmail.com>

Bitcoin Developers,

The 2nd instance of the recurring meeting is scheduled for Tuesday January
25th at 12:00 PT in channel ##ctv-bip-review in libera.chat IRC server.

The meeting should take approximately 2 hours.

The topics proposed to be discussed are agendized below. Please review the
agenda in advance of the meeting to make the best use of everyone's time.

If you have any feedback or proposed content changes to the agenda please
let me know.

See you Tuesday,

Jeremy

- Update on Bounty Program & Feedback (10 Min)
- Feedback Recap (20 Min)
  - In this section we'll review any recent feedback or review of CTV.
    To expedite the meeting, a summary is provided below of the main
feedback received since the last meeting and responses to them so that the
time allotted may be devoted to follow up questions.
  - Luke Dashjr's feedback
    - thread:
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019776.html
    - summary:
        Dashjr notes that while CTV is not done, it may be nearly done.
        Dashjr requests that some applications be made BIP-quality before
proceeding, amongst other smaller feedbacks.
        Dashjr also expresses his concerns about activation logic.
        Respondents debated the activation logic, and there was a general
sentiment to keep the discussion of CTV and activation logic somewhat
separate, as Activation is a general concern pertaining to all upgrades and
not CTV in particular.
        Rubin responded asking if BIP-quality is required or if examples
like those in rubin.io/advent21 suffice.
  - James O'Beirne's feedback
    - Github Link:
https://github.com/bitcoin/bitcoin/pull/21702#pullrequestreview-859718084
    - summary:
        O'Beirne tests the reindexing performance with the CTV patches and
finds a minor performance regression due to the cache precomputations.
        Rubin responds with patches for an improved caching strategy that
precomputes the CTV hashes only when they are used, but it is a little more
complex to review.
        Rubin also points out that the tested range is not representative
of "current" blocks which have a higher proportion of segwit.
  - Peter Todd's Feedback
    - thread:
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019738.html
    - response:
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019739.html
    - summary:
        Todd reviewed the BIP and an (outdated) implementation and was
disappointed to find that the testing was insufficient, the analysis of
validation resources was insufficient, and the quality of proof of concept
applications was insufficient.
        Rubin responded by pointing Todd to the most up to date
implementation which has more tests, updated the link in the BIP to the PR,
updated the BIP to describe resource usage, and asked what the bar is
expected to be for applications.
        Rubin further responded with an analysis of current congested
mempool behavior here:
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019756.html
.
        Todd is yet to respond.
- What is Sapio / How to think about Programming with CTV (15 Min)
  - Resources to review
    - https://learn.sapio-lang.org/ch02-00-bip-119.html
    - https://rubin.io/bitcoin/2021/12/06/advent-9/
    - https://rubin.io/bitcoin/2021/12/15/advent-18/
  - Composability
  - What's all this "Non-Interactivity" Business?
- Vaults (20 Min)
  - Resources:
    https://rubin.io/bitcoin/2021/12/07/advent-10/
    https://rubin.io/bitcoin/2021/12/08/advent-11/
    https://github.com/kanzure/python-vaults
- Congestion Control (20 Mins)
  - Resources:
    https://rubin.io/bitcoin/2021/12/09/advent-12/

https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019756.html
    https://utxos.org/analysis/batching_sim/
    https://utxos.org/analysis/bip_simulation/
- Payment Pools (20 Mins)
  - Resources:
    https://rubin.io/bitcoin/2021/12/10/advent-13/
    https://rubin.io/bitcoin/2021/12/15/advent-18/

https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019419.html

https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-June/017964.html
- General Q&A (15 Mins)


--
@JeremyRubin <https://twitter.com/JeremyRubin>
<https://twitter.com/JeremyRubin>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220123/7a55a9f4/attachment.html>

From lloyd.fourn at gmail.com  Mon Jan 24 08:01:17 2022
From: lloyd.fourn at gmail.com (Lloyd Fournier)
Date: Mon, 24 Jan 2022 19:01:17 +1100
Subject: [bitcoin-dev] CTV dramatically improves DLCs
Message-ID: <CAH5Bsr2vxL3FWXnJTszMQj83jTVdRvvuVpimEfY7JpFCyP1AZA@mail.gmail.com>

Hi dlc-dev and bitcoin-dev,

tl;dr OP_CTV simplifies and improves performance of DLCs by a factor of *a lot*.

## Introduction

Dryja introduced the idea of Discreet Log Contracts (DLC) in his
breakthrough work[1].
Since then (DLC) has become an umbrella term for Bitcoin protocols
that map oracle secret revelation to an on-chain transaction which
apportions coins accordingly.
The key property that each protocol iteration preserves is that the
oracle is an *oblivious trusted party* -- they do not interact with
the blockchain and it is not possible to tell which event or which
oracle the two parties were betting on with blockchain data alone.

 `OP_CHECKTEMPLATEVERIFY` (CTV) a.k.a. BIP119 [2] is a proposed
upgrade to Bitcoin which is being actively discussed.
CTV makes possible an optimized protocol which improves DLC
performance so dramatically that it solves several user experience
concerns and engineering difficulties.
To me this is the most compelling and practical application of CTV so
I thought it's about time to share it!

## Present state of DLC specification

The DLC specifications[3] use adaptor signatures to condition each
possible payout.
The protocol works roughly like this:

1. Oracle(s) announce events along with a nonce `R` for each event.
Let's say each event has `N` outcomes.
2. Two users who wish to make a bet take the `R` from the oracle
announcement and construct a set of attestation points `S` and their
corresponding payouts.
3. Each attestation point for each of the `N` outcomes is calculated
like `S_i = R + H(R || X || outcome_i) * X` where `X` is the oracle's
static key.
4. The users combine the attestation points into *contract execution
transaction* (CET) points e.g `CET_i = S1_i + S2_i + S3_i`.
   Here `CET_i` is the conjunction (`AND`) between the event outcomes
represented by `S1_i, S2_i, S3_i`.
5. The oracle(s) reveals the attestation `s_i` where `s_i * G = S_i`
if the `i`th is the outcome transpired.
6. Either of the parties takes the `s_i`s from each of the
attestations and combines them e.g. `cet_i = s1_i + s2_i + s3_i` and
uses `cet_i` to decrypt the CET adaptor signature encrypted by `CET_i`
and broadcast the transaction.

## Performance issues with DLCs

In the current DLC protocol both parties compute:
  - `E * N` attestation points where `E` is the number of events you
are combining and `N` is the number of outcomes per event. (1 mul)
  - `C >= E * N` CET adaptor signatures and verify them. (2 mul -- or
with MuSig2, 3 muls).

Note that the number of CETs can be much greater than the number of
attestation points. For example,
if an oracle decomposes the price of BTC/USD into 20 binary digits
e.g. 0..(2^20 -1), you could have
`E=20,N=2,C=2^20`. So the biggest concern for worst case performance
is the adaptor signatures multiplications.

If we take a multiplication as roughly 50 microseconds computing
MuSig2 adaptor signatures for ~6000 CETs would take around a second of
cpu time (each) or so.
6000 CETs is by no means sufficient if you wanted, for example, to bet
on the BTC/USD price per dollar.
Note there may be various ways of precomputing multiplications and
using fast linear combination algorithms and so on but I hope this
provides an idea of the scale of the issue.
Then consider that you may want to use a threshold of oracles which
will combinatorially increase this number (e.g. 3/5 threshold would
10x this).

You also would end up sending data on the order of megabytes to each other.

## committing to each CET in a tapleaf with CHECKTEMPLATEVERIFY

What can we do with OP_CTV + Taproot to improve this?

Instead of creating an adaptor signature for every CET, commit to the
CET with OP_CTV in a tapleaf:

```
<CET-hash_i> CHECKTEMPLATEVERIFY <CET_i> CHECKSIG
```

When the oracle(s) reveals their attestations either party can combine
them to get the secret key
corresponding to `CET_i` and spend the coins to the CET (whose CTV
hash is `CET-hash`) which
distributes the funds according to the contract.

This replaces all the multiplications needed for the adaptor signature
with a few hashes!
You will still need to compute the `CET_i` which will involve a point
normalisation but it still brings the computational cost per CET down
from hundreds of microseconds to around 5 (per party).
There will be a bit more data on chain (and a small privacy loss) in
the uncooperative case but even with tens of thousands of outcomes
it's only going to roughly double the virtual size of the transaction.
Keep in mind the uncooperative case should hopefully be rare too esp
when we are doing this in channels.

The amount of data that the parties need to exchange is also reduced
to a small constant size.

## getting rid of combinatorial complexity of oracle thresholds

Now that we're using script it's very easy to do a threshold along
with the script. e.g. a 2/3:

```
<CET-hash> CHECKTEMPLATEVERIFY
<attestation-point1> CHECKSIG
<attestation-point2> CHECKSIGADD
<attestation-point3> CHECKSIGADD
2 EQUAL
```

The improvement here is that the amount of computation and
communication does not increase with the number of oracles in the
threshold.
The size of the witness only increases linearly in the number of
oracles and only in the un-cooperative case.
This also solves a security issue with the current spec because
attestation points from different oracles are no longer summed (which
is a problem [4]).

## Getting rid of the attestation point multiplication

It's possible to get rid of the EC multiplications from the
attestation point computation too.
This is optimistically a 10x improvement but in the most important
cases it's a negligible improvement since computing the `E*N`
attestion points is a small fraction of the total CET point
computation.

Recall the original Schnorr style DLC attestation point was computed like:

```
S_i = R + H(R || X || outcome_i) * X
```

So for each outcome we have to hash it and multiply the result by the
oracle's public key.
I don't think hashing is necessary[6].

First note that an oracle attestation scheme is not a signature scheme:

1. The users need to be able to compute the attestation point
beforehand (signature schemes do not require the verifier to be able
to compute anything before hand).
2. There is a very different concept of a forgery -- you don't care
about someone being able to forge signatures under the oracle's key in
general you only care about them being able to forge an attestation
corresponding to some previously announced event i.e. you only care
about forgeries of things that people are actually betting on.

Long story[6] short we can get rid of the hash and do the following
instead for the `outcome_i`:

```
S_i = R + i * X
```

For each `outcome_i` the oracle will reveal a different linear
combination of `R` and `X`.
However, if we still want to preserve the ability to add attestation
points together to create an AND like condition for points
attestations from the same oracle so we have to do:

```
S_i = i * R + X
```

which when we combine two attestations from the same oracle becomes:

`S1_i + S2_j = (i*R1 + X) + (j*R2 + X) = i*R1 + j*R2 + 2*X`

As you can see the addition preserves the linear structure.
If you were to do the original suggestion it would be:

`S1_i + S2_j = (i*X + R1 + (j*X + R2) = (i + j)*X + R1 + R2)`

Which loses the structure and creates collisions e.g. `S1_1 + S2_2 =
S1_2 + S2_1` .
Note that this collision problem also exists in the current spec and
original paper[4,5] but requires a solving a hashing k-sum that should
be hard to do in practice.

So, when we compute for `i in 1..N`, `S_1 = R + X` and each subsequent
is `S_i = S_{i-1} + R` and so we only need to do one addition for each
attestation point.

## In summary

In the worst case this improves DLC performance by ~30x compared to
using MuSig2 adaptor signatures because it gets rid of all
multiplications for both parties.
In the case of a 3/5 threshold performance would be improved by another 10x.
Depending on the kind of event, removing the attestation point
multiplication will also help.
Communication complexity also becomes constant.

In other words, from the user's perspective everything can happen
pretty much instantly even on more resource constrained devices and
bad internet connections.

The downside of the protocol is that in the un-cooperative case, the
size of the witness is bigger and the transaction is distinguishable
from other protocols (it's not longer scriptless).

## Credits

Special thanks to:

- Ruben Somsen who first made the observation that OP_CTV could be
applied to DLCs in the way presented here.
- Thibaut Le Guilly who did benchmarking on getting rid of the
attestation point multiplication.
- Nadav Cohen who pointed out that doing `R + i*X` was broken.

[1]: https://adiabat.github.io/dlc.pdf
[2]: https://github.com/bitcoin/bips/blob/master/bip-0119.mediawiki
[3]: https://github.com/discreetlogcontracts/dlcspecs
[4]: https://bitcoinproblems.org/problems/secure-dlcs.html
[5]: https://mailmanlists.org/pipermail/dlc-dev/2021-March/000065.html
[6]: https://github.com/LLFourn/dlc-sec/blob/master/main.pdf
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220124/cec80a59/attachment-0001.html>

From AdamISZ at protonmail.com  Mon Jan 24 14:43:53 2022
From: AdamISZ at protonmail.com (AdamISZ)
Date: Mon, 24 Jan 2022 14:43:53 +0000
Subject: [bitcoin-dev] PathCoin
Message-ID: <jMANAdspMdPb1ZCFttQ3tGmkZ0oYojLY5Oz1d8ZSNl3JhZeDuT1xK0vxTu8uyHcgPXWsM_6XNb3R9tVD3_Yez88pviFrCaNt7LPqdWVBWus=@protonmail.com>

Hello list,

I took the time to write up this rather out-there idea:

Imagine you wanted to send a coin just like email, i.e. just transfer data to the counterparty.

Clearly this is in general entirely impossible; but with what restrictions and assumptions could you create a toy version of it?

See this gist for a detailed build up of the idea:

https://gist.github.com/AdamISZ/b462838cbc8cc06aae0c15610502e4da

Basically: using signature adaptors and CTV or a similar covenant, you could create a fully trustless transfer of control of a utxo from one party to another with no interaction with the rest of the group, at the time of transfer (modulo of course lots and lots of one-time setup).

The limitations are extreme and as you'd imagine. In the gist I feel like I got round one of them, but not the others.

(I very briefly mention comparison to e.g. statechains or payment pools; they are making other tradeoffs against the 'digital cash' type of goal. There is no claim that this 'pathcoin' idea is even viable yet, let alone better than those ideas).

Publishing this because I feel like it's the kind of thing imaginative minds like the ones here, may be able to develop further. Possibly!


waxwing / AdamISZ

From billy.tetrud at gmail.com  Tue Jan 25 11:53:36 2022
From: billy.tetrud at gmail.com (Billy Tetrud)
Date: Tue, 25 Jan 2022 05:53:36 -0600
Subject: [bitcoin-dev] PathCoin
In-Reply-To: <jMANAdspMdPb1ZCFttQ3tGmkZ0oYojLY5Oz1d8ZSNl3JhZeDuT1xK0vxTu8uyHcgPXWsM_6XNb3R9tVD3_Yez88pviFrCaNt7LPqdWVBWus=@protonmail.com>
References: <jMANAdspMdPb1ZCFttQ3tGmkZ0oYojLY5Oz1d8ZSNl3JhZeDuT1xK0vxTu8uyHcgPXWsM_6XNb3R9tVD3_Yez88pviFrCaNt7LPqdWVBWus=@protonmail.com>
Message-ID: <CAGpPWDY3vZ2JOsa1UhoT-z8kfxqkVWcq1nyt9Ah5ye6HE_6gOQ@mail.gmail.com>

There was a protocol someone mentioned a while back called Sabu that had
the same goals. As i recall, it had some pretty promising constructs, but
would have a critical vulnerability that could be exploited by miners. This
is the write up:

https://raymo-49157.medium.com/time-to-boost-bitcoin-circulation-million-transactions-per-second-and-privacy-1eef8568d180

Perhaps some of the techniques there could be combined with your ideas to
get closer to a solution.

On Mon, Jan 24, 2022, 08:51 AdamISZ via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Hello list,
>
> I took the time to write up this rather out-there idea:
>
> Imagine you wanted to send a coin just like email, i.e. just transfer data
> to the counterparty.
>
> Clearly this is in general entirely impossible; but with what restrictions
> and assumptions could you create a toy version of it?
>
> See this gist for a detailed build up of the idea:
>
> https://gist.github.com/AdamISZ/b462838cbc8cc06aae0c15610502e4da
>
> Basically: using signature adaptors and CTV or a similar covenant, you
> could create a fully trustless transfer of control of a utxo from one party
> to another with no interaction with the rest of the group, at the time of
> transfer (modulo of course lots and lots of one-time setup).
>
> The limitations are extreme and as you'd imagine. In the gist I feel like
> I got round one of them, but not the others.
>
> (I very briefly mention comparison to e.g. statechains or payment pools;
> they are making other tradeoffs against the 'digital cash' type of goal.
> There is no claim that this 'pathcoin' idea is even viable yet, let alone
> better than those ideas).
>
> Publishing this because I feel like it's the kind of thing imaginative
> minds like the ones here, may be able to develop further. Possibly!
>
>
> waxwing / AdamISZ
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220125/a599352b/attachment.html>

From AdamISZ at protonmail.com  Tue Jan 25 12:50:32 2022
From: AdamISZ at protonmail.com (AdamISZ)
Date: Tue, 25 Jan 2022 12:50:32 +0000
Subject: [bitcoin-dev] PathCoin
In-Reply-To: <CAGpPWDY3vZ2JOsa1UhoT-z8kfxqkVWcq1nyt9Ah5ye6HE_6gOQ@mail.gmail.com>
References: <jMANAdspMdPb1ZCFttQ3tGmkZ0oYojLY5Oz1d8ZSNl3JhZeDuT1xK0vxTu8uyHcgPXWsM_6XNb3R9tVD3_Yez88pviFrCaNt7LPqdWVBWus=@protonmail.com>
 <CAGpPWDY3vZ2JOsa1UhoT-z8kfxqkVWcq1nyt9Ah5ye6HE_6gOQ@mail.gmail.com>
Message-ID: <By1G6iST5DCXZJVfEd3HzdPgU3e_NGoqvH-5UoqsOzY8qjiOmy5iHXiOwjXtm7Znq1Z6z-XOL0IPDSyQiLOZ6-lRQ-vi1I6Cba4aqywe8xw=@protonmail.com>

Hi Billy,
I read through the description. I think systems like this *mostly* fail due to game theory.

With punishment-by-burn you have various issues that make it to my mind pretty unstable, too unstable to use for any serious system. To be fair, this isn't cut-and-dried. So let me unpack:

(I briefly touched on why I dismissed penalties via burn in my gist, section: "Not feeling the burn".)

There is a distinction between penalty via burn to unspendable output and penalty via burn to miner fees. The latter has an obvious problem: if your counterparties collude with (or are) miners, they may not actually be penalized at all (now to be clear, that is a problematic attack ex nihilo: nobody usually can be sure who's mining the next block, but markets have a way of solving and coordinating such things: see e.g. the various MEV discussions and initiatives in Ethereum for an example of that).

But the former (provable burn) is still imo extremely unstable: if the penalty tx destroys all the money, what is the incentive for the honest party to punish? In such a scenario even a one cent donation from the attacker to the victim might prevent the penalty from happening.
You can combine 'destruction of most, or some, of the funds' with a smaller payout to the aggrieved party, but then again you have to factor in the possibility of bribes. The Sabu post you linked describes it as: "There are precise and delicate formulas for calculating the amount of loss of the issuer and the creditor, which ensures that just and true act in both parties are cost-effective in all situations." I agree it's delicate, but after having spent time looking into these things, my strong intuition is that it will never be properly stable.

In the PathCoin description I am specifically looking for a trustless system, with this finesse: we still count it as trustless even though we are using penalties as disincentive, because the penalty *consists of a payment directly from the attacker to the attacked, and that payment is larger than the amount stolen*. I claim that that *is* stable.

Notice that Lightning has the same model (in LN-Penalty), as long as 'claiming the whole channel capacity' is enough to be larger than what is stolen (see: channel reserves etc.).

Sent with [ProtonMail](https://protonmail.com/) Secure Email.

??????? Original Message ???????
On Tuesday, January 25th, 2022 at 11:53, Billy Tetrud via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:

> There was a protocol someone mentioned a while back called Sabu that had the same goals. As i recall, it had some pretty promising constructs, but would have a critical vulnerability that could be exploited by miners. This is the write up:
>
> https://raymo-49157.medium.com/time-to-boost-bitcoin-circulation-million-transactions-per-second-and-privacy-1eef8568d180
>
> Perhaps some of the techniques there could be combined with your ideas to get closer to a solution.
>
> On Mon, Jan 24, 2022, 08:51 AdamISZ via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>> Hello list,
>>
>> I took the time to write up this rather out-there idea:
>>
>> Imagine you wanted to send a coin just like email, i.e. just transfer data to the counterparty.
>>
>> Clearly this is in general entirely impossible; but with what restrictions and assumptions could you create a toy version of it?
>>
>> See this gist for a detailed build up of the idea:
>>
>> https://gist.github.com/AdamISZ/b462838cbc8cc06aae0c15610502e4da
>>
>> Basically: using signature adaptors and CTV or a similar covenant, you could create a fully trustless transfer of control of a utxo from one party to another with no interaction with the rest of the group, at the time of transfer (modulo of course lots and lots of one-time setup).
>>
>> The limitations are extreme and as you'd imagine. In the gist I feel like I got round one of them, but not the others.
>>
>> (I very briefly mention comparison to e.g. statechains or payment pools; they are making other tradeoffs against the 'digital cash' type of goal. There is no claim that this 'pathcoin' idea is even viable yet, let alone better than those ideas).
>>
>> Publishing this because I feel like it's the kind of thing imaginative minds like the ones here, may be able to develop further. Possibly!
>>
>> waxwing / AdamISZ
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220125/e672234b/attachment.html>

From jonasdnick at gmail.com  Tue Jan 25 16:24:21 2022
From: jonasdnick at gmail.com (Jonas Nick)
Date: Tue, 25 Jan 2022 16:24:21 +0000
Subject: [bitcoin-dev] [dlc-dev] CTV dramatically improves DLCs
In-Reply-To: <CAH5Bsr2vxL3FWXnJTszMQj83jTVdRvvuVpimEfY7JpFCyP1AZA@mail.gmail.com>
References: <CAH5Bsr2vxL3FWXnJTszMQj83jTVdRvvuVpimEfY7JpFCyP1AZA@mail.gmail.com>
Message-ID: <2b316504-f785-b1b3-9ff9-8d781d6c0d9b@gmail.com>

Thank you, that's an interesting application of OP_CTV.

Perhaps worth pointing out that this does not require OP_CTV but could also be
enabled by other covenant constructions. For example, it seems like
ANYPREVOUT-based covenants provide similar benefits. The script of the Taproot
leaves could be set to

<sig> <G> CHECKSIGVERIFY <CET_i> CHECKSIGVERIFY

where <sig> is an ANYPREVOUTANYSCRIPT signature of the CET for public key P = G.
When using nonce R = G, signature creation has negligible computational cost (s
= 1 + H(R, P, m)). A downside compared to CTV is the additional overhead of 64
witness bytes (<sig>).

From roconnor at blockstream.com  Wed Jan 26 17:20:10 2022
From: roconnor at blockstream.com (Russell O'Connor)
Date: Wed, 26 Jan 2022 12:20:10 -0500
Subject: [bitcoin-dev] TXHASH + CHECKSIGFROMSTACKVERIFY in lieu of CTV and
	ANYPREVOUT
Message-ID: <CAMZUoK=pkZuovtifBzdqhoyegzG+9hRTFEc7fG9nZPDK4KbU3w@mail.gmail.com>

Recapping the relationship between CTV and ANYPREVOUT::

It is known that there is a significant amount of overlap in the
applications that are enabled by the CTV and ANYPREVOUT proposals despite
the fact that their primary applications (congestion control for CTV and
eltoo lightning channels for ANYPREVOUT) are quite distinct.
In particular, ANYPREVOUT can enable most of the applications of CTV,
albeit with a higher cost.  The primary functionality of CTV is to allow a
scriptPubKey to make a commitment to its spending transaction's hash with
the input's TXID excluded from the hash.  This exclusion is necessary
because the scriptPubKey is hashed into the input's TXID, and including the
TXID would cause a cycle of hash commitments, which is impossible to
construct.  On the other hand, ANYPREVOUT defines a signature hash mode
that similarly excludes the inputs TXID for its purpose of rebindable
signatures.

This means that ANYPREVOUT can mimic most of the properties of CTV by
committing both a public key along with an ANYPREVOUT signature inside
scriptPubKey.  In fact, the only reason Bitcoin doesn't have covenants
today is due to this cycle between scriptPubKeys and the TXIDs that occur
in all the sighash modes.

The major differences between simulating CTV via ANYPREVOUT and the actual
CTV proposal is: (1) The cost of simulating CTV.  With CTV the spending
transaction is committed using a hash of 32 bytes, while simulating it with
ANYPREVOUT requires 64 bytes for a signature, and 32 bytes for some public
key, plus a few more bytes for various flags.  Some of that cost could be
reduced by using the inner public key (1 byte representation) and, if we
had CAT, maybe by assembling the signature from reusable pieces (i.e.
setting the nonce of the commited signature equal to the public key).

The other major difference is: (2) CTV's transaction hash covers values
such as the number of inputs in the transaction and their sequence numbers,
which ANYPREVOUT does not cover.  CTV's hash contains enough information so
that when combined with the missing TXIDs, you can compute the TXID of the
spending transaction.  In particular if the number of inputs is committed
to being 1, once the scriptpubkey's transaction id is known and committed
to the blockchain, the TXID of its spending transaction is deducible.  And
if that transaction has outputs that have CTV commitments in them, you can
deduce their spending TXIDs in turn.  While this is a pretty neat feature,
something that ANYPREVOUT cannot mimic, the main application for it is
listed as using congestion control to fund lightning channels, fixing their
TXIDs in advance of them being placed on chain.  However, if ANYPREVOUT
were used to mimic CTV, then likely it would be eltoo channels that would
be funded, and it isn't necessary to know the TXIDs of eltoo channels in
advance in order to use them.



An Alternative Proposal::

Given the overlap in functionality between CTV and ANYPREVOUT, I think it
makes sense to decompose their operations into their constituent pieces and
reassemble their behaviour programmatically.  To this end, I'd like to
instead propose OP_TXHASH and OP_CHECKSIGFROMSTACKVERIFY.

OP_TXHASH would pop a txhash flag from the stack and compute a (tagged)
txhash in accordance with that flag, and push the resulting hash onto the
stack.
OP_CHECKSIGFROMSTACKVERIFY would pop a pubkey, message, and signature from
the stack and fail if the signature does not verify on that message.

CTV and TXHASH have roughly equivalent functionality.  'CTV DROP' can be
simulated by '<ctv_style_flag> TXHASH EQUALVERIFY'.  The reverse is also
true where '<ctv_style_flag> TXHASH' can be simulated by CTV by
'<ctv-result-from-witness-stack> CTV', however, as you can see, simulating
TXHASH from CTV is much more expensive than the other way around, because
the resulting 32-byte hash result must be included as part of the witness
stack.

'<anyprevout-pubkey> CHECKSIGVERIFY can be simulated by '<apo_style_flag>
TXHASH <pubkey> CHECKSIGFROMSTACKVERIFY'.  Here we see the advantage of
pushing the hash value onto the stack.  APO can be simulated without
needing to include a copy of the resulting txhash inside the witness data.

In addition to the CTV and ANYPREVOUT applications, with
CHECKSIGFROMSTACKVERIFY we can verify signatures on arbitrary messages
signed by oracles for oracle applications.  This is where we see the
benefit of decomposing operations into primitive pieces.  By giving users
the ability to program their own use cases from components, we get more
applications out of fewer op codes!



Caveats::

First, I acknowledge that replicating the behaviour of CTV and ANYPREVOUT
does cost a few more bytes than using the custom purpose built proposals
themselves.  That is the price to be paid when we choose the ability to
program solutions from pieces.  But we get to reap the advantages of being
able to build more applications from these pieces.

Unlike CTV, TXHASH is not NOP-compatable and can only be implemented within
tapscript.  In particular, bare CTV isn't possible with this proposal.
However, this proposal doesn't preclude the possibility of having CTV added
to legacy script in while having TXHASH added to tapscript.

For similar reasons, TXHASH is not amenable to extending the set of txflags
at a later date.  In theory, one could have TXHASH abort-with-success when
encountering an unknown set of flags.  However, this would make analyzing
tapscript much more difficult. Tapscripts would then be able to abort with
success or failure depending on the order script fragments are assembled
and executed, and getting the order incorrect would be catastrophic.  This
behavior is manifestly different from the current batch of OP_SUCCESS
opcodes that abort-with-success just by their mere presence, whether they
would be executed or not.

I believe the difficulties with upgrading TXHASH can be mitigated by
designing a robust set of TXHASH flags from the start.  For example having
bits to control whether (1) the version is covered; (2) the locktime is
covered; (3) txids are covered; (4) sequence numbers are covered; (5) input
amounts are covered; (6) input scriptpubkeys are covered; (7) number of
inputs is covered; (8) output amounts are covered; (9) output scriptpubkeys
are covered; (10) number of outputs is covered; (11) the tapbranch is
covered; (12) the tapleaf is covered; (13) the opseparator value is
covered; (14) whether all, one, or no inputs are covered; (15) whether all,
one or no outputs are covered; (16) whether the one input position is
covered; (17) whether the one output position is covered; (18) whether the
sighash flags are covered or not (note: whether or not the sighash flags
are or are not covered must itself be covered).  Possibly specifying which
input or output position is covered in the single case and whether the
position is relative to the input's position or is an absolute position.

That all said, even if other txhash flag modes are needed in the future,
adding TXHASH2 always remains an option.



Interactions with potential future opcodes::

We should give some consideration on how these opcodes may interact with
future opcodes such as CAT, rolling SHA256 opcodes, or how it might
interface with other covenant opcodes that may do things like, directly
push input or output amounts onto the stack for computation purposes,
opcodes which have been added to the Elements project.

With CAT and/or rolling SHA256 opcodes and/or existing SHA256 opcodes, the
CHECKSIGFROMSTACKVERIFY could verify signatures on programmatically
assembled messages.  Also, in combination with multiple calls to TXHASH,
could be used to create signatures that commit to complex subsets of
transaction data.

If new opcodes are added to push parts of the transaction data direction
onto the stack, e.g. OP_INSPECTOUTPUTVALUE, there is perhaps concern that
they would obsolete TXHASH, since, in the presence of rolling SHA256
opcodes, TXHASH could be simulated.  However, given that TXHASH can
compactly create a hash of large portions of transaction data, it seems
unlikely that TXHASH would fall into disuse.  Also, a combination of TXHASH
and transaction introspection opcodes can be used to build "*subtractive
covenants*".

The usual way of building a covenant, which we will call "*additive *
*covenants*", is to push all the parts of the transaction data you would
like to fix onto the stack, hash it all together, and verify the resulting
hash matches a fixed value.  Another way of building covenants, which we
will call "*subtractive covenants*", is to push all the parts of the
transaction data you would like to remain free onto the stack.  Then use
rolling SHA256 opcodes starting from a fixed midstate that commits to a
prefix of the transaction hash data. The free parts are hashed into that
midstate.  Finally, the resulting hash value is verified to match a value
returned by TXHASH.  The ability to nicely build subtractive covenants
depends on the details of how the TXHASH hash value is constructed,
something that I'm told CTV has given consideration to.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220126/1f33d0b3/attachment.html>

From jlrubin at mit.edu  Wed Jan 26 22:16:06 2022
From: jlrubin at mit.edu (Jeremy)
Date: Wed, 26 Jan 2022 14:16:06 -0800
Subject: [bitcoin-dev] TXHASH + CHECKSIGFROMSTACKVERIFY in lieu of CTV
	and ANYPREVOUT
In-Reply-To: <CAMZUoK=pkZuovtifBzdqhoyegzG+9hRTFEc7fG9nZPDK4KbU3w@mail.gmail.com>
References: <CAMZUoK=pkZuovtifBzdqhoyegzG+9hRTFEc7fG9nZPDK4KbU3w@mail.gmail.com>
Message-ID: <CAD5xwhhwqJ_AETAb3p_zUZmRX-Dzh8J9G984zwEs=KFsGN8aNQ@mail.gmail.com>

Hi Russell,

Thanks for this email, it's great to see this approach described.

A few preliminary notes of feedback:

1) a Verify approach can be made to work for OP_TXHASH (even with CTV
as-is) E.g., suppose a semantic added for a single byte stack[-1] sighash
flag to read the hash at stack[-2], then the hash can be passed in instead
of put on the stack. This has the disadvantage of larger witnesses, but the
advantage of allowing undefined sighash flags to pass for any hash type.
2) using the internal key for APO covenants is not an option because it
makes transaction construction interactive and precludes contracts with a
NUMS point taproot key. Instead, if you want similar savings, you should
advocate an OP_GENERATOR which puts G on the stack. Further, an untagged
APO variant which has split R and S values would permit something like
<sig> OP_GENERATOR OP_GENERATOR CHECKSIGAPO, which would be only 2 more
bytes than CTV.
3) I count something like 20 different flags in your proposal. As long as
flags are under 40 bytes (and 32 assuming we want it to be easy) without
upgrading math this should be feasible to manipulate on the stack
programmatically. This is ignoring some of the more flexible additions you
mention about picking which outputs/inputs are included. However, 20 flags
means that for testing we would want comprehensive tests and understanding
for ~1 million different flag combos and the behaviors they expose. I think
this necessitates a formal model of scripting and transaction validity
properties. Are there any combinations that might be undesirable?
4) Just hashing or not hashing isn't actually that flexible, because it
doesn't natively let you do things like (for example) TLUV. You really do
need tx operations for directly manipulating the data on the stack to
construct the hash if you want more flexible covenants. This happens to be
compatible with either a Verify or Push approach, since you either
destructure a pushed hash or build up a hash for a verify.
5) Flexible hashing has the potential for quadratic hashing bugs. The
fields you propose seem to be within similar range to work you could cause
with a regular OP_HASH256, although you'd want to be careful with some of
the proposed extensions that you don't create risk of quadratic hashing,
which seems possible with an output selecting opcode unless you cache
properly (which might be tricky to do). Overall for the fields explicitly
mentioned, seems safe, the "possibles" seem to have some more complex
interactions. E.g., CTV with the ability to pick a subset of outputs would
be exposed to quadratic hashing.
6) Missing field: covering the annex or some sub-range of the annex
(quadratic hashing issues on the latter)
7) It seems simpler to, for many of these fields, push values directly (as
in OP_PUSHTXDATA from Johnson Lau) because the combo of flags to push the
hash of a single output's amount to emulate OP_AMOUNT looks 'general but
annoying'. It may make more sense to do the OP_PUSHTXDATA style opcode
instead. This also makes it simpler to think about the combinations of
flags, since it's really N independent multi-byte opcodes.


Ultimately if we had OP_TXHASH available "tomorrow", I would be able to
build out the use cases I care about for CTV (and more). So I don't have an
opposition on it with regards to lack of function.

However, if one finds the TXHASH approach acceptable, then you should also
be relatively fine doing APO, CTV, CSFS, TXHASH acceptable in any order
(whenever "ready"), unless you are particularly sensitive to "technical
debt" and "soft fork processes". The only costs of doing something for CTV
or APO given an eventual TXHASH is perhaps a wasted key version or the 32
byte argument of a NOP opcode and some code to maintain.

Are there other costs I am missing?

However, as it pertains to actual rollout:

- OP_TXHASH+CSFSV doesn't seem to be the "full" set of things needed (we
still need e.g. OP_CAT, Upgraded >=64 bit Math, TLUV or OP_TWEAK
OP_TAPBRANCH OP_MANIPULATETAPTREE, and more) to full realize covenanting
power it intends to introduce.
- What sort of timeline would it take to ready something like TXHASH (and
desired friends) given greater scope of testing and analysis (standalone +
compared to CTV)?
- Is there opposition from the community to this degree of
general/recursive covenants?
- Does it make "more sense" to invest the research and development effort
that would go into proving TXHASH safe, for example, into Simplicity
instead?

Overall, *my opinion *is that:

- TXHASH is an acceptable theoretical approach, and I am happy to put more
thought into it and maybe draft a prototype of it.
- I prefer CTV as a first step for pragmatic engineering and availability
timeline reasons.
- If TXHASH were to take, optimistically, 2 years to develop and review,
and then 1 year to activate, the "path dependence of software" would put
Bitcoin in a much better place were we to have CTV within 1 year and
applications (that are to be a subset of TXHASH later) being built over the
next few years enhanced in the future by TXHASH's availability.
- There is an element of expediency meritted for something like CTV insofar
as it provides primitives to tackle time sensitive issues around privacy,
scalability, self custody, and decentralization. The aforementioned
properties may be difficult to reclaim once given away (with the exception
of perhaps scalability).
- Bringing CTV to an implemented state of near-unanimous "we could do this,
technically" is good for concretely driving the process of review for any
covenant proposals forward, irrespective of if we ultimately activate.
(I.e., if there were a reason we could not do CTV safely, it would likely
have implications for any other future covenant)

Concretely, I'm not going to stop advocating for CTV based on the above,
but I'm very happy to have something new in the mix to consider!

Best,

Jeremy


--
@JeremyRubin <https://twitter.com/JeremyRubin>
<https://twitter.com/JeremyRubin>


On Wed, Jan 26, 2022 at 9:23 AM Russell O'Connor via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Recapping the relationship between CTV and ANYPREVOUT::
>
> It is known that there is a significant amount of overlap in the
> applications that are enabled by the CTV and ANYPREVOUT proposals despite
> the fact that their primary applications (congestion control for CTV and
> eltoo lightning channels for ANYPREVOUT) are quite distinct.
> In particular, ANYPREVOUT can enable most of the applications of CTV,
> albeit with a higher cost.  The primary functionality of CTV is to allow a
> scriptPubKey to make a commitment to its spending transaction's hash with
> the input's TXID excluded from the hash.  This exclusion is necessary
> because the scriptPubKey is hashed into the input's TXID, and including the
> TXID would cause a cycle of hash commitments, which is impossible to
> construct.  On the other hand, ANYPREVOUT defines a signature hash mode
> that similarly excludes the inputs TXID for its purpose of rebindable
> signatures.
>
> This means that ANYPREVOUT can mimic most of the properties of CTV by
> committing both a public key along with an ANYPREVOUT signature inside
> scriptPubKey.  In fact, the only reason Bitcoin doesn't have covenants
> today is due to this cycle between scriptPubKeys and the TXIDs that occur
> in all the sighash modes.
>
> The major differences between simulating CTV via ANYPREVOUT and the actual
> CTV proposal is: (1) The cost of simulating CTV.  With CTV the spending
> transaction is committed using a hash of 32 bytes, while simulating it with
> ANYPREVOUT requires 64 bytes for a signature, and 32 bytes for some public
> key, plus a few more bytes for various flags.  Some of that cost could be
> reduced by using the inner public key (1 byte representation) and, if we
> had CAT, maybe by assembling the signature from reusable pieces (i.e.
> setting the nonce of the commited signature equal to the public key).
>
> The other major difference is: (2) CTV's transaction hash covers values
> such as the number of inputs in the transaction and their sequence numbers,
> which ANYPREVOUT does not cover.  CTV's hash contains enough information so
> that when combined with the missing TXIDs, you can compute the TXID of the
> spending transaction.  In particular if the number of inputs is committed
> to being 1, once the scriptpubkey's transaction id is known and committed
> to the blockchain, the TXID of its spending transaction is deducible.  And
> if that transaction has outputs that have CTV commitments in them, you can
> deduce their spending TXIDs in turn.  While this is a pretty neat feature,
> something that ANYPREVOUT cannot mimic, the main application for it is
> listed as using congestion control to fund lightning channels, fixing their
> TXIDs in advance of them being placed on chain.  However, if ANYPREVOUT
> were used to mimic CTV, then likely it would be eltoo channels that would
> be funded, and it isn't necessary to know the TXIDs of eltoo channels in
> advance in order to use them.
>
>
>
> An Alternative Proposal::
>
> Given the overlap in functionality between CTV and ANYPREVOUT, I think it
> makes sense to decompose their operations into their constituent pieces and
> reassemble their behaviour programmatically.  To this end, I'd like to
> instead propose OP_TXHASH and OP_CHECKSIGFROMSTACKVERIFY.
>
> OP_TXHASH would pop a txhash flag from the stack and compute a (tagged)
> txhash in accordance with that flag, and push the resulting hash onto the
> stack.
> OP_CHECKSIGFROMSTACKVERIFY would pop a pubkey, message, and signature from
> the stack and fail if the signature does not verify on that message.
>
> CTV and TXHASH have roughly equivalent functionality.  'CTV DROP' can be
> simulated by '<ctv_style_flag> TXHASH EQUALVERIFY'.  The reverse is also
> true where '<ctv_style_flag> TXHASH' can be simulated by CTV by
> '<ctv-result-from-witness-stack> CTV', however, as you can see, simulating
> TXHASH from CTV is much more expensive than the other way around, because
> the resulting 32-byte hash result must be included as part of the witness
> stack.
>
> '<anyprevout-pubkey> CHECKSIGVERIFY can be simulated by '<apo_style_flag>
> TXHASH <pubkey> CHECKSIGFROMSTACKVERIFY'.  Here we see the advantage of
> pushing the hash value onto the stack.  APO can be simulated without
> needing to include a copy of the resulting txhash inside the witness data.
>
> In addition to the CTV and ANYPREVOUT applications, with
> CHECKSIGFROMSTACKVERIFY we can verify signatures on arbitrary messages
> signed by oracles for oracle applications.  This is where we see the
> benefit of decomposing operations into primitive pieces.  By giving users
> the ability to program their own use cases from components, we get more
> applications out of fewer op codes!
>
>
>
> Caveats::
>
> First, I acknowledge that replicating the behaviour of CTV and ANYPREVOUT
> does cost a few more bytes than using the custom purpose built proposals
> themselves.  That is the price to be paid when we choose the ability to
> program solutions from pieces.  But we get to reap the advantages of being
> able to build more applications from these pieces.
>
> Unlike CTV, TXHASH is not NOP-compatable and can only be implemented
> within tapscript.  In particular, bare CTV isn't possible with this
> proposal.  However, this proposal doesn't preclude the possibility of
> having CTV added to legacy script in while having TXHASH added to tapscript.
>
> For similar reasons, TXHASH is not amenable to extending the set of
> txflags at a later date.  In theory, one could have TXHASH
> abort-with-success when encountering an unknown set of flags.  However,
> this would make analyzing tapscript much more difficult. Tapscripts would
> then be able to abort with success or failure depending on the order script
> fragments are assembled and executed, and getting the order incorrect would
> be catastrophic.  This behavior is manifestly different from the current
> batch of OP_SUCCESS opcodes that abort-with-success just by their mere
> presence, whether they would be executed or not.
>
> I believe the difficulties with upgrading TXHASH can be mitigated by
> designing a robust set of TXHASH flags from the start.  For example having
> bits to control whether (1) the version is covered; (2) the locktime is
> covered; (3) txids are covered; (4) sequence numbers are covered; (5) input
> amounts are covered; (6) input scriptpubkeys are covered; (7) number of
> inputs is covered; (8) output amounts are covered; (9) output scriptpubkeys
> are covered; (10) number of outputs is covered; (11) the tapbranch is
> covered; (12) the tapleaf is covered; (13) the opseparator value is
> covered; (14) whether all, one, or no inputs are covered; (15) whether all,
> one or no outputs are covered; (16) whether the one input position is
> covered; (17) whether the one output position is covered; (18) whether the
> sighash flags are covered or not (note: whether or not the sighash flags
> are or are not covered must itself be covered).  Possibly specifying which
> input or output position is covered in the single case and whether the
> position is relative to the input's position or is an absolute position.
>
> That all said, even if other txhash flag modes are needed in the future,
> adding TXHASH2 always remains an option.
>
>
>
> Interactions with potential future opcodes::
>
> We should give some consideration on how these opcodes may interact with
> future opcodes such as CAT, rolling SHA256 opcodes, or how it might
> interface with other covenant opcodes that may do things like, directly
> push input or output amounts onto the stack for computation purposes,
> opcodes which have been added to the Elements project.
>
> With CAT and/or rolling SHA256 opcodes and/or existing SHA256 opcodes, the
> CHECKSIGFROMSTACKVERIFY could verify signatures on programmatically
> assembled messages.  Also, in combination with multiple calls to TXHASH,
> could be used to create signatures that commit to complex subsets of
> transaction data.
>
> If new opcodes are added to push parts of the transaction data direction
> onto the stack, e.g. OP_INSPECTOUTPUTVALUE, there is perhaps concern that
> they would obsolete TXHASH, since, in the presence of rolling SHA256
> opcodes, TXHASH could be simulated.  However, given that TXHASH can
> compactly create a hash of large portions of transaction data, it seems
> unlikely that TXHASH would fall into disuse.  Also, a combination of TXHASH
> and transaction introspection opcodes can be used to build "*subtractive
> covenants*".
>
> The usual way of building a covenant, which we will call "*additive *
> *covenants*", is to push all the parts of the transaction data you would
> like to fix onto the stack, hash it all together, and verify the resulting
> hash matches a fixed value.  Another way of building covenants, which we
> will call "*subtractive covenants*", is to push all the parts of the
> transaction data you would like to remain free onto the stack.  Then use
> rolling SHA256 opcodes starting from a fixed midstate that commits to a
> prefix of the transaction hash data. The free parts are hashed into that
> midstate.  Finally, the resulting hash value is verified to match a value
> returned by TXHASH.  The ability to nicely build subtractive covenants
> depends on the details of how the TXHASH hash value is constructed,
> something that I'm told CTV has given consideration to.
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220126/ef2eb4e7/attachment-0001.html>

From thibaut at cryptogarage.co.jp  Thu Jan 27 00:45:12 2022
From: thibaut at cryptogarage.co.jp (Thibaut Le Guilly)
Date: Thu, 27 Jan 2022 09:45:12 +0900
Subject: [bitcoin-dev] [dlc-dev] CTV dramatically improves DLCs
In-Reply-To: <2b316504-f785-b1b3-9ff9-8d781d6c0d9b@gmail.com>
References: <CAH5Bsr2vxL3FWXnJTszMQj83jTVdRvvuVpimEfY7JpFCyP1AZA@mail.gmail.com>
 <2b316504-f785-b1b3-9ff9-8d781d6c0d9b@gmail.com>
Message-ID: <CABPZDUyMmyt0UCmHYfm+s-zs=iLjxXB0VtdJZ64X5HA3XLFESA@mail.gmail.com>

Hi,

Lloyd, thanks for this excellent writeup. I must say that indeed using CTV
seems like it would very much lower the complexity of the DLC protocol (and
it seems like APO would also work, thanks Jonas for pointing that out).
Though thinking about it, I can't help wondering if the ideal op code for
DLC wouldn't actually be CHECKSIGFROMSTACK? It feels to me that this would
give the most natural way of doing things. If I'm not mistaken, this would
enable simply requiring an oracle signature over the outcome, without any
special trick, and without even needing the oracle to release a nonce in
advance (the oracle could sign `event_outcome + event_id` to avoid
signature reuse). I must say that I haven't studied covenant opcodes in
detail yet so is that line of thinking correct or am I missing something?

Cheers,

Thibaut

On Wed, Jan 26, 2022 at 1:27 AM Jonas Nick via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Thank you, that's an interesting application of OP_CTV.
>
> Perhaps worth pointing out that this does not require OP_CTV but could
> also be
> enabled by other covenant constructions. For example, it seems like
> ANYPREVOUT-based covenants provide similar benefits. The script of the
> Taproot
> leaves could be set to
>
> <sig> <G> CHECKSIGVERIFY <CET_i> CHECKSIGVERIFY
>
> where <sig> is an ANYPREVOUTANYSCRIPT signature of the CET for public key
> P = G.
> When using nonce R = G, signature creation has negligible computational
> cost (s
> = 1 + H(R, P, m)). A downside compared to CTV is the additional overhead
> of 64
> witness bytes (<sig>).
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220127/6f228196/attachment-0001.html>

From jamtlu at gmail.com  Thu Jan 27 04:20:40 2022
From: jamtlu at gmail.com (James Lu)
Date: Wed, 26 Jan 2022 23:20:40 -0500
Subject: [bitcoin-dev] TXHASH + CHECKSIGFROMSTACKVERIFY in lieu of CTV
	and ANYPREVOUT
In-Reply-To: <CAD5xwhhwqJ_AETAb3p_zUZmRX-Dzh8J9G984zwEs=KFsGN8aNQ@mail.gmail.com>
References: <CAMZUoK=pkZuovtifBzdqhoyegzG+9hRTFEc7fG9nZPDK4KbU3w@mail.gmail.com>
 <CAD5xwhhwqJ_AETAb3p_zUZmRX-Dzh8J9G984zwEs=KFsGN8aNQ@mail.gmail.com>
Message-ID: <CANQHGB11yBUB4Z8tD8pxVhhDREtYRj-kx-NymsgtnPO3R4Eomg@mail.gmail.com>

What if OP_TXHASH is a no op except for the purpose of emulating CTV and
APO?

On Wed, Jan 26, 2022 at 5:16 PM Jeremy via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Hi Russell,
>
> Thanks for this email, it's great to see this approach described.
>
> A few preliminary notes of feedback:
>
> 1) a Verify approach can be made to work for OP_TXHASH (even with CTV
> as-is) E.g., suppose a semantic added for a single byte stack[-1] sighash
> flag to read the hash at stack[-2], then the hash can be passed in instead
> of put on the stack. This has the disadvantage of larger witnesses, but the
> advantage of allowing undefined sighash flags to pass for any hash type.
> 2) using the internal key for APO covenants is not an option because it
> makes transaction construction interactive and precludes contracts with a
> NUMS point taproot key. Instead, if you want similar savings, you should
> advocate an OP_GENERATOR which puts G on the stack. Further, an untagged
> APO variant which has split R and S values would permit something like
> <sig> OP_GENERATOR OP_GENERATOR CHECKSIGAPO, which would be only 2 more
> bytes than CTV.
> 3) I count something like 20 different flags in your proposal. As long as
> flags are under 40 bytes (and 32 assuming we want it to be easy) without
> upgrading math this should be feasible to manipulate on the stack
> programmatically. This is ignoring some of the more flexible additions you
> mention about picking which outputs/inputs are included. However, 20 flags
> means that for testing we would want comprehensive tests and understanding
> for ~1 million different flag combos and the behaviors they expose. I think
> this necessitates a formal model of scripting and transaction validity
> properties. Are there any combinations that might be undesirable?
> 4) Just hashing or not hashing isn't actually that flexible, because it
> doesn't natively let you do things like (for example) TLUV. You really do
> need tx operations for directly manipulating the data on the stack to
> construct the hash if you want more flexible covenants. This happens to be
> compatible with either a Verify or Push approach, since you either
> destructure a pushed hash or build up a hash for a verify.
> 5) Flexible hashing has the potential for quadratic hashing bugs. The
> fields you propose seem to be within similar range to work you could cause
> with a regular OP_HASH256, although you'd want to be careful with some of
> the proposed extensions that you don't create risk of quadratic hashing,
> which seems possible with an output selecting opcode unless you cache
> properly (which might be tricky to do). Overall for the fields explicitly
> mentioned, seems safe, the "possibles" seem to have some more complex
> interactions. E.g., CTV with the ability to pick a subset of outputs would
> be exposed to quadratic hashing.
> 6) Missing field: covering the annex or some sub-range of the annex
> (quadratic hashing issues on the latter)
> 7) It seems simpler to, for many of these fields, push values directly (as
> in OP_PUSHTXDATA from Johnson Lau) because the combo of flags to push the
> hash of a single output's amount to emulate OP_AMOUNT looks 'general but
> annoying'. It may make more sense to do the OP_PUSHTXDATA style opcode
> instead. This also makes it simpler to think about the combinations of
> flags, since it's really N independent multi-byte opcodes.
>
>
> Ultimately if we had OP_TXHASH available "tomorrow", I would be able to
> build out the use cases I care about for CTV (and more). So I don't have an
> opposition on it with regards to lack of function.
>
> However, if one finds the TXHASH approach acceptable, then you should also
> be relatively fine doing APO, CTV, CSFS, TXHASH acceptable in any order
> (whenever "ready"), unless you are particularly sensitive to "technical
> debt" and "soft fork processes". The only costs of doing something for CTV
> or APO given an eventual TXHASH is perhaps a wasted key version or the 32
> byte argument of a NOP opcode and some code to maintain.
>
> Are there other costs I am missing?
>
> However, as it pertains to actual rollout:
>
> - OP_TXHASH+CSFSV doesn't seem to be the "full" set of things needed (we
> still need e.g. OP_CAT, Upgraded >=64 bit Math, TLUV or OP_TWEAK
> OP_TAPBRANCH OP_MANIPULATETAPTREE, and more) to full realize covenanting
> power it intends to introduce.
> - What sort of timeline would it take to ready something like TXHASH (and
> desired friends) given greater scope of testing and analysis (standalone +
> compared to CTV)?
> - Is there opposition from the community to this degree of
> general/recursive covenants?
> - Does it make "more sense" to invest the research and development effort
> that would go into proving TXHASH safe, for example, into Simplicity
> instead?
>
> Overall, *my opinion *is that:
>
> - TXHASH is an acceptable theoretical approach, and I am happy to put more
> thought into it and maybe draft a prototype of it.
> - I prefer CTV as a first step for pragmatic engineering and availability
> timeline reasons.
> - If TXHASH were to take, optimistically, 2 years to develop and review,
> and then 1 year to activate, the "path dependence of software" would put
> Bitcoin in a much better place were we to have CTV within 1 year and
> applications (that are to be a subset of TXHASH later) being built over the
> next few years enhanced in the future by TXHASH's availability.
> - There is an element of expediency meritted for something like CTV
> insofar as it provides primitives to tackle time sensitive issues around
> privacy, scalability, self custody, and decentralization. The
> aforementioned properties may be difficult to reclaim once given away (with
> the exception of perhaps scalability).
> - Bringing CTV to an implemented state of near-unanimous "we could do
> this, technically" is good for concretely driving the process of review for
> any covenant proposals forward, irrespective of if we ultimately activate.
> (I.e., if there were a reason we could not do CTV safely, it would likely
> have implications for any other future covenant)
>
> Concretely, I'm not going to stop advocating for CTV based on the above,
> but I'm very happy to have something new in the mix to consider!
>
> Best,
>
> Jeremy
>
>
> --
> @JeremyRubin <https://twitter.com/JeremyRubin>
> <https://twitter.com/JeremyRubin>
>
>
> On Wed, Jan 26, 2022 at 9:23 AM Russell O'Connor via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>> Recapping the relationship between CTV and ANYPREVOUT::
>>
>> It is known that there is a significant amount of overlap in the
>> applications that are enabled by the CTV and ANYPREVOUT proposals despite
>> the fact that their primary applications (congestion control for CTV and
>> eltoo lightning channels for ANYPREVOUT) are quite distinct.
>> In particular, ANYPREVOUT can enable most of the applications of CTV,
>> albeit with a higher cost.  The primary functionality of CTV is to allow a
>> scriptPubKey to make a commitment to its spending transaction's hash with
>> the input's TXID excluded from the hash.  This exclusion is necessary
>> because the scriptPubKey is hashed into the input's TXID, and including the
>> TXID would cause a cycle of hash commitments, which is impossible to
>> construct.  On the other hand, ANYPREVOUT defines a signature hash mode
>> that similarly excludes the inputs TXID for its purpose of rebindable
>> signatures.
>>
>> This means that ANYPREVOUT can mimic most of the properties of CTV by
>> committing both a public key along with an ANYPREVOUT signature inside
>> scriptPubKey.  In fact, the only reason Bitcoin doesn't have covenants
>> today is due to this cycle between scriptPubKeys and the TXIDs that occur
>> in all the sighash modes.
>>
>> The major differences between simulating CTV via ANYPREVOUT and the
>> actual CTV proposal is: (1) The cost of simulating CTV.  With CTV the
>> spending transaction is committed using a hash of 32 bytes, while
>> simulating it with ANYPREVOUT requires 64 bytes for a signature, and 32
>> bytes for some public key, plus a few more bytes for various flags.  Some
>> of that cost could be reduced by using the inner public key (1 byte
>> representation) and, if we had CAT, maybe by assembling the signature from
>> reusable pieces (i.e. setting the nonce of the commited signature equal to
>> the public key).
>>
>> The other major difference is: (2) CTV's transaction hash covers values
>> such as the number of inputs in the transaction and their sequence numbers,
>> which ANYPREVOUT does not cover.  CTV's hash contains enough information so
>> that when combined with the missing TXIDs, you can compute the TXID of the
>> spending transaction.  In particular if the number of inputs is committed
>> to being 1, once the scriptpubkey's transaction id is known and committed
>> to the blockchain, the TXID of its spending transaction is deducible.  And
>> if that transaction has outputs that have CTV commitments in them, you can
>> deduce their spending TXIDs in turn.  While this is a pretty neat feature,
>> something that ANYPREVOUT cannot mimic, the main application for it is
>> listed as using congestion control to fund lightning channels, fixing their
>> TXIDs in advance of them being placed on chain.  However, if ANYPREVOUT
>> were used to mimic CTV, then likely it would be eltoo channels that would
>> be funded, and it isn't necessary to know the TXIDs of eltoo channels in
>> advance in order to use them.
>>
>>
>>
>> An Alternative Proposal::
>>
>> Given the overlap in functionality between CTV and ANYPREVOUT, I think it
>> makes sense to decompose their operations into their constituent pieces and
>> reassemble their behaviour programmatically.  To this end, I'd like to
>> instead propose OP_TXHASH and OP_CHECKSIGFROMSTACKVERIFY.
>>
>> OP_TXHASH would pop a txhash flag from the stack and compute a (tagged)
>> txhash in accordance with that flag, and push the resulting hash onto the
>> stack.
>> OP_CHECKSIGFROMSTACKVERIFY would pop a pubkey, message, and signature
>> from the stack and fail if the signature does not verify on that message.
>>
>> CTV and TXHASH have roughly equivalent functionality.  'CTV DROP' can be
>> simulated by '<ctv_style_flag> TXHASH EQUALVERIFY'.  The reverse is also
>> true where '<ctv_style_flag> TXHASH' can be simulated by CTV by
>> '<ctv-result-from-witness-stack> CTV', however, as you can see, simulating
>> TXHASH from CTV is much more expensive than the other way around, because
>> the resulting 32-byte hash result must be included as part of the witness
>> stack.
>>
>> '<anyprevout-pubkey> CHECKSIGVERIFY can be simulated by '<apo_style_flag>
>> TXHASH <pubkey> CHECKSIGFROMSTACKVERIFY'.  Here we see the advantage of
>> pushing the hash value onto the stack.  APO can be simulated without
>> needing to include a copy of the resulting txhash inside the witness data.
>>
>> In addition to the CTV and ANYPREVOUT applications, with
>> CHECKSIGFROMSTACKVERIFY we can verify signatures on arbitrary messages
>> signed by oracles for oracle applications.  This is where we see the
>> benefit of decomposing operations into primitive pieces.  By giving users
>> the ability to program their own use cases from components, we get more
>> applications out of fewer op codes!
>>
>>
>>
>> Caveats::
>>
>> First, I acknowledge that replicating the behaviour of CTV and ANYPREVOUT
>> does cost a few more bytes than using the custom purpose built proposals
>> themselves.  That is the price to be paid when we choose the ability to
>> program solutions from pieces.  But we get to reap the advantages of being
>> able to build more applications from these pieces.
>>
>> Unlike CTV, TXHASH is not NOP-compatable and can only be implemented
>> within tapscript.  In particular, bare CTV isn't possible with this
>> proposal.  However, this proposal doesn't preclude the possibility of
>> having CTV added to legacy script in while having TXHASH added to tapscript.
>>
>> For similar reasons, TXHASH is not amenable to extending the set of
>> txflags at a later date.  In theory, one could have TXHASH
>> abort-with-success when encountering an unknown set of flags.  However,
>> this would make analyzing tapscript much more difficult. Tapscripts would
>> then be able to abort with success or failure depending on the order script
>> fragments are assembled and executed, and getting the order incorrect would
>> be catastrophic.  This behavior is manifestly different from the current
>> batch of OP_SUCCESS opcodes that abort-with-success just by their mere
>> presence, whether they would be executed or not.
>>
>> I believe the difficulties with upgrading TXHASH can be mitigated by
>> designing a robust set of TXHASH flags from the start.  For example having
>> bits to control whether (1) the version is covered; (2) the locktime is
>> covered; (3) txids are covered; (4) sequence numbers are covered; (5) input
>> amounts are covered; (6) input scriptpubkeys are covered; (7) number of
>> inputs is covered; (8) output amounts are covered; (9) output scriptpubkeys
>> are covered; (10) number of outputs is covered; (11) the tapbranch is
>> covered; (12) the tapleaf is covered; (13) the opseparator value is
>> covered; (14) whether all, one, or no inputs are covered; (15) whether all,
>> one or no outputs are covered; (16) whether the one input position is
>> covered; (17) whether the one output position is covered; (18) whether the
>> sighash flags are covered or not (note: whether or not the sighash flags
>> are or are not covered must itself be covered).  Possibly specifying which
>> input or output position is covered in the single case and whether the
>> position is relative to the input's position or is an absolute position.
>>
>> That all said, even if other txhash flag modes are needed in the future,
>> adding TXHASH2 always remains an option.
>>
>>
>>
>> Interactions with potential future opcodes::
>>
>> We should give some consideration on how these opcodes may interact with
>> future opcodes such as CAT, rolling SHA256 opcodes, or how it might
>> interface with other covenant opcodes that may do things like, directly
>> push input or output amounts onto the stack for computation purposes,
>> opcodes which have been added to the Elements project.
>>
>> With CAT and/or rolling SHA256 opcodes and/or existing SHA256 opcodes,
>> the CHECKSIGFROMSTACKVERIFY could verify signatures on programmatically
>> assembled messages.  Also, in combination with multiple calls to TXHASH,
>> could be used to create signatures that commit to complex subsets of
>> transaction data.
>>
>> If new opcodes are added to push parts of the transaction data direction
>> onto the stack, e.g. OP_INSPECTOUTPUTVALUE, there is perhaps concern that
>> they would obsolete TXHASH, since, in the presence of rolling SHA256
>> opcodes, TXHASH could be simulated.  However, given that TXHASH can
>> compactly create a hash of large portions of transaction data, it seems
>> unlikely that TXHASH would fall into disuse.  Also, a combination of TXHASH
>> and transaction introspection opcodes can be used to build "*subtractive
>> covenants*".
>>
>> The usual way of building a covenant, which we will call "*additive *
>> *covenants*", is to push all the parts of the transaction data you would
>> like to fix onto the stack, hash it all together, and verify the resulting
>> hash matches a fixed value.  Another way of building covenants, which we
>> will call "*subtractive covenants*", is to push all the parts of the
>> transaction data you would like to remain free onto the stack.  Then use
>> rolling SHA256 opcodes starting from a fixed midstate that commits to a
>> prefix of the transaction hash data. The free parts are hashed into that
>> midstate.  Finally, the resulting hash value is verified to match a value
>> returned by TXHASH.  The ability to nicely build subtractive covenants
>> depends on the details of how the TXHASH hash value is constructed,
>> something that I'm told CTV has given consideration to.
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220126/5c9e6887/attachment-0001.html>

From gloriajzhao at gmail.com  Thu Jan 27 13:42:09 2022
From: gloriajzhao at gmail.com (Gloria Zhao)
Date: Thu, 27 Jan 2022 13:42:09 +0000
Subject: [bitcoin-dev] Improving RBF Policy
Message-ID: <CAFXO6=LGbaur6XQrE+6a6mAAHXduOCXoWPTgPosxAG59ZkK6Gg@mail.gmail.com>

Hi everyone,

This post discusses limitations of current Bitcoin Core RBF policy and
attempts to start a conversation about how we can improve it,
summarizing some ideas that have been discussed. Please reply if you
have any new input on issues to be solved and ideas for improvement!

Just in case I've screwed up the text wrapping again, another copy can be
found here: https://gist.github.com/glozow/25d9662c52453bd08b4b4b1d3783b9ff

## Background

Please feel free to skip this section if you are already familiar
with RBF.

Nodes may receive *conflicting* unconfirmed transactions, aka
"double spends" of the same inputs. Instead of always keeping the
first transaction, since v0.12, Bitcoin Core mempool policy has
included a set of Replace-by-Fee (RBF) criteria that allows the second
transaction to replace the first one and any descendants it may have.

Bitcoin Core RBF policy was previously documented as BIP 125.
The current RBF policy is documented [here][1]. In summary:

1. The directly conflicting transactions all signal replaceability
   explicitly.

2. The replacement transaction only includes an unconfirmed input if
   that input was included in one of the directly conflicting
transactions.

3. The replacement transaction pays an absolute fee of at least the
   sum paid by the original transactions.

4. The additional fees pays for the replacement transaction's
   bandwidth at or above the rate set by the node's *incremental relay
feerate*.

5. The sum of all directly conflicting transactions' descendant counts
   (number of transactions inclusive of itself and its descendants)
does not exceed 100.

We can split these rules into 3 categories/goals:

- **Allow Opting Out**: Some applications/businesses are unable to
  handle transactions that are replaceable (e.g. merchants that use
zero-confirmation transactions). We (try to) help these businesses by
honoring BIP125 signaling; we won't replace transactions that have not
opted in.

- **Incentive Compatibility**: Ensure that our RBF policy would not
  accept replacement transactions which would decrease fee profits
  of a miner. In general, if our mempool policy deviates from what is
economically rational, it's likely that the transactions in our
mempool will not match the ones in miners' mempools, making our
fee estimation, compact block relay, and other mempool-dependent
functions unreliable. Incentive-incompatible policy may also
encourage transaction submission through routes other than the p2p
network, harming censorship-resistance and privacy of Bitcoin payments.

- **DoS Protection**: Limit two types of DoS attacks on the node's
  mempool: (1) the number of times a transaction can be replaced and
(2) the volume of transactions that can be evicted during a
replacement.

Even more abstract: our goal is to make a replacement policy that
results in a useful interface for users and safe policy for
node operators.

## Motivation

There are a number of known problems with the current RBF policy.
Many of these shortcomings exist due to mempool limitations at the
time RBF was implemented or result from new types of Bitcoin usage;
they are not criticisms of the original design.

### Pinning Attacks

The most pressing concern is that attackers may take advantage of
limitations in RBF policy to prevent other users' transactions from
being mined or getting accepted as a replacement.

#### SIGHASH_ANYONECANPAY Pinning

BIP125#2 can be bypassed by creating intermediary transactions to be
replaced together. Anyone can simply split a 1-input 1-output
transaction off from the replacement transaction, then broadcast the
transaction as is. This can always be done, and quite cheaply. More
details in [this comment][2].

In general, if a transaction is signed with SIGHASH\_ANYONECANPAY,
anybody can just attach a low feerate parent to this transaction and
lower its ancestor feerate.  Even if you require SIGHASH\_ALL which
prevents an attacker from changing any outputs, the input can be a
very low amount (e.g. just above the dust limit) from a low-fee
ancestor and still bring down the ancestor feerate of the transaction.

TLDR: if your transaction is signed with SIGHASH\_ANYONECANPAY and
signals replaceability, regardless of the feerate you broadcast at, an
attacker can lower its mining priority by adding an ancestor.

#### Absolute Fee

The restriction of requiring replacement transactions to increase the
absolute fee of the mempool has been described as "bonkers." If the
original transaction has a very large descendant that pays a large
amount of fees, even if it has a low feerate, the replacement
transaction must now pay those fees in order to meet Rule #3.

#### Package RBF

There are a number of reasons why, in order to enable Package RBF, we
cannot use the same criteria.

For starters, the absolute fee pinning attack is especially
problematic if we apply the same rules (i.e. Rule #3 and #4) in
Package RBF. Imagine that Alice (honest) and Bob (adversary) share a
LN channel. The mempool is rather full, so their pre-negotiated
commitment transactions' feerates would not be considered high
priority by miners.  Bob broadcasts his commitment transaction and
attaches a very large child (100KvB with 100,000sat in fees) to his
anchor output. Alice broadcasts her commitment transaction with a
fee-bumping child (200vB with 50,000sat fees which is a generous
250sat/vB), but this does not meet the absolute fee requirement. She
would need to add another 50,000sat to replace Bob's commitment
transaction.

Disallowing new unconfirmed inputs (Rule #2) in Package RBF would be
broken for packages containing transactions already in the mempool,
explained [here][7].

Note: I originally [proposed][6] Package RBF using the same Rule #3
and #4 before I realized how significant this pinning attack is. I'm
retracting that proposal, and a new set of Package RBF rules would
follow from whatever the new individual RBF rules end up being.

#### Same Txid Different Witness

Two transactions with the same non-witness data but different
witnesses have the same txid but different wtxid, and the same fee but
not necessarily the same feerate. Currently, if we see a transaction
that has the same txid as one in the mempool, we reject it as a
duplicate, even if the feerate is much higher. It's unclear to me if
we have a very strong reason to change this, but noting it as a
limitation of our current replacement policy. See [#24007][12].

### User Interface

#### Using Unconfirmed UTXOs to Fund Replacements

The restriction of only allowing confirmed UTXOs for funding a
fee-bump (Rule #2) can hurt users trying to fee-bump their
transactions and complicate wallet implementations. If the original
transaction's output value isn't sufficient to fund a fee-bump and/or
all of the user's other UTXOs are unconfirmed, they might not be able
to fund a replacement transaction. Wallet developers also need to
treat self-owned unconfirmed UTXOs as unusable for fee-bumping, which
adds complexity to wallet logic. For example, see BDK issues [#144][4]
and [#414][5].

#### Interface Not Suitable for Coin Selection

Currently, a user cannot simply create a replacement transaction
targeting a specific feerate or meeting a minimum fee amount and
expect to meet the RBF criteria. The fee amount depends on the size of
the replacement transaction, and feerate is almost irrelevant.

Bitcoin Core's `bumpfee` doesn't use the RBF rules when funding the
replacement. It [estimates][13] a feerate which is "wallet incremental
relay fee" (a conservative overestimation of the node's incremental
relay fee) higher than the original transaction, selects coins for
that feerate, and hopes that it meets the RBF rules. It never fails
Rule #3 and #4 because it uses all original inputs and refuses to
bump a transaction with mempool descendants.

This is suboptimal, but is designed to work with the coin selection
engine: select a feerate first, and then add fees to cover it.
Following the exact RBF rules would require working the other way
around: based on how much fees we've added to the transaction and its
current size, calculate the feerate to see if we meet Rule #4.

While this isn't completely broken, and the user interface is
secondary to the safety of the mempool policy, we can do much better.
A much more user-friendly interface would depend *only* on the
fee and size of the original transactions.

### Updates to Mempool and Mining

Since RBF was first implemented, a number of improvements have been
made to mempool and mining logic. For example, we now use ancestor
feerates in mining (allowing CPFP), and keep track of ancestor
packages in the mempool.

## Ideas for Improvements

### Goals

To summarize, these seem to be desired changes, in order of priority:

1. Remove Rule #3. The replacement should not be *required* to pay
higher absolute fees.

2. Make it impossible for a replacement transaction to have a lower
mining score than the original transaction(s). This would eliminate
the `SIGHASH\_ANYONECANPAY` pinning attack.

3. Remove Rule #2. Adding new unconfirmed inputs should be allowed.

4. Create a more helpful interface that helps wallet fund replacement
transactions that aim for a feerate and fee.

### A Different Model for Fees

For incentive compatibility, I believe there are different
formulations we should consider.  Most importantly, if we want to get
rid of the absolute fee rule, we can no longer think of it as "the
transaction needs to pay for its own bandwidth," since we won't always
be getting additional fees. That means we need a new method of
rate-limiting replacements that doesn't require additional fees every
time.

While it makes sense to think about monetary costs when launching a
specific type of attack, given that the fees are paid to the miner and
not to the mempool operators, maybe it doesn't make much sense to
think about "paying for bandwidth". Maybe we should implement
transaction validation rate-limiting differently, e.g. building it
into the P2P layer instead of the mempool policy layer.

Recently, Suhas gave a [formulation][8] for incentive compatibility
that made sense to me: "are the fees expected to be paid in the next
(N?) blocks higher or lower if we process this transaction?"

I started by thinking about this where N=1 or `1 + p`.
Here, a rational miner is looking at what fees they would
collect in the next block, and then some proportion `p` of the rest of
the blocks based on their hashrate. We're assuming `p` isn't *so high*
that they would be okay with lower absolute fees in the next 1 block.
We're also assuming `p` isn't *so low* that the miner doesn't care
about what's left of the mempool after this block.

A tweak to this formulation is "if we process this transaction, would
the fees in the next 1 block higher or lower, and is the feerate
density of the rest of the mempool higher or lower?" This is pretty
similar, where N=1, but we consider the rest of the mempool by feerate
rather than fees.

### Mining Score of a Mempool Transaction

We are often interested in finding out what
the "mining score" of a transaction in the mempool is. That is, when
the transaction is considered in block template building, what is the
feerate it is considered at?

Obviously, it's not the transaction's individual feerate. Bitcoin Core
[mining code sorts][14] transactions by their ancestor feerate and
includes them packages at a time, keeping track of how this affects the
package feerates of remaining transactions in the mempool.

*ancestor feerate*: Ancestor feerate is easily accessible information,
but it's not accurate either, because it doesn't take into account the
fact that subsets of a transaction's ancestor set can be included
without it. For example, ancestors may have high feerates on their own
or we may have [high feerate siblings][8].

TLDR: *Looking at the current ancestor feerate of a transaction is
insufficient to tell us what feerate it will be considered at when
building a block template in the future.*

*min(individual feerate, ancestor feerate)*: Another
heuristic that is simple to calculate based on current mempool tooling
is to use the [minimum of a transaction's individual score and its
ancestor score][10] as a conservative measure.  But this can
overestimate as well (see the example below).

*min ancestor feerate(tx + possible ancestor subsets)* We can also
take the minimum of every possible ancestor subset, but this can be
computationally expensive since there can be lots and lots of ancestor
subsets.

*max ancestor feerate(tx + possible descendant subsets)*: Another idea
is to use the [maximum ancestor score of the transaction + each of its
descendants][9]. This doesn't work either; it has the same blindspot
of ancestor subsets being mined on their own.

#### Mining Score Example

Here's an example illustrating why mining score is tricky to
efficiently calculate for mempool transactions:

Let's say you have same-size transactions A (21sat/vB), B (1sat/vB),
C(9sat/vB), D(5sat/vB).
The layout is: grandparent A, parent B, and two children C and D.

```
    A
    ^
    B
   ^ ^
   C D
```

A miner using ancestor packages to build block templates will first
include A with a mining score of 21. Next, the miner will include B and
C with a mining score of 6. This leaves D, with a mining score of 5.

Note: in this case, mining by ancestor feerate results in the most
rational decisions, but [a candidate set-based approach][10] which
makes ancestor feerate much less relevant could
be more advantageous in other situations.

Here is a chart showing the "true" mining score alongside the values
calculating using imperfect heuristics described above. All of them
can overestimate or underestimate.

```
   A     B       C     D
mining score |   21   |   6   |   6   |   5   |
ancestor feerate   |   21   |  11   | 10.3  |   9   |
min(individual, ancestor) |   21   |   1   |   9   |   5   |
min(tx + ancestor subsets)      |   21   |   1   |   5   |   3   |
max(tx + descendants subsets) |   21   |   9   |   9   |   5   |

```

Possibly the best solution for finding the "mining score" of a
transaction is to build a block template, see what feerate each
package is included at. Perhaps at some cutoff, remaining mempool
transactions can be estimated using some heuristic that leans
{overestimating, underestimating} depending on the situation.

Mining score seems to be relevant in multiple places: Murch and I
recently [found][3] that it would be very important in
"ancestor-aware" funding of transactions (the wallet doesn't
incorporate ancestor fees when using unconfirmed transactions in coin
selection, which is a bug we want to fix).

In general, it would be nice to know the exact mining priority of
one's unconfirmed transaction is.  I can think of a few block/mempool
explorers who might want to display this information for users.

### RBF Improvement Proposals

After speaking to quite a few people, here are some suggestions
for improvements that I have heard:

* The ancestor score of the replacement must be {5, 10, N}% higher
  than that of every original transaction.

* The ancestor score of the replacement must be 1sat/vB higher than
  that of every original transaction.

* If the original transaction is in the top {0.75MvB, 1MvB} of the
  mempool, apply the current rules (absolute fees must increase and
pay for the replacement transaction's new bandwidth). Otherwise, use a
feerate-only rule.

* If fees don't increase, the size of the replacement transaction must
  decrease by at least N%.

* Rate-limit how many replacements we allow per prevout.

* Rate-limit transaction validation in general, per peer.

Perhaps some others on the mailing list can chime in to throw other
ideas into the ring and/or combine some of these rules into a sensible
policy.

#### Replace by Feerate Only

I don't think there's going to be a single-line feerate-based
rule that can incorporate everything we need.
On one hand, a feerate-only approach helps eliminate the issues
associated with Rule #3. On the other hand, I believe the main concern
with a feerate-only approach is how to rate limit replacements. We
don't want to enable an attack such as:

1. Attacker broadcasts large, low-feerate transaction, and attaches a
chain of descendants.

2. The attacker replaces the transaction with a smaller but higher
feerate transaction, attaching a new chain of descendants.

3. Repeat 1000 times.

#### Fees in Next Block and Feerate for the Rest of the Mempool

Perhaps we can look at replacements like this:

1. Calculate the directly conflicting transactions and, with their
descendants, the original transactions. Check signaling. Limit the
total volume (e.g. can't be more than 100 total or 1MvB or something).

2. Find which original transactions would be in the next ~1 block. The
replacement must pay at least this amount + X% in absolute fees. This
guarantees that the fees of the next block doesn't decrease.

3. Find which transactions would be left in the mempool after that ~1
block. The replacement's feerate must be Y% higher than the maximum
mining score of these transactions. This guarantees that you now have
only *better* candidates in your after-this-block mempool than you did
before, even if the size and fees the transactions decrease.

4. Now you have two numbers: a minimum absolute fee amount and a
minimum feerate. Check to see if the replacement(s) meet these
minimums. Also, a wallet would be able to ask the node "What fee and
feerate would I need to put on a transaction replacing this?" and use
this information to fund a replacement transaction, without needing to
guess or overshoot.

Obviously, there are some magic numbers missing here. X and Y are
TBD constants to ensure we have some kind of rate limiting for the
number of replacements allowed using some set of fees.

What should they be? We can do some arithmetic to see what happens if
you start with the biggest/lowest feerate transaction and do a bunch
of replacements. Maybe we end up with values that are high enough to
prevent abuse and make sense for applications/users that do RBF.

### Mempool Changes Need for Implementation

As described in the mining score section above,
we may want additional tooling to more accurately assess
the economic gain of replacing transactions in our mempool.

A few options have been discussed:

* Calculate block templates on the fly when we need to consider a
  replacement. However, since replacements are [quite common][11]
  and the information might be useful for other things as well,
  it may be worth it to cache a block template.

* Keep a persistent block template so that we know what transactions
  we would put in the next block. We need to remember the feerate
at which each transaction was included in the template, because an
ancestor package may be included in the same block template in
multiple subsets. Transactions included earlier alter the ancestor
feerate of the remaining transactions in the package. We also need
to keep track of the new feerates of transactions left over.

* Divide the mempool into two layers, "high feerate" and "low
  feerate." The high feerate layer contains ~1 block of packages with
the highest ancestor feerates, and the low feerate layer contains
everything else. At the edge of a block, we have a Knapsacky problem
where the next highest ancestor feerate package might not fit, so we
would probably want the high feerate layer ~2MvB or something to avoid
underestimating the fees.

## Acknowledgements

Thank you to everyone whose RBF-related suggestions, grievances,
criticisms and ideas were incorporated in this document:
Andrew Chow, Matt Corallo, Suhas Daftuar, Christian Decker,
Mark Erhardt, Lloyd Fournier, Lisa Neigut, John Newbery,
Antoine Poinsot, Antoine Riard, Larry Ruane,
S3RK and Bastien Teinturier.

Thanks for reading!

Best,
Gloria

[1]:
https://github.com/bitcoin/bitcoin/blob/master/doc/policy/mempool-replacements.md
[2]: https://github.com/bitcoin/bitcoin/pull/23121#issuecomment-929475999
[3]:
https://github.com/Xekyo/bitcoin/commit/d754b0242ec69d42c570418aebf9c1335af0b8ea
[4]: https://github.com/bitcoindevkit/bdk/issues/144
[5]: https://github.com/bitcoindevkit/bdk/issues/414
[6]:
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019464.html
[7]:
https://gist.github.com/glozow/dc4e9d5c5b14ade7cdfac40f43adb18a#new-unconfirmed-inputs-rule-2
[8]: https://github.com/bitcoin/bitcoin/pull/23121#discussion_r777131366
[9]: https://github.com/bitcoin/bitcoin/pull/22290#issuecomment-865887922
[10]:
https://gist.github.com/Xekyo/5cb413fe9f26dbce57abfd344ebbfaf2#file-candidate-set-based-block-building-md
[11]: https://github.com/bitcoin/bitcoin/pull/22539#issuecomment-885763670
[12]: https://github.com/bitcoin/bitcoin/pull/24007
[13]:
https://github.com/bitcoin/bitcoin/blob/1a369f006fd0bec373b95001ed84b480e852f191/src/wallet/feebumper.cpp#L114
[14]:
https://github.com/bitcoin/bitcoin/blob/cf5bb048e80d4cde8828787b266b7f5f2e3b6d7b/src/node/miner.cpp#L310-L320
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220127/ec8ff818/attachment-0001.html>

From roconnor at blockstream.com  Thu Jan 27 19:16:33 2022
From: roconnor at blockstream.com (Russell O'Connor)
Date: Thu, 27 Jan 2022 14:16:33 -0500
Subject: [bitcoin-dev] TXHASH + CHECKSIGFROMSTACKVERIFY in lieu of CTV
	and ANYPREVOUT
In-Reply-To: <CAD5xwhhwqJ_AETAb3p_zUZmRX-Dzh8J9G984zwEs=KFsGN8aNQ@mail.gmail.com>
References: <CAMZUoK=pkZuovtifBzdqhoyegzG+9hRTFEc7fG9nZPDK4KbU3w@mail.gmail.com>
 <CAD5xwhhwqJ_AETAb3p_zUZmRX-Dzh8J9G984zwEs=KFsGN8aNQ@mail.gmail.com>
Message-ID: <CAMZUoKmU1cwUAQaBv5m8oo8H3TWBvgsZ_OkQaMC0n0+3cpFtWg@mail.gmail.com>

I am sensitive to technical debt and soft fork processes, and I don't
believe I'm unordinary particular about these issues.  Once implemented,
opcodes must be supported and maintained indefinitely.  Some opcodes are
easier to maintain than others.  These particular opcodes involve caching
of hash computations and, for that reason, I would judge them to be of
moderate complexity.

But more importantly, soft-forks are inherently a risky process, so we
should be getting as much value out of them as we reasonably can. I don't
think implementing a CTV opcode that we expect to largely be obsoleted by a
TXHASH at a later date is yielding good value from a soft fork process.

The strongest argument I can make in favour of CTV would be something like:
"We definitely want bare CTV and if we are going to add CTV to legacy
script (since we cannot use TXHASH in legacy script), then it is actually
easier not to exclude it from tapscript, even if we plan to add TXHASH to
tapscript as well."

But that argument basically rests the entire value of CTV on the shoulders
of bare CTV.  As I understand, the argument for why we want bare CTV,
instead of just letting people use tapscript, involves the finer details of
weight calculations, and I haven't really reviewed that aspect yet.  I
think it would need to be pretty compelling to make it worthwhile to add
CTV for that one use case.


Regarding "OP_TXHASH+CSFSV doesn't seem to be the 'full' set of things
needed", I totally agree we will want more things such as CAT, rolling
SHA256 opcodes, wider arithmetic, pushing amounts onto the stack, some kind
of tapleaf manipulation and/or TWEAKVERIFY.  For now, I only want to argue
TXHASH+CSFSV is better than CTV+APO because it gives us more value, namely
oracle signature verification.  In particular, I want to argue that
TXHASH's push semantics is better that CTV's verify semantics because it
composes better by not needing to carry an extra 32-bytes (per instance) in
the witness data.  I expect that in a world of full recursive covenants,
TXHASH would still be useful as a fast and cheap way to verify the
"payload" of these covenants, i.e. that a transaction is paying a certain,
possibly large, set of addresses certain specific amounts of money.  And
even if not, TXHASH+CSFSV would still be the way that eltoo would be
implemented under this proposal.

On Wed, Jan 26, 2022 at 5:16 PM Jeremy <jlrubin at mit.edu> wrote:

> Hi Russell,
>
> Thanks for this email, it's great to see this approach described.
>
> A few preliminary notes of feedback:
>
> 1) a Verify approach can be made to work for OP_TXHASH (even with CTV
> as-is) E.g., suppose a semantic added for a single byte stack[-1] sighash
> flag to read the hash at stack[-2], then the hash can be passed in instead
> of put on the stack. This has the disadvantage of larger witnesses, but the
> advantage of allowing undefined sighash flags to pass for any hash type.
> 2) using the internal key for APO covenants is not an option because it
> makes transaction construction interactive and precludes contracts with a
> NUMS point taproot key. Instead, if you want similar savings, you should
> advocate an OP_GENERATOR which puts G on the stack. Further, an untagged
> APO variant which has split R and S values would permit something like
> <sig> OP_GENERATOR OP_GENERATOR CHECKSIGAPO, which would be only 2 more
> bytes than CTV.
> 3) I count something like 20 different flags in your proposal. As long as
> flags are under 40 bytes (and 32 assuming we want it to be easy) without
> upgrading math this should be feasible to manipulate on the stack
> programmatically. This is ignoring some of the more flexible additions you
> mention about picking which outputs/inputs are included. However, 20 flags
> means that for testing we would want comprehensive tests and understanding
> for ~1 million different flag combos and the behaviors they expose. I think
> this necessitates a formal model of scripting and transaction validity
> properties. Are there any combinations that might be undesirable?
> 4) Just hashing or not hashing isn't actually that flexible, because it
> doesn't natively let you do things like (for example) TLUV. You really do
> need tx operations for directly manipulating the data on the stack to
> construct the hash if you want more flexible covenants. This happens to be
> compatible with either a Verify or Push approach, since you either
> destructure a pushed hash or build up a hash for a verify.
> 5) Flexible hashing has the potential for quadratic hashing bugs. The
> fields you propose seem to be within similar range to work you could cause
> with a regular OP_HASH256, although you'd want to be careful with some of
> the proposed extensions that you don't create risk of quadratic hashing,
> which seems possible with an output selecting opcode unless you cache
> properly (which might be tricky to do). Overall for the fields explicitly
> mentioned, seems safe, the "possibles" seem to have some more complex
> interactions. E.g., CTV with the ability to pick a subset of outputs would
> be exposed to quadratic hashing.
> 6) Missing field: covering the annex or some sub-range of the annex
> (quadratic hashing issues on the latter)
> 7) It seems simpler to, for many of these fields, push values directly (as
> in OP_PUSHTXDATA from Johnson Lau) because the combo of flags to push the
> hash of a single output's amount to emulate OP_AMOUNT looks 'general but
> annoying'. It may make more sense to do the OP_PUSHTXDATA style opcode
> instead. This also makes it simpler to think about the combinations of
> flags, since it's really N independent multi-byte opcodes.
>
>
> Ultimately if we had OP_TXHASH available "tomorrow", I would be able to
> build out the use cases I care about for CTV (and more). So I don't have an
> opposition on it with regards to lack of function.
>
> However, if one finds the TXHASH approach acceptable, then you should also
> be relatively fine doing APO, CTV, CSFS, TXHASH acceptable in any order
> (whenever "ready"), unless you are particularly sensitive to "technical
> debt" and "soft fork processes". The only costs of doing something for CTV
> or APO given an eventual TXHASH is perhaps a wasted key version or the 32
> byte argument of a NOP opcode and some code to maintain.
>
> Are there other costs I am missing?
>
> However, as it pertains to actual rollout:
>
> - OP_TXHASH+CSFSV doesn't seem to be the "full" set of things needed (we
> still need e.g. OP_CAT, Upgraded >=64 bit Math, TLUV or OP_TWEAK
> OP_TAPBRANCH OP_MANIPULATETAPTREE, and more) to full realize covenanting
> power it intends to introduce.
> - What sort of timeline would it take to ready something like TXHASH (and
> desired friends) given greater scope of testing and analysis (standalone +
> compared to CTV)?
> - Is there opposition from the community to this degree of
> general/recursive covenants?
> - Does it make "more sense" to invest the research and development effort
> that would go into proving TXHASH safe, for example, into Simplicity
> instead?
>
> Overall, *my opinion *is that:
>
> - TXHASH is an acceptable theoretical approach, and I am happy to put more
> thought into it and maybe draft a prototype of it.
> - I prefer CTV as a first step for pragmatic engineering and availability
> timeline reasons.
> - If TXHASH were to take, optimistically, 2 years to develop and review,
> and then 1 year to activate, the "path dependence of software" would put
> Bitcoin in a much better place were we to have CTV within 1 year and
> applications (that are to be a subset of TXHASH later) being built over the
> next few years enhanced in the future by TXHASH's availability.
> - There is an element of expediency meritted for something like CTV
> insofar as it provides primitives to tackle time sensitive issues around
> privacy, scalability, self custody, and decentralization. The
> aforementioned properties may be difficult to reclaim once given away (with
> the exception of perhaps scalability).
> - Bringing CTV to an implemented state of near-unanimous "we could do
> this, technically" is good for concretely driving the process of review for
> any covenant proposals forward, irrespective of if we ultimately activate.
> (I.e., if there were a reason we could not do CTV safely, it would likely
> have implications for any other future covenant)
>
> Concretely, I'm not going to stop advocating for CTV based on the above,
> but I'm very happy to have something new in the mix to consider!
>
> Best,
>
> Jeremy
>
>
> --
> @JeremyRubin <https://twitter.com/JeremyRubin>
> <https://twitter.com/JeremyRubin>
>
>
> On Wed, Jan 26, 2022 at 9:23 AM Russell O'Connor via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>> Recapping the relationship between CTV and ANYPREVOUT::
>>
>> It is known that there is a significant amount of overlap in the
>> applications that are enabled by the CTV and ANYPREVOUT proposals despite
>> the fact that their primary applications (congestion control for CTV and
>> eltoo lightning channels for ANYPREVOUT) are quite distinct.
>> In particular, ANYPREVOUT can enable most of the applications of CTV,
>> albeit with a higher cost.  The primary functionality of CTV is to allow a
>> scriptPubKey to make a commitment to its spending transaction's hash with
>> the input's TXID excluded from the hash.  This exclusion is necessary
>> because the scriptPubKey is hashed into the input's TXID, and including the
>> TXID would cause a cycle of hash commitments, which is impossible to
>> construct.  On the other hand, ANYPREVOUT defines a signature hash mode
>> that similarly excludes the inputs TXID for its purpose of rebindable
>> signatures.
>>
>> This means that ANYPREVOUT can mimic most of the properties of CTV by
>> committing both a public key along with an ANYPREVOUT signature inside
>> scriptPubKey.  In fact, the only reason Bitcoin doesn't have covenants
>> today is due to this cycle between scriptPubKeys and the TXIDs that occur
>> in all the sighash modes.
>>
>> The major differences between simulating CTV via ANYPREVOUT and the
>> actual CTV proposal is: (1) The cost of simulating CTV.  With CTV the
>> spending transaction is committed using a hash of 32 bytes, while
>> simulating it with ANYPREVOUT requires 64 bytes for a signature, and 32
>> bytes for some public key, plus a few more bytes for various flags.  Some
>> of that cost could be reduced by using the inner public key (1 byte
>> representation) and, if we had CAT, maybe by assembling the signature from
>> reusable pieces (i.e. setting the nonce of the commited signature equal to
>> the public key).
>>
>> The other major difference is: (2) CTV's transaction hash covers values
>> such as the number of inputs in the transaction and their sequence numbers,
>> which ANYPREVOUT does not cover.  CTV's hash contains enough information so
>> that when combined with the missing TXIDs, you can compute the TXID of the
>> spending transaction.  In particular if the number of inputs is committed
>> to being 1, once the scriptpubkey's transaction id is known and committed
>> to the blockchain, the TXID of its spending transaction is deducible.  And
>> if that transaction has outputs that have CTV commitments in them, you can
>> deduce their spending TXIDs in turn.  While this is a pretty neat feature,
>> something that ANYPREVOUT cannot mimic, the main application for it is
>> listed as using congestion control to fund lightning channels, fixing their
>> TXIDs in advance of them being placed on chain.  However, if ANYPREVOUT
>> were used to mimic CTV, then likely it would be eltoo channels that would
>> be funded, and it isn't necessary to know the TXIDs of eltoo channels in
>> advance in order to use them.
>>
>>
>>
>> An Alternative Proposal::
>>
>> Given the overlap in functionality between CTV and ANYPREVOUT, I think it
>> makes sense to decompose their operations into their constituent pieces and
>> reassemble their behaviour programmatically.  To this end, I'd like to
>> instead propose OP_TXHASH and OP_CHECKSIGFROMSTACKVERIFY.
>>
>> OP_TXHASH would pop a txhash flag from the stack and compute a (tagged)
>> txhash in accordance with that flag, and push the resulting hash onto the
>> stack.
>> OP_CHECKSIGFROMSTACKVERIFY would pop a pubkey, message, and signature
>> from the stack and fail if the signature does not verify on that message.
>>
>> CTV and TXHASH have roughly equivalent functionality.  'CTV DROP' can be
>> simulated by '<ctv_style_flag> TXHASH EQUALVERIFY'.  The reverse is also
>> true where '<ctv_style_flag> TXHASH' can be simulated by CTV by
>> '<ctv-result-from-witness-stack> CTV', however, as you can see, simulating
>> TXHASH from CTV is much more expensive than the other way around, because
>> the resulting 32-byte hash result must be included as part of the witness
>> stack.
>>
>> '<anyprevout-pubkey> CHECKSIGVERIFY can be simulated by '<apo_style_flag>
>> TXHASH <pubkey> CHECKSIGFROMSTACKVERIFY'.  Here we see the advantage of
>> pushing the hash value onto the stack.  APO can be simulated without
>> needing to include a copy of the resulting txhash inside the witness data.
>>
>> In addition to the CTV and ANYPREVOUT applications, with
>> CHECKSIGFROMSTACKVERIFY we can verify signatures on arbitrary messages
>> signed by oracles for oracle applications.  This is where we see the
>> benefit of decomposing operations into primitive pieces.  By giving users
>> the ability to program their own use cases from components, we get more
>> applications out of fewer op codes!
>>
>>
>>
>> Caveats::
>>
>> First, I acknowledge that replicating the behaviour of CTV and ANYPREVOUT
>> does cost a few more bytes than using the custom purpose built proposals
>> themselves.  That is the price to be paid when we choose the ability to
>> program solutions from pieces.  But we get to reap the advantages of being
>> able to build more applications from these pieces.
>>
>> Unlike CTV, TXHASH is not NOP-compatable and can only be implemented
>> within tapscript.  In particular, bare CTV isn't possible with this
>> proposal.  However, this proposal doesn't preclude the possibility of
>> having CTV added to legacy script in while having TXHASH added to tapscript.
>>
>> For similar reasons, TXHASH is not amenable to extending the set of
>> txflags at a later date.  In theory, one could have TXHASH
>> abort-with-success when encountering an unknown set of flags.  However,
>> this would make analyzing tapscript much more difficult. Tapscripts would
>> then be able to abort with success or failure depending on the order script
>> fragments are assembled and executed, and getting the order incorrect would
>> be catastrophic.  This behavior is manifestly different from the current
>> batch of OP_SUCCESS opcodes that abort-with-success just by their mere
>> presence, whether they would be executed or not.
>>
>> I believe the difficulties with upgrading TXHASH can be mitigated by
>> designing a robust set of TXHASH flags from the start.  For example having
>> bits to control whether (1) the version is covered; (2) the locktime is
>> covered; (3) txids are covered; (4) sequence numbers are covered; (5) input
>> amounts are covered; (6) input scriptpubkeys are covered; (7) number of
>> inputs is covered; (8) output amounts are covered; (9) output scriptpubkeys
>> are covered; (10) number of outputs is covered; (11) the tapbranch is
>> covered; (12) the tapleaf is covered; (13) the opseparator value is
>> covered; (14) whether all, one, or no inputs are covered; (15) whether all,
>> one or no outputs are covered; (16) whether the one input position is
>> covered; (17) whether the one output position is covered; (18) whether the
>> sighash flags are covered or not (note: whether or not the sighash flags
>> are or are not covered must itself be covered).  Possibly specifying which
>> input or output position is covered in the single case and whether the
>> position is relative to the input's position or is an absolute position.
>>
>> That all said, even if other txhash flag modes are needed in the future,
>> adding TXHASH2 always remains an option.
>>
>>
>>
>> Interactions with potential future opcodes::
>>
>> We should give some consideration on how these opcodes may interact with
>> future opcodes such as CAT, rolling SHA256 opcodes, or how it might
>> interface with other covenant opcodes that may do things like, directly
>> push input or output amounts onto the stack for computation purposes,
>> opcodes which have been added to the Elements project.
>>
>> With CAT and/or rolling SHA256 opcodes and/or existing SHA256 opcodes,
>> the CHECKSIGFROMSTACKVERIFY could verify signatures on programmatically
>> assembled messages.  Also, in combination with multiple calls to TXHASH,
>> could be used to create signatures that commit to complex subsets of
>> transaction data.
>>
>> If new opcodes are added to push parts of the transaction data direction
>> onto the stack, e.g. OP_INSPECTOUTPUTVALUE, there is perhaps concern that
>> they would obsolete TXHASH, since, in the presence of rolling SHA256
>> opcodes, TXHASH could be simulated.  However, given that TXHASH can
>> compactly create a hash of large portions of transaction data, it seems
>> unlikely that TXHASH would fall into disuse.  Also, a combination of TXHASH
>> and transaction introspection opcodes can be used to build "*subtractive
>> covenants*".
>>
>> The usual way of building a covenant, which we will call "*additive *
>> *covenants*", is to push all the parts of the transaction data you would
>> like to fix onto the stack, hash it all together, and verify the resulting
>> hash matches a fixed value.  Another way of building covenants, which we
>> will call "*subtractive covenants*", is to push all the parts of the
>> transaction data you would like to remain free onto the stack.  Then use
>> rolling SHA256 opcodes starting from a fixed midstate that commits to a
>> prefix of the transaction hash data. The free parts are hashed into that
>> midstate.  Finally, the resulting hash value is verified to match a value
>> returned by TXHASH.  The ability to nicely build subtractive covenants
>> depends on the details of how the TXHASH hash value is constructed,
>> something that I'm told CTV has given consideration to.
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220127/97b618df/attachment-0001.html>

From aj at erisian.com.au  Fri Jan 28 01:34:36 2022
From: aj at erisian.com.au (Anthony Towns)
Date: Fri, 28 Jan 2022 11:34:36 +1000
Subject: [bitcoin-dev] TXHASH + CHECKSIGFROMSTACKVERIFY in lieu of CTV
 and ANYPREVOUT
In-Reply-To: <CAMZUoK=pkZuovtifBzdqhoyegzG+9hRTFEc7fG9nZPDK4KbU3w@mail.gmail.com>
References: <CAMZUoK=pkZuovtifBzdqhoyegzG+9hRTFEc7fG9nZPDK4KbU3w@mail.gmail.com>
Message-ID: <20220128013436.GA2939@erisian.com.au>

On Wed, Jan 26, 2022 at 12:20:10PM -0500, Russell O'Connor via bitcoin-dev wrote:
> Recapping the relationship between CTV and ANYPREVOUT::

> While this is a pretty neat feature,
> something that ANYPREVOUT cannot mimic, the main application for it is
> listed as using congestion control to fund lightning channels, fixing their
> TXIDs in advance of them being placed on chain.  However, if ANYPREVOUT
> were used to mimic CTV, then likely it would be eltoo channels that would
> be funded, and it isn't necessary to know the TXIDs of eltoo channels in
> advance in order to use them.

Even if they weren't eltoo channels, they could be updated lightning penalty
channels signed with APO signatures so that the txid wasn't crucial. So
I don't think this would require all the work to update to eltoo just to
have this feature, if APO were available without CTV per se.

> An Alternative Proposal::
>  ...

> For similar reasons, TXHASH is not amenable to extending the set of txflags
> at a later date.

> I believe the difficulties with upgrading TXHASH can be mitigated by
> designing a robust set of TXHASH flags from the start.  For example having
> bits to control whether [...]

I don't think that's really feasible -- eg, what you propose don't cover
SIGHASH_GROUP: 

 https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-July/019243.html

> That all said, even if other txhash flag modes are needed in the future,
> adding TXHASH2 always remains an option.

I think baking this in from day 0 might be better: make TXHASH be
a multibyte opcode, so that when you decode "0xBB" on the stack,
you also decode a serialize.h:VarInt as the version number. Version 0
(0xBB00) gives hashes corresponding to bip342, version 1 (0xBB01) gives
hashes corresponding to bip118 (anyprevout), anything else remains as
OP_SUCCESS behaviour, and you retain a pretty compact encoding even if
we somehow eventually end up needing hundreds or thousands of different
TXHASH versions.

Because the version here is part of the opcode rather than pulled from
the stack, I think this preserves any benefits related to composition
or analysis, but is otherwise still pretty general. I'm imagining that
the idea would be to be consistent between CHECKSIG key versions and
TXHASH versions.

So I think just designing it this way means TXHASH *would* be "amenable
to extending the set of txflags at a later date."

> '<anyprevout-pubkey> CHECKSIGVERIFY can be simulated by '<apo_style_flag> TXHASH <pubkey> CHECKSIGFROMSTACKVERIFY'. 

I don't think that's quite right. BIP 118 anyprevout is done by taking
the pubkey "P", marking it as "APO-capable" (by prefixing it with 0x01),
and then getting a sighash and sig from the witness. Doing the same
with TXHASH/CSFSV would just be replacing "<APO:P> CHECKSIGVERIFY" with
"TXHASH <P> CSFSV" with the witness providing both the signature and
txhash flag, just as separate elements rather than concatenated. (The
"APO-capable" part is implicit in the "TXHASH" opcode)

> In addition to the CTV and ANYPREVOUT applications, with
> CHECKSIGFROMSTACKVERIFY we can verify signatures on arbitrary messages
> signed by oracles for oracle applications.  This is where we see the
> benefit of decomposing operations into primitive pieces.  By giving users
> the ability to program their own use cases from components, we get more
> applications out of fewer op codes!

While I see the appeal of this from a language design perspective;
I'm not sure it's really the goal we want. When I look at bitcoin's
existing script, I see a lot of basic opcodes to do simple arithmetic and
manipulate the stack in various ways, but the opcodes that are actually
useful are more "do everything at once" things like check(multi)sig or
sha256. It seems like what's most useful on the blockchain is a higher
level language, rather than more of blockchain assembly language made
up of small generic pieces. I guess "program their own use cases from
components" seems to be coming pretty close to "write your own crypto
algorithms" here...

I'm not really sure what the dividing line there is, or even which side
TXHASH would be on. I'm not even totally convinced that the "high level
language" should be describing what consensus provides rather than some
layer on top that people compile (a la miniscript). Just trying to put
into words why I'm not 100% comfortable with the principle per se.


One thing I've thought about is an opcode like "POP_SIGDATA" which would
populate a new "register" called "sigdata", which would then be added
to the message being signed. That's a generalisation of tapscript's
behaviour for "codeseparator" essentially. That is,

   x POP_SIGDATA p CHECKSIG

would be roughly the same as

   TXHASH x CAT SHA256SUM p CHECKSIGFROMSTACK

I think "POP_SIGDATA" makes for an interesting counterpart to
"PUSH_ANNEXITEM" -- we implicitly commit to all the annex items in
signatures, so PUSH_ANNEXITEM would give a way to use signed data that's
given verbatim in the witness in further calculations; but POP_SIGDATA
would do the opposite, allowing you to require data that's the result
of calculations and not explicitly spelled out in the witness be signed.

You could implement CHECKSIGFROMSTACK using that, ie:

    sig x p CHECKSIGFROMSTACK

is the same as:

    sig' x POP_SIGDATA p CHECKSIG

provided sig' applies a new "SIGHASH_NO_TX_DATA_AT_ALL" sighash flag to
"sig" that just does what it says.

You could likewise implement CTV as an extension to CHECKSIG -- define a
new pubkey type that's just the constant "0x0000" and have the "signature"
be valid if it's an exact match for the corresponding message hash. You
could bump the key to "0x0001" to introduce new hashes; and include a
"sighash" with the "signature" as well perhaps. (Apart from reusing an
existing opcode instead of introducing a new one, and costing some
additional witnss bytes, I don't think that makes much difference
eithr way)

I think the key tradeoff between "x POP_SIGDATA p CHECKSIG" and
"CHECKSIGFROMSTACK" isn't so much that one approach is a couple of bytes
more or less or one claims two opcodes vs just one for the other, but
whether it's common to want to commit to some extra random data alongside
the tx itself, and in the cases where that's desirable, if we can have
a standard way of constructing that and assume everyone will use it; or
if it's important that wallets can design their own way of committing to
the extra data more manually, because it's impotant to support different
approaches in different circumstances.


If we had CTV, POP_SIGDATA, and SIGHASH_NO_TX_DATA_AT_ALL but no OP_CAT,
are there any practical use cases that wouldn't be covered that having
TXHASH/CAT/CHECKSIGFROMSTACK instead would allow? Or where those would
be significantly more convenient/efficient?

(Assume "y x POP_SIGDATA POP_SIGDATA p CHECKSIGVERIFY q CHECKSIG"
commits to a vector [x,y] via p but does not commit to either via q so
that there's some "CAT"-like behaviour available)


I think a difference between "TXHASH EQUALVERIFY" and "CTV" is that
because the idea for TXHASH is to be compatible with CHECKSIGFROMSTACK,
then the messages it hashes should be distinct from anything else you
might ever sign. But for CTV that doesn't matter, because there's no
signature to be reused; so as a result, how the message is hashed can
be simpler, and that in turn may make it easier to do the "subtractive
covenants" and similar.

I guess I don't find that super important -- if you're manually
constructing covenants in script by putting together various bits of
data about a tx, then I guess I think you've already lost the game, and
having to have your script be a little more complicated in order to to
tagged hashes and the like is no big deal.


Concretely:

 - I think TXHASH needs to be designed to be upgradable; but I think
   that's solvable

 - I think it makes sense for TXHASH and CHECKSIG to be synchronised;
   so any message digest you can hash via txhash should be signable via
   CHECKSIG and vice-versa. Given that, I don't think this approach
   replaces APO, just adds to it.

 - I think I'd prefer having a single set of message digests shared
   between TXHASH and CHECKSIG, than having one set of message digests
   for CHECKSIG and a different set for CTV. But that's a design choice
   for CTV rather than an advantage of TXHASH over CTV.

 - I think defining some OP_NOPx in terms of TXHASH so that it can
   be made available without p2sh/segwit/tapscript wrapping would work
   fine, if that optimisation is worthwhile

 - Even if we favoured CTV over TXHASH for consensus implementation,
   I think "TXHASH" seems like a good primitive to use when talking
   about script language design...

Cheers,
aj


From jlrubin at mit.edu  Fri Jan 28 01:35:11 2022
From: jlrubin at mit.edu (Jeremy)
Date: Thu, 27 Jan 2022 17:35:11 -0800
Subject: [bitcoin-dev] Improving RBF Policy
In-Reply-To: <CAFXO6=LGbaur6XQrE+6a6mAAHXduOCXoWPTgPosxAG59ZkK6Gg@mail.gmail.com>
References: <CAFXO6=LGbaur6XQrE+6a6mAAHXduOCXoWPTgPosxAG59ZkK6Gg@mail.gmail.com>
Message-ID: <CAD5xwhj=yc5g0NBG0ScNvNs-8pUWDFoGn1GZkqezX1_5e+4LKg@mail.gmail.com>

Gloria,

This is a brilliant post! Great job systematizing many of the issues. Quite
a lot to chew on & I hope other readers of this list digest the post fully.

Three things come to mind as partial responses:

under:

- **DoS Protection**: Limit two types of DoS attacks on the node's
>   mempool: (1) the number of times a transaction can be replaced and
> (2) the volume of transactions that can be evicted during a
> replacement.


I'd more simply put it:

Limiting the amount of work that must be done to consider the replacement

We don't particularly care about goal (1) or goal (2), we care about how
much it costs to do (1) or (2). And there are scenarios where the (1) or
(2) might not be particularly high, but the total work still might be. I
can give you some examples to consider if needed. There are also scenarios
where (1) and (2) might be high, but the cost is low overall. Therefore it
makes sense to be a little more general with what the anti-DoS goal is.




An issue I'd like to toss into the mix is that of iterative / additive
batching. E.g., https://bitcoinops.org/en/cardcoins-rbf-batching/

This is where an business puts a txn in the mempool that pays to N users,
and as they see additional requests for payouts the update it to N+2,
N+2... N+M payouts. This iterative batching can be highly efficient because
the number of transactions per business per 10 minutes is 1 (with variable
number of outputs).

One issue with this approach today is that because of the feerate rule, if
you go from N to N+1 you need to pay 1 sat/byte over the whole txn. Applied
M times, and you have to increase fees quadratically for this approach.
Therefore the less efficient long-chain of batches model ends up being
'rational' with respect to mempool policy and irrational with respect to
"optimally packing blocks with transactions".

If the absolute fee rule is dropped, but feerate remains, one thing you
might see is businesses doing iterative batches with N+2M outputs whereby
they drop 2 outputs for every input they add, allowing the iterative batch
to always increase the fee-rate but possibly not triggering the quadratic
feerate issue since the transaction gets smaller over time.

Another possible solution to this would be to allow relaying "txdiffs"
which only require re-relay of signatures + new/modified outputs, and not
the entire tx.

I think this iterative batching is pretty desirable to support, and so I'd
like to see a RBF model which doesn't make it "unfairly" expensive.

(I'll spare everyone the details on how CTV batching also solves this, but
feel free to ask elsewhere.)

A counterargument to additive batching is that if you instead do non
iterative batches every minute, and you have 100 txns that arrive
uniformly, you'd end up with 10 batches of size 10 on average. The bulk of
the benefit under this model is in the non-batched to batched transition,
and the iterative part only saves on space/fees marginally after that point.



A final point is that a verifiable delay function could be used over, e.g.,
each of the N COutpoints individually to rate-limit transaction
replacement. The VDF period can be made shorter / eliminated depending on
the feerate increase. E.g., always consider a much higher feerate txn
whenever available, for things of equal feerate only consider 1 per minute.
A VDF is like proof-of-work that doesn't parallelize, in case you are
unfamiliar, so no matter how many computers you have it would take about
the same amount of time (you could parallelize across N outputs, of course,
but you're still bound minimally to the time it takes to replace 1 output,
doing all outputs individually just is the most flexible option).


Cheers,

Jeremy
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220127/9ca1b277/attachment.html>

From james.obeirne at gmail.com  Fri Jan 28 00:18:54 2022
From: james.obeirne at gmail.com (James O'Beirne)
Date: Thu, 27 Jan 2022 19:18:54 -0500
Subject: [bitcoin-dev] TXHASH + CHECKSIGFROMSTACKVERIFY in lieu of CTV
	and ANYPREVOUT
In-Reply-To: <CAMZUoKmU1cwUAQaBv5m8oo8H3TWBvgsZ_OkQaMC0n0+3cpFtWg@mail.gmail.com>
References: <CAMZUoK=pkZuovtifBzdqhoyegzG+9hRTFEc7fG9nZPDK4KbU3w@mail.gmail.com>
 <CAD5xwhhwqJ_AETAb3p_zUZmRX-Dzh8J9G984zwEs=KFsGN8aNQ@mail.gmail.com>
 <CAMZUoKmU1cwUAQaBv5m8oo8H3TWBvgsZ_OkQaMC0n0+3cpFtWg@mail.gmail.com>
Message-ID: <CAPfvXfLr4n6RsS6VbEZR59=MRwAx41Crx88ko8-qnRXW4nFYGA@mail.gmail.com>

> I don't think implementing a CTV opcode that we expect to largely be
obsoleted by a TXHASH at a later date is yielding good value from a soft
fork process.

This presumes the eventual adoption of TXHASH (or something like it).
You're presenting a novel idea that, as far as I know, hasn't had much time
to bake in public. Like Jeremy, I'm concerned by the combinatorial growth
of flags and the implications that has for testing. Caching for something
like TXHASH looks to me like a whole different ballgame relative to CTV,
which has a single kind of hash.

Even if we were to adopt something like TXHASH, how long is it going to
take to develop, test, and release? My guess is "a while" - in the
meantime, users of Bitcoin are without a vault strategy that doesn't
require either presigning transactions with ephemeral keys (operationally
difficult) or multisig configurations that would make Rube Goldberg blush
(operationally difficult and precarious). The utility of vaulting seems
underappreciated among consensus devs and it's something I'd like to write
about soon in a separate post.

> The strongest argument I can make in favour of CTV would be something
like: "We definitely want bare CTV and if we are going to add CTV to legacy
script (since we cannot use TXHASH in legacy script), then it is actually
easier not to exclude it from tapscript, even if we plan to add TXHASH to
tapscript as well."

Another argument for CTV (which I find especially persuasive) is its
simplicity - it's relatively easy to reason about and, at this point,
pretty well understood. It seems like a low-risk change relative to some of
the other covenant proposals, nearly all of which elicit a good deal of
headscratching (at least from me) and seem to require not only larger
on-chain footprints but sizable code changes.

> I am sensitive to technical debt and soft fork processes

If OP_CTV ends up being the most practical approach for vaulting - among
other things - in terms of weight (which it seems to be at the moment) I
don't think "technical debt" is an applicable term.

On Thu, Jan 27, 2022 at 5:20 PM Russell O'Connor via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> I am sensitive to technical debt and soft fork processes, and I don't
> believe I'm unordinary particular about these issues.  Once implemented,
> opcodes must be supported and maintained indefinitely.  Some opcodes are
> easier to maintain than others.  These particular opcodes involve caching
> of hash computations and, for that reason, I would judge them to be of
> moderate complexity.
>
> But more importantly, soft-forks are inherently a risky process, so we
> should be getting as much value out of them as we reasonably can. I don't
> think implementing a CTV opcode that we expect to largely be obsoleted by a
> TXHASH at a later date is yielding good value from a soft fork process.
>
> The strongest argument I can make in favour of CTV would be something
> like: "We definitely want bare CTV and if we are going to add CTV to legacy
> script (since we cannot use TXHASH in legacy script), then it is actually
> easier not to exclude it from tapscript, even if we plan to add TXHASH to
> tapscript as well."
>
> But that argument basically rests the entire value of CTV on the shoulders
> of bare CTV.  As I understand, the argument for why we want bare CTV,
> instead of just letting people use tapscript, involves the finer details of
> weight calculations, and I haven't really reviewed that aspect yet.  I
> think it would need to be pretty compelling to make it worthwhile to add
> CTV for that one use case.
>
>
> Regarding "OP_TXHASH+CSFSV doesn't seem to be the 'full' set of things
> needed", I totally agree we will want more things such as CAT, rolling
> SHA256 opcodes, wider arithmetic, pushing amounts onto the stack, some kind
> of tapleaf manipulation and/or TWEAKVERIFY.  For now, I only want to argue
> TXHASH+CSFSV is better than CTV+APO because it gives us more value, namely
> oracle signature verification.  In particular, I want to argue that
> TXHASH's push semantics is better that CTV's verify semantics because it
> composes better by not needing to carry an extra 32-bytes (per instance) in
> the witness data.  I expect that in a world of full recursive covenants,
> TXHASH would still be useful as a fast and cheap way to verify the
> "payload" of these covenants, i.e. that a transaction is paying a certain,
> possibly large, set of addresses certain specific amounts of money.  And
> even if not, TXHASH+CSFSV would still be the way that eltoo would be
> implemented under this proposal.
>
> On Wed, Jan 26, 2022 at 5:16 PM Jeremy <jlrubin at mit.edu> wrote:
>
>> Hi Russell,
>>
>> Thanks for this email, it's great to see this approach described.
>>
>> A few preliminary notes of feedback:
>>
>> 1) a Verify approach can be made to work for OP_TXHASH (even with CTV
>> as-is) E.g., suppose a semantic added for a single byte stack[-1] sighash
>> flag to read the hash at stack[-2], then the hash can be passed in instead
>> of put on the stack. This has the disadvantage of larger witnesses, but the
>> advantage of allowing undefined sighash flags to pass for any hash type.
>> 2) using the internal key for APO covenants is not an option because it
>> makes transaction construction interactive and precludes contracts with a
>> NUMS point taproot key. Instead, if you want similar savings, you should
>> advocate an OP_GENERATOR which puts G on the stack. Further, an untagged
>> APO variant which has split R and S values would permit something like
>> <sig> OP_GENERATOR OP_GENERATOR CHECKSIGAPO, which would be only 2 more
>> bytes than CTV.
>> 3) I count something like 20 different flags in your proposal. As long as
>> flags are under 40 bytes (and 32 assuming we want it to be easy) without
>> upgrading math this should be feasible to manipulate on the stack
>> programmatically. This is ignoring some of the more flexible additions you
>> mention about picking which outputs/inputs are included. However, 20 flags
>> means that for testing we would want comprehensive tests and understanding
>> for ~1 million different flag combos and the behaviors they expose. I think
>> this necessitates a formal model of scripting and transaction validity
>> properties. Are there any combinations that might be undesirable?
>> 4) Just hashing or not hashing isn't actually that flexible, because it
>> doesn't natively let you do things like (for example) TLUV. You really do
>> need tx operations for directly manipulating the data on the stack to
>> construct the hash if you want more flexible covenants. This happens to be
>> compatible with either a Verify or Push approach, since you either
>> destructure a pushed hash or build up a hash for a verify.
>> 5) Flexible hashing has the potential for quadratic hashing bugs. The
>> fields you propose seem to be within similar range to work you could cause
>> with a regular OP_HASH256, although you'd want to be careful with some of
>> the proposed extensions that you don't create risk of quadratic hashing,
>> which seems possible with an output selecting opcode unless you cache
>> properly (which might be tricky to do). Overall for the fields explicitly
>> mentioned, seems safe, the "possibles" seem to have some more complex
>> interactions. E.g., CTV with the ability to pick a subset of outputs would
>> be exposed to quadratic hashing.
>> 6) Missing field: covering the annex or some sub-range of the annex
>> (quadratic hashing issues on the latter)
>> 7) It seems simpler to, for many of these fields, push values directly
>> (as in OP_PUSHTXDATA from Johnson Lau) because the combo of flags to push
>> the hash of a single output's amount to emulate OP_AMOUNT looks 'general
>> but annoying'. It may make more sense to do the OP_PUSHTXDATA style opcode
>> instead. This also makes it simpler to think about the combinations of
>> flags, since it's really N independent multi-byte opcodes.
>>
>>
>> Ultimately if we had OP_TXHASH available "tomorrow", I would be able to
>> build out the use cases I care about for CTV (and more). So I don't have an
>> opposition on it with regards to lack of function.
>>
>> However, if one finds the TXHASH approach acceptable, then you should
>> also be relatively fine doing APO, CTV, CSFS, TXHASH acceptable in any
>> order (whenever "ready"), unless you are particularly sensitive to
>> "technical debt" and "soft fork processes". The only costs of doing
>> something for CTV or APO given an eventual TXHASH is perhaps a wasted key
>> version or the 32 byte argument of a NOP opcode and some code to maintain.
>>
>> Are there other costs I am missing?
>>
>> However, as it pertains to actual rollout:
>>
>> - OP_TXHASH+CSFSV doesn't seem to be the "full" set of things needed (we
>> still need e.g. OP_CAT, Upgraded >=64 bit Math, TLUV or OP_TWEAK
>> OP_TAPBRANCH OP_MANIPULATETAPTREE, and more) to full realize covenanting
>> power it intends to introduce.
>> - What sort of timeline would it take to ready something like TXHASH (and
>> desired friends) given greater scope of testing and analysis (standalone +
>> compared to CTV)?
>> - Is there opposition from the community to this degree of
>> general/recursive covenants?
>> - Does it make "more sense" to invest the research and development effort
>> that would go into proving TXHASH safe, for example, into Simplicity
>> instead?
>>
>> Overall, *my opinion *is that:
>>
>> - TXHASH is an acceptable theoretical approach, and I am happy to put
>> more thought into it and maybe draft a prototype of it.
>> - I prefer CTV as a first step for pragmatic engineering and availability
>> timeline reasons.
>> - If TXHASH were to take, optimistically, 2 years to develop and review,
>> and then 1 year to activate, the "path dependence of software" would put
>> Bitcoin in a much better place were we to have CTV within 1 year and
>> applications (that are to be a subset of TXHASH later) being built over the
>> next few years enhanced in the future by TXHASH's availability.
>> - There is an element of expediency meritted for something like CTV
>> insofar as it provides primitives to tackle time sensitive issues around
>> privacy, scalability, self custody, and decentralization. The
>> aforementioned properties may be difficult to reclaim once given away (with
>> the exception of perhaps scalability).
>> - Bringing CTV to an implemented state of near-unanimous "we could do
>> this, technically" is good for concretely driving the process of review for
>> any covenant proposals forward, irrespective of if we ultimately activate.
>> (I.e., if there were a reason we could not do CTV safely, it would likely
>> have implications for any other future covenant)
>>
>> Concretely, I'm not going to stop advocating for CTV based on the above,
>> but I'm very happy to have something new in the mix to consider!
>>
>> Best,
>>
>> Jeremy
>>
>>
>> --
>> @JeremyRubin <https://twitter.com/JeremyRubin>
>> <https://twitter.com/JeremyRubin>
>>
>>
>> On Wed, Jan 26, 2022 at 9:23 AM Russell O'Connor via bitcoin-dev <
>> bitcoin-dev at lists.linuxfoundation.org> wrote:
>>
>>> Recapping the relationship between CTV and ANYPREVOUT::
>>>
>>> It is known that there is a significant amount of overlap in the
>>> applications that are enabled by the CTV and ANYPREVOUT proposals despite
>>> the fact that their primary applications (congestion control for CTV and
>>> eltoo lightning channels for ANYPREVOUT) are quite distinct.
>>> In particular, ANYPREVOUT can enable most of the applications of CTV,
>>> albeit with a higher cost.  The primary functionality of CTV is to allow a
>>> scriptPubKey to make a commitment to its spending transaction's hash with
>>> the input's TXID excluded from the hash.  This exclusion is necessary
>>> because the scriptPubKey is hashed into the input's TXID, and including the
>>> TXID would cause a cycle of hash commitments, which is impossible to
>>> construct.  On the other hand, ANYPREVOUT defines a signature hash mode
>>> that similarly excludes the inputs TXID for its purpose of rebindable
>>> signatures.
>>>
>>> This means that ANYPREVOUT can mimic most of the properties of CTV by
>>> committing both a public key along with an ANYPREVOUT signature inside
>>> scriptPubKey.  In fact, the only reason Bitcoin doesn't have covenants
>>> today is due to this cycle between scriptPubKeys and the TXIDs that occur
>>> in all the sighash modes.
>>>
>>> The major differences between simulating CTV via ANYPREVOUT and the
>>> actual CTV proposal is: (1) The cost of simulating CTV.  With CTV the
>>> spending transaction is committed using a hash of 32 bytes, while
>>> simulating it with ANYPREVOUT requires 64 bytes for a signature, and 32
>>> bytes for some public key, plus a few more bytes for various flags.  Some
>>> of that cost could be reduced by using the inner public key (1 byte
>>> representation) and, if we had CAT, maybe by assembling the signature from
>>> reusable pieces (i.e. setting the nonce of the commited signature equal to
>>> the public key).
>>>
>>> The other major difference is: (2) CTV's transaction hash covers values
>>> such as the number of inputs in the transaction and their sequence numbers,
>>> which ANYPREVOUT does not cover.  CTV's hash contains enough information so
>>> that when combined with the missing TXIDs, you can compute the TXID of the
>>> spending transaction.  In particular if the number of inputs is committed
>>> to being 1, once the scriptpubkey's transaction id is known and committed
>>> to the blockchain, the TXID of its spending transaction is deducible.  And
>>> if that transaction has outputs that have CTV commitments in them, you can
>>> deduce their spending TXIDs in turn.  While this is a pretty neat feature,
>>> something that ANYPREVOUT cannot mimic, the main application for it is
>>> listed as using congestion control to fund lightning channels, fixing their
>>> TXIDs in advance of them being placed on chain.  However, if ANYPREVOUT
>>> were used to mimic CTV, then likely it would be eltoo channels that would
>>> be funded, and it isn't necessary to know the TXIDs of eltoo channels in
>>> advance in order to use them.
>>>
>>>
>>>
>>> An Alternative Proposal::
>>>
>>> Given the overlap in functionality between CTV and ANYPREVOUT, I think
>>> it makes sense to decompose their operations into their constituent pieces
>>> and reassemble their behaviour programmatically.  To this end, I'd like to
>>> instead propose OP_TXHASH and OP_CHECKSIGFROMSTACKVERIFY.
>>>
>>> OP_TXHASH would pop a txhash flag from the stack and compute a (tagged)
>>> txhash in accordance with that flag, and push the resulting hash onto the
>>> stack.
>>> OP_CHECKSIGFROMSTACKVERIFY would pop a pubkey, message, and signature
>>> from the stack and fail if the signature does not verify on that message.
>>>
>>> CTV and TXHASH have roughly equivalent functionality.  'CTV DROP' can be
>>> simulated by '<ctv_style_flag> TXHASH EQUALVERIFY'.  The reverse is also
>>> true where '<ctv_style_flag> TXHASH' can be simulated by CTV by
>>> '<ctv-result-from-witness-stack> CTV', however, as you can see, simulating
>>> TXHASH from CTV is much more expensive than the other way around, because
>>> the resulting 32-byte hash result must be included as part of the witness
>>> stack.
>>>
>>> '<anyprevout-pubkey> CHECKSIGVERIFY can be simulated by
>>> '<apo_style_flag> TXHASH <pubkey> CHECKSIGFROMSTACKVERIFY'.  Here we see
>>> the advantage of pushing the hash value onto the stack.  APO can be
>>> simulated without needing to include a copy of the resulting txhash inside
>>> the witness data.
>>>
>>> In addition to the CTV and ANYPREVOUT applications, with
>>> CHECKSIGFROMSTACKVERIFY we can verify signatures on arbitrary messages
>>> signed by oracles for oracle applications.  This is where we see the
>>> benefit of decomposing operations into primitive pieces.  By giving users
>>> the ability to program their own use cases from components, we get more
>>> applications out of fewer op codes!
>>>
>>>
>>>
>>> Caveats::
>>>
>>> First, I acknowledge that replicating the behaviour of CTV and
>>> ANYPREVOUT does cost a few more bytes than using the custom purpose built
>>> proposals themselves.  That is the price to be paid when we choose the
>>> ability to program solutions from pieces.  But we get to reap the
>>> advantages of being able to build more applications from these pieces.
>>>
>>> Unlike CTV, TXHASH is not NOP-compatable and can only be implemented
>>> within tapscript.  In particular, bare CTV isn't possible with this
>>> proposal.  However, this proposal doesn't preclude the possibility of
>>> having CTV added to legacy script in while having TXHASH added to tapscript.
>>>
>>> For similar reasons, TXHASH is not amenable to extending the set of
>>> txflags at a later date.  In theory, one could have TXHASH
>>> abort-with-success when encountering an unknown set of flags.  However,
>>> this would make analyzing tapscript much more difficult. Tapscripts would
>>> then be able to abort with success or failure depending on the order script
>>> fragments are assembled and executed, and getting the order incorrect would
>>> be catastrophic.  This behavior is manifestly different from the current
>>> batch of OP_SUCCESS opcodes that abort-with-success just by their mere
>>> presence, whether they would be executed or not.
>>>
>>> I believe the difficulties with upgrading TXHASH can be mitigated by
>>> designing a robust set of TXHASH flags from the start.  For example having
>>> bits to control whether (1) the version is covered; (2) the locktime is
>>> covered; (3) txids are covered; (4) sequence numbers are covered; (5) input
>>> amounts are covered; (6) input scriptpubkeys are covered; (7) number of
>>> inputs is covered; (8) output amounts are covered; (9) output scriptpubkeys
>>> are covered; (10) number of outputs is covered; (11) the tapbranch is
>>> covered; (12) the tapleaf is covered; (13) the opseparator value is
>>> covered; (14) whether all, one, or no inputs are covered; (15) whether all,
>>> one or no outputs are covered; (16) whether the one input position is
>>> covered; (17) whether the one output position is covered; (18) whether the
>>> sighash flags are covered or not (note: whether or not the sighash flags
>>> are or are not covered must itself be covered).  Possibly specifying which
>>> input or output position is covered in the single case and whether the
>>> position is relative to the input's position or is an absolute position.
>>>
>>> That all said, even if other txhash flag modes are needed in the future,
>>> adding TXHASH2 always remains an option.
>>>
>>>
>>>
>>> Interactions with potential future opcodes::
>>>
>>> We should give some consideration on how these opcodes may interact with
>>> future opcodes such as CAT, rolling SHA256 opcodes, or how it might
>>> interface with other covenant opcodes that may do things like, directly
>>> push input or output amounts onto the stack for computation purposes,
>>> opcodes which have been added to the Elements project.
>>>
>>> With CAT and/or rolling SHA256 opcodes and/or existing SHA256 opcodes,
>>> the CHECKSIGFROMSTACKVERIFY could verify signatures on programmatically
>>> assembled messages.  Also, in combination with multiple calls to TXHASH,
>>> could be used to create signatures that commit to complex subsets of
>>> transaction data.
>>>
>>> If new opcodes are added to push parts of the transaction data direction
>>> onto the stack, e.g. OP_INSPECTOUTPUTVALUE, there is perhaps concern that
>>> they would obsolete TXHASH, since, in the presence of rolling SHA256
>>> opcodes, TXHASH could be simulated.  However, given that TXHASH can
>>> compactly create a hash of large portions of transaction data, it seems
>>> unlikely that TXHASH would fall into disuse.  Also, a combination of TXHASH
>>> and transaction introspection opcodes can be used to build "*subtractive
>>> covenants*".
>>>
>>> The usual way of building a covenant, which we will call "*additive *
>>> *covenants*", is to push all the parts of the transaction data you
>>> would like to fix onto the stack, hash it all together, and verify the
>>> resulting hash matches a fixed value.  Another way of building covenants,
>>> which we will call "*subtractive covenants*", is to push all the parts
>>> of the transaction data you would like to remain free onto the stack.  Then
>>> use rolling SHA256 opcodes starting from a fixed midstate that commits to a
>>> prefix of the transaction hash data. The free parts are hashed into that
>>> midstate.  Finally, the resulting hash value is verified to match a value
>>> returned by TXHASH.  The ability to nicely build subtractive covenants
>>> depends on the details of how the TXHASH hash value is constructed,
>>> something that I'm told CTV has given consideration to.
>>> _______________________________________________
>>> bitcoin-dev mailing list
>>> bitcoin-dev at lists.linuxfoundation.org
>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>
>> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220127/0c0eb4e2/attachment-0001.html>

From michaelfolkson at protonmail.com  Fri Jan 28 13:14:07 2022
From: michaelfolkson at protonmail.com (Michael Folkson)
Date: Fri, 28 Jan 2022 13:14:07 +0000
Subject: [bitcoin-dev] TXHASH + CHECKSIGFROMSTACKVERIFY in lieu of CTV
	and ANYPREVOUT
In-Reply-To: <CAPfvXfLr4n6RsS6VbEZR59=MRwAx41Crx88ko8-qnRXW4nFYGA@mail.gmail.com>
References: <CAMZUoK=pkZuovtifBzdqhoyegzG+9hRTFEc7fG9nZPDK4KbU3w@mail.gmail.com>
 <CAD5xwhhwqJ_AETAb3p_zUZmRX-Dzh8J9G984zwEs=KFsGN8aNQ@mail.gmail.com>
 <CAMZUoKmU1cwUAQaBv5m8oo8H3TWBvgsZ_OkQaMC0n0+3cpFtWg@mail.gmail.com>
 <CAPfvXfLr4n6RsS6VbEZR59=MRwAx41Crx88ko8-qnRXW4nFYGA@mail.gmail.com>
Message-ID: <XvyRH0U3-np2xDZhhaIgYDXFcTvAnLkP5n-7c58f1bMuh6jAvlF_22n2yquiyoFXYl0s7zQm_3zp46Fzn_tJkxN2Lsz6N75lJmqAS2rlCa4=@protonmail.com>

> Even if we were to adopt something like TXHASH, how long is it going to take to develop, test, and release? My guess is "a while" - in the meantime, users of Bitcoin are without a vault strategy that doesn't require either presigning transactions with ephemeral keys (operationally difficult) or multisig configurations that would make Rube Goldberg blush (operationally difficult and precarious).

To me this seems to be jumping ahead a number of steps from where we are at the current time. If the ecosystem was widely using all the tools available to them at the current time (MuSig(2), Taproot trees to embed complex scripts, Miniscript etc), was testing out upcoming available tools like threshold key aggregation schemes (e.g. FROST) on signets and the final missing piece was a covenant opcode to avoid the deleted key requirement then the argument for urgency would be stronger. I would still share the concerns I and many others have repeated over rushing soft forks and treating mainnet as a testbed for new use cases rather than the final destination for changes that will stand the test of time. But I would be a lot more sympathetic to that argument.

This isn't a criticism of the ecosystem or individual vault projects like Revault, it is clearly still very early. darosior (Revault) is working on getting a first version of Miniscript finalized and in Core [0] and I'm assuming will be part of the effort to get Taproot support in Miniscript assuming that initial effort succeeds. Murch is tracking basic send and receive to the P2TR addresses (not complex scripts, multisig, MuSig(2), merely single key spends) in the ecosystem [1] and there is still a long way to go there.

There are a bunch of covenant opcodes that have been enabled on Liquid [2] that I haven't heard yet of anyone building vault prototypes with. It would be good to get others (TLUV, TXHASH) in future. There is not even a custom signet with CTV (as far as I know) for those who subscribe to the view that we must rush to get CTV activated on mainnet as soon as possible with no thought to what opcodes might follow.

When this discussion focuses on the pros and cons of various proposals and how they are being tested and used in prototypes on signets, sidechains I think it is really productive. But when it gets onto urgency (or worse activation speculation) I am just perplexed. That viewpoint seems to completely ignore where we are currently with Taproot use and tooling (on which most vault designs will presumably build) and even more perplexingly where we are with vault prototypes on signets, sidechains.

I am sure at some point in the future we will have various vault prototypes on signets, sidechains making use of Taproot, Miniscript, MuSig(2), FROST etc and crying out for a covenant opcode or sighash flag to go into production on mainnet. But we seem miles away from that at the present time.

[0]: https://github.com/bitcoin/bitcoin/pull/24147
[1]: https://en.bitcoin.it/wiki/Bech32_adoption
[2]: https://github.com/ElementsProject/elements/blob/master/doc/tapscript_opcodes.md

--
Michael Folkson
Email: michaelfolkson at [protonmail.com](http://protonmail.com/)
Keybase: michaelfolkson
PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3

??????? Original Message ???????
On Friday, January 28th, 2022 at 12:18 AM, James O'Beirne via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:

>> I don't think implementing a CTV opcode that we expect to largely be obsoleted by a TXHASH at a later date is yielding good value from a soft fork process.
>
> This presumes the eventual adoption of TXHASH (or something like it). You're presenting a novel idea that, as far as I know, hasn't had much time to bake in public. Like Jeremy, I'm concerned by the combinatorial growth of flags and the implications that has for testing. Caching for something like TXHASH looks to me like a whole different ballgame relative to CTV, which has a single kind of hash.
>
> Even if we were to adopt something like TXHASH, how long is it going to take to develop, test, and release? My guess is "a while" - in the meantime, users of Bitcoin are without a vault strategy that doesn't require either presigning transactions with ephemeral keys (operationally difficult) or multisig configurations that would make Rube Goldberg blush (operationally difficult and precarious). The utility of vaulting seems underappreciated among consensus devs and it's something I'd like to write about soon in a separate post.
>
>> The strongest argument I can make in favour of CTV would be something like: "We definitely want bare CTV and if we are going to add CTV to legacy script (since we cannot use TXHASH in legacy script), then it is actually easier not to exclude it from tapscript, even if we plan to add TXHASH to tapscript as well."
>
> Another argument for CTV (which I find especially persuasive) is its simplicity - it's relatively easy to reason about and, at this point, pretty well understood. It seems like a low-risk change relative to some of the other covenant proposals, nearly all of which elicit a good deal of headscratching (at least from me) and seem to require not only larger on-chain footprints but sizable code changes.
>
>> I am sensitive to technical debt and soft fork processes
>
> If OP_CTV ends up being the most practical approach for vaulting - among other things - in terms of weight (which it seems to be at the moment) I don't think "technical debt" is an applicable term.
>
> On Thu, Jan 27, 2022 at 5:20 PM Russell O'Connor via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>> I am sensitive to technical debt and soft fork processes, and I don't believe I'm unordinary particular about these issues. Once implemented, opcodes must be supported and maintained indefinitely. Some opcodes are easier to maintain than others. These particular opcodes involve caching of hash computations and, for that reason, I would judge them to be of moderate complexity.
>>
>> But more importantly, soft-forks are inherently a risky process, so we should be getting as much value out of them as we reasonably can. I don't think implementing a CTV opcode that we expect to largely be obsoleted by a TXHASH at a later date is yielding good value from a soft fork process.
>>
>> The strongest argument I can make in favour of CTV would be something like: "We definitely want bare CTV and if we are going to add CTV to legacy script (since we cannot use TXHASH in legacy script), then it is actually easier not to exclude it from tapscript, even if we plan to add TXHASH to tapscript as well."
>>
>> But that argument basically rests the entire value of CTV on the shoulders of bare CTV. As I understand, the argument for why we want bare CTV, instead of just letting people use tapscript, involves the finer details of weight calculations, and I haven't really reviewed that aspect yet. I think it would need to be pretty compelling to make it worthwhile to add CTV for that one use case.
>>
>> Regarding "OP_TXHASH+CSFSV doesn't seem to be the 'full' set of things needed", I totally agree we will want more things such as CAT, rolling SHA256 opcodes, wider arithmetic, pushing amounts onto the stack, some kind of tapleaf manipulation and/or TWEAKVERIFY. For now, I only want to argue TXHASH+CSFSV is better than CTV+APO because it gives us more value, namely oracle signature verification. In particular, I want to argue that TXHASH's push semantics is better that CTV's verify semantics because it composes better by not needing to carry an extra 32-bytes (per instance) in the witness data. I expect that in a world of full recursive covenants, TXHASH would still be useful as a fast and cheap way to verify the "payload" of these covenants, i.e. that a transaction is paying a certain, possibly large, set of addresses certain specific amounts of money. And even if not, TXHASH+CSFSV would still be the way that eltoo would be implemented under this proposal.
>>
>> On Wed, Jan 26, 2022 at 5:16 PM Jeremy <jlrubin at mit.edu> wrote:
>>
>>> Hi Russell,
>>>
>>> Thanks for this email, it's great to see this approach described.
>>>
>>> A few preliminary notes of feedback:
>>>
>>> 1) a Verify approach can be made to work for OP_TXHASH (even with CTV as-is) E.g., suppose a semantic added for a single byte stack[-1] sighash flag to read the hash at stack[-2], then the hash can be passed in instead of put on the stack. This has the disadvantage of larger witnesses, but the advantage of allowing undefined sighash flags to pass for any hash type.
>>> 2) using the internal key for APO covenants is not an option because it makes transaction construction interactive and precludes contracts with a NUMS point taproot key. Instead, if you want similar savings, you should advocate an OP_GENERATOR which puts G on the stack. Further, an untagged APO variant which has split R and S values would permit something like <sig> OP_GENERATOR OP_GENERATOR CHECKSIGAPO, which would be only 2 more bytes than CTV.
>>> 3) I count something like 20 different flags in your proposal. As long as flags are under 40 bytes (and 32 assuming we want it to be easy) without upgrading math this should be feasible to manipulate on the stack programmatically. This is ignoring some of the more flexible additions you mention about picking which outputs/inputs are included. However, 20 flags means that for testing we would want comprehensive tests and understanding for ~1 million different flag combos and the behaviors they expose. I think this necessitates a formal model of scripting and transaction validity properties. Are there any combinations that might be undesirable?
>>> 4) Just hashing or not hashing isn't actually that flexible, because it doesn't natively let you do things like (for example) TLUV. You really do need tx operations for directly manipulating the data on the stack to construct the hash if you want more flexible covenants. This happens to be compatible with either a Verify or Push approach, since you either destructure a pushed hash or build up a hash for a verify.
>>> 5) Flexible hashing has the potential for quadratic hashing bugs. The fields you propose seem to be within similar range to work you could cause with a regular OP_HASH256, although you'd want to be careful with some of the proposed extensions that you don't create risk of quadratic hashing, which seems possible with an output selecting opcode unless you cache properly (which might be tricky to do). Overall for the fields explicitly mentioned, seems safe, the "possibles" seem to have some more complex interactions. E.g., CTV with the ability to pick a subset of outputs would be exposed to quadratic hashing.
>>> 6) Missing field: covering the annex or some sub-range of the annex (quadratic hashing issues on the latter)
>>> 7) It seems simpler to, for many of these fields, push values directly (as in OP_PUSHTXDATA from Johnson Lau) because the combo of flags to push the hash of a single output's amount to emulate OP_AMOUNT looks 'general but annoying'. It may make more sense to do the OP_PUSHTXDATA style opcode instead. This also makes it simpler to think about the combinations of flags, since it's really N independent multi-byte opcodes.
>>>
>>> Ultimately if we had OP_TXHASH available "tomorrow", I would be able to build out the use cases I care about for CTV (and more). So I don't have an opposition on it with regards to lack of function.
>>>
>>> However, if one finds the TXHASH approach acceptable, then you should also be relatively fine doing APO, CTV, CSFS, TXHASH acceptable in any order (whenever "ready"), unless you are particularly sensitive to "technical debt" and "soft fork processes". The only costs of doing something for CTV or APO given an eventual TXHASH is perhaps a wasted key version or the 32 byte argument of a NOP opcode and some code to maintain.
>>>
>>> Are there other costs I am missing?
>>>
>>> However, as it pertains to actual rollout:
>>>
>>> - OP_TXHASH+CSFSV doesn't seem to be the "full" set of things needed (we still need e.g. OP_CAT, Upgraded >=64 bit Math, TLUV or OP_TWEAK OP_TAPBRANCH OP_MANIPULATETAPTREE, and more) to full realize covenanting power it intends to introduce.
>>> - What sort of timeline would it take to ready something like TXHASH (and desired friends) given greater scope of testing and analysis (standalone + compared to CTV)?
>>> - Is there opposition from the community to this degree of general/recursive covenants?
>>> - Does it make "more sense" to invest the research and development effort that would go into proving TXHASH safe, for example, into Simplicity instead?
>>>
>>> Overall, my opinion is that:
>>>
>>> - TXHASH is an acceptable theoretical approach, and I am happy to put more thought into it and maybe draft a prototype of it.
>>> - I prefer CTV as a first step for pragmatic engineering and availability timeline reasons.
>>> - If TXHASH were to take, optimistically, 2 years to develop and review, and then 1 year to activate, the "path dependence of software" would put Bitcoin in a much better place were we to have CTV within 1 year and applications (that are to be a subset of TXHASH later) being built over the next few years enhanced in the future by TXHASH's availability.
>>> - There is an element of expediency meritted for something like CTV insofar as it provides primitives to tackle time sensitive issues around privacy, scalability, self custody, and decentralization. The aforementioned properties may be difficult to reclaim once given away (with the exception of perhaps scalability).
>>> - Bringing CTV to an implemented state of near-unanimous "we could do this, technically" is good for concretely driving the process of review for any covenant proposals forward, irrespective of if we ultimately activate. (I.e., if there were a reason we could not do CTV safely, it would likely have implications for any other future covenant)
>>>
>>> Concretely, I'm not going to stop advocating for CTV based on the above, but I'm very happy to have something new in the mix to consider!
>>>
>>> Best,
>>>
>>> Jeremy
>>>
>>> --
>>> [@JeremyRubin](https://twitter.com/JeremyRubin)https://twitter.com/JeremyRubin
>>>
>>> On Wed, Jan 26, 2022 at 9:23 AM Russell O'Connor via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
>>>
>>>> Recapping the relationship between CTV and ANYPREVOUT::
>>>>
>>>> It is known that there is a significant amount of overlap in the applications that are enabled by the CTV and ANYPREVOUT proposals despite the fact that their primary applications (congestion control for CTV and eltoo lightning channels for ANYPREVOUT) are quite distinct.
>>>> In particular, ANYPREVOUT can enable most of the applications of CTV, albeit with a higher cost. The primary functionality of CTV is to allow a scriptPubKey to make a commitment to its spending transaction's hash with the input's TXID excluded from the hash. This exclusion is necessary because the scriptPubKey is hashed into the input's TXID, and including the TXID would cause a cycle of hash commitments, which is impossible to construct. On the other hand, ANYPREVOUT defines a signature hash mode that similarly excludes the inputs TXID for its purpose of rebindable signatures.
>>>>
>>>> This means that ANYPREVOUT can mimic most of the properties of CTV by committing both a public key along with an ANYPREVOUT signature inside scriptPubKey. In fact, the only reason Bitcoin doesn't have covenants today is due to this cycle between scriptPubKeys and the TXIDs that occur in all the sighash modes.
>>>>
>>>> The major differences between simulating CTV via ANYPREVOUT and the actual CTV proposal is: (1) The cost of simulating CTV. With CTV the spending transaction is committed using a hash of 32 bytes, while simulating it with ANYPREVOUT requires 64 bytes for a signature, and 32 bytes for some public key, plus a few more bytes for various flags. Some of that cost could be reduced by using the inner public key (1 byte representation) and, if we had CAT, maybe by assembling the signature from reusable pieces (i.e. setting the nonce of the commited signature equal to the public key).
>>>>
>>>> The other major difference is: (2) CTV's transaction hash covers values such as the number of inputs in the transaction and their sequence numbers, which ANYPREVOUT does not cover. CTV's hash contains enough information so that when combined with the missing TXIDs, you can compute the TXID of the spending transaction. In particular if the number of inputs is committed to being 1, once the scriptpubkey's transaction id is known and committed to the blockchain, the TXID of its spending transaction is deducible. And if that transaction has outputs that have CTV commitments in them, you can deduce their spending TXIDs in turn. While this is a pretty neat feature, something that ANYPREVOUT cannot mimic, the main application for it is listed as using congestion control to fund lightning channels, fixing their TXIDs in advance of them being placed on chain. However, if ANYPREVOUT were used to mimic CTV, then likely it would be eltoo channels that would be funded, and it isn't necessary to know the TXIDs of eltoo channels in advance in order to use them.
>>>>
>>>> An Alternative Proposal::
>>>>
>>>> Given the overlap in functionality between CTV and ANYPREVOUT, I think it makes sense to decompose their operations into their constituent pieces and reassemble their behaviour programmatically. To this end, I'd like to instead propose OP_TXHASH and OP_CHECKSIGFROMSTACKVERIFY.
>>>>
>>>> OP_TXHASH would pop a txhash flag from the stack and compute a (tagged) txhash in accordance with that flag, and push the resulting hash onto the stack.
>>>> OP_CHECKSIGFROMSTACKVERIFY would pop a pubkey, message, and signature from the stack and fail if the signature does not verify on that message.
>>>>
>>>> CTV and TXHASH have roughly equivalent functionality. 'CTV DROP' can be simulated by '<ctv_style_flag> TXHASH EQUALVERIFY'. The reverse is also true where '<ctv_style_flag> TXHASH' can be simulated by CTV by '<ctv-result-from-witness-stack> CTV', however, as you can see, simulating TXHASH from CTV is much more expensive than the other way around, because the resulting 32-byte hash result must be included as part of the witness stack.
>>>>
>>>> '<anyprevout-pubkey> CHECKSIGVERIFY can be simulated by '<apo_style_flag> TXHASH <pubkey> CHECKSIGFROMSTACKVERIFY'. Here we see the advantage of pushing the hash value onto the stack. APO can be simulated without needing to include a copy of the resulting txhash inside the witness data.
>>>>
>>>> In addition to the CTV and ANYPREVOUT applications, with CHECKSIGFROMSTACKVERIFY we can verify signatures on arbitrary messages signed by oracles for oracle applications. This is where we see the benefit of decomposing operations into primitive pieces. By giving users the ability to program their own use cases from components, we get more applications out of fewer op codes!
>>>>
>>>> Caveats::
>>>>
>>>> First, I acknowledge that replicating the behaviour of CTV and ANYPREVOUT does cost a few more bytes than using the custom purpose built proposals themselves. That is the price to be paid when we choose the ability to program solutions from pieces. But we get to reap the advantages of being able to build more applications from these pieces.
>>>>
>>>> Unlike CTV, TXHASH is not NOP-compatable and can only be implemented within tapscript. In particular, bare CTV isn't possible with this proposal. However, this proposal doesn't preclude the possibility of having CTV added to legacy script in while having TXHASH added to tapscript.
>>>>
>>>> For similar reasons, TXHASH is not amenable to extending the set of txflags at a later date. In theory, one could have TXHASH abort-with-success when encountering an unknown set of flags. However, this would make analyzing tapscript much more difficult. Tapscripts would then be able to abort with success or failure depending on the order script fragments are assembled and executed, and getting the order incorrect would be catastrophic. This behavior is manifestly different from the current batch of OP_SUCCESS opcodes that abort-with-success just by their mere presence, whether they would be executed or not.
>>>>
>>>> I believe the difficulties with upgrading TXHASH can be mitigated by designing a robust set of TXHASH flags from the start. For example having bits to control whether (1) the version is covered; (2) the locktime is covered; (3) txids are covered; (4) sequence numbers are covered; (5) input amounts are covered; (6) input scriptpubkeys are covered; (7) number of inputs is covered; (8) output amounts are covered; (9) output scriptpubkeys are covered; (10) number of outputs is covered; (11) the tapbranch is covered; (12) the tapleaf is covered; (13) the opseparator value is covered; (14) whether all, one, or no inputs are covered; (15) whether all, one or no outputs are covered; (16) whether the one input position is covered; (17) whether the one output position is covered; (18) whether the sighash flags are covered or not (note: whether or not the sighash flags are or are not covered must itself be covered). Possibly specifying which input or output position is covered in the single case and whether the position is relative to the input's position or is an absolute position.
>>>>
>>>> That all said, even if other txhash flag modes are needed in the future, adding TXHASH2 always remains an option.
>>>>
>>>> Interactions with potential future opcodes::
>>>>
>>>> We should give some consideration on how these opcodes may interact with future opcodes such as CAT, rolling SHA256 opcodes, or how it might interface with other covenant opcodes that may do things like, directly push input or output amounts onto the stack for computation purposes, opcodes which have been added to the Elements project.
>>>>
>>>> With CAT and/or rolling SHA256 opcodes and/or existing SHA256 opcodes, the CHECKSIGFROMSTACKVERIFY could verify signatures on programmatically assembled messages. Also, in combination with multiple calls to TXHASH, could be used to create signatures that commit to complex subsets of transaction data.
>>>>
>>>> If new opcodes are added to push parts of the transaction data direction onto the stack, e.g. OP_INSPECTOUTPUTVALUE, there is perhaps concern that they would obsolete TXHASH, since, in the presence of rolling SHA256 opcodes, TXHASH could be simulated. However, given that TXHASH can compactly create a hash of large portions of transaction data, it seems unlikely that TXHASH would fall into disuse. Also, a combination of TXHASH and transaction introspection opcodes can be used to build "subtractive covenants".
>>>>
>>>> The usual way of building a covenant, which we will call "additive covenants", is to push all the parts of the transaction data you would like to fix onto the stack, hash it all together, and verify the resulting hash matches a fixed value. Another way of building covenants, which we will call "subtractive covenants", is to push all the parts of the transaction data you would like to remain free onto the stack. Then use rolling SHA256 opcodes starting from a fixed midstate that commits to a prefix of the transaction hash data. The free parts are hashed into that midstate. Finally, the resulting hash value is verified to match a value returned by TXHASH. The ability to nicely build subtractive covenants depends on the details of how the TXHASH hash value is constructed, something that I'm told CTV has given consideration to.
>>>> _______________________________________________
>>>> bitcoin-dev mailing list
>>>> bitcoin-dev at lists.linuxfoundation.org
>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220128/4df9e5b2/attachment-0001.html>

From roconnor at blockstream.com  Fri Jan 28 13:56:25 2022
From: roconnor at blockstream.com (Russell O'Connor)
Date: Fri, 28 Jan 2022 08:56:25 -0500
Subject: [bitcoin-dev] TXHASH + CHECKSIGFROMSTACKVERIFY in lieu of CTV
	and ANYPREVOUT
In-Reply-To: <20220128013436.GA2939@erisian.com.au>
References: <CAMZUoK=pkZuovtifBzdqhoyegzG+9hRTFEc7fG9nZPDK4KbU3w@mail.gmail.com>
 <20220128013436.GA2939@erisian.com.au>
Message-ID: <CAMZUoK=U_-ah3cQbESE8hBXOvSMpxJJd1-ca0mYo7SvMi7izYQ@mail.gmail.com>

On Thu, Jan 27, 2022 at 8:34 PM Anthony Towns <aj at erisian.com.au> wrote:

> > An Alternative Proposal::
> >  ...
>
> > For similar reasons, TXHASH is not amenable to extending the set of
> txflags
> > at a later date.
>
> > I believe the difficulties with upgrading TXHASH can be mitigated by
> > designing a robust set of TXHASH flags from the start.  For example
> having
> > bits to control whether [...]
>
> I don't think that's really feasible -- eg, what you propose don't cover
> SIGHASH_GROUP:
>
>
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-July/019243.html
>

For more complex interactions, I was imagining combining this TXHASH
proposal with CAT and/or rolling SHA256 opcodes.  If TXHASH ended up
supporting relative or absolute input/output indexes then users could
assemble the hashes of the particular inputs and outputs they care about
into a single signed message.


> > That all said, even if other txhash flag modes are needed in the future,
> > adding TXHASH2 always remains an option.
>
> I think baking this in from day 0 might be better: make TXHASH be
> a multibyte opcode, so that when you decode "0xBB" on the stack,
> you also decode a serialize.h:VarInt as the version number.


I wouldn't be opposed to this.

> '<anyprevout-pubkey> CHECKSIGVERIFY can be simulated by '<apo_style_flag>
> TXHASH <pubkey> CHECKSIGFROMSTACKVERIFY'.
>
> I don't think that's quite right. BIP 118 anyprevout is done by taking
> the pubkey "P", marking it as "APO-capable" (by prefixing it with 0x01),
> and then getting a sighash and sig from the witness. Doing the same
> with TXHASH/CSFSV would just be replacing "<APO:P> CHECKSIGVERIFY" with
> "TXHASH <P> CSFSV" with the witness providing both the signature and
> txhash flag, just as separate elements rather than concatenated. (The
> "APO-capable" part is implicit in the "TXHASH" opcode)
>

Indeed. The TXHASH variant does require splitting the signature and txhash
flag across two stack items.  So it wouldn't be an operationally identical
drop in replacement.


> > In addition to the CTV and ANYPREVOUT applications, with
> > CHECKSIGFROMSTACKVERIFY we can verify signatures on arbitrary messages
> > signed by oracles for oracle applications.  This is where we see the
> > benefit of decomposing operations into primitive pieces.  By giving users
> > the ability to program their own use cases from components, we get more
> > applications out of fewer op codes!
>
> While I see the appeal of this from a language design perspective;
> I'm not sure it's really the goal we want. When I look at bitcoin's
> existing script, I see a lot of basic opcodes to do simple arithmetic and
> manipulate the stack in various ways, but the opcodes that are actually
> useful are more "do everything at once" things like check(multi)sig or
> sha256. It seems like what's most useful on the blockchain is a higher
> level language, rather than more of blockchain assembly language made
> up of small generic pieces. I guess "program their own use cases from
> components" seems to be coming pretty close to "write your own crypto
> algorithms" here...
>

Which operations in Script are actually composable today?

CHECKSIG composes with nothing else (other than possibly other CHECKSIGs)
as there are no other operations that manipulate pubkey keys or signature
data.

CLTV and CSV in principle can be composed with addition and subtraction and
comparison operations.  But where are you going to get other values to add
and subtract from?  I suppose you could compare the relative and absolute
locktimes to each other.

What do the HASH functions compose with?  Without CAT you cannot construct
messages to hash.  You can hash the result of the arithmetic operations,
but you are limited to hashing 32-bit (or 33-bit if you are generous)
strings, which is too little entropy to have any security properties.  You
can hash a public key or a signature I suppose.

I don't think there is much in the way of lessons to be drawn from how we
see Bitcoin Script used today with regards to programs built out of
reusable components.  User's haven't been composing programs, not because
they don't find composition useful, but rather because the existing
primitives do not lend themselves to being composed at all.

There is one aspect of Bitcoin Script that is composable, which is
(monotone) boolean combinations of the few primitive transaction conditions
that do exist.  The miniscript language captures nearly the entirety of
what is composable in Bitcoin Script today: which amounts to conjunctions,
disjunctions (and thresholds) of signatures, locktimes, and revealing hash
preimages.

TXHASH + CSFSV won't be enough by itself to allow for very interesting
programs Bitcoin Script yet, we still need CAT and friends for that, but
CSFSV is at least a step in that direction.  CSFSV can take arbitrary
messages and these messages can be fixed strings, or they can be hashes of
strings (that need to be revealed), or they can be hashes returned from
TXHASH, or they can be locktime values, or they can be values that are
added or subtracted from locktime values, or they can be values used for
thresholds, or they can be other pubkeys for delegation purposes, or they
can be other signatures ... for who knows what purpose.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220128/beac8333/attachment.html>

From roconnor at blockstream.com  Fri Jan 28 14:13:11 2022
From: roconnor at blockstream.com (Russell O'Connor)
Date: Fri, 28 Jan 2022 09:13:11 -0500
Subject: [bitcoin-dev] TXHASH + CHECKSIGFROMSTACKVERIFY in lieu of CTV
	and ANYPREVOUT
In-Reply-To: <CAPfvXfLr4n6RsS6VbEZR59=MRwAx41Crx88ko8-qnRXW4nFYGA@mail.gmail.com>
References: <CAMZUoK=pkZuovtifBzdqhoyegzG+9hRTFEc7fG9nZPDK4KbU3w@mail.gmail.com>
 <CAD5xwhhwqJ_AETAb3p_zUZmRX-Dzh8J9G984zwEs=KFsGN8aNQ@mail.gmail.com>
 <CAMZUoKmU1cwUAQaBv5m8oo8H3TWBvgsZ_OkQaMC0n0+3cpFtWg@mail.gmail.com>
 <CAPfvXfLr4n6RsS6VbEZR59=MRwAx41Crx88ko8-qnRXW4nFYGA@mail.gmail.com>
Message-ID: <CAMZUoKkvoJs0WtN71A_qRSwToP4YnY707WdW3C-KJYGXsmkjSw@mail.gmail.com>

On Thu, Jan 27, 2022 at 7:19 PM James O'Beirne <james.obeirne at gmail.com>
wrote:

> > I don't think implementing a CTV opcode that we expect to largely be
> obsoleted by a TXHASH at a later date is yielding good value from a soft
> fork process.
>
> This presumes the eventual adoption of TXHASH (or something like it).
> You're presenting a novel idea that, as far as I know, hasn't had much time
> to bake in public. Like Jeremy, I'm concerned by the combinatorial growth
> of flags and the implications that has for testing. Caching for something
> like TXHASH looks to me like a whole different ballgame relative to CTV,
> which has a single kind of hash.
>

Let's not overstate the concern around the combinatorics of TXHASH.   It's
not like there is a vast amount of cross-flag interaction we are talking
about here.  There are also a combinatorial number of ways of assembling
opcodes in Bitcoin script, but we aren't required to exhaustively test
every single possible Script program.


> Even if we were to adopt something like TXHASH, how long is it going to
> take to develop, test, and release? My guess is "a while" - in the
> meantime, users of Bitcoin are without a vault strategy that doesn't
> require either presigning transactions with ephemeral keys (operationally
> difficult) or multisig configurations that would make Rube Goldberg blush
> (operationally difficult and precarious). The utility of vaulting seems
> underappreciated among consensus devs and it's something I'd like to write
> about soon in a separate post.
>
> > The strongest argument I can make in favour of CTV would be something
> like: "We definitely want bare CTV and if we are going to add CTV to legacy
> script (since we cannot use TXHASH in legacy script), then it is actually
> easier not to exclude it from tapscript, even if we plan to add TXHASH to
> tapscript as well."
>
> Another argument for CTV (which I find especially persuasive) is its
> simplicity - it's relatively easy to reason about and, at this point,
> pretty well understood. It seems like a low-risk change relative to some of
> the other covenant proposals, nearly all of which elicit a good deal of
> headscratching (at least from me) and seem to require not only larger
> on-chain footprints but sizable code changes.
>


> > I am sensitive to technical debt and soft fork processes
>

> If OP_CTV ends up being the most practical approach for vaulting - among
> other things - in terms of weight (which it seems to be at the moment) I
> don't think "technical debt" is an applicable term.
>

Technical debt isn't a measure of weight of transactions.  It's a measure
of the code complexity needed to implement, in this case, a Bitcoin Script
interpreter.

By itself, adding a single new hash format for CTV isn't that complex, and
it is certainly simpler than this TXHASH proposal.  But then we need to add
another two slightly different hash formats for APO support.  And tomorrow
we will need yet another set of transaction hash formats for the next
thing, and so on, with each instance requiring going through its own
soft-fork process.  It is at that point we end up with something more
complicated and with more deployment risk than if we had just done
something like TXHASH at the very beginning.  But unlike other programming
environments, we cannot refactor our way out of such a situation.  We
cannot make a new script version while deprecating the old one.  Our only
option here is to be mindful of the long term implications of the design
choices we are making today.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220128/a793638a/attachment-0001.html>

From aj at erisian.com.au  Fri Jan 28 14:17:40 2022
From: aj at erisian.com.au (Anthony Towns)
Date: Sat, 29 Jan 2022 00:17:40 +1000
Subject: [bitcoin-dev] TXHASH + CHECKSIGFROMSTACKVERIFY in lieu of CTV
 and ANYPREVOUT
In-Reply-To: <XvyRH0U3-np2xDZhhaIgYDXFcTvAnLkP5n-7c58f1bMuh6jAvlF_22n2yquiyoFXYl0s7zQm_3zp46Fzn_tJkxN2Lsz6N75lJmqAS2rlCa4=@protonmail.com>
References: <CAMZUoK=pkZuovtifBzdqhoyegzG+9hRTFEc7fG9nZPDK4KbU3w@mail.gmail.com>
 <CAD5xwhhwqJ_AETAb3p_zUZmRX-Dzh8J9G984zwEs=KFsGN8aNQ@mail.gmail.com>
 <CAMZUoKmU1cwUAQaBv5m8oo8H3TWBvgsZ_OkQaMC0n0+3cpFtWg@mail.gmail.com>
 <CAPfvXfLr4n6RsS6VbEZR59=MRwAx41Crx88ko8-qnRXW4nFYGA@mail.gmail.com>
 <XvyRH0U3-np2xDZhhaIgYDXFcTvAnLkP5n-7c58f1bMuh6jAvlF_22n2yquiyoFXYl0s7zQm_3zp46Fzn_tJkxN2Lsz6N75lJmqAS2rlCa4=@protonmail.com>
Message-ID: <20220128141740.GA3331@erisian.com.au>

On Fri, Jan 28, 2022 at 01:14:07PM +0000, Michael Folkson via bitcoin-dev wrote:
> There is not even a custom signet with CTV (as far as I know) 

https://twitter.com/jeremyrubin/status/1339699281192656897

signetchallenge=512102946e8ba8eca597194e7ed90377d9bbebc5d17a9609ab3e35e706612ee882759351ae
addnode=50.18.75.225

But I think there's only been a single coinbase consolidation tx, and no
actual CTV transactions?

Cheers,
aj


From james.obeirne at gmail.com  Fri Jan 28 15:14:12 2022
From: james.obeirne at gmail.com (James O'Beirne)
Date: Fri, 28 Jan 2022 10:14:12 -0500
Subject: [bitcoin-dev] TXHASH + CHECKSIGFROMSTACKVERIFY in lieu of CTV
	and ANYPREVOUT
In-Reply-To: <CAMZUoKkvoJs0WtN71A_qRSwToP4YnY707WdW3C-KJYGXsmkjSw@mail.gmail.com>
References: <CAMZUoK=pkZuovtifBzdqhoyegzG+9hRTFEc7fG9nZPDK4KbU3w@mail.gmail.com>
 <CAD5xwhhwqJ_AETAb3p_zUZmRX-Dzh8J9G984zwEs=KFsGN8aNQ@mail.gmail.com>
 <CAMZUoKmU1cwUAQaBv5m8oo8H3TWBvgsZ_OkQaMC0n0+3cpFtWg@mail.gmail.com>
 <CAPfvXfLr4n6RsS6VbEZR59=MRwAx41Crx88ko8-qnRXW4nFYGA@mail.gmail.com>
 <CAMZUoKkvoJs0WtN71A_qRSwToP4YnY707WdW3C-KJYGXsmkjSw@mail.gmail.com>
Message-ID: <CAPfvXfLWtDvgJYwQCaxnww5jyQkqFsi6aG0OUxtp3Okx_ab7Hw@mail.gmail.com>

> Technical debt isn't a measure of weight of transactions.

Sorry, my original sentence was a little unclear. I meant to say that the
notion that CTV is just a subpar waypoint en route to a more general
covenant system may not be accurate if it is a more efficient way (in terms
of chainstate/weight) to express highly useful patterns like vaults. In
that case, characterizing CTV as technical debt wouldn't be right.

> Our only option here is to be mindful of the long term implications of
the design choices we are making today.

Your points are well taken - I don't think anyone is arguing against
thinking hard about consensus changes. But I have yet to see a proposal for
covenants that is as efficient on-chain and easy to reason about as CTV is.

I also think there's some value in "legging into" covenants by deploying a
simple, non-recursive construction like CTV that services some very
important uses, and then taking as much time as necessary to think about
how to solve more existential problems, like UTXO scalability, that likely
require a recursive covenant construction.

There doesn't have to be mutual exclusion in the approaches, especially
when the maintenance burden of CTV seems to be so low. If we end up
deploying something that requires a wider variety of in-script hashing, it
seems likely that CTV's hash will be able to "free ride" on whatever more
general sighash cache structure we come up with.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220128/d4424a62/attachment-0001.html>

From billy.tetrud at gmail.com  Fri Jan 28 15:27:30 2022
From: billy.tetrud at gmail.com (Billy Tetrud)
Date: Fri, 28 Jan 2022 09:27:30 -0600
Subject: [bitcoin-dev] PathCoin
In-Reply-To: <By1G6iST5DCXZJVfEd3HzdPgU3e_NGoqvH-5UoqsOzY8qjiOmy5iHXiOwjXtm7Znq1Z6z-XOL0IPDSyQiLOZ6-lRQ-vi1I6Cba4aqywe8xw=@protonmail.com>
References: <jMANAdspMdPb1ZCFttQ3tGmkZ0oYojLY5Oz1d8ZSNl3JhZeDuT1xK0vxTu8uyHcgPXWsM_6XNb3R9tVD3_Yez88pviFrCaNt7LPqdWVBWus=@protonmail.com>
 <CAGpPWDY3vZ2JOsa1UhoT-z8kfxqkVWcq1nyt9Ah5ye6HE_6gOQ@mail.gmail.com>
 <By1G6iST5DCXZJVfEd3HzdPgU3e_NGoqvH-5UoqsOzY8qjiOmy5iHXiOwjXtm7Znq1Z6z-XOL0IPDSyQiLOZ6-lRQ-vi1I6Cba4aqywe8xw=@protonmail.com>
Message-ID: <CAGpPWDa=YBMrkuUHD0ogS3uxWq0g4LZubm=g9yQVuEffudsJhA@mail.gmail.com>

> what is the incentive for the honest party to punish?

Justice. Also, there's no incentive for the honest party to not punish -
presumably their software would automatically punish, and why go through
any effort to stop it? A 1 cent bribe certainly wouldn't be enough. Maybe a
$10 bribe might get someone somewhere to install hacked up software to be
able to fulfill such a bribe, but even then i think it would be a rare
person that would stoop to that. Were it to become a true negotiation, the
cheater has more to lose, and therefore the bribee has a lot of leverage.

> my strong intuition is that it will never be properly stable.

I'm curious what you mean by "stable". You had mentioned the game theory is
"fragile" and I'm wondering if there's more to this than just "what
incentive does the honest party have to burn?"

To be clear, I'm not advocating for Sabu and I haven't done any deep
thinking about burn based incentives.

One thing I thought of regarding path coin, if there's ever a situation
where there are multiple choices in path, whatever punishment there is
probably needs to be able to handle the multiple of the number of paths.
The only way around this i can imagine is to have some method of
coordination between payees, eg a place where a payee records their payment
such that a payee who has been double spent on to become aware they've been
double spent on and initiate the punishment. But once you have that
coordination mechanism it starts not looking more like an on chain
transaction.

On Tue, Jan 25, 2022, 06:50 AdamISZ <AdamISZ at protonmail.com> wrote:

> Hi Billy,
> I read through the description. I think systems like this *mostly* fail
> due to game theory.
>
> With punishment-by-burn you have various issues that make it to my mind
> pretty unstable, too unstable to use for any serious system. To be fair,
> this isn't cut-and-dried. So let me unpack:
>
> (I briefly touched on why I dismissed penalties via burn in my gist,
> section: "Not feeling the burn".)
>
> There is a distinction between penalty via burn to unspendable output and
> penalty via burn to miner fees. The latter has an obvious problem: if your
> counterparties collude with (or are) miners, they may not actually be
> penalized at all (now to be clear, that is a problematic attack ex nihilo:
> nobody usually can be sure who's mining the next block, but markets have a
> way of solving and coordinating such things: see e.g. the various MEV
> discussions and initiatives in Ethereum for an example of that).
>
> But the former (provable burn) is still imo extremely unstable: if the
> penalty tx destroys all the money, what is the incentive for the honest
> party to punish? In such a scenario even a one cent donation from the
> attacker to the victim might prevent the penalty from happening.
> You can combine 'destruction of most, or some, of the funds' with a
> smaller payout to the aggrieved party, but then again you have to factor in
> the possibility of bribes. The Sabu post you linked describes it as: "There
> are precise and delicate formulas for calculating the amount of loss of the
> issuer and the creditor, which ensures that just and true act in both
> parties are cost-effective in all situations." I agree it's delicate, but
> after having spent time looking into these things, my strong intuition is
> that it will never be properly stable.
>
> In the PathCoin description I am specifically looking for a trustless
> system, with this finesse: we still count it as trustless even though we
> are using penalties as disincentive, because the penalty *consists of a
> payment directly from the attacker to the attacked, and that payment is
> larger than the amount stolen*. I claim that that *is* stable.
>
> Notice that Lightning has the same model (in LN-Penalty), as long as
> 'claiming the whole channel capacity' is enough to be larger than what is
> stolen (see: channel reserves etc.).
>
> Sent with ProtonMail <https://protonmail.com/> Secure Email.
>
>
> ??????? Original Message ???????
> On Tuesday, January 25th, 2022 at 11:53, Billy Tetrud via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
> There was a protocol someone mentioned a while back called Sabu that had
> the same goals. As i recall, it had some pretty promising constructs, but
> would have a critical vulnerability that could be exploited by miners. This
> is the write up:
>
>
> https://raymo-49157.medium.com/time-to-boost-bitcoin-circulation-million-transactions-per-second-and-privacy-1eef8568d180
>
> Perhaps some of the techniques there could be combined with your ideas to
> get closer to a solution.
>
> On Mon, Jan 24, 2022, 08:51 AdamISZ via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>> Hello list,
>>
>> I took the time to write up this rather out-there idea:
>>
>> Imagine you wanted to send a coin just like email, i.e. just transfer
>> data to the counterparty.
>>
>> Clearly this is in general entirely impossible; but with what
>> restrictions and assumptions could you create a toy version of it?
>>
>> See this gist for a detailed build up of the idea:
>>
>> https://gist.github.com/AdamISZ/b462838cbc8cc06aae0c15610502e4da
>>
>> Basically: using signature adaptors and CTV or a similar covenant, you
>> could create a fully trustless transfer of control of a utxo from one party
>> to another with no interaction with the rest of the group, at the time of
>> transfer (modulo of course lots and lots of one-time setup).
>>
>> The limitations are extreme and as you'd imagine. In the gist I feel like
>> I got round one of them, but not the others.
>>
>> (I very briefly mention comparison to e.g. statechains or payment pools;
>> they are making other tradeoffs against the 'digital cash' type of goal.
>> There is no claim that this 'pathcoin' idea is even viable yet, let alone
>> better than those ideas).
>>
>> Publishing this because I feel like it's the kind of thing imaginative
>> minds like the ones here, may be able to develop further. Possibly!
>>
>>
>> waxwing / AdamISZ
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220128/18dd745a/attachment-0001.html>

From jlrubin at mit.edu  Fri Jan 28 16:38:58 2022
From: jlrubin at mit.edu (Jeremy)
Date: Fri, 28 Jan 2022 08:38:58 -0800
Subject: [bitcoin-dev] TXHASH + CHECKSIGFROMSTACKVERIFY in lieu of CTV
	and ANYPREVOUT
In-Reply-To: <20220128141740.GA3331@erisian.com.au>
References: <CAMZUoK=pkZuovtifBzdqhoyegzG+9hRTFEc7fG9nZPDK4KbU3w@mail.gmail.com>
 <CAD5xwhhwqJ_AETAb3p_zUZmRX-Dzh8J9G984zwEs=KFsGN8aNQ@mail.gmail.com>
 <CAMZUoKmU1cwUAQaBv5m8oo8H3TWBvgsZ_OkQaMC0n0+3cpFtWg@mail.gmail.com>
 <CAPfvXfLr4n6RsS6VbEZR59=MRwAx41Crx88ko8-qnRXW4nFYGA@mail.gmail.com>
 <XvyRH0U3-np2xDZhhaIgYDXFcTvAnLkP5n-7c58f1bMuh6jAvlF_22n2yquiyoFXYl0s7zQm_3zp46Fzn_tJkxN2Lsz6N75lJmqAS2rlCa4=@protonmail.com>
 <20220128141740.GA3331@erisian.com.au>
Message-ID: <CAD5xwhhk5iXQrbk7o22JQNxiS9e22NDDYmSctMPL4j3jYcnn2g@mail.gmail.com>

I probably need to reset it -- I ran into some issues with the IBD latch
bug IIRC and had difficulty producing new blocks.

I sent funds as a manual faucet to at least one person... not aware of
anyone else finding use for the signet. In part this is due to the fact
that in order to run a signet, you also kind of need to run some kind of
faucet on it, which wasn't readily available when I launched it previously.
I think I can use https://github.com/jsarenik/bitcoin-faucet-shell now
though.

Usually people are using Regtest to play around with CTV less so Signet.
There is value in a signet, but I don't think that "there's not a signet
for it" is a blocking issue v.s. nice to have.
--
@JeremyRubin <https://twitter.com/JeremyRubin>
<https://twitter.com/JeremyRubin>


On Fri, Jan 28, 2022 at 6:18 AM Anthony Towns via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> On Fri, Jan 28, 2022 at 01:14:07PM +0000, Michael Folkson via bitcoin-dev
> wrote:
> > There is not even a custom signet with CTV (as far as I know)
>
> https://twitter.com/jeremyrubin/status/1339699281192656897
>
>
> signetchallenge=512102946e8ba8eca597194e7ed90377d9bbebc5d17a9609ab3e35e706612ee882759351ae
> addnode=50.18.75.225
>
> But I think there's only been a single coinbase consolidation tx, and no
> actual CTV transactions?
>
> Cheers,
> aj
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220128/e92ac17f/attachment.html>

From jlrubin at mit.edu  Fri Jan 28 16:53:40 2022
From: jlrubin at mit.edu (Jeremy)
Date: Fri, 28 Jan 2022 08:53:40 -0800
Subject: [bitcoin-dev] [dlc-dev] CTV dramatically improves DLCs
In-Reply-To: <CABPZDUyMmyt0UCmHYfm+s-zs=iLjxXB0VtdJZ64X5HA3XLFESA@mail.gmail.com>
References: <CAH5Bsr2vxL3FWXnJTszMQj83jTVdRvvuVpimEfY7JpFCyP1AZA@mail.gmail.com>
 <2b316504-f785-b1b3-9ff9-8d781d6c0d9b@gmail.com>
 <CABPZDUyMmyt0UCmHYfm+s-zs=iLjxXB0VtdJZ64X5HA3XLFESA@mail.gmail.com>
Message-ID: <CAD5xwhhx3LmCW8Cup=mzmhosxu=WD=HVOk1pFYNe3oTmfQwJFg@mail.gmail.com>

Thibaut,

CSFS might have independent benefits, but in this case CTV is not being
used in the Oracle part of the DLC, it's being used in the user generated
mapping of Oracle result to Transaction Outcome.

So it'd only be complimentary if you came up with something CSFS based for
the Oracles.

Best,

Jeremy


On Thu, Jan 27, 2022 at 12:59 AM Thibaut Le Guilly via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Hi,
>
> Lloyd, thanks for this excellent writeup. I must say that indeed using CTV
> seems like it would very much lower the complexity of the DLC protocol (and
> it seems like APO would also work, thanks Jonas for pointing that out).
> Though thinking about it, I can't help wondering if the ideal op code for
> DLC wouldn't actually be CHECKSIGFROMSTACK? It feels to me that this would
> give the most natural way of doing things. If I'm not mistaken, this would
> enable simply requiring an oracle signature over the outcome, without any
> special trick, and without even needing the oracle to release a nonce in
> advance (the oracle could sign `event_outcome + event_id` to avoid
> signature reuse). I must say that I haven't studied covenant opcodes in
> detail yet so is that line of thinking correct or am I missing something?
>
> Cheers,
>
> Thibaut
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220128/e80aa4e2/attachment.html>

From jlrubin at mit.edu  Fri Jan 28 17:21:09 2022
From: jlrubin at mit.edu (Jeremy)
Date: Fri, 28 Jan 2022 09:21:09 -0800
Subject: [bitcoin-dev] CTV dramatically improves DLCs
In-Reply-To: <CAH5Bsr2vxL3FWXnJTszMQj83jTVdRvvuVpimEfY7JpFCyP1AZA@mail.gmail.com>
References: <CAH5Bsr2vxL3FWXnJTszMQj83jTVdRvvuVpimEfY7JpFCyP1AZA@mail.gmail.com>
Message-ID: <CAD5xwhiJiopwH87Bn+yq_0-XXSJYOtNzUg4JCaYwuj=oo9CacA@mail.gmail.com>

Lloyd,

This is an excellent write up, the idea and benefits are clear.

Is it correct that in the case of a 3/5th threshold it is a total 10x * 30x
= 300x improvement? Quite impressive.

I have a few notes of possible added benefits / features of DLCs with CTV:

1) CTV also enables a "trustless timeout" branch, whereby you can have a
failover claim that returns funds to both sides.

There are a few ways to do this:

A) The simplest is just an oracle-free <STH(timeout tx)> CTV whereby the
timeout transaction has an absolute/relative timelock after the creation of
the DLC in question.

B) An alternative approach I like is to have the base DLC have a branch
`<STH(begin timeout)> CTV` which pays into a DLC that is the exact same
except it removes the just-used branch and replaces it with `<STH(timeout
tx)> CTV` which contains a relative timelock R for the desired amount of
time to resolve. This has the advantage of always guaranteeing at least R
amount of time since the Oracles have been claimed to be non-live to
"return funds"  to parties participating


2) CTV DLCs are non-interactive asynchronously third-party unilaterally
creatable.

What I mean by this is that it is possible for a single party to create a
DLC on behalf of another user since there is no required per-instance
pre-signing or randomly generated state. E.g., if Alice wants to create a
DLC with Bob, and knows the contract details, oracles, and a key for Bob,
she can create the contract and pay to it unilaterally as a payment to Bob.

This enables use cases like pay-to-DLC addresses. Pay-to-DLC addresses can
also be constructed and then sent (along with a specific amount) to a third
party service (such as an exchange or Lightning node) to create DLCs
without requiring the third party service to do anything other than make
the payment as requested.


3) CTV DLCs can be composed in interesting ways

Options over DLCs open up many exciting types of instrument where Alice can
do things like:
A) Create a Option expiring in 1 week where Bob can add funds to pay a
premium and "Open" a DLC on an outcome closing in 1 year
B) Create an Option expiring in 1 week where one-of-many Bobs can pay the
premium (on-chain DEX?).

 See https://rubin.io/bitcoin/2021/12/20/advent-23/ for more concrete stuff
around this.

There are also opportunities for perpetual-like contracts where you could
combine into one logical DLC 12 DLCs closing 1 per month that can either be
payed out all at once at the end of the year, or profit pulled out
partially at any time earlier.

4) This satisfies (I think?) my request to make DLCs expressible as Sapio
contracts in https://rubin.io/bitcoin/2021/12/20/advent-23/

5) An additional performance improvement can be had for iterative DLCs in
Lightning where you might trade over a fixed set of attestation points with
variable payout curves (e.g., just modifying some set of the CTV points).
Defer to you on performance, but this could help enable some more HFT-y
experiences for DLCs in LN

Best,

Jeremy
--
@JeremyRubin <https://twitter.com/JeremyRubin>
<https://twitter.com/JeremyRubin>


On Mon, Jan 24, 2022 at 3:04 AM Lloyd Fournier via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Hi dlc-dev and bitcoin-dev,
>
> tl;dr OP_CTV simplifies and improves performance of DLCs by a factor of *a lot*.
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220128/442b0946/attachment-0001.html>

From jeremy.l.rubin at gmail.com  Fri Jan 28 19:38:29 2022
From: jeremy.l.rubin at gmail.com (Jeremy Rubin)
Date: Fri, 28 Jan 2022 11:38:29 -0800
Subject: [bitcoin-dev] CTV dramatically improves DLCs
In-Reply-To: <CAD5xwhiJiopwH87Bn+yq_0-XXSJYOtNzUg4JCaYwuj=oo9CacA@mail.gmail.com>
References: <CAH5Bsr2vxL3FWXnJTszMQj83jTVdRvvuVpimEfY7JpFCyP1AZA@mail.gmail.com>
 <CAD5xwhiJiopwH87Bn+yq_0-XXSJYOtNzUg4JCaYwuj=oo9CacA@mail.gmail.com>
Message-ID: <CAD5xwhgFUz8F4h0J1kXUazXvhJvTuzKTtXkKqHU7T5QoLe11-A@mail.gmail.com>

Apologies for the double post*, but I just had a follow up idea
that's pretty interesting to me.

You can make the close portion of a DLC be an "optimistic" execution with a
choice of justice scheme. This enables closing a DLC somewhat securely
without exposing the oracles on-chain at all.

Assuming honest oracles, the only cost of this mechanism over previous is
that you have to do a script path spend (but it can be a top-level branch,
since it's the "most likely" one).


For every DLC branch like:

*<CET-hash-i> CHECKTEMPLATEVERIFY
<attestation-point1> CHECKSIG
<attestation-point2> CHECKSIGADD
<attestation-point3> CHECKSIGADD
2 EQUAL*


add a 2 branches:


*<CET-hash-A> CHECKTEMPLATEVERIFY
<Alice> CHECKSIG
*

*<CET-hash-B> CHECKTEMPLATEVERIFY
<Bob> CHECKSIG*


This enables Alice or Bob to "lock in" a redemption of the contract
that becomes spendable by them after <period>. CET-hash-* should
include a nLockTime/nSequence such that it is at the same time as the
attestation points should be known.


Where CET-hash-T sends funds to a DLC that has the following conditions:


(cooperate):

*pk_internal=musig(Alice, Bob)*

or (unilateral timeout)

*<T> Checksig <2 weeks> CSV*

or (show oracles for this outcome)

*<CET-hash-i> CHECKTEMPLATEVERIFY*

*<attestation-point1> CHECKSIG
<attestation-point2> CHECKSIGADD
<attestation-point3> CHECKSIGADD
2 EQUAL*

or (justice with no punishment), forall j !=i:

*<CET-hash-j> CHECKTEMPLATEVERIFY*

*<attestation-point1> CHECKSIG
<attestation-point2> CHECKSIGADD
<attestation-point3> CHECKSIGADD
2 EQUAL*

or (justice with punishment), forall j!=i:

*<CET-hash-punish-j, send funds to not-T> CHECKTEMPLATEVERIFY*

*<attestation-point1> CHECKSIG
<attestation-point2> CHECKSIGADD
<attestation-point3> CHECKSIGADD
2 EQUAL*


Justice with punishment seems to me to be the better option since T is
actively choosing this resolution (the CTV transition is signed), but
justice with no punishment might be better if you think the oracles
might screw you over and collude to steal.

One interesting question is if the justice transactions can be
"compressed" to be fewer for a given outcome. I.e., if Bob has claimed
that the outcome is 35, and there are 100 total outcomes, do we need
99 justice paths or is there a way to make fewer of them? Intuitively,
it would seem so, because if we have a 8-10 threshold for picking a
path, a 3-10 proof would be sufficient to prove Bob claimed to know
the 8-10 falsely. However, that then means 3-10 could collude, v.s.
the fraud proof requiring a full 8-10 counter. Things to think about!


Best,


Jeremy


* this might actually be a triple or quadruple post depending on how
you count, I adjusted which email was the subscriber on my mailing
list account and resultantly sent from the old address... sincere
apologies if you are seeing this message >1 times to those who were on
the CC.

--
@JeremyRubin <https://twitter.com/JeremyRubin>
<https://twitter.com/JeremyRubin>


On Fri, Jan 28, 2022 at 9:21 AM Jeremy <jlrubin at mit.edu> wrote:

> Lloyd,
>
> This is an excellent write up, the idea and benefits are clear.
>
> Is it correct that in the case of a 3/5th threshold it is a total 10x *
> 30x = 300x improvement? Quite impressive.
>
> I have a few notes of possible added benefits / features of DLCs with CTV:
>
> 1) CTV also enables a "trustless timeout" branch, whereby you can have a
> failover claim that returns funds to both sides.
>
> There are a few ways to do this:
>
> A) The simplest is just an oracle-free <STH(timeout tx)> CTV whereby the
> timeout transaction has an absolute/relative timelock after the creation of
> the DLC in question.
>
> B) An alternative approach I like is to have the base DLC have a branch
> `<STH(begin timeout)> CTV` which pays into a DLC that is the exact same
> except it removes the just-used branch and replaces it with `<STH(timeout
> tx)> CTV` which contains a relative timelock R for the desired amount of
> time to resolve. This has the advantage of always guaranteeing at least R
> amount of time since the Oracles have been claimed to be non-live to
> "return funds"  to parties participating
>
>
> 2) CTV DLCs are non-interactive asynchronously third-party unilaterally
> creatable.
>
> What I mean by this is that it is possible for a single party to create a
> DLC on behalf of another user since there is no required per-instance
> pre-signing or randomly generated state. E.g., if Alice wants to create a
> DLC with Bob, and knows the contract details, oracles, and a key for Bob,
> she can create the contract and pay to it unilaterally as a payment to Bob.
>
> This enables use cases like pay-to-DLC addresses. Pay-to-DLC addresses can
> also be constructed and then sent (along with a specific amount) to a third
> party service (such as an exchange or Lightning node) to create DLCs
> without requiring the third party service to do anything other than make
> the payment as requested.
>
>
> 3) CTV DLCs can be composed in interesting ways
>
> Options over DLCs open up many exciting types of instrument where Alice
> can do things like:
> A) Create a Option expiring in 1 week where Bob can add funds to pay a
> premium and "Open" a DLC on an outcome closing in 1 year
> B) Create an Option expiring in 1 week where one-of-many Bobs can pay the
> premium (on-chain DEX?).
>
>  See https://rubin.io/bitcoin/2021/12/20/advent-23/ for more concrete
> stuff around this.
>
> There are also opportunities for perpetual-like contracts where you could
> combine into one logical DLC 12 DLCs closing 1 per month that can either be
> payed out all at once at the end of the year, or profit pulled out
> partially at any time earlier.
>
> 4) This satisfies (I think?) my request to make DLCs expressible as Sapio
> contracts in https://rubin.io/bitcoin/2021/12/20/advent-23/
>
> 5) An additional performance improvement can be had for iterative DLCs in
> Lightning where you might trade over a fixed set of attestation points with
> variable payout curves (e.g., just modifying some set of the CTV points).
> Defer to you on performance, but this could help enable some more HFT-y
> experiences for DLCs in LN
>
> Best,
>
> Jeremy
>
> --
> @JeremyRubin <https://twitter.com/JeremyRubin>
>
>
> On Mon, Jan 24, 2022 at 3:04 AM Lloyd Fournier via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>> Hi dlc-dev and bitcoin-dev,
>>
>> tl;dr OP_CTV simplifies and improves performance of DLCs by a factor of *a lot*.
>>
>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220128/7ec469d9/attachment.html>

From alex.schoof at gmail.com  Fri Jan 28 21:14:12 2022
From: alex.schoof at gmail.com (Alex Schoof)
Date: Fri, 28 Jan 2022 16:14:12 -0500
Subject: [bitcoin-dev] CTV dramatically improves DLCs
In-Reply-To: <CAD5xwhiJiopwH87Bn+yq_0-XXSJYOtNzUg4JCaYwuj=oo9CacA@mail.gmail.com>
References: <CAH5Bsr2vxL3FWXnJTszMQj83jTVdRvvuVpimEfY7JpFCyP1AZA@mail.gmail.com>
 <CAD5xwhiJiopwH87Bn+yq_0-XXSJYOtNzUg4JCaYwuj=oo9CacA@mail.gmail.com>
Message-ID: <CA+2b5C144Hz299qLiJ4beSw_x5U9xUbEXgG+rpbqJng2zCfhKQ@mail.gmail.com>

> CTV DLCs are non-interactive asynchronously third-party unilaterally
creatable.

This is super interesting. I think that would make it easier to do
multi-party DLCs. With a "normal" DLC, you need to have N parties
exchanging and signing CETs and you end up with a combinatorial explosion
of signing operations to perform. It sounds like if you did it with CTV,
then each party could compute all the outcomes on their own in parallel (to
be able to generate commitments for each tapleaf) and then just exchange
and sign the single opening transaction for the DLC. Or for devices with
limited resources, you could have a coordinator compute the whole TR tree
and publish a ZKP to the other signers.

Cheers,

Alex


On Fri, Jan 28, 2022 at 12:21 PM Jeremy via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Lloyd,
>
> This is an excellent write up, the idea and benefits are clear.
>
> Is it correct that in the case of a 3/5th threshold it is a total 10x *
> 30x = 300x improvement? Quite impressive.
>
> I have a few notes of possible added benefits / features of DLCs with CTV:
>
> 1) CTV also enables a "trustless timeout" branch, whereby you can have a
> failover claim that returns funds to both sides.
>
> There are a few ways to do this:
>
> A) The simplest is just an oracle-free <STH(timeout tx)> CTV whereby the
> timeout transaction has an absolute/relative timelock after the creation of
> the DLC in question.
>
> B) An alternative approach I like is to have the base DLC have a branch
> `<STH(begin timeout)> CTV` which pays into a DLC that is the exact same
> except it removes the just-used branch and replaces it with `<STH(timeout
> tx)> CTV` which contains a relative timelock R for the desired amount of
> time to resolve. This has the advantage of always guaranteeing at least R
> amount of time since the Oracles have been claimed to be non-live to
> "return funds"  to parties participating
>
>
> 2) CTV DLCs are non-interactive asynchronously third-party unilaterally
> creatable.
>
> What I mean by this is that it is possible for a single party to create a
> DLC on behalf of another user since there is no required per-instance
> pre-signing or randomly generated state. E.g., if Alice wants to create a
> DLC with Bob, and knows the contract details, oracles, and a key for Bob,
> she can create the contract and pay to it unilaterally as a payment to Bob.
>
> This enables use cases like pay-to-DLC addresses. Pay-to-DLC addresses can
> also be constructed and then sent (along with a specific amount) to a third
> party service (such as an exchange or Lightning node) to create DLCs
> without requiring the third party service to do anything other than make
> the payment as requested.
>
>
> 3) CTV DLCs can be composed in interesting ways
>
> Options over DLCs open up many exciting types of instrument where Alice
> can do things like:
> A) Create a Option expiring in 1 week where Bob can add funds to pay a
> premium and "Open" a DLC on an outcome closing in 1 year
> B) Create an Option expiring in 1 week where one-of-many Bobs can pay the
> premium (on-chain DEX?).
>
>  See https://rubin.io/bitcoin/2021/12/20/advent-23/ for more concrete
> stuff around this.
>
> There are also opportunities for perpetual-like contracts where you could
> combine into one logical DLC 12 DLCs closing 1 per month that can either be
> payed out all at once at the end of the year, or profit pulled out
> partially at any time earlier.
>
> 4) This satisfies (I think?) my request to make DLCs expressible as Sapio
> contracts in https://rubin.io/bitcoin/2021/12/20/advent-23/
>
> 5) An additional performance improvement can be had for iterative DLCs in
> Lightning where you might trade over a fixed set of attestation points with
> variable payout curves (e.g., just modifying some set of the CTV points).
> Defer to you on performance, but this could help enable some more HFT-y
> experiences for DLCs in LN
>
> Best,
>
> Jeremy
> --
> @JeremyRubin <https://twitter.com/JeremyRubin>
> <https://twitter.com/JeremyRubin>
>
>
> On Mon, Jan 24, 2022 at 3:04 AM Lloyd Fournier via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>> Hi dlc-dev and bitcoin-dev,
>>
>> tl;dr OP_CTV simplifies and improves performance of DLCs by a factor of *a lot*.
>>
>>
>> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>


-- 


Alex Schoof
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220128/95d5f0c6/attachment-0001.html>

From roconnor at blockstream.com  Sat Jan 29 15:43:13 2022
From: roconnor at blockstream.com (Russell O'Connor)
Date: Sat, 29 Jan 2022 10:43:13 -0500
Subject: [bitcoin-dev] TXHASH + CHECKSIGFROMSTACKVERIFY in lieu of CTV
	and ANYPREVOUT
In-Reply-To: <CAPfvXfLWtDvgJYwQCaxnww5jyQkqFsi6aG0OUxtp3Okx_ab7Hw@mail.gmail.com>
References: <CAMZUoK=pkZuovtifBzdqhoyegzG+9hRTFEc7fG9nZPDK4KbU3w@mail.gmail.com>
 <CAD5xwhhwqJ_AETAb3p_zUZmRX-Dzh8J9G984zwEs=KFsGN8aNQ@mail.gmail.com>
 <CAMZUoKmU1cwUAQaBv5m8oo8H3TWBvgsZ_OkQaMC0n0+3cpFtWg@mail.gmail.com>
 <CAPfvXfLr4n6RsS6VbEZR59=MRwAx41Crx88ko8-qnRXW4nFYGA@mail.gmail.com>
 <CAMZUoKkvoJs0WtN71A_qRSwToP4YnY707WdW3C-KJYGXsmkjSw@mail.gmail.com>
 <CAPfvXfLWtDvgJYwQCaxnww5jyQkqFsi6aG0OUxtp3Okx_ab7Hw@mail.gmail.com>
Message-ID: <CAMZUoKkqEx5mh9Aq9XFc=7YPKmfObMzEipECFuWm4e3q_tVEEQ@mail.gmail.com>

On Fri, Jan 28, 2022 at 10:14 AM James O'Beirne <james.obeirne at gmail.com>
wrote:

> > Technical debt isn't a measure of weight of transactions.
>
> Sorry, my original sentence was a little unclear. I meant to say that the
> notion that CTV is just a subpar waypoint en route to a more general
> covenant system may not be accurate if it is a more efficient way (in terms
> of chainstate/weight) to express highly useful patterns like vaults. In
> that case, characterizing CTV as technical debt wouldn't be right.
>

It only costs a few more weight units, on the order of 2 or 3, to use
TXHASH in place of CTV.  Notably, the reverse, using CTV in place of
TXHASH, is much more expensive, requiring more than 32 weight units.


> > Our only option here is to be mindful of the long term implications of
> the design choices we are making today.
>
> Your points are well taken - I don't think anyone is arguing against
> thinking hard about consensus changes. But I have yet to see a proposal for
> covenants that is as efficient on-chain and easy to reason about as CTV is.
>
> I also think there's some value in "legging into" covenants by deploying a
> simple, non-recursive construction like CTV that services some very
> important uses, and then taking as much time as necessary to think about
> how to solve more existential problems, like UTXO scalability, that likely
> require a recursive covenant construction.
>
> There doesn't have to be mutual exclusion in the approaches, especially
> when the maintenance burden of CTV seems to be so low. If we end up
> deploying something that requires a wider variety of in-script hashing, it
> seems likely that CTV's hash will be able to "free ride" on whatever more
> general sighash cache structure we come up with.
>

Perhaps there is some misunderstanding.  TXHASH + CSFSV doesn't allow for
complex or recursive covenants.  Typically CAT is needed, at minimum, to
create those sorts of things.  TXHASH still amounts to deploying a
non-recursive covenant construction.

With regards to CTV, in short my primary criticisms are (1) Push semantics
is preferable to verify semantics, because simulating verify semantics from
push is cheap, while simulating push semantics from verify is not
particularly cheap.
And (2) given Push semantics we ought to have parameters to support both
CTV-style hashes and APO-style hashes (which in the presence of CSFSV gives
us APO applications), and, while we are at it, as many other style hashes
as we can reasonably devise so we don't have to go through yet another
soft-fork process every time someone comes up with a new subset of
transaction data they would like to be hashed for their application.

I understand why CTV was designed with verify semantics: it would like to
be NOP compatible.  That certainly made sense pre-tapscript.  I just
haven't (yet) found the use cases for that compatibility to be compelling
in a post-tapscript world.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220129/cefdbd34/attachment.html>

From jeremy.l.rubin at gmail.com  Sat Jan 29 17:02:37 2022
From: jeremy.l.rubin at gmail.com (Jeremy Rubin)
Date: Sat, 29 Jan 2022 09:02:37 -0800
Subject: [bitcoin-dev] TXHASH + CHECKSIGFROMSTACKVERIFY in lieu of CTV
	and ANYPREVOUT
In-Reply-To: <CAMZUoKkqEx5mh9Aq9XFc=7YPKmfObMzEipECFuWm4e3q_tVEEQ@mail.gmail.com>
References: <CAMZUoK=pkZuovtifBzdqhoyegzG+9hRTFEc7fG9nZPDK4KbU3w@mail.gmail.com>
 <CAD5xwhhwqJ_AETAb3p_zUZmRX-Dzh8J9G984zwEs=KFsGN8aNQ@mail.gmail.com>
 <CAMZUoKmU1cwUAQaBv5m8oo8H3TWBvgsZ_OkQaMC0n0+3cpFtWg@mail.gmail.com>
 <CAPfvXfLr4n6RsS6VbEZR59=MRwAx41Crx88ko8-qnRXW4nFYGA@mail.gmail.com>
 <CAMZUoKkvoJs0WtN71A_qRSwToP4YnY707WdW3C-KJYGXsmkjSw@mail.gmail.com>
 <CAPfvXfLWtDvgJYwQCaxnww5jyQkqFsi6aG0OUxtp3Okx_ab7Hw@mail.gmail.com>
 <CAMZUoKkqEx5mh9Aq9XFc=7YPKmfObMzEipECFuWm4e3q_tVEEQ@mail.gmail.com>
Message-ID: <CAD5xwhjsVA7k7ZQ_QdrcZOxdi+L6L7dvqAj1Mhx+zmBA3DM5zw@mail.gmail.com>

Perhaps there is some misunderstanding.  TXHASH + CSFSV doesn't allow for
complex or recursive covenants.  Typically CAT is needed, at minimum, to
create those sorts of things.  TXHASH still amounts to deploying a
non-recursive covenant construction.


This seems false to me.

<Only hash a single input scriptpubkey> txhash <only hash a single output
scriptpubkey> txhash equalverify

Is that not a recursive covenant? With a little extra work you can also
control for amounts and stuff.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220129/57693bf7/attachment.html>

From roconnor at blockstream.com  Sat Jan 29 17:14:43 2022
From: roconnor at blockstream.com (Russell O'Connor)
Date: Sat, 29 Jan 2022 12:14:43 -0500
Subject: [bitcoin-dev] TXHASH + CHECKSIGFROMSTACKVERIFY in lieu of CTV
	and ANYPREVOUT
In-Reply-To: <CAD5xwhjHv2EGYb33p2MRS=VSz=ciGwAsiafX1yRHjxQEXfykSA@mail.gmail.com>
References: <CAMZUoK=pkZuovtifBzdqhoyegzG+9hRTFEc7fG9nZPDK4KbU3w@mail.gmail.com>
 <CAD5xwhhwqJ_AETAb3p_zUZmRX-Dzh8J9G984zwEs=KFsGN8aNQ@mail.gmail.com>
 <CAMZUoKmU1cwUAQaBv5m8oo8H3TWBvgsZ_OkQaMC0n0+3cpFtWg@mail.gmail.com>
 <CAPfvXfLr4n6RsS6VbEZR59=MRwAx41Crx88ko8-qnRXW4nFYGA@mail.gmail.com>
 <CAMZUoKkvoJs0WtN71A_qRSwToP4YnY707WdW3C-KJYGXsmkjSw@mail.gmail.com>
 <CAPfvXfLWtDvgJYwQCaxnww5jyQkqFsi6aG0OUxtp3Okx_ab7Hw@mail.gmail.com>
 <CAMZUoKkqEx5mh9Aq9XFc=7YPKmfObMzEipECFuWm4e3q_tVEEQ@mail.gmail.com>
 <CAD5xwhjHv2EGYb33p2MRS=VSz=ciGwAsiafX1yRHjxQEXfykSA@mail.gmail.com>
Message-ID: <CAMZUoKki0M6jvgdtQLETa2fjYJkCqwWaj1k1WSSa=e8DJ8tPxA@mail.gmail.com>

The hash would normally also cover the hash flags in use, and would be
different in those two cases.

But yes, it seems at the last minute I did include a suggestion to disable
covering the flag themselves in the hash and appear to have accidentally
allowed for recursive covenants (a common occurrence when designing
opcodes).

On Sat, Jan 29, 2022 at 12:01 PM Jeremy Rubin <j at rubin.io> wrote:

>
>
>
>> Perhaps there is some misunderstanding.  TXHASH + CSFSV doesn't allow for
>> complex or recursive covenants.  Typically CAT is needed, at minimum, to
>> create those sorts of things.  TXHASH still amounts to deploying a
>> non-recursive covenant construction.
>>
>>
> This seems false to me.
>
> <Only hash a single input scriptpubkey> txhash <only hash a single output
> scriptpubkey> txhash equalverify
>
> Is that not a recursive covenant? With a little extra work you can also
> control for amounts and stuff.
>
>
>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220129/a5d662ba/attachment.html>

From AdamISZ at protonmail.com  Sat Jan 29 17:16:29 2022
From: AdamISZ at protonmail.com (AdamISZ)
Date: Sat, 29 Jan 2022 17:16:29 +0000
Subject: [bitcoin-dev] PathCoin
In-Reply-To: <CAGpPWDa=YBMrkuUHD0ogS3uxWq0g4LZubm=g9yQVuEffudsJhA@mail.gmail.com>
References: <jMANAdspMdPb1ZCFttQ3tGmkZ0oYojLY5Oz1d8ZSNl3JhZeDuT1xK0vxTu8uyHcgPXWsM_6XNb3R9tVD3_Yez88pviFrCaNt7LPqdWVBWus=@protonmail.com>
 <CAGpPWDY3vZ2JOsa1UhoT-z8kfxqkVWcq1nyt9Ah5ye6HE_6gOQ@mail.gmail.com>
 <By1G6iST5DCXZJVfEd3HzdPgU3e_NGoqvH-5UoqsOzY8qjiOmy5iHXiOwjXtm7Znq1Z6z-XOL0IPDSyQiLOZ6-lRQ-vi1I6Cba4aqywe8xw=@protonmail.com>
 <CAGpPWDa=YBMrkuUHD0ogS3uxWq0g4LZubm=g9yQVuEffudsJhA@mail.gmail.com>
Message-ID: <3WOWxS-cioUIMYPIALmyVGumxk23bRnFn4ps8pr4DjMCi462UMmidiVZnWQBf4h9JVfQHggKKOMIJ1wxq8b19_5XsZ0hl2jzRlHNfXtpAi8=@protonmail.com>

> Justice. Also, there's no incentive for the honest party to not punish - presumably their software would automatically punish, and why go through any effort to stop it? A 1 cent bribe certainly wouldn't be enough. Maybe a $10 bribe might get someone somewhere to install hacked up software to be able to fulfill such a bribe, but even then i think it would be a rare person that would stoop to that. Were it to become a true negotiation, the cheater has more to lose, and therefore the bribee has a lot of leverage.

Justice isn't a strong enough incentive, it's too context-dependent, and in particular it's not something you could rely on if there is any financial incentive pushing the other way. Especially the ordering of events: if you have a counterparty who is malicious and they *take action* to steal, then they can present you with two alternatives one of which is more favourable than the other, if there is a bribe. It isn't *just* about logic I think, though the logic definitely matters.

These arguments about whether we could use 'mutually assured destruction' approaches (burn in particular) to make contract enforcement work have been ongoing amongst Bitcoin enthusiasts for a decade, I've always felt strongly that they do not ultimately work and haven't seen anything to change my mind (I seem to remember convincing Manfred Karrer not to use it in Bitsquare in 2014/15, but there've been many other examples of people proposing it and it never really getting traction).

> One thing I thought of regarding path coin, if there's ever a situation where there are multiple choices in path, whatever punishment there is probably needs to be able to handle the multiple of the number of paths.

Right, I briefly alluded to setting up with multiple paths - general idea is instead of only a->b->c->d->e it's possible to setup the n-ary tree, so a can go to all of b,c,d,e etc., but the problem is the factorial blowup that you get even if you restrict to no-revisiting (or exponential otherwise). For the toy example of 5 participants though, it is entirely possible to build the matrix as illustrated in the gist, but it's an N^2 matrix duplicated for every change in the path, here's the simplest possible extension of the base case:

path 1: A B* C* D* E*
path 2: A B C* D* E*
path 3: A B C* D* E*
path 4: A B C D* E*
path 5: A B C D E
path 6: A C* B* D* E*
path 7: A C B* D* E*
path 8: A C B D* E*
path 9: A C B D E*
path 10: A C B D E

The * would indicate pre-signs (and this whole list is branches in the taproot output of the pathcoin); this setup *only* allows one alternate path (second C instead of second B) for the coin.

If A chooses to pay B (not C), then: instead of only giving B an adaptor on path1 and signatures on paths 2,3,4,5, A would also have to give B adaptors on paths 6-10 as well. So it's easy to see that if you kept adding branches for every possible spending path A->E with no revisits you have like n^2(n-1)! (maybe not exactly; something very similar).
(Notice: though there are multiple paths via which A can cheat, they all reveal the same adaptor secret (and they're all the same coin) leading to the same forfeit of fidelity bond, see gist for the nice way you can always have it so that a single fidelity bond goes to the honest owner).

All of this is predicated on the idea that the participants do *not* coordinate at all after the initial setup; only a data transfer from payer to payee. A pretty massive restriction, of course.

Sent with [ProtonMail](https://protonmail.com/) Secure Email.

??????? Original Message ???????
On Friday, January 28th, 2022 at 15:27, Billy Tetrud via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:

>> what is the incentive for the honest party to punish?
>
> Justice. Also, there's no incentive for the honest party to not punish - presumably their software would automatically punish, and why go through any effort to stop it? A 1 cent bribe certainly wouldn't be enough. Maybe a $10 bribe might get someone somewhere to install hacked up software to be able to fulfill such a bribe, but even then i think it would be a rare person that would stoop to that. Were it to become a true negotiation, the cheater has more to lose, and therefore the bribee has a lot of leverage.
>
>> my strong intuition is that it will never be properly stable.
>
> I'm curious what you mean by "stable". You had mentioned the game theory is "fragile" and I'm wondering if there's more to this than just "what incentive does the honest party have to burn?"
>
> To be clear, I'm not advocating for Sabu and I haven't done any deep thinking about burn based incentives.
>
> One thing I thought of regarding path coin, if there's ever a situation where there are multiple choices in path, whatever punishment there is probably needs to be able to handle the multiple of the number of paths. The only way around this i can imagine is to have some method of coordination between payees, eg a place where a payee records their payment such that a payee who has been double spent on to become aware they've been double spent on and initiate the punishment. But once you have that coordination mechanism it starts not looking more like an on chain transaction.
>
> On Tue, Jan 25, 2022, 06:50 AdamISZ <AdamISZ at protonmail.com> wrote:
>
>> Hi Billy,
>> I read through the description. I think systems like this *mostly* fail due to game theory.
>>
>> With punishment-by-burn you have various issues that make it to my mind pretty unstable, too unstable to use for any serious system. To be fair, this isn't cut-and-dried. So let me unpack:
>>
>> (I briefly touched on why I dismissed penalties via burn in my gist, section: "Not feeling the burn".)
>>
>> There is a distinction between penalty via burn to unspendable output and penalty via burn to miner fees. The latter has an obvious problem: if your counterparties collude with (or are) miners, they may not actually be penalized at all (now to be clear, that is a problematic attack ex nihilo: nobody usually can be sure who's mining the next block, but markets have a way of solving and coordinating such things: see e.g. the various MEV discussions and initiatives in Ethereum for an example of that).
>>
>> But the former (provable burn) is still imo extremely unstable: if the penalty tx destroys all the money, what is the incentive for the honest party to punish? In such a scenario even a one cent donation from the attacker to the victim might prevent the penalty from happening.
>> You can combine 'destruction of most, or some, of the funds' with a smaller payout to the aggrieved party, but then again you have to factor in the possibility of bribes. The Sabu post you linked describes it as: "There are precise and delicate formulas for calculating the amount of loss of the issuer and the creditor, which ensures that just and true act in both parties are cost-effective in all situations." I agree it's delicate, but after having spent time looking into these things, my strong intuition is that it will never be properly stable.
>>
>> In the PathCoin description I am specifically looking for a trustless system, with this finesse: we still count it as trustless even though we are using penalties as disincentive, because the penalty *consists of a payment directly from the attacker to the attacked, and that payment is larger than the amount stolen*. I claim that that *is* stable.
>>
>> Notice that Lightning has the same model (in LN-Penalty), as long as 'claiming the whole channel capacity' is enough to be larger than what is stolen (see: channel reserves etc.).
>>
>> Sent with [ProtonMail](https://protonmail.com/) Secure Email.
>>
>> ??????? Original Message ???????
>> On Tuesday, January 25th, 2022 at 11:53, Billy Tetrud via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
>>
>>> There was a protocol someone mentioned a while back called Sabu that had the same goals. As i recall, it had some pretty promising constructs, but would have a critical vulnerability that could be exploited by miners. This is the write up:
>>>
>>> https://raymo-49157.medium.com/time-to-boost-bitcoin-circulation-million-transactions-per-second-and-privacy-1eef8568d180
>>>
>>> Perhaps some of the techniques there could be combined with your ideas to get closer to a solution.
>>>
>>> On Mon, Jan 24, 2022, 08:51 AdamISZ via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
>>>
>>>> Hello list,
>>>>
>>>> I took the time to write up this rather out-there idea:
>>>>
>>>> Imagine you wanted to send a coin just like email, i.e. just transfer data to the counterparty.
>>>>
>>>> Clearly this is in general entirely impossible; but with what restrictions and assumptions could you create a toy version of it?
>>>>
>>>> See this gist for a detailed build up of the idea:
>>>>
>>>> https://gist.github.com/AdamISZ/b462838cbc8cc06aae0c15610502e4da
>>>>
>>>> Basically: using signature adaptors and CTV or a similar covenant, you could create a fully trustless transfer of control of a utxo from one party to another with no interaction with the rest of the group, at the time of transfer (modulo of course lots and lots of one-time setup).
>>>>
>>>> The limitations are extreme and as you'd imagine. In the gist I feel like I got round one of them, but not the others.
>>>>
>>>> (I very briefly mention comparison to e.g. statechains or payment pools; they are making other tradeoffs against the 'digital cash' type of goal. There is no claim that this 'pathcoin' idea is even viable yet, let alone better than those ideas).
>>>>
>>>> Publishing this because I feel like it's the kind of thing imaginative minds like the ones here, may be able to develop further. Possibly!
>>>>
>>>> waxwing / AdamISZ
>>>> _______________________________________________
>>>> bitcoin-dev mailing list
>>>> bitcoin-dev at lists.linuxfoundation.org
>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220129/ad458d2e/attachment-0001.html>

From prayank at tutanota.de  Sat Jan 29 22:02:24 2022
From: prayank at tutanota.de (Prayank)
Date: Sat, 29 Jan 2022 23:02:24 +0100 (CET)
Subject: [bitcoin-dev] non-default ports for automatic connections in
	Bitcoin P2P network
Message-ID: <Mubr4YT--3-2@tutanota.de>

## Using non-default ports for automatic connections in Bitcoin P2P network


ISPs can block default port 8333 used by Bitcoin nodes. One example:
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-September/010798.html

While it would still be possible for crawlers and scanners to know about bitcoin nodes listening on non-default ports using other methods, it can be helpful in lot of countries that use basic things to block: domain, port etc.

In October 2021 a [pull request][1] was merged in Bitcoin Core in which lot of contributors
agreed to allow non default ports for automatic connections. It did not implement everything,
was limited to discussing the concept and allow AddrMan to support multiple ports per IP.

It was followed by another [pull request][2] in November 2021 which is still open and makes most
of the changes required for non-default ports to work with automatic connections.

I could not find any major issues with the changes however had some nits including a discussion on
mailing list which was even requested by a few other reviewers.


===Things that I found during my review, research and testing===

1.One user had posted about issues with default port 8333 on [bitcointalk][3] in July 2010. VMWare server
also used port 8333 so an option was requested to change port. This option was added in [May 2011][4] by Gavin Andresen. Gavin has discussed this option and related issues in detail with others on [bitcointalk][5].

2.I tried running signet for 1 hour v22.0 and 1 hour PR branch with debug=net. v22.0 had only 38333 port with different IPs in debug.log for connections. PR branch had 2 feeler connections with non-default ports 38331 and 13833.

Note: Default ports used in Bitcoin Core are 8333(mainnet), 18333(testnet), 18444(regtest) and 38333(signet)

3.Wrote a [PowerShell script][6] and tested it on v22.0 and PR branch which bans all peers every 100 seconds using default port. It works as expected and I could see one peer using port 3111 on signet.

4.I am not sure about the 'bad ports' list in Bitcoin Core added in PR #23542


8333 in leet becomes 'beee' in plain text. Not sure if this was considered by Satoshi to hardcode 8333 for Bitcoin.


? [1]: https://github.com/bitcoin/bitcoin/pull/23306
? [2]: https://github.com/bitcoin/bitcoin/pull/23542
? [3]: https://bitcointalk.org/index.php?topic=322.0
? [4]: https://github.com/bitcoin/bitcoin/pull/221
? [5]: https://bitcointalk.org/index.php?topic=589.0
? [6]: https://github.com/prayank23/bitcoin-ps-scripts/blob/main/Scripts/Node/ban_default_peers.ps1

-- 
Prayank

A3B1 E430 2298 178F
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220129/472360b4/attachment.html>

From billy.tetrud at gmail.com  Sun Jan 30 15:39:04 2022
From: billy.tetrud at gmail.com (Billy Tetrud)
Date: Sun, 30 Jan 2022 09:39:04 -0600
Subject: [bitcoin-dev] PathCoin
In-Reply-To: <3WOWxS-cioUIMYPIALmyVGumxk23bRnFn4ps8pr4DjMCi462UMmidiVZnWQBf4h9JVfQHggKKOMIJ1wxq8b19_5XsZ0hl2jzRlHNfXtpAi8=@protonmail.com>
References: <jMANAdspMdPb1ZCFttQ3tGmkZ0oYojLY5Oz1d8ZSNl3JhZeDuT1xK0vxTu8uyHcgPXWsM_6XNb3R9tVD3_Yez88pviFrCaNt7LPqdWVBWus=@protonmail.com>
 <CAGpPWDY3vZ2JOsa1UhoT-z8kfxqkVWcq1nyt9Ah5ye6HE_6gOQ@mail.gmail.com>
 <By1G6iST5DCXZJVfEd3HzdPgU3e_NGoqvH-5UoqsOzY8qjiOmy5iHXiOwjXtm7Znq1Z6z-XOL0IPDSyQiLOZ6-lRQ-vi1I6Cba4aqywe8xw=@protonmail.com>
 <CAGpPWDa=YBMrkuUHD0ogS3uxWq0g4LZubm=g9yQVuEffudsJhA@mail.gmail.com>
 <3WOWxS-cioUIMYPIALmyVGumxk23bRnFn4ps8pr4DjMCi462UMmidiVZnWQBf4h9JVfQHggKKOMIJ1wxq8b19_5XsZ0hl2jzRlHNfXtpAi8=@protonmail.com>
Message-ID: <CAGpPWDbjD8KDr1CcnPT6pa4=BnNV7Cfxe-Hwgpvb5=RX_GEuqA@mail.gmail.com>

> if you have a counterparty who is malicious and they *take action* to
steal, then they can present you with two alternatives

Generally I don't think this is the case.  In this case, these are
time-sensitive operations. There is no time to negotiate after the
malicious party has taken action. The software would have already taken
counteraction. Negotiation would have to happen before broadcast.

>  I've always felt strongly that they do not ultimately work

So you don't have any specific reasoning you can give for that gut feeling?
I'm not pushing for burn mechanisms, but trying to understand why you're
dismissing them.



On Sat, Jan 29, 2022 at 11:16 AM AdamISZ <AdamISZ at protonmail.com> wrote:

> > Justice. Also, there's no incentive for the honest party to not punish
> - presumably their software would automatically punish, and why go through
> any effort to stop it? A 1 cent bribe certainly wouldn't be enough. Maybe a
> $10 bribe might get someone somewhere to install hacked up software to be
> able to fulfill such a bribe, but even then i think it would be a rare
> person that would stoop to that. Were it to become a true negotiation, the
> cheater has more to lose, and therefore the bribee has a lot of leverage.
>
> Justice isn't a strong enough incentive, it's too context-dependent, and
> in particular it's not something you could rely on if there is any
> financial incentive pushing the other way. Especially the ordering of
> events: if you have a counterparty who is malicious and they *take action*
> to steal, then they can present you with two alternatives one of which is
> more favourable than the other, if there is a bribe. It isn't *just* about
> logic I think, though the logic definitely matters.
>
> These arguments about whether we could use 'mutually assured destruction'
> approaches (burn in particular) to make contract enforcement work have been
> ongoing amongst Bitcoin enthusiasts for a decade, I've always felt strongly
> that they do not ultimately work and haven't seen anything to change my
> mind (I seem to remember convincing Manfred Karrer not to use it in
> Bitsquare in 2014/15, but there've been many other examples of people
> proposing it and it never really getting traction).
>
> > One thing I thought of regarding path coin, if there's ever a situation
> where there are multiple choices in path, whatever punishment there is
> probably needs to be able to handle the multiple of the number of paths.
>
> Right, I briefly alluded to setting up with multiple paths - general idea
> is instead of only a->b->c->d->e it's possible to setup the n-ary tree, so
> a can go to all of b,c,d,e etc., but the problem is the factorial blowup
> that you get even if you restrict to no-revisiting (or exponential
> otherwise). For the toy example of 5 participants though, it is entirely
> possible to build the matrix as illustrated in the gist, but it's an N^2
> matrix duplicated for every change in the path, here's the simplest
> possible extension of the base case:
>
> path 1:  A  B* C* D* E*
> path 2:  A  B  C* D* E*
> path 3:  A  B  C* D* E*
> path 4:  A  B  C  D* E*
> path 5:  A  B  C  D  E
> path 6:  A  C* B* D* E*
> path 7:  A  C  B* D* E*
> path 8:  A  C  B  D* E*
> path 9:  A  C  B  D  E*
> path 10: A  C  B  D  E
>
> The * would indicate pre-signs (and this whole list is branches in the
> taproot output of the pathcoin); this setup *only* allows one alternate
> path (second C instead of second B) for the coin.
>
> If A chooses to pay B (not C), then: instead of only giving B an adaptor
> on path1 and signatures on paths 2,3,4,5, A would also have to give B
> adaptors on paths 6-10 as well. So it's easy to see that if you kept adding
> branches for every possible spending path A->E with no revisits you have
> like n^2(n-1)! (maybe not exactly; something very similar).
> (Notice: though there are multiple paths via which A can cheat, they all
> reveal the same adaptor secret (and they're all the same coin) leading to
> the same forfeit of fidelity bond, see gist for the nice way you can always
> have it so that a single fidelity bond goes to the honest owner).
>
> All of this is predicated on the idea that the participants do *not*
> coordinate at all after the initial setup; only a data transfer from payer
> to payee. A pretty massive restriction, of course.
>
> Sent with ProtonMail <https://protonmail.com/> Secure Email.
>
> ??????? Original Message ???????
> On Friday, January 28th, 2022 at 15:27, Billy Tetrud via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
> > what is the incentive for the honest party to punish?
>
> Justice. Also, there's no incentive for the honest party to not punish -
> presumably their software would automatically punish, and why go through
> any effort to stop it? A 1 cent bribe certainly wouldn't be enough. Maybe a
> $10 bribe might get someone somewhere to install hacked up software to be
> able to fulfill such a bribe, but even then i think it would be a rare
> person that would stoop to that. Were it to become a true negotiation, the
> cheater has more to lose, and therefore the bribee has a lot of leverage.
>
> > my strong intuition is that it will never be properly stable.
>
> I'm curious what you mean by "stable". You had mentioned the game theory
> is "fragile" and I'm wondering if there's more to this than just "what
> incentive does the honest party have to burn?"
>
> To be clear, I'm not advocating for Sabu and I haven't done any deep
> thinking about burn based incentives.
>
> One thing I thought of regarding path coin, if there's ever a situation
> where there are multiple choices in path, whatever punishment there is
> probably needs to be able to handle the multiple of the number of paths.
> The only way around this i can imagine is to have some method of
> coordination between payees, eg a place where a payee records their payment
> such that a payee who has been double spent on to become aware they've been
> double spent on and initiate the punishment. But once you have that
> coordination mechanism it starts not looking more like an on chain
> transaction.
>
> On Tue, Jan 25, 2022, 06:50 AdamISZ <AdamISZ at protonmail.com> wrote:
>
>> Hi Billy,
>> I read through the description. I think systems like this *mostly* fail
>> due to game theory.
>>
>> With punishment-by-burn you have various issues that make it to my mind
>> pretty unstable, too unstable to use for any serious system. To be fair,
>> this isn't cut-and-dried. So let me unpack:
>>
>> (I briefly touched on why I dismissed penalties via burn in my gist,
>> section: "Not feeling the burn".)
>>
>> There is a distinction between penalty via burn to unspendable output and
>> penalty via burn to miner fees. The latter has an obvious problem: if your
>> counterparties collude with (or are) miners, they may not actually be
>> penalized at all (now to be clear, that is a problematic attack ex nihilo:
>> nobody usually can be sure who's mining the next block, but markets have a
>> way of solving and coordinating such things: see e.g. the various MEV
>> discussions and initiatives in Ethereum for an example of that).
>>
>> But the former (provable burn) is still imo extremely unstable: if the
>> penalty tx destroys all the money, what is the incentive for the honest
>> party to punish? In such a scenario even a one cent donation from the
>> attacker to the victim might prevent the penalty from happening.
>> You can combine 'destruction of most, or some, of the funds' with a
>> smaller payout to the aggrieved party, but then again you have to factor in
>> the possibility of bribes. The Sabu post you linked describes it as: "There
>> are precise and delicate formulas for calculating the amount of loss of the
>> issuer and the creditor, which ensures that just and true act in both
>> parties are cost-effective in all situations." I agree it's delicate, but
>> after having spent time looking into these things, my strong intuition is
>> that it will never be properly stable.
>>
>> In the PathCoin description I am specifically looking for a trustless
>> system, with this finesse: we still count it as trustless even though we
>> are using penalties as disincentive, because the penalty *consists of a
>> payment directly from the attacker to the attacked, and that payment is
>> larger than the amount stolen*. I claim that that *is* stable.
>>
>> Notice that Lightning has the same model (in LN-Penalty), as long as
>> 'claiming the whole channel capacity' is enough to be larger than what is
>> stolen (see: channel reserves etc.).
>>
>>
>> Sent with ProtonMail <https://protonmail.com/> Secure Email.
>>
>>
>> ??????? Original Message ???????
>> On Tuesday, January 25th, 2022 at 11:53, Billy Tetrud via bitcoin-dev <
>> bitcoin-dev at lists.linuxfoundation.org> wrote:
>>
>> There was a protocol someone mentioned a while back called Sabu that had
>> the same goals. As i recall, it had some pretty promising constructs, but
>> would have a critical vulnerability that could be exploited by miners. This
>> is the write up:
>>
>>
>> https://raymo-49157.medium.com/time-to-boost-bitcoin-circulation-million-transactions-per-second-and-privacy-1eef8568d180
>>
>> Perhaps some of the techniques there could be combined with your ideas to
>> get closer to a solution.
>>
>> On Mon, Jan 24, 2022, 08:51 AdamISZ via bitcoin-dev <
>> bitcoin-dev at lists.linuxfoundation.org> wrote:
>>
>>> Hello list,
>>>
>>> I took the time to write up this rather out-there idea:
>>>
>>> Imagine you wanted to send a coin just like email, i.e. just transfer
>>> data to the counterparty.
>>>
>>> Clearly this is in general entirely impossible; but with what
>>> restrictions and assumptions could you create a toy version of it?
>>>
>>> See this gist for a detailed build up of the idea:
>>>
>>> https://gist.github.com/AdamISZ/b462838cbc8cc06aae0c15610502e4da
>>>
>>> Basically: using signature adaptors and CTV or a similar covenant, you
>>> could create a fully trustless transfer of control of a utxo from one party
>>> to another with no interaction with the rest of the group, at the time of
>>> transfer (modulo of course lots and lots of one-time setup).
>>>
>>> The limitations are extreme and as you'd imagine. In the gist I feel
>>> like I got round one of them, but not the others.
>>>
>>> (I very briefly mention comparison to e.g. statechains or payment pools;
>>> they are making other tradeoffs against the 'digital cash' type of goal.
>>> There is no claim that this 'pathcoin' idea is even viable yet, let alone
>>> better than those ideas).
>>>
>>> Publishing this because I feel like it's the kind of thing imaginative
>>> minds like the ones here, may be able to develop further. Possibly!
>>>
>>>
>>> waxwing / AdamISZ
>>> _______________________________________________
>>> bitcoin-dev mailing list
>>> bitcoin-dev at lists.linuxfoundation.org
>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220130/89f4a034/attachment-0001.html>

From antoine.riard at gmail.com  Sun Jan 30 22:53:32 2022
From: antoine.riard at gmail.com (Antoine Riard)
Date: Sun, 30 Jan 2022 17:53:32 -0500
Subject: [bitcoin-dev] Improving RBF Policy
In-Reply-To: <CAFXO6=LGbaur6XQrE+6a6mAAHXduOCXoWPTgPosxAG59ZkK6Gg@mail.gmail.com>
References: <CAFXO6=LGbaur6XQrE+6a6mAAHXduOCXoWPTgPosxAG59ZkK6Gg@mail.gmail.com>
Message-ID: <CALZpt+EjqKbhnN_5jy3kvYpMvjN8=iwRzMLSM7yS8_j-WzLrBQ@mail.gmail.com>

Hi Gloria,

Thanks for this RBF sum up. Few thoughts and more context comments if it
can help other readers.

> For starters, the absolute fee pinning attack is especially
> problematic if we apply the same rules (i.e. Rule #3 and #4) in
> Package RBF. Imagine that Alice (honest) and Bob (adversary) share a
> LN channel. The mempool is rather full, so their pre-negotiated
> commitment transactions' feerates would not be considered high
> priority by miners.  Bob broadcasts his commitment transaction and
> attaches a very large child (100KvB with 100,000sat in fees) to his
> anchor output. Alice broadcasts her commitment transaction with a
> fee-bumping child (200vB with 50,000sat fees which is a generous
> 250sat/vB), but this does not meet the absolute fee requirement. She
> would need to add another 50,000sat to replace Bob's commitment
> transaction.

Solving LN pinning attacks, what we're aiming for is enabling a fair
feerate bid between the  counterparties, thus either forcing the adversary
to overbid or to disengage from the confirmation competition. If the
replace-by-feerate rule is adopted, there shouldn't be an incentive for Bob
to
pick up the first option. Though if he does, that's a winning outcome for
Alice, as one of the commitment transactions confirms and her
time-sensitive second-stage HTLC can be subsequently confirmed.

> It's unclear to me if
> we have a very strong reason to change this, but noting it as a
> limitation of our current replacement policy. See [#24007][12].

Deployment of Taproot opens interesting possibilities in the vaults/payment
channels design space, where the tapscripts can commit to different set of
timelocks/quorum of keys. Even if the pre-signed states stay symmetric,
whoever is the publisher, the feerate cost to spend can fluctuate.

> While this isn't completely broken, and the user interface is
> secondary to the safety of the mempool policy

I think with L2s transaction broadcast backend, the stability and clarity
of the RBF user interface is primary. What we could be worried about is a
too-much complex interface easing the way for an attacker to trigger your
L2 node to issue policy-invalid chain of transactions. Especially, when we
consider that an attacker might have leverage on chain of transactions
composition ("force broadcast of commitment A then commitment B, knowing
they will share a CPFP") or even transactions size ("overload commitment A
with HTLCs").

> * If the original transaction is in the top {0.75MvB, 1MvB} of the
>   mempool, apply the current rules (absolute fees must increase and
> pay for the replacement transaction's new bandwidth). Otherwise, use a
> feerate-only rule.

How this new replacement rule would behave if you have a parent in the
"replace-by-feerate" half but the child is in the "replace-by-fee" one ?

If we allow the replacement of the parent based on the feerate, we might
decrease the top block absolute fees.

If we block the replacement of the parent based on the feerate because the
replacement absolute fees aren't above the replaced package, we still
preclude a pinning vector. The child might be low-feerate junk and even
attached to a low ancestor-score branch.

If I'm correct on this limitation, maybe we could turn off the
"replace-by-fee" behavior as soon as the mempool is fulfilled with a few
blocks ?

> * Rate-limit how many replacements we allow per prevout.

Depending on how it is implemented, though I would be concerned it
introduces a new pinning vector in the context of shared-utxo. If it's a
hardcoded constant, it could be exhausted by an adversary starting at the
lowest acceptable feerate then slowly increasing while still not reaching
the top of the mempool. Same if it's time-based or block-based, no
guarantee the replacement slot is honestly used by your counterparty.

Further, an above-the-average replacement frequency might just be the
reflection of your confirmation strategy reacting to block schedule or
mempools historical data. As long as the feerate penalty is paid, I lean to
allow replacement.

(One solution could be to associate per-user "tag" to the LN transactions,
where each "tag" would have its own replacement slots, but privacy?)

> * Rate-limit transaction validation in general, per peer.

I think we could improve on the Core's new transaction requester logic.
Maybe we could bind the peer announced flow based on the feerate score
(modulo validation time) of the previously validated transactions from that
peer ? That said, while related to RBF, it sounds to me that enhancing
Core's rate-limiting transaction strategy is a whole discussion in itself
[0]. Especially ensuring it's tolerant to the specific requirements of LN &
consorts.

> What should they be? We can do some arithmetic to see what happens if
> you start with the biggest/lowest feerate transaction and do a bunch
> of replacements. Maybe we end up with values that are high enough to
> prevent abuse and make sense for applications/users that do RBF.

That's a good question.

One observation is that the attacker can always renew the set of DoSy utxos
to pursue the attack. So maybe we could pick up constants scaled on the
block size ? That way an attacker would have to burn fees, thus deterring
them from launching an attack. Even if the attackers are miners, they have
to renounce their income to acquire new DoSy utxos. If a low-fee period, we
could scale up the constants ?


Overall, I think there is the deployment issue to warn of. Moving to a new
set of RBF rules implies for a lot of Bitcoin applications to rewrite their
RBF logics. We might have a more-or-less long transition period during
which we support both...

Cheers,
Antoine

[0] https://github.com/bitcoin/bitcoin/pull/21224

Le jeu. 27 janv. 2022 ? 09:10, Gloria Zhao via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> a ?crit :

> Hi everyone,
>
> This post discusses limitations of current Bitcoin Core RBF policy and
> attempts to start a conversation about how we can improve it,
> summarizing some ideas that have been discussed. Please reply if you
> have any new input on issues to be solved and ideas for improvement!
>
> Just in case I've screwed up the text wrapping again, another copy can be
> found here:
> https://gist.github.com/glozow/25d9662c52453bd08b4b4b1d3783b9ff
>
> ## Background
>
> Please feel free to skip this section if you are already familiar
> with RBF.
>
> Nodes may receive *conflicting* unconfirmed transactions, aka
> "double spends" of the same inputs. Instead of always keeping the
> first transaction, since v0.12, Bitcoin Core mempool policy has
> included a set of Replace-by-Fee (RBF) criteria that allows the second
> transaction to replace the first one and any descendants it may have.
>
> Bitcoin Core RBF policy was previously documented as BIP 125.
> The current RBF policy is documented [here][1]. In summary:
>
> 1. The directly conflicting transactions all signal replaceability
>    explicitly.
>
> 2. The replacement transaction only includes an unconfirmed input if
>    that input was included in one of the directly conflicting
> transactions.
>
> 3. The replacement transaction pays an absolute fee of at least the
>    sum paid by the original transactions.
>
> 4. The additional fees pays for the replacement transaction's
>    bandwidth at or above the rate set by the node's *incremental relay
> feerate*.
>
> 5. The sum of all directly conflicting transactions' descendant counts
>    (number of transactions inclusive of itself and its descendants)
> does not exceed 100.
>
> We can split these rules into 3 categories/goals:
>
> - **Allow Opting Out**: Some applications/businesses are unable to
>   handle transactions that are replaceable (e.g. merchants that use
> zero-confirmation transactions). We (try to) help these businesses by
> honoring BIP125 signaling; we won't replace transactions that have not
> opted in.
>
> - **Incentive Compatibility**: Ensure that our RBF policy would not
>   accept replacement transactions which would decrease fee profits
>   of a miner. In general, if our mempool policy deviates from what is
> economically rational, it's likely that the transactions in our
> mempool will not match the ones in miners' mempools, making our
> fee estimation, compact block relay, and other mempool-dependent
> functions unreliable. Incentive-incompatible policy may also
> encourage transaction submission through routes other than the p2p
> network, harming censorship-resistance and privacy of Bitcoin payments.
>
> - **DoS Protection**: Limit two types of DoS attacks on the node's
>   mempool: (1) the number of times a transaction can be replaced and
> (2) the volume of transactions that can be evicted during a
> replacement.
>
> Even more abstract: our goal is to make a replacement policy that
> results in a useful interface for users and safe policy for
> node operators.
>
> ## Motivation
>
> There are a number of known problems with the current RBF policy.
> Many of these shortcomings exist due to mempool limitations at the
> time RBF was implemented or result from new types of Bitcoin usage;
> they are not criticisms of the original design.
>
> ### Pinning Attacks
>
> The most pressing concern is that attackers may take advantage of
> limitations in RBF policy to prevent other users' transactions from
> being mined or getting accepted as a replacement.
>
> #### SIGHASH_ANYONECANPAY Pinning
>
> BIP125#2 can be bypassed by creating intermediary transactions to be
> replaced together. Anyone can simply split a 1-input 1-output
> transaction off from the replacement transaction, then broadcast the
> transaction as is. This can always be done, and quite cheaply. More
> details in [this comment][2].
>
> In general, if a transaction is signed with SIGHASH\_ANYONECANPAY,
> anybody can just attach a low feerate parent to this transaction and
> lower its ancestor feerate.  Even if you require SIGHASH\_ALL which
> prevents an attacker from changing any outputs, the input can be a
> very low amount (e.g. just above the dust limit) from a low-fee
> ancestor and still bring down the ancestor feerate of the transaction.
>
> TLDR: if your transaction is signed with SIGHASH\_ANYONECANPAY and
> signals replaceability, regardless of the feerate you broadcast at, an
> attacker can lower its mining priority by adding an ancestor.
>
> #### Absolute Fee
>
> The restriction of requiring replacement transactions to increase the
> absolute fee of the mempool has been described as "bonkers." If the
> original transaction has a very large descendant that pays a large
> amount of fees, even if it has a low feerate, the replacement
> transaction must now pay those fees in order to meet Rule #3.
>
> #### Package RBF
>
> There are a number of reasons why, in order to enable Package RBF, we
> cannot use the same criteria.
>
> For starters, the absolute fee pinning attack is especially
> problematic if we apply the same rules (i.e. Rule #3 and #4) in
> Package RBF. Imagine that Alice (honest) and Bob (adversary) share a
> LN channel. The mempool is rather full, so their pre-negotiated
> commitment transactions' feerates would not be considered high
> priority by miners.  Bob broadcasts his commitment transaction and
> attaches a very large child (100KvB with 100,000sat in fees) to his
> anchor output. Alice broadcasts her commitment transaction with a
> fee-bumping child (200vB with 50,000sat fees which is a generous
> 250sat/vB), but this does not meet the absolute fee requirement. She
> would need to add another 50,000sat to replace Bob's commitment
> transaction.
>
> Disallowing new unconfirmed inputs (Rule #2) in Package RBF would be
> broken for packages containing transactions already in the mempool,
> explained [here][7].
>
> Note: I originally [proposed][6] Package RBF using the same Rule #3
> and #4 before I realized how significant this pinning attack is. I'm
> retracting that proposal, and a new set of Package RBF rules would
> follow from whatever the new individual RBF rules end up being.
>
> #### Same Txid Different Witness
>
> Two transactions with the same non-witness data but different
> witnesses have the same txid but different wtxid, and the same fee but
> not necessarily the same feerate. Currently, if we see a transaction
> that has the same txid as one in the mempool, we reject it as a
> duplicate, even if the feerate is much higher. It's unclear to me if
> we have a very strong reason to change this, but noting it as a
> limitation of our current replacement policy. See [#24007][12].
>
> ### User Interface
>
> #### Using Unconfirmed UTXOs to Fund Replacements
>
> The restriction of only allowing confirmed UTXOs for funding a
> fee-bump (Rule #2) can hurt users trying to fee-bump their
> transactions and complicate wallet implementations. If the original
> transaction's output value isn't sufficient to fund a fee-bump and/or
> all of the user's other UTXOs are unconfirmed, they might not be able
> to fund a replacement transaction. Wallet developers also need to
> treat self-owned unconfirmed UTXOs as unusable for fee-bumping, which
> adds complexity to wallet logic. For example, see BDK issues [#144][4]
> and [#414][5].
>
> #### Interface Not Suitable for Coin Selection
>
> Currently, a user cannot simply create a replacement transaction
> targeting a specific feerate or meeting a minimum fee amount and
> expect to meet the RBF criteria. The fee amount depends on the size of
> the replacement transaction, and feerate is almost irrelevant.
>
> Bitcoin Core's `bumpfee` doesn't use the RBF rules when funding the
> replacement. It [estimates][13] a feerate which is "wallet incremental
> relay fee" (a conservative overestimation of the node's incremental
> relay fee) higher than the original transaction, selects coins for
> that feerate, and hopes that it meets the RBF rules. It never fails
> Rule #3 and #4 because it uses all original inputs and refuses to
> bump a transaction with mempool descendants.
>
> This is suboptimal, but is designed to work with the coin selection
> engine: select a feerate first, and then add fees to cover it.
> Following the exact RBF rules would require working the other way
> around: based on how much fees we've added to the transaction and its
> current size, calculate the feerate to see if we meet Rule #4.
>
> While this isn't completely broken, and the user interface is
> secondary to the safety of the mempool policy, we can do much better.
> A much more user-friendly interface would depend *only* on the
> fee and size of the original transactions.
>
> ### Updates to Mempool and Mining
>
> Since RBF was first implemented, a number of improvements have been
> made to mempool and mining logic. For example, we now use ancestor
> feerates in mining (allowing CPFP), and keep track of ancestor
> packages in the mempool.
>
> ## Ideas for Improvements
>
> ### Goals
>
> To summarize, these seem to be desired changes, in order of priority:
>
> 1. Remove Rule #3. The replacement should not be *required* to pay
> higher absolute fees.
>
> 2. Make it impossible for a replacement transaction to have a lower
> mining score than the original transaction(s). This would eliminate
> the `SIGHASH\_ANYONECANPAY` pinning attack.
>
> 3. Remove Rule #2. Adding new unconfirmed inputs should be allowed.
>
> 4. Create a more helpful interface that helps wallet fund replacement
> transactions that aim for a feerate and fee.
>
> ### A Different Model for Fees
>
> For incentive compatibility, I believe there are different
> formulations we should consider.  Most importantly, if we want to get
> rid of the absolute fee rule, we can no longer think of it as "the
> transaction needs to pay for its own bandwidth," since we won't always
> be getting additional fees. That means we need a new method of
> rate-limiting replacements that doesn't require additional fees every
> time.
>
> While it makes sense to think about monetary costs when launching a
> specific type of attack, given that the fees are paid to the miner and
> not to the mempool operators, maybe it doesn't make much sense to
> think about "paying for bandwidth". Maybe we should implement
> transaction validation rate-limiting differently, e.g. building it
> into the P2P layer instead of the mempool policy layer.
>
> Recently, Suhas gave a [formulation][8] for incentive compatibility
> that made sense to me: "are the fees expected to be paid in the next
> (N?) blocks higher or lower if we process this transaction?"
>
> I started by thinking about this where N=1 or `1 + p`.
> Here, a rational miner is looking at what fees they would
> collect in the next block, and then some proportion `p` of the rest of
> the blocks based on their hashrate. We're assuming `p` isn't *so high*
> that they would be okay with lower absolute fees in the next 1 block.
> We're also assuming `p` isn't *so low* that the miner doesn't care
> about what's left of the mempool after this block.
>
> A tweak to this formulation is "if we process this transaction, would
> the fees in the next 1 block higher or lower, and is the feerate
> density of the rest of the mempool higher or lower?" This is pretty
> similar, where N=1, but we consider the rest of the mempool by feerate
> rather than fees.
>
> ### Mining Score of a Mempool Transaction
>
> We are often interested in finding out what
> the "mining score" of a transaction in the mempool is. That is, when
> the transaction is considered in block template building, what is the
> feerate it is considered at?
>
> Obviously, it's not the transaction's individual feerate. Bitcoin Core
> [mining code sorts][14] transactions by their ancestor feerate and
> includes them packages at a time, keeping track of how this affects the
> package feerates of remaining transactions in the mempool.
>
> *ancestor feerate*: Ancestor feerate is easily accessible information,
> but it's not accurate either, because it doesn't take into account the
> fact that subsets of a transaction's ancestor set can be included
> without it. For example, ancestors may have high feerates on their own
> or we may have [high feerate siblings][8].
>
> TLDR: *Looking at the current ancestor feerate of a transaction is
> insufficient to tell us what feerate it will be considered at when
> building a block template in the future.*
>
> *min(individual feerate, ancestor feerate)*: Another
> heuristic that is simple to calculate based on current mempool tooling
> is to use the [minimum of a transaction's individual score and its
> ancestor score][10] as a conservative measure.  But this can
> overestimate as well (see the example below).
>
> *min ancestor feerate(tx + possible ancestor subsets)* We can also
> take the minimum of every possible ancestor subset, but this can be
> computationally expensive since there can be lots and lots of ancestor
> subsets.
>
> *max ancestor feerate(tx + possible descendant subsets)*: Another idea
> is to use the [maximum ancestor score of the transaction + each of its
> descendants][9]. This doesn't work either; it has the same blindspot
> of ancestor subsets being mined on their own.
>
> #### Mining Score Example
>
> Here's an example illustrating why mining score is tricky to
> efficiently calculate for mempool transactions:
>
> Let's say you have same-size transactions A (21sat/vB), B (1sat/vB),
> C(9sat/vB), D(5sat/vB).
> The layout is: grandparent A, parent B, and two children C and D.
>
> ```
>     A
>     ^
>     B
>    ^ ^
>    C D
> ```
>
> A miner using ancestor packages to build block templates will first
> include A with a mining score of 21. Next, the miner will include B and
> C with a mining score of 6. This leaves D, with a mining score of 5.
>
> Note: in this case, mining by ancestor feerate results in the most
> rational decisions, but [a candidate set-based approach][10] which
> makes ancestor feerate much less relevant could
> be more advantageous in other situations.
>
> Here is a chart showing the "true" mining score alongside the values
> calculating using imperfect heuristics described above. All of them
> can overestimate or underestimate.
>
> ```
>    A     B       C     D
> mining score |   21   |   6   |   6   |   5   |
> ancestor feerate   |   21   |  11   | 10.3  |   9   |
> min(individual, ancestor) |   21   |   1   |   9   |   5   |
> min(tx + ancestor subsets)      |   21   |   1   |   5   |   3   |
> max(tx + descendants subsets) |   21   |   9   |   9   |   5   |
>
> ```
>
> Possibly the best solution for finding the "mining score" of a
> transaction is to build a block template, see what feerate each
> package is included at. Perhaps at some cutoff, remaining mempool
> transactions can be estimated using some heuristic that leans
> {overestimating, underestimating} depending on the situation.
>
> Mining score seems to be relevant in multiple places: Murch and I
> recently [found][3] that it would be very important in
> "ancestor-aware" funding of transactions (the wallet doesn't
> incorporate ancestor fees when using unconfirmed transactions in coin
> selection, which is a bug we want to fix).
>
> In general, it would be nice to know the exact mining priority of
> one's unconfirmed transaction is.  I can think of a few block/mempool
> explorers who might want to display this information for users.
>
> ### RBF Improvement Proposals
>
> After speaking to quite a few people, here are some suggestions
> for improvements that I have heard:
>
> * The ancestor score of the replacement must be {5, 10, N}% higher
>   than that of every original transaction.
>
> * The ancestor score of the replacement must be 1sat/vB higher than
>   that of every original transaction.
>
> * If the original transaction is in the top {0.75MvB, 1MvB} of the
>   mempool, apply the current rules (absolute fees must increase and
> pay for the replacement transaction's new bandwidth). Otherwise, use a
> feerate-only rule.
>
> * If fees don't increase, the size of the replacement transaction must
>   decrease by at least N%.
>
> * Rate-limit how many replacements we allow per prevout.
>
> * Rate-limit transaction validation in general, per peer.
>
> Perhaps some others on the mailing list can chime in to throw other
> ideas into the ring and/or combine some of these rules into a sensible
> policy.
>
> #### Replace by Feerate Only
>
> I don't think there's going to be a single-line feerate-based
> rule that can incorporate everything we need.
> On one hand, a feerate-only approach helps eliminate the issues
> associated with Rule #3. On the other hand, I believe the main concern
> with a feerate-only approach is how to rate limit replacements. We
> don't want to enable an attack such as:
>
> 1. Attacker broadcasts large, low-feerate transaction, and attaches a
> chain of descendants.
>
> 2. The attacker replaces the transaction with a smaller but higher
> feerate transaction, attaching a new chain of descendants.
>
> 3. Repeat 1000 times.
>
> #### Fees in Next Block and Feerate for the Rest of the Mempool
>
> Perhaps we can look at replacements like this:
>
> 1. Calculate the directly conflicting transactions and, with their
> descendants, the original transactions. Check signaling. Limit the
> total volume (e.g. can't be more than 100 total or 1MvB or something).
>
> 2. Find which original transactions would be in the next ~1 block. The
> replacement must pay at least this amount + X% in absolute fees. This
> guarantees that the fees of the next block doesn't decrease.
>
> 3. Find which transactions would be left in the mempool after that ~1
> block. The replacement's feerate must be Y% higher than the maximum
> mining score of these transactions. This guarantees that you now have
> only *better* candidates in your after-this-block mempool than you did
> before, even if the size and fees the transactions decrease.
>
> 4. Now you have two numbers: a minimum absolute fee amount and a
> minimum feerate. Check to see if the replacement(s) meet these
> minimums. Also, a wallet would be able to ask the node "What fee and
> feerate would I need to put on a transaction replacing this?" and use
> this information to fund a replacement transaction, without needing to
> guess or overshoot.
>
> Obviously, there are some magic numbers missing here. X and Y are
> TBD constants to ensure we have some kind of rate limiting for the
> number of replacements allowed using some set of fees.
>
> What should they be? We can do some arithmetic to see what happens if
> you start with the biggest/lowest feerate transaction and do a bunch
> of replacements. Maybe we end up with values that are high enough to
> prevent abuse and make sense for applications/users that do RBF.
>
> ### Mempool Changes Need for Implementation
>
> As described in the mining score section above,
> we may want additional tooling to more accurately assess
> the economic gain of replacing transactions in our mempool.
>
> A few options have been discussed:
>
> * Calculate block templates on the fly when we need to consider a
>   replacement. However, since replacements are [quite common][11]
>   and the information might be useful for other things as well,
>   it may be worth it to cache a block template.
>
> * Keep a persistent block template so that we know what transactions
>   we would put in the next block. We need to remember the feerate
> at which each transaction was included in the template, because an
> ancestor package may be included in the same block template in
> multiple subsets. Transactions included earlier alter the ancestor
> feerate of the remaining transactions in the package. We also need
> to keep track of the new feerates of transactions left over.
>
> * Divide the mempool into two layers, "high feerate" and "low
>   feerate." The high feerate layer contains ~1 block of packages with
> the highest ancestor feerates, and the low feerate layer contains
> everything else. At the edge of a block, we have a Knapsacky problem
> where the next highest ancestor feerate package might not fit, so we
> would probably want the high feerate layer ~2MvB or something to avoid
> underestimating the fees.
>
> ## Acknowledgements
>
> Thank you to everyone whose RBF-related suggestions, grievances,
> criticisms and ideas were incorporated in this document:
> Andrew Chow, Matt Corallo, Suhas Daftuar, Christian Decker,
> Mark Erhardt, Lloyd Fournier, Lisa Neigut, John Newbery,
> Antoine Poinsot, Antoine Riard, Larry Ruane,
> S3RK and Bastien Teinturier.
>
> Thanks for reading!
>
> Best,
> Gloria
>
> [1]:
> https://github.com/bitcoin/bitcoin/blob/master/doc/policy/mempool-replacements.md
> [2]: https://github.com/bitcoin/bitcoin/pull/23121#issuecomment-929475999
> [3]:
> https://github.com/Xekyo/bitcoin/commit/d754b0242ec69d42c570418aebf9c1335af0b8ea
> [4]: https://github.com/bitcoindevkit/bdk/issues/144
> [5]: https://github.com/bitcoindevkit/bdk/issues/414
> [6]:
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019464.html
> [7]:
> https://gist.github.com/glozow/dc4e9d5c5b14ade7cdfac40f43adb18a#new-unconfirmed-inputs-rule-2
> [8]: https://github.com/bitcoin/bitcoin/pull/23121#discussion_r777131366
> [9]: https://github.com/bitcoin/bitcoin/pull/22290#issuecomment-865887922
> [10]:
> https://gist.github.com/Xekyo/5cb413fe9f26dbce57abfd344ebbfaf2#file-candidate-set-based-block-building-md
> [11]: https://github.com/bitcoin/bitcoin/pull/22539#issuecomment-885763670
> [12]: https://github.com/bitcoin/bitcoin/pull/24007
> [13]:
> https://github.com/bitcoin/bitcoin/blob/1a369f006fd0bec373b95001ed84b480e852f191/src/wallet/feebumper.cpp#L114
> [14]:
> https://github.com/bitcoin/bitcoin/blob/cf5bb048e80d4cde8828787b266b7f5f2e3b6d7b/src/node/miner.cpp#L310-L320
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220130/f53be2a3/attachment-0001.html>

From aj at erisian.com.au  Mon Jan 31 02:18:52 2022
From: aj at erisian.com.au (Anthony Towns)
Date: Mon, 31 Jan 2022 12:18:52 +1000
Subject: [bitcoin-dev] TXHASH + CHECKSIGFROMSTACKVERIFY in lieu of CTV
 and ANYPREVOUT
In-Reply-To: <CAPfvXfLr4n6RsS6VbEZR59=MRwAx41Crx88ko8-qnRXW4nFYGA@mail.gmail.com>
References: <CAMZUoK=pkZuovtifBzdqhoyegzG+9hRTFEc7fG9nZPDK4KbU3w@mail.gmail.com>
 <CAD5xwhhwqJ_AETAb3p_zUZmRX-Dzh8J9G984zwEs=KFsGN8aNQ@mail.gmail.com>
 <CAMZUoKmU1cwUAQaBv5m8oo8H3TWBvgsZ_OkQaMC0n0+3cpFtWg@mail.gmail.com>
 <CAPfvXfLr4n6RsS6VbEZR59=MRwAx41Crx88ko8-qnRXW4nFYGA@mail.gmail.com>
Message-ID: <20220131021852.GA4149@erisian.com.au>

On Thu, Jan 27, 2022 at 07:18:54PM -0500, James O'Beirne via bitcoin-dev wrote:
> > I don't think implementing a CTV opcode that we expect to largely be
> > obsoleted by a TXHASH at a later date is yielding good value from a soft
> > fork process.
> Caching for something
> like TXHASH looks to me like a whole different ballgame relative to CTV,
> which has a single kind of hash.

I don't think caching is a particular problem even for the plethora of
flags Russell described: you cache each value upon use, and reuse that
cached item if it's needed for other signatures within the tx; sharing
with BIP 143, 341 or 342 signatures as appropriate. Once everything's
cached, each signature then only requires hashing about 32*17+4 = ~548
bytes, and you're only hashing each part of the transaction once in
order to satisfy every possible flag.

> Even if we were to adopt something like TXHASH, how long is it going to
> take to develop, test, and release?

I think the work to release something like TXHASH is all in deciding:

 - if TXHASH or CTV or something else is the better "UX"
 - what is a good tx to message algorithm and how it should be
   parametized
 - what's an appropriate upgrade path for the TXHASH/CTV/??? mechanism

BIP 119 provides one answer to each of those, but you still have to do
the work to decide if its a *good* answer to each of them.

> My guess is "a while" - 

If we want to get a good answer to those questions, it might be true
that it takes a while; but even if we want to rush ahead with more of
a "well, we're pretty sure it's not going to be a disaster" attitude,
we can do that with TXHASH (almost) as easily as with CTV.

> The utility of vaulting seems
> underappreciated among consensus devs and it's something I'd like to write
> about soon in a separate post.

I think most of the opposition is just that support for CTV seems to be
taking the form "something must be done; this is something, therefore
it must be done"...

I'd be more comfortable if the support looked more like "here are the
alternatives to CTV, and here's the advantages and drawbacks for each,
here's how they interact with other ideas, and here's why we think,
on balance, we think this approach is the best one". But mostly the
alternatives are dismissed with "this will take too long" or "this enables
recursive covenants which someone (we don't know who) might oppose".

Cheers,
aj


From bastien at acinq.fr  Mon Jan 31 15:57:52 2022
From: bastien at acinq.fr (Bastien TEINTURIER)
Date: Mon, 31 Jan 2022 16:57:52 +0100
Subject: [bitcoin-dev] Improving RBF Policy
In-Reply-To: <CALZpt+EjqKbhnN_5jy3kvYpMvjN8=iwRzMLSM7yS8_j-WzLrBQ@mail.gmail.com>
References: <CAFXO6=LGbaur6XQrE+6a6mAAHXduOCXoWPTgPosxAG59ZkK6Gg@mail.gmail.com>
 <CALZpt+EjqKbhnN_5jy3kvYpMvjN8=iwRzMLSM7yS8_j-WzLrBQ@mail.gmail.com>
Message-ID: <CACdvm3P1co1HDFKNxpHRe_JX_UPNw_P5qgL5cHCM=Qs+kR=B_A@mail.gmail.com>

Hi Gloria,

Many thanks for raising awareness on these issues and constantly pushing
towards finding a better model. This work will highly improve the
security of any multi-party contract trying to build on top of bitcoin
(because most multi-party contracts will need to have timeout conditions
and participants will need to make some transactions confirm before a
timeout happens - otherwise they may lose funds).

For starters, let me quickly explain why the current rules are hard to
work with in the context of lightning (but I believe most L2 protocols
will have the same issues). Feel free to skip this part if you are
already convinced.

## Motivation

The biggest pain point is BIP 125 rule 2.
If I need to increase the fees of a time-sensitive transaction because
the feerate has been rising since I broadcast it, I may need to also pay
high fees just to produce a confirmed utxo that I can use. I'm actually
paying a high fee twice instead of once (and needlessly using on-chain
space, our scarcest asset, because we could have avoided that additional
transaction!).

It also has some annoying "non-determinism".
Imagine that my transaction has been evicted from my mempool because its
feerate was too low. I could think "Great, that means I don't have to
apply BIP 125 restrictions, I can just fund this transaction as if it
were a new one!". But actually I do, because my transaction could still
be in miner's mempools and I have no way of knowing it...this means that
whenever I have broadcast a transaction, I must assume that I will
always need to abide by whatever replacement rules the network applies.

Fortunately, as far as I understand it, this rule only exists because of
a previous implementation detail of bitcoin core, so there's simply no
good reason to keep it.

The second biggest pain point is rule 3. It prevents me from efficiently
using my capital while it's unconfirmed. Whenever I'm using a big utxo
to fund a transaction, I will get a big change output, and it would
really be a waste to be unable to use that change output to fund other
transactions. In order to be capital-efficient, I will end up creating
descendant trees for my time-sensitive transactions. But as Gloria
explained, replacing all my children will cost me an absurdly large
amount of fees. So what I'm actually planning to do instead is to RBF
one of the descendants high enough to get the whole tree confirmed.
But if those descendants' timeouts were far in the future, that's a
waste, I paid a lot more fees for them than I should have. I'd like to
just replace my transaction and republish the invalidated children
independently.

Rule 4 doesn't hurt as much as the two previous ones, I don't have too
much to say about it.

To be fair to the BIP 125 authors, all of these scenarios were very hard
to forecast at the time this BIP was created. We needed years to build
on those rules to get a better understanding of their limitations and if
the rationale behind them made sense in the long term.

## Proposals

I believe that now is a good time to re-think those, and I really like
Gloria's categorization of the design constraints.

I'd like to propose a different way of looking at descendants that makes
it easier to design the new rules. The way I understand it, limiting the
impact on descendant transactions is only important for DoS protection,
not for incentive compatibility. I would argue that after evictions,
descendant transactions will be submitted again (because they represent
transactions that people actually want to make), so evicting them does
not have a negative impact on mining incentives (in a world where blocks
are full most of the time).

I'm curious to hear other people's thoughts on that. If it makes sense,
I would propose the following very simple rules:

1. The transaction's ancestor absolute fees must be X% higher than the
previous transaction's ancestor fees
2. The transaction's ancestor feerate must be Y% higher than the
previous transaction's ancestor feerate

I believe it's completely ok to require increasing both the fees and
feerate if we don't take descendants into account, because you control
your ancestor set - whereas the descendant set may be completely out of
your control.

This is very easy to use by wallets, because the ancestor set is easy to
obtain. And an important point is that the ancestor set is the same in
every mempool, whereas the descendant set is not (your mempool may have
rejected the last descendants, while other people's mempools may still
contain them).

Because of that reason, I'd like to avoid having a rule that relies on
some size of the replaced descendant set: it may be valid in your
mempool but invalid in someone else's, which makes it exploitable for
pinning attacks.

I believe these rules are incentive compatible (again, if you accept
the fact that the descendants will be re-submitted and mined as well,
so their fees aren't lost).

Can we choose X and Y so that these two rules are also DoS-resistant?
Unfortunately I'm not sure, so maybe we'll need to add a third rule to
address that. But before we do, can someone detail what it costs for a
node to evict a descendant tree? Given that bitcoin core doesn't allow
chains of more than 25 transactions, the maximum number of transactions
being replaced will be bounded by 25 * N (where N is the number of
outputs of the transaction being replaced). If it's just O(n) pruning of
a graph, maybe that's ok? Or maybe we make X or Y depend on the number
of outputs of the transaction being replaced (this would need very
careful thoughts)?

If you made it this far, thanks for reading!
A couple of comments on the previous messages:

> Currently, if we see a transaction
> that has the same txid as one in the mempool, we reject it as a
> duplicate, even if the feerate is much higher. It's unclear to me if
> we have a very strong reason to change this, but noting it as a
> limitation of our current replacement policy.

I don't see a strong reason from an L2 protocol's point of view yet, but
there are many unkown unknowns. But from a miner incentive's point of
view, we should keep the transaction with the higher feerate, shouldn't
we? In that case it's also a more efficient use of on-chain space, which
is a win, right?

> We might have a more-or-less long transition period during which we
support both...

Yes, this is a long term thing.
Even if bitcoin core releases a new version with updated RBF rules, as a
wallet you'll need to keep using the old rules for a long time if you
want to be safe.

But it's all the more reason to try to ship this as soon as possible,
this way maybe our grand-children will be able to benefit from it ;)
(just kidding on the timespan obviously).

Cheers,
Bastien

Le lun. 31 janv. 2022 ? 00:11, Antoine Riard via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> a ?crit :

> Hi Gloria,
>
> Thanks for this RBF sum up. Few thoughts and more context comments if it
> can help other readers.
>
> > For starters, the absolute fee pinning attack is especially
> > problematic if we apply the same rules (i.e. Rule #3 and #4) in
> > Package RBF. Imagine that Alice (honest) and Bob (adversary) share a
> > LN channel. The mempool is rather full, so their pre-negotiated
> > commitment transactions' feerates would not be considered high
> > priority by miners.  Bob broadcasts his commitment transaction and
> > attaches a very large child (100KvB with 100,000sat in fees) to his
> > anchor output. Alice broadcasts her commitment transaction with a
> > fee-bumping child (200vB with 50,000sat fees which is a generous
> > 250sat/vB), but this does not meet the absolute fee requirement. She
> > would need to add another 50,000sat to replace Bob's commitment
> > transaction.
>
> Solving LN pinning attacks, what we're aiming for is enabling a fair
> feerate bid between the  counterparties, thus either forcing the adversary
> to overbid or to disengage from the confirmation competition. If the
> replace-by-feerate rule is adopted, there shouldn't be an incentive for Bob
> to
> pick up the first option. Though if he does, that's a winning outcome for
> Alice, as one of the commitment transactions confirms and her
> time-sensitive second-stage HTLC can be subsequently confirmed.
>
> > It's unclear to me if
> > we have a very strong reason to change this, but noting it as a
> > limitation of our current replacement policy. See [#24007][12].
>
> Deployment of Taproot opens interesting possibilities in the
> vaults/payment channels design space, where the tapscripts can commit to
> different set of timelocks/quorum of keys. Even if the pre-signed states
> stay symmetric, whoever is the publisher, the feerate cost to spend can
> fluctuate.
>
> > While this isn't completely broken, and the user interface is
> > secondary to the safety of the mempool policy
>
> I think with L2s transaction broadcast backend, the stability and clarity
> of the RBF user interface is primary. What we could be worried about is a
> too-much complex interface easing the way for an attacker to trigger your
> L2 node to issue policy-invalid chain of transactions. Especially, when we
> consider that an attacker might have leverage on chain of transactions
> composition ("force broadcast of commitment A then commitment B, knowing
> they will share a CPFP") or even transactions size ("overload commitment A
> with HTLCs").
>
> > * If the original transaction is in the top {0.75MvB, 1MvB} of the
> >   mempool, apply the current rules (absolute fees must increase and
> > pay for the replacement transaction's new bandwidth). Otherwise, use a
> > feerate-only rule.
>
> How this new replacement rule would behave if you have a parent in the
> "replace-by-feerate" half but the child is in the "replace-by-fee" one ?
>
> If we allow the replacement of the parent based on the feerate, we might
> decrease the top block absolute fees.
>
> If we block the replacement of the parent based on the feerate because the
> replacement absolute fees aren't above the replaced package, we still
> preclude a pinning vector. The child might be low-feerate junk and even
> attached to a low ancestor-score branch.
>
> If I'm correct on this limitation, maybe we could turn off the
> "replace-by-fee" behavior as soon as the mempool is fulfilled with a few
> blocks ?
>
> > * Rate-limit how many replacements we allow per prevout.
>
> Depending on how it is implemented, though I would be concerned it
> introduces a new pinning vector in the context of shared-utxo. If it's a
> hardcoded constant, it could be exhausted by an adversary starting at the
> lowest acceptable feerate then slowly increasing while still not reaching
> the top of the mempool. Same if it's time-based or block-based, no
> guarantee the replacement slot is honestly used by your counterparty.
>
> Further, an above-the-average replacement frequency might just be the
> reflection of your confirmation strategy reacting to block schedule or
> mempools historical data. As long as the feerate penalty is paid, I lean to
> allow replacement.
>
> (One solution could be to associate per-user "tag" to the LN transactions,
> where each "tag" would have its own replacement slots, but privacy?)
>
> > * Rate-limit transaction validation in general, per peer.
>
> I think we could improve on the Core's new transaction requester logic.
> Maybe we could bind the peer announced flow based on the feerate score
> (modulo validation time) of the previously validated transactions from that
> peer ? That said, while related to RBF, it sounds to me that enhancing
> Core's rate-limiting transaction strategy is a whole discussion in itself
> [0]. Especially ensuring it's tolerant to the specific requirements of LN &
> consorts.
>
> > What should they be? We can do some arithmetic to see what happens if
> > you start with the biggest/lowest feerate transaction and do a bunch
> > of replacements. Maybe we end up with values that are high enough to
> > prevent abuse and make sense for applications/users that do RBF.
>
> That's a good question.
>
> One observation is that the attacker can always renew the set of DoSy
> utxos to pursue the attack. So maybe we could pick up constants scaled on
> the block size ? That way an attacker would have to burn fees, thus
> deterring them from launching an attack. Even if the attackers are miners,
> they have to renounce their income to acquire new DoSy utxos. If a low-fee
> period, we could scale up the constants ?
>
>
> Overall, I think there is the deployment issue to warn of. Moving to a new
> set of RBF rules implies for a lot of Bitcoin applications to rewrite their
> RBF logics. We might have a more-or-less long transition period during
> which we support both...
>
> Cheers,
> Antoine
>
> [0] https://github.com/bitcoin/bitcoin/pull/21224
>
> Le jeu. 27 janv. 2022 ? 09:10, Gloria Zhao via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> a ?crit :
>
>> Hi everyone,
>>
>> This post discusses limitations of current Bitcoin Core RBF policy and
>> attempts to start a conversation about how we can improve it,
>> summarizing some ideas that have been discussed. Please reply if you
>> have any new input on issues to be solved and ideas for improvement!
>>
>> Just in case I've screwed up the text wrapping again, another copy can be
>> found here:
>> https://gist.github.com/glozow/25d9662c52453bd08b4b4b1d3783b9ff
>>
>> ## Background
>>
>> Please feel free to skip this section if you are already familiar
>> with RBF.
>>
>> Nodes may receive *conflicting* unconfirmed transactions, aka
>> "double spends" of the same inputs. Instead of always keeping the
>> first transaction, since v0.12, Bitcoin Core mempool policy has
>> included a set of Replace-by-Fee (RBF) criteria that allows the second
>> transaction to replace the first one and any descendants it may have.
>>
>> Bitcoin Core RBF policy was previously documented as BIP 125.
>> The current RBF policy is documented [here][1]. In summary:
>>
>> 1. The directly conflicting transactions all signal replaceability
>>    explicitly.
>>
>> 2. The replacement transaction only includes an unconfirmed input if
>>    that input was included in one of the directly conflicting
>> transactions.
>>
>> 3. The replacement transaction pays an absolute fee of at least the
>>    sum paid by the original transactions.
>>
>> 4. The additional fees pays for the replacement transaction's
>>    bandwidth at or above the rate set by the node's *incremental relay
>> feerate*.
>>
>> 5. The sum of all directly conflicting transactions' descendant counts
>>    (number of transactions inclusive of itself and its descendants)
>> does not exceed 100.
>>
>> We can split these rules into 3 categories/goals:
>>
>> - **Allow Opting Out**: Some applications/businesses are unable to
>>   handle transactions that are replaceable (e.g. merchants that use
>> zero-confirmation transactions). We (try to) help these businesses by
>> honoring BIP125 signaling; we won't replace transactions that have not
>> opted in.
>>
>> - **Incentive Compatibility**: Ensure that our RBF policy would not
>>   accept replacement transactions which would decrease fee profits
>>   of a miner. In general, if our mempool policy deviates from what is
>> economically rational, it's likely that the transactions in our
>> mempool will not match the ones in miners' mempools, making our
>> fee estimation, compact block relay, and other mempool-dependent
>> functions unreliable. Incentive-incompatible policy may also
>> encourage transaction submission through routes other than the p2p
>> network, harming censorship-resistance and privacy of Bitcoin payments.
>>
>> - **DoS Protection**: Limit two types of DoS attacks on the node's
>>   mempool: (1) the number of times a transaction can be replaced and
>> (2) the volume of transactions that can be evicted during a
>> replacement.
>>
>> Even more abstract: our goal is to make a replacement policy that
>> results in a useful interface for users and safe policy for
>> node operators.
>>
>> ## Motivation
>>
>> There are a number of known problems with the current RBF policy.
>> Many of these shortcomings exist due to mempool limitations at the
>> time RBF was implemented or result from new types of Bitcoin usage;
>> they are not criticisms of the original design.
>>
>> ### Pinning Attacks
>>
>> The most pressing concern is that attackers may take advantage of
>> limitations in RBF policy to prevent other users' transactions from
>> being mined or getting accepted as a replacement.
>>
>> #### SIGHASH_ANYONECANPAY Pinning
>>
>> BIP125#2 can be bypassed by creating intermediary transactions to be
>> replaced together. Anyone can simply split a 1-input 1-output
>> transaction off from the replacement transaction, then broadcast the
>> transaction as is. This can always be done, and quite cheaply. More
>> details in [this comment][2].
>>
>> In general, if a transaction is signed with SIGHASH\_ANYONECANPAY,
>> anybody can just attach a low feerate parent to this transaction and
>> lower its ancestor feerate.  Even if you require SIGHASH\_ALL which
>> prevents an attacker from changing any outputs, the input can be a
>> very low amount (e.g. just above the dust limit) from a low-fee
>> ancestor and still bring down the ancestor feerate of the transaction.
>>
>> TLDR: if your transaction is signed with SIGHASH\_ANYONECANPAY and
>> signals replaceability, regardless of the feerate you broadcast at, an
>> attacker can lower its mining priority by adding an ancestor.
>>
>> #### Absolute Fee
>>
>> The restriction of requiring replacement transactions to increase the
>> absolute fee of the mempool has been described as "bonkers." If the
>> original transaction has a very large descendant that pays a large
>> amount of fees, even if it has a low feerate, the replacement
>> transaction must now pay those fees in order to meet Rule #3.
>>
>> #### Package RBF
>>
>> There are a number of reasons why, in order to enable Package RBF, we
>> cannot use the same criteria.
>>
>> For starters, the absolute fee pinning attack is especially
>> problematic if we apply the same rules (i.e. Rule #3 and #4) in
>> Package RBF. Imagine that Alice (honest) and Bob (adversary) share a
>> LN channel. The mempool is rather full, so their pre-negotiated
>> commitment transactions' feerates would not be considered high
>> priority by miners.  Bob broadcasts his commitment transaction and
>> attaches a very large child (100KvB with 100,000sat in fees) to his
>> anchor output. Alice broadcasts her commitment transaction with a
>> fee-bumping child (200vB with 50,000sat fees which is a generous
>> 250sat/vB), but this does not meet the absolute fee requirement. She
>> would need to add another 50,000sat to replace Bob's commitment
>> transaction.
>>
>> Disallowing new unconfirmed inputs (Rule #2) in Package RBF would be
>> broken for packages containing transactions already in the mempool,
>> explained [here][7].
>>
>> Note: I originally [proposed][6] Package RBF using the same Rule #3
>> and #4 before I realized how significant this pinning attack is. I'm
>> retracting that proposal, and a new set of Package RBF rules would
>> follow from whatever the new individual RBF rules end up being.
>>
>> #### Same Txid Different Witness
>>
>> Two transactions with the same non-witness data but different
>> witnesses have the same txid but different wtxid, and the same fee but
>> not necessarily the same feerate. Currently, if we see a transaction
>> that has the same txid as one in the mempool, we reject it as a
>> duplicate, even if the feerate is much higher. It's unclear to me if
>> we have a very strong reason to change this, but noting it as a
>> limitation of our current replacement policy. See [#24007][12].
>>
>> ### User Interface
>>
>> #### Using Unconfirmed UTXOs to Fund Replacements
>>
>> The restriction of only allowing confirmed UTXOs for funding a
>> fee-bump (Rule #2) can hurt users trying to fee-bump their
>> transactions and complicate wallet implementations. If the original
>> transaction's output value isn't sufficient to fund a fee-bump and/or
>> all of the user's other UTXOs are unconfirmed, they might not be able
>> to fund a replacement transaction. Wallet developers also need to
>> treat self-owned unconfirmed UTXOs as unusable for fee-bumping, which
>> adds complexity to wallet logic. For example, see BDK issues [#144][4]
>> and [#414][5].
>>
>> #### Interface Not Suitable for Coin Selection
>>
>> Currently, a user cannot simply create a replacement transaction
>> targeting a specific feerate or meeting a minimum fee amount and
>> expect to meet the RBF criteria. The fee amount depends on the size of
>> the replacement transaction, and feerate is almost irrelevant.
>>
>> Bitcoin Core's `bumpfee` doesn't use the RBF rules when funding the
>> replacement. It [estimates][13] a feerate which is "wallet incremental
>> relay fee" (a conservative overestimation of the node's incremental
>> relay fee) higher than the original transaction, selects coins for
>> that feerate, and hopes that it meets the RBF rules. It never fails
>> Rule #3 and #4 because it uses all original inputs and refuses to
>> bump a transaction with mempool descendants.
>>
>> This is suboptimal, but is designed to work with the coin selection
>> engine: select a feerate first, and then add fees to cover it.
>> Following the exact RBF rules would require working the other way
>> around: based on how much fees we've added to the transaction and its
>> current size, calculate the feerate to see if we meet Rule #4.
>>
>> While this isn't completely broken, and the user interface is
>> secondary to the safety of the mempool policy, we can do much better.
>> A much more user-friendly interface would depend *only* on the
>> fee and size of the original transactions.
>>
>> ### Updates to Mempool and Mining
>>
>> Since RBF was first implemented, a number of improvements have been
>> made to mempool and mining logic. For example, we now use ancestor
>> feerates in mining (allowing CPFP), and keep track of ancestor
>> packages in the mempool.
>>
>> ## Ideas for Improvements
>>
>> ### Goals
>>
>> To summarize, these seem to be desired changes, in order of priority:
>>
>> 1. Remove Rule #3. The replacement should not be *required* to pay
>> higher absolute fees.
>>
>> 2. Make it impossible for a replacement transaction to have a lower
>> mining score than the original transaction(s). This would eliminate
>> the `SIGHASH\_ANYONECANPAY` pinning attack.
>>
>> 3. Remove Rule #2. Adding new unconfirmed inputs should be allowed.
>>
>> 4. Create a more helpful interface that helps wallet fund replacement
>> transactions that aim for a feerate and fee.
>>
>> ### A Different Model for Fees
>>
>> For incentive compatibility, I believe there are different
>> formulations we should consider.  Most importantly, if we want to get
>> rid of the absolute fee rule, we can no longer think of it as "the
>> transaction needs to pay for its own bandwidth," since we won't always
>> be getting additional fees. That means we need a new method of
>> rate-limiting replacements that doesn't require additional fees every
>> time.
>>
>> While it makes sense to think about monetary costs when launching a
>> specific type of attack, given that the fees are paid to the miner and
>> not to the mempool operators, maybe it doesn't make much sense to
>> think about "paying for bandwidth". Maybe we should implement
>> transaction validation rate-limiting differently, e.g. building it
>> into the P2P layer instead of the mempool policy layer.
>>
>> Recently, Suhas gave a [formulation][8] for incentive compatibility
>> that made sense to me: "are the fees expected to be paid in the next
>> (N?) blocks higher or lower if we process this transaction?"
>>
>> I started by thinking about this where N=1 or `1 + p`.
>> Here, a rational miner is looking at what fees they would
>> collect in the next block, and then some proportion `p` of the rest of
>> the blocks based on their hashrate. We're assuming `p` isn't *so high*
>> that they would be okay with lower absolute fees in the next 1 block.
>> We're also assuming `p` isn't *so low* that the miner doesn't care
>> about what's left of the mempool after this block.
>>
>> A tweak to this formulation is "if we process this transaction, would
>> the fees in the next 1 block higher or lower, and is the feerate
>> density of the rest of the mempool higher or lower?" This is pretty
>> similar, where N=1, but we consider the rest of the mempool by feerate
>> rather than fees.
>>
>> ### Mining Score of a Mempool Transaction
>>
>> We are often interested in finding out what
>> the "mining score" of a transaction in the mempool is. That is, when
>> the transaction is considered in block template building, what is the
>> feerate it is considered at?
>>
>> Obviously, it's not the transaction's individual feerate. Bitcoin Core
>> [mining code sorts][14] transactions by their ancestor feerate and
>> includes them packages at a time, keeping track of how this affects the
>> package feerates of remaining transactions in the mempool.
>>
>> *ancestor feerate*: Ancestor feerate is easily accessible information,
>> but it's not accurate either, because it doesn't take into account the
>> fact that subsets of a transaction's ancestor set can be included
>> without it. For example, ancestors may have high feerates on their own
>> or we may have [high feerate siblings][8].
>>
>> TLDR: *Looking at the current ancestor feerate of a transaction is
>> insufficient to tell us what feerate it will be considered at when
>> building a block template in the future.*
>>
>> *min(individual feerate, ancestor feerate)*: Another
>> heuristic that is simple to calculate based on current mempool tooling
>> is to use the [minimum of a transaction's individual score and its
>> ancestor score][10] as a conservative measure.  But this can
>> overestimate as well (see the example below).
>>
>> *min ancestor feerate(tx + possible ancestor subsets)* We can also
>> take the minimum of every possible ancestor subset, but this can be
>> computationally expensive since there can be lots and lots of ancestor
>> subsets.
>>
>> *max ancestor feerate(tx + possible descendant subsets)*: Another idea
>> is to use the [maximum ancestor score of the transaction + each of its
>> descendants][9]. This doesn't work either; it has the same blindspot
>> of ancestor subsets being mined on their own.
>>
>> #### Mining Score Example
>>
>> Here's an example illustrating why mining score is tricky to
>> efficiently calculate for mempool transactions:
>>
>> Let's say you have same-size transactions A (21sat/vB), B (1sat/vB),
>> C(9sat/vB), D(5sat/vB).
>> The layout is: grandparent A, parent B, and two children C and D.
>>
>> ```
>>     A
>>     ^
>>     B
>>    ^ ^
>>    C D
>> ```
>>
>> A miner using ancestor packages to build block templates will first
>> include A with a mining score of 21. Next, the miner will include B and
>> C with a mining score of 6. This leaves D, with a mining score of 5.
>>
>> Note: in this case, mining by ancestor feerate results in the most
>> rational decisions, but [a candidate set-based approach][10] which
>> makes ancestor feerate much less relevant could
>> be more advantageous in other situations.
>>
>> Here is a chart showing the "true" mining score alongside the values
>> calculating using imperfect heuristics described above. All of them
>> can overestimate or underestimate.
>>
>> ```
>>    A     B       C     D
>> mining score |   21   |   6   |   6   |   5   |
>> ancestor feerate   |   21   |  11   | 10.3  |   9   |
>> min(individual, ancestor) |   21   |   1   |   9   |   5   |
>> min(tx + ancestor subsets)      |   21   |   1   |   5   |   3   |
>> max(tx + descendants subsets) |   21   |   9   |   9   |   5   |
>>
>> ```
>>
>> Possibly the best solution for finding the "mining score" of a
>> transaction is to build a block template, see what feerate each
>> package is included at. Perhaps at some cutoff, remaining mempool
>> transactions can be estimated using some heuristic that leans
>> {overestimating, underestimating} depending on the situation.
>>
>> Mining score seems to be relevant in multiple places: Murch and I
>> recently [found][3] that it would be very important in
>> "ancestor-aware" funding of transactions (the wallet doesn't
>> incorporate ancestor fees when using unconfirmed transactions in coin
>> selection, which is a bug we want to fix).
>>
>> In general, it would be nice to know the exact mining priority of
>> one's unconfirmed transaction is.  I can think of a few block/mempool
>> explorers who might want to display this information for users.
>>
>> ### RBF Improvement Proposals
>>
>> After speaking to quite a few people, here are some suggestions
>> for improvements that I have heard:
>>
>> * The ancestor score of the replacement must be {5, 10, N}% higher
>>   than that of every original transaction.
>>
>> * The ancestor score of the replacement must be 1sat/vB higher than
>>   that of every original transaction.
>>
>> * If the original transaction is in the top {0.75MvB, 1MvB} of the
>>   mempool, apply the current rules (absolute fees must increase and
>> pay for the replacement transaction's new bandwidth). Otherwise, use a
>> feerate-only rule.
>>
>> * If fees don't increase, the size of the replacement transaction must
>>   decrease by at least N%.
>>
>> * Rate-limit how many replacements we allow per prevout.
>>
>> * Rate-limit transaction validation in general, per peer.
>>
>> Perhaps some others on the mailing list can chime in to throw other
>> ideas into the ring and/or combine some of these rules into a sensible
>> policy.
>>
>> #### Replace by Feerate Only
>>
>> I don't think there's going to be a single-line feerate-based
>> rule that can incorporate everything we need.
>> On one hand, a feerate-only approach helps eliminate the issues
>> associated with Rule #3. On the other hand, I believe the main concern
>> with a feerate-only approach is how to rate limit replacements. We
>> don't want to enable an attack such as:
>>
>> 1. Attacker broadcasts large, low-feerate transaction, and attaches a
>> chain of descendants.
>>
>> 2. The attacker replaces the transaction with a smaller but higher
>> feerate transaction, attaching a new chain of descendants.
>>
>> 3. Repeat 1000 times.
>>
>> #### Fees in Next Block and Feerate for the Rest of the Mempool
>>
>> Perhaps we can look at replacements like this:
>>
>> 1. Calculate the directly conflicting transactions and, with their
>> descendants, the original transactions. Check signaling. Limit the
>> total volume (e.g. can't be more than 100 total or 1MvB or something).
>>
>> 2. Find which original transactions would be in the next ~1 block. The
>> replacement must pay at least this amount + X% in absolute fees. This
>> guarantees that the fees of the next block doesn't decrease.
>>
>> 3. Find which transactions would be left in the mempool after that ~1
>> block. The replacement's feerate must be Y% higher than the maximum
>> mining score of these transactions. This guarantees that you now have
>> only *better* candidates in your after-this-block mempool than you did
>> before, even if the size and fees the transactions decrease.
>>
>> 4. Now you have two numbers: a minimum absolute fee amount and a
>> minimum feerate. Check to see if the replacement(s) meet these
>> minimums. Also, a wallet would be able to ask the node "What fee and
>> feerate would I need to put on a transaction replacing this?" and use
>> this information to fund a replacement transaction, without needing to
>> guess or overshoot.
>>
>> Obviously, there are some magic numbers missing here. X and Y are
>> TBD constants to ensure we have some kind of rate limiting for the
>> number of replacements allowed using some set of fees.
>>
>> What should they be? We can do some arithmetic to see what happens if
>> you start with the biggest/lowest feerate transaction and do a bunch
>> of replacements. Maybe we end up with values that are high enough to
>> prevent abuse and make sense for applications/users that do RBF.
>>
>> ### Mempool Changes Need for Implementation
>>
>> As described in the mining score section above,
>> we may want additional tooling to more accurately assess
>> the economic gain of replacing transactions in our mempool.
>>
>> A few options have been discussed:
>>
>> * Calculate block templates on the fly when we need to consider a
>>   replacement. However, since replacements are [quite common][11]
>>   and the information might be useful for other things as well,
>>   it may be worth it to cache a block template.
>>
>> * Keep a persistent block template so that we know what transactions
>>   we would put in the next block. We need to remember the feerate
>> at which each transaction was included in the template, because an
>> ancestor package may be included in the same block template in
>> multiple subsets. Transactions included earlier alter the ancestor
>> feerate of the remaining transactions in the package. We also need
>> to keep track of the new feerates of transactions left over.
>>
>> * Divide the mempool into two layers, "high feerate" and "low
>>   feerate." The high feerate layer contains ~1 block of packages with
>> the highest ancestor feerates, and the low feerate layer contains
>> everything else. At the edge of a block, we have a Knapsacky problem
>> where the next highest ancestor feerate package might not fit, so we
>> would probably want the high feerate layer ~2MvB or something to avoid
>> underestimating the fees.
>>
>> ## Acknowledgements
>>
>> Thank you to everyone whose RBF-related suggestions, grievances,
>> criticisms and ideas were incorporated in this document:
>> Andrew Chow, Matt Corallo, Suhas Daftuar, Christian Decker,
>> Mark Erhardt, Lloyd Fournier, Lisa Neigut, John Newbery,
>> Antoine Poinsot, Antoine Riard, Larry Ruane,
>> S3RK and Bastien Teinturier.
>>
>> Thanks for reading!
>>
>> Best,
>> Gloria
>>
>> [1]:
>> https://github.com/bitcoin/bitcoin/blob/master/doc/policy/mempool-replacements.md
>> [2]: https://github.com/bitcoin/bitcoin/pull/23121#issuecomment-929475999
>> [3]:
>> https://github.com/Xekyo/bitcoin/commit/d754b0242ec69d42c570418aebf9c1335af0b8ea
>> [4]: https://github.com/bitcoindevkit/bdk/issues/144
>> [5]: https://github.com/bitcoindevkit/bdk/issues/414
>> [6]:
>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019464.html
>> [7]:
>> https://gist.github.com/glozow/dc4e9d5c5b14ade7cdfac40f43adb18a#new-unconfirmed-inputs-rule-2
>> [8]: https://github.com/bitcoin/bitcoin/pull/23121#discussion_r777131366
>> [9]: https://github.com/bitcoin/bitcoin/pull/22290#issuecomment-865887922
>> [10]:
>> https://gist.github.com/Xekyo/5cb413fe9f26dbce57abfd344ebbfaf2#file-candidate-set-based-block-building-md
>> [11]:
>> https://github.com/bitcoin/bitcoin/pull/22539#issuecomment-885763670
>> [12]: https://github.com/bitcoin/bitcoin/pull/24007
>> [13]:
>> https://github.com/bitcoin/bitcoin/blob/1a369f006fd0bec373b95001ed84b480e852f191/src/wallet/feebumper.cpp#L114
>> [14]:
>> https://github.com/bitcoin/bitcoin/blob/cf5bb048e80d4cde8828787b266b7f5f2e3b6d7b/src/node/miner.cpp#L310-L320
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220131/bab2313a/attachment-0001.html>

From bram at chia.net  Mon Jan 31 22:54:10 2022
From: bram at chia.net (Bram Cohen)
Date: Mon, 31 Jan 2022 14:54:10 -0800
Subject: [bitcoin-dev] Improving RBF policy
In-Reply-To: <mailman.19693.1643292568.8511.bitcoin-dev@lists.linuxfoundation.org>
References: <mailman.19693.1643292568.8511.bitcoin-dev@lists.linuxfoundation.org>
Message-ID: <CAHUJnBA7AtX_osJUJQyKmc5QBknH5U0TKU3hiyxzpPv4TN88JQ@mail.gmail.com>

Gloria Zhao wrote:

>
> This post discusses limitations of current Bitcoin Core RBF policy and
> attempts to start a conversation about how we can improve it,
> summarizing some ideas that have been discussed. Please reply if you
> have any new input on issues to be solved and ideas for improvement!
>

Is it still verboten to acknowledge that RBF is normal behavior and
disallowing it is the feature, and that feature is mostly there to appease
some people's delusions that zeroconf is a thing? It seems a bit overdue to
disrespect the RBF flag in the direction of always assuming it's on.


> - **Incentive Compatibility**: Ensure that our RBF policy would not
>   accept replacement transactions which would decrease fee profits
>   of a miner. In general, if our mempool policy deviates from what is
> economically rational, it's likely that the transactions in our
> mempool will not match the ones in miners' mempools, making our
> fee estimation, compact block relay, and other mempool-dependent
> functions unreliable. Incentive-incompatible policy may also
> encourage transaction submission through routes other than the p2p
> network, harming censorship-resistance and privacy of Bitcoin payments.
>

There are two different common regimes which result in different
incentivized behavior. One of them is that there's more than a block's
backlog in the mempool in which case between two conflicting transactions
the one with the higher fee rate should win. In the other case where there
isn't a whole block's worth of transactions the one with higher total value
should win. It would be nice to have consolidated logic which handles both,
it seems the issue has to do with the slope of the supply/demand curve
which in the first case is gentle enough to keep the one transaction from
hitting the rate but in the second one is basically infinite.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220131/0d66162d/attachment.html>

