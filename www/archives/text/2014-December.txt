From cryptocurrencies at quidecco.de  Mon Dec  1 10:42:58 2014
From: cryptocurrencies at quidecco.de (Isidor Zeuner)
Date: Mon,  1 Dec 2014 11:42:58 +0100 (CET)
Subject: [Bitcoin-development] Deanonymisation of clients in Bitcoin P2P
 network paper
In-Reply-To: <CAAS2fgRSxBmyDg5R7WgisB-XmhrpGVKHXQpchtL-Ow0xDQAziA@mail.gmail.com>
References: <CAAS2fgRSxBmyDg5R7WgisB-XmhrpGVKHXQpchtL-Ow0xDQAziA@mail.gmail.com>
	<CAJHLa0N6+hpwNECpHUSiKuj4-BYohh=Wr1DP=67Ff8xVBsi8-Q@mail.gmail.com>
	<54760A50.201@riseup.net> <20141127020947.A13D2E19A09@quidecco.de>
Message-ID: <20141201104258.9E56EE170B7@quidecco.de>

Hi Gregory,

response below quote:
> > Since this attack vector has been discussed, I started making some
> > measurements on how effective it is to connect to Bitcoin using Tor,
> > and I found that the number of connections dropping to near-zero is
> > a situation which occurs rather frequently, which suggests that there
> > is still room to improve on the DoS handling.
>
> I'm confused by this, I run quite a few nodes exclusively on tor and
> chart their connectivity and have seen no such connection dropping
> behaviour.
>
> Can you tell me more about how you measured this?
>

When you say "running exclusively on Tor", what do you mean exactly?
Do you also connect or allow connections through hidden services?

I made outbound connections through Tor exit points the only way to
connect to Bitcoin, and increased the number of allowed outbound
connection in order to get more meaningful values.

Lately, I could see unusual behaviour at:

* 2014-11-28 13:14 UTC
* 2014-11-25 07:32 UTC
* 2014-11-24 13:06 UTC

Anything I should look into?

> [As an aside I agree that there are lots of things to improve here,
> but the fact that users can in theory be forced off of tor via DOS
> attacks is not immediately concerning to me because its a conscious
> choice users would make to abandon their privacy (and the behaviour of
> the system here is known and intentional). There are other mechanisms
> available for people to relay their transactions than connecting
> directly to the bitcoin network; so their choice isn't just abandon
> privacy or don't use bitcoin at all.]
>

I think this issue is more important than it seems.

Firstly, when running Tor-only, there are still attack vectors which
make use of the DoS protection deficiencies.

Secondly, if we tell people not to connect directly if they want
privacy, how do we ensure that these indirect methods will not come
with implications for their privacy?

Best regards,

Isidor



From thiagocmartinsc at gmail.com  Thu Dec  4 14:32:19 2014
From: thiagocmartinsc at gmail.com (=?UTF-8?B?TWFydGlueCAtIOOCuOOCp+ODvOODoOOCug==?=)
Date: Thu, 4 Dec 2014 12:32:19 -0200
Subject: [Bitcoin-development] [bitcoin-list] Running a full node
In-Reply-To: <CAD2Ti2_AgRK=Fbz+i=HvUZis8ZwLx7PsHWHzgAUOF=jb19oGqQ@mail.gmail.com>
References: <545B5323.3000403@numlog.fr> <545F86AD.3050002@numlog.fr>
	<CAD2Ti2_AgRK=Fbz+i=HvUZis8ZwLx7PsHWHzgAUOF=jb19oGqQ@mail.gmail.com>
Message-ID: <CAJSM8J1LW2DJx4AFUqAFNYs4syEtB221uMWS4Vrstvzwp3WAjg@mail.gmail.com>

Bitcoind|qt needs Dual-Stack support.   ;-)

Cheers!
Thiago

On 9 November 2014 at 15:52, grarpamp <grarpamp at gmail.com> wrote:
> You may also wish to consider linking your node into
> the Tor, I2P, and maybe even CJDNS networks. Details
> on their respective mailing lists.
>
> ------------------------------------------------------------------------------
> _______________________________________________
> bitcoin-list mailing list
> bitcoin-list at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-list



From luke at dashjr.org  Thu Dec  4 15:42:42 2014
From: luke at dashjr.org (Luke Dashjr)
Date: Thu, 4 Dec 2014 15:42:42 +0000
Subject: [Bitcoin-development] Serialised P2SH HD chains
Message-ID: <201412041542.44207.luke@dashjr.org>

Is anyone working on a serialisation format to convey P2SH HD chains? For 
example, to give someone who wants to make recurring payments a single token 
that can be used to generate many P2SH addresses paying to a multisig script.

I'm thinking of something along the lines of a simple series of tokens, each 
indicating either a HD chain or literal script content. For all HD chains in 
the data, a child key would be generated based on the payment number, and all 
tokens concatenated to form the P2SH serialised script. Eg, for a simple 2-
of-2, you would do something like this:
    literal(OP_2) HDChain HDChain literal(OP_2 OP_CHECKMULTISIG)
Does this sufficiently cover all reasonable use cases?

Luke



From gavinandresen at gmail.com  Thu Dec  4 16:46:28 2014
From: gavinandresen at gmail.com (Gavin Andresen)
Date: Thu, 4 Dec 2014 11:46:28 -0500
Subject: [Bitcoin-development] Serialised P2SH HD chains
In-Reply-To: <201412041542.44207.luke@dashjr.org>
References: <201412041542.44207.luke@dashjr.org>
Message-ID: <CABsx9T0rS0R-tGHpBajPrRjtu77Z97+nhSLuWsXshHiQp4SqWg@mail.gmail.com>

On Thu, Dec 4, 2014 at 10:42 AM, Luke Dashjr <luke at dashjr.org> wrote:

> Is anyone working on a serialisation format to convey P2SH HD chains? For example,
> to give someone who wants to make recurring payments a single token that
> can be used to generate many P2SH addresses paying to a multisig script.


Seems like the wrong approach to me, because in practice you really need
a reasonable expiration date or some way of determining that whatever you
are paying
is still around (I still get random transactions to the Bitcoin Faucet's
old addresses).

See the discussion from January about extending the payment protocol for
recurring transactions:

https://www.mail-archive.com/bitcoin-development at lists.sourceforge.net/msg03823.html

"Give them a single token" == "give them a recurring PaymentRequest" in my
mind. Or maybe "Give them a URL where they can fetch PaymentRequests
whenever they need to make a payment" or maybe "Give them an array of
PaymentRequests for the next X days/months/years of payments."

-- 
--
Gavin Andresen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141204/2bb31fe5/attachment.html>

From swansontec at gmail.com  Thu Dec  4 17:25:05 2014
From: swansontec at gmail.com (William Swanson)
Date: Thu, 4 Dec 2014 09:25:05 -0800
Subject: [Bitcoin-development] Serialised P2SH HD chains
In-Reply-To: <201412041542.44207.luke@dashjr.org>
References: <201412041542.44207.luke@dashjr.org>
Message-ID: <CABjHNoRJV4r9YxjFamnA1G2CJwmig3FqbJhpXt9LAovMkPCPvA@mail.gmail.com>

Yes. A few of us over here in San Diego actually started working on a
format like this a few months ago, but it's been on the back burner
for a while.

Our motivation was to come up with a shared HD wallet format. Say I
would like create a 2-of-3 multisig wallet using my phone, PC, and
hardware key fob. All three devices would presumably be running
different wallet software, so we need some sort of standardized HD
multisig chain-description format that all three wallets can
understand. That way, regardless of their other differences, the
wallets can at least agree on how to generate new addresses.

Of course, once you share this chain-description file with a third
party, they too can generate addresses out of the wallet. This can be
used for auditing (like for charities), for receive-only wallets (like
a merchant kiosk), and for recurring payments. The recurring payment
case is a little problematic, since you need to trust the payee with
your privacy. I imagine this would only be useful for payouts you
manage yourself, like a mining pool, and not something you share with
the general public.

Our format is very similar to yours. We have a script template, just
like you do, but we describe the HD chains in a separate section
rather than in-line with the script. The script template only comes
into being once the chains have been gathered together into one place,
so the chain descriptions need to stand alone.

Unfortunately, we still have a lot of details to work through before
we have a concrete proposal that's ready for this mailing list.
Perhaps we can work together to come up with something.

-William

On Thu, Dec 4, 2014 at 7:42 AM, Luke Dashjr <luke at dashjr.org> wrote:
> Is anyone working on a serialisation format to convey P2SH HD chains? For
> example, to give someone who wants to make recurring payments a single token
> that can be used to generate many P2SH addresses paying to a multisig script.
>
> I'm thinking of something along the lines of a simple series of tokens, each
> indicating either a HD chain or literal script content. For all HD chains in
> the data, a child key would be generated based on the payment number, and all
> tokens concatenated to form the P2SH serialised script. Eg, for a simple 2-
> of-2, you would do something like this:
>     literal(OP_2) HDChain HDChain literal(OP_2 OP_CHECKMULTISIG)
> Does this sufficiently cover all reasonable use cases?
>
> Luke



From mike at plan99.net  Thu Dec  4 18:04:21 2014
From: mike at plan99.net (Mike Hearn)
Date: Thu, 4 Dec 2014 19:04:21 +0100
Subject: [Bitcoin-development] Serialised P2SH HD chains
In-Reply-To: <CABjHNoRJV4r9YxjFamnA1G2CJwmig3FqbJhpXt9LAovMkPCPvA@mail.gmail.com>
References: <201412041542.44207.luke@dashjr.org>
	<CABjHNoRJV4r9YxjFamnA1G2CJwmig3FqbJhpXt9LAovMkPCPvA@mail.gmail.com>
Message-ID: <CANEZrP2AErGjNtynaKb-a-9ScTJVWNpVzbeebCfGHuNoZK8Y3A@mail.gmail.com>

I wrote a little Javascript program
<https://github.com/bitcoinj/bitcoinj/blob/master/examples/src/main/javascript/payprotocol.js>
to print some minimal protobufs to base64.

Result for a multisig output:

Ik0SSRJHUiECpm1rIsOcaCf/CqL/YeqNXgcnQzb/+hfaawdi9u46xhEhAgoJfDU3M5mr++dfBG2gO5DiBiBVkVmLzjSLf26HEINeUq4YAA

Result for a regular pay to address output:

Ih8SGxIZdqkU4nFAzWDBp6LEi4uXgddL65H11nGIrBgA

That is without any expiry time, which you'd want in practice. For an
HD-iterating payment request you'd also need a few flags and fields, but a
well designed protocol should only add a handful of bytes. The above
strings are, I think, short enough to set as a username in a mining program
so the general UX of Eligius can be maintained.

How to generate them? That's not too hard. Building specialised one-off SPV
wallets is quite easy these days with bitcoinj, there's a template app and
a video tutorial on how to customise it available here:

https://bitcoinj.github.io/simple-gui-wallet

You can just copy/paste the code into a new directory and start modifying
it. The final result is like Lighthouse - you run a program and get an EXE
installer or MSI for Windows, a DMG for MacOS and a .deb for Linux (though
a tarball would work just as well).

So producing a little GUI that lets you build a base64 encoded payment
protocol request that supports HD iteration for one or more keys, along
with a little BIP70 extension that says "although this output is a multisig
output, please actually create a p2sh output", would make a nice starter
project for someone. It could also then act as a watching wallet and plot a
graph of mining payouts over time, for example.

If anyone wants to take this on let me know. I can help out with the final
code signing steps to make Gatekeeper/Internet Explorer happy so don't
worry about distribution.

On Thu, Dec 4, 2014 at 6:25 PM, William Swanson <swansontec at gmail.com>
wrote:

> Yes. A few of us over here in San Diego actually started working on a
> format like this a few months ago, but it's been on the back burner
> for a while.
>
> Our motivation was to come up with a shared HD wallet format. Say I
> would like create a 2-of-3 multisig wallet using my phone, PC, and
> hardware key fob. All three devices would presumably be running
> different wallet software, so we need some sort of standardized HD
> multisig chain-description format that all three wallets can
> understand. That way, regardless of their other differences, the
> wallets can at least agree on how to generate new addresses.
>
> Of course, once you share this chain-description file with a third
> party, they too can generate addresses out of the wallet. This can be
> used for auditing (like for charities), for receive-only wallets (like
> a merchant kiosk), and for recurring payments. The recurring payment
> case is a little problematic, since you need to trust the payee with
> your privacy. I imagine this would only be useful for payouts you
> manage yourself, like a mining pool, and not something you share with
> the general public.
>
> Our format is very similar to yours. We have a script template, just
> like you do, but we describe the HD chains in a separate section
> rather than in-line with the script. The script template only comes
> into being once the chains have been gathered together into one place,
> so the chain descriptions need to stand alone.
>
> Unfortunately, we still have a lot of details to work through before
> we have a concrete proposal that's ready for this mailing list.
> Perhaps we can work together to come up with something.
>
> -William
>
> On Thu, Dec 4, 2014 at 7:42 AM, Luke Dashjr <luke at dashjr.org> wrote:
> > Is anyone working on a serialisation format to convey P2SH HD chains? For
> > example, to give someone who wants to make recurring payments a single
> token
> > that can be used to generate many P2SH addresses paying to a multisig
> script.
> >
> > I'm thinking of something along the lines of a simple series of tokens,
> each
> > indicating either a HD chain or literal script content. For all HD
> chains in
> > the data, a child key would be generated based on the payment number,
> and all
> > tokens concatenated to form the P2SH serialised script. Eg, for a simple
> 2-
> > of-2, you would do something like this:
> >     literal(OP_2) HDChain HDChain literal(OP_2 OP_CHECKMULTISIG)
> > Does this sufficiently cover all reasonable use cases?
> >
> > Luke
>
>
> ------------------------------------------------------------------------------
> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server
> from Actuate! Instantly Supercharge Your Business Reports and Dashboards
> with Interactivity, Sharing, Native Excel Exports, App Integration & more
> Get technology previously reserved for billion-dollar corporations, FREE
>
> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141204/0b9d3095/attachment.html>

From jp at eeqj.com  Thu Dec  4 20:02:17 2014
From: jp at eeqj.com (Jeffrey Paul)
Date: Thu, 4 Dec 2014 12:02:17 -0800
Subject: [Bitcoin-development] Serialised P2SH HD chains
In-Reply-To: <201412041542.44207.luke@dashjr.org>
References: <201412041542.44207.luke@dashjr.org>
Message-ID: <F904F6F8-BA2E-4B86-8C6C-B34A88D384BD@eeqj.com>


> On 20141204, at 07:42, Luke Dashjr <luke at dashjr.org> wrote:
> 
> Is anyone working on a serialisation format to convey P2SH HD chains? For 
> example, to give someone who wants to make recurring payments a single token 
> that can be used to generate many P2SH addresses paying to a multisig script.
> 
> I'm thinking of something along the lines of a simple series of tokens, each 
> indicating either a HD chain or literal script content. For all HD chains in 
> the data, a child key would be generated based on the payment number, and all 
> tokens concatenated to form the P2SH serialised script. Eg, for a simple 2-
> of-2, you would do something like this:
>    literal(OP_2) HDChain HDChain literal(OP_2 OP_CHECKMULTISIG)
> Does this sufficiently cover all reasonable use cases?


What is the use case for something like this?  It?s my impression that a single token that can be used to obtain many P2SH addresses paying to a multisig script looks something like

   bitcoin:?r=https://payee.com/customer12345/recurring/paymentrequest/new

As it?s impossible to actually transmit a tx without network access, why would it be necessary to, at payment time, not contact the payee and use the existing bip70 authenticated payment request protocol to find out exactly what multisig address they?d like paid at that moment?

The model that you describe where a payer can, without communication with the payee, generate additional multisig p2sh addresses based on a set of xpubs presumes that the payee would never want to e.g. cycle their own keys or change their cooperating multisig participants? keys.  Is this wise?

Lately I?ve been thinking of bitcoin addresses (even multisig) as sort of MX records - something that the paying user shouldn?t depend on being static, because they are derived from keys that may change (or be lost or compromised) over time.  The canonical ?pay me at this address forever QR code? should be a bitcoin: URI that points to a payment request generating URL, should it not?

Best,
-jp

--
Jeffrey Paul                                                      EEQJ
jp at eeqj.com                                           https://eeqj.com
+1-800-403-1126 (America)                  +1-312-361-0355 (Worldwide)
5539 AD00 DE4C 42F3 AFE1                      1575 0524 43F4 DF2A 55C2




From mperklin at bitcoinsultants.ca  Thu Dec  4 20:40:12 2014
From: mperklin at bitcoinsultants.ca (Michael Perklin)
Date: Thu, 4 Dec 2014 15:40:12 -0500
Subject: [Bitcoin-development] Serialised P2SH HD chains
In-Reply-To: <mailman.473107.1417725057.2207.bitcoin-development@lists.sourceforge.net>
References: <mailman.473107.1417725057.2207.bitcoin-development@lists.sourceforge.net>
Message-ID: <C314D374-FD73-4997-9DCC-0386F807E494@bitcoinsultants.ca>

Luke,

Eric Lombrozo is doing work similar to that. You may wish to connect.

He's building a BIP to standardize a multisig application of BIP32.
Like there are xprv and xpubs for single keychains, he is developing a similar construct that would embed all information necessary for a "multisig xpub" (total keychains in system, minimum # of keys required, and which derivation paths on each keychain are to be combined to make the resultant multisig wallet)

The result would be taking an xpub style string and piping it through a BIP32-like algorithm to pop off P2SH addresses in a deterministic order, just like BIP32 pops off standard addresses in deterministic order.

I will ping Eric to connect with you in case the both of you are working on something similar and you can help each other.


Michael Perklin
Bitcoinsultants Inc.

On Thu, Dec 4, 2014 at 7:42 AM, Luke Dashjr <luke at dashjr.org <mailto:luke at dashjr.org>> wrote:
> Is anyone working on a serialisation format to convey P2SH HD chains? For
> example, to give someone who wants to make recurring payments a single token
> that can be used to generate many P2SH addresses paying to a multisig script.
> 
> I'm thinking of something along the lines of a simple series of tokens, each
> indicating either a HD chain or literal script content. For all HD chains in
> the data, a child key would be generated based on the payment number, and all
> tokens concatenated to form the P2SH serialised script. Eg, for a simple 2-
> of-2, you would do something like this:
>    literal(OP_2) HDChain HDChain literal(OP_2 OP_CHECKMULTISIG)
> Does this sufficiently cover all reasonable use cases?
> 
> Luke
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141204/144f7678/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 842 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141204/144f7678/attachment.sig>

From pete at petertodd.org  Thu Dec  4 20:43:32 2014
From: pete at petertodd.org (Peter Todd)
Date: Thu, 04 Dec 2014 20:43:32 +0000
Subject: [Bitcoin-development] Serialised P2SH HD chains
In-Reply-To: <F904F6F8-BA2E-4B86-8C6C-B34A88D384BD@eeqj.com>
References: <201412041542.44207.luke@dashjr.org>
	<F904F6F8-BA2E-4B86-8C6C-B34A88D384BD@eeqj.com>
Message-ID: <EDE19DB7-A029-47AB-8E34-B59F09B3320D@petertodd.org>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256



On 4 December 2014 20:02:17 GMT+00:00, Jeffrey Paul <jp at eeqj.com> wrote:
>
>> On 20141204, at 07:42, Luke Dashjr <luke at dashjr.org> wrote:
>>
>> Is anyone working on a serialisation format to convey P2SH HD chains?
>For
>> example, to give someone who wants to make recurring payments a
>single token
>> that can be used to generate many P2SH addresses paying to a multisig
>script.
>>
>> I'm thinking of something along the lines of a simple series of
>tokens, each
>> indicating either a HD chain or literal script content. For all HD
>chains in
>> the data, a child key would be generated based on the payment number,
>and all
>> tokens concatenated to form the P2SH serialised script. Eg, for a
>simple 2-
>> of-2, you would do something like this:
>>    literal(OP_2) HDChain HDChain literal(OP_2 OP_CHECKMULTISIG)
>> Does this sufficiently cover all reasonable use cases?
>
>
>What is the use case for something like this?  It?s my impression that
>a single token that can be used to obtain many P2SH addresses paying to
>a multisig script looks something like
>
>bitcoin:?r=https://payee.com/customer12345/recurring/paymentrequest/new
>
>As it?s impossible to actually transmit a tx without network access,
>why would it be necessary to, at payment time, not contact the payee
>and use the existing bip70 authenticated payment request protocol to
>find out exactly what multisig address they?d like paid at that moment?

It's quite common to run into situations where the payee is *not* online. Similarly requiring them to be online is a security risk and defeats many ways of authenticating payment addresses. This stuff isn't evident in trivial consumer<->merchant use-cases, but is very common in anything else. For instance, consider the case of moving funds from a hot wallet or cold, and vice-versa.

Luke-Jr: sounds like some of the ideas I've been playing around with for generalised stealth addresses, using a declarative template scheme to avoid specifying scriptPubKey formats too explicitly. (though obcs k-anon set issues)
-----BEGIN PGP SIGNATURE-----
Version: APG v1.1.1

iQFQBAEBCAA6BQJUgMd0MxxQZXRlciBUb2RkIChsb3cgc2VjdXJpdHkga2V5KSA8
cGV0ZUBwZXRlcnRvZGQub3JnPgAKCRAZnIM7qOfwhRJjB/0fvNisFR4cktOhDJYl
nq2gb39aiV7Wufh7NcTI0mqsC1yhIgFW5fgl7TmiK76Tn4gH0rhfJe3u7GhVsmSy
Sx1qEJJN6yNsiu6elmLe8xISVTwHu+kLqKFTyZNrd4BObHVumyLAhea2lFSzZmBu
GQF/AnVzf06vAT8CnZZm3hMgt1kFv32KglIIWLdztvvgi7yK6fi2GlZUW1J+jCUk
6AyQbnpPkHPHIJe7UMM0oeC2w6cN5nH0ccIutwkYDHwo/APa0TkX1hu3bJh5/Cor
zh+BLdOYgAP28wUZ1fkQoAj/0l79+3wyBC7+6lblV90y7C68G6zqMav7lDZdsBK9
4DU0
=Atvv
-----END PGP SIGNATURE-----




From luke at dashjr.org  Thu Dec  4 21:10:14 2014
From: luke at dashjr.org (Luke Dashjr)
Date: Thu, 4 Dec 2014 21:10:14 +0000
Subject: [Bitcoin-development] Serialised P2SH HD chains
In-Reply-To: <F904F6F8-BA2E-4B86-8C6C-B34A88D384BD@eeqj.com>
References: <201412041542.44207.luke@dashjr.org>
	<F904F6F8-BA2E-4B86-8C6C-B34A88D384BD@eeqj.com>
Message-ID: <201412042110.16655.luke@dashjr.org>

On Thursday, December 04, 2014 8:02:17 PM Jeffrey Paul wrote:
> What is the use case for something like this?  It?s my impression that a
> single token that can be used to obtain many P2SH addresses paying to a
> multisig script looks something like
> 
>    bitcoin:?r=https://payee.com/customer12345/recurring/paymentrequest/new

This requires the payee operate a server. My use case is for payment to 
individuals, who may or may not have a computer powered at the time of the 
transactions being sent. Furthermore, the users I am targeting (miners, to be 
specific), wish to remain entirely anonymous, and not hold accounts of any 
sort.

> The model that you describe where a payer can, without communication with
> the payee, generate additional multisig p2sh addresses based on a set of
> xpubs presumes that the payee would never want to e.g. cycle their own
> keys or change their cooperating multisig participants? keys.  Is this
> wise?

This depends on the framework. As of present day, miners are limited to only 
use a single address ever, and cannot change it even to avoid address reuse. 
One goal is to solve that, without breaking multisig.

Luke



From cryptocurrencies at quidecco.de  Mon Dec  8 16:15:14 2014
From: cryptocurrencies at quidecco.de (Isidor Zeuner)
Date: Mon,  8 Dec 2014 17:15:14 +0100 (CET)
Subject: [Bitcoin-development] Deanonymisation of clients in Bitcoin P2P
 network paper
In-Reply-To: <CANEZrP2JLUu9V4HGSLWr1Mg37qmTFVuihTQhJeJ4iyQPxrqsMQ@mail.gmail.com>
References: <CANEZrP2JLUu9V4HGSLWr1Mg37qmTFVuihTQhJeJ4iyQPxrqsMQ@mail.gmail.com>
	<CAJHLa0N6+hpwNECpHUSiKuj4-BYohh=Wr1DP=67Ff8xVBsi8-Q@mail.gmail.com>
	<54760A50.201@riseup.net> <20141127020947.A13D2E19A09@quidecco.de>
	<CAAS2fgRSxBmyDg5R7WgisB-XmhrpGVKHXQpchtL-Ow0xDQAziA@mail.gmail.com>
Message-ID: <20141208161514.6C492E1B59B@quidecco.de>

> >
> > [As an aside I agree that there are lots of things to improve here,
> > but the fact that users can in theory be forced off of tor via DOS
> > attacks is not immediately concerning to me because its a conscious
> > choice users would make to abandon their privacy
>
>
> Bitcoin already has a large population of users who have little or no
> technical skill, it wouldn't surprise me at all if it was found to be the
> clear majority by now. Assuming success and growth in future, very few
> users will make any decisions at all about their privacy, they will just
> accept the defaults. In such a world no consumer wallet is going to
> directly expose Tor to end users - if used at all it'll just be used behind
> the scenes. So automated fallback or control over exits would be a concern
> for such wallets.
>

In order to get more synergy between Bitcoin users of varying skill
levels, my suggestion would be a cleaner separation between technical
mechanisms and policies (possibly suitable for users without technical
skills).

Core development would mean providing suitable mechanisms by which it
is possible to run Bitcoin on different constraints. This may include
ways to handle attacks specific to the Tor/Bitcoin combination.

People who like to research what is possible with the protocol can
then experiment on how these mechanisms can be used in order to
mitigate these attacks.

Finally, distributors of consumer wallets can use this research in
order to distribute their wallet with policies which may be less prone
to Tor-specific attacks. Or leave this out altogether if their
audience has different expectations for connecting to Bitcoin.

The tricky part is probably to figure out what is the greatest common
denominator of what keeps Bitcoin stable and running while still
leaving room for customized policies. But I think that separating
concerns like this is better than letting a debate about how to
mitigate certain Tor-related attacks evolve towards a debate about Tor
or not Tor.

> My gut feeling about this stuff has changed over time. I don't think it'd
> be a great idea to tie Bitcoin to Tor too deeply, convenient though its
> infrastructure is. Most apps don't need a whole lot of onion routing - a
> small amount built in to the p2p layer would be sufficient. Tor is huge,
> complicated and could be a liability in future.
>

I think it would be very interesting to explore alternatives for
Tor. But at this point, completely abandoning Tor would mean that
users either have to agree to have their transactions correlated to
their IP address, or to trust their transactions to a third party
where they are not subject to the security guarantees Bitcoin's
logic can provide anymore. In my opinion, it's a rather huge
sacrifice.

What I find interesting, however, is that a lot of suggestions I see
with respect to attacks related to Tor/Bitcoin (including my own)
involve some kind of extra effort required for Tor users on Bitcoin in
order to protect themselves against these attacks. So, it may be
interesting to explore if it is viable to think of Tor's privacy
guarantees as coming for free. Going from there, if it cannot be
guaranteed to work completely for free, the question would be to what
extent the required extra effort should be a shared effort of the
network, and to what extent users requiring the improved privacy
should use their own resources in order to make it possible.

Best regards,

Isidor



From mike at plan99.net  Mon Dec  8 16:59:06 2014
From: mike at plan99.net (Mike Hearn)
Date: Mon, 8 Dec 2014 17:59:06 +0100
Subject: [Bitcoin-development] Deanonymisation of clients in Bitcoin P2P
 network paper
In-Reply-To: <20141208161514.6C492E1B59B@quidecco.de>
References: <CAJHLa0N6+hpwNECpHUSiKuj4-BYohh=Wr1DP=67Ff8xVBsi8-Q@mail.gmail.com>
	<54760A50.201@riseup.net> <20141127020947.A13D2E19A09@quidecco.de>
	<CAAS2fgRSxBmyDg5R7WgisB-XmhrpGVKHXQpchtL-Ow0xDQAziA@mail.gmail.com>
	<CANEZrP2JLUu9V4HGSLWr1Mg37qmTFVuihTQhJeJ4iyQPxrqsMQ@mail.gmail.com>
	<20141208161514.6C492E1B59B@quidecco.de>
Message-ID: <CANEZrP1Wh_98+47PmmHwSTDoSASw96R+Xnh5qWzROdmxPwO0Gw@mail.gmail.com>

>
> Finally, distributors of consumer wallets can use this research in
> order to distribute their wallet with policies which may be less prone
> to Tor-specific attacks. Or leave this out altogether if their
> audience has different expectations for connecting to Bitcoin.
>

Sure. I guess there will be wallets for all kinds of people in future,
sharing a common core that they can customise (this is certainly the vision
and general direction for bitcoinj, and it's working out OK).

To clarify, my comments above were for mainstream granny-focused wallets.
Wallets designed for crypto geeks can and should expose all the knobs to
let people run wild.

One possible direction to go is to use Tor for writing to the network and
use general link encryption and better Bloom filtering for reading it. Thus
new transactions would pop out of Tor exits, but there isn't much they can
do that's malicious there except mutate them or block them entirely. If you
insert the same transaction into the P2P network via say 10 randomly chosen
exits, the worst a malicious mutator can do is race the real transaction
and that's no different to a malicious P2P node. Even in a world where an
attacker has DoS-banned a lot of nodes and now controls your TX submission
path entirely, it's hard to see how it helps them.

The nice thing about the above approach is that it solves the latency
problems. Startup speed is really an issue for reading from the network:
just syncing the block chain is already enough of a speed hit without
adding consensus sync as well. But if you're syncing the block chain via
the clearnet you can connect to Tor in parallel so that by the time the
user has scanned a QR code, verified the details on the screen and then
pressed the Pay button, you have a warm connection and can upload the TX
through that. It reduces the level of startup time optimisation needed,
although Tor consensus download is still too slow even to race a QR code
scan at the moment. I think tuning the consensus caching process and
switching to a fresh one on the fly might be the way to go.

When BIP70 is in use, you wouldn't write the tx to the network yourself but
you could download the PaymentRequest and upload the Payment message via an
SSLd Tor connection to the merchant. Then malicious exits can only DoS you
but not do anything else so there's no need for multiple exit paths
simultaneously.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141208/02888598/attachment.html>

From sergiolerner at certimix.com  Tue Dec  9 21:14:59 2014
From: sergiolerner at certimix.com (Sergio Lerner)
Date: Tue, 09 Dec 2014 18:14:59 -0300
Subject: [Bitcoin-development] ACK NACK utACK "Concept ACK"
Message-ID: <54876653.4020403@certimix.com>

Is that the full terminology or are there more acronyms?
Is this documented somewhere?

Best regards,
 Sergio.





From bitcoin-list at bluematt.me  Tue Dec  9 21:30:34 2014
From: bitcoin-list at bluematt.me (Matt Corallo)
Date: Tue, 09 Dec 2014 21:30:34 +0000
Subject: [Bitcoin-development] ACK NACK utACK "Concept ACK"
In-Reply-To: <54876653.4020403@certimix.com>
References: <54876653.4020403@certimix.com>
Message-ID: <548769FA.5040406@bluematt.me>

Also utACK ("untested ack") and "tested ack" when people are being explicit.

On 12/09/14 21:14, Sergio Lerner wrote:
> Is that the full terminology or are there more acronyms?
> Is this documented somewhere?
> 
> Best regards,
>  Sergio.
> 
> 
> 
> ------------------------------------------------------------------------------
> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server
> from Actuate! Instantly Supercharge Your Business Reports and Dashboards
> with Interactivity, Sharing, Native Excel Exports, App Integration & more
> Get technology previously reserved for billion-dollar corporations, FREE
> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> 



From laanwj at gmail.com  Wed Dec 10 06:47:53 2014
From: laanwj at gmail.com (Wladimir)
Date: Wed, 10 Dec 2014 06:47:53 +0000
Subject: [Bitcoin-development] ACK NACK utACK "Concept ACK"
In-Reply-To: <548769FA.5040406@bluematt.me>
References: <54876653.4020403@certimix.com>
	<548769FA.5040406@bluematt.me>
Message-ID: <CA+s+GJAe9MeO+Sr0+2BRwu3q-Be5JQt_s_xdnBBEcquXqOyxcA@mail.gmail.com>

Abbreviations:

Concept ACK -> agree with the idea and overall direction, but haven't
reviewed the code changes nor tested it
utACK -> reviewed the code changes, but did not put it through any testing
Tested ACK -> reviewed the code changes and verified the functionality/bug fix

I tend to only use bare "ACK" if there is nothing to test in the first
place, for example for documentation changes.

Wladimir


On Tue, Dec 9, 2014 at 9:30 PM, Matt Corallo <bitcoin-list at bluematt.me> wrote:
> Also utACK ("untested ack") and "tested ack" when people are being explicit.
>
> On 12/09/14 21:14, Sergio Lerner wrote:
>> Is that the full terminology or are there more acronyms?
>> Is this documented somewhere?
>>
>> Best regards,
>>  Sergio.
>>
>>
>>
>> ------------------------------------------------------------------------------
>> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server
>> from Actuate! Instantly Supercharge Your Business Reports and Dashboards
>> with Interactivity, Sharing, Native Excel Exports, App Integration & more
>> Get technology previously reserved for billion-dollar corporations, FREE
>> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>
> ------------------------------------------------------------------------------
> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server
> from Actuate! Instantly Supercharge Your Business Reports and Dashboards
> with Interactivity, Sharing, Native Excel Exports, App Integration & more
> Get technology previously reserved for billion-dollar corporations, FREE
> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development



From tamas at bitsofproof.com  Wed Dec 10 07:35:01 2014
From: tamas at bitsofproof.com (Tamas Blummer)
Date: Wed, 10 Dec 2014 08:35:01 +0100
Subject: [Bitcoin-development] Merged mining a side chain with proof of burn
	on parent chain
In-Reply-To: <CA+s+GJAe9MeO+Sr0+2BRwu3q-Be5JQt_s_xdnBBEcquXqOyxcA@mail.gmail.com>
References: <54876653.4020403@certimix.com> <548769FA.5040406@bluematt.me>
	<CA+s+GJAe9MeO+Sr0+2BRwu3q-Be5JQt_s_xdnBBEcquXqOyxcA@mail.gmail.com>
Message-ID: <417518B4-1E4D-4467-BC87-95C9EAF0C599@bitsofproof.com>


We spend scarce resources external to the digital realm to create Bitcoin. Real world sacrifice is needed to avoid ?nothing at stake?  and sybil attacks. With Bitcoin we now have a scarce resource within the digital realm, so it appeals my intuition to re-use it for sacrifice instead of linking again an external, real world resource. 

In following I outline a new mining algorithm for side chains, that burn Bitcoins to secure them.

The side chain block validity rules would require that a transaction on the Bitcoin block chain provably destroys Bitcoins with an OP_RET output, that contains the hash of the block header of the side chain. To also introduce a lottery, the burn transaction?s hash is required to satisfy some function of the block hash it was included in on the Bitcoin block chain. For example modulo m of the burn transaction hash must match modulo m of the block hash, that is not known in advance.

Those who want to mine the side chain will assemble  side chain block candidates that comply the rules of the side chain, then a Bitcoin transaction burning to the hash of the block candidate and submit it to the Bitcoin network. Should he burn transaction be included into the Bitcoin block chain and the Bitcoin block?s hash satisfy the lottery criteria, then the block candidate can be submitted to extend the side chain.

A side chain block header sequence would be accepted as side chain trunk if a sequence of Bitcoin SPV proofs for burn transactions prove, that linked blocks have the highest cumulative burn, if compared to alternative sequences. 

The Bitcoin miner will include burn transactions because they offer Bitcoin fees. Bitcoin miner can not selectively block side chains since the hashes associated with the burn do not disclose which side chain or other project they are for. Here you have a ?merged mining? that does not need Bitcoin miner support or even consent.

Mining difficulty of the side chain could be adjusted by stepping up the required burn and/or hardening the criteria that links a burn proof transaction with the bitcoin block hash it is included in.

The difficulty to mine with burn would be dynamic and would also imply a floating exchange rate between Bitcoin and the side coin.

Tamas Blummer
Bits of Proof

00000000000000001172380e63346e3e915b52fcbae838ba958948ac9aa85edd
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 496 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141210/190bfea3/attachment.sig>

From laanwj at gmail.com  Wed Dec 10 08:21:00 2014
From: laanwj at gmail.com (Wladimir)
Date: Wed, 10 Dec 2014 08:21:00 +0000
Subject: [Bitcoin-development] ACK NACK utACK "Concept ACK"
In-Reply-To: <CA+s+GJAe9MeO+Sr0+2BRwu3q-Be5JQt_s_xdnBBEcquXqOyxcA@mail.gmail.com>
References: <54876653.4020403@certimix.com> <548769FA.5040406@bluematt.me>
	<CA+s+GJAe9MeO+Sr0+2BRwu3q-Be5JQt_s_xdnBBEcquXqOyxcA@mail.gmail.com>
Message-ID: <CA+s+GJA0BDMaa2+A7QJdz08Ck4PFQcXs2dg22hi5PCMsGu7dqw@mail.gmail.com>

On Wed, Dec 10, 2014 at 6:47 AM, Wladimir <laanwj at gmail.com> wrote:
> Abbreviations:
>
> Concept ACK -> agree with the idea and overall direction, but haven't
> reviewed the code changes nor tested it
> utACK -> reviewed the code changes, but did not put it through any testing
> Tested ACK -> reviewed the code changes and verified the functionality/bug fix

And there is also NACK, that's an aspecific 'I wouldn't like this
merged'. I always explain why in the text.

A document on this would be welcome, as it may look like Martian to
outsiders. That's been brought up many times before, but no one ever
created it.

Wladimir



From patrick at intersango.com  Wed Dec 10 08:30:10 2014
From: patrick at intersango.com (patrick)
Date: Wed, 10 Dec 2014 02:30:10 -0600
Subject: [Bitcoin-development] Merged mining a side chain with proof of
 burn on parent chain
In-Reply-To: <417518B4-1E4D-4467-BC87-95C9EAF0C599@bitsofproof.com>
References: <54876653.4020403@certimix.com>
	<548769FA.5040406@bluematt.me>	<CA+s+GJAe9MeO+Sr0+2BRwu3q-Be5JQt_s_xdnBBEcquXqOyxcA@mail.gmail.com>
	<417518B4-1E4D-4467-BC87-95C9EAF0C599@bitsofproof.com>
Message-ID: <54880492.9060300@intersango.com>

The goal is to have an opportunity cost to breaking the rules.

Proof of Burn is a real cost for following the rules.

On 12/10/2014 01:35 AM, Tamas Blummer wrote:
> We spend scarce resources external to the digital realm to create Bitcoin. Real world sacrifice is needed to avoid ?nothing at stake?  and sybil attacks. With Bitcoin we now have a scarce resource within the digital realm, so it appeals my intuition to re-use it for sacrifice instead of linking again an external, real world resource. 
>
> In following I outline a new mining algorithm for side chains, that burn Bitcoins to secure them.
>
> The side chain block validity rules would require that a transaction on the Bitcoin block chain provably destroys Bitcoins with an OP_RET output, that contains the hash of the block header of the side chain. To also introduce a lottery, the burn transaction?s hash is required to satisfy some function of the block hash it was included in on the Bitcoin block chain. For example modulo m of the burn transaction hash must match modulo m of the block hash, that is not known in advance.
>
> Those who want to mine the side chain will assemble  side chain block candidates that comply the rules of the side chain, then a Bitcoin transaction burning to the hash of the block candidate and submit it to the Bitcoin network. Should he burn transaction be included into the Bitcoin block chain and the Bitcoin block?s hash satisfy the lottery criteria, then the block candidate can be submitted to extend the side chain.
>
> A side chain block header sequence would be accepted as side chain trunk if a sequence of Bitcoin SPV proofs for burn transactions prove, that linked blocks have the highest cumulative burn, if compared to alternative sequences. 
>
> The Bitcoin miner will include burn transactions because they offer Bitcoin fees. Bitcoin miner can not selectively block side chains since the hashes associated with the burn do not disclose which side chain or other project they are for. Here you have a ?merged mining? that does not need Bitcoin miner support or even consent.
>
> Mining difficulty of the side chain could be adjusted by stepping up the required burn and/or hardening the criteria that links a burn proof transaction with the bitcoin block hash it is included in.
>
> The difficulty to mine with burn would be dynamic and would also imply a floating exchange rate between Bitcoin and the side coin.
>
> Tamas Blummer
> Bits of Proof
>
> 00000000000000001172380e63346e3e915b52fcbae838ba958948ac9aa85edd
>
>
> ------------------------------------------------------------------------------
> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server
> from Actuate! Instantly Supercharge Your Business Reports and Dashboards
> with Interactivity, Sharing, Native Excel Exports, App Integration & more
> Get technology previously reserved for billion-dollar corporations, FREE
> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk
>
>
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141210/ed5fdc7d/attachment.html>

From austin.walne at gmail.com  Wed Dec 10 15:45:49 2014
From: austin.walne at gmail.com (Austin Walne)
Date: Wed, 10 Dec 2014 07:45:49 -0800
Subject: [Bitcoin-development] ACK NACK utACK "Concept ACK"
In-Reply-To: <CA+s+GJA0BDMaa2+A7QJdz08Ck4PFQcXs2dg22hi5PCMsGu7dqw@mail.gmail.com>
References: <54876653.4020403@certimix.com> <548769FA.5040406@bluematt.me>
	<CA+s+GJAe9MeO+Sr0+2BRwu3q-Be5JQt_s_xdnBBEcquXqOyxcA@mail.gmail.com>
	<CA+s+GJA0BDMaa2+A7QJdz08Ck4PFQcXs2dg22hi5PCMsGu7dqw@mail.gmail.com>
Message-ID: <48E6B6DA-F977-409C-AEDD-53572986438D@gmail.com>

I've had these same questions myself. I'm happy to write up some documentation this afternoon. I can draft something based on this thread. What other key terminology should be included?

> On Dec 10, 2014, at 00:21, Wladimir <laanwj at gmail.com> wrote:
> 
>> On Wed, Dec 10, 2014 at 6:47 AM, Wladimir <laanwj at gmail.com> wrote:
>> Abbreviations:
>> 
>> Concept ACK -> agree with the idea and overall direction, but haven't
>> reviewed the code changes nor tested it
>> utACK -> reviewed the code changes, but did not put it through any testing
>> Tested ACK -> reviewed the code changes and verified the functionality/bug fix
> 
> And there is also NACK, that's an aspecific 'I wouldn't like this
> merged'. I always explain why in the text.
> 
> A document on this would be welcome, as it may look like Martian to
> outsiders. That's been brought up many times before, but no one ever
> created it.
> 
> Wladimir
> 
> ------------------------------------------------------------------------------
> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server
> from Actuate! Instantly Supercharge Your Business Reports and Dashboards
> with Interactivity, Sharing, Native Excel Exports, App Integration & more
> Get technology previously reserved for billion-dollar corporations, FREE
> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development



From jgarzik at bitpay.com  Wed Dec 10 15:52:59 2014
From: jgarzik at bitpay.com (Jeff Garzik)
Date: Wed, 10 Dec 2014 10:52:59 -0500
Subject: [Bitcoin-development] ACK NACK utACK "Concept ACK"
In-Reply-To: <CA+s+GJAe9MeO+Sr0+2BRwu3q-Be5JQt_s_xdnBBEcquXqOyxcA@mail.gmail.com>
References: <54876653.4020403@certimix.com> <548769FA.5040406@bluematt.me>
	<CA+s+GJAe9MeO+Sr0+2BRwu3q-Be5JQt_s_xdnBBEcquXqOyxcA@mail.gmail.com>
Message-ID: <CAJHLa0NtJqwPOFYYSkvrJZo+YwiJ6fzvmPY7wcP0GX0FN3E6CQ@mail.gmail.com>

On Wed, Dec 10, 2014 at 1:47 AM, Wladimir <laanwj at gmail.com> wrote:

> Concept ACK -> agree with the idea and overall direction, but haven't
> reviewed the code changes nor tested it
>

Concept ACK -> like the idea; the code may need rewriting (or haven't
reviewed).

-- 
Jeff Garzik
Bitcoin core developer and open source evangelist
BitPay, Inc.      https://bitpay.com/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141210/18685b0f/attachment.html>

From docilio at gmail.com  Wed Dec 10 17:07:38 2014
From: docilio at gmail.com (Tiago Docilio Caldeira)
Date: Wed, 10 Dec 2014 21:07:38 +0400
Subject: [Bitcoin-development] BitCoin TPB, P2P Currency/Torrent
Message-ID: <CAJEcgC71k7vu8b6yz5bn0OTVniFe5QWiNRr06Jn2JS9rJSCRxw@mail.gmail.com>

Dear All,

I've been trying to better understand the bitcoin in the last few months,
both in the mathematical as the programming point of view. I went through
part of the documentation, and I got curious to find ways to use their data
package to store some useful msg.

As most of you know, one of the freedom parts of the internet was
(temporary) knock out yesterday, the PirateBay, a "service" that was built
in open source and the freedom to share, so I start trying to design an
idea to allow us to create the future of p2p transference, using bitcoin as
a currency and data provider.

If you insert similar message that a torrent has inside of a bitcoin
portion (for example, in a satochi), you could not only "tip" the person
who would share the content (eventually, even the producer of it), but
also, make a public (but anonymous) request of a certain content.

By doing this micro transference, you would receive an entry to a content
torrent information.

What is your opinion about this? Would someone (with more pratice inside
bitcoin algorithms) be interested in developing some front end with me?

Hope that you like the idea, and share the vision of a open content world,
with fair return for the people who shares the data.

Best Regards,

Tiago Caldeira
bitcoin: 1BTdPcpLfpLVouDh32532SqCXibAjXoRqp
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141210/321b6dde/attachment.html>

From parazyd1 at gmail.com  Wed Dec 10 17:18:31 2014
From: parazyd1 at gmail.com (Parazyd)
Date: Wed, 10 Dec 2014 18:18:31 +0100
Subject: [Bitcoin-development] BitCoin TPB, P2P Currency/Torrent
In-Reply-To: <CAJEcgC71k7vu8b6yz5bn0OTVniFe5QWiNRr06Jn2JS9rJSCRxw@mail.gmail.com>
References: <CAJEcgC71k7vu8b6yz5bn0OTVniFe5QWiNRr06Jn2JS9rJSCRxw@mail.gmail.com>
Message-ID: <54888067.7090000@gmail.com>

What came to my mind today, is, implementing a blockchain as a tracker. 
Nothing to do with Bitcoin as such, but with the blockchain 
platform/technology.
I thought about making the blockchain contain all the magnet links and 
developing it independently. But that's another story and I think it has 
no place in this mailing list.
Also, you do realize that the majority of The Pirate Bay's content is 
illegal and shouldn't be discussed here.

You talk about open source, and yet you insist on people doing spam 
transactions in order to access certain content? That's a no-no.

On 12/10/2014 06:07 PM, Tiago Docilio Caldeira wrote:
> Dear All,
>
> I've been trying to better understand the bitcoin in the last few 
> months, both in the mathematical as the programming point of view. I 
> went through part of the documentation, and I got curious to find ways 
> to use their data package to store some useful msg.
>
> As most of you know, one of the freedom parts of the internet was 
> (temporary) knock out yesterday, the PirateBay, a "service" that was 
> built in open source and the freedom to share, so I start trying to 
> design an idea to allow us to create the future of p2p transference, 
> using bitcoin as a currency and data provider.
>
> If you insert similar message that a torrent has inside of a bitcoin 
> portion (for example, in a satochi), you could not only "tip" the 
> person who would share the content (eventually, even the producer of 
> it), but also, make a public (but anonymous) request of a certain content.
>
> By doing this micro transference, you would receive an entry to a 
> content torrent information.
>
> What is your opinion about this? Would someone (with more pratice 
> inside bitcoin algorithms) be interested in developing some front end 
> with me?
>
> Hope that you like the idea, and share the vision of a open content 
> world, with fair return for the people who shares the data.
>
> Best Regards,
>
> Tiago Caldeira
> bitcoin: 1BTdPcpLfpLVouDh32532SqCXibAjXoRqp
>
>
>
> ------------------------------------------------------------------------------
> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server
> from Actuate! Instantly Supercharge Your Business Reports and Dashboards
> with Interactivity, Sharing, Native Excel Exports, App Integration & more
> Get technology previously reserved for billion-dollar corporations, FREE
> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk
>
>
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141210/78c19b09/attachment.html>

From cryptocurrencies at quidecco.de  Thu Dec 11 11:51:18 2014
From: cryptocurrencies at quidecco.de (Isidor Zeuner)
Date: Thu, 11 Dec 2014 12:51:18 +0100 (CET)
Subject: [Bitcoin-development] Deanonymisation of clients in Bitcoin P2P
 network paper
In-Reply-To: <CAAS2fgRPZ5yrHYrdG8fEZQi92J-DVY_fZNFc8wnt81Pvx_mLNQ@mail.gmail.com>
References: <CAAS2fgRPZ5yrHYrdG8fEZQi92J-DVY_fZNFc8wnt81Pvx_mLNQ@mail.gmail.com>
	<CABssiCpUE=3GhC+Scd3htzVb9+gmLeZ0mEO5LY-zxywvguZ--w@mail.gmail.com>
Message-ID: <20141211115118.C2587E22B8D@quidecco.de>

[...]
> And, on the flip side if the host is persistently behind tor, even
> with some watermarkable behaviour, their privacy is protected.  So
> making sure that hosts can continually use tor (or similar systems)
> should be the higher priority.  (And, of course, not reimplementing
> tor  leverages the millions of dollars of investment and dozens of
> subject matter experts working on that system).
>

Reimplementing Tor would not only mean to lose all the investment that
ran into Tor, but also to lose a large user base. We can see this with
TorCoin. Still, the fact that Bitcoin is a use case for Tor which
measurably shows some limits where it is not fully clear if Tor or
Bitcoin is to be blamed does not only mean that both projects may
have to evolve in order to properly solve the issue, but also that the
means of interfacing between both projects may have to be
extended. Ideally, in a way which does not require to run a separate
Tor and/or Bitcoin network in order to work, but which will be generic
enough to satisfy both sides' need to still work in a standalone
manner.

But I do see huge merit in exploring better ways of synergy between
the projects. For example, Tor's hardcoded circuit length may be
considered as a hack which was only necessary due to the lack of a
suitable resource compensation mechanism. Which is something that is
available with Bitcoin.

Best regards,

Isidor



From cryptocurrencies at quidecco.de  Thu Dec 11 12:09:16 2014
From: cryptocurrencies at quidecco.de (Isidor Zeuner)
Date: Thu, 11 Dec 2014 13:09:16 +0100 (CET)
Subject: [Bitcoin-development] Merged mining a side chain with proof of
	burn	on parent chain
In-Reply-To: <417518B4-1E4D-4467-BC87-95C9EAF0C599@bitsofproof.com>
References: <417518B4-1E4D-4467-BC87-95C9EAF0C599@bitsofproof.com>
	<CA+s+GJAe9MeO+Sr0+2BRwu3q-Be5JQt_s_xdnBBEcquXqOyxcA@mail.gmail.com>
Message-ID: <20141211120916.E912EE22B92@quidecco.de>

[...]
> The Bitcoin miner will include burn transactions because they offer
> Bitcoin fees. Bitcoin miner can not selectively block side chains
> since the hashes associated with the burn do not disclose which side
> chain or other project they are for. Here you have a ?merged
> mining? that does not need Bitcoin miner support or even consent.
>

Miners might decide to block all burn transactions, and other nodes
might decide to stop relaying them. This may be considered as
preferable by all participants who do not want to add more potential
for deflation.

Best regards,

Isidor



From tamas at bitsofproof.com  Thu Dec 11 14:56:24 2014
From: tamas at bitsofproof.com (Tamas Blummer)
Date: Thu, 11 Dec 2014 15:56:24 +0100
Subject: [Bitcoin-development] Merged mining a side chain with proof of
	burn	on parent chain
In-Reply-To: <20141211120916.E912EE22B92@quidecco.de>
References: <417518B4-1E4D-4467-BC87-95C9EAF0C599@bitsofproof.com>
	<CA+s+GJAe9MeO+Sr0+2BRwu3q-Be5JQt_s_xdnBBEcquXqOyxcA@mail.gmail.com>
	<20141211120916.E912EE22B92@quidecco.de>
Message-ID: <B8D7AE7E-567E-4656-9231-17EEAD6ED603@bitsofproof.com>

Isodor: Rational Miner will include burn transaction for fee, no doubt. Censoring transactions is against Bitcoin?s core values, unlikely to get wide support for any form of that.

Patrick: Mining is at cost even if following the rules. No change to that.

Tamas Blummer
Bits of Proof
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141211/8b7cc2e1/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 496 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141211/8b7cc2e1/attachment.sig>

From pete at petertodd.org  Fri Dec 12 09:05:51 2014
From: pete at petertodd.org (Peter Todd)
Date: Fri, 12 Dec 2014 09:05:51 +0000
Subject: [Bitcoin-development] Setting the record straight on
	Proof-of-Publication
Message-ID: <20141212090551.GA8259@muck>

Introduction
============

While not a new concept proof-of-publication is receiving a significant
amount of attention right now both as an idea, with regard to the
embedded consensus systems that make use of it, and in regard to the
sidechains model proposed by Blockstream that rejects it. Here we give a
clear definition of proof-of-publication and its weaker predecessor
timestamping, describe some usecases for it, and finally dispel some of
the common myths about it.


What is timestamping?
=====================

A cryptographic timestamp proves that message m existed prior to some
time t.

This is the cryptographic equivalent of mailing yourself a patentable
idea in a sealed envelope to establish the date at which the idea
existed on paper.

Traditionally this has been done with one or more trusted third parties
who attest to the fact that they saw m prior to the time t. More
recently blockchains have been used for this purpose, particularly the
Bitcoin blockchain, as block headers include a block time which is
verified by the consensus algorithm.


What is proof-of-publication?
=============================

Proof-of-publication is what solves the double-spend problem.

Cryptographic proof-of-publication actually refers to a few closely
related proofs, and practical uses of it will generally make use of more
than one proof.


Proof-of-receipt
----------------

Prove that every member p in of audience P has received message m. A
real world analogy is a legal notice being published in a major
newspaper - we can assume any subscriber received the message and had a
chance to read it.


Proof-of-non-publication
------------------------

Prove that message m has *not* been published. Extending the above real
world analogy the court can easily determine that a legal notice was not
published when it should have been by examining newspaper archives. (or
equally, *because* the notice had not been published, some action a
litigant had taken was permissable)


Proof-of-membership
-------------------

A proof-of-non-publication isn't very useful if you can't prove that
some member q is in the audience P. In particular, if you are to
evaluate a proof-of-membership, q is yourself, and you want assurance
you are in that audience. In the case of our newspaper analogy because
we know what today's date is, and we trust the newspaper never to
publish two different editions with the same date we can be certain we
have searched all possible issues where the legal notice may have been
published.


Real-world proof-of-publication: The Torrens Title System
---------------------------------------------------------

Land titles are a real-world example, dating back centuries, with
remarkable simularities to the Bitcoin blockchain. Prior to the torrens
system land was transferred between owners through a chain of valid
title deeds going back to some "genesis" event establishing rightful
ownership independently of prior history. As with the blockchain the
title deed system has two main problems: establishing that each title
deed in the chain is valid in isolation, and establishing that no other
valid title deeds exist. While the analogy isn't exact - establishing
the validity of title deeds isn't as crisp a process as simple checking
a cryptographic signature - these two basic problems are closely related
to the actions of checking a transaction's signatures in isolation, and
ensuring it hasn't been double-spent.

To solve these problems the Torrens title system was developed, first in
Australia and later Canada, to establish a singular central registry of
deeds, or property transfers. Simplifying a bit we can say inclusion -
publication - in the official registery is a necessary pre-condition to
a given property transfer being valid. Multiple competing transfers are
made obvious, and the true valid transfer can be determined by whichever
transfer happened first.

Similarly in places where the Torrens title system has not been adopted,
almost always a small number of title insurance providers have taken on
the same role. The title insurance provider maintains a database of all
known title deeds, and in practice if a given title deed isn't published
in the database it's not considered valid.


Common myths
============

Proof-of-publication is the same as timestamping
------------------------------------------------

No. Timestamping is a significantly weaker primitive than
proof-of-publication. This myth seems to persist because unfortunately
many members of the Bitcoin development and theory community - and even
members of the Blockstream project - have frequently used the term
"timestamping" for applications that need proof-of-publication.


Publication means publishing meaningful data to the whole world
---------------------------------------------------------------

No. The data to be published can often be an otherwise meaningless
nonce, indistinguishable from any other random value. (e.g. an ECC
pubkey)

For example colored coins can be implemented by committing the hash of
the map of colored inputs to outputs inside a transaction. These maps
can be passed from payee to payor to prove that a given output is
colored with a set of recursive proofs, as is done in the author's
Smartcolors library. The commitment itself can be a simple hash, or even
a pay-to-contract style derived pubkey.

A second example is Zerocash, which depends on global consensus of a set
of revealed serial numbers. As this set can include "false-positives" -
false revealed serial numbers that do not actually correspond to a real
Zerocash transaction - the blockchain itself can be that set. The
Zerocash transactions themselves - and associated proofs - can then be
passed around via a p2p network separate from the blockchain itself.
Each Zerocash Pour proof then simply needs to specify what set of
priorly evaluated proofs makes up its particular commitment merkle tree
and the proofs are then evaluated against that proof-specific tree. (in
practice likely some kind of DAG-like structure) (note that there is a
sybil attack risk here: a sybil attack reduces your k-anonymity set by
the number of transactions you were prevented from seeing; a weaker
proof-of-publication mechanism may be appropriate to prevent that sybil
attack).

The published data may also not be meaningful because it is encrypted.
Only a small community may need to come to consensus about it; everyone
else can ignore it. For instance proof-of-publication for decentralized
asset exchange is an application where you need publication to be
timely, however the audience may still be small. That audience can share
an encryption key.


Proof-of-publication is always easy to censor
---------------------------------------------

No, with some precautions. This myth is closely related to the above
idea that the data must be globally meaningful to be useful. The colored
coin and Zerocash examples above are cases where censoring the
publication is obviously impossible as it can be made prior to giving
anyone at all sufficient info to determine if the publicaiton has been
made; the data itself is just nonces.

In the case of encrypted data the encryption key can also often be
revealed well after the publication has been made. For instance in a
Certificate Transparency scheme the certificate authority (CA) may use
proof-of-publication to prove that a certificate was in a set of
certificates. If that set of certificates is hashed into a merkelized
binary prefix tree indexed by domain name the correct certificate for a
given domain name - or lack thereof - is easily proven. Changes to that
set can be published on the blockchain by publishing successive prefix
tree commitments.

If these commitments are encrypted, each commitment C_i can also commit
to the encryption key to be used for C_{i+1}. That key need not be
revealed until the commitment is published; validitity is assured as
every client knows that only one C_{i+1} is possible, so any malfeasance
is guaranteed to be revealed when C_{i+2} is published.

Secondly the published data can be timelock encrypted with timelocks
that take more than the average block interval to decrypt. This puts
would-be censoring miners into a position of either delaying all
transactions, or accepting that they will end up mining publication
proofs. The only way to circumvent this is highly restrictive
whitelisting.


Proof-of-publication is easier to censor than (merge)-mined sidechains
----------------------------------------------------------------------

False under all circumstances. Even if the publications use no
anti-censorship techniques to succesfully censor a proof-of-publication
system at least 51% of the total hashing power must decide to censor it,
and they must do so by attacking the other 49% of hashing power -
specifically rejecting their blocks. This is true no matter how "niche"
the proof-of-publication system is - whether it is used by two people or
two million people it has the same security.

On the other hand a (merge)-mined sidechain with x% of the total hashing
power supporting it can be attacked at by anyone with >x% hashing power.
In the case of a merge-mined sidechain this cost will often be near zero
- only by providing miners with a significant and ongoing reward can the
marginal cost be made high. In the case of sidechains with niche
audiences this is particularly true - sidechain advocates have often
advocated that sidechains be initially protected by centralized
checkpoints until they become popular enough to begin to be secure.

Secondly sidechains can't make use of anti-censorship techniques the way
proof-of-publication systems can: they inherently must be public for
miners to be able to mine them in a decentralized fashion. Of course,
users of them may use anti-censorship techniques, but that leads to a
simple security-vs-cost tradeoff between using the Bitcoin blockchain
and a sidechain. (note the simularity to the author's treechains
proposal!)


Proof-of-publication can be made expensive
------------------------------------------

True, in some cases! By tightly constraining the Bitcoin scripting
system the available bytes for stenographic embedment can be reduced.
For instance P2SH^2 requires an brute force exponentially increasing
amount of hashes-per-byte-per-pushdata. However this is still
ineffective against publishing hashes, and to fully implement it -
scriptSigs included - would require highly invasive changes to the
entire scripting system that would greatly limit its value.


Proof-of-publication can be outsourced to untrusted third-parties
-----------------------------------------------------------------

Timestamping yes, but proof-of-publication no.

We're talking about systems that attempt to publish multiple pieces of
data from multiple parties with a single hash in the Bitcoin blockchain,
such as Factom.  Essentially this works by having a "child" blockchain,
and the hash of that child blockchain is published in the master Bitcoin
blockchain. To prove publicaiton you prove that your message is in that
child chain, and the child chain is itself published in the Bitcoin
blockchain.  Proving membership is possible for yourself by determining
if you have the contents corresponding to the most recent child-chain
hash.

The problem is proving non-publication. The set of all *potential*
child-chain hashes must be possible to obtain by scanning the Bitcoin
blockchain. As a hash is meaningless by itself, these hashes must be
signed. That introduces a trusted third-party who can also sign an
invalid hash that does not correspond to a block and publish it in the
blockchain. This in turn makes it impossible for anyone using the child
blockchain to prove non-publication - they can't prove they did not
publish a message because the content of *all* child blockchains is now
unknown.

In short, Factom and systems like it rely on trusted third parties who
can put you in a position where you can't prove you did not commit
fraud.


Proof-of-publication "bloats" the blockchain
--------------------------------------------

Depends on your perspective.

Systems that do not make use of the UTXO are no different technically
than any other transaction: they pay fees to publish messages to the
Bitcoin blockchain with no amortized increase in the UTXO set. Some
systems do grow the UTXO set - a potential scaling problem as currently
that all full nodes must have the entire UTXO set - although there are a
number of existing mechanisms and proposals to mitigate this issue such
as the (crippled) OP_RETURN scriptPubKey format, the dust rule, the
authors TXO commitments, UTXO expiry etc.

From an economic point of view proof-of-publication systems compete with
other uses of the blockchain as they pay fees; supply of blockchain
space is fixed so the increased demand must result in a higher
per-transaction price in fees. On the other hand this is true of *all*
uses of the blockchain, which collectively share the limited transaction
capacity. For instance Satoshidice and similar sites have been widely
condemned for doing conventional transactions on Bitcoin when they could
have potentially used off-chain transactions.

It's unknown what the effect on the Bitcoin price will actually be. Some
proof-of-publication uses have nothing to do with money at all - e.g.
certificate transparency. Others are only indirectly related, such as
securing financial audit logs such as merkle-sum-trees of total Bitcoins
held by exchanges. Others in effect add new features to Bitcoin, such as
how colored coins allows the trade of assets on the blockchain, or how
Zerocash makes Bitcoin transactions anonymous. The sum total of all
these effects on the Bitcoin price is difficult to predict.

The authors belief is that even if proof-of-publication is a
net-negative to Bitcoin as it is significantly more secure than the
alternatives and can't be effectively censored people will use it
regardless of effects to discourage them through social pressure. Thus
Bitcoin must make technical improvements to scalability that negate
these potentially harmful effects.


Proof-of-publication systems are inefficient
--------------------------------------------

If you're talking about inefficient from the perspective of a full-node
that does full validation, they are no different than (merge)-mined
sidechain and altcoin alternatives. If you're talking about efficiency
from the perspective of a SPV client, then yes, proof-of-publication
systems will often require more resources than mining-based
alternatives.

However it must be remembered that the cost of mining is the
introduction of a trusted third party - miners. Of course, mined
proof-of-publication has miners already, but trusting those miners to
determine the meaning of that data places significantly more trust in
them than mearly trusting them to create consensus on the order in which
data is published.

Many usecases involve trusted third-parties anyway - the role of
proof-of-publication is to hold those third-parties to account and keep
them honest. For these use-cases - certificate transparency, audit logs,
financial assets - mined alternatives simply add new trusted third
parties and points of failure rather than remove them.

Of course, global consensus is inefficient - Bitcoin itself is
inefficient. But this is a fundemental problem to Bitcoin's architecture
that applies to all uses of it, a problem that should be solved in
general.


Proof-of-publication needs "scamcoins" like Mastercoin and Counterparty
-----------------------------------------------------------------------

First of all, whether or not a limited-supply token is a "scam" is not a
technical question. However some types of embedded consensus systems, a
specific use-case for proof-of-publication, do require limited-supply
tokens within the system for technical reasons, for instance to support
bid orders functionality in decentralized marketplaces.

Secondly using a limited-supply token in a proof-of-publicaton system is
what lets you have secure client side validation rather than the
alternative of 2-way-pegging that requires users to trust miners not to
steal the pegged funds. Tokens also do not need to be, economically
speaking, assets that can appreciate in value relative to Bitcoin;
one-way-pegs where Bitcoins can always be turned into the token in
conjunction with decentralized exchange to buy and sell tokens for
Bitcoins ensure the token value will always closely approximate the
Bitcoin value as long as the protocol itself is considered valuable.

Finally only a subset of proof-of-publication use-cases involve tokens
at all - many like colored coins transact directly to and from Bitcoin,
while other use-cases don't even involve finance at all.

-- 
'peter'[:-1]@petertodd.org
00000000000000000681f4e5c84bc0bf7e6c5db8673eef225da652fbb785a0de
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 455 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141212/444476e8/attachment.sig>

From gacrux at gmail.com  Fri Dec 12 12:25:53 2014
From: gacrux at gmail.com (Gareth Williams)
Date: Fri, 12 Dec 2014 23:25:53 +1100
Subject: [Bitcoin-development] Setting the record straight on
	Proof-of-Publication
In-Reply-To: <20141212090551.GA8259@muck>
References: <20141212090551.GA8259@muck>
Message-ID: <548ADED1.6060300@gmail.com>

On 12/12/14 20:05, Peter Todd wrote:
> Secondly using a limited-supply token in a proof-of-publicaton system is
> what lets you have secure client side validation rather than the
> alternative of 2-way-pegging that requires users to trust miners not to
> steal the pegged funds. 

"Secure" and "client side validation" don't really belong in the same
sentence, do they?

If I am to accept a transaction with any assurance of security at all,
the important question to ask is not: "does my client consider this
valid?" but: "does the rest of the world consider this valid?"

Validated data in the blockchain is far more useful for this purpose
than unvalidated data with a mere proof of publication in the
blockchain, precisely because it records what /everybody else/ considers
valid history (and very likely will continue to consider valid history
in future.)

Pegged sidechains have their challenges, but at least they provide
distributed consensus on transaction history.

Proof-of-publication systems like Counterparty and Mastercoin require me
to trust, with zero evidence, that everybody else's client has the exact
same interpretation of transaction history as mine, and will continue to
have for the indefinite future. How is that not a horribly broken
security model? I'd use a sidechain - with reasonable parameters that
disincentivise peg theft as much as practical - over that any day.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141212/e4a2e4e2/attachment.sig>

From odinn.cyberguerrilla at riseup.net  Fri Dec 12 13:41:34 2014
From: odinn.cyberguerrilla at riseup.net (odinn)
Date: Fri, 12 Dec 2014 13:41:34 +0000
Subject: [Bitcoin-development] Setting the record straight on
	Proof-of-Publication
In-Reply-To: <20141212090551.GA8259@muck>
References: <20141212090551.GA8259@muck>
Message-ID: <548AF08E.6080408@riseup.net>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

Peter... It kind of sounds to me that (as fine of a position paper as
this is) on _certain_ points, you're falling prey to the "but it's
inefficient, but it's a scamcoin, but luke-jr told me so" argument...

I think the Mastercoin devs are doing fine work and I consider the
zerocash devs to have developed (in v2, mint and pour) to have
developed something that will really turn the world on its ear, but
what do I know? Nothing.  Nothing at all.

gmorning

Peter Todd:
> Introduction ============
> 
> While not a new concept proof-of-publication is receiving a
> significant amount of attention right now both as an idea, with
> regard to the embedded consensus systems that make use of it, and
> in regard to the sidechains model proposed by Blockstream that
> rejects it. Here we give a clear definition of proof-of-publication
> and its weaker predecessor timestamping, describe some usecases for
> it, and finally dispel some of the common myths about it.
> 
> 
> What is timestamping? =====================
> 
> A cryptographic timestamp proves that message m existed prior to
> some time t.
> 
> This is the cryptographic equivalent of mailing yourself a
> patentable idea in a sealed envelope to establish the date at which
> the idea existed on paper.
> 
> Traditionally this has been done with one or more trusted third
> parties who attest to the fact that they saw m prior to the time t.
> More recently blockchains have been used for this purpose,
> particularly the Bitcoin blockchain, as block headers include a
> block time which is verified by the consensus algorithm.
> 
> 
> What is proof-of-publication? =============================
> 
> Proof-of-publication is what solves the double-spend problem.
> 
> Cryptographic proof-of-publication actually refers to a few
> closely related proofs, and practical uses of it will generally
> make use of more than one proof.
> 
> 
> Proof-of-receipt ----------------
> 
> Prove that every member p in of audience P has received message m.
> A real world analogy is a legal notice being published in a major 
> newspaper - we can assume any subscriber received the message and
> had a chance to read it.
> 
> 
> Proof-of-non-publication ------------------------
> 
> Prove that message m has *not* been published. Extending the above
> real world analogy the court can easily determine that a legal
> notice was not published when it should have been by examining
> newspaper archives. (or equally, *because* the notice had not been
> published, some action a litigant had taken was permissable)
> 
> 
> Proof-of-membership -------------------
> 
> A proof-of-non-publication isn't very useful if you can't prove
> that some member q is in the audience P. In particular, if you are
> to evaluate a proof-of-membership, q is yourself, and you want
> assurance you are in that audience. In the case of our newspaper
> analogy because we know what today's date is, and we trust the
> newspaper never to publish two different editions with the same
> date we can be certain we have searched all possible issues where
> the legal notice may have been published.
> 
> 
> Real-world proof-of-publication: The Torrens Title System 
> ---------------------------------------------------------
> 
> Land titles are a real-world example, dating back centuries, with 
> remarkable simularities to the Bitcoin blockchain. Prior to the
> torrens system land was transferred between owners through a chain
> of valid title deeds going back to some "genesis" event
> establishing rightful ownership independently of prior history. As
> with the blockchain the title deed system has two main problems:
> establishing that each title deed in the chain is valid in
> isolation, and establishing that no other valid title deeds exist.
> While the analogy isn't exact - establishing the validity of title
> deeds isn't as crisp a process as simple checking a cryptographic
> signature - these two basic problems are closely related to the
> actions of checking a transaction's signatures in isolation, and 
> ensuring it hasn't been double-spent.
> 
> To solve these problems the Torrens title system was developed,
> first in Australia and later Canada, to establish a singular
> central registry of deeds, or property transfers. Simplifying a bit
> we can say inclusion - publication - in the official registery is a
> necessary pre-condition to a given property transfer being valid.
> Multiple competing transfers are made obvious, and the true valid
> transfer can be determined by whichever transfer happened first.
> 
> Similarly in places where the Torrens title system has not been
> adopted, almost always a small number of title insurance providers
> have taken on the same role. The title insurance provider maintains
> a database of all known title deeds, and in practice if a given
> title deed isn't published in the database it's not considered
> valid.
> 
> 
> Common myths ============
> 
> Proof-of-publication is the same as timestamping 
> ------------------------------------------------
> 
> No. Timestamping is a significantly weaker primitive than 
> proof-of-publication. This myth seems to persist because
> unfortunately many members of the Bitcoin development and theory
> community - and even members of the Blockstream project - have
> frequently used the term "timestamping" for applications that need
> proof-of-publication.
> 
> 
> Publication means publishing meaningful data to the whole world 
> ---------------------------------------------------------------
> 
> No. The data to be published can often be an otherwise meaningless 
> nonce, indistinguishable from any other random value. (e.g. an ECC 
> pubkey)
> 
> For example colored coins can be implemented by committing the hash
> of the map of colored inputs to outputs inside a transaction. These
> maps can be passed from payee to payor to prove that a given output
> is colored with a set of recursive proofs, as is done in the
> author's Smartcolors library. The commitment itself can be a simple
> hash, or even a pay-to-contract style derived pubkey.
> 
> A second example is Zerocash, which depends on global consensus of
> a set of revealed serial numbers. As this set can include
> "false-positives" - false revealed serial numbers that do not
> actually correspond to a real Zerocash transaction - the blockchain
> itself can be that set. The Zerocash transactions themselves - and
> associated proofs - can then be passed around via a p2p network
> separate from the blockchain itself. Each Zerocash Pour proof then
> simply needs to specify what set of priorly evaluated proofs makes
> up its particular commitment merkle tree and the proofs are then
> evaluated against that proof-specific tree. (in practice likely
> some kind of DAG-like structure) (note that there is a sybil attack
> risk here: a sybil attack reduces your k-anonymity set by the
> number of transactions you were prevented from seeing; a weaker 
> proof-of-publication mechanism may be appropriate to prevent that
> sybil attack).
> 
> The published data may also not be meaningful because it is
> encrypted. Only a small community may need to come to consensus
> about it; everyone else can ignore it. For instance
> proof-of-publication for decentralized asset exchange is an
> application where you need publication to be timely, however the
> audience may still be small. That audience can share an encryption
> key.
> 
> 
> Proof-of-publication is always easy to censor 
> ---------------------------------------------
> 
> No, with some precautions. This myth is closely related to the
> above idea that the data must be globally meaningful to be useful.
> The colored coin and Zerocash examples above are cases where
> censoring the publication is obviously impossible as it can be made
> prior to giving anyone at all sufficient info to determine if the
> publicaiton has been made; the data itself is just nonces.
> 
> In the case of encrypted data the encryption key can also often be 
> revealed well after the publication has been made. For instance in
> a Certificate Transparency scheme the certificate authority (CA)
> may use proof-of-publication to prove that a certificate was in a
> set of certificates. If that set of certificates is hashed into a
> merkelized binary prefix tree indexed by domain name the correct
> certificate for a given domain name - or lack thereof - is easily
> proven. Changes to that set can be published on the blockchain by
> publishing successive prefix tree commitments.
> 
> If these commitments are encrypted, each commitment C_i can also
> commit to the encryption key to be used for C_{i+1}. That key need
> not be revealed until the commitment is published; validitity is
> assured as every client knows that only one C_{i+1} is possible, so
> any malfeasance is guaranteed to be revealed when C_{i+2} is
> published.
> 
> Secondly the published data can be timelock encrypted with
> timelocks that take more than the average block interval to
> decrypt. This puts would-be censoring miners into a position of
> either delaying all transactions, or accepting that they will end
> up mining publication proofs. The only way to circumvent this is
> highly restrictive whitelisting.
> 
> 
> Proof-of-publication is easier to censor than (merge)-mined
> sidechains 
> ----------------------------------------------------------------------
>
>  False under all circumstances. Even if the publications use no 
> anti-censorship techniques to succesfully censor a
> proof-of-publication system at least 51% of the total hashing power
> must decide to censor it, and they must do so by attacking the
> other 49% of hashing power - specifically rejecting their blocks.
> This is true no matter how "niche" the proof-of-publication system
> is - whether it is used by two people or two million people it has
> the same security.
> 
> On the other hand a (merge)-mined sidechain with x% of the total
> hashing power supporting it can be attacked at by anyone with >x%
> hashing power. In the case of a merge-mined sidechain this cost
> will often be near zero - only by providing miners with a
> significant and ongoing reward can the marginal cost be made high.
> In the case of sidechains with niche audiences this is particularly
> true - sidechain advocates have often advocated that sidechains be
> initially protected by centralized checkpoints until they become
> popular enough to begin to be secure.
> 
> Secondly sidechains can't make use of anti-censorship techniques
> the way proof-of-publication systems can: they inherently must be
> public for miners to be able to mine them in a decentralized
> fashion. Of course, users of them may use anti-censorship
> techniques, but that leads to a simple security-vs-cost tradeoff
> between using the Bitcoin blockchain and a sidechain. (note the
> simularity to the author's treechains proposal!)
> 
> 
> Proof-of-publication can be made expensive 
> ------------------------------------------
> 
> True, in some cases! By tightly constraining the Bitcoin scripting 
> system the available bytes for stenographic embedment can be
> reduced. For instance P2SH^2 requires an brute force exponentially
> increasing amount of hashes-per-byte-per-pushdata. However this is
> still ineffective against publishing hashes, and to fully implement
> it - scriptSigs included - would require highly invasive changes to
> the entire scripting system that would greatly limit its value.
> 
> 
> Proof-of-publication can be outsourced to untrusted third-parties 
> -----------------------------------------------------------------
> 
> Timestamping yes, but proof-of-publication no.
> 
> We're talking about systems that attempt to publish multiple pieces
> of data from multiple parties with a single hash in the Bitcoin
> blockchain, such as Factom.  Essentially this works by having a
> "child" blockchain, and the hash of that child blockchain is
> published in the master Bitcoin blockchain. To prove publicaiton
> you prove that your message is in that child chain, and the child
> chain is itself published in the Bitcoin blockchain.  Proving
> membership is possible for yourself by determining if you have the
> contents corresponding to the most recent child-chain hash.
> 
> The problem is proving non-publication. The set of all *potential* 
> child-chain hashes must be possible to obtain by scanning the
> Bitcoin blockchain. As a hash is meaningless by itself, these
> hashes must be signed. That introduces a trusted third-party who
> can also sign an invalid hash that does not correspond to a block
> and publish it in the blockchain. This in turn makes it impossible
> for anyone using the child blockchain to prove non-publication -
> they can't prove they did not publish a message because the content
> of *all* child blockchains is now unknown.
> 
> In short, Factom and systems like it rely on trusted third parties
> who can put you in a position where you can't prove you did not
> commit fraud.
> 
> 
> Proof-of-publication "bloats" the blockchain 
> --------------------------------------------
> 
> Depends on your perspective.
> 
> Systems that do not make use of the UTXO are no different
> technically than any other transaction: they pay fees to publish
> messages to the Bitcoin blockchain with no amortized increase in
> the UTXO set. Some systems do grow the UTXO set - a potential
> scaling problem as currently that all full nodes must have the
> entire UTXO set - although there are a number of existing
> mechanisms and proposals to mitigate this issue such as the
> (crippled) OP_RETURN scriptPubKey format, the dust rule, the 
> authors TXO commitments, UTXO expiry etc.
> 
> From an economic point of view proof-of-publication systems compete
> with other uses of the blockchain as they pay fees; supply of
> blockchain space is fixed so the increased demand must result in a
> higher per-transaction price in fees. On the other hand this is
> true of *all* uses of the blockchain, which collectively share the
> limited transaction capacity. For instance Satoshidice and similar
> sites have been widely condemned for doing conventional
> transactions on Bitcoin when they could have potentially used
> off-chain transactions.
> 
> It's unknown what the effect on the Bitcoin price will actually be.
> Some proof-of-publication uses have nothing to do with money at all
> - e.g. certificate transparency. Others are only indirectly
> related, such as securing financial audit logs such as
> merkle-sum-trees of total Bitcoins held by exchanges. Others in
> effect add new features to Bitcoin, such as how colored coins
> allows the trade of assets on the blockchain, or how Zerocash makes
> Bitcoin transactions anonymous. The sum total of all these effects
> on the Bitcoin price is difficult to predict.
> 
> The authors belief is that even if proof-of-publication is a 
> net-negative to Bitcoin as it is significantly more secure than
> the alternatives and can't be effectively censored people will use
> it regardless of effects to discourage them through social
> pressure. Thus Bitcoin must make technical improvements to
> scalability that negate these potentially harmful effects.
> 
> 
> Proof-of-publication systems are inefficient 
> --------------------------------------------
> 
> If you're talking about inefficient from the perspective of a
> full-node that does full validation, they are no different than
> (merge)-mined sidechain and altcoin alternatives. If you're talking
> about efficiency from the perspective of a SPV client, then yes,
> proof-of-publication systems will often require more resources than
> mining-based alternatives.
> 
> However it must be remembered that the cost of mining is the 
> introduction of a trusted third party - miners. Of course, mined 
> proof-of-publication has miners already, but trusting those miners
> to determine the meaning of that data places significantly more
> trust in them than mearly trusting them to create consensus on the
> order in which data is published.
> 
> Many usecases involve trusted third-parties anyway - the role of 
> proof-of-publication is to hold those third-parties to account and
> keep them honest. For these use-cases - certificate transparency,
> audit logs, financial assets - mined alternatives simply add new
> trusted third parties and points of failure rather than remove
> them.
> 
> Of course, global consensus is inefficient - Bitcoin itself is 
> inefficient. But this is a fundemental problem to Bitcoin's
> architecture that applies to all uses of it, a problem that should
> be solved in general.
> 
> 
> Proof-of-publication needs "scamcoins" like Mastercoin and
> Counterparty 
> -----------------------------------------------------------------------
>
>  First of all, whether or not a limited-supply token is a "scam" is
> not a technical question. However some types of embedded consensus
> systems, a specific use-case for proof-of-publication, do require
> limited-supply tokens within the system for technical reasons, for
> instance to support bid orders functionality in decentralized
> marketplaces.
> 
> Secondly using a limited-supply token in a proof-of-publicaton
> system is what lets you have secure client side validation rather
> than the alternative of 2-way-pegging that requires users to trust
> miners not to steal the pegged funds. Tokens also do not need to
> be, economically speaking, assets that can appreciate in value
> relative to Bitcoin; one-way-pegs where Bitcoins can always be
> turned into the token in conjunction with decentralized exchange to
> buy and sell tokens for Bitcoins ensure the token value will always
> closely approximate the Bitcoin value as long as the protocol
> itself is considered valuable.
> 
> Finally only a subset of proof-of-publication use-cases involve
> tokens at all - many like colored coins transact directly to and
> from Bitcoin, while other use-cases don't even involve finance at
> all.
> 
> 
> 
> ------------------------------------------------------------------------------
>
> 
Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server
> from Actuate! Instantly Supercharge Your Business Reports and
> Dashboards with Interactivity, Sharing, Native Excel Exports, App
> Integration & more Get technology previously reserved for
> billion-dollar corporations, FREE 
> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk
>
> 
> 
> 
> _______________________________________________ Bitcoin-development
> mailing list Bitcoin-development at lists.sourceforge.net 
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> 

- -- 
http://abis.io ~
"a protocol concept to enable decentralization
and expansion of a giving economy, and a new social good"
https://keybase.io/odinn
-----BEGIN PGP SIGNATURE-----

iQEcBAEBCgAGBQJUivCNAAoJEGxwq/inSG8ChVUH/26zj2pj7AF+oa2RDkPZN980
qFTY7x2s9w97bEuCiFfFpYjIP26mY4+snuoTWBa8yCp7gLVVsk9JKkN0dmXIboXf
ocoJY9s/wT7QLqJMRRwWb/8XPKwjXB10PNawCRoUk++8E0Y+W6mxiH5Gs1UnYKwI
2DHHh/hTh35mR5burwdLGEMLaVtK4BFLJTZwW+4xlWESsoWeQnxEuty799HldOaN
+wms8dvtZlzJElLUPjBGBZT6DRTaPsvqSvQ0CnHI84LYwuUObMcV89mkBcfTHlMt
MczwaO7CCc/jmoOoQKDyIVuW1eJeXggln+LOS34qwH8rCgjdOZeT3y4PgUTZ+AM=
=Sm96
-----END PGP SIGNATURE-----



From justusranvier at riseup.net  Fri Dec 12 14:17:47 2014
From: justusranvier at riseup.net (Justus Ranvier)
Date: Fri, 12 Dec 2014 14:17:47 +0000
Subject: [Bitcoin-development] Setting the record straight on
	Proof-of-Publication
In-Reply-To: <548AF08E.6080408@riseup.net>
References: <20141212090551.GA8259@muck> <548AF08E.6080408@riseup.net>
Message-ID: <548AF90B.7020305@riseup.net>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

On 12/12/2014 01:41 PM, odinn wrote:
> I think the Mastercoin devs are doing fine work

I wonder if all the Mastercoin devs would agree with that statement.

- -- 
Support online privacy by using email encryption whenever possible.
Learn how here: http://www.youtube.com/watch?v=bakOKJFtB-k
-----BEGIN PGP SIGNATURE-----

iQEcBAEBCAAGBQJUivkLAAoJEMP3uyY4RQ21r5cIANvabja0i5j79a6KSkKOgEyR
LhBz4mugzTc8Zej2NBeyEtv0pzO4fs5wvQo4N/1BW7aHXuFJsgJpGlV8thkuFhek
UhoPC23i7u3jCPQ30PintqvCBCimse+PJa60KE2QL2DZn7WgRGKrEuo41AROxeit
vfVMcFULc6bB9hxIEBpcU4RuwKJHVgzSHMkO75/uHHtPLJ9TbCfqcxT146cZvSjc
Tc62ukuX1xBj5PhQM8GaUGzkQcfcZ+7d3DD1X22Gk1U6w+zat52dapy/qYgn9oA5
ubk/p/7Kywd8D44rPsr/pbdlDZxG0w77yRJIMboXhFMV7rY3sMRHHQmAUz+I8FY=
=R4pR
-----END PGP SIGNATURE-----
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x38450DB5.asc
Type: application/pgp-keys
Size: 14542 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141212/3302f4a2/attachment.bin>

From alex.mizrahi at gmail.com  Fri Dec 12 17:04:08 2014
From: alex.mizrahi at gmail.com (Alex Mizrahi)
Date: Fri, 12 Dec 2014 19:04:08 +0200
Subject: [Bitcoin-development] Setting the record straight on
	Proof-of-Publication
In-Reply-To: <548ADED1.6060300@gmail.com>
References: <20141212090551.GA8259@muck>
	<548ADED1.6060300@gmail.com>
Message-ID: <CAE28kUR-PLzMGC23ETesc2Bz1_F1JfgcqyMW4qFvV5Vjk+ubbg@mail.gmail.com>

>
> "Secure" and "client side validation" don't really belong in the same
> sentence, do they?
>

Well, client-side validation is mathematically secure, while SPV is
economically secure.
I.e. it is secure if you make several assumptions about economics of the
whole thing.

In my opinion the former is transfinitely more secure than the later.
But it's more of a philosophical question, sure.

The good thing about PoW-based consensus is that it is robust against
version inconsistencies and various accidents of this nature up to a
certain degree. But you hardly can depend on that:
You know, The Great Fork of 2013 was resolved through human intervention,
Bitcoin nodes were not smart enough to detect that something is going awry
on their own.

Naive proof-of-publication is very fragile in that respect, but you can
easily bring back robustness.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141212/76a5cbeb/attachment.html>

From alex.mizrahi at gmail.com  Fri Dec 12 17:50:48 2014
From: alex.mizrahi at gmail.com (Alex Mizrahi)
Date: Fri, 12 Dec 2014 19:50:48 +0200
Subject: [Bitcoin-development] Setting the record straight on
	Proof-of-Publication
In-Reply-To: <CAOG=w-v3qjG3zd_WhfFU-OGnsHZEuYvY82eL4GqcdgY6np5bvA@mail.gmail.com>
References: <20141212090551.GA8259@muck> <548ADED1.6060300@gmail.com>
	<CAE28kUR-PLzMGC23ETesc2Bz1_F1JfgcqyMW4qFvV5Vjk+ubbg@mail.gmail.com>
	<CAOG=w-v3qjG3zd_WhfFU-OGnsHZEuYvY82eL4GqcdgY6np5bvA@mail.gmail.com>
Message-ID: <CAE28kUSZcGrFL3OMf=uOJ2=NQ89M54FOhR_iOXkEubrb6qqVAg@mail.gmail.com>

> I think what Gareth was getting at was that with client-side validation
> there can be no concept of a soft-fork. And how certain are you that the
> consensus rules will never change?
>

Yes, it is true that you can't do a soft-fork, but you can do a hard-fork.
Using scheduled updates: client simply stops working at a certain block,
and user is required to download an update.

In Bitcoin we can operate with some assurance that hard-forks will almost
> never happen, exactly because extensions are more likely to occur via
> soft-fork mechanisms. In such a case, old non-updated clients will still
> generate a correct view of the ledger state. But this is not so with client
> side validation!
>

You assume that an ability to operate with zero maintenance is very
important, but is this a case?

There was a plenty of critical bugs in bitcoind, and in many cases people
were strongly encouraged to upgrade to a new version.
So, you urge people to keep their clients up-to-date, but at the same time
claim that keeping very old versions is critically important.
How does this make sense? Is this an exercise at double-think?

An alternative to this is to make updates mandatory. You will no longer
need to maintain compatibility with version 0.1 (which is impossible) and
you can also evolve consensus rules over time.

It looks like people make a cargo cult out of Bitcoin's emergent
properties.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141212/7dd1f4ef/attachment.html>

From pete at petertodd.org  Sat Dec 13 02:34:58 2014
From: pete at petertodd.org (Peter Todd)
Date: Sat, 13 Dec 2014 02:34:58 +0000
Subject: [Bitcoin-development] Near-zero fee transactions with hub-and-spoke
	micropayments
Message-ID: <20141213023458.GA961@muck>

From the So-Obvious-No-one-Has-Bothered-to-Write-It-Down-Department:

tl;dr: Micropayment channels can be extended to arbitrary numbers of
parties using a nearly completley untrusted hub, greatly decreasing
transaction fees and greatly increasing the maximum number of financial
transactions per second that Bitcoin can support.


So a micropayment channel enables a payor to incrementally pay a payee
by first locking a deposit of Bitcoins in a scriptPubKey of the
following form:

    IF
        <timeout> CHECKLOCKTIMEVERIFY OP_DROP
    ELSE
        <payee> CHECKSIGVERIFY
    ENDIF
    <payor> CHECKSIGVERIFY

(obviously many other forms are possible, e.g. multisig)

Once the funds are confirmed, creating txout1, the payor creates
transactions spending txout1 sending some fraction of the txout value to
the payee and gives that half-signed transaction to the payee. Each time
the payor wants to send more money to the payee they sign a new
half-signed transaction double-spending the previous one.

When the payee is satisfied they can close the channel by signing the
most recent, highest value, tx with their key, thus making it valid. If
the payee vanishes the payor can get all the funds back once the timeout
is reached using just their key.

Since confirmation is controlled by the payee once the initial deposit
confirms subsequent increases in funds sent happen instantly in that the
payor can not double-spend the input until the timeout is reached.

(there's another formulation from Jeremy Spilman that can be almost
implemented right now using a signed refund transaction, however it is
vulnerable to transaction mutability)


Hub-and-Spoke Payments
======================

Using a nearly completely untrusted hub we can allow any number of
parties to mutually send and receive Bitcoins instantly with near-zero
transaction fees. Each participant creates one or two micropayment
channels with the hub; for Alice to send Bob some funds Alice first
sends the funds to the hub in some small increment, the hub sends the
funds to Bob, and finally the hub gives proof of that send to Alice. The
incremental amount of Bitcoins sent can be set arbitrarily low, limited
only by bandwidth and CPU time, and Bob does not necessarily need to
actually be online. The worst that the hub can do is leave user's funds
locked until the timeout expires.


Multiple Hubs
=============

Of course, hubs can in turn send to each other, again in a trustless
manner; multiple hops could act as a onion-style privacy scheme. The
micropayments could also use an additional chaum token layer for
privacy, although note that the k-anonymity set involves a trade-off
between privacy and total # of Bitcoins that could be stolen by the hub.

Of course, in general the micropayment hub breaks the linkage between
payor and payee, with respect to the data available from the blockchain.


Capital Requirements
====================

A business disadvantage with a hub-and-spoke system is that it ties up
capital, creating a tradeoff between fees saved and Bitcoins tied up.
How exactly to handle this is a business decision - for instance opening
the micropayment channel could involve a small initial payment to
account fo rthe time-value-of-money.


Embedded consensus/Colored coins
================================

Note how many embedded consensus schemes like colored coins are
compatible with micropayment channels. (though have fun figuring out who
deserves the dividends!)

-- 
'peter'[:-1]@petertodd.org
000000000000000012367d385ad11358a4a1eee86cf8ebe06a76add36dfb4622
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 455 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141213/0bc51275/attachment.sig>

From gacrux at gmail.com  Sat Dec 13 13:32:22 2014
From: gacrux at gmail.com (Gareth Williams)
Date: Sun, 14 Dec 2014 00:32:22 +1100
Subject: [Bitcoin-development] Setting the record straight on
	Proof-of-Publication
In-Reply-To: <CAE28kUSZcGrFL3OMf=uOJ2=NQ89M54FOhR_iOXkEubrb6qqVAg@mail.gmail.com>
References: <20141212090551.GA8259@muck>	<548ADED1.6060300@gmail.com>	<CAE28kUR-PLzMGC23ETesc2Bz1_F1JfgcqyMW4qFvV5Vjk+ubbg@mail.gmail.com>	<CAOG=w-v3qjG3zd_WhfFU-OGnsHZEuYvY82eL4GqcdgY6np5bvA@mail.gmail.com>
	<CAE28kUSZcGrFL3OMf=uOJ2=NQ89M54FOhR_iOXkEubrb6qqVAg@mail.gmail.com>
Message-ID: <548C3FE6.9090508@gmail.com>

On 13/12/14 04:04, Alex Mizrahi wrote:
> Well, client-side validation is mathematically secure, while SPV is
> economically secure.
> I.e. it is secure if you make several assumptions about economics of the
> whole thing.

Comparisons with the SPV security of sidechains are fallacious. The
alternative to a proof-of-publication system reliant on client-side
validation is a blockchain. The question of whether the token used on
said blockchain should be two-way-pegged to BTC is completely orthogonal.

(ie. yes, sidechains are "economically secure", in that you're reduced
to balancing economic incentives to avoid peg theft. But sidechains also
give us something unique in return - the ability to innovate without
needing to start new artificial scarcity races. Nothing else can do that.)

<snip>

> You know, The Great Fork of 2013 was resolved through human
> intervention, Bitcoin nodes were not smart enough to detect that
> something is going awry on their own.

I hate to think what the outcome would've been on a proof-of-publication
system. You don't even have a fork. You just have a whole bunch of nodes
who sort-of-mostly agree on a shared history, except where they don't.
Maybe they just disagree on the validity of a single transaction.
They'll slowly diverge over time (as bad transactions are used as input
to other transactions.) You have no reliable way to detect this lapse in
consensus, nor any mechanism to incentivse convergence. Indeed, you have
no consensus mechanism in the first place.

Bitcoin is where it is today because of Satoshi's elegant solution to
exactly such problems. Which some people now appear to be in a hurry to
discard :)

Alex Mizrahi wrote:
> Using scheduled updates: client simply stops working at a certain block,
> and user is required to download an update.

<snip>

> An alternative to this is to make updates mandatory. You will no longer
> need to maintain compatibility with version 0.1 (which is impossible)
> and you can also evolve consensus rules over time.

Peter Todd might disagree with the wisdom of that :) He wrote an
excellent email to this list not long ago warning of the dangers of
centralisation. IIRC one point he made was that scheduled, regular
hardforks were a real threat - if a single entity (eg. the Bitcoin
Foundation) were to become politically established as the coordinator of
such forks, they would have de-facto control over the protocol.

Even in that dark scenario, I would feel a measure of confidence that
past transactions I had received could not be tampered with. The fact
that those transactions happened, and that there was (and is) consensus
they were valid, is publicly documented in the blockchain. I trust any
reasonable person would not accept a client that ignored validated data
in the blockchain as "Bitcoin" any more.

Your proof-of-publication system with mandatory updates is another
matter entirely. No public record of transactions I have received with
that system exists, anywhere. If tomorrow's mandatory update has the
effect of zeroing my account balance (by happening to now interpret one
or more transactions I received, or their inputs, as invalid) then I
have no recourse. I won't find sympathy with the majority of users, who
are unaffected and just accept the update.

In short, what you describe doesn't sound very decentralised :) Do you
want transactions you receive validated by distributed consensus and
burried under PoW, or validated by some guy's mandatory-updating python
script?

(Also worth noting: all such systems are effectively "mandatory
updating" due to the risk of subtle consensus bugs of the type I
described above. Your only assurance that your view of the world is the
same as everyone elses' is that you're running the exact same software.
I played with Counterparty a while ago and quickly learned - the hard
way - to do a 'git pull' before any important operation.)






-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141214/312b03d8/attachment.sig>

From pete at petertodd.org  Mon Dec 15 04:17:14 2014
From: pete at petertodd.org (Peter Todd)
Date: Sun, 14 Dec 2014 23:17:14 -0500
Subject: [Bitcoin-development] Setting the record straight on
 Proof-of-Publication
In-Reply-To: <CAE28kUSZcGrFL3OMf=uOJ2=NQ89M54FOhR_iOXkEubrb6qqVAg@mail.gmail.com>
References: <20141212090551.GA8259@muck> <548ADED1.6060300@gmail.com>
	<CAE28kUR-PLzMGC23ETesc2Bz1_F1JfgcqyMW4qFvV5Vjk+ubbg@mail.gmail.com>
	<CAOG=w-v3qjG3zd_WhfFU-OGnsHZEuYvY82eL4GqcdgY6np5bvA@mail.gmail.com>
	<CAE28kUSZcGrFL3OMf=uOJ2=NQ89M54FOhR_iOXkEubrb6qqVAg@mail.gmail.com>
Message-ID: <20141215041714.GA23859@savin.petertodd.org>

On Fri, Dec 12, 2014 at 07:50:48PM +0200, Alex Mizrahi wrote:
> > I think what Gareth was getting at was that with client-side validation
> > there can be no concept of a soft-fork. And how certain are you that the
> > consensus rules will never change?
> >
> 
> Yes, it is true that you can't do a soft-fork, but you can do a hard-fork.
> Using scheduled updates: client simply stops working at a certain block,
> and user is required to download an update.

You're quite mistaken actually. One of the first things to come out of
my research as Mastercoin's Chief Scientist - indeed after a week on the
job - was how to safely upgrade embedded consensus systems in a
decentralized fashion:

http://www.mail-archive.com/bitcoin-development at lists.sourceforge.net/msg03890.html

To recap, where valuable scarce tokens are concerned we want to ensure
that an attacker can't use a fork caused by an upgrade to double-spend
tokens. We solve this problem by ensuring that when a token visible to
version V_i is spent in a V_{i+1} client, the token appears spent to
version V_i clients as well. This is easy to accomplish by a "split
transaction" scheme that separates all operations into separate
"increment" and "decrement" operations.

The simplest example of this principle in action is colored coins, which
are certainly an example of an embedded consensus system. Colored coin
implementations naturally ensure that all versions of the system see a
token getting spent the same way - the corresponding txout is spent! So
long as changes to the coloring rules are handled such that only one set
of rules - one version - can apply to a given txout spend we get
anti-doublespend protection.

The second aspect of the problem is the social/political implications of
upgrades - because embedded consensus systems don't outsource trust they
very clearly require the co-operation of the economic majority in an
upgrade. For instance if the community has two competing proposals for
how to upgrade version V1 of Counterparty, V2a and V2b, choosing to move
your tokens to either version becomes a vote with serious economic
consequences. In fact, it's quite possible that a community would choose
to simply fork into two different systems each offering a different set
of features. Equally in the event of such a fork someone can create a
third version, V3, that recombines the two incompatible forks. Again,
anyone who agrees with version V3 can choose to move their tokens to it,
healing the fork.

Arguably this process of handling forks by direct economic voting is
significantly *more* decentralized than Bitcoin's soft-fork mechanism as
adoption of a new version is something all participants in the system
play a part in equally. (as measured by economic stake) Of course, it
will lead to sometimes ugly political battles, but that's simply part of
the cost of having democratic systems.


> It looks like people make a cargo cult out of Bitcoin's emergent
> properties.

+1

-- 
'peter'[:-1]@petertodd.org
00000000000000000681f4e5c84bc0bf7e6c5db8673eef225da652fbb785a0de
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141214/616bc743/attachment.sig>

From pete at petertodd.org  Mon Dec 15 04:52:36 2014
From: pete at petertodd.org (Peter Todd)
Date: Sun, 14 Dec 2014 23:52:36 -0500
Subject: [Bitcoin-development] Setting the record straight on
 Proof-of-Publication
In-Reply-To: <548C3FE6.9090508@gmail.com>
References: <20141212090551.GA8259@muck> <548ADED1.6060300@gmail.com>
	<CAE28kUR-PLzMGC23ETesc2Bz1_F1JfgcqyMW4qFvV5Vjk+ubbg@mail.gmail.com>
	<CAOG=w-v3qjG3zd_WhfFU-OGnsHZEuYvY82eL4GqcdgY6np5bvA@mail.gmail.com>
	<CAE28kUSZcGrFL3OMf=uOJ2=NQ89M54FOhR_iOXkEubrb6qqVAg@mail.gmail.com>
	<548C3FE6.9090508@gmail.com>
Message-ID: <20141215045236.GB23859@savin.petertodd.org>

On Sun, Dec 14, 2014 at 12:32:22AM +1100, Gareth Williams wrote:
> On 13/12/14 04:04, Alex Mizrahi wrote:
> > Well, client-side validation is mathematically secure, while SPV is
> > economically secure.
> > I.e. it is secure if you make several assumptions about economics of the
> > whole thing.
> 
> Comparisons with the SPV security of sidechains are fallacious. The
> alternative to a proof-of-publication system reliant on client-side
> validation is a blockchain. The question of whether the token used on
> said blockchain should be two-way-pegged to BTC is completely orthogonal.
> 
> (ie. yes, sidechains are "economically secure", in that you're reduced
> to balancing economic incentives to avoid peg theft. But sidechains also
> give us something unique in return - the ability to innovate without
> needing to start new artificial scarcity races. Nothing else can do that.)

I covered this in my original post: 1-way-pegs allow the creation of new
valuable tokens without those tokens being useful for speculation.

To recap, a 1-way-peg allows the conversion of Bitcoins to another token
by provably destroying the Bitcoins, thus capping the maximum possible
value of that token and ensuring the token can-not become an investment.
For owners of these tokens they can convert them back to Bitcoin by
selling them at a discount to buyers who would otherwise be able to
purchase them via provable destruction. A pragmatic implementation may
wish to make obtaining the token via destruction option unattractive
compared to obtaining them through trade by incorporating a time delay
into the destruction process to encourage liquidity. (interestingly a
natural outcome of an announce-commit sacrifice-to-fees scheme)

Of course even without 1-way-pegs there's a much more important issue
with your objection: worrying about creating new artificial scarcity
races while innovating is fundementally a *moralistic* and *regulatory*
concern that has no little if any bearing on whether or not the systems
created are useful and secure. It's also an objection that raises
serious questions about conflicts of interest between giving accurate
and honest technical advice and promoting ways of using Bitcoin that
will drive the price up.

> > You know, The Great Fork of 2013 was resolved through human
> > intervention, Bitcoin nodes were not smart enough to detect that
> > something is going awry on their own.
> 
> I hate to think what the outcome would've been on a proof-of-publication
> system. You don't even have a fork. You just have a whole bunch of nodes
> who sort-of-mostly agree on a shared history, except where they don't.
> Maybe they just disagree on the validity of a single transaction.
> They'll slowly diverge over time (as bad transactions are used as input
> to other transactions.) You have no reliable way to detect this lapse in
> consensus, nor any mechanism to incentivse convergence. Indeed, you have
> no consensus mechanism in the first place.

A number of mechanisms for detecting divergence are possible in embedded
consensus systems, some of them even natural outcomes. For instance
transactions can contain a hash of the previous consensus state, thereby
creating an indicator of consensus measured in terms of economic stake.
Extending that idea many anti-censorship proposals are to use such state
hashes as encryption keys - if you are out of consensus you won't even
see the transaction. (and you can't be double-spent either if
implemented correctly; see my other reply to this thread today)

> Bitcoin is where it is today because of Satoshi's elegant solution to
> exactly such problems. Which some people now appear to be in a hurry to
> discard :)

FWIW usually Satoshi's solution is described as a hack, sometimes as an
elegant hack.

> Peter Todd might disagree with the wisdom of that :) He wrote an
> excellent email to this list not long ago warning of the dangers of
> centralisation. IIRC one point he made was that scheduled, regular
> hardforks were a real threat - if a single entity (eg. the Bitcoin
> Foundation) were to become politically established as the coordinator of
> such forks, they would have de-facto control over the protocol.

Indeed I did, which is why I worked out a better way to do upgrades
almost a year ago:

http://www.mail-archive.com/bitcoin-development at lists.sourceforge.net/msg06578.html


> (Also worth noting: all such systems are effectively "mandatory
> updating" due to the risk of subtle consensus bugs of the type I
> described above. Your only assurance that your view of the world is the
> same as everyone elses' is that you're running the exact same software.
> I played with Counterparty a while ago and quickly learned - the hard
> way - to do a 'git pull' before any important operation.)

The quality of Counterparty's software engineering has no bearing on
whether or not the underlying idea is a good one; you wouldn't say ring
signatures are an inherently bad idea just because the CryptoNote
implementation of them is atrocious.

-- 
'peter'[:-1]@petertodd.org
00000000000000000681f4e5c84bc0bf7e6c5db8673eef225da652fbb785a0de
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141214/599477c2/attachment.sig>

From pete at petertodd.org  Mon Dec 15 04:59:58 2014
From: pete at petertodd.org (Peter Todd)
Date: Sun, 14 Dec 2014 23:59:58 -0500
Subject: [Bitcoin-development] Setting the record straight on
 Proof-of-Publication
In-Reply-To: <548AF08E.6080408@riseup.net>
References: <20141212090551.GA8259@muck>
 <548AF08E.6080408@riseup.net>
Message-ID: <20141215045958.GD23859@savin.petertodd.org>

On Fri, Dec 12, 2014 at 01:41:34PM +0000, odinn wrote:
> Peter... It kind of sounds to me that (as fine of a position paper as
> this is) on _certain_ points, you're falling prey to the "but it's
> inefficient, but it's a scamcoin, but luke-jr told me so" argument...

I prefer to make robust arguments; if I can start with accepting that
95% of what my opponents say is true, yet still end up being correct,
all the better!

> I think the Mastercoin devs are doing fine work and I consider the
> zerocash devs to have developed (in v2, mint and pour) to have
> developed something that will really turn the world on its ear, but
> what do I know? Nothing.  Nothing at all.

My personal opinion is that what Mastercoin has started will turn the
world on its ear, but I'd be surprised if the succesful implementations
of the underlying ideas come from that team. But there's nothing
surprising about that - when was the last time you used Netscape
Navigator, let alone NCSA Mosaic?

-- 
'peter'[:-1]@petertodd.org
00000000000000000681f4e5c84bc0bf7e6c5db8673eef225da652fbb785a0de
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141214/4d956b31/attachment.sig>

From tamas at bitsofproof.com  Mon Dec 15 10:21:01 2014
From: tamas at bitsofproof.com (Tamas Blummer)
Date: Mon, 15 Dec 2014 11:21:01 +0100
Subject: [Bitcoin-development] Merged mining a side chain with proof of
	burn	on parent chain
In-Reply-To: <B8D7AE7E-567E-4656-9231-17EEAD6ED603@bitsofproof.com>
References: <417518B4-1E4D-4467-BC87-95C9EAF0C599@bitsofproof.com>
	<CA+s+GJAe9MeO+Sr0+2BRwu3q-Be5JQt_s_xdnBBEcquXqOyxcA@mail.gmail.com>
	<20141211120916.E912EE22B92@quidecco.de>
	<B8D7AE7E-567E-4656-9231-17EEAD6ED603@bitsofproof.com>
Message-ID: <AEDF060A-17E7-4519-950A-30974D1520E3@bitsofproof.com>

Burn mining side chains might be one of the foundation ideas for that ecosystem, enabling permission-less merge mining for
anyone with interest in a side chain.

I am puzzled by the lack of feedback on the idea.

Tamas Blummer
Bits of Proof
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141215/ecb6c9ca/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 496 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141215/ecb6c9ca/attachment.sig>

From pete at petertodd.org  Mon Dec 15 12:39:42 2014
From: pete at petertodd.org (Peter Todd)
Date: Mon, 15 Dec 2014 07:39:42 -0500
Subject: [Bitcoin-development] Merged mining a side chain with proof of
 burn	on parent chain
In-Reply-To: <AEDF060A-17E7-4519-950A-30974D1520E3@bitsofproof.com>
References: <417518B4-1E4D-4467-BC87-95C9EAF0C599@bitsofproof.com>
	<CA+s+GJAe9MeO+Sr0+2BRwu3q-Be5JQt_s_xdnBBEcquXqOyxcA@mail.gmail.com>
	<20141211120916.E912EE22B92@quidecco.de>
	<B8D7AE7E-567E-4656-9231-17EEAD6ED603@bitsofproof.com>
	<AEDF060A-17E7-4519-950A-30974D1520E3@bitsofproof.com>
Message-ID: <20141215123942.GA28381@savin.petertodd.org>

On Mon, Dec 15, 2014 at 11:21:01AM +0100, Tamas Blummer wrote:
> Burn mining side chains might be one of the foundation ideas for that ecosystem, enabling permission-less merge mining for
> anyone with interest in a side chain.
> 
> I am puzzled by the lack of feedback on the idea.

It's not a new idea actually - I outlined a system I eventually called
"zookeyv"? based on the notion of sacrificing Bitcoins to achieve
consensus a year and a half ago on #bitcoin-wizards. The discussion
started here and continued for a few days:

https://download.wpsoftware.net/bitcoin/wizards/2013/05/13-05-29.log

I later wrote up the idea in the context of adding Zerocoin to Bitcoin:

http://www.mail-archive.com/bitcoin-development at lists.sourceforge.net/msg02472.html

For key-value mapping I eventually decided that the system didn't
necessarily need to be a strict linear blockchain - a directed acyclic
graph of commitments had advantages as there needed to be less
syncronization between transactions. This also means that the graph
doesn't necessarily need to be revealed directly in the blockchain,
exposing it to miner censorship. OTOH revealing it makes it easy to
determine if an attacker larger than you exists. These days I'd suggest
using timelock crypto to defeat miner censorship, while ensuring that in
principle consensus over all possible parts of the chain can eventually
be reached.?

Proof-of-sacrifice for consensus has a few weird properties. For
instance you can defeat attackers after the fact by simply sacrificing
more than the attacker. Not unlike having a infinite amount of mining
equipment available with the only constraint being funds to pay for the
electricity. (which *is* semi-true with altcoins!)

As for your specific example, you can improve it's censorship resistance
by having the transactions commit to a nonce in advance in some way
indistinguishable from normal transactions, and then making the
selection criteria be some function of H(nonce | blockhash) - for
instance highest wins. So long as the chain selection is based on
cumulative difficulty based on a fixed target - as is the case in
Bitcoin proper - you should get a proper incentive to publish blocks, as
well as the "total work information rachet" effect Bitcoin has against
attackers.


1) In honor of Zooko's triangle.

2) This doesn't necessarily take as much work as you might expect: you
   can work backwards from the most recent block(s) if the scheme
   requires block B_i to include the decryption key for block B_{i-1}.

-- 
'peter'[:-1]@petertodd.org
000000000000000018d439a78581d2a9ecd762a2b37dd5b403a82beb58dcbc7c
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141215/493ead87/attachment.sig>

From pete at petertodd.org  Mon Dec 15 12:47:30 2014
From: pete at petertodd.org (Peter Todd)
Date: Mon, 15 Dec 2014 07:47:30 -0500
Subject: [Bitcoin-development] Recent EvalScript() changes mean
	CHECKLOCKTIMEVERIFY can't be merged
Message-ID: <20141215124730.GA8321@savin.petertodd.org>

BtcDrak was working on rebasing my CHECKLOCKTIMEVERIFY? patch to master a few
days ago and found a fairly large design change that makes merging it currently
impossible. Pull-req #4890?, specifically commit c7829ea7, changed the
EvalScript() function to take an abstract SignatureChecker object, removing the
txTo and nIn arguments that used to contain the transaction the script was in
and the txin # respectively. CHECKLOCKTIMEVERIFY needs txTo to obtain the
nLockTime field of the transaction, and it needs nIn to obtain the nSequence of
the txin.

We need to fix this if CHECKLOCKTIMEVERIFY is to be merged.

Secondly, that this change was made, and the manner in which is was made, is I
think indicative of a development process that has been taking significant
risks with regard to refactoring the consensus critical codebase. I know I
personally have had a hard time keeping up with the very large volume of code
being moved and changed for the v0.10 release, and I know BtcDrak - who is
keeping Viacoin up to date with v0.10 - has also had a hard time giving the
changes reasonable review. The #4890 pull-req in question had no ACKs at all,
and only two untested utACKS, which I find worrying for something that made
significant consensus critical code changes.

While it would be nice to have a library encapsulating the consensus code, this
shouldn't come at the cost of safety, especially when the actual users of that
library or their needs is still uncertain. This is after all a multi-billion
project where a simple fork will cost miners alone tens of thousands of dollars
an hour; easily much more if it results in users being defrauded. That's also
not taking into account the significant negative PR impact and loss of trust. I
personally would recommend *not* upgrading to v0.10 due to these issues.

A much safer approach would be to keep the code changes required for a
consensus library to only simple movements of code for this release, accept
that the interface to that library won't be ideal, and wait until we have
feedback from multiple opensource projects with publicly evaluatable code on
where to go next with the API.

1) https://github.com/bitcoin/bips/blob/master/bip-0065.mediawiki
2) https://github.com/bitcoin/bitcoin/pull/4890

-- 
'peter'[:-1]@petertodd.org
00000000000000001b18a596ecadd07c0e49620fb71b16f9e41131df9fc52fa6
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141215/c0b5116e/attachment.sig>

From tamas at bitsofproof.com  Mon Dec 15 13:06:32 2014
From: tamas at bitsofproof.com (Tamas Blummer)
Date: Mon, 15 Dec 2014 14:06:32 +0100
Subject: [Bitcoin-development] Merged mining a side chain with proof of
	burn	on parent chain
In-Reply-To: <20141215123942.GA28381@savin.petertodd.org>
References: <417518B4-1E4D-4467-BC87-95C9EAF0C599@bitsofproof.com>
	<CA+s+GJAe9MeO+Sr0+2BRwu3q-Be5JQt_s_xdnBBEcquXqOyxcA@mail.gmail.com>
	<20141211120916.E912EE22B92@quidecco.de>
	<B8D7AE7E-567E-4656-9231-17EEAD6ED603@bitsofproof.com>
	<AEDF060A-17E7-4519-950A-30974D1520E3@bitsofproof.com>
	<20141215123942.GA28381@savin.petertodd.org>
Message-ID: <709AAA00-A40A-42EF-A17D-9B3E07FE902A@bitsofproof.com>

Peter,

Thanks for the research, I am glad that the idea, that proof-of-burn can ?transfer" proof-of-work 
was discussed earlier, as those discussions give some attack vectors that I can reevaluate in 
a new context, that is side chains. 

I think that the lottery component I suggested, makes it much more resilient to ?outspend? attack, since
the attacker not only needs to outspend but win the lottery for a reorg. This raises the cost of the attack
by magnitudes above the regular miner burn cost.

In addition, I suggest the burn transaction to include the Bitcoin block height, thereby disabling re-use of a burn,
for a later reorg.

Tamas Blummer
Bits of Proof

On Dec 15, 2014, at 1:39 PM, Peter Todd <pete at petertodd.org> wrote:

> On Mon, Dec 15, 2014 at 11:21:01AM +0100, Tamas Blummer wrote:
>> Burn mining side chains might be one of the foundation ideas for that ecosystem, enabling permission-less merge mining for
>> anyone with interest in a side chain.
>> 
>> I am puzzled by the lack of feedback on the idea.
> 
> It's not a new idea actually - I outlined a system I eventually called
> "zookeyv"? based on the notion of sacrificing Bitcoins to achieve
> consensus a year and a half ago on #bitcoin-wizards. The discussion
> started here and continued for a few days:
> 
> https://download.wpsoftware.net/bitcoin/wizards/2013/05/13-05-29.log
> 
> I later wrote up the idea in the context of adding Zerocoin to Bitcoin:
> 
> http://www.mail-archive.com/bitcoin-development at lists.sourceforge.net/msg02472.html
> 
> For key-value mapping I eventually decided that the system didn't
> necessarily need to be a strict linear blockchain - a directed acyclic
> graph of commitments had advantages as there needed to be less
> syncronization between transactions. This also means that the graph
> doesn't necessarily need to be revealed directly in the blockchain,
> exposing it to miner censorship. OTOH revealing it makes it easy to
> determine if an attacker larger than you exists. These days I'd suggest
> using timelock crypto to defeat miner censorship, while ensuring that in
> principle consensus over all possible parts of the chain can eventually
> be reached.?
> 
> Proof-of-sacrifice for consensus has a few weird properties. For
> instance you can defeat attackers after the fact by simply sacrificing
> more than the attacker. Not unlike having a infinite amount of mining
> equipment available with the only constraint being funds to pay for the
> electricity. (which *is* semi-true with altcoins!)
> 
> As for your specific example, you can improve it's censorship resistance
> by having the transactions commit to a nonce in advance in some way
> indistinguishable from normal transactions, and then making the
> selection criteria be some function of H(nonce | blockhash) - for
> instance highest wins. So long as the chain selection is based on
> cumulative difficulty based on a fixed target - as is the case in
> Bitcoin proper - you should get a proper incentive to publish blocks, as
> well as the "total work information rachet" effect Bitcoin has against
> attackers.
> 
> 
> 1) In honor of Zooko's triangle.
> 
> 2) This doesn't necessarily take as much work as you might expect: you
>   can work backwards from the most recent block(s) if the scheme
>   requires block B_i to include the decryption key for block B_{i-1}.
> 
> -- 
> 'peter'[:-1]@petertodd.org
> 000000000000000018d439a78581d2a9ecd762a2b37dd5b403a82beb58dcbc7c

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141215/5921cb09/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 496 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141215/5921cb09/attachment.sig>

From cryptocurrencies at quidecco.de  Mon Dec 15 13:25:14 2014
From: cryptocurrencies at quidecco.de (Isidor Zeuner)
Date: Mon, 15 Dec 2014 14:25:14 +0100 (CET)
Subject: [Bitcoin-development] Deanonymisation of clients in Bitcoin P2P
 network paper
In-Reply-To: <CA+s+GJBsxmQJkrUYekFuUOgmEcD7qeL2e9Rf-d2nD1G1N7c_EQ@mail.gmail.com>
References: <CA+s+GJBsxmQJkrUYekFuUOgmEcD7qeL2e9Rf-d2nD1G1N7c_EQ@mail.gmail.com>
	<CAJHLa0N6+hpwNECpHUSiKuj4-BYohh=Wr1DP=67Ff8xVBsi8-Q@mail.gmail.com>
	<54760A50.201@riseup.net> <20141127020947.A13D2E19A09@quidecco.de>
	<CAAS2fgRSxBmyDg5R7WgisB-XmhrpGVKHXQpchtL-Ow0xDQAziA@mail.gmail.com>
Message-ID: <20141215132514.BCC88E2353B@quidecco.de>

[...]
> > I'm confused by this, I run quite a few nodes exclusively on tor and
> > chart their connectivity and have seen no such connection dropping
> > behaviour.
>
> In my experience the problem has always been getting bootstrapped.
> Most nodes hardly give any hidden service nodes in their getaddr.
> (this has been improved in master by including a set of hidden service
> seed nodes)
> But this assumes -onlynet=tor. Tor with exit nodes should be less
> problematic, unless someone managed to DoSban all the exit nodes as
> described in the paper (but I've never seen such an attack myself).
>

When refering to "getting bootstrapped", do you only mean collecting
node addresses, or also syncing blocks?

If you're saying the drops in connection counts are likely to be
not caused by a DoSban attack on the exit nodes, what could be other
reasons to look into?

> > Can you tell me more about how you measured this?
> >
> > [As an aside I agree that there are lots of things to improve here,
> > but the fact that users can in theory be forced off of tor via DOS
> > attacks is not immediately concerning to me because its a conscious
> > choice users would make to abandon their privacy (and the behaviour of
> > the system here is known and intentional). There are other mechanisms
> > available for people to relay their transactions than connecting
> > directly to the bitcoin network; so their choice isn't just abandon
> > privacy or don't use bitcoin at all.]
>
> Right, there's something to be said for splitting your own transaction
> submission from normal P2P networking and transaction relay.
> (esp for non-SPV wallets which don't inherently leak any information
> about their addresses)
>
> There was a pull request about this for Bitcoin Core one, maybe I
> closed it unfairly https://github.com/bitcoin/bitcoin/issues/4564 .
>

Great! I find it very interesting to research options for splitting
communication between Tor and non-Tor as long as the introduced
information leakage between both connection methods can be proved to
be nonexistent or negligible.

In the case of Bitcoin, this makes me wonder about an attack that
could look approximately like this:

* Node A connects to Bitcoin using Tor (for submitting transactions)
  and IPv4 (for all other communication).

* Node B strives for direct IPv4 connections with node A

* Node B uses the direct IPv4 connections in order to supply Node A
  with additional peer addresses not supplied to any other nodes

* Node B observes these additional peer addresses

For transactions submitted to the additional peer addresses supplied
by node B, how to prevent that the probability of these originating
from node A is higher than for originating from other nodes?

For handling block propagation using non-Tor connections, it's
probably harder to create information leaks, as the logic for handling
disagreement about blocks is pretty well-researched, meaning that
it's less important where the blocks come from.

Best regards,

Isidor



From cryptocurrencies at quidecco.de  Mon Dec 15 14:55:06 2014
From: cryptocurrencies at quidecco.de (Isidor Zeuner)
Date: Mon, 15 Dec 2014 15:55:06 +0100 (CET)
Subject: [Bitcoin-development] Merged mining a side chain with proof of
 burn on parent chain
In-Reply-To: <54880492.9060300@intersango.com>
References: <54880492.9060300@intersango.com> <54876653.4020403@certimix.com>
	<548769FA.5040406@bluematt.me>
	<CA+s+GJAe9MeO+Sr0+2BRwu3q-Be5JQt_s_xdnBBEcquXqOyxcA@mail.gmail.com>
	<417518B4-1E4D-4467-BC87-95C9EAF0C599@bitsofproof.com>
Message-ID: <20141215145506.54A06E23568@quidecco.de>

> The goal is to have an opportunity cost to breaking the rules.
>
> Proof of Burn is a real cost for following the rules.
>

For every participant who could try to decide about the adequateness
of the cost, no direct effect comes from the difference between Proof
of Burn, and approaches which keep the Bitcoins inside the set of
outputs that can still participate. So, any notion which
differentiates with respect to this must make some assumption about
what defines the interest of the Bitcoin nodes as a community.

Best regards,

Isidor



From btcdrak at gmail.com  Mon Dec 15 14:57:07 2014
From: btcdrak at gmail.com (Btc Drak)
Date: Mon, 15 Dec 2014 14:57:07 +0000
Subject: [Bitcoin-development] Recent EvalScript() changes mean
 CHECKLOCKTIMEVERIFY can't be merged
In-Reply-To: <20141215124730.GA8321@savin.petertodd.org>
References: <20141215124730.GA8321@savin.petertodd.org>
Message-ID: <CADJgMztRdNWyogPCjv64qpUHcvGDiOZDVAkv5Ra8hn25Z9xa8w@mail.gmail.com>

This is a pretty good example about refactoring discipline as well as
premature/over optimisation.

We all want to see more modular code, but the first steps should just be to
relocate blocks of code so everything is more logically organised in
smaller files (especially for consensus critical code). Refactoring should
come in a second wave preferably after a stable release. Refactoring should
be in the pure sense, optimising code with absolutely no change in
behaviour.

When it comes to actual API changes, I think we need to be a lot more
careful and should be considered feature requests and get a lot more
scrutiny as we are essentially breaking backwards compatibility. #4890 was
pretty much merged with no discussion or thought yet other really simple
and uncontroversial PRs remain unmerged for months. A key question in the
case of EvalScript() would have been, "why are we passing txTo and nIn
here, and are there any future use cases that might require them? Why
should this be removed from the API and the entire method signature
changed?". BC breaks always need strong justification.

So I've expressed my concern a few times about the speed and frequency of
refactoring and also the way it's being done. I am not alone, as others not
directly connected with the Bitcoin Core project have also expressed
concerns about the number of refactorings "for the sake of refactoring",
especially of consensus critical code. Careful as we may be, we know from
history that small edge case bugs can creep in very easily and cause a lot
of unforeseen problems.

BtcDrak


On Mon, Dec 15, 2014 at 12:47 PM, Peter Todd <pete at petertodd.org> wrote:
>
> BtcDrak was working on rebasing my CHECKLOCKTIMEVERIFY? patch to master a
> few
> days ago and found a fairly large design change that makes merging it
> currently
> impossible. Pull-req #4890?, specifically commit c7829ea7, changed the
> EvalScript() function to take an abstract SignatureChecker object,
> removing the
> txTo and nIn arguments that used to contain the transaction the script was
> in
> and the txin # respectively. CHECKLOCKTIMEVERIFY needs txTo to obtain the
> nLockTime field of the transaction, and it needs nIn to obtain the
> nSequence of
> the txin.
>
> We need to fix this if CHECKLOCKTIMEVERIFY is to be merged.
>
> Secondly, that this change was made, and the manner in which is was made,
> is I
> think indicative of a development process that has been taking significant
> risks with regard to refactoring the consensus critical codebase. I know I
> personally have had a hard time keeping up with the very large volume of
> code
> being moved and changed for the v0.10 release, and I know BtcDrak - who is
> keeping Viacoin up to date with v0.10 - has also had a hard time giving the
> changes reasonable review. The #4890 pull-req in question had no ACKs at
> all,
> and only two untested utACKS, which I find worrying for something that made
> significant consensus critical code changes.
>
> While it would be nice to have a library encapsulating the consensus code,
> this
> shouldn't come at the cost of safety, especially when the actual users of
> that
> library or their needs is still uncertain. This is after all a
> multi-billion
> project where a simple fork will cost miners alone tens of thousands of
> dollars
> an hour; easily much more if it results in users being defrauded. That's
> also
> not taking into account the significant negative PR impact and loss of
> trust. I
> personally would recommend *not* upgrading to v0.10 due to these issues.
>
> A much safer approach would be to keep the code changes required for a
> consensus library to only simple movements of code for this release, accept
> that the interface to that library won't be ideal, and wait until we have
> feedback from multiple opensource projects with publicly evaluatable code
> on
> where to go next with the API.
>
> 1) https://github.com/bitcoin/bips/blob/master/bip-0065.mediawiki
> 2) https://github.com/bitcoin/bitcoin/pull/4890
>
> --
> 'peter'[:-1]@petertodd.org
> 00000000000000001b18a596ecadd07c0e49620fb71b16f9e41131df9fc52fa6
>
>
> ------------------------------------------------------------------------------
> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server
> from Actuate! Instantly Supercharge Your Business Reports and Dashboards
> with Interactivity, Sharing, Native Excel Exports, App Integration & more
> Get technology previously reserved for billion-dollar corporations, FREE
>
> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141215/d2a843f5/attachment.html>

From jgarzik at bitpay.com  Mon Dec 15 15:20:47 2014
From: jgarzik at bitpay.com (Jeff Garzik)
Date: Mon, 15 Dec 2014 10:20:47 -0500
Subject: [Bitcoin-development] Recent EvalScript() changes mean
 CHECKLOCKTIMEVERIFY can't be merged
In-Reply-To: <CADJgMztRdNWyogPCjv64qpUHcvGDiOZDVAkv5Ra8hn25Z9xa8w@mail.gmail.com>
References: <20141215124730.GA8321@savin.petertodd.org>
	<CADJgMztRdNWyogPCjv64qpUHcvGDiOZDVAkv5Ra8hn25Z9xa8w@mail.gmail.com>
Message-ID: <CAJHLa0OvDPazCQVonhokm0KopN-WYj0_PP_LO8gPewc1LG5Qow@mail.gmail.com>

On Mon, Dec 15, 2014 at 9:57 AM, Btc Drak <btcdrak at gmail.com> wrote:

> We all want to see more modular code, but the first steps should just be
> to relocate blocks of code so everything is more logically organised in
> smaller files (especially for consensus critical code). Refactoring should
> come in a second wave preferably after a stable release.
>

This is my opinion as well.  In the Linux kernel, we often were faced with
a situation where you have a One Big File driver with > 1MB of source
code.  The first step was -always- raw code movement, a brain-dead breaking
up of code into logical source code files.

Refactoring of data structures comes after that.

While not always money-critical, these drivers Had To Keep Working.  We had
several situations where we had active users, but zero hardware access for
debugging, and zero access to the vendor knowledge (hardware documentation,
engineers).  Failure was not an option.  ;p

Performing the dumb Break Up Files step first means that future, more
invasive data structures are easier to review, logically segregated, and
not obscured by further code movement changes down the line.  In code such
as Bitcoin Core, it is important to think about the _patch stream_ and how
to optimize for reviewer bandwidth.

The current stream of refactoring is really a turn-off in terms of
reviewing, sapping reviewer bandwidth by IMO being reviewer-unfriendly.  It
is a seemingly never-ending series of tiny
refactor-and-then-stuff-in-a-class-and-make-it-pretty-and-do-all-the-work.
Some change is in order, gentlemen.

-- 
Jeff Garzik
Bitcoin core developer and open source evangelist
BitPay, Inc.      https://bitpay.com/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141215/fa588b20/attachment.html>

From laanwj at gmail.com  Mon Dec 15 17:46:41 2014
From: laanwj at gmail.com (Wladimir)
Date: Mon, 15 Dec 2014 17:46:41 +0000
Subject: [Bitcoin-development] Recent EvalScript() changes mean
 CHECKLOCKTIMEVERIFY can't be merged
In-Reply-To: <20141215124730.GA8321@savin.petertodd.org>
References: <20141215124730.GA8321@savin.petertodd.org>
Message-ID: <CA+s+GJAYC8SJ2wOTfhATfzemV+Qb3CarOQotHrzmx5JE+q2iLQ@mail.gmail.com>

> While it would be nice to have a library encapsulating the consensus code, this
> shouldn't come at the cost of safety, especially when the actual users of that
> library or their needs is still uncertain.

While I agree that it shouldn't come at unreasonable risk, my whole
reason for prioritizing the consensus library is that it is the first
step toward the goal of isolating the consensus code completely. As
soon as it exists in a repository by itself, it is easier to enforce a
different regime of change control there, or even freeze it completely
over time. To keep track of consensus changes one'd only have to
follow that repository, instead of filter it between tons of GUI, RPC
or utility commits.

IMO having the consensus isolated into a portable self-contained
library is the most important goal of Bitcoin Core project at this
point. I've tried to keep the amount of unnecessary refactoring down,
but some is unfortunately unavoidable.

I'm sure we can find a way to rebase CHECKLOCKTIMEVERIFY so that it
can land in 0.11.

Wladimir



From gmaxwell at gmail.com  Mon Dec 15 17:38:57 2014
From: gmaxwell at gmail.com (Gregory Maxwell)
Date: Mon, 15 Dec 2014 17:38:57 +0000
Subject: [Bitcoin-development] Recent EvalScript() changes mean
 CHECKLOCKTIMEVERIFY can't be merged
In-Reply-To: <20141215124730.GA8321@savin.petertodd.org>
References: <20141215124730.GA8321@savin.petertodd.org>
Message-ID: <CAAS2fgQuLfU=QmK4oyYtEQxiLByLqie9GKDyMs2_2-KZP0qrWA@mail.gmail.com>

On Mon, Dec 15, 2014 at 12:47 PM, Peter Todd <pete at petertodd.org> wrote:
[snip]
> Pull-req #4890?, specifically commit c7829ea7, changed the

This change was authored more than three months ago and merged more
than two months ago.
[And also, AFAICT, prior to you authoring BIP65]

I didn't participate in that pull-req, though I saw it... it had five
other contributors working on it and I try to have minimal opinions on
code organization and formatting.

But the idea sounded (and still sounds) reasonable to me.  Of course,
anything could still be backed out if it turned out to be ill-advised
(even post 0.10, as I think now we've had months of testing with this
code in place and removing it may be more risky)... but your comments
here are really not timely.
Everyone has limited resources, which is understandable, but the
concerns you are here are ones that didn't involve looking at the code
to raise, and would have been better process wise raised earlier.

> We need to fix this if CHECKLOCKTIMEVERIFY is to be merged.

I don't see why you conclude this. Rather than violating the layering
by re-parsing the transaction as the lower level, just make this data
additional information that is needed available.
Yes, does mean that rebasing an altcoin that made modifications here
will take more effort and understanding of the code than a purely
mechanical change.

> Secondly, that this change was made, and the manner in which is was made, is I
> think indicative of a development process that has been taking significant
> risks with regard to refactoring the consensus critical codebase.

I don't agree. The character of this change is fairly narrow. We have
moderately good test coverage here, and there were five participants
on the PR.

> While it would be nice to have a library encapsulating the consensus code, this
> shouldn't come at the cost of safety, especially when the actual users of that

This is all true stuff, but the fact of it doesn't follow that any
particular change was especially risky.

Beyond the general 'things were changed in a way that made rebasing
an-altcoin take more work' do you have a specific concern here?

Other than travling back in time three months and doing something
differently, do you have any suggestions to ameliorate that concern?
E.g. are their additional tests we don't already have that you think
would increase your confidence with respect to specific safety
concerns?

> A much safer approach would be to keep the code changes required for a
> consensus library to only simple movements of code for this release, accept
> that the interface to that library won't be ideal, and wait until we have
> feedback from multiple opensource projects with publicly evaluatable code on
> where to go next with the API.

There won't be any public users of the library until there can
actually _be_ a library.

PR4890's primary objective was disentangling the script validation
from the node state introduced by the the signature caching changes a
couple years ago, making it possible to build the consensus components
without application specific threading logic... and makes it possible
to have a plain script evaluator call without having to replicate all
of bitcoind's threading, signature cache, etc. logic.  Without a
change like this you can't invoke the script engine without having a
much larger chunk of bitcoind running.

0.10 is a major release, not a maintenance release. It's specifically
in major releases that we make changes which are not purely code
motion and narrow bugfixes (Though many of the changes in 0.10 were
nicely factored into verify pure code motion changes from behavioral
changes). There are many very important, even critical, behavioural
changes in 0.10.  That these changes have their own risks are part of
why they aren't in 0.9.x.



From lists at coryfields.com  Mon Dec 15 18:35:11 2014
From: lists at coryfields.com (Cory Fields)
Date: Mon, 15 Dec 2014 13:35:11 -0500
Subject: [Bitcoin-development] Recent EvalScript() changes mean
 CHECKLOCKTIMEVERIFY can't be merged
In-Reply-To: <20141215124730.GA8321@savin.petertodd.org>
References: <20141215124730.GA8321@savin.petertodd.org>
Message-ID: <CAApLimhQePn6JVDz_zYCom0uNrJqPtevPOYkQ+aj32QFT5WjQQ@mail.gmail.com>

On Mon, Dec 15, 2014 at 7:47 AM, Peter Todd <pete at petertodd.org> wrote:
> BtcDrak was working on rebasing my CHECKLOCKTIMEVERIFY? patch to master a few
> days ago and found a fairly large design change that makes merging it currently
> impossible. Pull-req #4890?, specifically commit c7829ea7, changed the
> EvalScript() function to take an abstract SignatureChecker object, removing the
> txTo and nIn arguments that used to contain the transaction the script was in
> and the txin # respectively. CHECKLOCKTIMEVERIFY needs txTo to obtain the
> nLockTime field of the transaction, and it needs nIn to obtain the nSequence of
> the txin.
>
> We need to fix this if CHECKLOCKTIMEVERIFY is to be merged.
>
> Secondly, that this change was made, and the manner in which is was made, is I
> think indicative of a development process that has been taking significant
> risks with regard to refactoring the consensus critical codebase. I know I
> personally have had a hard time keeping up with the very large volume of code
> being moved and changed for the v0.10 release, and I know BtcDrak - who is
> keeping Viacoin up to date with v0.10 - has also had a hard time giving the
> changes reasonable review. The #4890 pull-req in question had no ACKs at all,
> and only two untested utACKS, which I find worrying for something that made
> significant consensus critical code changes.
>
> While it would be nice to have a library encapsulating the consensus code, this
> shouldn't come at the cost of safety, especially when the actual users of that
> library or their needs is still uncertain. This is after all a multi-billion
> project where a simple fork will cost miners alone tens of thousands of dollars
> an hour; easily much more if it results in users being defrauded. That's also
> not taking into account the significant negative PR impact and loss of trust. I
> personally would recommend *not* upgrading to v0.10 due to these issues.
>
> A much safer approach would be to keep the code changes required for a
> consensus library to only simple movements of code for this release, accept
> that the interface to that library won't be ideal, and wait until we have
> feedback from multiple opensource projects with publicly evaluatable code on
> where to go next with the API.
>
> 1) https://github.com/bitcoin/bips/blob/master/bip-0065.mediawiki
> 2) https://github.com/bitcoin/bitcoin/pull/4890
>
> --
> 'peter'[:-1]@petertodd.org
> 00000000000000001b18a596ecadd07c0e49620fb71b16f9e41131df9fc52fa6

It would appear as though you're trying to drum up controversy here,
but the argument is quite a stretch, and contrary to some other
arguments you're making in parallel. There seem to be three themes in
your above complaint, so I'd like to address them individually.

1. Pr #4890 specifically. The argument seems to be that this was not
properly reviewed/tested, and that it is an unnecessary risk to the
consensus codebase.

Looking at the PR at github, while I certainly don't agree with those
conclusions, I suppose I can understand where they're coming from.
There's plenty of context missing, as well as sidebar discussions on
IRC and other PRs. To an outside observer, these changes may look
under-tested and unnecessary.

The context that's missing is the flurry of work that was going on in
parallel to modularize this (and surrounding code). #4890 was one of
the first pieces necessary for that, so some of the discussion about
it was happening in dependent pull requests.

You can point to a lack ACKs in one place for that PR, but that
doesn't mean that the changes weren't tested/reviewed/necessary. You
could also argue that ACKs should've been mirrored on the PR in
question for posterity, which would be a perfectly reasonable argument
that I would agree with.


2. These changes conflict with a rebased version of your
CHECKLOCKTIMEVERIFY changes. OK? You have a tree that's a few months
old, and you find that you have conflicts when rebasing to master. It
happens to all of us. Do as the rest of us do and update your changes
to fit. If you missed the review of #4890 and think it should be
reverted, then call for a revert. But please give a concrete reason
other than "I've picked this commit series for a crusade because it
gave me merge conflicts".

What is the conspiracy here? There's a signature cache that is
implementation-specific, and in a parallel universe, you might be
arguing that we should rip it out because it adds unnecessary
complexity to the consensus code. The PR provides a path around that
complexity. For some reason, your reaction is to cry foul months later
because you missed reviewing it at the time, rather than cheering for
the reduced complexity.

3. You seem to think that 1. and 2. seem to point to a systemic
failure of the review process because modularization "shouldn't come
at the cost of safety". I agree that it shouldn't come at the cost of
safety, but I see no failure here. There has been a HUGE effort to
modularize the code with a combination of pure-code-movement and small
interface reworks. Please take a moment to grep the git logs for
"MOVEONLY" in the 0.10 branch.

You'll notice that script verification is now 100% free of bitcoind
state, threading, and third-party libraries (other than openssl for
now). That constitutes a massive reduction in code complexity, future
review overhead, etc. I'll point out here that those were my reasons
for my contributions to the libbitcoinconsensus effort. I have no
interest in altcoins or sidechains.

Those milestones were thanks to an effort which included #4890. If you
have issues with these changes and/or how they were made, please call
out individual failures and proposed solutions _in context_. That they
conflict with CHECKLOCKTIMEVERIFY may be a valid concern, and it may
be worth evaluating how separate coding efforts may more effectively
parallelized.

Without pointers to specific failures or solutions, I'm not sure what
you were trying to communicate here, other than maybe stirring the
social networks with: "I
personally would recommend *not* upgrading to v0.10 due to these
issues." That's fine I suppose, but it does nothing to solve whatever
issue you're trying to call out here.

Cory



From lists at coryfields.com  Mon Dec 15 18:42:27 2014
From: lists at coryfields.com (Cory Fields)
Date: Mon, 15 Dec 2014 13:42:27 -0500
Subject: [Bitcoin-development] Recent EvalScript() changes mean
 CHECKLOCKTIMEVERIFY can't be merged
In-Reply-To: <CAJHLa0OvDPazCQVonhokm0KopN-WYj0_PP_LO8gPewc1LG5Qow@mail.gmail.com>
References: <20141215124730.GA8321@savin.petertodd.org>
	<CADJgMztRdNWyogPCjv64qpUHcvGDiOZDVAkv5Ra8hn25Z9xa8w@mail.gmail.com>
	<CAJHLa0OvDPazCQVonhokm0KopN-WYj0_PP_LO8gPewc1LG5Qow@mail.gmail.com>
Message-ID: <CAApLimi+Jskwn=70+cfqr8=d55CKJFpBDBmW48zJk24PSBZczg@mail.gmail.com>

On Mon, Dec 15, 2014 at 10:20 AM, Jeff Garzik <jgarzik at bitpay.com> wrote:
> On Mon, Dec 15, 2014 at 9:57 AM, Btc Drak <btcdrak at gmail.com> wrote:
>>
>> We all want to see more modular code, but the first steps should just be
>> to relocate blocks of code so everything is more logically organised in
>> smaller files (especially for consensus critical code). Refactoring should
>> come in a second wave preferably after a stable release.
>
>
> This is my opinion as well.  In the Linux kernel, we often were faced with a
> situation where you have a One Big File driver with > 1MB of source code.
> The first step was -always- raw code movement, a brain-dead breaking up of
> code into logical source code files.
>
> Refactoring of data structures comes after that.
>
> While not always money-critical, these drivers Had To Keep Working.  We had
> several situations where we had active users, but zero hardware access for
> debugging, and zero access to the vendor knowledge (hardware documentation,
> engineers).  Failure was not an option.  ;p
>
> Performing the dumb Break Up Files step first means that future, more
> invasive data structures are easier to review, logically segregated, and not
> obscured by further code movement changes down the line.  In code such as
> Bitcoin Core, it is important to think about the _patch stream_ and how to
> optimize for reviewer bandwidth.
>
> The current stream of refactoring is really a turn-off in terms of
> reviewing, sapping reviewer bandwidth by IMO being reviewer-unfriendly.  It
> is a seemingly never-ending series of tiny
> refactor-and-then-stuff-in-a-class-and-make-it-pretty-and-do-all-the-work.
> Some change is in order, gentlemen.
>
> --
> Jeff Garzik
> Bitcoin core developer and open source evangelist
> BitPay, Inc.      https://bitpay.com/

That's exactly what happened during the modularization process, with
the exception that the code movement and refactors happened in
parallel rather than in series. But they _were_ done in separate
logical chunks for the sake of easier review. The commit tag
"MOVEONLY" developed organically out of this process, and a grep of
the 0.10 branch for "MOVEONLY" is a testament to exactly how much code
moved 1:1 out of huge files and into logically separated places and/or
new files.

Perhaps it's worth making "MOVEONLY" (which as the name implies, means
that code has been copied 1:1 to a new location) use an official dev
guideline for use in future refactors.

Cory



From jgarzik at bitpay.com  Mon Dec 15 19:35:00 2014
From: jgarzik at bitpay.com (Jeff Garzik)
Date: Mon, 15 Dec 2014 14:35:00 -0500
Subject: [Bitcoin-development] Recent EvalScript() changes mean
 CHECKLOCKTIMEVERIFY can't be merged
In-Reply-To: <CAApLimi+Jskwn=70+cfqr8=d55CKJFpBDBmW48zJk24PSBZczg@mail.gmail.com>
References: <20141215124730.GA8321@savin.petertodd.org>
	<CADJgMztRdNWyogPCjv64qpUHcvGDiOZDVAkv5Ra8hn25Z9xa8w@mail.gmail.com>
	<CAJHLa0OvDPazCQVonhokm0KopN-WYj0_PP_LO8gPewc1LG5Qow@mail.gmail.com>
	<CAApLimi+Jskwn=70+cfqr8=d55CKJFpBDBmW48zJk24PSBZczg@mail.gmail.com>
Message-ID: <CAJHLa0MDftgnxB5itQS2jKqZsPj2vg-=SM+jVqUDxKGRZjuukA@mail.gmail.com>

On Mon, Dec 15, 2014 at 1:42 PM, Cory Fields <lists at coryfields.com> wrote:

> That's exactly what happened during the modularization process, with
> the exception that the code movement and refactors happened in
> parallel rather than in series. But they _were_ done in separate
> logical chunks for the sake of easier review.
>

"That's exactly what was done except it wasn't"

Yes, in micro, at the pull request level, this happened
* Code movement
* Refactor

At a macro level, that cycle was repeated many times, leading to the
opposite end result:  a lot of tiny movement/refactor/movement/refactor
producing the review and patch annoyances described.

It produces a blizzard of new files and new data structures, breaking a
bunch of out-of-tree patches, complicating review quite a bit.  If the vast
majority of code movement is up front, followed by algebraic
simplifications, followed by data structure work, further patches are easy
to review/apply with less impact on unrelated code.

The flow of patches into the tree over time should be examined.  Simply
tagging patches as movement-only does not address the described problem at
all.

-- 
Jeff Garzik
Bitcoin core developer and open source evangelist
BitPay, Inc.      https://bitpay.com/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141215/e2cb4696/attachment.html>

From pieter.wuille at gmail.com  Mon Dec 15 18:10:08 2014
From: pieter.wuille at gmail.com (Pieter Wuille)
Date: Mon, 15 Dec 2014 19:10:08 +0100
Subject: [Bitcoin-development] Recent EvalScript() changes mean
 CHECKLOCKTIMEVERIFY can't be merged
In-Reply-To: <20141215124730.GA8321@savin.petertodd.org>
References: <20141215124730.GA8321@savin.petertodd.org>
Message-ID: <CAPg+sBiz9TS0-uEMyRs9grecB-sJLd1vVd2DuTo6p+PSGNUUhg@mail.gmail.com>

On Mon, Dec 15, 2014 at 1:47 PM, Peter Todd <pete at petertodd.org> wrote:

> BtcDrak was working on rebasing my CHECKLOCKTIMEVERIFY? patch to master a few
> days ago and found a fairly large design change that makes merging it currently
> impossible. Pull-req #4890?, specifically commit c7829ea7, changed the
> EvalScript() function to take an abstract SignatureChecker object, removing the
> txTo and nIn arguments that used to contain the transaction the script was in
> and the txin # respectively. CHECKLOCKTIMEVERIFY needs txTo to obtain the
> nLockTime field of the transaction, and it needs nIn to obtain the nSequence of
> the txin.

I agree, and I was thinking earlier that some rebasing would be needed
for CLTV when the change was made. I think this is a good thing
though: #4890 introduced a clear separation between the script
evaluation code and what it can access out of its environment (the
transaction being verified). As CLTV changes the amount available out
of the environment, this indeed requires changing the interface.

> We need to fix this if CHECKLOCKTIMEVERIFY is to be merged.

Done. See https://github.com/sipa/bitcoin/commit/cltv2 for a rebased
version of the BIP65 code on top of 0.10 and master. I haven't ported
any tests you may have that are not in the BIP, to avoid doing double
work. Those should apply cleanly. There is a less clean version (IMHO)
with smaller code changes wrt to the BIP code in my 'cltv' branch too.

> Secondly, that this change was made, and the manner in which is was made, is I
> think indicative of a development process that has been taking significant
> risks with regard to refactoring the consensus critical codebase.

I fully agree that we shouldn't be taking unnecessary risks when
changing consensus code. For example, I closed #5091 (which I would
very much have liked as a code improvement) when realizing the risks.
That said, I don't believe we are at a point where we can just freeze
anything that touches consensus-related, and sometimes refactorings
are necessary. In particular, #4890 introduced separation between a
very fundamental part of consensus logic (script logic) and an
optional optimization for it (caching). If we ever want to get to a
separate consensus code tree or repository, possibly with more strict
reviews, I think changes like this are inevitable.

> I know I
> personally have had a hard time keeping up with the very large volume of code
> being moved and changed for the v0.10 release, and I know BtcDrak - who is
> keeping Viacoin up to date with v0.10 - has also had a hard time giving the
> changes reasonable review. The #4890 pull-req in question had no ACKs at all,
> and only two untested utACKS, which I find worrying for something that made
> significant consensus critical code changes.

I'm sorry to hear that that, and I do understand that many code
movements make this harder. If this is a concern shared by many
people, we can always decide to roll back some refactorings in the
0.10 branch. On the other hand, we don't even have release candidates
yet (which are a pretty important part of the testing and reviewing
process), and doing so would delay things further. 0.10 has many very
significant improvements which are beneficial to the network too,
which I'm sure you're aware of.

It's perfectly reasonable that not everyone has the same bandwidth
available to keep up with changes, and perhaps that means slowing
things down. Again, I don't want to say "this was reviewed before, we
can't go back to this" - but did you really need 3 months to realize
this change? I also see that elsewhere you're complaining about #5421
of yours which hasn't made it in yet - after less than 2 weeks. Yes, I
like the change, and I will review it. Surely you are not arguing it
can be merged without decent review?

> While it would be nice to have a library encapsulating the consensus code, this
> shouldn't come at the cost of safety, especially when the actual users of that
> library or their needs is still uncertain. This is after all a multi-billion
> project where a simple fork will cost miners alone tens of thousands of dollars
> an hour; easily much more if it results in users being defrauded. That's also
> not taking into account the significant negative PR impact and loss of trust. I
> personally would recommend *not* upgrading to v0.10 due to these issues.

I have been very much in favor of a libconsensus library, and for
several reasons. It's a step towards separating out the
consensus-critical parts from optional pieces of the codebase, and it
is a step towards avoiding the "reimplementing consensus code is very
dangerous! ... but we really don't have a way to allow you to reuse
the existing code either" argument. It does not fully accomplish
either of those goals, but gradual steps with time to let changes
mature in between are nice.

> A much safer approach would be to keep the code changes required for a
> consensus library to only simple movements of code for this release, accept
> that the interface to that library won't be ideal, and wait until we have
> feedback from multiple opensource projects with publicly evaluatable code on
> where to go next with the API.

If at this point the consensus code was nicely separated, I would
argue to *copy* it (despite all normal engineering practices that
argue against code duplication), into a frozen separate directory or
even repository, and have all validation related code use the
consensus version, while everything else can use a normal tree
version, which then can evolve at a normal pace, and undergo cleanups,
API changes and feature improvements along with the rest of the code.

Unfortunately, it is not. The consensus code is mixed all over the
place, and this forces unnecessary strain on all development of the
codebase. I hope people agree that getting to a point where this is no
longer the case is important.

-- 
Pieter



From btcdrak at gmail.com  Mon Dec 15 21:57:27 2014
From: btcdrak at gmail.com (Btc Drak)
Date: Mon, 15 Dec 2014 21:57:27 +0000
Subject: [Bitcoin-development] Recent EvalScript() changes mean
 CHECKLOCKTIMEVERIFY can't be merged
In-Reply-To: <CAJHLa0MDftgnxB5itQS2jKqZsPj2vg-=SM+jVqUDxKGRZjuukA@mail.gmail.com>
References: <20141215124730.GA8321@savin.petertodd.org>
	<CADJgMztRdNWyogPCjv64qpUHcvGDiOZDVAkv5Ra8hn25Z9xa8w@mail.gmail.com>
	<CAJHLa0OvDPazCQVonhokm0KopN-WYj0_PP_LO8gPewc1LG5Qow@mail.gmail.com>
	<CAApLimi+Jskwn=70+cfqr8=d55CKJFpBDBmW48zJk24PSBZczg@mail.gmail.com>
	<CAJHLa0MDftgnxB5itQS2jKqZsPj2vg-=SM+jVqUDxKGRZjuukA@mail.gmail.com>
Message-ID: <CADJgMzsSg28ZJakKaqx8xqTKqTuszzNj2yqEj_cDKaxU5C4tiA@mail.gmail.com>

On Mon, Dec 15, 2014 at 7:35 PM, Jeff Garzik <jgarzik at bitpay.com> wrote:
>
> At a macro level, that cycle was repeated many times, leading to the
> opposite end result:  a lot of tiny movement/refactor/movement/refactor
> producing the review and patch annoyances described.
>
> It produces a blizzard of new files and new data structures, breaking a
> bunch of out-of-tree patches, complicating review quite a bit.  If the vast
> majority of code movement is up front, followed by algebraic
> simplifications, followed by data structure work, further patches are easy
> to review/apply with less impact on unrelated code.
>
> The flow of patches into the tree over time should be examined.  Simply
> tagging patches as movement-only does not address the described problem at
> all.
>

I think we can all agree that if the process is made more friendly for
reviewers, everyone wins. It's been hard to even know where everything is
because it moves so often. e.g. In the last couple weeks stuff moved from
core.h to core/block.h to primitive/block.h or something to that effect.
Anyway, Jeff said this quite elegantly.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141215/7cf75389/attachment.html>

From jgarzik at bitpay.com  Mon Dec 15 21:54:20 2014
From: jgarzik at bitpay.com (Jeff Garzik)
Date: Mon, 15 Dec 2014 16:54:20 -0500
Subject: [Bitcoin-development] Recent EvalScript() changes mean
 CHECKLOCKTIMEVERIFY can't be merged
In-Reply-To: <CAApLimjMkPvi+JfXMWsgS+tFCxXLivZc=eptuLn7z72O6CE6SA@mail.gmail.com>
References: <20141215124730.GA8321@savin.petertodd.org>
	<CADJgMztRdNWyogPCjv64qpUHcvGDiOZDVAkv5Ra8hn25Z9xa8w@mail.gmail.com>
	<CAJHLa0OvDPazCQVonhokm0KopN-WYj0_PP_LO8gPewc1LG5Qow@mail.gmail.com>
	<CAApLimi+Jskwn=70+cfqr8=d55CKJFpBDBmW48zJk24PSBZczg@mail.gmail.com>
	<CAJHLa0MDftgnxB5itQS2jKqZsPj2vg-=SM+jVqUDxKGRZjuukA@mail.gmail.com>
	<CAApLimjMkPvi+JfXMWsgS+tFCxXLivZc=eptuLn7z72O6CE6SA@mail.gmail.com>
Message-ID: <CAJHLa0OcSNQTDmseUyu7jrb4HyMQy19emEER8rkjT=cexmAENQ@mail.gmail.com>

If code movement is not compressed into a tight time window, code movement
becomes a constant stream during development.  A constant stream of code
movement is a constant stream of patch breakage, for any patch or project
not yet in-tree.  The result is to increase the work and cost on any
contributor whose patches are not immediately merged.

For the record, since this is trending reddit, I __do__ support the end
result of 0.10 refactoring, the work towards the consensus lib.

My criticism is of a merge flow which _unintentionally_ rewards only
certain types of patches, and creates disincentives for working on other
types of patches.







On Mon, Dec 15, 2014 at 4:19 PM, Cory Fields <lists at coryfields.com> wrote:
>
> On Mon, Dec 15, 2014 at 2:35 PM, Jeff Garzik <jgarzik at bitpay.com> wrote:
> > On Mon, Dec 15, 2014 at 1:42 PM, Cory Fields <lists at coryfields.com>
> wrote:
> >>
> >> That's exactly what happened during the modularization process, with
> >> the exception that the code movement and refactors happened in
> >> parallel rather than in series. But they _were_ done in separate
> >> logical chunks for the sake of easier review.
> >
> >
> > "That's exactly what was done except it wasn't"
> >
> > Yes, in micro, at the pull request level, this happened
> > * Code movement
> > * Refactor
> >
> > At a macro level, that cycle was repeated many times, leading to the
> > opposite end result:  a lot of tiny movement/refactor/movement/refactor
> > producing the review and patch annoyances described.
> >
> > It produces a blizzard of new files and new data structures, breaking a
> > bunch of out-of-tree patches, complicating review quite a bit.  If the
> vast
> > majority of code movement is up front, followed by algebraic
> > simplifications, followed by data structure work, further patches are
> easy
> > to review/apply with less impact on unrelated code.
> >
>
> I won't argue that at all because it's perfectly logical, but in
> practice that doesn't translate from the macro level to the micro
> level very well. At the micro level, minor code changes are almost
> always needed to accommodate useful code movement. Even if they're not
> required, it's often hard to justify code movement for the sake of
> code movement with the promise that it will be useful later.
>
> Rather than arguing hypotheticals, let's use a real example:
> https://github.com/bitcoin/bitcoin/pull/5118 . That one's pretty
> simple. The point of the PR was to unchain our openssl wrapper so that
> key operations could be performed by the consensus lib without
> dragging in bitcoind's structures. The first commit severs the
> dependencies. The second commit does the code movement from the
> now-freed wrapper.
>
> I'm having a hard time coming up with a workflow that would handle
> these two changes as _separate_ events, while making review easier.
> Note that I'm not attempting to argue with you here, rather I'm
> genuinely curious as to how you'd rather see this specific example
> (which is representative of most of my other code movement for the
> libbitcoinconsensus work, i believe) handled.
>
> Using your model above, I suppose we'd do the code movement first with
> the dependencies still intact as a pull request. At some later date,
> we'd sever the dependencies in the new files. I suppose you'd also
> prefer that I group a bunch of code-movement changes together into a
> single PR which needs little scrutiny, only verification that it's
> move-only. Once the code-movement PRs are merged, I can begin the
> cleanups which actually fix something.
>
> In practice, though, that'd be a massive headache for different
> reasons. Lots in flux with seemingly no benefits until some later
> date. My PR's can't depend on eachother because they don't actually
> fix issues in a linear fashion. That means that other devs can't
> depend on my PRs either for the same reason. And what have we gained?
>
> Do you find that assessment unreasonable?
>
> Cory
>


-- 
Jeff Garzik
Bitcoin core developer and open source evangelist
BitPay, Inc.      https://bitpay.com/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141215/86432848/attachment.html>

From lists at coryfields.com  Mon Dec 15 21:19:16 2014
From: lists at coryfields.com (Cory Fields)
Date: Mon, 15 Dec 2014 16:19:16 -0500
Subject: [Bitcoin-development] Recent EvalScript() changes mean
 CHECKLOCKTIMEVERIFY can't be merged
In-Reply-To: <CAJHLa0MDftgnxB5itQS2jKqZsPj2vg-=SM+jVqUDxKGRZjuukA@mail.gmail.com>
References: <20141215124730.GA8321@savin.petertodd.org>
	<CADJgMztRdNWyogPCjv64qpUHcvGDiOZDVAkv5Ra8hn25Z9xa8w@mail.gmail.com>
	<CAJHLa0OvDPazCQVonhokm0KopN-WYj0_PP_LO8gPewc1LG5Qow@mail.gmail.com>
	<CAApLimi+Jskwn=70+cfqr8=d55CKJFpBDBmW48zJk24PSBZczg@mail.gmail.com>
	<CAJHLa0MDftgnxB5itQS2jKqZsPj2vg-=SM+jVqUDxKGRZjuukA@mail.gmail.com>
Message-ID: <CAApLimjMkPvi+JfXMWsgS+tFCxXLivZc=eptuLn7z72O6CE6SA@mail.gmail.com>

On Mon, Dec 15, 2014 at 2:35 PM, Jeff Garzik <jgarzik at bitpay.com> wrote:
> On Mon, Dec 15, 2014 at 1:42 PM, Cory Fields <lists at coryfields.com> wrote:
>>
>> That's exactly what happened during the modularization process, with
>> the exception that the code movement and refactors happened in
>> parallel rather than in series. But they _were_ done in separate
>> logical chunks for the sake of easier review.
>
>
> "That's exactly what was done except it wasn't"
>
> Yes, in micro, at the pull request level, this happened
> * Code movement
> * Refactor
>
> At a macro level, that cycle was repeated many times, leading to the
> opposite end result:  a lot of tiny movement/refactor/movement/refactor
> producing the review and patch annoyances described.
>
> It produces a blizzard of new files and new data structures, breaking a
> bunch of out-of-tree patches, complicating review quite a bit.  If the vast
> majority of code movement is up front, followed by algebraic
> simplifications, followed by data structure work, further patches are easy
> to review/apply with less impact on unrelated code.
>

I won't argue that at all because it's perfectly logical, but in
practice that doesn't translate from the macro level to the micro
level very well. At the micro level, minor code changes are almost
always needed to accommodate useful code movement. Even if they're not
required, it's often hard to justify code movement for the sake of
code movement with the promise that it will be useful later.

Rather than arguing hypotheticals, let's use a real example:
https://github.com/bitcoin/bitcoin/pull/5118 . That one's pretty
simple. The point of the PR was to unchain our openssl wrapper so that
key operations could be performed by the consensus lib without
dragging in bitcoind's structures. The first commit severs the
dependencies. The second commit does the code movement from the
now-freed wrapper.

I'm having a hard time coming up with a workflow that would handle
these two changes as _separate_ events, while making review easier.
Note that I'm not attempting to argue with you here, rather I'm
genuinely curious as to how you'd rather see this specific example
(which is representative of most of my other code movement for the
libbitcoinconsensus work, i believe) handled.

Using your model above, I suppose we'd do the code movement first with
the dependencies still intact as a pull request. At some later date,
we'd sever the dependencies in the new files. I suppose you'd also
prefer that I group a bunch of code-movement changes together into a
single PR which needs little scrutiny, only verification that it's
move-only. Once the code-movement PRs are merged, I can begin the
cleanups which actually fix something.

In practice, though, that'd be a massive headache for different
reasons. Lots in flux with seemingly no benefits until some later
date. My PR's can't depend on eachother because they don't actually
fix issues in a linear fashion. That means that other devs can't
depend on my PRs either for the same reason. And what have we gained?

Do you find that assessment unreasonable?

Cory



From tamas at bitsofproof.com  Tue Dec 16 08:28:02 2014
From: tamas at bitsofproof.com (Tamas Blummer)
Date: Tue, 16 Dec 2014 09:28:02 +0100
Subject: [Bitcoin-development] Merged mining a side chain with proof of
	burn on parent chain
In-Reply-To: <20141215145506.54A06E23568@quidecco.de>
References: <54880492.9060300@intersango.com> <54876653.4020403@certimix.com>
	<548769FA.5040406@bluematt.me>
	<CA+s+GJAe9MeO+Sr0+2BRwu3q-Be5JQt_s_xdnBBEcquXqOyxcA@mail.gmail.com>
	<417518B4-1E4D-4467-BC87-95C9EAF0C599@bitsofproof.com>
	<20141215145506.54A06E23568@quidecco.de>
Message-ID: <6890C7A6-DE8B-4F0C-98AD-1358F2BFC883@bitsofproof.com>

The output has to be burned  otherwise there is no cost of expressing
any number of alternate opinions the same time. 

Tamas Blummer
Bits of Proof

On Dec 15, 2014, at 3:55 PM, Isidor Zeuner <cryptocurrencies at quidecco.de> wrote:
> For every participant who could try to decide about the adequateness
> of the cost, no direct effect comes from the difference between Proof
> of Burn, and approaches which keep the Bitcoins inside the set of
> outputs that can still participate. So, any notion which
> differentiates with respect to this must make some assumption about
> what defines the interest of the Bitcoin nodes as a community.
> 
> Best regards,
> 
> Isidor
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141216/1d71ad5e/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 496 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141216/1d71ad5e/attachment.sig>

From alex.mizrahi at gmail.com  Tue Dec 16 09:55:50 2014
From: alex.mizrahi at gmail.com (Alex Mizrahi)
Date: Tue, 16 Dec 2014 11:55:50 +0200
Subject: [Bitcoin-development] Merged mining a side chain with proof of
 burn on parent chain
In-Reply-To: <54880492.9060300@intersango.com>
References: <54876653.4020403@certimix.com> <548769FA.5040406@bluematt.me>
	<CA+s+GJAe9MeO+Sr0+2BRwu3q-Be5JQt_s_xdnBBEcquXqOyxcA@mail.gmail.com>
	<417518B4-1E4D-4467-BC87-95C9EAF0C599@bitsofproof.com>
	<54880492.9060300@intersango.com>
Message-ID: <CAE28kUQ1tzCXp=90-1ZQG67f2Vh3uCrApJTbx+Lf1r-1byV4Lw@mail.gmail.com>

>  The goal is to have an opportunity cost to breaking the rules.
>

You could as well have said "The goal is to implement it in a specific way
I want it to be implemented."
This makes zero sense.
You aren't even trying to compare properties of different possible
implementations, you just outright reject the alternatives.

So the thing is, relying on opportunity cost is rather problematic.

1. can't work when system isn't heavily used (you'll have to rely on the
honesty of miners instead)
2. chicken-and-egg: system is not secure until it is heavily used, and it
isn't heavily used until it is secure
3. finally, if the expected profit from attack is higher than the
opportunity cost of it, it just makes no sense

Let's put 1 and 2 aside. For the start, you need to prove that attack
cannot yield profits which are higher than honest mining.

The problem with it is that the total amount of money is much higher than
the amount of money which is being transacted in a short time frame. And it
is much higher than what fees might yield within a reasonable time frame.

So if there is a way to attack the whole (with a profit proportional to the
whole), you won't be able to rely on opportunity cost to prevent the attack.

Usually at this point people say "we assume that miners aren't going to
collude, otherwise even Bitcoin is not secure".
Well, this is BS. The fact that a pool can acquire more than 50% of total
hashpower was successfully demonstrated by ghash.io.
But the thing is, Bitcoin doesn't offer one a good way to attack the whole,
as there are powerful factors which will work against the attacker.
But this is not the case with sidechains (or any merged-mined chains, for
that matter).
And once you have a clear incentive, collusion is much more likely.


> Proof of Burn is a real cost for following the rules.
>

 So what? As long as cost is less than revenue, it is OK.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141216/ec335df8/attachment.html>

From tamas at bitsofproof.com  Tue Dec 16 12:30:04 2014
From: tamas at bitsofproof.com (Tamas Blummer)
Date: Tue, 16 Dec 2014 13:30:04 +0100
Subject: [Bitcoin-development] Merged mining a side chain with proof of
	burn on parent chain
In-Reply-To: <417518B4-1E4D-4467-BC87-95C9EAF0C599@bitsofproof.com>
References: <54876653.4020403@certimix.com> <548769FA.5040406@bluematt.me>
	<CA+s+GJAe9MeO+Sr0+2BRwu3q-Be5JQt_s_xdnBBEcquXqOyxcA@mail.gmail.com>
	<417518B4-1E4D-4467-BC87-95C9EAF0C599@bitsofproof.com>
Message-ID: <C90BC633-9BB0-4886-B818-02980ED3D6C4@bitsofproof.com>

Let me be more concrete in implementation details: 

1) burn transaction sends at least n satoshis to an OP_RETURN h, 
2) h mod m matches the bitcoin block hash mod m, for the block the burn transaction was mined into.
3) The side chain block header hashes to h and also contains the bitcoin block hight.
4) a side chain block releases x new side coins

Since the burn hash does not reveal in advance which side chain it will be used for, the Bitcoin miner can not selectively block burn mining. They will include loosing bets for the Bitcoin fee. Bitcoin miner have no advantage over independent burn miner of the side chain.

Anyone who issues a burn transaction that complies the rules 1-3 has 1/m the chance to win the next block on the side chain. This implies a fair exchange rate of n*m satoshis = x side coins (at the margin).

Should two burn transactions fulfill the mod m lottery criteria, then we have a competing fork on the side chain. Just as for Bitcoin, the next block(s) will pick the winner. 

To contain fork rate, the parameter m would have to be adjusted dynamically, similar to Bitcoins difficulty. It needs to increase if fork rate increases and decrease if no valid block is burned with Bitcoin blocks. Unfortunately SPV can only prove the existence of a transaction, but not the non-existence of an alternative. Therefore the fork rate within a block cycle can not be evaluated with SPV proofs. 

Rational burn miner who frequently faces and loses head-to-head runs with a competing forks would increase his bet for the next burn cycle, as increasing the individual bet amount has the advantage that if he wins his victory is more stable. Remember the side chain trunk is selected as the one with highest cumulative burn.

Consequently cumulative burn within an adjustment period (measured in Bitcoin blocks) is expected to rise in face of high fork rate. If the sample period burn exceeds a target, then it would trigger a rise to the lottery criteria m, reducing the fork rate and vs.

Tamas Blummer
Bits of Proof

On Dec 10, 2014, at 8:35 AM, Tamas Blummer <tamas at bitsofproof.com> wrote:

> 
> We spend scarce resources external to the digital realm to create Bitcoin. Real world sacrifice is needed to avoid ?nothing at stake?  and sybil attacks. With Bitcoin we now have a scarce resource within the digital realm, so it appeals my intuition to re-use it for sacrifice instead of linking again an external, real world resource. 
> 
> In following I outline a new mining algorithm for side chains, that burn Bitcoins to secure them.
> 
> The side chain block validity rules would require that a transaction on the Bitcoin block chain provably destroys Bitcoins with an OP_RET output, that contains the hash of the block header of the side chain. To also introduce a lottery, the burn transaction?s hash is required to satisfy some function of the block hash it was included in on the Bitcoin block chain. For example modulo m of the burn transaction hash must match modulo m of the block hash, that is not known in advance.
> 
> Those who want to mine the side chain will assemble  side chain block candidates that comply the rules of the side chain, then a Bitcoin transaction burning to the hash of the block candidate and submit it to the Bitcoin network. Should he burn transaction be included into the Bitcoin block chain and the Bitcoin block?s hash satisfy the lottery criteria, then the block candidate can be submitted to extend the side chain.
> 
> A side chain block header sequence would be accepted as side chain trunk if a sequence of Bitcoin SPV proofs for burn transactions prove, that linked blocks have the highest cumulative burn, if compared to alternative sequences. 
> 
> The Bitcoin miner will include burn transactions because they offer Bitcoin fees. Bitcoin miner can not selectively block side chains since the hashes associated with the burn do not disclose which side chain or other project they are for. Here you have a ?merged mining? that does not need Bitcoin miner support or even consent.
> 
> Mining difficulty of the side chain could be adjusted by stepping up the required burn and/or hardening the criteria that links a burn proof transaction with the bitcoin block hash it is included in.
> 
> The difficulty to mine with burn would be dynamic and would also imply a floating exchange rate between Bitcoin and the side coin.
> 
> Tamas Blummer
> Bits of Proof
> 
> 00000000000000001172380e63346e3e915b52fcbae838ba958948ac9aa85edd

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141216/4179037c/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 496 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141216/4179037c/attachment.sig>

From pete at petertodd.org  Tue Dec 16 12:36:42 2014
From: pete at petertodd.org (Peter Todd)
Date: Tue, 16 Dec 2014 07:36:42 -0500
Subject: [Bitcoin-development] Merged mining a side chain with proof of
 burn on parent chain
In-Reply-To: <CAE28kUQ1tzCXp=90-1ZQG67f2Vh3uCrApJTbx+Lf1r-1byV4Lw@mail.gmail.com>
References: <54876653.4020403@certimix.com> <548769FA.5040406@bluematt.me>
	<CA+s+GJAe9MeO+Sr0+2BRwu3q-Be5JQt_s_xdnBBEcquXqOyxcA@mail.gmail.com>
	<417518B4-1E4D-4467-BC87-95C9EAF0C599@bitsofproof.com>
	<54880492.9060300@intersango.com>
	<CAE28kUQ1tzCXp=90-1ZQG67f2Vh3uCrApJTbx+Lf1r-1byV4Lw@mail.gmail.com>
Message-ID: <20141216123642.GA19943@savin.petertodd.org>

On Tue, Dec 16, 2014 at 11:55:50AM +0200, Alex Mizrahi wrote:
> Usually at this point people say "we assume that miners aren't going to
> collude, otherwise even Bitcoin is not secure".
> Well, this is BS. The fact that a pool can acquire more than 50% of total
> hashpower was successfully demonstrated by ghash.io.
> But the thing is, Bitcoin doesn't offer one a good way to attack the whole,
> as there are powerful factors which will work against the attacker.
> But this is not the case with sidechains (or any merged-mined chains, for
> that matter).
> And once you have a clear incentive, collusion is much more likely.

+1

It's notable that blockstream hasn't published much if anything concrete
on what exactly you'd use merge-mined sidechains for; they're even worse
than Ethereum in that regard.

> > Proof of Burn is a real cost for following the rules.
> >
> 
>  So what? As long as cost is less than revenue, it is OK.

It's even better than that: if an attack does happen, the participants
in the consensus system have an incentive to defend against it to
maintain the value of their tokens. Proof-of-burn allows that defense to
be in response to a threat, and essentially unlimited in size.

So now any attacker knows that if they launch an attack in theory the
response could be as strong as the value of the system itself.

This can be improved upon with systems that allow the tokens to be
burned, "internal" proof-of-burn. This suffers from "nothing-at-stake"
vulnerabilities to an extent, OTOH within the context of the system it
is a true sacrifice of value; probably not a big deal in a zookeyv-style
block-DAG where multiple lines of history can be combined. Here the
incentives of the defenders are even more strongly tipped towards
burning their value to preserve the system, not unlike
replace-by-fee-scorched-earth thinking.

-- 
'peter'[:-1]@petertodd.org
00000000000000000e0c078667795abe21bfdebb913eba60cc7a625c732f0a89
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141216/369a1f00/attachment.sig>

From jgarzik at bitpay.com  Tue Dec 16 17:59:06 2014
From: jgarzik at bitpay.com (Jeff Garzik)
Date: Tue, 16 Dec 2014 12:59:06 -0500
Subject: [Bitcoin-development] Open development processes and reddit charms
Message-ID: <CAJHLa0M0YeEWWaP4gNpwnaDq56w=AHW_kmLr=f3AVvHDB89SNA@mail.gmail.com>

It can be useful to review open source development processes from time to
time.  This reddit thread[1] serves use both as a case study, and also a
moment of OSS process introduction for newbies.
[1]
http://www.reddit.com/r/Bitcoin/comments/2pd0zy/peter_todd_is_saying_shoddy_development_on_v010/




*Dirty Laundry*
When building businesses or commercial software projects, outsiders
typically hear little about the internals of project development.  The
public only hears what the companies release, which is prepped and
polished. Internal disagreements, schedule slips, engineer fistfights are
all unseen.

Open source development is the opposite.  The goal is radical
transparency.  Inevitably there is private chatter (0day bugs etc.), but
the default is openness.  This means that is it normal practice to "air
dirty laundry in public."  Engineers will disagree, sometimes quietly,
sometimes loudly, sometimes rudely and with ad hominem attacks.  On the
Internet, there is a pile-on effect, where informed and uninformed
supporters add their 0.02 BTC.

Competing interests cloud the issues further.  Engineers are typically
employed by an organization, as a technology matures.  Those organizations
have different strategies and motivations.  These organizations will
sponsor work they find beneficial.  Sometimes those orgs are non-profit
foundations, sometimes for-profit corporations.  Sometimes that work is
maintenance ("keep it running"), sometimes that work is developing new,
competitive features that company feels will give it a better market
position.  In a transparent development environment, all parties are
hyperaware of these competing interests.  Internet natterers painstakingly
document and repeat every conspiracy theory about Bitcoin Foundation,
Blockstream, BitPay, various altcoin developers, and more as a result of
these competing interests.

Bitcoin and altcoin development adds an interesting new dimension.
Sometimes engineers have a more direct conflict of interest, in that the
technology they are developing is also potentially their road to instant
$millions.  Investors, amateur and professional, have direct stakes in a
certain coin or coin technology.  Engineers also have an emotional stake in
technology they design and nurture.  This results in incentives where
supporters of a non-bitcoin technology work very hard to thump bitcoin.
And vice versa.  Even inside bitcoin, you see "tree chains vs. side chains"
threads of a similar stripe.  This can lead to a very skewed debate.

That should not distract from the engineering discussion.  Starting from
first principles, Assume Good Faith[2].  Most engineers in open source tend
to mean what they say.  Typically they speak for themselves first, and
their employers value that engineer's freedom of opinion.  Pay attention to
the engineers actually working on the technology, and less attention to the
noise bubbling around the Internet like the kindergarten game of grapevine.
[2] http://en.wikipedia.org/wiki/Wikipedia:Assume_good_faith

Being open and transparent means engineering disagreements happen in
public.  This is normal.  Open source engineers live an aquarium life[3].
[3] https://www.youtube.com/watch?v=QKe-aO44R7k




*What the fork?*
In this case, a tweet suggests consensus bug risks, which reddit account
"treeorsidechains" hyperbolizes into a dramatic headline[1].  However, the
headline would seem to be the opposite of the truth.  Several changes were
merged during 0.10 development which move snippets of source code into new
files and new sub-directories.  The general direction of this work is
creating a "libconsensus" library that carefully encapsulates consensus
code in a manner usable by external projects.  This is a good thing.

The development was performed quite responsible:  Multiple developers would
verify each cosmetic change, ensuring no behavior changes had been
accidentally (or maliciously!) introduced.  Each pull request receives a
full multi-platform build + automated testing, over and above individual
dev testing.  Comparisons at the assembly language level were sometimes
made in critical areas, to ensure zero before-and-after change.  Each
transformation gets the Bitcoin Core codebase to a more sustainable, more
reusable state.

Certainly zero-change is the most conservative approach. Strictly speaking,
that has the lowest consensus risk.  But that is a short term mentality.
Both Bitcoin Core and the larger ecosystem will benefit when the "hairball"
pile of source code is cleaned up.  Progress has been made on that front in
the past 2 years, and continues.   *Long term*, combined with the
"libconsensus" work, that leads to less community-wide risk.

The key is balance.  Continue software engineering practices -- like those
just mentioned above -- that enable change with least consensus risk.  Part
of those practices is review at each step of the development process:
social media thought bubble, mailing list post, pull request, git merge,
pre-release & release.  It probably seems chaotic at times.  In effect,
git[hub] and the Internet enable a dynamic system of review and feedback,
where each stage provides a check-and-balance for bad ideas and bad
software changes.  It's a human process, designed to acknowledge and handle
that human engineers are fallible and might make mistakes (or be
coerced/under duress!).  History and field experience will be the ultimate
judge, but I think Bitcoin Core is doing good on this score, all things
considered.

At the end of the day, while no change is without risk, version 0.10 work
was done with attention to consensus risk at multiple levels (not just
short term).




*Technical and social debt*
Working on the Linux kernel was an interesting experience that combined
git-driven parallel development and a similar source code hairball.  One of
the things that quickly became apparent is that cosmetic patches,
especially code movement, was hugely disruptive.  Some even termed it
anti-social.  To understand why, it is important to consider how modern
software changes are developed:

Developers work in parallel on their personal computers to develop XYZ
change, then submit their change "upstream" as a github pull request.  Then
time passes.  If code movement and refactoring changes are accepted
upstream before XYZ, then the developer is forced update XYZ -- typically
trivial fixes, re-review XYZ, and re-test XYZ to ensure it remains in a
known-working state.

Seemingly cosmetic changes such as code movement have a ripple effect on
participating developers, and wider developer community.  Every developer
who is *not* immediately merged upstream must bear the costs of updating
their unmerged work.

Normally, this is expected.  Encouraging developers to build on top of
"upstream" produces virtuous cycles.

However, a constant stream of code movement and cosmetic changes may
produce a constant stream of disruption to developers working on
non-trivial features that take a bit longer to develop before going
upstream.  Trivial changes are encouraged, and non-trivial changes face a
binary choice of (a) be merged immediately or (b) bear added re-base,
re-view, re-test costs.

Taken over a timescale of months, I argue that a steady stream of cosmetic
code movement changes serves as a disincentive to developers working with
upstream.  Each upstream breakage has a ripple effect to all developers
downstream, and imposes some added chance of newly introduced bugs on
downstream developers.  I'll call this "social debt", a sort of technical
debt[4] for developers.
[4] http://en.wikipedia.org/wiki/Technical_debt

As mentioned above, the libconsensus and code movement work is a net gain.
The codebase needs cleaning up.  Each change however incurs a little bit of
social debt.  Life is a little bit harder on people trying to get work into
the tree.  Developers are a little bit more discouraged at the busy-work
they must perform.  Non-trivial pull requests take a little bit longer to
approve, because they take a little bit more work to rebase (again).

A steady flow of code movement and cosmetic breakage into the tree may be a
net gain, but it also incurs a *lot* of social debt.  In such situations,
developers find that tested, working out-of-tree code repeatedly stops
working *during the process of trying to get that work in-tree*.  Taken
over time, it discourages working on the tree.  It is rational to sit back,
*not* work on the tree, let the breakage stop, and then pick up the pieces.




*Paradox Unwound*
Bitcoin Core, then, is pulled in opposite directions by a familiar
problem.  It is generally agreed that the codebase needs further
refactoring.  That's not just isolated engineer nit-picking.  However, for
non-trivial projects, refactoring is always anti-social in the short term.
It impacts projects other than your own, projects you don't even know
about. One change causes work for N developers.  Given these twin opposing
goals, the key, as ever, is finding the right balance.

Much like "feature freeze" in other software projects, developing a policy
that opens and closes windows for code movement and major disruptive
changes seems prudent.  One week of code movement & cosmetics followed by 3
weeks without, for example.  Part of open source parallel development
is *social
signalling*:  Signal to developers when certain changes are favored or not,
then trust they can handle the rest from there.

While recent code movement commits themselves are individually ACK-worthy,
professionally executed and moving towards a positive goal, I think the
project could strike a better balance when it comes to disruptive cosmetic
changes, a balance that better encourages developers to work on more
involved Bitcoin Core projects.


-- 
Jeff Garzik
Bitcoin core developer and open source evangelist
BitPay, Inc.      https://bitpay.com/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141216/949232b1/attachment.html>

From hozer at hozed.org  Tue Dec 16 19:24:15 2014
From: hozer at hozed.org (Troy Benjegerdes)
Date: Tue, 16 Dec 2014 13:24:15 -0600
Subject: [Bitcoin-development] Open development processes and reddit
 charms
In-Reply-To: <CAJHLa0M0YeEWWaP4gNpwnaDq56w=AHW_kmLr=f3AVvHDB89SNA@mail.gmail.com>
References: <CAJHLa0M0YeEWWaP4gNpwnaDq56w=AHW_kmLr=f3AVvHDB89SNA@mail.gmail.com>
Message-ID: <20141216192415.GQ29130@nl.grid.coop>

Thank you Jeff.

Having looked at a lot of linux code, and now a lot of bitcoin code, the
biggest long-term systemic risk I see is that Bitcoin has is the lack of 
code janitors.

The problem is that janitoring was *disruptive* for non-x86 linux architectures
when it first got going, and it's going to be very disruptive for bitcoin as
well, but it **needs** to happen. 

The code is too complex and hard to follow as it is now. (now, I could just
be speaking because I haven't paid the social debt of looking at the latest
bitcoin code, including libconsensus), but there really needs to be a focus
on readability, maintainability, and (as much as I hate to say it) a rather
hard-line policy on coding standards.

I don't care which tabbing style or column width you pick, but **pick one**,
and enforce it across the entire codebase.

Maybe this should be bitcoin-stable, and bitcoin-devel, with a 6-9 month
social expectation of minimal cosmetic changes in -stable, with a 1 month
'merge window' where -devel turns into -stable.


On Tue, Dec 16, 2014 at 12:59:06PM -0500, Jeff Garzik wrote:
> It can be useful to review open source development processes from time to
> time.  This reddit thread[1] serves use both as a case study, and also a
> moment of OSS process introduction for newbies.
> [1]
> http://www.reddit.com/r/Bitcoin/comments/2pd0zy/peter_todd_is_saying_shoddy_development_on_v010/
> 
> 
> 
> 
> *Dirty Laundry*
> When building businesses or commercial software projects, outsiders
> typically hear little about the internals of project development.  The
> public only hears what the companies release, which is prepped and
> polished. Internal disagreements, schedule slips, engineer fistfights are
> all unseen.
> 
> Open source development is the opposite.  The goal is radical
> transparency.  Inevitably there is private chatter (0day bugs etc.), but
> the default is openness.  This means that is it normal practice to "air
> dirty laundry in public."  Engineers will disagree, sometimes quietly,
> sometimes loudly, sometimes rudely and with ad hominem attacks.  On the
> Internet, there is a pile-on effect, where informed and uninformed
> supporters add their 0.02 BTC.
> 
> Competing interests cloud the issues further.  Engineers are typically
> employed by an organization, as a technology matures.  Those organizations
> have different strategies and motivations.  These organizations will
> sponsor work they find beneficial.  Sometimes those orgs are non-profit
> foundations, sometimes for-profit corporations.  Sometimes that work is
> maintenance ("keep it running"), sometimes that work is developing new,
> competitive features that company feels will give it a better market
> position.  In a transparent development environment, all parties are
> hyperaware of these competing interests.  Internet natterers painstakingly
> document and repeat every conspiracy theory about Bitcoin Foundation,
> Blockstream, BitPay, various altcoin developers, and more as a result of
> these competing interests.
> 
> Bitcoin and altcoin development adds an interesting new dimension.
> Sometimes engineers have a more direct conflict of interest, in that the
> technology they are developing is also potentially their road to instant
> $millions.  Investors, amateur and professional, have direct stakes in a
> certain coin or coin technology.  Engineers also have an emotional stake in
> technology they design and nurture.  This results in incentives where
> supporters of a non-bitcoin technology work very hard to thump bitcoin.
> And vice versa.  Even inside bitcoin, you see "tree chains vs. side chains"
> threads of a similar stripe.  This can lead to a very skewed debate.
> 
> That should not distract from the engineering discussion.  Starting from
> first principles, Assume Good Faith[2].  Most engineers in open source tend
> to mean what they say.  Typically they speak for themselves first, and
> their employers value that engineer's freedom of opinion.  Pay attention to
> the engineers actually working on the technology, and less attention to the
> noise bubbling around the Internet like the kindergarten game of grapevine.
> [2] http://en.wikipedia.org/wiki/Wikipedia:Assume_good_faith
> 
> Being open and transparent means engineering disagreements happen in
> public.  This is normal.  Open source engineers live an aquarium life[3].
> [3] https://www.youtube.com/watch?v=QKe-aO44R7k
> 
> 
> 
> 
> *What the fork?*
> In this case, a tweet suggests consensus bug risks, which reddit account
> "treeorsidechains" hyperbolizes into a dramatic headline[1].  However, the
> headline would seem to be the opposite of the truth.  Several changes were
> merged during 0.10 development which move snippets of source code into new
> files and new sub-directories.  The general direction of this work is
> creating a "libconsensus" library that carefully encapsulates consensus
> code in a manner usable by external projects.  This is a good thing.
> 
> The development was performed quite responsible:  Multiple developers would
> verify each cosmetic change, ensuring no behavior changes had been
> accidentally (or maliciously!) introduced.  Each pull request receives a
> full multi-platform build + automated testing, over and above individual
> dev testing.  Comparisons at the assembly language level were sometimes
> made in critical areas, to ensure zero before-and-after change.  Each
> transformation gets the Bitcoin Core codebase to a more sustainable, more
> reusable state.
> 
> Certainly zero-change is the most conservative approach. Strictly speaking,
> that has the lowest consensus risk.  But that is a short term mentality.
> Both Bitcoin Core and the larger ecosystem will benefit when the "hairball"
> pile of source code is cleaned up.  Progress has been made on that front in
> the past 2 years, and continues.   *Long term*, combined with the
> "libconsensus" work, that leads to less community-wide risk.
> 
> The key is balance.  Continue software engineering practices -- like those
> just mentioned above -- that enable change with least consensus risk.  Part
> of those practices is review at each step of the development process:
> social media thought bubble, mailing list post, pull request, git merge,
> pre-release & release.  It probably seems chaotic at times.  In effect,
> git[hub] and the Internet enable a dynamic system of review and feedback,
> where each stage provides a check-and-balance for bad ideas and bad
> software changes.  It's a human process, designed to acknowledge and handle
> that human engineers are fallible and might make mistakes (or be
> coerced/under duress!).  History and field experience will be the ultimate
> judge, but I think Bitcoin Core is doing good on this score, all things
> considered.
> 
> At the end of the day, while no change is without risk, version 0.10 work
> was done with attention to consensus risk at multiple levels (not just
> short term).
> 
> 
> 
> 
> *Technical and social debt*
> Working on the Linux kernel was an interesting experience that combined
> git-driven parallel development and a similar source code hairball.  One of
> the things that quickly became apparent is that cosmetic patches,
> especially code movement, was hugely disruptive.  Some even termed it
> anti-social.  To understand why, it is important to consider how modern
> software changes are developed:
> 
> Developers work in parallel on their personal computers to develop XYZ
> change, then submit their change "upstream" as a github pull request.  Then
> time passes.  If code movement and refactoring changes are accepted
> upstream before XYZ, then the developer is forced update XYZ -- typically
> trivial fixes, re-review XYZ, and re-test XYZ to ensure it remains in a
> known-working state.
> 
> Seemingly cosmetic changes such as code movement have a ripple effect on
> participating developers, and wider developer community.  Every developer
> who is *not* immediately merged upstream must bear the costs of updating
> their unmerged work.
> 
> Normally, this is expected.  Encouraging developers to build on top of
> "upstream" produces virtuous cycles.
> 
> However, a constant stream of code movement and cosmetic changes may
> produce a constant stream of disruption to developers working on
> non-trivial features that take a bit longer to develop before going
> upstream.  Trivial changes are encouraged, and non-trivial changes face a
> binary choice of (a) be merged immediately or (b) bear added re-base,
> re-view, re-test costs.
> 
> Taken over a timescale of months, I argue that a steady stream of cosmetic
> code movement changes serves as a disincentive to developers working with
> upstream.  Each upstream breakage has a ripple effect to all developers
> downstream, and imposes some added chance of newly introduced bugs on
> downstream developers.  I'll call this "social debt", a sort of technical
> debt[4] for developers.
> [4] http://en.wikipedia.org/wiki/Technical_debt
> 
> As mentioned above, the libconsensus and code movement work is a net gain.
> The codebase needs cleaning up.  Each change however incurs a little bit of
> social debt.  Life is a little bit harder on people trying to get work into
> the tree.  Developers are a little bit more discouraged at the busy-work
> they must perform.  Non-trivial pull requests take a little bit longer to
> approve, because they take a little bit more work to rebase (again).
> 
> A steady flow of code movement and cosmetic breakage into the tree may be a
> net gain, but it also incurs a *lot* of social debt.  In such situations,
> developers find that tested, working out-of-tree code repeatedly stops
> working *during the process of trying to get that work in-tree*.  Taken
> over time, it discourages working on the tree.  It is rational to sit back,
> *not* work on the tree, let the breakage stop, and then pick up the pieces.
> 
> 
> 
> 
> *Paradox Unwound*
> Bitcoin Core, then, is pulled in opposite directions by a familiar
> problem.  It is generally agreed that the codebase needs further
> refactoring.  That's not just isolated engineer nit-picking.  However, for
> non-trivial projects, refactoring is always anti-social in the short term.
> It impacts projects other than your own, projects you don't even know
> about. One change causes work for N developers.  Given these twin opposing
> goals, the key, as ever, is finding the right balance.
> 
> Much like "feature freeze" in other software projects, developing a policy
> that opens and closes windows for code movement and major disruptive
> changes seems prudent.  One week of code movement & cosmetics followed by 3
> weeks without, for example.  Part of open source parallel development
> is *social
> signalling*:  Signal to developers when certain changes are favored or not,
> then trust they can handle the rest from there.
> 
> While recent code movement commits themselves are individually ACK-worthy,
> professionally executed and moving towards a positive goal, I think the
> project could strike a better balance when it comes to disruptive cosmetic
> changes, a balance that better encourages developers to work on more
> involved Bitcoin Core projects.





From snow.paul at gmail.com  Tue Dec 16 20:28:29 2014
From: snow.paul at gmail.com (paul snow)
Date: Tue, 16 Dec 2014 14:28:29 -0600
Subject: [Bitcoin-development] Setting the record straight on
	Proof-of-Publication
Message-ID: <CAMU7uitZX3DEQri3nqC4vS+cs35MgtPd9CDi7Q_qNn7j6WsaCg@mail.gmail.com>

Peter provides an excellent summary of Proof of Publication, which starts
with defining it as being composed of a solution to the double spend
problem.  He requires Proof-of-receipt (proof every member of p in audience
P has received a message m), Proof-of-non-publication (proof a message m
has not been published to an audience P), and Proof-of-membership (proof
some q is a member of P).

He goes on to state (curiously) that Factom cannot provide Proof of
Publication.

Proof of Audience
=============

Let's first satisfy the easier proofs. A Factom user can know they are in
the Factom audience if they have access to the Bitcoin Blockchain,
knowledge of Factom's first anchor (Merkle root stored in the blockchain)
and the Factom network for distributing Factom's structures.  They can
pretty much know that they are in the Audience.

Proof of Receipt
============

Proof of receipt is also pretty easy for the Factom user.  User submit
entries, and Factom publishes a Merkle Root to the Bitcoin Blockchain.  The
Merkle proof to the entry proves receipt.  To get the Merkle proof requires
access to Factom structures, which all in the audience have access to by
definition.  But the proof itself only requires the blockchain.

At this point the user can have a Merkle proof of their entry rooted in the
blockchain.

Proof of non-publication
==================

Last, can the Factom user have a  Proof-of-non-publication.  Well,
absolutely.  The Factom state limits the public keys that can be used to
write the anchors in the blockchain.  Entries that are not written with
those public keys are discounted out of hand.  Just like publishing in Mad
Magazine does not qualify if publishing a notice in the New York Times is
the standard.

The complaint Peter has that the user cannot see all the "child chains"
(what we call Factom Chains) is invalid.  The user can absolutely see all
the Directory Blocks (which documents all Factom Chains) if they have
access to Factom. But the user doesn't need to prove publication in all
chains.  Some of those chains are like Car Magazines, Math Textbooks,
Toaster manuals, etc. Without restricting the domain of publication there
is no proof of the negative. The negative must be proved in the standard of
publication, i.e. the user's chain.  And the user can in fact know their
chain, and can enumerate their chain, without regard to most of the other
data in Factom.

Peter seems to be operating under the assumption that the audience for a
Factom user must necessarily be limited to information found in the
blockchain.  Yet the user certainly should have access to Factom if they
are a Factom user.  Factom then is no different from the New York Times,
and the trust in Factom is less. As Peter says himself, he has to trust the
New York Times doesn't publish multiple versions of the same issue. The
user of the New York Times would have no way to know if there were other
versions of an issue outside of looking at all New York Times issues ever
published.

Factom on the other hand documents their "issues" on the blockchain.  Any
fork in publication is obvious as it would require different Bitcoin
addresses to be used, and the blocks would have to have validating
signatures of majorities of all the Factom servers. As long as a fork in
Factom can be clearly identified, and no fork exists, proof of the negative
is assured.  And upon a fork, one must assume the users will specify which
fork should be used.

Proof of publication does not require a system that cannot fork, since no
such non-trivial system exists.  What is required is that forks can be
detected, and that a path can be chosen to move forward.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141216/d02c40c2/attachment.html>

From btcdrak at gmail.com  Tue Dec 16 23:40:34 2014
From: btcdrak at gmail.com (Btc Drak)
Date: Tue, 16 Dec 2014 23:40:34 +0000
Subject: [Bitcoin-development] ACK NACK utACK "Concept ACK"
In-Reply-To: <CAJHLa0NtJqwPOFYYSkvrJZo+YwiJ6fzvmPY7wcP0GX0FN3E6CQ@mail.gmail.com>
References: <54876653.4020403@certimix.com> <548769FA.5040406@bluematt.me>
	<CA+s+GJAe9MeO+Sr0+2BRwu3q-Be5JQt_s_xdnBBEcquXqOyxcA@mail.gmail.com>
	<CAJHLa0NtJqwPOFYYSkvrJZo+YwiJ6fzvmPY7wcP0GX0FN3E6CQ@mail.gmail.com>
Message-ID: <CADJgMzsMOcwoeW+DJAG=iD-jHSWjr55isGBSUGEUXavUnyVmQA@mail.gmail.com>

Would someone also clarify the use of "nit" for nitpicking and how it plays
in the role of consensus?
It seems like it's used for minor complaints/preferences.

Drak

On Wed, Dec 10, 2014 at 3:52 PM, Jeff Garzik <jgarzik at bitpay.com> wrote:
>
> On Wed, Dec 10, 2014 at 1:47 AM, Wladimir <laanwj at gmail.com> wrote:
>
>> Concept ACK -> agree with the idea and overall direction, but haven't
>> reviewed the code changes nor tested it
>>
>
> Concept ACK -> like the idea; the code may need rewriting (or haven't
> reviewed).
>
> --
> Jeff Garzik
> Bitcoin core developer and open source evangelist
> BitPay, Inc.      https://bitpay.com/
>
>
> ------------------------------------------------------------------------------
> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server
> from Actuate! Instantly Supercharge Your Business Reports and Dashboards
> with Interactivity, Sharing, Native Excel Exports, App Integration & more
> Get technology previously reserved for billion-dollar corporations, FREE
>
> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141216/55cd726a/attachment.html>

From odinn.cyberguerrilla at riseup.net  Wed Dec 17 01:16:30 2014
From: odinn.cyberguerrilla at riseup.net (odinn)
Date: Wed, 17 Dec 2014 01:16:30 +0000
Subject: [Bitcoin-development] Setting the record straight on
	Proof-of-Publication
In-Reply-To: <20141215045958.GD23859@savin.petertodd.org>
References: <20141212090551.GA8259@muck> <548AF08E.6080408@riseup.net>
	<20141215045958.GD23859@savin.petertodd.org>
Message-ID: <5490D96E.8030604@riseup.net>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

bleep bloop

Peter Todd:
> On Fri, Dec 12, 2014 at 01:41:34PM +0000, odinn wrote:
>> Peter... It kind of sounds to me that (as fine of a position
>> paper as this is) on _certain_ points, you're falling prey to the
>> "but it's inefficient, but it's a scamcoin, but luke-jr told me
>> so" argument...
> 
> I prefer to make robust arguments; if I can start with accepting
> that 95% of what my opponents say is true, yet still end up being
> correct, all the better!
> 
>> I think the Mastercoin devs are doing fine work and I consider
>> the zerocash devs to have developed (in v2, mint and pour) to
>> have developed something that will really turn the world on its
>> ear, but what do I know? Nothing.  Nothing at all.
> 
> My personal opinion is that what Mastercoin has started will turn
> the world on its ear, but I'd be surprised if the succesful
> implementations of the underlying ideas come from that team. But
> there's nothing surprising about that - when was the last time you
> used Netscape Navigator, let alone NCSA Mosaic?
> 

- -- 
http://abis.io ~
"a protocol concept to enable decentralization
and expansion of a giving economy, and a new social good"
https://keybase.io/odinn
-----BEGIN PGP SIGNATURE-----

iQEcBAEBCgAGBQJUkNluAAoJEGxwq/inSG8CKy0IAJmCUmDbaCx33/km0J2mP7ha
kxX3fxiPpicD8hXa4FXBsrYqj7ZFu0OmFOU/ei0AXMOuu94rQdIp6hon3f5GO73J
WVT2Toqd2GTCXhmddyqtOzZ5mYOyZhlJUYlNjbwTmlk+U2hQbZC1aJ4AKdmjQn5v
9DFkZfqBSsNhcoLCKoVqY3l4qzw0XqeL6fOYkz2H9AssWdcUV9JB5C0wm8rI70AX
qcxABgrKDwhThWgHyHGZXHLCvRRpMUFFVbzO67BPZA2R+gXYtOAVDozl7jdx7PLl
x3nyzZK3pX1bqcT2T5fD8wQtu4yJ3RCBVWzHfrA5MF6q4Yh6DEh7DnO8ccOnPlk=
=1os7
-----END PGP SIGNATURE-----



From laanwj at gmail.com  Wed Dec 17 08:44:45 2014
From: laanwj at gmail.com (Wladimir)
Date: Wed, 17 Dec 2014 08:44:45 +0000
Subject: [Bitcoin-development] ACK NACK utACK "Concept ACK"
In-Reply-To: <48E6B6DA-F977-409C-AEDD-53572986438D@gmail.com>
References: <54876653.4020403@certimix.com> <548769FA.5040406@bluematt.me>
	<CA+s+GJAe9MeO+Sr0+2BRwu3q-Be5JQt_s_xdnBBEcquXqOyxcA@mail.gmail.com>
	<CA+s+GJA0BDMaa2+A7QJdz08Ck4PFQcXs2dg22hi5PCMsGu7dqw@mail.gmail.com>
	<48E6B6DA-F977-409C-AEDD-53572986438D@gmail.com>
Message-ID: <CA+s+GJCpApaQuv6GQc2E-hGdKXM_csADUHa7UcWvYmrXJ0p=NQ@mail.gmail.com>

On Wed, Dec 10, 2014 at 3:45 PM, Austin Walne <austin.walne at gmail.com> wrote:
> I've had these same questions myself. I'm happy to write up some documentation this afternoon. I can draft something based on this thread. What other key terminology should be included?

Fanquake already started on that (but didn't even mention it here!)
https://github.com/bitcoin/bitcoin/pull/5468

Wladimir



From laanwj at gmail.com  Wed Dec 17 08:53:16 2014
From: laanwj at gmail.com (Wladimir)
Date: Wed, 17 Dec 2014 08:53:16 +0000
Subject: [Bitcoin-development] Open development processes and reddit
	charms
In-Reply-To: <20141216192415.GQ29130@nl.grid.coop>
References: <CAJHLa0M0YeEWWaP4gNpwnaDq56w=AHW_kmLr=f3AVvHDB89SNA@mail.gmail.com>
	<20141216192415.GQ29130@nl.grid.coop>
Message-ID: <CA+s+GJCAVB35EYPSK2ZgZW-o=Ujxk-RKtZ16VP63V2AaTB4gOg@mail.gmail.com>

> I don't care which tabbing style or column width you pick, but **pick one**,
> and enforce it across the entire codebase.

See https://github.com/bitcoin/bitcoin/pull/5387

Wladimir



From gacrux at gmail.com  Wed Dec 17 11:55:28 2014
From: gacrux at gmail.com (Gareth Williams)
Date: Wed, 17 Dec 2014 22:55:28 +1100
Subject: [Bitcoin-development] Setting the record straight on
	Proof-of-Publication
In-Reply-To: <20141215045236.GB23859@savin.petertodd.org>
References: <20141212090551.GA8259@muck> <548ADED1.6060300@gmail.com>
	<CAE28kUR-PLzMGC23ETesc2Bz1_F1JfgcqyMW4qFvV5Vjk+ubbg@mail.gmail.com>
	<CAOG=w-v3qjG3zd_WhfFU-OGnsHZEuYvY82eL4GqcdgY6np5bvA@mail.gmail.com>
	<CAE28kUSZcGrFL3OMf=uOJ2=NQ89M54FOhR_iOXkEubrb6qqVAg@mail.gmail.com>
	<548C3FE6.9090508@gmail.com>
	<20141215045236.GB23859@savin.petertodd.org>
Message-ID: <CALohRkgbHvLCwAY0+2zpd-LwRxnntzcpPuUjU4zDEz=oODaK1w@mail.gmail.com>

On Mon, Dec 15, 2014 at 3:52 PM, Peter Todd <pete at petertodd.org> wrote:
>> Comparisons with the SPV security of sidechains are fallacious. The
>> alternative to a proof-of-publication system reliant on client-side
>> validation is a blockchain. The question of whether the token used on
>> said blockchain should be two-way-pegged to BTC is completely orthogonal.
>>
>> (ie. yes, sidechains are "economically secure", in that you're reduced
>> to balancing economic incentives to avoid peg theft. But sidechains also
>> give us something unique in return - the ability to innovate without
>> needing to start new artificial scarcity races. Nothing else can do that.)
>
> I covered this in my original post: 1-way-pegs allow the creation of new
> valuable tokens without those tokens being useful for speculation.

I stand corrected. A permanent 1-way-peg is sufficient to preserve
scarcity; "nothing else can do that" WRT 2-way-pegs was overreaching.

I still don't see what "2-way-peg vs. 1-way-peg" has to do with
"embedded consensus vs. blockchain consensus" though, and feel it
disingenious to conflate them.

Blockchain consensus (eg. sidechains) can utilise either mechanism,
1-way-peg or 2-way-peg. Arguments in favour of 1-way-peg are
interesting, but they're ultimatley just arguments in favour of one
type of sidechain over another.

Arguments in favour of embedded consensus - and I feel I'm being
generous with the term "consensus" here - should surely stand on their
own merit against blockchain consensus, if they're to be convincing.

> Of course even without 1-way-pegs there's a much more important issue
> with your objection: worrying about creating new artificial scarcity
> races while innovating is fundementally a *moralistic* and *regulatory*
> concern that has no little if any bearing on whether or not the systems
> created are useful and secure. It's also an objection that raises
> serious questions about conflicts of interest between giving accurate
> and honest technical advice and promoting ways of using Bitcoin that
> will drive the price up.

IMO the question of whether scarcity can be preserved while enabling
innovation bears heavily on the liklihood of longterm viability of
said innovations - and perhaps of Bitcoin itself.

FWIW I'll happily declare that I hold a modest amount of BTC and have
an interest in the price appreciating. I'm sure you'll admit you're
hardly an impartial party in this discussion yourself Peter :) But it
really shouldn't matter. I'm not here today to make it, but I think
the argument for preservation of scarcity stands quite well on its own
merits - as rightly it should, regardless of anybody's interests.

> A number of mechanisms for detecting divergence are possible in embedded
> consensus systems, some of them even natural outcomes. For instance
> transactions can contain a hash of the previous consensus state, thereby
> creating an indicator of consensus measured in terms of economic stake.
> Extending that idea many anti-censorship proposals are to use such state
> hashes as encryption keys - if you are out of consensus you won't even
> see the transaction. (and you can't be double-spent either if
> implemented correctly; see my other reply to this thread today)

<snip>

> Indeed I did, which is why I worked out a better way to do upgrades
> almost a year ago:
>
> http://www.mail-archive.com/bitcoin-development at lists.sourceforge.net/msg06578.html

<snip>

> The quality of Counterparty's software engineering has no bearing on
> whether or not the underlying idea is a good one; you wouldn't say ring
> signatures are an inherently bad idea just because the CryptoNote
> implementation of them is atrocious.

Very interesting. I admit I hadn't come across these ideas before; I
really must search the archive before posting :) They certainly offer
a measure of robustness over the naive approach. I'm not sure they
address my primary concerns however, WRT how consensus is demonstrated
and incentivised.

I know what my own node considers valid transaction history; how can I
be confident that everyone else takes the same view? For contrast,
with blockchain consensus, I can be confident that there is consensus
on the longest chain observed. If I receive a new transaction, simply
waiting for it to be buried under N blocks of PoW provides a high
level of confidence that everyone else considers it valid.

The obvious "embedded consensus" answer of "wait until N other
transactions have occurred that include a hash of system state that
includes your transaction" doesn't provide me with any confidence; it
could be simulated with a Sybil attack.

<snip>

> I prefer to make robust arguments; if I can start with accepting that
> 95% of what my opponents say is true, yet still end up being correct,
> all the better!

Indeed :) To avoid wasting time it's only ever worth arguing against
the strongest opposing position you're aware of (whether your opponent
is aware of it or not.)

https://en.wikipedia.org/wiki/Principle_of_charity



From snow.paul at gmail.com  Wed Dec 17 22:20:33 2014
From: snow.paul at gmail.com (paul snow)
Date: Wed, 17 Dec 2014 16:20:33 -0600
Subject: [Bitcoin-development] Setting the record straight on
	Proof-of-Publication
Message-ID: <CAMU7uis0A=BEOgPw=7Z_9F744hrXaVMB_p_D3Z7MYxk40oL+9A@mail.gmail.com>

[[Since I sent this while the List Server was down, it didn't actually go
to everyone.  Forgive me if you ended up with two copies.]]

Peter provides an excellent summary of Proof of Publication, which starts
with defining it as being composed of a solution to the double spend
problem.  He requires Proof-of-receipt (proof every member of p in audience
P has received a message m), Proof-of-non-publication (proof a message m
has not been published to an audience P), and Proof-of-membership (proof
some q is a member of P).

He goes on to state (curiously) that Factom cannot provide Proof of
Publication.

Proof of Membership
================

Let's first satisfy the easier proofs. A Factom user can know they are a
member of the Factom audience if they have access to the Bitcoin
Blockchain, knowledge of Factom's first anchor (Merkle root stored in the
blockchain) and the Factom network for distributing Factom's structures.
They can pretty much know that they are in the Audience.

Proof of Receipt
============

Proof of receipt is also pretty easy for the Factom user.  User submit
entries, and Factom publishes a Merkle Root to the Bitcoin Blockchain.  The
Merkle proof to the entry proves receipt.  To get the Merkle proof requires
access to Factom structures, which all in the audience have access to by
definition.  But the proof itself only requires the blockchain.

At this point the user can have a Merkle proof of their entry rooted in the
blockchain.

Proof of non-publication
==================

Last, can the Factom user have a  Proof-of-non-publication?  Well,
absolutely.  The Factom state limits the public keys that can be used to
write the anchors in the blockchain.  Transactions in Bitcoin that are not
signed with those public keys are discounted out of hand.  Just like
publishing in Mad Magazine does not qualify if publishing a notice in the
New York Times is the standard.

The complaint Peter has that the user cannot see all the "child chains"
(what we call Factom Chains) is invalid.  The user can absolutely see all
the Directory Blocks (which documents all Factom Chains) if they have
access to Factom. But the user doesn't need to prove publication in all
chains.  Some of those chains are like Car Magazines, Math Textbooks,
Toaster manuals, etc. Without restricting the domain of publication there
is no proof of the negative. The negative must be proved in the standard of
publication, i.e. the user's chain.  And the user can in fact know their
chain, and can enumerate their chain, without regard to most of the other
data in Factom.

Peter seems to be operating under the assumption that the audience for a
Factom user must necessarily be limited to information found in the
blockchain.  Yet the user certainly should have access to Factom if they
are a Factom user.  Factom then is no different from the New York Times,
and the trust in Factom is less. As Peter says himself, he has to trust the
New York Times doesn't publish multiple versions of the same issue. The
user of the New York Times would have no way to know if there were other
versions of an issue outside of looking at all New York Times issues ever
published.

Factom on the other hand documents their "issues" on the blockchain.  Any
fork in publication is obvious as it would require different Bitcoin
addresses to be used, and the blocks would have to have validating
signatures of majorities of all the Factom servers. As long as a fork in
Factom can be clearly identified, and no fork exists, proof of the negative
is assured.  And upon a fork, one must assume the users will specify which
fork should be used.

Proof of publication does not require a system that cannot fork, since no
such non-trivial system exists.  What is required is that forks can be
detected, and that a path can be chosen to move forward.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141217/ec077915/attachment.html>

From 21xe14 at gmail.com  Thu Dec 18 05:56:18 2014
From: 21xe14 at gmail.com (21E14)
Date: Thu, 18 Dec 2014 05:56:18 +0000
Subject: [Bitcoin-development] Open development processes and reddit
	charms
In-Reply-To: <CAJHLa0M0YeEWWaP4gNpwnaDq56w=AHW_kmLr=f3AVvHDB89SNA@mail.gmail.com>
References: <CAJHLa0M0YeEWWaP4gNpwnaDq56w=AHW_kmLr=f3AVvHDB89SNA@mail.gmail.com>
Message-ID: <CAFZQHkHPoWBK5nq3DYFWUrSTTbqYn+x+DzwpGUxmWHSyJ6bgzw@mail.gmail.com>

I'll pick up where you left off, Jeff. The thought process behind the
Bitcoin Core threading model, platform support, libification, dependency
management, core data structures, DoS mitigation, script evolution,
scalability roadmap... just to scratch the surface, is likely never going
to be apparent entirely from the source code itself, and will not, in its
current form, be easily understood before digesting repository docs, repo
issues, pull requests, IRC logs, mailing list archives (open and closed),
forum posts, wiki articles, historical repositories, the foundation's
technical blog, whitepapers, to name a few. I'd rather not guess how many
have got a grip on it. If any, across the entire spectrum. It may be the
bottleneck to address. I encourage everyone to take a look at the C#
Language Design Notes* on codeplex. We'll know we've met the challenge when
folks are no longer digging up gmaxwell's IRC comments to understand the
rationale on nScriptCheckThreads, nor having to refer to sipa's
stackexchange to figure out chainstate & blockindex key/value pairs.

*
https://roslyn.codeplex.com/wikipage?title=CSharp%20Language%20Design%20Notes&referringTitle=Documentation


On Tue, Dec 16, 2014 at 5:59 PM, Jeff Garzik <jgarzik at bitpay.com> wrote:
>
>
> It can be useful to review open source development processes from time to
> time.  This reddit thread[1] serves use both as a case study, and also a
> moment of OSS process introduction for newbies.
> [1]
> http://www.reddit.com/r/Bitcoin/comments/2pd0zy/peter_todd_is_saying_shoddy_development_on_v010/
>
>
>
>
> *Dirty Laundry*
> When building businesses or commercial software projects, outsiders
> typically hear little about the internals of project development.  The
> public only hears what the companies release, which is prepped and
> polished. Internal disagreements, schedule slips, engineer fistfights are
> all unseen.
>
> Open source development is the opposite.  The goal is radical
> transparency.  Inevitably there is private chatter (0day bugs etc.), but
> the default is openness.  This means that is it normal practice to "air
> dirty laundry in public."  Engineers will disagree, sometimes quietly,
> sometimes loudly, sometimes rudely and with ad hominem attacks.  On the
> Internet, there is a pile-on effect, where informed and uninformed
> supporters add their 0.02 BTC.
>
> Competing interests cloud the issues further.  Engineers are typically
> employed by an organization, as a technology matures.  Those organizations
> have different strategies and motivations.  These organizations will
> sponsor work they find beneficial.  Sometimes those orgs are non-profit
> foundations, sometimes for-profit corporations.  Sometimes that work is
> maintenance ("keep it running"), sometimes that work is developing new,
> competitive features that company feels will give it a better market
> position.  In a transparent development environment, all parties are
> hyperaware of these competing interests.  Internet natterers painstakingly
> document and repeat every conspiracy theory about Bitcoin Foundation,
> Blockstream, BitPay, various altcoin developers, and more as a result of
> these competing interests.
>
> Bitcoin and altcoin development adds an interesting new dimension.
> Sometimes engineers have a more direct conflict of interest, in that the
> technology they are developing is also potentially their road to instant
> $millions.  Investors, amateur and professional, have direct stakes in a
> certain coin or coin technology.  Engineers also have an emotional stake in
> technology they design and nurture.  This results in incentives where
> supporters of a non-bitcoin technology work very hard to thump bitcoin.
> And vice versa.  Even inside bitcoin, you see "tree chains vs. side chains"
> threads of a similar stripe.  This can lead to a very skewed debate.
>
> That should not distract from the engineering discussion.  Starting from
> first principles, Assume Good Faith[2].  Most engineers in open source tend
> to mean what they say.  Typically they speak for themselves first, and
> their employers value that engineer's freedom of opinion.  Pay attention to
> the engineers actually working on the technology, and less attention to the
> noise bubbling around the Internet like the kindergarten game of grapevine.
> [2] http://en.wikipedia.org/wiki/Wikipedia:Assume_good_faith
>
> Being open and transparent means engineering disagreements happen in
> public.  This is normal.  Open source engineers live an aquarium life[3].
> [3] https://www.youtube.com/watch?v=QKe-aO44R7k
>
>
>
>
> *What the fork?*
> In this case, a tweet suggests consensus bug risks, which reddit account
> "treeorsidechains" hyperbolizes into a dramatic headline[1].  However, the
> headline would seem to be the opposite of the truth.  Several changes were
> merged during 0.10 development which move snippets of source code into new
> files and new sub-directories.  The general direction of this work is
> creating a "libconsensus" library that carefully encapsulates consensus
> code in a manner usable by external projects.  This is a good thing.
>
> The development was performed quite responsible:  Multiple developers
> would verify each cosmetic change, ensuring no behavior changes had been
> accidentally (or maliciously!) introduced.  Each pull request receives a
> full multi-platform build + automated testing, over and above individual
> dev testing.  Comparisons at the assembly language level were sometimes
> made in critical areas, to ensure zero before-and-after change.  Each
> transformation gets the Bitcoin Core codebase to a more sustainable, more
> reusable state.
>
> Certainly zero-change is the most conservative approach. Strictly
> speaking, that has the lowest consensus risk.  But that is a short term
> mentality.  Both Bitcoin Core and the larger ecosystem will benefit when
> the "hairball" pile of source code is cleaned up.  Progress has been made
> on that front in the past 2 years, and continues.   *Long term*, combined
> with the "libconsensus" work, that leads to less community-wide risk.
>
> The key is balance.  Continue software engineering practices -- like those
> just mentioned above -- that enable change with least consensus risk.  Part
> of those practices is review at each step of the development process:
> social media thought bubble, mailing list post, pull request, git merge,
> pre-release & release.  It probably seems chaotic at times.  In effect,
> git[hub] and the Internet enable a dynamic system of review and feedback,
> where each stage provides a check-and-balance for bad ideas and bad
> software changes.  It's a human process, designed to acknowledge and handle
> that human engineers are fallible and might make mistakes (or be
> coerced/under duress!).  History and field experience will be the ultimate
> judge, but I think Bitcoin Core is doing good on this score, all things
> considered.
>
> At the end of the day, while no change is without risk, version 0.10 work
> was done with attention to consensus risk at multiple levels (not just
> short term).
>
>
>
>
> *Technical and social debt*
> Working on the Linux kernel was an interesting experience that combined
> git-driven parallel development and a similar source code hairball.  One of
> the things that quickly became apparent is that cosmetic patches,
> especially code movement, was hugely disruptive.  Some even termed it
> anti-social.  To understand why, it is important to consider how modern
> software changes are developed:
>
> Developers work in parallel on their personal computers to develop XYZ
> change, then submit their change "upstream" as a github pull request.  Then
> time passes.  If code movement and refactoring changes are accepted
> upstream before XYZ, then the developer is forced update XYZ -- typically
> trivial fixes, re-review XYZ, and re-test XYZ to ensure it remains in a
> known-working state.
>
> Seemingly cosmetic changes such as code movement have a ripple effect on
> participating developers, and wider developer community.  Every developer
> who is *not* immediately merged upstream must bear the costs of updating
> their unmerged work.
>
> Normally, this is expected.  Encouraging developers to build on top of
> "upstream" produces virtuous cycles.
>
> However, a constant stream of code movement and cosmetic changes may
> produce a constant stream of disruption to developers working on
> non-trivial features that take a bit longer to develop before going
> upstream.  Trivial changes are encouraged, and non-trivial changes face a
> binary choice of (a) be merged immediately or (b) bear added re-base,
> re-view, re-test costs.
>
> Taken over a timescale of months, I argue that a steady stream of cosmetic
> code movement changes serves as a disincentive to developers working with
> upstream.  Each upstream breakage has a ripple effect to all developers
> downstream, and imposes some added chance of newly introduced bugs on
> downstream developers.  I'll call this "social debt", a sort of technical
> debt[4] for developers.
> [4] http://en.wikipedia.org/wiki/Technical_debt
>
> As mentioned above, the libconsensus and code movement work is a net
> gain.  The codebase needs cleaning up.  Each change however incurs a little
> bit of social debt.  Life is a little bit harder on people trying to get
> work into the tree.  Developers are a little bit more discouraged at the
> busy-work they must perform.  Non-trivial pull requests take a little bit
> longer to approve, because they take a little bit more work to rebase
> (again).
>
> A steady flow of code movement and cosmetic breakage into the tree may be
> a net gain, but it also incurs a *lot* of social debt.  In such
> situations, developers find that tested, working out-of-tree code
> repeatedly stops working *during the process of trying to get that work
> in-tree*.  Taken over time, it discourages working on the tree.  It is
> rational to sit back, *not* work on the tree, let the breakage stop, and
> then pick up the pieces.
>
>
>
>
> *Paradox Unwound*
> Bitcoin Core, then, is pulled in opposite directions by a familiar
> problem.  It is generally agreed that the codebase needs further
> refactoring.  That's not just isolated engineer nit-picking.  However, for
> non-trivial projects, refactoring is always anti-social in the short term.
> It impacts projects other than your own, projects you don't even know
> about. One change causes work for N developers.  Given these twin opposing
> goals, the key, as ever, is finding the right balance.
>
> Much like "feature freeze" in other software projects, developing a policy
> that opens and closes windows for code movement and major disruptive
> changes seems prudent.  One week of code movement & cosmetics followed by 3
> weeks without, for example.  Part of open source parallel development is *social
> signalling*:  Signal to developers when certain changes are favored or
> not, then trust they can handle the rest from there.
>
> While recent code movement commits themselves are individually ACK-worthy,
> professionally executed and moving towards a positive goal, I think the
> project could strike a better balance when it comes to disruptive cosmetic
> changes, a balance that better encourages developers to work on more
> involved Bitcoin Core projects.
>
>
> --
> Jeff Garzik
> Bitcoin core developer and open source evangelist
> BitPay, Inc.      https://bitpay.com/
>
>
> ------------------------------------------------------------------------------
> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server
> from Actuate! Instantly Supercharge Your Business Reports and Dashboards
> with Interactivity, Sharing, Native Excel Exports, App Integration & more
> Get technology previously reserved for billion-dollar corporations, FREE
>
> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141218/2fbf1055/attachment.html>

From tamas at bitsofproof.com  Thu Dec 18 16:23:53 2014
From: tamas at bitsofproof.com (Tamas Blummer)
Date: Thu, 18 Dec 2014 17:23:53 +0100
Subject: [Bitcoin-development] Merged mining a side chain with proof of
	burn on parent chain
In-Reply-To: <C90BC633-9BB0-4886-B818-02980ED3D6C4@bitsofproof.com>
References: <54876653.4020403@certimix.com> <548769FA.5040406@bluematt.me>
	<CA+s+GJAe9MeO+Sr0+2BRwu3q-Be5JQt_s_xdnBBEcquXqOyxcA@mail.gmail.com>
	<417518B4-1E4D-4467-BC87-95C9EAF0C599@bitsofproof.com>
	<C90BC633-9BB0-4886-B818-02980ED3D6C4@bitsofproof.com>
Message-ID: <09D82E62-C816-4BD9-8EE4-8CBD39C946C9@bitsofproof.com>

Moving further with the Idea:

Alternative to re-adjusting the lottery criteria, the side chain block candidate could be required to prove a work to be eligible for the burn lottery. 

A mix of required burn, work and luck could be tailored to achieve the desired "51% resilience? of the side chain. 

The side chain could use work for regular blocks and a much higher ?difficulty? parent chain burn lottery for less frequent ?checkpoints". 

Eg. the side chain difficulty of 1/n of Bitcoin is attainable for a small side chain miner community to advance its chain at Bitcoin?s speed. Simultaneously the block candidates
would be submitted to a Bitcoin burn lottery with 1/n odds, so the security of the side chain roughly equals that of Bitcoin at every successful burn mined checkpoint.

Tamas Blummer
Bits of Proof

On Dec 16, 2014, at 1:30 PM, Tamas Blummer <tamas at bitsofproof.com> wrote:

> Let me be more concrete in implementation details: 
> 
> 1) burn transaction sends at least n satoshis to an OP_RETURN h, 
> 2) h mod m matches the bitcoin block hash mod m, for the block the burn transaction was mined into.
> 3) The side chain block header hashes to h and also contains the bitcoin block hight.
> 4) a side chain block releases x new side coins
> 
> Since the burn hash does not reveal in advance which side chain it will be used for, the Bitcoin miner can not selectively block burn mining. They will include loosing bets for the Bitcoin fee. Bitcoin miner have no advantage over independent burn miner of the side chain.
> 
> Anyone who issues a burn transaction that complies the rules 1-3 has 1/m the chance to win the next block on the side chain. This implies a fair exchange rate of n*m satoshis = x side coins (at the margin).
> 
> Should two burn transactions fulfill the mod m lottery criteria, then we have a competing fork on the side chain. Just as for Bitcoin, the next block(s) will pick the winner. 
> 
> To contain fork rate, the parameter m would have to be adjusted dynamically, similar to Bitcoins difficulty. It needs to increase if fork rate increases and decrease if no valid block is burned with Bitcoin blocks. Unfortunately SPV can only prove the existence of a transaction, but not the non-existence of an alternative. Therefore the fork rate within a block cycle can not be evaluated with SPV proofs. 
> 
> Rational burn miner who frequently faces and loses head-to-head runs with a competing forks would increase his bet for the next burn cycle, as increasing the individual bet amount has the advantage that if he wins his victory is more stable. Remember the side chain trunk is selected as the one with highest cumulative burn.
> 
> Consequently cumulative burn within an adjustment period (measured in Bitcoin blocks) is expected to rise in face of high fork rate. If the sample period burn exceeds a target, then it would trigger a rise to the lottery criteria m, reducing the fork rate and vs.
> 
> Tamas Blummer
> Bits of Proof
> 
> On Dec 10, 2014, at 8:35 AM, Tamas Blummer <tamas at bitsofproof.com> wrote:
> 
>> 
>> We spend scarce resources external to the digital realm to create Bitcoin. Real world sacrifice is needed to avoid ?nothing at stake?  and sybil attacks. With Bitcoin we now have a scarce resource within the digital realm, so it appeals my intuition to re-use it for sacrifice instead of linking again an external, real world resource. 
>> 
>> In following I outline a new mining algorithm for side chains, that burn Bitcoins to secure them.
>> 
>> The side chain block validity rules would require that a transaction on the Bitcoin block chain provably destroys Bitcoins with an OP_RET output, that contains the hash of the block header of the side chain. To also introduce a lottery, the burn transaction?s hash is required to satisfy some function of the block hash it was included in on the Bitcoin block chain. For example modulo m of the burn transaction hash must match modulo m of the block hash, that is not known in advance.
>> 
>> Those who want to mine the side chain will assemble  side chain block candidates that comply the rules of the side chain, then a Bitcoin transaction burning to the hash of the block candidate and submit it to the Bitcoin network. Should he burn transaction be included into the Bitcoin block chain and the Bitcoin block?s hash satisfy the lottery criteria, then the block candidate can be submitted to extend the side chain.
>> 
>> A side chain block header sequence would be accepted as side chain trunk if a sequence of Bitcoin SPV proofs for burn transactions prove, that linked blocks have the highest cumulative burn, if compared to alternative sequences. 
>> 
>> The Bitcoin miner will include burn transactions because they offer Bitcoin fees. Bitcoin miner can not selectively block side chains since the hashes associated with the burn do not disclose which side chain or other project they are for. Here you have a ?merged mining? that does not need Bitcoin miner support or even consent.
>> 
>> Mining difficulty of the side chain could be adjusted by stepping up the required burn and/or hardening the criteria that links a burn proof transaction with the bitcoin block hash it is included in.
>> 
>> The difficulty to mine with burn would be dynamic and would also imply a floating exchange rate between Bitcoin and the side coin.
>> 
>> Tamas Blummer
>> Bits of Proof
>> 
>> 00000000000000001172380e63346e3e915b52fcbae838ba958948ac9aa85edd
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141218/ba26d4c3/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 496 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141218/ba26d4c3/attachment.sig>

From wbic16 at gmail.com  Sat Dec 20 07:42:23 2014
From: wbic16 at gmail.com (Will Bickford)
Date: Sat, 20 Dec 2014 01:42:23 -0600
Subject: [Bitcoin-development] Area of Focus
Message-ID: <CAB2qGxXDtxWxyLUCEZ9XQ4nP0U-Cj5Xiz9ac=vot1H+wzRCHrA@mail.gmail.com>

Hi all, I'm looking to help with Bitcoin core development in my spare time
(a few hours per week).

A little bit about me:
* I use C++ and Qt daily
* I love to automate and enhance software systems
* I enjoy root causing and fixing issues

I saw Gavin say we needed help with testing in a Reddit AMA a while ago.
I'm curious where I can make the best impact. Any feedback would be
appreciated. Thanks!

Will Bickford
"In Google We Trust"
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141220/e2726c10/attachment.html>

From bitcoin-list at bluematt.me  Sat Dec 20 08:57:53 2014
From: bitcoin-list at bluematt.me (Matt Corallo)
Date: Sat, 20 Dec 2014 08:57:53 +0000
Subject: [Bitcoin-development] Area of Focus
In-Reply-To: <CAB2qGxXDtxWxyLUCEZ9XQ4nP0U-Cj5Xiz9ac=vot1H+wzRCHrA@mail.gmail.com>
References: <CAB2qGxXDtxWxyLUCEZ9XQ4nP0U-Cj5Xiz9ac=vot1H+wzRCHrA@mail.gmail.com>
Message-ID: <54953A11.1060202@bluematt.me>

There was recently some discussion around dnsseeds. Currently some
dnsseeds are getting blocked by ISPs because the hosts they pick up
(which run bitcoin core nodes) often run rather web servers alongside
which serve malware or whatever else and thus end up on IP-based malware
blacklists.

Of course we really dont want to move off of DNS because it has this big
built-in anonymity network where the DNS seed servers only get
information about your ISP, not you, and its cached so you dont get as
much information about how many users are making those requests.

A potential solution might be supporting some subdomain which has
results XORed with some constant mask to tweak the real IP.

Additionally, it might be cool to stuff a TXT/AAAA/whatever record with
a signature of the results provided by the DNSseed operator.

Matt

On 12/20/14 07:42, Will Bickford wrote:
> Hi all, I'm looking to help with Bitcoin core development in my spare
> time (a few hours per week).
> 
> A little bit about me:
> * I use C++ and Qt daily
> * I love to automate and enhance software systems
> * I enjoy root causing and fixing issues
> 
> I saw Gavin say we needed help with testing in a Reddit AMA a while ago.
> I'm curious where I can make the best impact. Any feedback would be
> appreciated. Thanks!
> 
> Will Bickford
> "In Google We Trust"
> 
> 
> ------------------------------------------------------------------------------
> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server
> from Actuate! Instantly Supercharge Your Business Reports and Dashboards
> with Interactivity, Sharing, Native Excel Exports, App Integration & more
> Get technology previously reserved for billion-dollar corporations, FREE
> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk
> 
> 
> 
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> 



From roy at gnomon.org.uk  Sat Dec 20 10:08:17 2014
From: roy at gnomon.org.uk (Roy Badami)
Date: Sat, 20 Dec 2014 10:08:17 +0000
Subject: [Bitcoin-development] Area of Focus
In-Reply-To: <54953A11.1060202@bluematt.me>
References: <CAB2qGxXDtxWxyLUCEZ9XQ4nP0U-Cj5Xiz9ac=vot1H+wzRCHrA@mail.gmail.com>
	<54953A11.1060202@bluematt.me>
Message-ID: <20141220100816.GD7902@giles.gnomon.org.uk>

Why would we want to have anything to do with people who are hosting
malware?  Or do I misunderstand?

On Sat, Dec 20, 2014 at 08:57:53AM +0000, Matt Corallo wrote:
> There was recently some discussion around dnsseeds. Currently some
> dnsseeds are getting blocked by ISPs because the hosts they pick up
> (which run bitcoin core nodes) often run rather web servers alongside
> which serve malware or whatever else and thus end up on IP-based malware
> blacklists.
> 
> Of course we really dont want to move off of DNS because it has this big
> built-in anonymity network where the DNS seed servers only get
> information about your ISP, not you, and its cached so you dont get as
> much information about how many users are making those requests.
> 
> A potential solution might be supporting some subdomain which has
> results XORed with some constant mask to tweak the real IP.
> 
> Additionally, it might be cool to stuff a TXT/AAAA/whatever record with
> a signature of the results provided by the DNSseed operator.
> 
> Matt
> 
> On 12/20/14 07:42, Will Bickford wrote:
> > Hi all, I'm looking to help with Bitcoin core development in my spare
> > time (a few hours per week).
> > 
> > A little bit about me:
> > * I use C++ and Qt daily
> > * I love to automate and enhance software systems
> > * I enjoy root causing and fixing issues
> > 
> > I saw Gavin say we needed help with testing in a Reddit AMA a while ago.
> > I'm curious where I can make the best impact. Any feedback would be
> > appreciated. Thanks!
> > 
> > Will Bickford
> > "In Google We Trust"
> > 
> > 
> > ------------------------------------------------------------------------------
> > Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server
> > from Actuate! Instantly Supercharge Your Business Reports and Dashboards
> > with Interactivity, Sharing, Native Excel Exports, App Integration & more
> > Get technology previously reserved for billion-dollar corporations, FREE
> > http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk
> > 
> > 
> > 
> > _______________________________________________
> > Bitcoin-development mailing list
> > Bitcoin-development at lists.sourceforge.net
> > https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> > 
> 
> ------------------------------------------------------------------------------
> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server
> from Actuate! Instantly Supercharge Your Business Reports and Dashboards
> with Interactivity, Sharing, Native Excel Exports, App Integration & more
> Get technology previously reserved for billion-dollar corporations, FREE
> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> 



From jeremy at taplink.co  Sat Dec 20 11:14:28 2014
From: jeremy at taplink.co (Jeremy Spilman)
Date: Sat, 20 Dec 2014 03:14:28 -0800
Subject: [Bitcoin-development] Area of Focus
In-Reply-To: <20141220100816.GD7902@giles.gnomon.org.uk>
References: <CAB2qGxXDtxWxyLUCEZ9XQ4nP0U-Cj5Xiz9ac=vot1H+wzRCHrA@mail.gmail.com>
	<54953A11.1060202@bluematt.me>
	<20141220100816.GD7902@giles.gnomon.org.uk>
Message-ID: <op.xq5yue2cyldrnw@laptop-air>

On Sat, Dec 20, 2014 at 08:57:53AM +0000, Matt Corallo wrote:
>> There was recently some discussion around dnsseeds. Currently some
>> dnsseeds are getting blocked by ISPs because the hosts they pick up
>> (which run bitcoin core nodes) often run rather web servers alongside
>> which serve malware or whatever else and thus end up on IP-based malware
>> blacklists.

On Sat, 20 Dec 2014 02:08:17 -0800, Roy Badami <roy at gnomon.org.uk> wrote:
> Why would we want to have anything to do with people who are hosting
> malware?  Or do I misunderstand?

It sounds like Matt is saying the nodes the dnsseed is pointing to as  
valid full nodes, that those IPs are hosting the malware. Since the  
dnsseed picks up any stable nodes it can find without auditing, it's  
perhaps not surprising some servers in the world are running a full node  
and a malware server together.

I guess what confused me about this though, how are ISPs reading the  
dnsseed's node list, scanning *those* IPs for malware, and then ending up  
blocking the dnsseed? Seems like a pretty winding path to end up blocking  
a DNS server?

Since when do ISPs null-route a DNS server for happening to resolve some  
domains to IPs which happen to also be hosting some malware? Null-route  
those endpoint IPs sure, but the DNS server too? I guess there was that  
incident of Microsoft taking over No-IP.com -- are dnsseeds being blocked  
ostensibly because they are acting as dyanamic DNS infrastructure for  
malware sites?




From pete at petertodd.org  Sat Dec 20 14:48:01 2014
From: pete at petertodd.org (Peter Todd)
Date: Sat, 20 Dec 2014 09:48:01 -0500
Subject: [Bitcoin-development] The relationship between Proof-of-Publication
 and Anti-Replay Oracles
In-Reply-To: <20141212090551.GA8259@muck>
References: <20141212090551.GA8259@muck>
Message-ID: <20141220144800.GA26284@savin.petertodd.org>

Gregory Maxwell recently pointed out to me in private conservation that
there potentially existed a fundemental disagreement between him and I
on our philosophical approaches to blockchains, in that he prioritised
the notion of the blockchain as an anti-replay oracle, and I prioritised
it as a publication layer. Here I'll talk about the differences and
simularities between those two approaches.


What's Anti-Replay?
===================

We have some action - perhaps spending a txout - and we only want it to
be possible for that action to happen once; we don't want it to be
possible for that action to be replayed again. This is inherently not
possible with cryptography alone as cryptography is just math and any
mathematical calculation can be repeated with different parameters.


What's an Anti-Replay Oracle?
=============================

We need the following primitives operating on message m, pubkey p, and a
valid signature sig1 for m, p:

    AntiReplaySign(m, p, sig1) -> sig2
    VerifyAntiReplaySig(m, p, sig2) -> True or False

Additionally once AntiReplaySign() has been used once for a given pubkey
it is impossible to re-run the primitive on a different message m'. This
is of course impossible to implement with math alone, but we can
implement it with a trusted third party. For instance Carol can perform
the AntiReplaySign operation and make the promise that she will only
ever perform it once for any given (m,p) tuple.

Maxwell points out in CoinWitness? that the anti-replay oracle is
sufficient to implement a digital currency. So long as the trusted
oracle, or majority of a federation of trusted oracles, is honest coins
cannot be double-spent and can be securely passed from owner-to-owner
with an ever-growing transcript? proving each valid spend.

i) The transcript is needed in this model only because the oracles do
   nothing more than promise to never sign a message twice; it can be
   removed if the oracles additionally validate transactions in some
   way.


The Blockchain as an Anti-Replay Oracle
=======================================

In Bitcoin miners act as a trusted anti-replay oracle. If they follow
the Bitcoin protocol faithfully for any given txout one and only one
valid scriptSig will ever be accepted into the blockchain. Thus the
spend of a txout is a valid anti-replay-protected signature, and the
validity of that signature can be verified by SPV clients with a merkle
path to the block headers.


Using proof-of-publication to prove non-replay
==============================================

Given a secure proof-of-publication? system we can prove non-replay. We
define a valid signature as both being published on that system, as well
as there existing no other valid signature. (proof-of-non-publication)
An attempt to fraudulently create a second signature will either fail
the first test - not being published at all - or will fail the second
test - not being able to prove no other valid signature exists.

Thus we see that proof-of-publication can be used to securely audit the
honesty of an anti-replay oracle, resulting in secure anti-replay
protection without the requirement of trust.

However the converse is not possible: anti-replay cannot be used to
implement proof-of-publication. Knowing that no conflicting message
exists says nothing about who be in posession of that message, or
indeed, any message at all. Thus anti-replay is not sufficient to
implement other uses of proof-of-publication such as decentralized
exchange?.


Anti-replay in place of proof-of-publication to secure audit logs
=================================================================

The author's proof-of-concept Uniquebits? allows Alice to prove to Bob
that some set of records R_i that she has given to Bob is the same set
of records she has given to everyone else - that is no R_i' exists.
Secondly Alice can update the records producing R_{i+1}, and Bob can
determine if such an update exists.

Currently Uniquebits uses proof-of-publication via the Bitcoin
blockchain directly for both guarantees. It could however make use of
the anti-replay function provided by Bitcoin to satisfy the first
requirement with the following protocol:

0) Alice publishes record set R_i such that H(T_i + n_i) is committed in
   R_i, where T_0 is a txout she controls, and n_i is a nonce.

1) Alice creates T_{i+1}, another txout that she controls, and nonce
   n_{i+1}

2) Alice creates R_{i+1} which commits to H(T_{i+1} + n_i)

3) Finally to publish R_{i+1} she spends T_i in a transaction X_{i+1}
   that commits to R_{i+1} (e.g. in an OP_RETURN output, or with
   pay-to-contract?/sign-to-contract)

This process can be repeated again indefinitely, starting at step #1.
When Alice wants to prove to Bob - who has R_i - she simply gives him a
SPV proof that transaction X_{i+1} exists in the blockchain along with
n_i. This proves that T_i was spent, which can only happen once, and
that it committed to R_{i+1}. As the output can only be spent once it is
not possible to create a valid-looking R_{i+1}'

However to prove to Bob that R_{i+1} is the most recent set of records
Alice still needs to use proof-of-publication, by showing him txout
T_{i+1} is unspent.


Case study: Fidelity-bonded Ledgers/Federated Sidechains
========================================================

The author's Fidelity-Bonded Ledgers? and the more general idea of
Federated Sidechains? both describe the notion of a trusted third party,
possibly implemented as a federated majority set, who guarantees the
correct maintenance of some financial ledger according to some set of
rules. Coins can be moved to/from the ledger by payment to a specific
set of scriptPubKey's. Federated sidechains proposes that the
scriptPubKey simply be a n-of-m multisig; fidelity-bonded ledgers
proposes new opcodes that allow redemption via proof-of-fraud.

In any case someone relying on a transaction within the ledger itself
still needs to be able to audit that their view of the ledger is the
same view everyone else sees; in short that there do not exist
double-spends on the ledger. The author's fidelity-bonded ledgers paper
proposed that the ledger be made available over a Tor-accessible website
to prevent selective censorship. The federated sidechains proposal is
mute on this issue.

As the state of the ledger is a specific instance of the more general
set of records problem that Uniquebits solves as can use the same
principles for fidelity-bonded ledgers/federated sidechains. The third
party periodically publishes the ledger state to the Bitcoin blockchain
allowing anyone to detect if their copy of the ledger is incomplete; if
not there may be double-spends in it. Finally proof of such
double-spends can trigger the destruction of a fidelity-bond? and/or
return funds to their rightful owners. (with appropriate opcodes?)

Censorship of the ledger state publications is an issue, however in the
case of financial ledgers with pegged funds we can use the pegged funds
themselves in the publication. Censoring those publications by
preventing the designated txouts from being spent then becomes
equivalent to blacklisting funds. This requires a majority of hashing
power supporting the blacklist, and is a highly politically charged
issue? in the Bitcoin community.


References
==========

1) Really Really ultimate blockchain compression: CoinWitness,
   Gregory Maxwell, Aug 19th 2013, Accessed 2014-12-20,
   https://bitcointalk.org/index.php?topic=277389.msg2961736

2) Setting the record straight on Proof-of-Publication,
   Peter Todd, Dec 12th 2014,
   http://www.mail-archive.com/bitcoin-development at lists.sourceforge.net/msg06570.html

3) Decentralized digital asset exchange with honest pricing and market depth,
   Peter Todd, Feb 9th 2014,
   http://www.mail-archive.com/bitcoin-development%40lists.sourceforge.net/msg03892.html

4) Uniquebits, Peter Todd, Accessed 2014-12-20,
   https://github.com/petertodd/uniquebits/tree/b9213f6769d80305bdd192925e8bd7bd04239d1b

5) Homomorphic Payment Addresses and the Pay-to-Contract Protocol,
   Ilja Gerhardt and Timo Hanke, Dec 13th 2012,
   http://arxiv.org/abs/1212.3257

6) Fidelity-bonded ledgers, Peter Todd, Feb 25th 2013,
   http://www.mail-archive.com/bitcoin-development%40lists.sourceforge.net/msg01786.html

7) Enabling Blockchain Innovations with Pegged Sidechains,
   Blockstream, Oct 22nd 2014,
   SHA256: 680c71aef9ed578720e25c58fd50de5cdbee755c3800e7601dad9a745ca65cf3,
   http://www.blockstream.com/sidechains.pdf

8) Fidelity-bonded banks: decentralized, auditable, private, off-chain payments,
   Peter Todd, Feb 23rd 2014,
   https://bitcointalk.org/index.php?topic=146307.0

9) WARNING: Bitcoin Address Blacklists have been forced into the Gentoo Linux bitcoind distribution by Luke-jr against the will of other core devs. Gentoo maintainers are clueless and not reversing the change.  Boycott Gentoo now.,
   historian1111, Oct 10th 2014, Accessed 2014-12-20,
   https://www.reddit.com/r/Bitcoin/comments/2ityg2/warning_bitcoin_address_blacklists_have_been/

-- 
'peter'[:-1]@petertodd.org
000000000000000001eeaba4cdadaf5b8338cb1b2ae0cf969de77437dd83faac
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141220/3895cdee/attachment.sig>

From decker.christian at gmail.com  Sat Dec 20 18:27:53 2014
From: decker.christian at gmail.com (Christian Decker)
Date: Sat, 20 Dec 2014 19:27:53 +0100
Subject: [Bitcoin-development] Area of Focus
In-Reply-To: <54953A11.1060202@bluematt.me>
References: <CAB2qGxXDtxWxyLUCEZ9XQ4nP0U-Cj5Xiz9ac=vot1H+wzRCHrA@mail.gmail.com>
	<54953A11.1060202@bluematt.me>
Message-ID: <CALxbBHXxEfROeHOkHQPVpPzNSvaFK0hSJbY0d3oEA0D8CcN7qg@mail.gmail.com>

Thanks for bringing this to my attention.

I added a safety check to my crawler and seed.bitcoinstats.com should
not return IPs that also run HTTP or HTTPS, hopefully this'll keep it
off blacklists :-)
--
Christian Decker


On Sat, Dec 20, 2014 at 9:57 AM, Matt Corallo <bitcoin-list at bluematt.me> wrote:
> There was recently some discussion around dnsseeds. Currently some
> dnsseeds are getting blocked by ISPs because the hosts they pick up
> (which run bitcoin core nodes) often run rather web servers alongside
> which serve malware or whatever else and thus end up on IP-based malware
> blacklists.
>
> Of course we really dont want to move off of DNS because it has this big
> built-in anonymity network where the DNS seed servers only get
> information about your ISP, not you, and its cached so you dont get as
> much information about how many users are making those requests.
>
> A potential solution might be supporting some subdomain which has
> results XORed with some constant mask to tweak the real IP.
>
> Additionally, it might be cool to stuff a TXT/AAAA/whatever record with
> a signature of the results provided by the DNSseed operator.
>
> Matt
>
> On 12/20/14 07:42, Will Bickford wrote:
>> Hi all, I'm looking to help with Bitcoin core development in my spare
>> time (a few hours per week).
>>
>> A little bit about me:
>> * I use C++ and Qt daily
>> * I love to automate and enhance software systems
>> * I enjoy root causing and fixing issues
>>
>> I saw Gavin say we needed help with testing in a Reddit AMA a while ago.
>> I'm curious where I can make the best impact. Any feedback would be
>> appreciated. Thanks!
>>
>> Will Bickford
>> "In Google We Trust"
>>
>>
>> ------------------------------------------------------------------------------
>> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server
>> from Actuate! Instantly Supercharge Your Business Reports and Dashboards
>> with Interactivity, Sharing, Native Excel Exports, App Integration & more
>> Get technology previously reserved for billion-dollar corporations, FREE
>> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk
>>
>>
>>
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>
> ------------------------------------------------------------------------------
> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server
> from Actuate! Instantly Supercharge Your Business Reports and Dashboards
> with Interactivity, Sharing, Native Excel Exports, App Integration & more
> Get technology previously reserved for billion-dollar corporations, FREE
> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development



From bitcoin-list at bluematt.me  Sat Dec 20 21:20:53 2014
From: bitcoin-list at bluematt.me (Matt Corallo)
Date: Sat, 20 Dec 2014 21:20:53 +0000
Subject: [Bitcoin-development] Area of Focus
In-Reply-To: <op.xq5yue2cyldrnw@laptop-air>
References: <CAB2qGxXDtxWxyLUCEZ9XQ4nP0U-Cj5Xiz9ac=vot1H+wzRCHrA@mail.gmail.com>	<54953A11.1060202@bluematt.me>	<20141220100816.GD7902@giles.gnomon.org.uk>
	<op.xq5yue2cyldrnw@laptop-air>
Message-ID: <5495E835.2080802@bluematt.me>

Well, some ISPs, when they see an IP address serving malware, will
(apparently) simply replace DNS results for anything returning that IP
with a warning page.

One solutions is to just blindly block everything with HTTP(S), as
Christian has done, but this is a rather ugly solution, since many
perfectly good nodes will get caught in the crossfire. Hiding what
actual IPs we're returning in the results seems much cleaner, despite
being an ugly hack.

On 12/20/14 11:14, Jeremy Spilman wrote:
> On Sat, Dec 20, 2014 at 08:57:53AM +0000, Matt Corallo wrote:
>>> There was recently some discussion around dnsseeds. Currently some
>>> dnsseeds are getting blocked by ISPs because the hosts they pick up
>>> (which run bitcoin core nodes) often run rather web servers alongside
>>> which serve malware or whatever else and thus end up on IP-based malware
>>> blacklists.
> 
> On Sat, 20 Dec 2014 02:08:17 -0800, Roy Badami <roy at gnomon.org.uk> wrote:
>> Why would we want to have anything to do with people who are hosting
>> malware?  Or do I misunderstand?
> 
> It sounds like Matt is saying the nodes the dnsseed is pointing to as  
> valid full nodes, that those IPs are hosting the malware. Since the  
> dnsseed picks up any stable nodes it can find without auditing, it's  
> perhaps not surprising some servers in the world are running a full node  
> and a malware server together.
> 
> I guess what confused me about this though, how are ISPs reading the  
> dnsseed's node list, scanning *those* IPs for malware, and then ending up  
> blocking the dnsseed? Seems like a pretty winding path to end up blocking  
> a DNS server?
> 
> Since when do ISPs null-route a DNS server for happening to resolve some  
> domains to IPs which happen to also be hosting some malware? Null-route  
> those endpoint IPs sure, but the DNS server too? I guess there was that  
> incident of Microsoft taking over No-IP.com -- are dnsseeds being blocked  
> ostensibly because they are acting as dyanamic DNS infrastructure for  
> malware sites?
> 
> 
> ------------------------------------------------------------------------------
> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server
> from Actuate! Instantly Supercharge Your Business Reports and Dashboards
> with Interactivity, Sharing, Native Excel Exports, App Integration & more
> Get technology previously reserved for billion-dollar corporations, FREE
> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
> 



From gmaxwell at gmail.com  Sat Dec 20 21:30:03 2014
From: gmaxwell at gmail.com (Gregory Maxwell)
Date: Sat, 20 Dec 2014 21:30:03 +0000
Subject: [Bitcoin-development] Area of Focus
In-Reply-To: <op.xq5yue2cyldrnw@laptop-air>
References: <CAB2qGxXDtxWxyLUCEZ9XQ4nP0U-Cj5Xiz9ac=vot1H+wzRCHrA@mail.gmail.com>
	<54953A11.1060202@bluematt.me>
	<20141220100816.GD7902@giles.gnomon.org.uk>
	<op.xq5yue2cyldrnw@laptop-air>
Message-ID: <CAAS2fgRB33c+JGphkT72OiRnLY_41b5Ufkfmff=4u-yB1oq2Qw@mail.gmail.com>

On Sat, Dec 20, 2014 at 11:14 AM, Jeremy Spilman <jeremy at taplink.co> wrote:
>> are dnsseeds being blocked
> ostensibly because they are acting as dyanamic DNS infrastructure for
> malware sites?

Pretty much appears to be the case. In every instance it appears to be
automated. This predates the msft no-ip.com stuff.
We also had similar problems with the IRC based method that the
software originally used.

It's the same story for mail relay spam blacklisting.  There is a
whole industry out there selling people semi-snake-oil blocking
solutions to make the baddness of the internet go away. The low margin
business demands a cheap and highly automated approach... lots of
inappropriate things get blocked. Nagging people to fix things is time
consuming, better to move out of their sights a bit, so that they at
least have to specifically target Bitcoin. If they do, it'll at least
be worth the time spent fixing it.

I believe opendns is blocking all of sipa.be still as we speak, so if
you'd like to see it for yourself try to load http://bitcoin.sipa.be
while using opendns.



From jgarzik at bitpay.com  Sat Dec 20 21:26:20 2014
From: jgarzik at bitpay.com (Jeff Garzik)
Date: Sat, 20 Dec 2014 16:26:20 -0500
Subject: [Bitcoin-development] Area of Focus
In-Reply-To: <CAB2qGxXDtxWxyLUCEZ9XQ4nP0U-Cj5Xiz9ac=vot1H+wzRCHrA@mail.gmail.com>
References: <CAB2qGxXDtxWxyLUCEZ9XQ4nP0U-Cj5Xiz9ac=vot1H+wzRCHrA@mail.gmail.com>
Message-ID: <CAJHLa0PBghVhEwWVgH3nXMJAV00OPPPoeZd8qgiCKf07xyEEDg@mail.gmail.com>

Getting back to the original topic...

I would recommend first taking a look at how the current tests are built
(via autoconf/automake) in src/test.  There are several surfaces to test,
RPC, REST, P2P, internal unit tests, and more.  Then, Travis applies a
second level of testing via the bitcoinj-based regression tests.

Some automated tests that operate at the Qt level would be interesting.  In
general, the current tests only scratch the surface of what Needs To Be
Tested...  but part of figuring out a good test is (a) knowing bitcoin and
(b) knowing the current test regimes.

Join #bitcoin-dev IRC and ask questions.  Read the bitcoin wiki.




On Sat, Dec 20, 2014 at 2:42 AM, Will Bickford <wbic16 at gmail.com> wrote:
>
> Hi all, I'm looking to help with Bitcoin core development in my spare time
> (a few hours per week).
>
> A little bit about me:
> * I use C++ and Qt daily
> * I love to automate and enhance software systems
> * I enjoy root causing and fixing issues
>
> I saw Gavin say we needed help with testing in a Reddit AMA a while ago.
> I'm curious where I can make the best impact. Any feedback would be
> appreciated. Thanks!
>
> Will Bickford
> "In Google We Trust"
>
>
> ------------------------------------------------------------------------------
> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server
> from Actuate! Instantly Supercharge Your Business Reports and Dashboards
> with Interactivity, Sharing, Native Excel Exports, App Integration & more
> Get technology previously reserved for billion-dollar corporations, FREE
>
> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
>

-- 
Jeff Garzik
Bitcoin core developer and open source evangelist
BitPay, Inc.      https://bitpay.com/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141220/9609c701/attachment.html>

From wbic16 at gmail.com  Sat Dec 20 22:37:58 2014
From: wbic16 at gmail.com (Will Bickford)
Date: Sat, 20 Dec 2014 16:37:58 -0600
Subject: [Bitcoin-development] Area of Focus
In-Reply-To: <CAJHLa0PBghVhEwWVgH3nXMJAV00OPPPoeZd8qgiCKf07xyEEDg@mail.gmail.com>
References: <CAB2qGxXDtxWxyLUCEZ9XQ4nP0U-Cj5Xiz9ac=vot1H+wzRCHrA@mail.gmail.com>
	<CAJHLa0PBghVhEwWVgH3nXMJAV00OPPPoeZd8qgiCKf07xyEEDg@mail.gmail.com>
Message-ID: <CAB2qGxXaxPc3y6HRg4fToPT4SX2bbgsEBYkz5dFQZE7DqGZ4DA@mail.gmail.com>

Thanks Jeff. I'll start looking there.

Will Bickford
"In Google We Trust"

On Sat, Dec 20, 2014 at 3:26 PM, Jeff Garzik <jgarzik at bitpay.com> wrote:

> Getting back to the original topic...
>
> I would recommend first taking a look at how the current tests are built
> (via autoconf/automake) in src/test.  There are several surfaces to test,
> RPC, REST, P2P, internal unit tests, and more.  Then, Travis applies a
> second level of testing via the bitcoinj-based regression tests.
>
> Some automated tests that operate at the Qt level would be interesting.
> In general, the current tests only scratch the surface of what Needs To Be
> Tested...  but part of figuring out a good test is (a) knowing bitcoin and
> (b) knowing the current test regimes.
>
> Join #bitcoin-dev IRC and ask questions.  Read the bitcoin wiki.
>
>
>
>
> On Sat, Dec 20, 2014 at 2:42 AM, Will Bickford <wbic16 at gmail.com> wrote:
>
>> Hi all, I'm looking to help with Bitcoin core development in my spare
>> time (a few hours per week).
>>
>> A little bit about me:
>> * I use C++ and Qt daily
>> * I love to automate and enhance software systems
>> * I enjoy root causing and fixing issues
>>
>> I saw Gavin say we needed help with testing in a Reddit AMA a while ago.
>> I'm curious where I can make the best impact. Any feedback would be
>> appreciated. Thanks!
>>
>> Will Bickford
>> "In Google We Trust"
>>
>>
>> ------------------------------------------------------------------------------
>> Download BIRT iHub F-Type - The Free Enterprise-Grade BIRT Server
>> from Actuate! Instantly Supercharge Your Business Reports and Dashboards
>> with Interactivity, Sharing, Native Excel Exports, App Integration & more
>> Get technology previously reserved for billion-dollar corporations, FREE
>>
>> http://pubads.g.doubleclick.net/gampad/clk?id=164703151&iu=/4140/ostg.clktrk
>> _______________________________________________
>> Bitcoin-development mailing list
>> Bitcoin-development at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>>
>>
>
> --
> Jeff Garzik
> Bitcoin core developer and open source evangelist
> BitPay, Inc.      https://bitpay.com/
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141220/ca76d3fa/attachment.html>

From pete at petertodd.org  Sun Dec 21 05:52:20 2014
From: pete at petertodd.org (Peter Todd)
Date: Sun, 21 Dec 2014 00:52:20 -0500
Subject: [Bitcoin-development] The relationship between
 Proof-of-Publication and Anti-Replay Oracles
In-Reply-To: <CAOG=w-vrHPY1aCNndmoW9QyCh9XnWyv8uZn2PyjZ6rNg2MoSSw@mail.gmail.com>
References: <20141212090551.GA8259@muck>
	<20141220144800.GA26284@savin.petertodd.org>
	<CAOG=w-vrHPY1aCNndmoW9QyCh9XnWyv8uZn2PyjZ6rNg2MoSSw@mail.gmail.com>
Message-ID: <20141221055220.GB8255@savin.petertodd.org>

On Sun, Dec 21, 2014 at 11:57:51AM +0800, Mark Friedenbach wrote:
> On Sat, Dec 20, 2014 at 10:48 PM, Peter Todd <pete at petertodd.org> wrote:
> 
> > However the converse is not possible: anti-replay cannot be used to
> > implement proof-of-publication. Knowing that no conflicting message
> > exists says nothing about who be in posession of that message, or
> > indeed, any message at all. Thus anti-replay is not sufficient to
> > implement other uses of proof-of-publication such as decentralized
> > exchange?.
> >
> 
> I think you are trying to say something more specific / limited than that,
> and I suggest you adjust your wording accordingly. Decentralized exchange
> would be possible today with vanilla bitcoin using SIGHASH_SINGLE if only
> the protocol supported multiple validated assets (which it could, but
> doesn't). Rather straightforward further extensions to the protocol would
> enable market participants to use a wider class of orders, as well as
> enable the buyer rather than the seller to dictate order sizes via partial
> redemption, as we demonstrate in our Freimarkets paper.

Do you realise that all those Freimarket's uses are either based on
proof-of-publication, or insecure due to sybil attacks?

-- 
'peter'[:-1]@petertodd.org
000000000000000017d70ee98f4cee509d95c4f31d5b998bae6deb09df1088fc
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141221/0a2a8521/attachment.sig>

From pete at petertodd.org  Sun Dec 21 06:12:20 2014
From: pete at petertodd.org (Peter Todd)
Date: Sun, 21 Dec 2014 01:12:20 -0500
Subject: [Bitcoin-development] Setting the record straight on
 Proof-of-Publication
In-Reply-To: <CALohRkgbHvLCwAY0+2zpd-LwRxnntzcpPuUjU4zDEz=oODaK1w@mail.gmail.com>
References: <20141212090551.GA8259@muck> <548ADED1.6060300@gmail.com>
	<CAE28kUR-PLzMGC23ETesc2Bz1_F1JfgcqyMW4qFvV5Vjk+ubbg@mail.gmail.com>
	<CAOG=w-v3qjG3zd_WhfFU-OGnsHZEuYvY82eL4GqcdgY6np5bvA@mail.gmail.com>
	<CAE28kUSZcGrFL3OMf=uOJ2=NQ89M54FOhR_iOXkEubrb6qqVAg@mail.gmail.com>
	<548C3FE6.9090508@gmail.com>
	<20141215045236.GB23859@savin.petertodd.org>
	<CALohRkgbHvLCwAY0+2zpd-LwRxnntzcpPuUjU4zDEz=oODaK1w@mail.gmail.com>
Message-ID: <20141221061220.GC8255@savin.petertodd.org>

On Wed, Dec 17, 2014 at 10:55:28PM +1100, Gareth Williams wrote:
> > I covered this in my original post: 1-way-pegs allow the creation of new
> > valuable tokens without those tokens being useful for speculation.
> 
> I stand corrected. A permanent 1-way-peg is sufficient to preserve
> scarcity; "nothing else can do that" WRT 2-way-pegs was overreaching.

Yup.

> I still don't see what "2-way-peg vs. 1-way-peg" has to do with
> "embedded consensus vs. blockchain consensus" though, and feel it
> disingenious to conflate them.

1-way-pegs don't require the Bitcoin protocol to change; 2-way-pegs do.

> Blockchain consensus (eg. sidechains) can utilise either mechanism,
> 1-way-peg or 2-way-peg. Arguments in favour of 1-way-peg are
> interesting, but they're ultimatley just arguments in favour of one
> type of sidechain over another.

No, they're in favor of systems that are client-side validatable vs.
systems that either allow anyone with sufficient hashing power to steal
coins *or* require "moon-math" that isn't yet available to production
systems.

> IMO the question of whether scarcity can be preserved while enabling
> innovation bears heavily on the liklihood of longterm viability of
> said innovations - and perhaps of Bitcoin itself.
> 
> FWIW I'll happily declare that I hold a modest amount of BTC and have
> an interest in the price appreciating. I'm sure you'll admit you're
> hardly an impartial party in this discussion yourself Peter :) But it
> really shouldn't matter. I'm not here today to make it, but I think
> the argument for preservation of scarcity stands quite well on its own
> merits - as rightly it should, regardless of anybody's interests.

But again, all these discussions about scarcity are fundementally
*moral* arguments that have no bearing on what's actually the most
appropriate solution for an *individual* problem.

In a decentralized system filled with anonymous actors telling people
"stop doing that! it's bad!" on reddit has pretty severe limitations in
trying to convince people to act against their own best interests.

> > The quality of Counterparty's software engineering has no bearing on
> > whether or not the underlying idea is a good one; you wouldn't say ring
> > signatures are an inherently bad idea just because the CryptoNote
> > implementation of them is atrocious.
> 
> Very interesting. I admit I hadn't come across these ideas before; I
> really must search the archive before posting :) They certainly offer
> a measure of robustness over the naive approach. I'm not sure they
> address my primary concerns however, WRT how consensus is demonstrated
> and incentivised.

I think you think consensus in Bitcoin is more "magical" than it really
is; Bitcoin is just code running on computers; consensus isn't really
incentivised at the protocol level beyond "screw it up and you'll lose
money"

Embedded consensus systems are no different: screw up consensus and
you'll lose money in a variety of ways.

> The obvious "embedded consensus" answer of "wait until N other
> transactions have occurred that include a hash of system state that
> includes your transaction" doesn't provide me with any confidence; it
> could be simulated with a Sybil attack.

No it can't - the transactions are in the blockchain so the sybil attack
has to attack the host system as well.

In any case, keep in mind all of this is in the context of tradeoffs:
for a different and sometimes more fragile consensus mechanism embedded
consensus gets immunity to attack by miners. You're trading off one type
of fragility for another - I'd much rather take the "one-time" fragility
inherent in having to write really solid software than the ongoing
fragility of always being vulnerable to miners.

Notably this is the exact same tradeoff taken elsewhere by the majority
of the crypto world.

-- 
'peter'[:-1]@petertodd.org
000000000000000017d70ee98f4cee509d95c4f31d5b998bae6deb09df1088fc
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141221/c9345024/attachment.sig>

From pete at petertodd.org  Sun Dec 21 07:01:54 2014
From: pete at petertodd.org (Peter Todd)
Date: Sun, 21 Dec 2014 02:01:54 -0500
Subject: [Bitcoin-development] The relationship between
 Proof-of-Publication and Anti-Replay Oracles
In-Reply-To: <CAOG=w-tZke--6OsqNjJhE9SOdCwdZYZM8iz1VBTFziegt9UZWw@mail.gmail.com>
References: <20141212090551.GA8259@muck>
	<20141220144800.GA26284@savin.petertodd.org>
	<CAOG=w-vrHPY1aCNndmoW9QyCh9XnWyv8uZn2PyjZ6rNg2MoSSw@mail.gmail.com>
	<20141221055220.GB8255@savin.petertodd.org>
	<CAOG=w-tZke--6OsqNjJhE9SOdCwdZYZM8iz1VBTFziegt9UZWw@mail.gmail.com>
Message-ID: <20141221070154.GD8255@savin.petertodd.org>

On Sun, Dec 21, 2014 at 02:18:18PM +0800, Mark Friedenbach wrote:
> Care to expand?
> 
> Freimarkets does not require proof of publication of bids or asks, which
> are distributed out of band from the block chain until a match is made. It
> does not guarantee ordering of market transactions. Indeed, front-running
> is embraced as the mechanism for generating miner fees to pay for the
> service.

Right, so Freimarkets is delibrately insecure.

Best of luck on that.

> Sybil attacks? I'm not sure what you could be referring to. In Freimarkets
> a bid or ask is valid when received; a double-spend is required to cancel
> it. You could only flood the network with actual executable orders, and the
> counter-party to the order doesn't care if they all came from the same
> person or not.
> 
> Can you explain what it is you are objecting to?

Read my paper? - proof-of-publication is what allows you to detect
front-running robustly within certain parameters. Protecting against
that is widely considered to be a very important goal by people actually
in finance, to the point where I've had discussions with people where
anti-front-running protection might be the *only* thing they use a
decentralized system for.


1) Decentralized digital asset exchange with honest pricing and market depth,
   Peter Todd, Feb 9th 2014,
   http://www.mail-archive.com/bitcoin-development%40lists.sourceforge.net/msg03892.html

-- 
'peter'[:-1]@petertodd.org
000000000000000000c879729eae178096b092248706a407ec1b18eb62a792e9
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141221/bb56fbc7/attachment.sig>

From adam at cypherspace.org  Sun Dec 21 10:01:37 2014
From: adam at cypherspace.org (Adam Back)
Date: Sun, 21 Dec 2014 10:01:37 +0000
Subject: [Bitcoin-development] The relationship between
 Proof-of-Publication and Anti-Replay Oracles
In-Reply-To: <20141220144800.GA26284@savin.petertodd.org>
References: <20141212090551.GA8259@muck>
	<20141220144800.GA26284@savin.petertodd.org>
Message-ID: <CALqxMTHC0Rhotei4B1civoc_9NF5M+tw-qmE46EmHSadCrmScQ@mail.gmail.com>

On 20 December 2014 at 14:48, Peter Todd <pete at petertodd.org> wrote:
> We need the following primitives operating on message m, pubkey p, and a
> valid signature sig1 for m, p:
>
>     AntiReplaySign(m, p, sig1) -> sig2
>     VerifyAntiReplaySig(m, p, sig2) -> True or False
>
> Additionally once AntiReplaySign() has been used once for a given pubkey
> it is impossible to re-run the primitive on a different message m'. This
> is of course impossible to implement with math alone, but we can
> implement it with a trusted third party.

Well while you cant prevent it you could render it insecure enabling
miners to take funds.

That could work via a one-show signature; normal ECDSA being address
a=H(Q), public key Q=dG, R=kG, r=R.x, s=(H(m)+rd)/k, signature (r,s),
verify: a=?H(Q) and sR=?H(m)G+rQ one-show being: a=H(Q,R), verify
being: a=?H(Q,R) and sR=?H(m)G+rQ.  Now that is unsafe to double-spend
by design as only that specific R is usable and as we know reusing R
with different messages leaks the private key because: s=(H(m)+rd)/k
and s'=(H(m')+rd)/k implies sk=H(m)+rd and s'k=H(m')+rd so
k=(H(m)-H(m'))/(s'-s), and d=(sk-H(m))/r.

Adam



From jtimon at jtimon.cc  Sun Dec 21 11:25:36 2014
From: jtimon at jtimon.cc (=?UTF-8?B?Sm9yZ2UgVGltw7Nu?=)
Date: Sun, 21 Dec 2014 12:25:36 +0100
Subject: [Bitcoin-development] The relationship between
 Proof-of-Publication and Anti-Replay Oracles
In-Reply-To: <20141221055220.GB8255@savin.petertodd.org>
References: <20141212090551.GA8259@muck>
	<20141220144800.GA26284@savin.petertodd.org>
	<CAOG=w-vrHPY1aCNndmoW9QyCh9XnWyv8uZn2PyjZ6rNg2MoSSw@mail.gmail.com>
	<20141221055220.GB8255@savin.petertodd.org>
Message-ID: <CABm2gDp0nw+z2NdaNDb8VQ=4e9Eh44mkzp9OePJyJfrbyfpy7A@mail.gmail.com>

st

On Sun, Dec 21, 2014 at 6:52 AM, Peter Todd <pete at petertodd.org> wrote:
> On Sun, Dec 21, 2014 at 11:57:51AM +0800, Mark Friedenbach wrote:
>> I think you are trying to say something more specific / limited than that,
>> and I suggest you adjust your wording accordingly. Decentralized exchange
>> would be possible today with vanilla bitcoin using SIGHASH_SINGLE if only
>> the protocol supported multiple validated assets (which it could, but
>> doesn't). Rather straightforward further extensions to the protocol would
>> enable market participants to use a wider class of orders, as well as
>> enable the buyer rather than the seller to dictate order sizes via partial
>> redemption, as we demonstrate in our Freimarkets paper.
>
> Do you realise that all those Freimarket's uses are either based on
> proof-of-publication, or insecure due to sybil attacks?

So let's go through an example to see in which ways
non-proof-of-publication orders are "insecure".

Alice the seller wants to sell 1 unit of A for 100 units of B.
Bob is willing to pay up to 200 Bs for 1 A.

Let's assume a proof of publication system first, in which the
execution price is the mean between bid and ask.
Alice publishes her order.
Bob could publish his order at price 200 Bs and the order would
execute at 150 Bs.
But after seeing Alice's order he knows he doesn't need to pay that
much, so he publishes and order buying for 100 Bs.

Alice gets 100 Bs (what she signed she wanted) and Bob pays less than
he was wiling to pay, he pays 100 Bs. Everybody happy.

Now let's assume native assets and sighash_single.

Alice publishes her order (out of band, using various channels).
Bob could publish his order at price 200 Bs and then a miner would
execute at 100 Bs for Alice, at 200 Bs for Bob and pocket 100 Bs as
mining fees.
But after seeing Alice's order he knows he doesn't need to pay that
much, so he publishes and order buying for 100 Bs.

Again, Alice gets 100 Bs (what she signed she wanted) and Bob pays pays 100 Bs.
The main difference is that Alice didn't had to pay a fee to publish
her binding order.

Now let's try to articulate your concerns.
Your concern is that Carol, isolates Bob preventing him from seeing
Alice's order.
Then maybe Bob publishes his own order at 200 Bs.
If Carol sees both orders while preventing the other participants from
seeing them, she can build a tx in which Alice sells at 100, Bob buys
at 200, and Carol pockets the difference.
But...any smart miner will replace Carol's address with his own when
processing the trade, so Carol cannot win this way.

Another thing Carol can do is to buy the A herself for 100 Bs, leaving
Bob without them.
If Alice cares about Bob getting the deal instead of Carol she can do
two things:
1) Establish a direct communication channel with Bob
2) Move to a proof of publication system and start paying fees for
publishing binding orders.

So again, what's the advantage that proof-of-publication provides TO
ALICE so that she will be so eager to pay the higher costs to get the
same deal?
If this example is not enough to be able to explain the advantage of
proof-of-publication markets feel free to write a more complex one.



From snow.paul at gmail.com  Sun Dec 21 13:49:17 2014
From: snow.paul at gmail.com (paul snow)
Date: Sun, 21 Dec 2014 07:49:17 -0600
Subject: [Bitcoin-development] The relationship between
 Proof-of-Publication and Anti-Replay Oracles
In-Reply-To: <20141220144800.GA26284@savin.petertodd.org>
References: <20141212090551.GA8259@muck>
	<20141220144800.GA26284@savin.petertodd.org>
Message-ID: <CAMU7uivcB8969-R=eBtPNXyWt+ULpXWN5sDBOkRN1XRUtXU9Yg@mail.gmail.com>

On Dec 20, 2014 8:49 AM, "Peter Todd" <pete at petertodd.org> wrote:
>
> However the converse is not possible: anti-replay cannot be used to
implement proof-of-publication. Knowing that no conflicting message exists
says nothing about who be in posession of that message, or indeed, any
message at all. Thus anti-replay is not sufficient to implement other uses
of proof-of-publication such as decentralized exchange?.

How does proof of publication prove who is in possession of that message?
Or of any message at all?  The data written in an anti-replay system and
the data written in a proof of publication system differs in that you can't
repeat data in an anti-replay system according to some understanding of the
rules of the meaning of the data (if I am following your description
correctly).

Obviously you can publish the same data as many times as you like in a
proof-of-publication system; the interpretation of what that data means
would be the responsibility of the observers, not the "publishing
vehicle".  Repeated entries thus can be written, and the user of PoP can
validate and prove they did so.

If the data itself defines possession, the "ownership of the message" (it
isn't even clear to me what you mean by that phrase) isn't defined by
either proof, but by the message itself.  And the message itself isn't
constrained by either to prohibit proving ownership (what ever you mean by
that).

Of course, I do assume I can test a message (or a set of messages sharing
some feature like a particular input on a transaction) as being publishable
in an anti-replay system without actually publishing it.  That does allow
one to prove non-publishing.  You can determine if a message exists that
would preclude the publishing of a message; the very purpose of an
anti-replay proof.

And I would assert that such a search (i.e. the idea that such a search has
meaning in a anti-replay system) is already incorporating the assumption
that such a search is possible and must be possible for an anti-replay
system.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141221/793952f0/attachment.html>

From pete at petertodd.org  Sun Dec 21 15:22:56 2014
From: pete at petertodd.org (Peter Todd)
Date: Sun, 21 Dec 2014 10:22:56 -0500
Subject: [Bitcoin-development] The relationship between
 Proof-of-Publication and Anti-Replay Oracles
In-Reply-To: <CAMU7uivcB8969-R=eBtPNXyWt+ULpXWN5sDBOkRN1XRUtXU9Yg@mail.gmail.com>
References: <20141212090551.GA8259@muck>
	<20141220144800.GA26284@savin.petertodd.org>
	<CAMU7uivcB8969-R=eBtPNXyWt+ULpXWN5sDBOkRN1XRUtXU9Yg@mail.gmail.com>
Message-ID: <20141221152256.GA3927@savin.petertodd.org>

On Sun, Dec 21, 2014 at 07:49:17AM -0600, paul snow wrote:
> On Dec 20, 2014 8:49 AM, "Peter Todd" <pete at petertodd.org> wrote:
> >
> > However the converse is not possible: anti-replay cannot be used to
> implement proof-of-publication. Knowing that no conflicting message exists
> says nothing about who be in posession of that message, or indeed, any
> message at all. Thus anti-replay is not sufficient to implement other uses
> of proof-of-publication such as decentralized exchange?.
> 
> How does proof of publication prove who is in possession of that message?
> Or of any message at all?

With the blockchain you prove the message in in the blockchain; anyone
in posession of the blockchain will be in posession of the message.
Secondly determining if you are in posession of the blockchain is
possible subject to the usual considerations about attacker size,
whether or not your local clock is up-to-date, etc.

> The data written in an anti-replay system and
> the data written in a proof of publication system differs in that you can't
> repeat data in an anti-replay system according to some understanding of the
> rules of the meaning of the data (if I am following your description
> correctly).

I'm not sure you understand what an anti-replay system is; data isn't
written to them; they're an abstract mathematical model that may be
actually implemented in a variety of ways.

Now it is true that any conceivable implementation must involve some
type of storage, but that storage can easily 100% local to the
anti-replay oracle and need not store the data itself. For instance a
trusted computer in a vault that maintains an extremely large bloom
filter of previously used keys would be a perfectly reasonable
implementation.

> If the data itself defines possession, the "ownership of the message" (it
> isn't even clear to me what you mean by that phrase) isn't defined by
> either proof, but by the message itself.  And the message itself isn't
> constrained by either to prohibit proving ownership (what ever you mean by
> that).

Wait, where did I say "ownership of the message"? What you quoted above
says *posession*, which != ownership.

> Of course, I do assume I can test a message (or a set of messages sharing
> some feature like a particular input on a transaction) as being publishable
> in an anti-replay system without actually publishing it.  That does allow
> one to prove non-publishing.  You can determine if a message exists that
> would preclude the publishing of a message; the very purpose of an
> anti-replay proof.
>
> And I would assert that such a search (i.e. the idea that such a search has
> meaning in a anti-replay system) is already incorporating the assumption
> that such a search is possible and must be possible for an anti-replay
> system.

You're confused about what an anti-replay system actually is - you're
really talking about a specific implementation of one based on
proof-of-publication, not the concept itself.

-- 
'peter'[:-1]@petertodd.org
00000000000000001b728df6414af5ef95388557f1c3e5d29c569d7636b93681
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141221/f938d68b/attachment.sig>

From pete at petertodd.org  Sun Dec 21 15:29:37 2014
From: pete at petertodd.org (Peter Todd)
Date: Sun, 21 Dec 2014 10:29:37 -0500
Subject: [Bitcoin-development] The relationship between
 Proof-of-Publication and Anti-Replay Oracles
In-Reply-To: <CALqxMTHC0Rhotei4B1civoc_9NF5M+tw-qmE46EmHSadCrmScQ@mail.gmail.com>
References: <20141212090551.GA8259@muck>
	<20141220144800.GA26284@savin.petertodd.org>
	<CALqxMTHC0Rhotei4B1civoc_9NF5M+tw-qmE46EmHSadCrmScQ@mail.gmail.com>
Message-ID: <20141221152936.GB3927@savin.petertodd.org>

On Sun, Dec 21, 2014 at 10:01:37AM +0000, Adam Back wrote:
> On 20 December 2014 at 14:48, Peter Todd <pete at petertodd.org> wrote:
> > We need the following primitives operating on message m, pubkey p, and a
> > valid signature sig1 for m, p:
> >
> >     AntiReplaySign(m, p, sig1) -> sig2
> >     VerifyAntiReplaySig(m, p, sig2) -> True or False
> >
> > Additionally once AntiReplaySign() has been used once for a given pubkey
> > it is impossible to re-run the primitive on a different message m'. This
> > is of course impossible to implement with math alone, but we can
> > implement it with a trusted third party.
> 
> Well while you cant prevent it you could render it insecure enabling
> miners to take funds.
> 
> That could work via a one-show signature; normal ECDSA being address
> a=H(Q), public key Q=dG, R=kG, r=R.x, s=(H(m)+rd)/k, signature (r,s),
> verify: a=?H(Q) and sR=?H(m)G+rQ one-show being: a=H(Q,R), verify
> being: a=?H(Q,R) and sR=?H(m)G+rQ.  Now that is unsafe to double-spend
> by design as only that specific R is usable and as we know reusing R
> with different messages leaks the private key because: s=(H(m)+rd)/k
> and s'=(H(m')+rd)/k implies sk=H(m)+rd and s'k=H(m')+rd so
> k=(H(m)-H(m'))/(s'-s), and d=(sk-H(m))/r.

There's no need to get into the specifics of crypto math so early; you
can just as easily and only slightly less efficiently obtain the same
result with a few extensions to the Bitcoin scripting system to verify
ECDSA signatures directly.

The interesting question is how "risky" this actually is? Sybil attacks
are reasonably easy to pull off, and users have little incentive to
validate if 99% of the time everything works, so you don't want to
create a system where an actual attack will likely go undetected.
Talking about the low level details of how double-spend punishment is
actually detailed is just premature optimization.

As usual in Bitcoin, the hard part is *not* the math.

-- 
'peter'[:-1]@petertodd.org
000000000000000012f5511833a1304a72a754df8afef26f5712438bcc40826b
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141221/5b4ce534/attachment.sig>

From pete at petertodd.org  Sun Dec 21 15:32:41 2014
From: pete at petertodd.org (Peter Todd)
Date: Sun, 21 Dec 2014 10:32:41 -0500
Subject: [Bitcoin-development] The relationship between
 Proof-of-Publication and Anti-Replay Oracles
In-Reply-To: <CAOG=w-s1_VXJAKxBpMOK=B50qnHjxSe4J=vwwSfFPRz0_Cb9rA@mail.gmail.com>
References: <20141212090551.GA8259@muck>
	<20141220144800.GA26284@savin.petertodd.org>
	<CAOG=w-vrHPY1aCNndmoW9QyCh9XnWyv8uZn2PyjZ6rNg2MoSSw@mail.gmail.com>
	<20141221055220.GB8255@savin.petertodd.org>
	<CAOG=w-tZke--6OsqNjJhE9SOdCwdZYZM8iz1VBTFziegt9UZWw@mail.gmail.com>
	<20141221070154.GD8255@savin.petertodd.org>
	<CAOG=w-s1_VXJAKxBpMOK=B50qnHjxSe4J=vwwSfFPRz0_Cb9rA@mail.gmail.com>
Message-ID: <20141221153241.GC3927@savin.petertodd.org>

On Sun, Dec 21, 2014 at 03:11:32PM +0800, Mark Friedenbach wrote:
> On Sun, Dec 21, 2014 at 3:01 PM, Peter Todd <pete at petertodd.org> wrote:
> 
> > Right, so Freimarkets is deliberately insecure.
> >
> 
> Please define your terms, particularly what your security requirements are
> here. In the architecture we created users remain in control of their funds
> at all times, and miners have incentives to mine the host chain. So I don't
> know what insecurity you are possibly talking about, and seem unwilling to
> elaborate.

Sybil attacks leading to front-running.

You may not be aware of this, but not being able to get the best price
due to a sybil attack *is* considered to be a security issue by the
users of these systems.

> I have read your posting and engaged with you in that very thread, where I
> point out that global ordering of bids & asks is a superfluous requirement.

It's superfluous until you have real businesses actually using these
systems.

> As to front-running, there is a distinct difference between centralized
> systems where front-running is essentially theft, and a distributed block
> chain system with actual costs paid by fees captured from the spread.

Among other things, ever noticed how this incentivises people to sybil
attack the entire system? Not good.

-- 
'peter'[:-1]@petertodd.org
000000000000000012f5511833a1304a72a754df8afef26f5712438bcc40826b
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141221/5accbf50/attachment.sig>

From snow.paul at gmail.com  Sun Dec 21 15:41:08 2014
From: snow.paul at gmail.com (paul snow)
Date: Sun, 21 Dec 2014 09:41:08 -0600
Subject: [Bitcoin-development] The relationship between
 Proof-of-Publication and Anti-Replay Oracles
In-Reply-To: <20141221152256.GA3927@savin.petertodd.org>
References: <20141212090551.GA8259@muck>
	<20141220144800.GA26284@savin.petertodd.org>
	<CAMU7uivcB8969-R=eBtPNXyWt+ULpXWN5sDBOkRN1XRUtXU9Yg@mail.gmail.com>
	<20141221152256.GA3927@savin.petertodd.org>
Message-ID: <CAMU7uitBBm58iNH6QXP4K+PQzn9Uw=JaYvv5vGgvSM-dCFZZig@mail.gmail.com>

I could play the game where I say, "You don't understand," and, like you,
not address any of your points.

First, there is no dependence on implementation in my arguments.  If a
system can prevent replay by some set of rules, it necessarily must be able
to answer the question if a message is publishable.  Non publishing proofs
are thus possible and even required.

The argument that proof of audience isn't part of an anti-replay system is
not one I picked up on, but an publicly auditable anti replay system
necessarily must define its audience. Again, not an issue for an auditable
system.
On Dec 21, 2014 9:23 AM, "Peter Todd" <pete at petertodd.org> wrote:

> On Sun, Dec 21, 2014 at 07:49:17AM -0600, paul snow wrote:
> > On Dec 20, 2014 8:49 AM, "Peter Todd" <pete at petertodd.org> wrote:
> > >
> > > However the converse is not possible: anti-replay cannot be used to
> > implement proof-of-publication. Knowing that no conflicting message
> exists
> > says nothing about who be in posession of that message, or indeed, any
> > message at all. Thus anti-replay is not sufficient to implement other
> uses
> > of proof-of-publication such as decentralized exchange?.
> >
> > How does proof of publication prove who is in possession of that message?
> > Or of any message at all?
>
> With the blockchain you prove the message in in the blockchain; anyone
> in posession of the blockchain will be in posession of the message.
> Secondly determining if you are in posession of the blockchain is
> possible subject to the usual considerations about attacker size,
> whether or not your local clock is up-to-date, etc.
>
> > The data written in an anti-replay system and
> > the data written in a proof of publication system differs in that you
> can't
> > repeat data in an anti-replay system according to some understanding of
> the
> > rules of the meaning of the data (if I am following your description
> > correctly).
>
> I'm not sure you understand what an anti-replay system is; data isn't
> written to them; they're an abstract mathematical model that may be
> actually implemented in a variety of ways.
>
> Now it is true that any conceivable implementation must involve some
> type of storage, but that storage can easily 100% local to the
> anti-replay oracle and need not store the data itself. For instance a
> trusted computer in a vault that maintains an extremely large bloom
> filter of previously used keys would be a perfectly reasonable
> implementation.
>
> > If the data itself defines possession, the "ownership of the message" (it
> > isn't even clear to me what you mean by that phrase) isn't defined by
> > either proof, but by the message itself.  And the message itself isn't
> > constrained by either to prohibit proving ownership (what ever you mean
> by
> > that).
>
> Wait, where did I say "ownership of the message"? What you quoted above
> says *posession*, which != ownership.
>
> > Of course, I do assume I can test a message (or a set of messages sharing
> > some feature like a particular input on a transaction) as being
> publishable
> > in an anti-replay system without actually publishing it.  That does allow
> > one to prove non-publishing.  You can determine if a message exists that
> > would preclude the publishing of a message; the very purpose of an
> > anti-replay proof.
> >
> > And I would assert that such a search (i.e. the idea that such a search
> has
> > meaning in a anti-replay system) is already incorporating the assumption
> > that such a search is possible and must be possible for an anti-replay
> > system.
>
> You're confused about what an anti-replay system actually is - you're
> really talking about a specific implementation of one based on
> proof-of-publication, not the concept itself.
>
> --
> 'peter'[:-1]@petertodd.org
> 00000000000000001b728df6414af5ef95388557f1c3e5d29c569d7636b93681
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141221/d3022b3a/attachment.html>

From pete at petertodd.org  Sun Dec 21 16:07:13 2014
From: pete at petertodd.org (Peter Todd)
Date: Sun, 21 Dec 2014 11:07:13 -0500
Subject: [Bitcoin-development] The relationship between
 Proof-of-Publication and Anti-Replay Oracles
In-Reply-To: <CABm2gDp0nw+z2NdaNDb8VQ=4e9Eh44mkzp9OePJyJfrbyfpy7A@mail.gmail.com>
References: <20141212090551.GA8259@muck>
	<20141220144800.GA26284@savin.petertodd.org>
	<CAOG=w-vrHPY1aCNndmoW9QyCh9XnWyv8uZn2PyjZ6rNg2MoSSw@mail.gmail.com>
	<20141221055220.GB8255@savin.petertodd.org>
	<CABm2gDp0nw+z2NdaNDb8VQ=4e9Eh44mkzp9OePJyJfrbyfpy7A@mail.gmail.com>
Message-ID: <20141221160713.GD3927@savin.petertodd.org>

On Sun, Dec 21, 2014 at 12:25:36PM +0100, Jorge Tim?n wrote:
> So let's go through an example to see in which ways
> non-proof-of-publication orders are "insecure".
> 
> Alice the seller wants to sell 1 unit of A for 100 units of B.
> Bob is willing to pay up to 200 Bs for 1 A.
> 
> Let's assume a proof of publication system first, in which the
> execution price is the mean between bid and ask.
> Alice publishes her order.
> Bob could publish his order at price 200 Bs and the order would
> execute at 150 Bs.
> But after seeing Alice's order he knows he doesn't need to pay that
> much, so he publishes and order buying for 100 Bs.
> 
> Alice gets 100 Bs (what she signed she wanted) and Bob pays less than
> he was wiling to pay, he pays 100 Bs. Everybody happy.
> 
> Now let's assume native assets and sighash_single.

Incidentally, SIGHASH_SINGLE is just as usable in embedded consensus;
it's not specific to native assets.

> So again, what's the advantage that proof-of-publication provides TO
> ALICE so that she will be so eager to pay the higher costs to get the
> same deal?

Like I said the last time this issue was discused on the mailing list,
it's silly to think the seller of an asset starts off with a specific
price they want to sell it at and is happy no matter what happens or how
it gets fufilled. In the real world sellers and buyers want to know
they're connected to actual sellers and buyers - not sybil attackers
trying to shave off a margin for themselves - and are willing to pay a
premium for that. Note all the hatred and vitrol directed towards
high-frequency traders...

How *much* of a premium is an interesting question, and depends a lot on
the specific scenario. For instance I fully expect to see a whole
variety of mediums become used for the proof-of-publication needed,
ranging from directly on a major blockchain to minor/less secure
blockchains like Bitmessage over treechains to centralized-but-audited
proof-of-publication schemes - AKA centralized exchanges - to standard
exchanges. Point is, the concept of proof-of-publication makes these
tradeoffs and options available and lets end-users pick the right one
for their needs.

Accurate unbiased price information is worth money. In systems that
allow third-parties to republish asset bids and offers we'll even see
third-parties republishing bids and offers from less secure systems to
more secure systems to get better price discovery.

> If this example is not enough to be able to explain the advantage of
> proof-of-publication markets feel free to write a more complex one.

I gotta ask, have you actually run the design and tradeoffs of
Friemarket's past actual finance types? I have, and it's remarkable how
excited many of them are about cryptographically provable fair price
discovery.

-- 
'peter'[:-1]@petertodd.org
000000000000000002661192e72bdc83e6c8101371520159531301aa1437cc2c
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141221/5262d433/attachment.sig>

From adam at cypherspace.org  Sun Dec 21 18:10:47 2014
From: adam at cypherspace.org (Adam Back)
Date: Sun, 21 Dec 2014 18:10:47 +0000
Subject: [Bitcoin-development] one-show signatures (Re: The relationship
 between Proof-of-Publication and Anti-Replay Oracles)
Message-ID: <CALqxMTFK_sxdFjVi0qAC0JMdXa=tVBBNp0VrveRUfwa3b1UYhw@mail.gmail.com>

Yes you could for example define a new rule that two signatures
(double-spend) authorises something - eg miners to take funds. (And
this would work with existing ECDSA addresses & unrestricted R-value
choices).

I wasnt really making a point other than an aside that it maybe is
sort-of possible to do with math what you said was not possible where
you said "This [preventing signing more than one message] is
impossible to implement with math alone".

Adam

On 21 December 2014 at 15:29, Peter Todd <pete at petertodd.org>
> There's no need to get into the specifics of crypto math so early; you
> can just as easily and only slightly less efficiently obtain the same
> result with a few extensions to the Bitcoin scripting system to verify
> ECDSA signatures directly.



From pete at petertodd.org  Sun Dec 21 18:51:26 2014
From: pete at petertodd.org (Peter Todd)
Date: Sun, 21 Dec 2014 13:51:26 -0500
Subject: [Bitcoin-development] one-show signatures (Re: The relationship
 between Proof-of-Publication and Anti-Replay Oracles)
In-Reply-To: <CALqxMTFK_sxdFjVi0qAC0JMdXa=tVBBNp0VrveRUfwa3b1UYhw@mail.gmail.com>
References: <CALqxMTFK_sxdFjVi0qAC0JMdXa=tVBBNp0VrveRUfwa3b1UYhw@mail.gmail.com>
Message-ID: <20141221185126.GC18711@savin.petertodd.org>

On Sun, Dec 21, 2014 at 06:10:47PM +0000, Adam Back wrote:
> Yes you could for example define a new rule that two signatures
> (double-spend) authorises something - eg miners to take funds. (And
> this would work with existing ECDSA addresses & unrestricted R-value
> choices).
> 
> I wasnt really making a point other than an aside that it maybe is
> sort-of possible to do with math what you said was not possible where
> you said "This [preventing signing more than one message] is
> impossible to implement with math alone".

Introducing a bunch of clever ECDSA math doesn't change the fact that
the clever math isn't what is preventing double-spending, clever
economics is. Just like Bitcoin itself.

No sense getting people potentially confused by a bunch of complex
equations that aren't relevant to the more fundemental and much more
important principle that math alone can't prevent double-spending.

-- 
'peter'[:-1]@petertodd.org
00000000000000001bc21486eb6e305efc085daa6b9acd37305feba64327342e
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141221/a20fc8eb/attachment.sig>

From jtimon at jtimon.cc  Sun Dec 21 19:39:46 2014
From: jtimon at jtimon.cc (=?UTF-8?B?Sm9yZ2UgVGltw7Nu?=)
Date: Sun, 21 Dec 2014 20:39:46 +0100
Subject: [Bitcoin-development] The relationship between
 Proof-of-Publication and Anti-Replay Oracles
In-Reply-To: <20141221160713.GD3927@savin.petertodd.org>
References: <20141212090551.GA8259@muck>
	<20141220144800.GA26284@savin.petertodd.org>
	<CAOG=w-vrHPY1aCNndmoW9QyCh9XnWyv8uZn2PyjZ6rNg2MoSSw@mail.gmail.com>
	<20141221055220.GB8255@savin.petertodd.org>
	<CABm2gDp0nw+z2NdaNDb8VQ=4e9Eh44mkzp9OePJyJfrbyfpy7A@mail.gmail.com>
	<20141221160713.GD3927@savin.petertodd.org>
Message-ID: <CABm2gDp8CphQf4awAft8S6whJ-_qxxfa4D9aeXFoXAiDLjcFQA@mail.gmail.com>

On Sun, Dec 21, 2014 at 5:07 PM, Peter Todd <pete at petertodd.org> wrote:
> On Sun, Dec 21, 2014 at 12:25:36PM +0100, Jorge Tim?n wrote:
>> So let's go through an example to see in which ways
>> non-proof-of-publication orders are "insecure".
>>
>> Alice the seller wants to sell 1 unit of A for 100 units of B.
>> Bob is willing to pay up to 200 Bs for 1 A.
>>
>> Let's assume a proof of publication system first, in which the
>> execution price is the mean between bid and ask.
>> Alice publishes her order.
>> Bob could publish his order at price 200 Bs and the order would
>> execute at 150 Bs.
>> But after seeing Alice's order he knows he doesn't need to pay that
>> much, so he publishes and order buying for 100 Bs.
>>
>> Alice gets 100 Bs (what she signed she wanted) and Bob pays less than
>> he was wiling to pay, he pays 100 Bs. Everybody happy.
>>
>> Now let's assume native assets and sighash_single.
>
> Incidentally, SIGHASH_SINGLE is just as usable in embedded consensus;
> it's not specific to native assets.
>
>> So again, what's the advantage that proof-of-publication provides TO
>> ALICE so that she will be so eager to pay the higher costs to get the
>> same deal?
>
> Like I said the last time this issue was discused on the mailing list,
> it's silly to think the seller of an asset starts off with a specific
> price they want to sell it at and is happy no matter what happens or how
> it gets fufilled. In the real world sellers and buyers want to know
> they're connected to actual sellers and buyers - not sybil attackers
> trying to shave off a margin for themselves - and are willing to pay a
> premium for that. Note all the hatred and vitrol directed towards
> high-frequency traders...

And like last time we discussed this on the mailing list my opinion
differs from yours.
You talk about "real world sellers and buyers" but ignore Alice the
seller and Bob the buyer in my example.
You failed to explain how sybil attackers (Carol) get all those
margins. In my example I claim miners get them, what am I missing?
How is the same example with a proof-of-publication market any better?
Miners can reorder the orders with proof of publication too.
If getting orders into mined blocks faster has an advantage miners can
charge privileged traders for privileged connections (just like it
happens today with "perfectly fair" centralized markets today that
feature the high-frequency trading you mention).
They could even charge for moving transactions around within the same
block if that has any effect on the execution rules.
I prefer that miners can get the difference between bids and asks
directly to compensate for their hashing power.

> How *much* of a premium is an interesting question, and depends a lot on
> the specific scenario. For instance I fully expect to see a whole
> variety of mediums become used for the proof-of-publication needed,
> ranging from directly on a major blockchain to minor/less secure
> blockchains like Bitmessage over treechains to centralized-but-audited
> proof-of-publication schemes - AKA centralized exchanges - to standard
> exchanges. Point is, the concept of proof-of-publication makes these
> tradeoffs and options available and lets end-users pick the right one
> for their needs.

The point is that there's more models for p2p markets beyond those
that require proof of publication for their orders, and you're
claiming that only those using proof of publication are secure.
That's incorrect.

> Accurate unbiased price information is worth money.

Can you define "Accurate unbiased price information"?

> In systems that
> allow third-parties to republish asset bids and offers we'll even see
> third-parties republishing bids and offers from less secure systems to
> more secure systems to get better price discovery.

Traders want to trade. The primary function of markets is exchange,
not price discovery.

>> If this example is not enough to be able to explain the advantage of
>> proof-of-publication markets feel free to write a more complex one.
>
> I gotta ask, have you actually run the design and tradeoffs of
> Friemarket's past actual finance types? I have, and it's remarkable how
> excited many of them are about cryptographically provable fair price
> discovery.

"Provably fair price discovery" is probably impossible. But I can
imagine how many people could get excited about such a technology.
Can you formally define what you mean by this?
You see, "fair" implies morality and therefore it's a very subjective
term, so it's not obvious to me what you may mean by that.


> --
> 'peter'[:-1]@petertodd.org
> 000000000000000002661192e72bdc83e6c8101371520159531301aa1437cc2c



From pete at petertodd.org  Mon Dec 22 00:11:37 2014
From: pete at petertodd.org (Peter Todd)
Date: Sun, 21 Dec 2014 19:11:37 -0500
Subject: [Bitcoin-development] The relationship between
 Proof-of-Publication and Anti-Replay Oracles
In-Reply-To: <20141220144800.GA26284@savin.petertodd.org>
References: <20141212090551.GA8259@muck>
	<20141220144800.GA26284@savin.petertodd.org>
Message-ID: <20141222001136.GA10165@savin.petertodd.org>

On Sat, Dec 20, 2014 at 09:48:01AM -0500, Peter Todd wrote:

Andrew Miller asked me to publish the following to the mailing list on his
behalf: (https://twitter.com/socrates1024/status/546819355565391872)

One of the main points in this note is that you can use a
"proof-of-publication" system to implement an "anti-replay" system.
However this isn't true - at least not given the description of
proof-of-(non)-publication in 2) and the definition of "anti-replay"
given here.

In 2), proof-of-*non*-publication allows you to prove that *some
specific message* has never been published. You can imagine having a
function ProveNotPublished(m), which proves "message m was not
published."

However, the anti-replay mechanism is about proving that *no* message
satisfying some property has been published. Hence
VerifyAntiReplaySig(m, p, s) checks that "for all possible messages m'
(distinct from m), AntiReplaySign(m', p) has not been called."


This isn't *just* splitting hairs, this distinction is actually
relevant for analyzing several cryptocurrency designs. You can imagine
extending the definition of proof-of-(non)-publication to take in some
predicate P, so that you can prove "no message m such that P(m) holds
has ever been published." However, to do this efficiently requires
anticipating some classes of P and building some appropriate indices.

- As a baseline, as long as you have the whole blockchain available,
you can scan through the entire blockchain and evaluate P for every
transaction, but this is pretty inefficient.
- Other tradeoffs are available if you are willing to trust some
(quora of) servers to maintain indices for you
- Bitcoin's UTXO set effectively supports a predicate for each txout,
where P(x) = "x is a valid tranasction that spends <txout>"
- Ethereum contracts, in a sense, allow for general purpose contracts
to 'build-your-own" index. On the other hand its key-value store
doesn't support range queries, so it's not necessarily "universal" or
as expressive as SQL, for example.


But the point isn't to argue about design choices and tradeoffs in
this thread. The main point I want to make is:
*Indexes and Validation Matter!*
The classic "proof-of-publication" system is to embed opaque data (as
far as bitcoin miners are concerned) in transactions using OP_RETURN.
A significance of establishing "proof-of-publication" as a universal
underlying primitive is that this OP_RETURN trick is then sufficient
for anything you might want. But part of what Bitcoin provides is
indexing and validation/exclusion, and this is important for
supporting efficient anti-replay proofs. Proof-of-(non)-publication
alone isn't sufficient for this.

-- 
'peter'[:-1]@petertodd.org
00000000000000000a7b40becd0babbd64ec49b8b34823fb4f4b081c95188b66
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 650 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141221/f4d89c08/attachment.sig>

From snow.paul at gmail.com  Mon Dec 22 00:56:28 2014
From: snow.paul at gmail.com (paul snow)
Date: Sun, 21 Dec 2014 18:56:28 -0600
Subject: [Bitcoin-development] one-show signatures (Re: The relationship
 between Proof-of-Publication and Anti-Replay Oracles)
In-Reply-To: <20141221185126.GC18711@savin.petertodd.org>
References: <CALqxMTFK_sxdFjVi0qAC0JMdXa=tVBBNp0VrveRUfwa3b1UYhw@mail.gmail.com>
	<20141221185126.GC18711@savin.petertodd.org>
Message-ID: <CAMU7uiu_wmsZRf6tXdE--rXLb6DSwJHs2YnspQ-cCoN_dw62JA@mail.gmail.com>

On Sun, Dec 21, 2014 at 12:51 PM, Peter Todd <pete at petertodd.org> wrote:

> On Sun, Dec 21, 2014 at 06:10:47PM +0000, Adam Back wrote:
> > Yes you could for example define a new rule that two signatures
> > (double-spend) authorises something - eg miners to take funds. (And
> > this would work with existing ECDSA addresses & unrestricted R-value
> > choices).
> >
> > I wasnt really making a point other than an aside that it maybe is
> > sort-of possible to do with math what you said was not possible where
> > you said "This [preventing signing more than one message] is
> > impossible to implement with math alone".
>
> Introducing a bunch of clever ECDSA math doesn't change the fact that
> the clever math isn't what is preventing double-spending, clever
> economics is. Just like Bitcoin itself.
>
> No sense getting people potentially confused by a bunch of complex
> equations that aren't relevant to the more fundemental and much more
> important principle that math alone can't prevent double-spending.


Math alone describes all of Bitcoin's structure; as math is a way to model
reality, it has no limits. Saying Math can't prevent double-spending is
near equivalent to saying it cannot be done.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141221/15e13227/attachment.html>

From adam at cypherspace.org  Mon Dec 22 20:05:40 2014
From: adam at cypherspace.org (Adam Back)
Date: Mon, 22 Dec 2014 20:05:40 +0000
Subject: [Bitcoin-development] The relationship between
 Proof-of-Publication and Anti-Replay Oracles
In-Reply-To: <20141220144800.GA26284@savin.petertodd.org>
References: <20141212090551.GA8259@muck>
	<20141220144800.GA26284@savin.petertodd.org>
Message-ID: <CALqxMTEjYsYs6uTfYKKAx_VCi1L8fHRX-MMKpYbMB56FNnHgqQ@mail.gmail.com>

(Again nothing new to say here, just putting my notes in this
discussion, where I started with an earlier discussion that Peter
wrote up with a subject of "disentangling" blockchain design).

In the discussion last year that started the analysis of
"disentangling" blockchain design I had broken out the candidate layer
properties that one could use as building blocks to construct a
decentralised PoW-chain assured immutable history based ecash system
as:

- time-stamping (really just time-ordered as network time is weak)

- namespace (first come first served name value pairs)

I thought it was interesting to look at potential minimum enabling
functionality in order to explore whether the consensus critical code
could be simplified for security, and also to understand the tradeoffs
towards seeing if there were any improvements that could be found.
(And it seems its pretty hard to find any improvements was my
conclusion).


Time-stamping (or time-ordering) at a requirements level does not have
to imply that there is a uniqueness guarantee, or even that the nodes
see what they are time-stamping (it could be committed with a random
nonce) and indeed hiding the committed data from the service and
public view is a common property of time-stamping.  Time-ordering just
creates an immutable (and not strongly deduplicated) stream of data
items that came from various users and had a time-ordering placed on
them.

Minimally the person who submitted the data item would need to know
the merkle path to it, and that might be achieved by publishing the
merkle tree, where some or all of the leaves are hidden commitments.

For bitcoin composability purposes you might require that there be no
hidden commitments, and then other miners and full nodes could
download all the merkle trees for each PoW-interval and ignore
duplicates.


Namespace service adds the uniqueness and first-come first-served
property up-front (as its more efficient for people catching up to not
have to download and discard duplicates/double-spends), and this more
strict rule requires miners to know about (and presumably index) all
previous information to avoid violating this rule. I assume name
attributes to hold information like a public key to approve changes in
ownership, an IP address, an email address etc.  For efficient proof
reasons there is still a merkle tree per PoW time-interval binding
names into a hash-chain.

For bitcoin re-described using a namespace the unique coins are the
names, and values and ownership public key etc are attributes of the
name; names (coins) are only added (via mining) or after deletion
(spend/transfer) of previous names.  Transfers are approved via
digital signature.

The additional property bitcoin requires is that the values add up.


I presume the phrase proof of publication means to draw out separately
that the full-node version of bitcoin requires a rule that miners
should not build on top of blocks unless they have copies of all data
committed to.  Otherwise a malicious party can hide ownership
transfers that can be revealed later, so that no one is assured of
ownership: any possibility for a gap in the ownership chain calls into
question ownership.  So from that perspective a miner consensus rule
that it should not build on top of blocks that it hasnt seen a full
gap-free history for makes the PoW chain a kind of proof that the
miner population at one time saw all data hashed into it.

I think you need one more thing which is that the miners (and other
full nodes who have copies of the data) are willing to share that
historic data with you.  There is some meta-incentive for bitcoin
holders to help others catchup and be assured of the history and
information has to be broadcast as there are many miners and
full-nodes.


I presume anti-relay term is meant at system level, rather than node
level, though technically bitcoin nodes in the current protocol
version dont relay double-spent transactions.  Particularly that
miners wont bless double-spent transactions (and will do PoW only over
non double-spent transfers).


While there does seem to be some confusion from some people perhaps
not realising that it is essential that there are no gaps in the
ownership chain, I am not sure there are necessarily any practical
implication of philosophical differences between proof of publication
& anti-relay (or namespace for that matter).  It is also important
that there is no way to attack the insertion logic so that eg someone
cant get a hash into an internal nor leaf node of the merkle tree
without the miners first seeing that data.

Presumably as they are all describing ways to think about bitcoin and
assuming no one is confused about how bitcoin works, the distinction
just comes down to what features are assumed to be naturally included
in the layer definition, and what features have to be added.  For
example I think its relatively normally assumed that people can look
up names.


I suppose it might be possible to put a self-authenticating access
handle for the data item into the data set which points into a
redundant immutable data store.  In effect that is what the bitcoin
nodes do provide (with full redundancy).  But, more efficiently though
perhaps with less redundancy and assurance, one could put the data
into tahoe-lafs which implements immutability, append-only and
self-authenticating urls and such properties.  From that perspective
it does make sense to say there is a layer that provides assurance of
availability of history; the PoW-chain and merkle-tree in the header
assures already immutability.  The remaining thing that has to be
assured is availability.

Adam

On 20 December 2014 at 14:48, Peter Todd <pete at petertodd.org> wrote:
> Gregory Maxwell recently pointed out to me in private conservation that
> there potentially existed a fundemental disagreement between him and I
> on our philosophical approaches to blockchains, in that he prioritised
> the notion of the blockchain as an anti-replay oracle, and I prioritised
> it as a publication layer. Here I'll talk about the differences and
> simularities between those two approaches.



From wbic16 at gmail.com  Wed Dec 24 17:08:59 2014
From: wbic16 at gmail.com (Will Bickford)
Date: Wed, 24 Dec 2014 11:08:59 -0600
Subject: [Bitcoin-development] Reading List for Getting Up to Speed
Message-ID: <CAB2qGxXm1brQLS_T8TWS50iH4me03HEOPh95BYOfk3UN6EnNhw@mail.gmail.com>

I've started to familiarize myself with the source code and build tools.
I'll be posting regular status updates on my blog (linked below) for others
to follow getting started with bitcoin development.

http://hewo.xedoloh.com/bitcoin-dev/

A tally from August indicated that I may need to slog through 280,000 lines
of code to get up to speed. I sampled
https://github.com/bitcoin/bitcoin/blob/master/src/key.cpp and skimmed it
in about 5 minutes, putting me at 2600 lines per hour. At that rate, I
would need to devote 110 hours to read the entire code base.

With that time investment I could get a fair amount of testing done, so I'm
curious if we have a map of the most important areas to study for new
developers and automated test writers.

Thanks for your time,

Will Bickford
"In Google We Trust"
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141224/948de5e7/attachment.html>

From gmaxwell at gmail.com  Wed Dec 24 19:44:37 2014
From: gmaxwell at gmail.com (Gregory Maxwell)
Date: Wed, 24 Dec 2014 19:44:37 +0000
Subject: [Bitcoin-development] Reading List for Getting Up to Speed
In-Reply-To: <CAB2qGxXm1brQLS_T8TWS50iH4me03HEOPh95BYOfk3UN6EnNhw@mail.gmail.com>
References: <CAB2qGxXm1brQLS_T8TWS50iH4me03HEOPh95BYOfk3UN6EnNhw@mail.gmail.com>
Message-ID: <CAAS2fgQhWXx1bqMpDs2qTngYmG8A-HLMKZOkuQf-P_JSL1JiPg@mail.gmail.com>

On Wed, Dec 24, 2014 at 5:08 PM, Will Bickford <wbic16 at gmail.com> wrote:
> A tally from August indicated that I may need to slog through 280,000 lines

You're counting 170kloc of machine generated code with the translation
strings there.

The top level (/src) and libconsensus are only about 36kloc. This is
small enough that I would strongly recommend at least skimming all of
it.



From wbic16 at gmail.com  Wed Dec 24 19:58:02 2014
From: wbic16 at gmail.com (Will Bickford)
Date: Wed, 24 Dec 2014 13:58:02 -0600
Subject: [Bitcoin-development] Reading List for Getting Up to Speed
In-Reply-To: <CAAS2fgQhWXx1bqMpDs2qTngYmG8A-HLMKZOkuQf-P_JSL1JiPg@mail.gmail.com>
References: <CAB2qGxXm1brQLS_T8TWS50iH4me03HEOPh95BYOfk3UN6EnNhw@mail.gmail.com>
	<CAAS2fgQhWXx1bqMpDs2qTngYmG8A-HLMKZOkuQf-P_JSL1JiPg@mail.gmail.com>
Message-ID: <CAB2qGxV_qjte1rVRMGCPaYWanMY+oYW0J1nBekO3WC9bg+DJqw@mail.gmail.com>

Gotcha. That's much more manageable. Thanks!

Will Bickford
"In Google We Trust"

On Wed, Dec 24, 2014 at 1:44 PM, Gregory Maxwell <gmaxwell at gmail.com> wrote:

> On Wed, Dec 24, 2014 at 5:08 PM, Will Bickford <wbic16 at gmail.com> wrote:
> > A tally from August indicated that I may need to slog through 280,000
> lines
>
> You're counting 170kloc of machine generated code with the translation
> strings there.
>
> The top level (/src) and libconsensus are only about 36kloc. This is
> small enough that I would strongly recommend at least skimming all of
> it.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141224/513a60a7/attachment.html>

From laanwj at gmail.com  Fri Dec 26 18:28:12 2014
From: laanwj at gmail.com (Wladimir)
Date: Fri, 26 Dec 2014 18:28:12 +0000
Subject: [Bitcoin-development] Bitcoin 0.10.0c1 available for download
Message-ID: <CA+s+GJBijiKETCKNXNMiz9uv6pPcDTb=Crk=cJj2yKQ9zk1eHQ@mail.gmail.com>

Signed executables are available for 0.10.0 release candidate 1, at

https://bitcoin.org/bin/0.10.0/test/

Preliminary release notes for the 0.10 release can be found here:
https://github.com/bitcoin/bitcoin/blob/0.10/doc/release-notes.md

Please report bugs using the issue tracker at github:
https://github.com/bitcoin/bitcoin/issues

Cheers,
Wladimir



From mike at plan99.net  Sun Dec 28 18:25:29 2014
From: mike at plan99.net (Mike Hearn)
Date: Sun, 28 Dec 2014 18:25:29 +0000
Subject: [Bitcoin-development] Cartographer
Message-ID: <CANEZrP1tGYOsShk5Z91_JwH7E0pX8WcyT_-ZBkrWBqZAyrcd1A@mail.gmail.com>

Hi there!

Lately we have been bumping up against the limitations of DNS as a protocol
for learning about the p2p network. As a proposal for how to address this,
I have written a new network crawler and seed:

https://github.com/mikehearn/httpseed

It implements a standard DNS seed with a minimal embedded DNS server (you
can find one running at dnsseed.vinumeris.com) and also has the following
extra features:


   - Can serve seed data using gzipped, timestamped digitally signed
   protocol buffers over HTTP. This fixes authentication, auditability,
   malware false positives and extensibility. The signature uses secp256k1.
   SSL is *not* used, to simplify deployment and to allow ISPs to cache the
   results transparently when a future version sets cache control headers.
   - Can additionally serve data in JSON, XML and HTML (examples for json
   <http://vinumeris.com:8081/peers.json> xml
   <http://vinumeris.com:8081/peers.xml> html
   <http://vinumeris.com:8081/peers.html>) for ease of use with other
   tools, like web browsers.
   - Results can be restricted using query parameters, e.g. for a service
   flags bit mask. Cartographer tests nodes that set service bit 2 to see if
   they really support BIP 64, and this requirement can also be specified as
   an argument to the query.
   - Crawl speed can be specified in terms of successful connects per
   second, rather than the number-of-threads approach used by other crawlers.
   - Can export statistics and controls using JMX, so you can reconfigure
   it at runtime and view charts of things like connects/sec or CPU usage
   using any JMX console, like Mission Control.
   - A client for it is in bitcoinj master branch.

To provide all these features Cartographer relies heavily on libraries and
is written in a concise new language called Kotlin <http://kotlinlang.org/>,
so it fits in about 650 lines of code. Kotlin is easy to learn for anyone
who knows Scala or Java, so it should be straightforward to hack on and
there is no chance of any buffer/heap exploits in the DNS, HTTP or Bitcoin
protocol stacks.

In the new year I will probably write a BIP describing the protocol. For
now you can see the definition here
<https://github.com/mikehearn/httpseed/blob/master/src/main/peerseeds.proto>
or just read the textual forms from the links above. It's pretty self
explanatory. I hope that in future other DNS seeds will start supporting
this protocol too, as it has many advantages.

Future versions might include data like how long the peer has been around,
node keys if we add auth/encrypt support to the p2p protocol and so on.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141228/f79042e7/attachment.html>

From mike at plan99.net  Sun Dec 28 18:04:08 2014
From: mike at plan99.net (Mike Hearn)
Date: Sun, 28 Dec 2014 18:04:08 +0000
Subject: [Bitcoin-development] Bitcoin XT
Message-ID: <CANEZrP2zxVgeqLZML0UUQUk8aLEZ=oY8pXdunjSq3qfakkdSHA@mail.gmail.com>

Hi there,

I hope everyone who celebrates Christmas is having a relaxing and enjoyable
break! :)

I'd like to announce Bitcoin XT <https://github.com/bitcoinxt/bitcoinxt>, a
patch set on top of Bitcoin Core 0.10rc1 that focuses on enhancements to
the peer to peer protocol. It is reproducibly built with gitian and there
are binaries for Linux, OS X and Windows (code signed). It currently
contains the following two features:

   1. Double spend relaying, by Gavin Andresen and Tom Harding. This is
   useful for merchants that currently connect to thousands of nodes to spot
   double spends, which is wasteful of resources.

   2. BIP 64 support (the getutxo message). This is useful for Lighthouse
   to render a more helpful GUI.

By running XT you provide additional services to users of the P2P network,
test the features more thoroughly and help build the case for inclusion in
Bitcoin Core.

There is a mailing list for discussion of patch inclusion
<https://groups.google.com/forum/#!forum/bitcoin-xt/>, and another list for
announcements <https://groups.google.com/forum/#!forum/bitcoin-xt-announce>.
Because XT is a patch set the feature branches will be rebased from time to
time. If you branch from them, be aware of that and plan accordingly.

XT nodes advertise themselves by using the getutxo service bit (i.e. bit
2). You can find them by querying a Cartographer, which I will describe in
another email.



A brief note about the goals of this project. The XT project is intended to
provide a friendly environment where [SPV] app developers and merchants can
experiment with new features and explore new directions for the protocol,
if there is demand for that. Those upgrades could then be considered for
inclusion into Core at a later date. I do not expect there to be thousands
of XT users any time soon, but that's OK. Because the patch set contains
features that don't require everyone to opt in (e.g. changes to the
tx/block formats), even just a few nodes can be useful.


Thanks for reading, and have a great new year's eve!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141228/35ae8c7b/attachment.html>

From thomas at thomaszander.se  Mon Dec 29 08:47:29 2014
From: thomas at thomaszander.se (Thomas Zander)
Date: Mon, 29 Dec 2014 09:47:29 +0100
Subject: [Bitcoin-development] Cartographer
In-Reply-To: <CANEZrP1tGYOsShk5Z91_JwH7E0pX8WcyT_-ZBkrWBqZAyrcd1A@mail.gmail.com>
References: <CANEZrP1tGYOsShk5Z91_JwH7E0pX8WcyT_-ZBkrWBqZAyrcd1A@mail.gmail.com>
Message-ID: <3685166.ROb67lzbMM@coldstorage>

On Sunday 28. December 2014 18.25.29 Mike Hearn wrote:
> Lately we have been bumping up against the limitations of DNS as a protocol
> for learning about the p2p network.

Can you explain further where limitations and problems were hit?

-- 
Thomas Zander



From pete at petertodd.org  Mon Dec 29 10:39:52 2014
From: pete at petertodd.org (Peter Todd)
Date: Mon, 29 Dec 2014 11:39:52 +0100
Subject: [Bitcoin-development] Cartographer
In-Reply-To: <3685166.ROb67lzbMM@coldstorage>
References: <CANEZrP1tGYOsShk5Z91_JwH7E0pX8WcyT_-ZBkrWBqZAyrcd1A@mail.gmail.com>
	<3685166.ROb67lzbMM@coldstorage>
Message-ID: <9C411ACE-B4C7-4AD0-B644-8DD4FC88352C@petertodd.org>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

A big one is the privacy is way too good: every DNS request goes through multiple levels of caching and indirection, so there's no way to figure out who made the request to subject them additional targeting.

A connection-oriented protocol gets rid of all those protections, giving us seed operators monetisation opportunities like selling usage statistics, per-client targeted results, etc. We recently got rid of all the "call-home" functionality that previously gave this type of insight; a connecyion-oriented seed protocol gives us this right back.

There's also this pesky problem of ISP's censoring DNS results with dumb automated systems to block malware - easily fixed with Gregory Maxwell's suggestion of permuting the results with XOR - but that kind of end-user driven solution really misses out in the needs of other Bitcoin stakeholders like law enforcement and marketing companies.


On 29 December 2014 09:47:29 CET, Thomas Zander <thomas at thomaszander.se> wrote:
>On Sunday 28. December 2014 18.25.29 Mike Hearn wrote:
>> Lately we have been bumping up against the limitations of DNS as a
>protocol
>> for learning about the p2p network.
>
>Can you explain further where limitations and problems were hit?
-----BEGIN PGP SIGNATURE-----
Version: APG v1.1.1

iQFQBAEBCAA6BQJUoS94MxxQZXRlciBUb2RkIChsb3cgc2VjdXJpdHkga2V5KSA8
cGV0ZUBwZXRlcnRvZGQub3JnPgAKCRAZnIM7qOfwhQzHB/97jRf4iX0v/zDW0EkT
8My2ExCdOqwYToxqTF0DQhwBjVzh2OHH9tVFKPXfgg87xtIxYZjx70yQpw7O4anw
7E5eJpFRjTayafclzRupgMn2AVT9AN45zjxkEutAEO27mxJ2p0OQPkNKzVR38sGW
95siatZMej68jflr0o0JrRePaDn3jufZEYQ5IvS80HxEwjzLCx/qCnPKkiKEQjr0
EHbovZo/5DNmJys4an+hoZkPeDRGw30w86kxXaY2SQP8aefswfg6rTOcrfkuQQfQ
AEYRZCZb6XxkL/gLU1dSgidswg+wgt/JW7QB+n6Z0fMGnX92EAxpwrvQUxDm55sC
HhOT
=dRuK
-----END PGP SIGNATURE-----




From mike at plan99.net  Mon Dec 29 11:30:42 2014
From: mike at plan99.net (Mike Hearn)
Date: Mon, 29 Dec 2014 11:30:42 +0000
Subject: [Bitcoin-development] Cartographer
In-Reply-To: <3685166.ROb67lzbMM@coldstorage>
References: <CANEZrP1tGYOsShk5Z91_JwH7E0pX8WcyT_-ZBkrWBqZAyrcd1A@mail.gmail.com>
	<3685166.ROb67lzbMM@coldstorage>
Message-ID: <CANEZrP0GsuiCF4oHGnTnVXwUsc0dNBOTtusr_CFn+29SxYYwHw@mail.gmail.com>

>
> Can you explain further where limitations and problems were hit?
>

Well, look at the feature list :)

The biggest need from my POV is querying support. It's awkward to try and
retrofit flexible key=value pair queries onto DNS, it just wasn't designed
for that. With HTTP it's easy. This will become more important in future as
the protocol evolves. For example, some nodes will soon stop serving the
block chain because they start pruning. Today this is managed with a hack:
pruning nodes just stop providing *all* services to the p2p network. This
takes them out of the DNS seeds entirely. But they can actually still
provide download of the parts of the chain they still have, and they can
provide transaction filtering and relay support, along with misc other
things.

With the current DNS protocol you get an all or nothing choice - so
probably seeds that only support it will elect to only show nodes that have
the entire block chain, because that's what Bitcoin Core would find most
useful. SPV wallets have slightly different needs.

In theory you could come up with a pile of hacks to specify what the client
needs in the DNS query, but then you have a v2 protocol anyway and might as
well go the whole way.

Additionally, with DNS it's awkward to provide extra data in the responses
beyond IP address and it's VERY awkward to sign the responses. Signing the
responses has a couple of benefits. The biggest is, in future it'd be nice
to have an authenticated and encrypted network, to raise the bar for sybil
and MITM attacks. DNS seeding can't be upgraded to support that with any
reasonable level of effort. And DNS is awkward to configure/set up.
Actually DNS is just awkward, period.

The second benefit of signing is it provides audibility. If you see a seed
give bad answers, you can now prove it to other people.

There is also the previously discussed issue that DNS seeds sometimes get
blocked by aggressive networks because they start serving IPs that are
infected with malware i.e. they look like fast-flux sites.

Using a simple HTTP based protocol fixes all of these problems in one go.

Now, re: privacy.

Firstly, Peter, get help. I'm serious. You are starting to sound like an
auto-generated parody of yourself. When you can't debate something as
boring as HTTP vs DNS without trying to raise an angry mob using bizarre
conspiracy theories, that's not normal.

I don't think the "DNS has caches" issue is worth worrying about for a lot
of reasons:

   1. Full nodes try as hard as they can to open ports and advertise their
   IP addresses to everyone. Even if you change the defaults to disable that,
   you're about to connect to a bunch of random computers with no reputation
   anyway.

   2. Lists of stale IP addresses are hardly useful to regular people and
   network operators can identify Bitcoin users by looking for traffic on port
   8333, so it's unclear what threat model is being addressed here.

   3. The biggest users of the seeds are all SPV wallets. Every single one
   of these already phones home to check for online updates.

   4. DNS proxying only hides part of the IP address. If you're serious
   about this you want to be doing lookups via Tor. Whilst it's possible to
   use the DNS seeds via Tor in a reasonable way with exit diversity (and
   bitcoinj does), doing it requires low level Tor protocol programming
   <https://github.com/bitcoinj/bitcoinj/blob/42f9d7c193fcd56fda7691b0ea934bae9d23f2d6/core/src/main/java/org/bitcoinj/net/discovery/TorDiscovery.java#L260>
   that is out of reach for most implementors. An HTTP lookup is trivial with
   any HTTP stack that supports SOCKS.

   5. ISPs also deploy transparent HTTP caches. The Cartographer protocol
   uses HTTP with inline signing so responses can be cached, once the right
   headers are being set.

tl;dr it's unclear that DNS caching actually solves any real privacy
problem but regardless, you can get the same distributed caching with HTTP
as with DNS. So in the end it makes little difference.

I believe that Cartographer is a better protocol all round and there are no
costs beyond the one-time upgrades, but even if for some reason you
disagree with the five privacy points above, I think the benefits still
massively outweigh the costs.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141229/c1277067/attachment.html>

From thomas at thomaszander.se  Mon Dec 29 11:49:45 2014
From: thomas at thomaszander.se (Thomas Zander)
Date: Mon, 29 Dec 2014 12:49:45 +0100
Subject: [Bitcoin-development] Cartographer
In-Reply-To: <CANEZrP0GsuiCF4oHGnTnVXwUsc0dNBOTtusr_CFn+29SxYYwHw@mail.gmail.com>
References: <CANEZrP1tGYOsShk5Z91_JwH7E0pX8WcyT_-ZBkrWBqZAyrcd1A@mail.gmail.com>
	<3685166.ROb67lzbMM@coldstorage>
	<CANEZrP0GsuiCF4oHGnTnVXwUsc0dNBOTtusr_CFn+29SxYYwHw@mail.gmail.com>
Message-ID: <26300405.yWTjxdDyQj@coldstorage>

On Monday 29. December 2014 11.30.42 Mike Hearn wrote:
> With the current DNS protocol you get an all or nothing choice

Its a seed. Not the protocol itself.

> Firstly, Peter, get help. I'm serious.
I think most would agree with me that, Mike, this answer is not just a little 
over the line, its unacceptable behavior in any collaborative group.
Please be respectful and avoid ad-hominem attacks.

-- 
Thomas Zander



From pete at petertodd.org  Mon Dec 29 11:59:16 2014
From: pete at petertodd.org (Peter Todd)
Date: Mon, 29 Dec 2014 12:59:16 +0100
Subject: [Bitcoin-development] Cartographer
In-Reply-To: <26300405.yWTjxdDyQj@coldstorage>
References: <CANEZrP1tGYOsShk5Z91_JwH7E0pX8WcyT_-ZBkrWBqZAyrcd1A@mail.gmail.com>
	<3685166.ROb67lzbMM@coldstorage>
	<CANEZrP0GsuiCF4oHGnTnVXwUsc0dNBOTtusr_CFn+29SxYYwHw@mail.gmail.com>
	<26300405.yWTjxdDyQj@coldstorage>
Message-ID: <8CB91BE2-ABA8-43B0-ADA5-CA1D811F80F5@petertodd.org>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256



On 29 December 2014 12:49:45 CET, Thomas Zander <thomas at thomaszander.se> wrote:
>On Monday 29. December 2014 11.30.42 Mike Hearn wrote:
>> With the current DNS protocol you get an all or nothing choice
>
>Its a seed. Not the protocol itself.
>
>> Firstly, Peter, get help. I'm serious.
>I think most would agree with me that, Mike, this answer is not just a
>little
>over the line, its unacceptable behavior in any collaborative group.
>Please be respectful and avoid ad-hominem attacks.

Yes I agree, Mike shouldn't be making ad-hominim attacks by calling people "a parody"

You'll note my response however carefully avoiding talking about the person who originated the idea, and merely stuck to criticising - via parody - the idea itself.

-----BEGIN PGP SIGNATURE-----
Version: APG v1.1.1

iQFQBAEBCAA6BQJUoUIUMxxQZXRlciBUb2RkIChsb3cgc2VjdXJpdHkga2V5KSA8
cGV0ZUBwZXRlcnRvZGQub3JnPgAKCRAZnIM7qOfwhfnpB/9JMcBtq7nCudCvXWgZ
TyKiSrK811L1PxtPih6UtzskFzNIKIVOgJrZcc0Cs7AoFoXiIPVEqzsqOOjZbhst
Op2w2scUoQhvhweNLAUdAH5dY+GFJoOn5fol4BD95SuFuao/t1J8G4Ma4b+JGXR5
vlXtDD/dBJNWJeSVKN/Mgcp7eis3lXp1/rzc9/Ka45oXvUHFSxvQq2v/KgFeHKJ7
onx551+41MS7R1bedg+dPOtCFBFycW51Obt7vS8GudRqwKyuKoKIQzY910gHYdXL
gTdQ16wXvp06fYlR4nJJPosE7ADP1udKJZNskVObJsX5z9sukI3r7noHNDDg3ZjH
bS9/
=ouap
-----END PGP SIGNATURE-----




From btcdrak at gmail.com  Mon Dec 29 12:13:41 2014
From: btcdrak at gmail.com (Btc Drak)
Date: Mon, 29 Dec 2014 12:13:41 +0000
Subject: [Bitcoin-development] Cartographer
In-Reply-To: <CANEZrP0GsuiCF4oHGnTnVXwUsc0dNBOTtusr_CFn+29SxYYwHw@mail.gmail.com>
References: <CANEZrP1tGYOsShk5Z91_JwH7E0pX8WcyT_-ZBkrWBqZAyrcd1A@mail.gmail.com>
	<3685166.ROb67lzbMM@coldstorage>
	<CANEZrP0GsuiCF4oHGnTnVXwUsc0dNBOTtusr_CFn+29SxYYwHw@mail.gmail.com>
Message-ID: <CADJgMzsL26G1YRK+gBfHx-=XOKVDQjj0=sdF-j3dur1Zux9Oew@mail.gmail.com>

Mike,

In all seriousness, are you on the payroll of the NSA or similar to
repeatedly attempt to introduce privacy leaks[1] and weaknesses[2] into the
ecosystem not to mention logical fallacies like ad hominem attacks;
disruption[3] and FUD[4]?

Why do you answer objections by hand waving and misdirection as opposed to
sound technical reasoning? Remember how hand waving ended for you the last
time with your p2p getutxo pull-request[5] and the public flogging the
ensued because you refused to accept your implementation was not only
flawed but critically vulnerable to attack[6].

Given your intelligence, education and experience, it would seem logical
that your behaviour is not random or irrational, but in fact calculated and
planned.

references:
[1]
http://www.reddit.com/r/Bitcoin/comments/2byqz0/mike_hearn_proposes_to_build_vulnerable/
[2]
https://www.reddit.com/r/Bitcoin/comments/1qmbtu/mike_hearn_chair_of_the_bitcoin_foundations_law/
[3]
http://www.reddit.com/r/Bitcoin/comments/28zts3/mike_hearn_interview_quotes_progress_on_the/
[4] https://www.youtube.com/watch?v=iMIzMVABFxQ
[5] https://github.com/bitcoin/bitcoin/pull/4351
[6]
http://www.reddit.com/r/Bitcoin/comments/2eq8gi/getutxos_a_convenient_way_to_crash_bitcoind/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141229/e9e1441f/attachment.html>

From misterbg6 at gmail.com  Mon Dec 29 13:08:52 2014
From: misterbg6 at gmail.com (Mistr Bigs)
Date: Mon, 29 Dec 2014 14:08:52 +0100
Subject: [Bitcoin-development] Cartographer
In-Reply-To: <CADJgMzsL26G1YRK+gBfHx-=XOKVDQjj0=sdF-j3dur1Zux9Oew@mail.gmail.com>
References: <CANEZrP1tGYOsShk5Z91_JwH7E0pX8WcyT_-ZBkrWBqZAyrcd1A@mail.gmail.com>
	<3685166.ROb67lzbMM@coldstorage>
	<CANEZrP0GsuiCF4oHGnTnVXwUsc0dNBOTtusr_CFn+29SxYYwHw@mail.gmail.com>
	<CADJgMzsL26G1YRK+gBfHx-=XOKVDQjj0=sdF-j3dur1Zux9Oew@mail.gmail.com>
Message-ID: <CABssiCpUTbNQZtsAJPJwU9mDxXR71ubBtDsA1J9fwgE8sxNo=g@mail.gmail.com>

As an outside observer, I have to say I also found Peter's sardonic message
tone inappropriate for furthering the discussion.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141229/05f09336/attachment.html>

From sergiolerner at certimix.com  Mon Dec 29 19:21:02 2014
From: sergiolerner at certimix.com (Sergio Lerner)
Date: Mon, 29 Dec 2014 16:21:02 -0300
Subject: [Bitcoin-development] BIP: Voluntary deposit bonds
Message-ID: <54A1A99E.1020604@certimix.com>

I propose to allow miners to voluntarily lock funds by letting miners
add additional inputs to the coinbase transaction. Currently the
coinbase transaction does not allow any real input  to be added (only a
pseudo-input).
This is a hard-fork, and we could include it the next time a hardfork is
made.
The modifications to the code are minimal (no more than 12 lines
modified where IsCoinBase() is called), and they generally involve
removing code, not adding.

Why ?

Because sometime in the future (maybe 5-10 years) we may have to deal
with problems of securing the blockchain, as the subsidy is lowered. We
don't want the number of confirmation blocks to be increased in
compensation because Bitcoin won't be able to compete with other payment
networks.
Then by having this hardfork now, we will be able to soft-fork later to
any rule we may came come up with involving deposit bonds,
proof-of-stake, and the penalization of double-mining (mining two blocks
at the same height) to prevent short-range attacks.

Can it hurt?

No. I doesn't not change the incentives or the security in any way, as
adding additional inputs to the coinbase transaction would be voluntary
until the time for a soft-fork comes.
We shouldn't hard-fork for this change only, but maybe we could do this
change when the next hard-fork is scheduled (when we increase the block
size?).

Regards, S.











From mike at plan99.net  Mon Dec 29 21:10:20 2014
From: mike at plan99.net (Mike Hearn)
Date: Mon, 29 Dec 2014 21:10:20 +0000
Subject: [Bitcoin-development] BIP: Voluntary deposit bonds
In-Reply-To: <54A1A99E.1020604@certimix.com>
References: <54A1A99E.1020604@certimix.com>
Message-ID: <CANEZrP0zVTVdDWZCUk9wvcuAjBi4Eq+a8SQP4-R5aKrxDw_xMA@mail.gmail.com>

Could you explain a bit further Sergio? I'm not sure I fully understand the
proposal.

How does adding inputs to a coinbase differ from just having pay-to-fee
transactions in the block?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141229/9a0dc72b/attachment.html>

From luke at dashjr.org  Mon Dec 29 22:35:04 2014
From: luke at dashjr.org (Luke Dashjr)
Date: Mon, 29 Dec 2014 22:35:04 +0000
Subject: [Bitcoin-development] BIP: Voluntary deposit bonds
In-Reply-To: <54A1A99E.1020604@certimix.com>
References: <54A1A99E.1020604@certimix.com>
Message-ID: <201412292235.05695.luke@dashjr.org>

On Monday, December 29, 2014 7:21:02 PM Sergio Lerner wrote:
> I propose to allow miners to voluntarily lock funds by letting miners
> add additional inputs to the coinbase transaction. Currently the
> coinbase transaction does not allow any real input  to be added (only a
> pseudo-input).

This is something I've wanted since 2011, but hasn't been a priority.

> Because sometime in the future (maybe 5-10 years) we may have to deal
> with problems of securing the blockchain, as the subsidy is lowered. We
> don't want the number of confirmation blocks to be increased in
> compensation because Bitcoin won't be able to compete with other payment
> networks.
> Then by having this hardfork now, we will be able to soft-fork later to
> any rule we may came come up with involving deposit bonds,
> proof-of-stake, and the penalization of double-mining (mining two blocks
> at the same height) to prevent short-range attacks.

I'm not sure this increases the priority of it.

If someone feels it's worth the time, I'd suggest coding up a branch that 
hardforks it in at some far-off block height. Even if it doesn't get merged 
right away, at least the code will be available for testing and ready to go 
when/if that time comes.

Luke



From justus.ranvier at monetas.net  Mon Dec 29 21:34:07 2014
From: justus.ranvier at monetas.net (Justus Ranvier)
Date: Mon, 29 Dec 2014 21:34:07 +0000
Subject: [Bitcoin-development] BIP: Voluntary deposit bonds
In-Reply-To: <CANEZrP0zVTVdDWZCUk9wvcuAjBi4Eq+a8SQP4-R5aKrxDw_xMA@mail.gmail.com>
References: <54A1A99E.1020604@certimix.com>
	<CANEZrP0zVTVdDWZCUk9wvcuAjBi4Eq+a8SQP4-R5aKrxDw_xMA@mail.gmail.com>
Message-ID: <54A1C8CF.50907@monetas.net>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

On 12/29/2014 09:10 PM, Mike Hearn wrote:
> How does adding inputs to a coinbase differ from just having
> pay-to-fee transactions in the block?

If a miner includes pay-to-fee transactions in a block, those fees
could be claimed by another miner in the case the first miner's block
is orphaned.

Inputs to a generation transaction can not be similarly poached.

That difference makes some services possible that would can not be
safely achieved with pay-to-fee transactions.

- -- 
Justus Ranvier                   | Monetas <http://monetas.net/>
<mailto:justus at monetas.net>      | Public key ID : C3F7BB2638450DB5
                                 | BM-2cTepVtZ6AyJAs2Y8LpcvZB8KbdaWLwKqc
-----BEGIN PGP SIGNATURE-----

iQEcBAEBCAAGBQJUocjPAAoJEMP3uyY4RQ21zrMH/1f3vjac9XqOZbDItjiD6XXU
EkpRUROjyQAs6/tO6dwWAIcXgulYREAJsU/udQNkTYteIDFlDzwkYL+NLXpYtwHs
BiZJEEwmAEHFgOD3QmmqhTx867zIbEYIB/dpHlMOppE6fhTKFr9z6JdqAKlNcHHW
tkW5sq8q9uq7StiUs3/mmZ0XXeEb84N+bPiJ9S7kuTm9QWnrF1oMLhAk4M6yX8hn
7MUowmfc9RZ4uIFkqxk6gkWJSRx7dlnCRP2TRhyABpZwAcZANuPhqBOZ6eJ6T9Fs
DOJ14c5JYachXW5z8GqR+abeq0JPE76kEQt145B4degJ4DTQLLhlfdvjbuJvzy4=
=Kfe2
-----END PGP SIGNATURE-----
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x38450DB5.asc
Type: application/pgp-keys
Size: 14542 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141229/66a61d85/attachment.bin>

From luke at dashjr.org  Mon Dec 29 22:36:48 2014
From: luke at dashjr.org (Luke Dashjr)
Date: Mon, 29 Dec 2014 22:36:48 +0000
Subject: [Bitcoin-development] BIP: Voluntary deposit bonds
In-Reply-To: <CANEZrP0zVTVdDWZCUk9wvcuAjBi4Eq+a8SQP4-R5aKrxDw_xMA@mail.gmail.com>
References: <54A1A99E.1020604@certimix.com>
	<CANEZrP0zVTVdDWZCUk9wvcuAjBi4Eq+a8SQP4-R5aKrxDw_xMA@mail.gmail.com>
Message-ID: <201412292236.49596.luke@dashjr.org>

On Monday, December 29, 2014 9:10:20 PM Mike Hearn wrote:
> How does adding inputs to a coinbase differ from just having pay-to-fee
> transactions in the block?

Pay-to-fee transactions can be "stolen" by another block at the same or 
greater height. Additional inputs to the generation transaction are tied to 
that block alone.

Luke



From gmaxwell at gmail.com  Tue Dec 30 04:51:51 2014
From: gmaxwell at gmail.com (Gregory Maxwell)
Date: Tue, 30 Dec 2014 04:51:51 +0000
Subject: [Bitcoin-development] BIP: Voluntary deposit bonds
In-Reply-To: <54A1A99E.1020604@certimix.com>
References: <54A1A99E.1020604@certimix.com>
Message-ID: <CAAS2fgSvq_Tnon1C+xED06VYPizj+XTiDu0xm0MvCg_9-ejcjA@mail.gmail.com>

On Mon, Dec 29, 2014 at 7:21 PM, Sergio Lerner
<sergiolerner at certimix.com> wrote:
> I propose to allow miners to voluntarily lock funds by letting miners
> add additional inputs to the coinbase transaction. Currently the
> coinbase transaction does not allow any real input  to be added (only a
> pseudo-input).
> This is a hard-fork, and we could include it the next time a hardfork is
> made.
> The modifications to the code are minimal (no more than 12 lines
> modified where IsCoinBase() is called), and they generally involve
> removing code, not adding.


If the motivation is purely enabling different rules in a soft-fork
than I think nothing needs to be done.

Instead of providing inputs to a coinbase: you provide an unusual
anyone can spend transaction in the block which pays to fees; and
simultaneously add a soft-forking rule that makes that anyone can
spend rule no longer anyone can spend.

To make that more concrete.  E.g. You make your anyone can spend
output   "PUSH<hash of coinbase output script_pubkeys> OP_NOP3".  Now
this anyone can pay transaction is really just a coinbase input.

The construction is reasonably efficient, and also more flexible-- in
that it could control the data under the hash in more flexible ways
than available in the existing sighash flags.


As an aside, I'm not sure that I agree with the claim that making
coinbases have inputs is a simple modification... as we use one of the
inputs already as the special coinbase field and at least that must be
special cased.



From jtimon at jtimon.cc  Tue Dec 30 10:47:46 2014
From: jtimon at jtimon.cc (=?UTF-8?B?Sm9yZ2UgVGltw7Nu?=)
Date: Tue, 30 Dec 2014 11:47:46 +0100
Subject: [Bitcoin-development] BIP: Voluntary deposit bonds
In-Reply-To: <54A1C8CF.50907@monetas.net>
References: <54A1A99E.1020604@certimix.com>
	<CANEZrP0zVTVdDWZCUk9wvcuAjBi4Eq+a8SQP4-R5aKrxDw_xMA@mail.gmail.com>
	<54A1C8CF.50907@monetas.net>
Message-ID: <CABm2gDo4XFvcYhwhiTu3L8Hf6dQMohSk5GE2dg8wQWky1iuS1w@mail.gmail.com>

On Mon, Dec 29, 2014 at 10:34 PM, Justus Ranvier
<justus.ranvier at monetas.net> wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> On 12/29/2014 09:10 PM, Mike Hearn wrote:
>> How does adding inputs to a coinbase differ from just having
>> pay-to-fee transactions in the block?
>
> If a miner includes pay-to-fee transactions in a block, those fees
> could be claimed by another miner in the case the first miner's block
> is orphaned.
>
> Inputs to a generation transaction can not be similarly poached.
>
> That difference makes some services possible that would can not be
> safely achieved with pay-to-fee transactions.

What services?
I must be missing something obvious about the motivation.
I understand the difference between "paying to myself only when I mine
the next block" and "offering fees to whoever mines this tx".
But how does allowing miners to pay to themselves in this way help
with security and future lower subsidies at all?



From justus.ranvier at monetas.net  Tue Dec 30 13:16:56 2014
From: justus.ranvier at monetas.net (Justus Ranvier)
Date: Tue, 30 Dec 2014 13:16:56 +0000
Subject: [Bitcoin-development] BIP: Voluntary deposit bonds
In-Reply-To: <CABm2gDo4XFvcYhwhiTu3L8Hf6dQMohSk5GE2dg8wQWky1iuS1w@mail.gmail.com>
References: <54A1A99E.1020604@certimix.com>	<CANEZrP0zVTVdDWZCUk9wvcuAjBi4Eq+a8SQP4-R5aKrxDw_xMA@mail.gmail.com>	<54A1C8CF.50907@monetas.net>
	<CABm2gDo4XFvcYhwhiTu3L8Hf6dQMohSk5GE2dg8wQWky1iuS1w@mail.gmail.com>
Message-ID: <54A2A5C8.4010804@monetas.net>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

On 12/30/2014 10:47 AM, Jorge Tim?n wrote:
> What services? I must be missing something obvious about the
> motivation. I understand the difference between "paying to myself
> only when I mine the next block" and "offering fees to whoever
> mines this tx". But how does allowing miners to pay to themselves
> in this way help with security and future lower subsidies at all?

I don't know what Sergio Lernet meant about miners paying themselves
and future network security.

If miners wanted to offer value-added services, especially if those
services involved adding specific scripts to the outputs of the
generation transaction, the most natural way for their customers to
pay them is to allow inputs to the generation transaction.

It could also be done with pay-to-fee transactions, but that would
make the services more expensive due to risk premium.

- -- 
Justus Ranvier                   | Monetas <http://monetas.net/>
<mailto:justus at monetas.net>      | Public key ID : C3F7BB2638450DB5
                                 | BM-2cTepVtZ6AyJAs2Y8LpcvZB8KbdaWLwKqc
-----BEGIN PGP SIGNATURE-----

iQEcBAEBCAAGBQJUoqXIAAoJEMP3uyY4RQ21OZUH/iI9N9bQ3TLPnmCVW6bkIitD
WT6uBUhBREls2NMjyDQ//UN9F9nt+aU7jN/I0AMrdB8ngFb4r1gfxSpld9KVp6Yw
k3jW8Lo3WhTnCCE0a1MbBqomsAfIwDdksZoH73QW+sGYD+cShgFC55QWfE6gy3OF
pge1dsWNPlMSHmWn9+g7g3+FjkhKeZFNSb0MKzIvEBE7iJOf85etJpMs9a/425sx
UcJX33bVdhG51Au3PSs+0jUljoFby28EM717otq8Tkjei2hw1yNNmtws4/NcQlh3
W6TGBZLb188hUrOOH52p2Cckm8gGgw9hTc9nSLSjQS2pPjVRpTRR4smxMTKND9E=
=QBYE
-----END PGP SIGNATURE-----
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x38450DB5.asc
Type: application/pgp-keys
Size: 14542 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141230/ae058422/attachment.bin>

From sergiolerner at certimix.com  Tue Dec 30 16:25:24 2014
From: sergiolerner at certimix.com (Sergio Lerner)
Date: Tue, 30 Dec 2014 13:25:24 -0300
Subject: [Bitcoin-development] BIP: Voluntary deposit bonds
In-Reply-To: <CAAS2fgSvq_Tnon1C+xED06VYPizj+XTiDu0xm0MvCg_9-ejcjA@mail.gmail.com>
References: <54A1A99E.1020604@certimix.com>
	<CAAS2fgSvq_Tnon1C+xED06VYPizj+XTiDu0xm0MvCg_9-ejcjA@mail.gmail.com>
Message-ID: <54A2D1F4.9050306@certimix.com>


On 30/12/2014 01:51 a.m., Gregory Maxwell wrote:
> On Mon, Dec 29, 2014 at 7:21 PM, Sergio Lerner
> <sergiolerner at certimix.com> wrote:
>> I propose to allow miners to voluntarily lock funds by letting miners
>> add additional inputs to the coinbase transaction. Currently the
>> coinbase transaction does not allow any real input  to be added (only a
>> pseudo-input).
>>
>
> To make that more concrete.  E.g. You make your anyone can spend
> output   "PUSH<hash of coinbase output script_pubkeys> OP_NOP3".  Now
> this anyone can pay transaction is really just a coinbase input.

Slight off-topic:
That looks like an abuse of the VM. Even P2SH is an abuse of the VM.
Gavin's OP_EVAL (hard-fork) should had been chosen. I'm taking about a
simple change that goes along the lines of Satoshi's original design.
Bitcoin was a beautiful design, and extra complexity is making it ugly.
We need Bitcoin to be simple to understand for new programmers so they
can keep the project going. It doesn't help the project that one needs
to be a guru to code for Bitcoin.



From gmaxwell at gmail.com  Tue Dec 30 18:28:54 2014
From: gmaxwell at gmail.com (Gregory Maxwell)
Date: Tue, 30 Dec 2014 18:28:54 +0000
Subject: [Bitcoin-development] BIP: Voluntary deposit bonds
In-Reply-To: <54A2D1F4.9050306@certimix.com>
References: <54A1A99E.1020604@certimix.com>
	<CAAS2fgSvq_Tnon1C+xED06VYPizj+XTiDu0xm0MvCg_9-ejcjA@mail.gmail.com>
	<54A2D1F4.9050306@certimix.com>
Message-ID: <CAAS2fgRxysRqkSxqbF8Y9u2ptfVjX0PU6W85jD-RjSn9hUqNBA@mail.gmail.com>

On Tue, Dec 30, 2014 at 4:25 PM, Sergio Lerner
<sergiolerner at certimix.com> wrote:
> Slight off-topic:
> That looks like an abuse of the VM. Even P2SH is an abuse of the VM.
> Gavin's OP_EVAL (hard-fork) should had been chosen. I'm taking about a
> simple change that goes along the lines of Satoshi's original design.
> Bitcoin was a beautiful design, and extra complexity is making it ugly.
> We need Bitcoin to be simple to understand for new programmers so they
> can keep the project going. It doesn't help the project that one needs
> to be a guru to code for Bitcoin.

Sergio there is no "abuse" there,  OP_NOP3 in that case would be
redefined to OP_COINBASE_FOO_CONSISTENCY.

(I say FOO because it's not clear what rule you actually hope to apply there.)

What you suggested has no purpose by itself: it would need an
additional change which overlays functionality in order to actually do
something. Such a change would likely be "ugly"-- it's easy to be
elegant when you do nothing.



From stephencalebmorse at gmail.com  Wed Dec 31 18:25:41 2014
From: stephencalebmorse at gmail.com (Stephen Morse)
Date: Wed, 31 Dec 2014 13:25:41 -0500
Subject: [Bitcoin-development] BIP: Voluntary deposit bonds
In-Reply-To: <CAAS2fgRxysRqkSxqbF8Y9u2ptfVjX0PU6W85jD-RjSn9hUqNBA@mail.gmail.com>
References: <54A1A99E.1020604@certimix.com>
	<CAAS2fgSvq_Tnon1C+xED06VYPizj+XTiDu0xm0MvCg_9-ejcjA@mail.gmail.com>
	<54A2D1F4.9050306@certimix.com>
	<CAAS2fgRxysRqkSxqbF8Y9u2ptfVjX0PU6W85jD-RjSn9hUqNBA@mail.gmail.com>
Message-ID: <CABHVRKT6TFcdbqbdyX8D-zbUO4xFXuL3LLd1R7VLH4=JGEK9UQ@mail.gmail.com>

I agree with Gregory Maxwell, I don't think it would be as easy as just
changing IsCoinBase(), since there are places where the code assumes that
the coinbase's vin doesn't spend any prevouts and/or has size 1. For
example, here
<https://github.com/bitcoin/bitcoin/blob/v0.9.3/src/main.cpp#L617-620> and
here <https://github.com/bitcoin/bitcoin/blob/v0.9.3/src/main.cpp#L785-L808>
.

I think the motivation behind the original suggestion is to have a way to
pay specific miners upon solving a block without risking possibly paying
other miners through pay-to-fee. What I'm not sure about, though, is why
not just send them a transaction once you see that the miner has solved a
block? Not a pay-to-fee transaction, a pay to pubkeyhash or whatever type
of transaction you need to make to send the miner some coins.

Although I don't completely understand the motivation for making such
transactions, maybe this would this work. Have outputs in the coinbase
transaction which have nValue == 0, then only apply the COINBASE_MATURITY
rule to spending coinbase outputs which have non-zero value. That way you
could make a transactions which is only valid after the miner specified
solves a block with the coinbase having the same TxID referenced by the new
transaction's input. It's still a hard fork, but might be easier than
allowing the coinbase to spend prevouts. I guess, at that point though, why
not just hard fork to allow the coinbase to spend prevouts...

Best,
Stephen

On Tue, Dec 30, 2014 at 1:28 PM, Gregory Maxwell <gmaxwell at gmail.com> wrote:

> On Tue, Dec 30, 2014 at 4:25 PM, Sergio Lerner
> <sergiolerner at certimix.com> wrote:
> > Slight off-topic:
> > That looks like an abuse of the VM. Even P2SH is an abuse of the VM.
> > Gavin's OP_EVAL (hard-fork) should had been chosen. I'm taking about a
> > simple change that goes along the lines of Satoshi's original design.
> > Bitcoin was a beautiful design, and extra complexity is making it ugly.
> > We need Bitcoin to be simple to understand for new programmers so they
> > can keep the project going. It doesn't help the project that one needs
> > to be a guru to code for Bitcoin.
>
> Sergio there is no "abuse" there,  OP_NOP3 in that case would be
> redefined to OP_COINBASE_FOO_CONSISTENCY.
>
> (I say FOO because it's not clear what rule you actually hope to apply
> there.)
>
> What you suggested has no purpose by itself: it would need an
> additional change which overlays functionality in order to actually do
> something. Such a change would likely be "ugly"-- it's easy to be
> elegant when you do nothing.
>
>
> ------------------------------------------------------------------------------
> Dive into the World of Parallel Programming! The Go Parallel Website,
> sponsored by Intel and developed in partnership with Slashdot Media, is
> your
> hub for all things parallel software development, from weekly thought
> leadership blogs to news, videos, case studies, tutorials and more. Take a
> look and join the conversation now. http://goparallel.sourceforge.net
> _______________________________________________
> Bitcoin-development mailing list
> Bitcoin-development at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/bitcoin-development
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20141231/83b8f521/attachment.html>

