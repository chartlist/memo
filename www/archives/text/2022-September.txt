From ali at notatether.com  Sun Sep  4 22:31:38 2022
From: ali at notatether.com (Ali Sherief)
Date: Sun, 04 Sep 2022 22:31:38 +0000
Subject: [bitcoin-dev] Multipayment Channels - A scalability solution for
	Layer 1
Message-ID: <20220904223132.zpvhw6hcekaowlme@artanis>

Over the past few days I've figured out a novel way to batch transactions together into blocks, thereby compacting the transaction size and increasing the transactions-per-second. This is all on layer 1, without any hardforks - only a single softfork is required to add MuSig1 support for individual invoice addresses.

The nucleus of the idea was born after a discussion with Greg Maxwell about a different BIP (Implementing multisig using Taproot, to be specific)[1]. He suggested to me that I should add MuSig1 signatures into the Taproot script paths.

After some thinking, I realized a use case for MuSig1 signatures as a kind of on-chain Lightning Network. Allow me to explain:

LN is very attractive to users because it keeps intermediate transaction states off-chain, and only broadcasts the final state. But without mitigations in the protocol, it suffers from two disadvantages:

- You have to trust the other channel partner not to broadcast a previous state
- You also have to trust all the middlemen in intermediate channels not to do the above.

Most of us probably know that many mitigations have been created for this problem, e.g. penalty transactions. But what if it were possible to create a scheme where so-called technical fraud is not possible? That is what I'm going to demonstrate here.

My scheme makes use of MuSig1, OP_CHECKLOCKTIMEVERIFY (OP_CLTV) timelock type, and negligible OP_RETURN data. It revolves around constructs I call "multipayment channels", called so because they allow multiple people to pay in one transaction - something that is already possible BTW, but with much larger tx size (for large number of cosigners) than when using MuSig1. These have the advantage over LN channels that the intermediate state is also on the blockchain, but it's very compact.

A channel consists of a fixed amount of people N. These people open a channel by creating a (optionally Taproot) address with the following script:
<blockheightofoutput+desiredwaitingblocks>* OP_CTLV OP_DROP <N-of-N MuSig1> OP_CHECKMUSIG**

Simultaneously, each of the N participants receives the N signatures and constructs the N-of-N MuSig. Each participant will use this MuSig to generate his own independent "commitment transaction" with the following properties:

- It has a single input, the MuSig output. It has an nSequence of desiredwaitingblocks. <This prevents the output from being spent immediately.>
- It has outputs corresponding to the addresses and balances of each of the participants in the agreed-upon distribution.
Disadvantage: Because the N-of-N signature is given to all participants, it might be leaked into the public and consequentially anybody can spend this transaction after the timelock, to commit the balance.*** On the other hand, removing the timelocks means that if one of the participants goes missing, all funds are locked forever.****

A second output with a script OP_RETURN <32-byte connection ID> can be added to the transaction to enable L1 channel discovery.

Full nodes parsing the blockchain can maintain a list of connection IDs to connect to (but without a non-malleable refund transaction, nobody is going to use this). SPVs can simply export a list of them from Full Nodes.

A connection only lasts for one transaction. Spending the output to another MuSig of the above format will create a new connection if it spends to a similarly-constructed MuSig output with different signature. In all cases, the current connection is destroyed.

*This introduces a variable grace period, in blocks, after which anybody can broadcast this transaction to commit the channel funds distribution to each of the participants' addresses. blockheightofoutput is the block height of the musig output, and desiredwaitingblocks is the maximum number of blocks the connection can stay alive for.
**This implies that a hypothetical OP_CHECKMUSIG would take a single aggregated signature, a single aggregated public key, and an integer N that denotes how many public keys were combined together. I elected not to overload OP_CHECKSIG since MuSig and regular signatures are both valid for the same address types. This part is a rought draft and requires lots of work on making an OP_CHECKMUSIG opcode that satisfies the requirements of multipayment channels.
***This is quite a bad flaw of this scheme because it means that all the participants must be trustworthy - you can't use this in trustless environments. I appreciate any ways on how to implement non-malleable refund transactions with single (non-aggregated) signatures!
****Perhaps the best solution is to offer both alternatives: <N-of-N MuSig1> OP_CHECKMUSIG in a public scenario where none of the participants want to face the prospect of losing their money, and <blockheightofoutput+desiredwaitingblocks>* OP_CTLV OP_DROP <N-of-N MuSig1> OP_CHECKMUSIG with signature sharing in private scenarios.

This draft is very crude and parts have not been fully developed. Tips for fleshing it out is much appreciated. Not that there's anything wrong with LN for that matter, I'm just concerned about the security reprocussions of not broadcasting intermediate transactions, and its enabling of crime.

- Ali

[1]: https://bitcointalk.org/index.php?topic=5410553.0


From ZmnSCPxj at protonmail.com  Mon Sep  5 03:17:27 2022
From: ZmnSCPxj at protonmail.com (ZmnSCPxj)
Date: Mon, 05 Sep 2022 03:17:27 +0000
Subject: [bitcoin-dev] Multipayment Channels - A scalability solution
	for Layer 1
In-Reply-To: <20220904223132.zpvhw6hcekaowlme@artanis>
References: <20220904223132.zpvhw6hcekaowlme@artanis>
Message-ID: <bm20xKm5eaD1AqJh8hDHq8FRjajvA5Ah8f8qFzILCJeTJaLkRflBAi6q3NABipq-XkIwdzo78Rdt1vQcRNcyyUp0G8gCMDVq-9VCraVYJ9E=@protonmail.com>

Good morning Ali,

> Over the past few days I've figured out a novel way to batch transactions together into blocks, thereby compacting the transaction size and increasing the transactions-per-second. This is all on layer 1, without any hardforks - only a single softfork is required to add MuSig1 support for individual invoice addresses.
> 
> The nucleus of the idea was born after a discussion with Greg Maxwell about a different BIP (Implementing multisig using Taproot, to be specific)[1]. He suggested to me that I should add MuSig1 signatures into the Taproot script paths.
> 
> After some thinking, I realized a use case for MuSig1 signatures as a kind of on-chain Lightning Network. Allow me to explain:
> 
> LN is very attractive to users because it keeps intermediate transaction states off-chain, and only broadcasts the final state. But without mitigations in the protocol, it suffers from two disadvantages:
> 
> - You have to trust the other channel partner not to broadcast a previous state
> - You also have to trust all the middlemen in intermediate channels not to do the above.
> 
> Most of us probably know that many mitigations have been created for this problem, e.g. penalty transactions. But what if it were possible to create a scheme where so-called technical fraud is not possible? That is what I'm going to demonstrate here.

The fact that you need to invoke trust later on ("Because the N-of-N signature is given to all participants, it might be leaked into the public") kinda breaks the point of "technical fraud is not possible".

At least with the penalty transactions of Poon-Dryja and the update transactions of Decker-Russell-Osuntokun you never have to worry about other parties leaking information and possibly changing the balance of the channel.
You only need to worry about ensuring you have an up-to-date view of the blockchain, which can be mitigated further by e.g. running a "spare" fullnode on a Torv3 address that secretly connects to your main fullnode (making eclipse attacks that target your known IP harder), connecting to Blockstream Satellite, etc.
You can always get more data yourself, you cannot stop data being acquired by others.

> My scheme makes use of MuSig1, OP_CHECKLOCKTIMEVERIFY (OP_CLTV) timelock type, and negligible OP_RETURN data. It revolves around constructs I call "multipayment channels", called so because they allow multiple people to pay in one transaction - something that is already possible BTW, but with much larger tx size (for large number of cosigners) than when using MuSig1. These have the advantage over LN channels that the intermediate state is also on the blockchain, but it's very compact.

How is this more advantageous than e.g. CoinPools / multiparticipant channels / Statechains ?

> A channel consists of a fixed amount of people N. These people open a channel by creating a (optionally Taproot) address with the following script:
> <blockheightofoutput+desiredwaitingblocks>* OP_CTLV OP_DROP <N-of-N MuSig1> OP_CHECKMUSIG**

If it is Taproot, then `OP_CHECKSIG` is already `OP_CHECKMUSIG`, since MuSig1 (and MuSig2, for that matter....) is just an ordinary Schnorr signature.
In a Tapscript, `OP_CHECKSIG` validates Schnorr signatures (as specified in the relevant BIP), not the ECDSA signatures.

> Simultaneously, each of the N participants receives the N signatures and constructs the N-of-N MuSig. Each participant will use this MuSig to generate his own independent "commitment transaction" with the following properties:
> 
> - It has a single input, the MuSig output. It has an nSequence of desiredwaitingblocks. <This prevents the output from being spent immediately.>
> 
> - It has outputs corresponding to the addresses and balances of each of the participants in the agreed-upon distribution.
> Disadvantage: Because the N-of-N signature is given to all participants, it might be leaked into the public and consequentially anybody can spend this transaction after the timelock, to commit the balance.*** On the other hand, removing the timelocks means that if one of the participants goes missing, all funds are locked forever.****

As I understand it, in your mechanism:

* Onchain, there is an output with the above SCRIPT: `<blockheightofoutput+desiredwaitingblocks>* OP_CTLV OP_DROP <N-of-N MuSig1> OP_CHECKMUSIG`
  * Let me call this the "channel UTXO".
* Offchain, you have a "default transaction" which spends the above output, and redistributes it back to the original owners of the funds, with a timelock requirement (as needed by `OP_CLTV`).

Is that correct?

Then I can improve it in the following ways:

* Since everyone has to sign off the "default transaction" anyway, everyone can ensure that the `nLockTime` field is correct, without having `OP_CLTV` in the channel UTXO SCRIPT.
  * So, the channel UTXO does not need a SCRIPT --- it can just use a Taproot-address Schnorr MuSig point directly.
  * This has the massive advantage that the "default transaction" does not have any special SCRIPTs, improving privacy (modulo the fact that you are cooperating with others who could leak their data).
* If the participants can agree on a new distribution of the funds, then they can sign off with the current blockheight without waiting for the later blockheight.
  * This improves security, since the new distribution can appear on the mempool first and be confirmed first before the "default transaction" can.


Now I want you to look at the literature on channel constructions, particularly "Spilman channels".
For example, see this:

* https://old.reddit.com/r/Bitcoin/comments/cc9psl/technical_a_brief_history_of_payment_channels/

My modifications to your scheme are just a modernization of the Spilman channels.

Regards,
ZmnSCPxj

From michaelfolkson at protonmail.com  Thu Sep  8 11:19:47 2022
From: michaelfolkson at protonmail.com (Michael Folkson)
Date: Thu, 08 Sep 2022 11:19:47 +0000
Subject: [bitcoin-dev] Transcript: Online Socratic on MuSig2
Message-ID: <EmtE82I8JgQTb_sA2erMy6I4pqOFA91CacD0U45JYMrBb5d0F0l8Ht9DS90diAj6v2GHsrSIFqv8cpdzLXUQviccBUTGYMbkc3hLHcZeKfo=@protonmail.com>

Hi

We had an online Socratic on August 11th with Tim Ruffing (co-author of MuSig2 draft BIP) and Elizabeth Crites (co-author of research papers on MuSig(2), FROST). It was previously announced here [0] but ended up being rescheduled.

The transcript is here [1], the video is here [2] and a reading list collecting together a number of resources on MuSig(2), FROST, ROAST etc is here [3].

We discussed a retrospective look at BIP340, handling x-only public keys in MuSig2 and the proposed TLUV covenant opcode, the history from initially broken MuSig1 through MuSig-DN to MuSig2, how MuSig2 and FROST compare for multisig schemes (i.e. n-of-n), why MuSig2 doesn't use proofs of possession and the current state of the draft MuSig2 BIP.

We covered a lot of topics and it was rather long (~2.5 hours) so check out the transcript or video if you are interested in any of the above topics. Many thanks to those who participated.

Jonas Nick recently tweeted [4] that the MuSig2 BIP [5] is approaching a stable version 1.0 which should be helpful to those who are interested (or already!) using it in the wild.

[0]: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-July/020772.html
[1]: https://btctranscripts.com/london-bitcoin-devs/2022-08-11-tim-ruffing-musig2/
[2]: https://www.youtube.com/watch?v=TpyK_ayKlj0
[3]: https://gist.github.com/michaelfolkson/5bfffa71a93426b57d518b09ebd0998c
[4}: https://twitter.com/n1ckler/status/1567168267025874944
[5]: https://github.com/jonasnick/bips/blob/musig2/bip-musig2.mediawiki

--
Michael Folkson
Email: michaelfolkson at [protonmail.com](http://protonmail.com/)
Keybase: michaelfolkson
PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220908/f6918882/attachment.html>

From woltx at protonmail.com  Fri Sep  9 21:05:07 2022
From: woltx at protonmail.com (woltx)
Date: Fri, 09 Sep 2022 21:05:07 +0000
Subject: [bitcoin-dev] joinstr: coinjoin implementation using nostr
In-Reply-To: <GDi7LdVsoIcf4DyylHYn9L24lNn6cE47Vo7DWE4GNmkHi-OePqMkqrx5VYisPG28nv4ih4763vKSS_Yul1BvxjXQn4Sr4zF62kQpL_5nzYY=@protonmail.com>
References: <GDi7LdVsoIcf4DyylHYn9L24lNn6cE47Vo7DWE4GNmkHi-OePqMkqrx5VYisPG28nv4ih4763vKSS_Yul1BvxjXQn4Sr4zF62kQpL_5nzYY=@protonmail.com>
Message-ID: <N_V7H1P2laUdee_YZE16Y4jNPGO0qBBebW1hdeRucs832Iu5ekvNlb3BDTjZG9lgnRjOm5ts7PDeyAvUAXlGdijIty2hIIXk0bEIn-RC-kQ=@protonmail.com>

Hi /dev/fd0,

I've been reviewing joinstr, and if I understand the code correctly, the cryptographic scheme mentioned as an alternative to blind signatures isn't implemented yet, is it? Currently, it seems that anyone can submit unrelated inputs and outputs.

Perhaps PR #24058 (https://github.com/bitcoin/bitcoin/pull/24058) (basic support BIP-322) can improve this scheme as it implements proof of ownership. 

Instead of clients sending descriptors to the relay and then verifying them using `scantxoutset`, it can send `txid:out` with a message signed with the address, verify using `verifymessage` and then use `gettxout` to retrieve the value. That way, only the owner can send the UTXO.

I've done some tests connected to a node with BIP322 enabled:

# to send
input_txt: str = json.dumps(input)
result = core.signmessage(wallet, input['address'], input_txt)
input['signature'] = result['result']
nostr_interface.publish_input(input)

# to receive
def validate_input(input: dict[str, int, str, str]) -> bool:
    # ...
    result = core.verifymessage(address=input['address'], message=json.dumps(message), signature=input['signature'])
    return result['error'] == None and result['result'] == True





------- Original Message -------
On Saturday, August 20th, 2022 at 1:52 PM, alicexbt via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:


> Hi Max,
> 
> There a few DoS vectors that need to be fixed. Its just a proof of concept that I wanted to share with everyone to get feedback which could be improved over time. There is also a warning at the bottom of README to not use this on mainnet as it might have bugs.
> 
> I will continue the development with coinjoin transactions on signet for a few weeks until there is a stable release with no bugs.
> 
> I have a few ideas in mind for various relay types that might be used concurrently to prevent numerous problems. Custom relays are supported by Nostr. Examples include paying a fee to register for a round, subscribing with a time limit, or using invite-only relays. I will run a free and open nostr relay for this project and try to fix the Dos issues before a mainnet version is released for python script(for nerds) and android app (for all users).
> 
> Related links:
> 
> https://github.com/fiatjaf/relayer
> https://github.com/fiatjaf/expensive-relay
> https://github.com/fiatjaf/relayer/tree/master/whitelisted
> 
> /dev/fd0
> 
> 
> Sent with Proton Mail secure email.
> 
> 
> ------- Original Message -------
> On Saturday, August 20th, 2022 at 10:04 AM, Max Hillebrand max at towardsliberty.com wrote:
> 
> 
> 
> > Great to see an implementation of the idea.
> > 
> > Maybe I misunderstand, but isn't there a vulnerability of denial of service here?
> > 
> > A user who registers one input will receive the round secret identifier, and this is all the information required for output registration. However, that malicious user can now register multiple outputs, providing the same secret, and nobody can link the malicious outputs to any specific input. Therefor there cannot be a blame round where the malicious input is removed, and thus there can be a ongoing free denial of service attack without attribution or defense.
> > 
> > Skol
> > Max
> > 
> > On August 20, 2022 10:20:00 AM GMT+02:00, alicexbt via bitcoin-dev bitcoin-dev at lists.linuxfoundation.org wrote:
> > 
> > > Hi Bitcoin Developers,
> > > 
> > > I have written a python script as proof of concept for the coinjoin implementation using nostr. I used a lot of Python scripts created by others in school, so it feels nice to offer something that could be useful to others.
> > > 
> > > The implementation uses Bitcoin Core wallet and RPCs: `listunspent`, `getnewaddress`, `scantxoutset`, `createpsbt`, `combinepsbt`, `finalizepsbt` and `sendrawtransaction`. It requires python-nostr library because nostr is used for coordination between peers. Nostr is a decentralized network based on cryptographic keypairs. It is not peer-to-peer however simple and scalable.
> > > 
> > > Every step is published as an event using a nostr relay and 5 peers coordinate to create, sign and broadcast a coinjoin transaction. I need to write a NIP that would be an alternative to blind signatures. Relay will share a random secret with clients for one round which should be present in output registration request although never gets published. If someone tries to register an output without registering any inputs, request would not have the number initially shared with inputs so request would get rejected or published as unverified. Relay would not be able to link inputs and outputs as the number is same for all inputs in a round and they get registered at different times with new keys and IP address. Clients can use multiple relays at the same time to avoid trusting one relay. This would result in different shared secret number but same process. If a relay tries to cheat, users will not sign the transaction and avoid using it in future.
> > > 
> > > Usage:
> > > 
> > > 1)Run `python coinjoin.py` and enter descriptor for one of the inputs.
> > > 2)Script will check inputs for this round in every 30 seconds and register a new adddress for output once 5 inputs are registered.
> > > 3)Similar check happens every 30 seconds for outputs. Last peer should create a PSBT.
> > > 4)Unsigned PSBT will be printed and signed by wallet with `walletprocesspsbt` RPC.
> > > 5)Script will check signed PSBTs and last peer to sign should finalize coinjoin transaction once 5 signed PSBTs are received.
> > > 6)Coinjoin transaction will be broadcasted and txid will printed.
> > > 
> > > Example:
> > > 
> > > ```
> > > List of utxos in wallet:
> > > 
> > > wpkh([53830dca/84'/1'/0'/0/0]02449be5fb74725255eeeb50eba930fa87705f21e99d13cd710cf2c1f21153c808)#x2hyyeg5
> > > 
> > > Enter descriptor for the input registration: wpkh([53830dca/84'/1'/0'/0/0]02449be5fb74725255eeeb50eba930fa87705f21e99d13cd710cf2c1f21153c808)#x2hyyeg5
> > > 
> > > event id: bcbbe62d75d99fed73f1e50ac58a38d1840b658951893e63c0322b378d7d56f0
> > > 
> > > 
> > > tb1qhxrp4zl54ul0twtyz0gury5399q7z0kvqqrl6m registered for output
> > > 
> > > event id: 9449c9065bef356d21507a98f88b028b17fc1c49eb195c8d4420604fcaaef041
> > > 
> > > Unsigned PSBT: cHNidP8BAP1yAQIAAAAFtMaoJYcXvOG5L3Yaz3YyS7gIt4h5/zzOrRRS3hrVvwoAAAAAAP////+o83geaSm4L76KToIUl5MiZqLAUbIDJLq6DWrjP/3b8AEAAAAA/////zEF3CXIvVHpIa7No1s1yg+KtyOfXTRSyWnOdXMfzcDwAQAAAAD/////wMa4XAgnU+39Ien+KG9rYtv8bLMNYakmZyY/QFfwLRcAAAAAAP/////5M42ID6uLmQTb2tnFHnN7UMpnDD25uN8ZX7A+GNSM3QEAAAAA/////wV4xwEAAAAAABYAFLmGGov0rz71uWQT0cGSkSlB4T7MeMcBAAAAAAAWABSc0/FM6Hdbdxh10IJkYOklVFWqjnjHAQAAAAAAFgAUPSZKe/w6PT6qIF+WhL4wHaFymjd4xwEAAAAAABYAFMx0rxYlpPWB3NFry4Ctk2eVi/UNeMcBAAAAAAAWABSzc4xK0VTfvjK0MHXrAUFLYgYnOgAAAAAAAAAAAAAAAAAAAA==
> > > 
> > > event id: 976744b38fa9343fb79e1b5215512ead6ee08e5890d79a201fc5b872f6de4eba
> > > 
> > > Signed PSBT: cHNidP8BAP1yAQIAAAAFtMaoJYcXvOG5L3Yaz3YyS7gIt4h5/zzOrRRS3hrVvwoAAAAAAP////+o83geaSm4L76KToIUl5MiZqLAUbIDJLq6DWrjP/3b8AEAAAAA/////zEF3CXIvVHpIa7No1s1yg+KtyOfXTRSyWnOdXMfzcDwAQAAAAD/////wMa4XAgnU+39Ien+KG9rYtv8bLMNYakmZyY/QFfwLRcAAAAAAP/////5M42ID6uLmQTb2tnFHnN7UMpnDD25uN8ZX7A+GNSM3QEAAAAA/////wV4xwEAAAAAABYAFLmGGov0rz71uWQT0cGSkSlB4T7MeMcBAAAAAAAWABSc0/FM6Hdbdxh10IJkYOklVFWqjnjHAQAAAAAAFgAUPSZKe/w6PT6qIF+WhL4wHaFymjd4xwEAAAAAABYAFMx0rxYlpPWB3NFry4Ctk2eVi/UNeMcBAAAAAAAWABSzc4xK0VTfvjK0MHXrAUFLYgYnOgAAAAAAAQBxAgAAAAG+qpMXZCy6tBuUlgo8JD0GVXKp60FkhwDeg2sF1fkFkwMAAAAA/f///wLo9wEAAAAAABYAFFfLA5xarC/w/SxeMDQ5tuXrYJLUWwMAAAAAAAAWABRfPf//hwMjHB4OKj87cU19XOSh7yOWAQABAR/o9wEAAAAAABYAFFfLA5xarC/w/SxeMDQ5tuXrYJLUAQhrAkcwRAIgOIhLoC5348U8YkEr4GU1K4yWskIOEXgW4Wsk/W2cR7ICIEJXqtOuDJ5CkwrSuwJLWtzab4dslbN3KuL/pyooMnOCASECRJvl+3RyUlXu61DrqTD6h3BfIemdE81xDPLB8hFTyAgAAAAAACICA77Cnd6o3kr0yc+91eabpOn5igs/MUMbudNYSS6oyMWMGFODDcpUAACAAQAAgAAAAIAAAAAAFAAAAAAAAAAA
> > > 
> > > event id: 5846b6e6902f3c5a43496d7d9785ed62444aa74963f03c33d637d8b09ee7a139
> > > 
> > > Coinjoin tx: 75e490b10b15a6a0422f25ff66ad98ef70390c8fecaac02712705dce8cc3564b
> > > 
> > > event id: 9b5d4bf279b59e2b6e539e683fba83da72dce2b640360aa95db1b1400be93190
> > > ```
> > > 
> > > There are lot of things that could be improved and a few suggestions are in the gist that described the idea. I would love read to any opinions about this experiment and will start working on creating an Android app for joinstr next week.
> > > 
> > > Credits:
> > > 
> > > - fiatjaf (Nostr)
> > > - Andrew Chow (PSBT)
> > > - Jeff Thibault (python-nostr)
> > > - Existing coinjoin implmentations
> > > 
> > > /dev/fd0
> > > 
> > > Sent with Proton Mail secure email.
> > > 
> > > bitcoin-dev mailing list
> > > bitcoin-dev at lists.linuxfoundation.org
> > > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> 
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

From antoine.riard at gmail.com  Sat Sep 10 00:10:55 2022
From: antoine.riard at gmail.com (Antoine Riard)
Date: Fri, 9 Sep 2022 20:10:55 -0400
Subject: [bitcoin-dev] On a new community process to specify covenants
In-Reply-To: <CALZpt+FhpZETHP8UpDGgw-Wg=m4Hxm8y9XZ9kXYgmt90_6Zt6w@mail.gmail.com>
References: <CALZpt+FhpZETHP8UpDGgw-Wg=m4Hxm8y9XZ9kXYgmt90_6Zt6w@mail.gmail.com>
Message-ID: <CALZpt+GetNpWoF=b19oVFJUJwE8Z_6nhpx-5F5UQHwXOufxgAw@mail.gmail.com>

Hi all,

Following up on my July's mail proposing to setup a new community process
dedicated to covenant R&D, after aggregating all the feedbacks received
online/offline, I've started a repository to collect the use-cases and
known design constraints:

https://github.com/ariard/bitcoin-contracting-primitives-wg

One notable change, the proposed process has been renamed to "Bitcoin
Contracting Primitives WG", as covenants sound for few folks to be
inaccurate in terms of scope to designate the whole range of techniques to
enable/empower contracting applications.

So far, I've documented the extension of the vault and payment pools
use-cases. Use-case analysis is following somehow inspired by the reasoning
framework as laid out by RFC 3426 [0]. This is a first shot and all current
descriptions should only be taken as a "best-effort" for now. More
use-cases descriptions coming soon. Hopefully we'll have a set of
"champions" by use-case emerging with time.

There is another ongoing effort to document the primitives themselves:

https://github.com/bitcoinops/bitcoinops.github.io/pull/806

About the starting point for regular meetings, I think the good timing is
somewhere in November, after the upcoming cycle of Bitcoin conferences, as
I guess a good chunk of folks will attend them.

Defining a communication channel is still an open question: IRC, Slack,
Discord, Discourse, ...

As discussed before, softfork activation discussions will be considered as
off-topic and discouraged. This is first and foremost a long-term R&D
effort.

Contributors, reviewers and co-maintainers to the repository are welcome.
All content is licensed under Creative Commons 4.0, though can be
relicensed to another thing if it suits more (like all Bitcoin devs I'm
only part-time lawyer).

Still open to more feedbacks on what the ideal Bitcoin
covenants/contracting primitives community process would looks like.

Cheers,
Antoine

[0] https://www.rfc-editor.org/rfc/rfc3426.html

Le mer. 20 juil. 2022 ? 16:42, Antoine Riard <antoine.riard at gmail.com> a
?crit :

> Hi,
>
> Discussions on covenants have been prolific and intense on this mailing
> list and within the wider Bitcoin technical circles, I believe however
> without succeeding to reach consensus on any new set of contracting
> primitives satisfying the requirements of known covenant-enabled use-cases.
> I think that's a fact to deplore as covenants would not only offer vast
> extensions of the capabilities of Bitcoin as a system, i.e enabling new
> types of multi-party contract protocols. But also empowering Bitcoin on its
> fundamental value propositions of store of value (e.g by making vaults more
> flexible) and payment system (e.g by making realistic channel
> factories/payment pools).
>
> If we retain as a covenant definition, a spending constraint restricting
> the transaction to which the spent UTXO can be spent, and enabling to
> program contracts/protocols at the transaction-level instead of the
> script-level, the list of Script primitives proposed during the last years
> has grown large : ANYPREVOUT [0], CHECKSIGFROMSTACK [1],
> CHECK_TEMPLATE_VERIFY [2], TAPROOT_LEAF_UPDATE_VERIFY [3], TXHASH [4],
> PUSHTXDATA [5], CAT [6], EVICT [7], Grafroot delegation [8], SIGHASH_GROUP
> [9], MERKLEBRANCHVERIFY [10] and more than I can't remember. Of course, all
> the listed primitives are at different states of formalization, some
> already fully fleshed-out in BIPs, other still ideas on whiteboard, yet
> they all extend the range of workable multi-party contract protocols.
>
> Indeed this range has grown wild. Without aiming to be exhaustive (I'm
> certainly missing some interesting proposals lost in the abyss of
> bitcointalk.org), we can mention the following use-cases: multi-party
> stateful contracts [11], congestion trees [12], payment pools [13], "eltoo"
> layered commitments [14], programmable vaults [15], multi-events contracts
> [16], blockchain-as-oracle bets [17], spacechains [18], trustless
> collateral lending [19], ...
>
> Minding all those facts, I would say the task of technical evaluation of
> any covenant proposal sounds at least two fold. There is first reasoning
> about the enabled protocols on a range of criterias such as scalability,
> efficiency, simplicity, extensibility, robustness, data confidentiality,
> etc. Asking questions like what are the interactions between layers, if any
> ? Or how robust is the protocol, not just interactivity failure between
>  participant nodes but in the face of mempools spikes or internet
> disruption ? Or if the performance is still acceptable on shared resources
> like blockspace or routing tables if everyone is using this protocol ? Or
> if the protocol minimizes regulatory attack surface or centralization
> vectors ?
>
> Though once this step is achieved, there is still more reasoning work to
> evaluate how good a fit is a proposed Script primitive, the
> efficiency/simplicity/ease to use trade-offs, but also if there are no
> functionality overlap or hard constraints on the use-cases design
> themselves or evolvability w.rt future Script extensions or generalization
> of the opcode operations.
>
> Moreover, if you would like your evaluation of a covenant proposal to be
> complete, I don't believe you can squeeze the implications with the mempool
> rules and combination with any consistent fee-bumping strategy. To say
> things politely, those areas have been a quagmire of vulnerabilities,
> attacks and defects for second-layers Bitcoin protocols during the last
> years [20].
>
> Considering the abundant problem-space offered by covenants, I believe
> there is a reasonable groundwork to pursue in building the use-cases
> understanding (e.g prototype, pseudo-specification, documentation, ...) and
> building consensus on the framework of criterias on which to evaluate them
> [21]. It might raise a really high bar for any covenant proposal compared
> to previous softforks, however I think it would adequately reflect the
> growth in Bitcoin complexity and funds at stakes during the last years.
>
> Moving towards this outcome, I would like to propose a new covenant open
> specification process, in the same spirit as we have with the BOLTs or
> dlcspecs. We would have regular meetings (biweekly/monthly ?), an open
> agenda where topics of discussion can be pinned in advance and
> documentation artifacts would be built with time driven by consensus (e.g
> 1st phase could be to collect, pseudo-specify and find champion(s) for
> known use-cases ?) and no timeframe. Starting date could be September /
> October / November (later, 2023 ?), giving time for anyone interested in
> such a covenant process to allocate development and contribution bandwidth
> in function of their involvement interest.
>
> Learning from the good but specially from the bad with setting up the L2
> onchain support meetings last year, I think it would be better to keep the
> agenda open, loose and free as much we can in a "burn-the-roadmap" spirit,
> avoiding to create a sense of commitment or perceived signaling in the
> process participants towards any covenant solution. I would guess things to
> be experimental and evolutionary and folks to spend the first meetings
> actually to express what they would like the covenant process to be about
> (and yes that means if you're a domain expert and you find the pace of
> things too slow sometimes, you have to learn to handle your own
> frustration...).
>
> In a "decentralize-everything" fashion, I believe it would be good to have
> rotating meeting chairs and multiple covenant documentation archivists. I'm
> super happy to spend the time and energy bootstrapping well such covenant
> process effort, though as it's Bitcoin learn to decentralize yourself.
>
> I'm really curious what the outcome of such a covenant process would look
> like. We might end up concluding that complex covenants are too unsafe by
> enabling sophisticated MEV-attacks against LN [22]. Or even if there is an
> emergent technical consensus, it doesn't mean there is a real market
> interest for such covenant solutions. That said, I'm not sure if it's
> really a subject of concern when you're reasoning as a scientist/engineer
> and you value technical statements in terms of accuracy, systematic
> relevance and intrinsic interest.
>
> Overall, my motivation to kick-start such a process stays in the fact that
> covenants are required building blocks to enable scalable payments pools
> design like CoinPool. I believe payments pools are a) cool and b) a good
> shot at scaling Bitcoin as a payment system once we have reached
> scalability limits of Lightning, still under the same security model for
> users. However, as a community we might sense it's not the good timing for
> a covenant process. I'm really fine with that outcome as there are still
> holes to patch in LN to keep me busy enough for the coming years.
>
> Zooming out, I believe with any discussion about covenants or other soft
> forks, the hard part isn't about coming up with the best technical solution
> to a set of problems but in the iterative process where all voices are
> listened to reach (or not) consensus on what is actually meant by "best"
> and if the problems are accurate. The real physics of Bitcoin is the
> physics of people. It's a work of patience.
>
> Anyways, eager to collect feedbacks on what the ideal covenant
> specification process looks like. As usual, all opinions and mistakes are
> my own.
>
> Cheers,
> Antoine
>
> [0] https://github.com/bitcoin/bips/blob/master/bip-0118.mediawiki
> [1] https://bitcoinops.org/en/topics/op_checksigfromstack/
> [2] https://github.com/bitcoin/bips/blob/master/bip-0119.mediawiki
> [3]
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019419.html
> [4]
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019813.html
> [5] https://github.com/jl2012/bips/blob/vault/bip-0ZZZ.mediawiki
> [6] https://medium.com/blockstream/cat-and-schnorr-tricks-i-faf1b59bd298
> [7]
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-February/019926.html
> [8]
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-February/015700.html
> [9]
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-July/019243.html
> [10] https://github.com/bitcoin/bips/blob/master/bip-0116.mediawiki
> [11]
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019808.html
> [12]
> https://github.com/bitcoin/bips/blob/master/bip-0119.mediawiki#Congestion_Controlled_Transactions
> [13]
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-June/017964.html
> [14]
> https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-January/002448.html
> [15] http://fc17.ifca.ai/bitcoin/papers/bitcoin17-final28.pdf
> [16]
> https://github.com/ariard/talk-slides/blob/master/advanced-contracts.pdf
> [17] https://blog.bitmex.com/taproot-you-betcha/
> [18]
> https://gist.github.com/RubenSomsen/c9f0a92493e06b0e29acced61ca9f49a#spacechains
> [19] https://gist.github.com/RubenSomsen/bf08664b3d174551ab7361ffb835fcef
> [20] https://github.com/jamesob/mempool.work
> [21] https://github.com/bitcoinops/bitcoinops.github.io/pull/806
> [22] https://blog.bitmex.com/txwithhold-smart-contracts/
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220909/6d617955/attachment-0001.html>

From alicexbt at protonmail.com  Sat Sep 10 10:17:37 2022
From: alicexbt at protonmail.com (alicexbt)
Date: Sat, 10 Sep 2022 10:17:37 +0000
Subject: [bitcoin-dev] joinstr: coinjoin implementation using nostr
In-Reply-To: <N_V7H1P2laUdee_YZE16Y4jNPGO0qBBebW1hdeRucs832Iu5ekvNlb3BDTjZG9lgnRjOm5ts7PDeyAvUAXlGdijIty2hIIXk0bEIn-RC-kQ=@protonmail.com>
References: <GDi7LdVsoIcf4DyylHYn9L24lNn6cE47Vo7DWE4GNmkHi-OePqMkqrx5VYisPG28nv4ih4763vKSS_Yul1BvxjXQn4Sr4zF62kQpL_5nzYY=@protonmail.com>
 <N_V7H1P2laUdee_YZE16Y4jNPGO0qBBebW1hdeRucs832Iu5ekvNlb3BDTjZG9lgnRjOm5ts7PDeyAvUAXlGdijIty2hIIXk0bEIn-RC-kQ=@protonmail.com>
Message-ID: <NIAcS2bTRs-yCLyDvLvCydA8bCIFaClt_zD251QcEQ2IiEUgUCcKvTQwJ7YN-m7NUrawEdX5Z5lE2CR9UJ_RV5N77hmzoLYkiPWVgDETKi0=@protonmail.com>

Hi woltx,

> I've been reviewing joinstr, and if I understand the code correctly, the cryptographic scheme mentioned as an alternative to blind signatures isn't implemented yet, is it? Currently, it seems that anyone can submit unrelated inputs and outputs.

Thanks for reviewing joinstr. Yes, its not implemented right now as it requires a NIP and at least one relay using it.

> Instead of clients sending descriptors to the relay and then verifying them using `scantxoutset`, it can send `txid:out` with a message signed with the address, verify using `verifymessage` and then use `gettxout` to retrieve the value. That way, only the owner can send the UTXO.

`scantxoutset` is only used to get UTXO details (txid, vout and amount) as I thought its easier for users to just share a descriptor for coinjoin. 

If a user sends `txid:out` with a message signed with the address, this would be publicly available to everyone connected to same relay and links an input with output. Responding with a secret shared by relay for the round confirms user owns one of the input but does not reveal exact input.


/dev/fd0


Sent with Proton Mail secure email.

------- Original Message -------
On Friday, September 9th, 2022 at 9:05 PM, woltx <woltx at protonmail.com> wrote:


> Hi /dev/fd0,
> 
> I've been reviewing joinstr, and if I understand the code correctly, the cryptographic scheme mentioned as an alternative to blind signatures isn't implemented yet, is it? Currently, it seems that anyone can submit unrelated inputs and outputs.
> 
> Perhaps PR #24058 (https://github.com/bitcoin/bitcoin/pull/24058) (basic support BIP-322) can improve this scheme as it implements proof of ownership.
> 
> Instead of clients sending descriptors to the relay and then verifying them using `scantxoutset`, it can send `txid:out` with a message signed with the address, verify using `verifymessage` and then use `gettxout` to retrieve the value. That way, only the owner can send the UTXO.
> 
> I've done some tests connected to a node with BIP322 enabled:
> 
> # to send
> input_txt: str = json.dumps(input)
> result = core.signmessage(wallet, input['address'], input_txt)
> input['signature'] = result['result']
> nostr_interface.publish_input(input)
> 
> # to receive
> def validate_input(input: dict[str, int, str, str]) -> bool:
> 
> # ...
> result = core.verifymessage(address=input['address'], message=json.dumps(message), signature=input['signature'])
> return result['error'] == None and result['result'] == True
> 
> 
> 
> 
> 
> ------- Original Message -------
> On Saturday, August 20th, 2022 at 1:52 PM, alicexbt via bitcoin-dev bitcoin-dev at lists.linuxfoundation.org wrote:
> 
> 
> 
> > Hi Max,
> > 
> > There a few DoS vectors that need to be fixed. Its just a proof of concept that I wanted to share with everyone to get feedback which could be improved over time. There is also a warning at the bottom of README to not use this on mainnet as it might have bugs.
> > 
> > I will continue the development with coinjoin transactions on signet for a few weeks until there is a stable release with no bugs.
> > 
> > I have a few ideas in mind for various relay types that might be used concurrently to prevent numerous problems. Custom relays are supported by Nostr. Examples include paying a fee to register for a round, subscribing with a time limit, or using invite-only relays. I will run a free and open nostr relay for this project and try to fix the Dos issues before a mainnet version is released for python script(for nerds) and android app (for all users).
> > 
> > Related links:
> > 
> > https://github.com/fiatjaf/relayer
> > https://github.com/fiatjaf/expensive-relay
> > https://github.com/fiatjaf/relayer/tree/master/whitelisted
> > 
> > /dev/fd0
> > 
> > Sent with Proton Mail secure email.
> > 
> > ------- Original Message -------
> > On Saturday, August 20th, 2022 at 10:04 AM, Max Hillebrand max at towardsliberty.com wrote:
> > 
> > > Great to see an implementation of the idea.
> > > 
> > > Maybe I misunderstand, but isn't there a vulnerability of denial of service here?
> > > 
> > > A user who registers one input will receive the round secret identifier, and this is all the information required for output registration. However, that malicious user can now register multiple outputs, providing the same secret, and nobody can link the malicious outputs to any specific input. Therefor there cannot be a blame round where the malicious input is removed, and thus there can be a ongoing free denial of service attack without attribution or defense.
> > > 
> > > Skol
> > > Max
> > > 
> > > On August 20, 2022 10:20:00 AM GMT+02:00, alicexbt via bitcoin-dev bitcoin-dev at lists.linuxfoundation.org wrote:
> > > 
> > > > Hi Bitcoin Developers,
> > > > 
> > > > I have written a python script as proof of concept for the coinjoin implementation using nostr. I used a lot of Python scripts created by others in school, so it feels nice to offer something that could be useful to others.
> > > > 
> > > > The implementation uses Bitcoin Core wallet and RPCs: `listunspent`, `getnewaddress`, `scantxoutset`, `createpsbt`, `combinepsbt`, `finalizepsbt` and `sendrawtransaction`. It requires python-nostr library because nostr is used for coordination between peers. Nostr is a decentralized network based on cryptographic keypairs. It is not peer-to-peer however simple and scalable.
> > > > 
> > > > Every step is published as an event using a nostr relay and 5 peers coordinate to create, sign and broadcast a coinjoin transaction. I need to write a NIP that would be an alternative to blind signatures. Relay will share a random secret with clients for one round which should be present in output registration request although never gets published. If someone tries to register an output without registering any inputs, request would not have the number initially shared with inputs so request would get rejected or published as unverified. Relay would not be able to link inputs and outputs as the number is same for all inputs in a round and they get registered at different times with new keys and IP address. Clients can use multiple relays at the same time to avoid trusting one relay. This would result in different shared secret number but same process. If a relay tries to cheat, users will not sign the transaction and avoid using it in future.
> > > > 
> > > > Usage:
> > > > 
> > > > 1)Run `python coinjoin.py` and enter descriptor for one of the inputs.
> > > > 2)Script will check inputs for this round in every 30 seconds and register a new adddress for output once 5 inputs are registered.
> > > > 3)Similar check happens every 30 seconds for outputs. Last peer should create a PSBT.
> > > > 4)Unsigned PSBT will be printed and signed by wallet with `walletprocesspsbt` RPC.
> > > > 5)Script will check signed PSBTs and last peer to sign should finalize coinjoin transaction once 5 signed PSBTs are received.
> > > > 6)Coinjoin transaction will be broadcasted and txid will printed.
> > > > 
> > > > Example:
> > > > 
> > > > ```
> > > > List of utxos in wallet:
> > > > 
> > > > wpkh([53830dca/84'/1'/0'/0/0]02449be5fb74725255eeeb50eba930fa87705f21e99d13cd710cf2c1f21153c808)#x2hyyeg5
> > > > 
> > > > Enter descriptor for the input registration: wpkh([53830dca/84'/1'/0'/0/0]02449be5fb74725255eeeb50eba930fa87705f21e99d13cd710cf2c1f21153c808)#x2hyyeg5
> > > > 
> > > > event id: bcbbe62d75d99fed73f1e50ac58a38d1840b658951893e63c0322b378d7d56f0
> > > > 
> > > > tb1qhxrp4zl54ul0twtyz0gury5399q7z0kvqqrl6m registered for output
> > > > 
> > > > event id: 9449c9065bef356d21507a98f88b028b17fc1c49eb195c8d4420604fcaaef041
> > > > 
> > > > Unsigned PSBT: cHNidP8BAP1yAQIAAAAFtMaoJYcXvOG5L3Yaz3YyS7gIt4h5/zzOrRRS3hrVvwoAAAAAAP////+o83geaSm4L76KToIUl5MiZqLAUbIDJLq6DWrjP/3b8AEAAAAA/////zEF3CXIvVHpIa7No1s1yg+KtyOfXTRSyWnOdXMfzcDwAQAAAAD/////wMa4XAgnU+39Ien+KG9rYtv8bLMNYakmZyY/QFfwLRcAAAAAAP/////5M42ID6uLmQTb2tnFHnN7UMpnDD25uN8ZX7A+GNSM3QEAAAAA/////wV4xwEAAAAAABYAFLmGGov0rz71uWQT0cGSkSlB4T7MeMcBAAAAAAAWABSc0/FM6Hdbdxh10IJkYOklVFWqjnjHAQAAAAAAFgAUPSZKe/w6PT6qIF+WhL4wHaFymjd4xwEAAAAAABYAFMx0rxYlpPWB3NFry4Ctk2eVi/UNeMcBAAAAAAAWABSzc4xK0VTfvjK0MHXrAUFLYgYnOgAAAAAAAAAAAAAAAAAAAA==
> > > > 
> > > > event id: 976744b38fa9343fb79e1b5215512ead6ee08e5890d79a201fc5b872f6de4eba
> > > > 
> > > > Signed PSBT: cHNidP8BAP1yAQIAAAAFtMaoJYcXvOG5L3Yaz3YyS7gIt4h5/zzOrRRS3hrVvwoAAAAAAP////+o83geaSm4L76KToIUl5MiZqLAUbIDJLq6DWrjP/3b8AEAAAAA/////zEF3CXIvVHpIa7No1s1yg+KtyOfXTRSyWnOdXMfzcDwAQAAAAD/////wMa4XAgnU+39Ien+KG9rYtv8bLMNYakmZyY/QFfwLRcAAAAAAP/////5M42ID6uLmQTb2tnFHnN7UMpnDD25uN8ZX7A+GNSM3QEAAAAA/////wV4xwEAAAAAABYAFLmGGov0rz71uWQT0cGSkSlB4T7MeMcBAAAAAAAWABSc0/FM6Hdbdxh10IJkYOklVFWqjnjHAQAAAAAAFgAUPSZKe/w6PT6qIF+WhL4wHaFymjd4xwEAAAAAABYAFMx0rxYlpPWB3NFry4Ctk2eVi/UNeMcBAAAAAAAWABSzc4xK0VTfvjK0MHXrAUFLYgYnOgAAAAAAAQBxAgAAAAG+qpMXZCy6tBuUlgo8JD0GVXKp60FkhwDeg2sF1fkFkwMAAAAA/f///wLo9wEAAAAAABYAFFfLA5xarC/w/SxeMDQ5tuXrYJLUWwMAAAAAAAAWABRfPf//hwMjHB4OKj87cU19XOSh7yOWAQABAR/o9wEAAAAAABYAFFfLA5xarC/w/SxeMDQ5tuXrYJLUAQhrAkcwRAIgOIhLoC5348U8YkEr4GU1K4yWskIOEXgW4Wsk/W2cR7ICIEJXqtOuDJ5CkwrSuwJLWtzab4dslbN3KuL/pyooMnOCASECRJvl+3RyUlXu61DrqTD6h3BfIemdE81xDPLB8hFTyAgAAAAAACICA77Cnd6o3kr0yc+91eabpOn5igs/MUMbudNYSS6oyMWMGFODDcpUAACAAQAAgAAAAIAAAAAAFAAAAAAAAAAA
> > > > 
> > > > event id: 5846b6e6902f3c5a43496d7d9785ed62444aa74963f03c33d637d8b09ee7a139
> > > > 
> > > > Coinjoin tx: 75e490b10b15a6a0422f25ff66ad98ef70390c8fecaac02712705dce8cc3564b
> > > > 
> > > > event id: 9b5d4bf279b59e2b6e539e683fba83da72dce2b640360aa95db1b1400be93190
> > > > ```
> > > > 
> > > > There are lot of things that could be improved and a few suggestions are in the gist that described the idea. I would love read to any opinions about this experiment and will start working on creating an Android app for joinstr next week.
> > > > 
> > > > Credits:
> > > > 
> > > > - fiatjaf (Nostr)
> > > > - Andrew Chow (PSBT)
> > > > - Jeff Thibault (python-nostr)
> > > > - Existing coinjoin implmentations
> > > > 
> > > > /dev/fd0
> > > > 
> > > > Sent with Proton Mail secure email.
> > > > 
> > > > bitcoin-dev mailing list
> > > > bitcoin-dev at lists.linuxfoundation.org
> > > > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> > 
> > _______________________________________________
> > bitcoin-dev mailing list
> > bitcoin-dev at lists.linuxfoundation.org
> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

From alicexbt at protonmail.com  Sat Sep 10 10:20:48 2022
From: alicexbt at protonmail.com (alicexbt)
Date: Sat, 10 Sep 2022 10:20:48 +0000
Subject: [bitcoin-dev] Full Disclosure: Denial of Service in STONEWALLx2
	(p2p coinjoin)
In-Reply-To: <eCSIPVH6QM3r1n0PGBWr39xv4BSyAWx6q0icycfo4mESnQfNg7NJWRu7wwyoxnR6E9Own_CJxGVufqQhqx1H4JyAQil3MUUkdI_kUC5bmVg=@protonmail.com>
References: <eCSIPVH6QM3r1n0PGBWr39xv4BSyAWx6q0icycfo4mESnQfNg7NJWRu7wwyoxnR6E9Own_CJxGVufqQhqx1H4JyAQil3MUUkdI_kUC5bmVg=@protonmail.com>
Message-ID: <uQ5LTbHpJKnhgCIXly1Ft5rq_8HCz4_jkLP2sHrqvjXNrYbrWuCm2MOC4KmQCoPLlC_esQNi38Hman6j2zJYM2xJUq4W_p8lt_-BH1GHmcM=@protonmail.com>

This has been assigned CVE-2022-35913: https://www.cve.org/CVERecord?id=CVE-2022-35913

/dev/fd0

Sent with Proton Mail secure email.

------- Original Message -------
On Thursday, July 14th, 2022 at 9:25 AM, alicexbt via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:


> Hi bitcoin-dev list members,
> 
> 
> STONEWALLx2[1] is a p2p coinjoin transaction in Samourai wallet. The miner fee is split between both participants of the transaction.
> 
> 
> ==========================
> Problem
> ==========================
> 
> Antoine Riard shared the details of DoS attack in an [email][2] on 21 June 2022.
> 
> Proof of Concept:
> 
> 1) Download Samourai APK, create testnet wallet, get some coins from faucet and claim a paynym in 2 android devices. Consider Bob and Carol are using these devices.
> 
> 2) Bob and Carol follow each other's paynyms. Carol is the attacker in this case and she could make several paynyms.
> 
> 3) Bob initiates a Stonewallx2 transaction that requires collaboration with Carol.
> 
> 4) Carol confirms this request in the app.
> 
> 5) Carol spends the UTXO from wallet configured in electrum with same seed before Bob could complete the last step and broadcast STONEWALLx2 transaction. It was non RBF [transaction][3] with 1 sat/vbyte fee rate and was unconfirmed during testing.
> 
> 6) Bob receives an [error][4] in the app when trying to broadcast Stonewallx2 transaction which disappears in a few seconds. The [progress bar][5] appears as if wallet is still trying to broadcast the transaction until Bob manually go back or close the app.
> 
> 
> ==========================
> Solution
> ==========================
> 
> Suggestions:
> 
> a) Error message that states collaborator spent her UTXO used in STONEWALLx2, end the p2p coinjoin process, unfollow collaborator's paynym and suggest user to do such transactions with trusted users only for a while.
> 
> b) Once full RBF is used by some nodes and miners, attacker's transaction could be replaced with a higher fee rate.
> 
> Conclusions by Samourai:
> 
> a) As the threat involves the collaborator attacking the spender. We strongly advise that collab spends be done w/ counterparties with which some measure of trust is shared. As such, this does not seem to have an important threat surface.
> 
> b) Bumping fee won't be simple as fees are shared 50/50 for STONEWALLx2 spends. Change would have to be recalculated for both spender and collaborator. Collab would either have had already authorized a possible fee bump beforehand or would have to be prompted before broadcast.
> 
> 
> ==========================
> Timeline
> ==========================
> 
> 22 June 2022: I emailed Antoine after testing STONEWALLx2
> 
> 23 June 2022: I shared the details of attack in a confidential issue in Samourai wallet [repository][6]
> 
> 07 July 2022: TDevD (Samourai) acknowledged the issue and wanted to discuss it internally with team
> 
> 14 July 2022: TDevD shared the conclusions
> 
> 
> ==========================
> Credits
> ==========================
> 
> Antoine Riard discovered DoS vector in p2p coinjoin transactions and helped by responding to emails during testing.
> 
> 
> [1]: https://docs.samourai.io/spend-tools
> [2]: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-June/020595.html
> [3]: https://mempool.space/testnet/tx/42db696460a46f196f457779d60acbf46b31accc5414b9eac54b2e785d4c1cbb
> [4]: https://i.imgur.com/6uf3VJn.png
> [5]: https://i.imgur.com/W6ITl4G.gif
> [6]: https://code.samourai.io/wallet/samourai-wallet-android
> 
> 
> /dev/fd0
> 
> 
> Sent with Proton Mail secure email.
> 
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

From ali at notatether.com  Sun Sep 11 07:43:11 2022
From: ali at notatether.com (Ali Sherief)
Date: Sun, 11 Sep 2022 07:43:11 +0000
Subject: [bitcoin-dev] Transcript: Online Socratic on MuSig2
Message-ID: <ZSUlUBf8IO0xdA3QEaw8ytaD_2qTkfEa5vtU3t6F2OTMrOSOnrl1_Gy-zL75uhpJ3M5iWjVyeyImiCqW2c1F2xfllxyVTh8cd6ImFo0kYDk=@notatether.com>

Hi Michael.

I read the transcript of the Socratic and I have to say that it is quite detailed and touches a lot of problems including the well-known theft/offline problems which also has forms elsewhere such as for passwords.

My question is, do you or anyone else in the Socratic know of any research to this that's don't involve a trade-off of theft or online connectivity?

ROAST and Liquid is perhaps the farthest I know of that addresses this problem, but it's using centralized nodes right now. I was thinking, maybe these federated nodes can be decentralized into a few of these "lite nodes" managed by each service wanting a payment, that make a threshold signature out of many subscribers paying at the same time.

- Ali
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220911/5966df87/attachment.html>

From buck.perley at protonmail.com  Mon Sep 12 00:05:18 2022
From: buck.perley at protonmail.com (Buck O Perley)
Date: Mon, 12 Sep 2022 00:05:18 +0000
Subject: [bitcoin-dev] On a new community process to specify covenants
Message-ID: <BQjnkZZajHKYBOUFAin8toHgNHhG346VUR4GQx6bSi2ftOuNTK1c1d4LWN4Zmr0tUg2w3xgtIZJSphBORYgWw4PPXq5pGFoZJk2Lx6AokuQ=@protonmail.com>

Hi Antoine,

First just wanted to thank you for taking the initiative to 
put this together. I think that as the community and 
ecosystem continue to grow, it's going to be an important 
part of the process to have groups like this develop. Hopefully
they allow us to resist the "Tyranny of Structurelessness" without 
resorting to formalized governance processes and systems. 

> Defining a communication channel is still an open question: IRC, Slack,
Discord, Discourse, ...

I would vote against Slack. IRC is probably the best but maybe too
high a barrier to entry? Publishing logs at least would counter
concerns of it being exclusive. Maybe discord as an alternative. 

> About the starting point for regular meetings, I think the good timing is
somewhere in November, after the upcoming cycle of Bitcoin conferences,

+1 

> softfork activation discussions will be considered as
off-topic and discouraged. This is first and foremost a long-term R&D
effort.

I understand the reason for this but I do have some concerns that
it's not as off-topic as most of us would like. It shouldn't
be a priority but how any of these primitives end up getting activated
is part of the proposal itself in my opinion. 

I think it also became clear in some of the discussions over the past 
~year that maybe there were more concerns than people realized about
even the taproot activation process, whether the method used or if it 
was done too quickly. An example of where there might be 
some intersection with the WG as proposed is the question of how much 
research, security audits, etc. are "enough" before it should be 
considered for activation? 

Maybe as a way to keep these topics separate, it would make sense 
for activation to have its own WG. As norms develop around this one, 
they could inform creating a separate space focused on forwarding 
research and discussion around how to introduce upgrades to bitcoin. 

In general it would be nice to have multiple of these groups
happening at once, and finding a way that they can operate separate
from centralized companies. To my mind, there's no good reason why
a supposedly decentralized protocol should have to be focusing on only
one set of protocol advancements at a time. The linear way that
discussions post-Taproot activation took shape ("What do you think the
next bitcoin softfork should be?") is a sign of weakness in my opinion. 
Definitely a big red flag that we should be concerned with. 

Couple other comments from the proposal/repo:

* it seems like there might be some opportunities to work with 
bipbounty.org which grew out of the organic bounty donations that
were made towards finding CTV vulnerabilities. For example, 
if the group develops specific, achievable research goals (building
out use cases, researching vulnerabilities or limitations, etc.), 
bipbounty.org could help support these efforts in a more decentralized
way by diversifying funding. 

* Any thoughts on starting to commit to an in-person meetup to happen 
~6 months - 1 year after the start of the regular online meetings? 
That should be plenty of time for people to plan and formalize 
a location and it seems like other IRL dev meetups have been 
very productive in terms of knowledge sharing and setting priorities. 
An in-person meetup would give a nice goal to work towards and a way
to measure progress. 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: publickey - buck.perley at protonmail.com - 0xC64EEB00.asc
Type: application/pgp-keys
Size: 608 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220912/600d520a/attachment.bin>

From michaelfolkson at protonmail.com  Mon Sep 12 16:00:52 2022
From: michaelfolkson at protonmail.com (Michael Folkson)
Date: Mon, 12 Sep 2022 16:00:52 +0000
Subject: [bitcoin-dev] Transcript: Online Socratic on MuSig2
In-Reply-To: <ZSUlUBf8IO0xdA3QEaw8ytaD_2qTkfEa5vtU3t6F2OTMrOSOnrl1_Gy-zL75uhpJ3M5iWjVyeyImiCqW2c1F2xfllxyVTh8cd6ImFo0kYDk=@notatether.com>
References: <ZSUlUBf8IO0xdA3QEaw8ytaD_2qTkfEa5vtU3t6F2OTMrOSOnrl1_Gy-zL75uhpJ3M5iWjVyeyImiCqW2c1F2xfllxyVTh8cd6ImFo0kYDk=@notatether.com>
Message-ID: <EjQcONe5___52yZQzB5cSJfXjXB0S7fXT2FXo1NAD6F8h4kbbl-JZhu1C-4tZW2qxp7nMQJ9A08peU9U8FBrUc7DJDeCdJPJk-Rde9GaRak=@protonmail.com>

Hi Ali

> do you or anyone else in the Socratic know of any research to this that's don't involve a trade-off of theft or online connectivity?

Any generation of a signature(s), whether that be single key (e.g. OP_CHECKSIG), multisig with multiple signatures going onchain (e.g. OP_CHECKMULTISIG, OP_CHECKSIGADD) or key aggregation multisig with only a single signature going onchain (e.g. OP_CHECKSIG), requires private key(s) and hence has concerns with regards to security and theft of those private keys. Clearly funds locked behind any kind multisig arrangement is better than no multisig arrangement as otherwise theft of a single private key can result in loss of funds.

With regards to connectivity or interactivity key aggregation multisig does increase the interactivity requirements so if you wanted to minimize interactivity requirements you'd probably stick to OP_CHECKMULTISIG, OP_CHECKSIGADD that only requires you to generate a signature and then pass it onto the next signer.

> ROAST and Liquid is perhaps the farthest I know of that addresses this problem, but it's using centralized nodes right now. I was thinking, maybe these federated nodes can be decentralized into a few of these "lite nodes" managed by each service wanting a payment, that make a threshold signature out of many subscribers paying at the same time.

I'm not sure what you mean here. In the realm of generating signatures there isn't really a concept of a "lite node". That makes more sense in the realm of verification where you may or may not be doing full verification. In the generating signatures realm you are either contributing to the aggregated signature or generating a standalone signature yourself. If you are not doing either of those and aren't doing some kind of coordination then you are entirely irrelevant to the scheme. In the case of Liquid there is a 11-of-15 threshold signature arrangement where currently 11 signatures go onchain when funds are moved but if Liquid used a key aggregation scheme like FROST only a single signature would need to go onchain. With regards to centralization/decentralization you could increase the 11-of-15 to say a 22-of-30. Or you could have a nested MuSig/FROST scheme behind one of the 11 signers of the 11-of-15. But you can't get around the fact that you are either generating a signature that ultimately contributes to the moving of the funds or you aren't. If you aren't generating a signature then you are just verifying the signature(s) that go onchain like all other full nodes on the network.

Thanks
Michael

--
Michael Folkson
Email: michaelfolkson at [protonmail.com](http://protonmail.com/)
Keybase: michaelfolkson
PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3

------- Original Message -------
On Sunday, September 11th, 2022 at 08:43, Ali Sherief <ali at notatether.com> wrote:

> Hi Michael.
>
> I read the transcript of the Socratic and I have to say that it is quite detailed and touches a lot of problems including the well-known theft/offline problems which also has forms elsewhere such as for passwords.
>
> My question is, do you or anyone else in the Socratic know of any research to this that's don't involve a trade-off of theft or online connectivity?
>
> ROAST and Liquid is perhaps the farthest I know of that addresses this problem, but it's using centralized nodes right now. I was thinking, maybe these federated nodes can be decentralized into a few of these "lite nodes" managed by each service wanting a payment, that make a threshold signature out of many subscribers paying at the same time.
>
> - Ali
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220912/f261ff41/attachment.html>

From bitcoin-dev at rgrant.org  Tue Sep 13 16:02:35 2022
From: bitcoin-dev at rgrant.org (Ryan Grant)
Date: Tue, 13 Sep 2022 16:02:35 +0000
Subject: [bitcoin-dev] On a new community process to specify covenants
In-Reply-To: <BQjnkZZajHKYBOUFAin8toHgNHhG346VUR4GQx6bSi2ftOuNTK1c1d4LWN4Zmr0tUg2w3xgtIZJSphBORYgWw4PPXq5pGFoZJk2Lx6AokuQ=@protonmail.com>
References: <BQjnkZZajHKYBOUFAin8toHgNHhG346VUR4GQx6bSi2ftOuNTK1c1d4LWN4Zmr0tUg2w3xgtIZJSphBORYgWw4PPXq5pGFoZJk2Lx6AokuQ=@protonmail.com>
Message-ID: <CAMnpzfo-LZO5h2HE0Hwt7BxejJk-ZBKvKT0yjgdz92CHLOXm7A@mail.gmail.com>

On Mon, Sep 12, 2022 at 2:47 AM Buck O Perley via bitcoin-dev
<bitcoin-dev at lists.linuxfoundation.org> First just wanted to thank you
for taking the initiative to
> put this together. I think that as the community and
> ecosystem continue to grow, it's going to be an important
> part of the process to have groups like this develop. Hopefully
> they allow us to resist the "Tyranny of Structurelessness" without
> resorting to formalized governance processes and systems.

Huh, lots of reading material behind that phrase.  I'd heard it
before, but hadn't looked it up.

> > Defining a communication channel is still an open question: IRC, Slack,
> Discord, Discourse, ...
>
> I would vote against Slack. IRC is probably the best but maybe too
> high a barrier to entry? Publishing logs at least would counter
> concerns of it being exclusive. Maybe discord as an alternative.

I found Discord immediately wanted a phone number from me.  I think
IRC remains the lowest bar for participants to contribute.

> > About the starting point for regular meetings, I think the good timing is
> somewhere in November, after the upcoming cycle of Bitcoin conferences,

+1

> Maybe as a way to keep these topics separate, it would make sense
> for activation to have its own WG. As norms develop around this one,
> they could inform creating a separate space focused on forwarding
> research and discussion around how to introduce upgrades to bitcoin.

I'd participate in this.

> In general it would be nice to have multiple of these groups
> happening at once, and finding a way that they can operate separate
> from centralized companies. To my mind, there's no good reason why
> a supposedly decentralized protocol should have to be focusing on only
> one set of protocol advancements at a time. The linear way that
> discussions post-Taproot activation took shape ("What do you think the
> next bitcoin softfork should be?") is a sign of weakness in my opinion.
> Definitely a big red flag that we should be concerned with.

Yes.

> * Any thoughts on starting to commit to an in-person meetup to happen
> ~6 months - 1 year after the start of the regular online meetings?

I think that sounds reasonable.

From jeremy.l.rubin at gmail.com  Wed Sep 14 18:31:55 2022
From: jeremy.l.rubin at gmail.com (Jeremy Rubin)
Date: Wed, 14 Sep 2022 11:31:55 -0700
Subject: [bitcoin-dev] Spookchains: Drivechain Analog with One-Time Trusted
	Setup & APO
Message-ID: <CAD5xwhgKGMx79+RLpb-hjd3Gc=EKxTVzkpME-=KuM_C5+d7mRQ@mail.gmail.com>

*also available here on my blog with nicer
formatting: https://rubin.io/bitcoin/2022/09/14/drivechain-apo/
<https://rubin.io/bitcoin/2022/09/14/drivechain-apo/>*

This post draws heavily from Zmnscpxj's fantastic post showing how to
make drivechains with recursive covenants. In this post, I will show
similar tricks that can accomplish something similar using ANYPREVOUT
with a one time trusted setup ceremony.

This post presents general techniques that could be applied to many
different types of covenant.

# Peano Counters

The first component we need to build is a Peano counter graph. Instead
of using sha-256, like in Zmnscpxj's scheme, we will use a key and
build a simple 1 to 5 counter that has inc / dec.

Assume a key K1...K5, and a point NUMS which is e.g.
HashToCurve("Spookchains").

Generate scripts as follows:

```
<1 || K1> CHECKSIG
...
<1 || K5> CHECKSIG
```

Now generate 2 signatures under Ki with flags `SIGHASH_SINGLE |
SIGHASH_ANYONECANPAY | SIGHASH_ANYPREVOUT`.


## Rule Increment
For each Ki, when `i < 5`, create a signature that covers a
transaction described as:

```
Amount: 1 satoshi
Key: Tr(NUMS, {<1 || K{i+1}> CHECKSIG})
```

## Rule Decrement
For each Ki, when `i > 1` The second signature should cover:
```
Amount: 1 satoshi
Key: Tr(NUMS, {<1 || K{i-1}> CHECKSIG})
```



_Are these really Peano?_ Sort of. While a traditional Peano numeral
is defined as a structural type, e.g. `Succ(Succ(Zero))`, here we
define them via a Inc / Dec transaction operator, and we have to
explicitly bound these Peano numbers since we need a unique key per
element. They're at least spiritually similar.

## Instantiation
Publish a booklet of all the signatures for the Increment and
Decrement rules.

Honest parties should destroy the secret key sets `k`.


To create a counter, simply spend to output C:

```
Amount: 1 satoshi
Key: Tr(NUMS, {<1 || K1> CHECKSIG})
```


The signature from K1 can be bound to C to 'transition' it to (+1):

```
Amount: 1 satoshi
Key: Tr(NUMS, {<1 || K2> CHECKSIG})
```

Which can then transition to (+1):

```
Amount: 1 satoshi
Key: Tr(NUMS, {<1 || K3> CHECKSIG})
```

Which can then transition (-1) to:

```
Amount: 1 satoshi
Key: Tr(NUMS, {<1 || K2> CHECKSIG})
```

This can repeat indefinitely.


We can generalize this technique from `1...5` to `1...N`.



# Handling Arbitrary Deposits / Withdrawals


One issue with the design presented previously is that it does not
handle arbitrary deposits well.

One simple way to handle this is to instantiate the protocol for every
amount you'd like to support.

This is not particularly efficient and requires a lot of storage
space.

Alternatively, divide (using base 2 or another base) the deposit
amount into a counter utxo per bit.

For each bit, instead of creating outputs with 1 satoshi, create
outputs with 2^i satoshis.

Instead of using keys `K1...KN`, create keys `K^i_j`, where i
represents the number of sats, and j represents the counter. Multiple
keys are required per amount otherwise the signatures would be valid
for burning funds.

## Splitting and Joining

For each `K^i_j`, it may also be desirable to allow splitting or
joining.

Splitting can be accomplished by pre-signing, for every `K^i_j`, where
`i!=0`, with `SIGHASH_ALL | SIGHASH_ANYPREVOUT`:

```
Input: 2^i sats with key K^i_j
Outputs:
    - 2^i-1 sats to key K^{i-1}_j
    - 2^i-1 sats to key K^{i-1}_j
```

Joining can be accomplished by pre-signing, for every `K^i_j`, where
`i!=MAX`, with `SIGHASH_ALL | SIGHASH_ANYPREVOUT`:

```
Inputs:
    - 2^i sats with key K^i_j
    - 2^i sats with key K^i_j
Outputs:
    - 2^i+1 sats to key K^{i+1}_j
```

N.B.: Joining allows for third parties to deposit money in externally,
that is not a part of the covenant.


The splitting and joining behavior means that spookchain operators
would be empowered to consolidate UTXOs to a smaller number, while
allowing arbitrary deposits.


# One Vote Per Block

To enforce that only one vote per block mined is allowed, ensure that
all signatures set the input sequence to 1 block. No CSV is required
because nSequence is in the signatures already.

# Terminal States / Thresholds

When a counter reaches the Nth state, it represents a certain amount
of accumulated work over a period where progress was agreed on for
some outcome.

There should be some viable state transition at this point.

One solution would be to have the money at this point sent to an
`OP_TRUE` output, which the miner incrementing that state is
responsible for following the rules of the spookchain. Or, it could be
specified to be some administrator key / federation for convenience,
with a N block timeout that degrades it to fewer signers (eventually
0) if the federation is dead to allow recovery.

This would look like, from any `K^i_j`, a signature for a transaction
putting it into an `OP_TRUE` and immediately spending it. Other
spookchain miners would be expected to orphan that miner otherwise.


# Open States / Proposals

>From a state `K^i_1`, the transaction transitioning to `K^i_2` can be
treated as 'special' and the `OP_RETURN` output type can be used to
commit to, e.g., the outputs that must be created in when the Terminal
State is reached. This clarifies the issue of "what is being voted
on".

This method does not *lock in* at a consensus layer what Terminal
State is being voted on.

In certain circumstances, without violating the one-time-setup
constraint, if a fixed list of withdrawer's addresses is known in
advance, the Open States could cover withdrawals to specific
participants, which then must collect a certain number of votes from
miners.  However, it seems impossible, without new primitives, for an
arbitrary transaction proposal to be voted on.

# Setup Variants

## xpubs

Instead of using randomly generated keys for each state, define each
to be an xpub and derive a path where it is k/i/j for each
state/satoshi amount. This saves some data, and also requires less
entropy.

### Trustless Data Commit:

commit to the hash of the entire program spec as a tweak to the xpub,
so that someone can quickly verify if they have all the signatures you
are expected to generate if honest.

One way to do this is to convert a hash to a list of HD Child Numbers
(9 of them) deterministically, and tweak the xpub by that. This is a
convenient, yet inefficient, way to tweak an xpub because the child
has a normal derivation path for signing devices.

## Single Party

A single party pre-signs all the transactions for the spookchain, and
then deletes their xpriv.

You trust them to have deleted the key, and signed properly, but you
do not trust whoever served you the spookchain blob to have given you
all the state transitions because of the trustless data commitment.

## MuSig Multi-Party

Define a MuSig among all participants in the setup ceremony, N-of-N.

Now you simply trust that any one person in the one-time-setup was
honest! Very good.

## Unaggregated Multi-Party


Allow for unaggregated multi-sig keys in the spec. This grows with
O(signers), however, it means that a-la-carte you can aggregate setups
from random participants who never interacted / performed setup
ceremonies independently if they signed the same specs.

Can also combine multiple MuSig Multi-Parties in this way.

This is nice because MuSig inherently implies the parties colluded at
one point to do a MuSig setup, whereas unaggregated multi-sig could be
performed with no connectivity between parties.

## Soft Forking Away Trust

Suppose a spookchain becomes popular. You could configure your client
to reject invalid state transitions, or restrict the spookchain keys
to only sign with the known signatures. This soft fork would smoothly
upgrade the trust assumption.

## Symmetry of State Transition Rules & DAG Covenants

We could have our increment state transitions be done via a trustless
covenant, and our backwards state transitions be done via the setup.

This would look something like the following for state i:

```
Tr(NUMS, {
    `<sig for state K_{i+1}> <1 || PK_nonsecret> CHECKSIG`,
    `<1 || Ki> CHECKSIG`
})
```

The advantage of such an optimization is theoretically nice because it
means that *only* the non-destructuring recursive part of the
computation is subject to the one-time-setup trust assumption, which
might be of use in various other protocols, where recursivity might
only be unlocked e.g. after a timeout (but for spookchains it is used
at each step).

A compiler writer might perform this task by starting with an
arbitrary abstract graph, and then removing edges selectively (a
number of heuristics may make sense, e.g., to minimize reliance on
one-time-setup or minimize costs) until the graph is a Directed
Acyclic Graph, consisting of one or more components, compiling those
with committed covenants, and then adding the removed edges back using
the one-time-setup key materials.


# Commentary on Trust and Covenantiness

Is this a covenant? I would say "yes". When I defined covenants in my
_Calculus of Covenants_ post, it was with a particular set of
assumptions per covenant.

Under that model, you could, e.g., call a 7-10 multi-sig with specific
committed instructions as 4-10 honest (requires 4 signatories to be
honest to do invalid state transition) and 4-10 killable (requires 4
signatories to die to have no way of recovering).

For emulations that are pre-signed, like the varieties used to emulate
CTV, it is a different model because if your program is correct and
you've pre-gotten the signatures for N-N it is 1-N honest (only 1
party must be honest to prevent an invalid state transition) and
unkillable (all parties can safely delete keys).

I model these types of assumptions around liveness and honesty as
different 'complexity classes' than one another.

What I would point out is that with the counter model presented above,
this is entirely a pre-signed 1-N honest and unkillable covenant that
requires no liveness from signers. Further, with APO, new instances of
the covenant do not require a new set of signers, the setup is truly
one-time. Therefore this type of covenant exists in an even lower
trust-complexity class than CTV emulation via presigneds, which
requires a new federation to sign off on each contract instance.


With that preface, let us analyze this covenant:


1) A set of sets of transaction intents (a family), potentially
recursive or co-recursive (e.g., the types of state transitions that
can be generated).  These intents can also be represented by a
language that generates the transactions, rather than the literal
transactions themselves. We do the family rather than just sets at
this level because to instantiate a covenant we must pick a member of
the family to use.


The set of sets of transaction intents is to increment / decrement to
a successor or predecessor, or to halve into two instances or double
value by adding funds. Each successor or predecessor is the same type
of covenant, with the excetion of the first and last, which have some
special rules.


2) A verifier generator function that generates a function that
accepts an intent that is any element of one member of the family of
intents and a proof for it and rejects others.

The verifier generator is the simple APO CHECKSIG script.

3) A prover generator function that generates a function that takes an
intent that is any element of one member of the family and some extra
data and returns either a new prover function, a finished proof, or a
rejection (if not a valid intent).

The prover generator is the selection of the correct signature from a
table for a given script.

Run the prover generator with the private keys present *once* to
initialize over all reachable states, and cache the signatures, then
the keys may be deleted for future runs.

4) A set of proofs that the Prover, Verifier, and a set of intents are
"impedance matched", that is, all statements the prover can prove and
all statements the verifier can verify are one-to-one and onto (or
something similar), and that this also is one-to-one and onto with one
element of the intents (a set of transactions) and no other.

At a given key state the only things that may happen are signed
transactions, no other data is interpreted off of the stack. Therefore
there is perfect impedance match.


5) A set of assumptions under which the covenant is verified (e.g., a
multi-sig covenant with at least 1-n honesty, a multisig covenant with
any 3-n honesty required, Sha256 collision resistance, Discrete Log
Hardness, a SGX module being correct).

Uniquely, that during the setup phase at least one of the keys
were faithfully deleted.

The usual suspects for any bitcoin transaction are also assumed for
security.


6) Composability:

The Terminal State can pay out into a pre-specified covenant if
desired from any other family of covenants.
--
@JeremyRubin <https://twitter.com/JeremyRubin>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220914/c337d266/attachment-0001.html>

From c1.bitcoin at niftybox.net  Thu Sep 15 08:05:27 2022
From: c1.bitcoin at niftybox.net (Devrandom)
Date: Thu, 15 Sep 2022 10:05:27 +0200
Subject: [bitcoin-dev] On a new community process to specify covenants
In-Reply-To: <CAMnpzfo-LZO5h2HE0Hwt7BxejJk-ZBKvKT0yjgdz92CHLOXm7A@mail.gmail.com>
References: <BQjnkZZajHKYBOUFAin8toHgNHhG346VUR4GQx6bSi2ftOuNTK1c1d4LWN4Zmr0tUg2w3xgtIZJSphBORYgWw4PPXq5pGFoZJk2Lx6AokuQ=@protonmail.com>
 <CAMnpzfo-LZO5h2HE0Hwt7BxejJk-ZBKvKT0yjgdz92CHLOXm7A@mail.gmail.com>
Message-ID: <CAB0O3SWsjuQ+gc+QPcqnKQWFO=aXYsUm+TSfjiXFvi+diUtUMA@mail.gmail.com>

On Tue, Sep 13, 2022 at 6:03 PM Ryan Grant via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> On Mon, Sep 12, 2022 at 2:47 AM Buck O Perley via bitcoin-dev
> <bitcoin-dev at lists.linuxfoundation.org> First just wanted to thank you
> for taking the initiative to
> > put this together. I think that as the community and
> > ecosystem continue to grow, it's going to be an important
> > part of the process to have groups like this develop. Hopefully
> > they allow us to resist the "Tyranny of Structurelessness" without
> > resorting to formalized governance processes and systems.
>
> Huh, lots of reading material behind that phrase.  I'd heard it
> before, but hadn't looked it up.
>
> > > Defining a communication channel is still an open question: IRC, Slack,
> > Discord, Discourse, ...
> >
> > I would vote against Slack. IRC is probably the best but maybe too
> > high a barrier to entry? Publishing logs at least would counter
> > concerns of it being exclusive. Maybe discord as an alternative.
>
> I found Discord immediately wanted a phone number from me.  I think
> IRC remains the lowest bar for participants to contribute.
>
>
Agreed, anything that requires a phone number makes it difficult to be
pseudonymous.

I recommend Matrix, since it doesn't require any privacy invasive
information and has e2ee by default for 1-1 conversations.

The Matrix room could optionally bridge to IRC if there is a significant
demand for that.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220915/2f70be72/attachment.html>

From aj at erisian.com.au  Fri Sep 16 07:15:45 2022
From: aj at erisian.com.au (Anthony Towns)
Date: Fri, 16 Sep 2022 17:15:45 +1000
Subject: [bitcoin-dev] bitcoin-inquistion: evaluating soft forks on signet
Message-ID: <YyQioS3F942wu1HW@erisian.com.au>

Subhead: "Nobody expects a Bitcoin Inquistion? C'mon man, *everyone*
expects a Bitcoin Inquisition."

As we've seen from the attempt at a CHECKTEMPLATEVERIFY activation earlier
in the year [0], the question of "how to successfully get soft fork
ideas from concept to deployment" doesn't really have a good answer today.

Obviously, a centralised solution to this problem exists: we could
establish a trusted group, perhaps one containing devs, industry
representatives, investors, etc, have them review proposals and their
implementations, and follow their lead when they decide that a proposal
has met their standards and should be widely deployed. Some might even
say "sipa is precisely that group". The problem with having a group of
that nature isn't one of effectiveness, but rather that they are then
vulnerable to pressure and corruption, which isn't desirable if we want
everyone using Bitcoin to truly be peers, and often isn't desirable for
the prospective members of the group either. So that's not something we
should want people to volunteer for, nor is it a duty we should thrust
on people. Or at least, that's my opinion, anyway.

I think any alternative approach to doing consensus changes (while
avoiding a chain split) has to look something like this:

 * propose an idea (research phase)
 * implement the idea (development phase)
 * demonstrate the idea is worthwhile (evaluation phase)
 * once everyone is convinced, activate (deployment phase)

Without an evaluation phase that is thorough enough to convince (almost)
everyone, I think deployment becomes controversial and perhaps effectively
impossible (at least without some trusted leadership group). But with an
evaluation phase that demonstrates to everyone who's interested that the
proposal has actual value, minimal cost and no risk, I think activation
could be fairly easy and straightforward.

I contend that the most significant problem we have is in the "evaluation
phase". How do you convince enough people that a change is sufficiently
beneficial to justify the risk of messing with their money? If you're
only trying to convince a few experts, then perhaps you can do that with
papers and talks; but limiting the evaluation to only a few experts is
effectively just falling back to the centralised approach.

So I think that means that part of the "evaluation phase" should involve
implementing real systems on top of the proposed change, so that you
can demonstrate real value from the change. It's easy to say that
"CTV can enable vaults" or "CTV can make opening a lightning channel
non-interactive" -- but it's harder to go from saying something
is possible to actually making it happen, so, at least to me, it
seems reasonable to be skeptical of people claiming benefits without
demonstrating they're achievable in practice.

I contend the easiest way we could make it easy to demonstrate a soft
fork working as designed is to deploy it on the default global signet,
essentially as soon as it has a fully specified proposal and a reasonably
high-quality implementation.

The problem with that idea is that creates a conundrum: you can't activate
a soft fork on the default signet without first merging the code into
bitcoin core, you can't merge the code into bitcoin core until it's been
fully evaluated, and the way you evaluate it is by activating it on the
default signet?

I think the weakest link in that loop is the first one: what if we did
activate soft forks on the default signet prior to the code being merged
into core? To that end, I'm proposing a fork of core that I'm calling
"bitcoin-inquisition", with the idea that it branches from stable
releases of core and adds support for proposed changes to consensus
(CTV, ANYPREVOUT, TLUV, OP_CAT, etc...) and potentially also relay
policy (relay changes are often implied by consensus changes, but also
potentially things like package relay).

  https://github.com/bitcoin-inquisition/bitcoin/wiki
  https://github.com/bitcoin-inquisition/bitcoin/pulls

The idea being that if you're trying to work on "upgrading lightning
to support eltoo", you can iterate through changes needed to consensus
(via bitcoin-inquisition) and client apps (cln, lnd, eclair etc), while
testing them in public (on signet) and having any/all the pre-existing
signet infrastructure available (faucets, explorers etc) without having
to redeploy it yourself. Having multiple consensus changes deployed in
one place also seems like it might make it easier to compare alternative
approaches (eg CTV vs ANYPREVOUT vs OP_TXHASH vs OP_TX, etc).

So that's the concept. For practical purposes, I haven't yet merged
either CTV or APO support into the bitcoin-inquisition 23.0 branch yet,
and before actually mining blocks I want to make the signet miner able
to automatically detect/recover if the bitcoin-inquisition node either
crashes or starts producing incompatible blocks.

Anyway, I wanted to post the idea publicly, both to give folks an
opportunity to poke holes in the idea, or to suggest any further
improvements or otherwise do any review before the CTV and APO patches
get merged.

Some other details that may be of interest.

The biggest challenge with soft forks and the idea of "iterating
through changes" is that making improvements can create a hard fork,
which then forces everyone running old software to update, which can be
pretty inconvenient, especially if you don't actually care about that
change. Since signet (and regtest) mining is effectively permissioned,
we can avoid that problem by having all these proposed soft forks
come with a pre-baked ability to abandon the soft fork (much as David
Harding described in [1]). Once a soft fork is abandoned, it can either
be ignored forever (and later versions of the software can not include
the code to enforce it at all), or it can be replaced by a new version
of the soft fork.

Another benefit that comes from signet chains being permissioned is
that miners can be expected to coordinate upgrading out of band, so
there is no need for a 90% signalling threshold. Instead, activation
(and abandonment) of a soft fork can be triggered by a single block
signalling. That further means there is no need for any individual
block to signal for multiple forks, and instead of having 29 different
signals, we can instead easily have up to 2**29. I've chosen to make
the standard signal have 16 bits for specifying a bip number (0-65535)
and 8 bits for specifying a version of that bip, which seems like it
should be more than enough at least for a while. More details at [2].

I'm basing bitcoin-inquisition solely off stable releases. This is partly
because it can be annoying to constantly rebase consensus changes aginst
bitcoin core's master branch, but also I think it might help consensus
changes be easily backported once they pass the "evaluation phase"
and move into the "deployment phase".

I'm not sure what level of code quality PRs should have before being
merged into bitcoin-inquisition. I think CTV is plenty good enough,
but I'm not sure about APO, particularly its test coverage. If you want
to influence what becomes the tradition here, contributing a review,
or posting patches against the upsteam branch might be a good start?

Does this make the global default signet miners, or perhaps the
bitcoin-inquisition maintainers the "trusted group" that we want to
avoid? Hopefully not -- anyone can run their own fork or do their own
fork of bitcoin core, so if the miners/maintainers start trying to
arbitrarily block proposals they can be worked around without too much
hassle. And since they're clearly separate from any of the actions that
need to be taken for actual deployment once activation is complete,
they shouldn't have any ability to unduly promote fork proposals that
people aren't fully satisfied are ready for deployment.

Cheers,
aj

[0] https://bitcoinops.org/en/newsletters/2022/04/27/#discussion-about-activating-ctv

[1] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-April/020242.html

[2] https://github.com/bitcoin-inquisition/bitcoin/wiki/Heretical-Deployments


From lf-lists at mattcorallo.com  Fri Sep 16 16:46:53 2022
From: lf-lists at mattcorallo.com (Matt Corallo)
Date: Fri, 16 Sep 2022 12:46:53 -0400
Subject: [bitcoin-dev] bitcoin-inquistion: evaluating soft forks on
	signet
In-Reply-To: <YyQioS3F942wu1HW@erisian.com.au>
References: <YyQioS3F942wu1HW@erisian.com.au>
Message-ID: <798e8c4a-78e2-b210-2202-4b358b95a581@mattcorallo.com>

Apologies for any typos, somewhat jet-lagged atm.

On 9/16/22 3:15 AM, Anthony Towns via bitcoin-dev wrote:
> Subhead: "Nobody expects a Bitcoin Inquistion? C'mon man, *everyone*
> expects a Bitcoin Inquisition."
> 
> As we've seen from the attempt at a CHECKTEMPLATEVERIFY activation earlier
> in the year [0], the question of "how to successfully get soft fork
> ideas from concept to deployment" doesn't really have a good answer today.

I strongly disagree with this. Going back many, many years we've had many discussions about fork 
process, and the parts people (historically) agreed with tend to be:

(1) come up with an idea
(2) socialize the idea in the technical community, see if anyone comes up with any major issues or 
can suggest better ideas which solve the same use-cases in cleaner ways
(3) propose the concrete idea with a more well-defined strawman, socialize that, get some kind of 
rough consensus in the loosely-defined, subjective, "technical community" (ie just ask people and 
adapt to feedback until you have found some kind of average of the opinions of people you, the 
fork-champion, think are reasonably well-informed!).
(4) okay, admittedly beyond this is a bit less defined, but we can deal with it when we get there.

Turns out, the issue today is a lack of champions following steps 1-3, we can debate what the 
correct answer is to step (4) once we actually have people who want to be champions who are willing 
to (humbly) push an idea forward towards rough agreement of the world of technical bitcoiners 
(without which I highly doubt you'd ever see broader-community consensus).

Matt

From antoine.riard at gmail.com  Fri Sep 16 18:59:50 2022
From: antoine.riard at gmail.com (Antoine Riard)
Date: Fri, 16 Sep 2022 14:59:50 -0400
Subject: [bitcoin-dev] On a new community process to specify covenants
In-Reply-To: <BQjnkZZajHKYBOUFAin8toHgNHhG346VUR4GQx6bSi2ftOuNTK1c1d4LWN4Zmr0tUg2w3xgtIZJSphBORYgWw4PPXq5pGFoZJk2Lx6AokuQ=@protonmail.com>
References: <BQjnkZZajHKYBOUFAin8toHgNHhG346VUR4GQx6bSi2ftOuNTK1c1d4LWN4Zmr0tUg2w3xgtIZJSphBORYgWw4PPXq5pGFoZJk2Lx6AokuQ=@protonmail.com>
Message-ID: <CALZpt+HaeyA8U_6G6RMZCzK944qs4i1ZtcQ=gvAYHm-NSFe4xw@mail.gmail.com>

Hi Buck,

> First just wanted to thank you for taking the initiative to
> put this together. I think that as the community and
> ecosystem continue to grow, it's going to be an important
> part of the process to have groups like this develop. Hopefully
> they allow us to resist the "Tyranny of Structurelessness" without
> resorting to formalized governance processes and systems.

Thanks for the words. Effectively, organic WGs are likely good avenues for
the ecosystem to make steady and substantial progress during the coming
future. If there is any structure in the development of Bitcoin it's the
rich network of open, neutral and decentralized communication networks and
spaces that has been nurtured through the past decade and I hope that's a
tradition we'll keep maintaining.

> Defining a communication channel is still an open question: IRC, Slack,
Discord, Discourse, ...

I would vote against Slack. IRC is probably the best but maybe too high a
barrier to entry? Publishing logs at least would counter concerns of it
being exclusive. Maybe discord as an alternative.

I would say I really like IRC too. The strong text-based format, the lack
of avatar emoji, the low-bar to participate pseudonymously, the leveling
field for non-native speakers contrary to audio and the easiness to grab
the mics, all features valuable for such a process I think.

If IRC is still considered a technical high-bar for a standard
communication organ by many community stakeholders, discord is an
alternative.

> I understand the reason for this but I do have some concerns that
> it's not as off-topic as most of us would like. It shouldn't
> be a priority but how any of these primitives end up getting activated
> is part of the proposal itself in my opinion.
>
> I think it also became clear in some of the discussions over the past
> ~year that maybe there were more concerns than people realized about
> even the taproot activation process, whether the method used or if it
> was done too quickly. An example of where there might be
> some intersection with the WG as proposed is the question of how much
> research, security audits, etc. are "enough" before it should be
> considered for activation?

>From my understanding, how any of these primitives end up getting activated
is more a deployment methodology concern. What is more interesting is why
any of those primitives would be valuable as a Bitcoin upgrade. Beyond
proposing and refining primitives design and associated use-cases, there is
significant work to collect feedback on many dimensions and set of
criterias that matters to community stakeholders to achieve a consistent
and sound "why".

Where I believe there is an interaction between the "why" and "how" is that
during activation discussion some participant might bring new information
about shortcomings of a proposal, and as such if it's estimated relevant
could induce a step back to the "R&D" whiteboard phase, in a circular
feedback loop fashion. As those steps back are not free in terms of
community engineering resources, especially if deployment code starts to be
already disseminated across the ecosystem, I hope in the future we'll leave
reasonable time (in function of the complexity of the proposal) between
upgrade phases for grounded objections to raise.

>From my memory, about the taproot activation process it's correct that a
lot of people had discussions about producing more proof-of-work, e.g back
in 2019, LN devs were excited to PoC PTLC in the context of the structured
taproot review.
It didn't happen because it would have implied good refactoring works in
all implementations for that to happen and coordination with cryptographic
libraries dependencies.

In fact, it's likely the difficulty target for consensus upgrades to be
dynamic with the complexity of the ecosystem and stakes at risk increasing
modulo the amount of Bitcoin engineering resources dedicated.

> Maybe as a way to keep these topics separate, it would make sense
> for activation to have its own WG. As norms develop around this one,
> they could inform creating a separate space focused on forwarding
> research and discussion around how to introduce upgrades to bitcoin.

I think it could be interesting for activation to have its own WG. I
wouldn't call myself super knowledgeable in upgrades activation. I believe
it could be worthy for such WG to do the archival work of documentation and
referencing well all
the previous upgrades discussions, the set of signals and data points that
has been deemed as valuable by the community, etc.

> In general it would be nice to have multiple of these groups
> happening at once, and finding a way that they can operate separate
> from centralized companies. To my mind, there's no good reason why
> a supposedly decentralized protocol should have to be focusing on only
> one set of protocol advancements at a time. The linear way that
> discussions post-Taproot activation took shape ("What do you think the
> next bitcoin softfork should be?") is a sign of weakness in my opinion.
> Definitely a big red flag that we should be concerned with.

I agree with the sentiment, that it would be worthy to have multiple groups
happening at once, in a asynchronous and decentralized fashion, neutral
from centralized companies or cultural mobs. However, on the linearity of
the discussions post-Taproot, from my perspective the reason doesn't have
to be found in any community stakeholder bottlenecking or whatever but
rather in the limited subset of experienced Bitcoin protocol engineers we
have across the ecosystem. From quick mental maths, the number of active
folks with more than 4/5 years of experience and decent practical knowledge
of the critical Bitcoin subsystems to be able to work on consensus upgrades
is likely to be evaluated to two dozens. No more. And they're already the
most busy of the ecosystem: maintaining the critical pieces of code,
catching the bugs during reviews, doing active security research, caring
about the Q&A & release process, sharing back the knowledge towards new
devs...

Of course, everyone of them as the choice to prioritize consensus upgrades
over other tasks, but in the long-term it's likely at the detriment of
outcome valued by the community as a whole (e.g hardening the base-layer
P2P stack against high grade attacks, solving Lightning numerous liquidity
issues, etc).

Real weakness is the fact that as a community we're bleeding too much
seasoned protocol engineers for XYZ reasons.

> * it seems like there might be some opportunities to work with
> bipbounty.org which grew out of the organic bounty donations that
> were made towards finding CTV vulnerabilities. For example,
> if the group develops specific, achievable research goals (building
> out use cases, researching vulnerabilities or limitations, etc.),
> bipbounty.org could help support these efforts in a more decentralized
> way by diversifying funding.

First and foremost, thanks to everyone dedicating resources (engineering,
financial, operational, legal, ...) towards making Bitcoin stronger. About
bipbounty.org, I would like to observe the neutrality of the
decision-making process in the fund allocation could be better, especially
in terms of high-impact and sensitive subjects like consensus upgrades. It
sounds like the unique team member is also the technical author of the only
bounty displayed so far... Academics, law and medecine have centuries-long
traditions of board or peer-to-peer decision-making structure to allocate
scientific and engineering ressources with minimal guarantees of neutrality.

I think it would be valuable for this effort to structure for the
long-term, it would be great to have more community people dedicating their
own personal time on doing the hard operational and legal work to make
things sustainable. I would say there is definitively a need for more
Bitcoin researchers working on multiple-years scale "moonshots" projects.

> * Any thoughts on starting to commit to an in-person meetup to happen
> ~6 months - 1 year after the start of the regular online meetings?
> That should be plenty of time for people to plan and formalize
> a location and it seems like other IRL dev meetups have been
> very productive in terms of knowledge sharing and setting priorities.
> An in-person meetup would give a nice goal to work towards and a way
> to measure progress.

Yeah, I think in-person meetups would be very valuable and personally I've
always appreciated the knowledge sharing, priorities setting and
productivity boost of all the Bitcoin engineering meetings I've had the
opportunity to attend. 6 months - 1 year after the start of the regular
online meetings sounds like a good timeline, there is a preliminary step of
folks flooding and exchanging on their expectations, taking the process
habits and doing seminal work.

Best,
Antoine

Le dim. 11 sept. 2022 ? 22:47, Buck O Perley via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> a ?crit :

> Hi Antoine,
>
> First just wanted to thank you for taking the initiative to
> put this together. I think that as the community and
> ecosystem continue to grow, it's going to be an important
> part of the process to have groups like this develop. Hopefully
> they allow us to resist the "Tyranny of Structurelessness" without
> resorting to formalized governance processes and systems.
>
> > Defining a communication channel is still an open question: IRC, Slack,
> Discord, Discourse, ...
>
> I would vote against Slack. IRC is probably the best but maybe too
> high a barrier to entry? Publishing logs at least would counter
> concerns of it being exclusive. Maybe discord as an alternative.
>
> > About the starting point for regular meetings, I think the good timing is
> somewhere in November, after the upcoming cycle of Bitcoin conferences,
>
> +1
>
> > softfork activation discussions will be considered as
> off-topic and discouraged. This is first and foremost a long-term R&D
> effort.
>
> I understand the reason for this but I do have some concerns that
> it's not as off-topic as most of us would like. It shouldn't
> be a priority but how any of these primitives end up getting activated
> is part of the proposal itself in my opinion.
>
> I think it also became clear in some of the discussions over the past
> ~year that maybe there were more concerns than people realized about
> even the taproot activation process, whether the method used or if it
> was done too quickly. An example of where there might be
> some intersection with the WG as proposed is the question of how much
> research, security audits, etc. are "enough" before it should be
> considered for activation?
>
> Maybe as a way to keep these topics separate, it would make sense
> for activation to have its own WG. As norms develop around this one,
> they could inform creating a separate space focused on forwarding
> research and discussion around how to introduce upgrades to bitcoin.
>
> In general it would be nice to have multiple of these groups
> happening at once, and finding a way that they can operate separate
> from centralized companies. To my mind, there's no good reason why
> a supposedly decentralized protocol should have to be focusing on only
> one set of protocol advancements at a time. The linear way that
> discussions post-Taproot activation took shape ("What do you think the
> next bitcoin softfork should be?") is a sign of weakness in my opinion.
> Definitely a big red flag that we should be concerned with.
>
> Couple other comments from the proposal/repo:
>
> * it seems like there might be some opportunities to work with
> bipbounty.org which grew out of the organic bounty donations that
> were made towards finding CTV vulnerabilities. For example,
> if the group develops specific, achievable research goals (building
> out use cases, researching vulnerabilities or limitations, etc.),
> bipbounty.org could help support these efforts in a more decentralized
> way by diversifying funding.
>
> * Any thoughts on starting to commit to an in-person meetup to happen
> ~6 months - 1 year after the start of the regular online meetings?
> That should be plenty of time for people to plan and formalize
> a location and it seems like other IRL dev meetups have been
> very productive in terms of knowledge sharing and setting priorities.
> An in-person meetup would give a nice goal to work towards and a way
> to measure progress.
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220916/53376bec/attachment-0001.html>

From antoine.riard at gmail.com  Fri Sep 16 19:08:06 2022
From: antoine.riard at gmail.com (Antoine Riard)
Date: Fri, 16 Sep 2022 15:08:06 -0400
Subject: [bitcoin-dev] On a new community process to specify covenants
In-Reply-To: <CAB0O3SWsjuQ+gc+QPcqnKQWFO=aXYsUm+TSfjiXFvi+diUtUMA@mail.gmail.com>
References: <BQjnkZZajHKYBOUFAin8toHgNHhG346VUR4GQx6bSi2ftOuNTK1c1d4LWN4Zmr0tUg2w3xgtIZJSphBORYgWw4PPXq5pGFoZJk2Lx6AokuQ=@protonmail.com>
 <CAMnpzfo-LZO5h2HE0Hwt7BxejJk-ZBKvKT0yjgdz92CHLOXm7A@mail.gmail.com>
 <CAB0O3SWsjuQ+gc+QPcqnKQWFO=aXYsUm+TSfjiXFvi+diUtUMA@mail.gmail.com>
Message-ID: <CALZpt+GKqGzbUh=MiKmgkb+4R6Ha=Qb_+p-r3Q723wfAVtG+Kw@mail.gmail.com>

Hi Devrandom,

> Agreed, anything that requires a phone number makes it difficult to be
> pseudonymous.
>
> I recommend Matrix, since it doesn't require any privacy invasive
> information and has e2ee by default for 1-1 conversations.

Yeah sounds like people are opting for either Matrix or IRC and good to let
cast open.

If there are more things that the process could adopt to encourage or stay
open to pseudonymous participation that's interesting to bookmark.

Best,
Antoine

Le jeu. 15 sept. 2022 ? 04:37, Devrandom via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> a ?crit :

> On Tue, Sep 13, 2022 at 6:03 PM Ryan Grant via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>> On Mon, Sep 12, 2022 at 2:47 AM Buck O Perley via bitcoin-dev
>> <bitcoin-dev at lists.linuxfoundation.org> First just wanted to thank you
>> for taking the initiative to
>> > put this together. I think that as the community and
>> > ecosystem continue to grow, it's going to be an important
>> > part of the process to have groups like this develop. Hopefully
>> > they allow us to resist the "Tyranny of Structurelessness" without
>> > resorting to formalized governance processes and systems.
>>
>> Huh, lots of reading material behind that phrase.  I'd heard it
>> before, but hadn't looked it up.
>>
>> > > Defining a communication channel is still an open question: IRC,
>> Slack,
>> > Discord, Discourse, ...
>> >
>> > I would vote against Slack. IRC is probably the best but maybe too
>> > high a barrier to entry? Publishing logs at least would counter
>> > concerns of it being exclusive. Maybe discord as an alternative.
>>
>> I found Discord immediately wanted a phone number from me.  I think
>> IRC remains the lowest bar for participants to contribute.
>>
>>
> Agreed, anything that requires a phone number makes it difficult to be
> pseudonymous.
>
> I recommend Matrix, since it doesn't require any privacy invasive
> information and has e2ee by default for 1-1 conversations.
>
> The Matrix room could optionally bridge to IRC if there is a significant
> demand for that.
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220916/f33e741c/attachment.html>

From aj at erisian.com.au  Sat Sep 17 06:14:05 2022
From: aj at erisian.com.au (Anthony Towns)
Date: Sat, 17 Sep 2022 16:14:05 +1000
Subject: [bitcoin-dev] bitcoin-inquistion: evaluating soft forks on
	signet
In-Reply-To: <798e8c4a-78e2-b210-2202-4b358b95a581@mattcorallo.com>
References: <YyQioS3F942wu1HW@erisian.com.au>
 <798e8c4a-78e2-b210-2202-4b358b95a581@mattcorallo.com>
Message-ID: <YyVlra0AMIFO9Xid@erisian.com.au>

On Fri, Sep 16, 2022 at 12:46:53PM -0400, Matt Corallo via bitcoin-dev wrote:
> On 9/16/22 3:15 AM, Anthony Towns via bitcoin-dev wrote:
> > As we've seen from the attempt at a CHECKTEMPLATEVERIFY activation earlier
> > in the year [0], the question of "how to successfully get soft fork
> > ideas from concept to deployment" doesn't really have a good answer today.
> I strongly disagree with this.

Okay? "X is good" is obviously just a statement of opinion, so if you
want to disagree, that's obviously allowed. 

I also kind of feel like that's the *least* interesting paragraph in the
entire email to talk further about; if you think the current answer's
already good, then the rest of the mail's just about (hopefully) making
it better, which would be worthwhile anyway?

> Going back many, many years we've had many
> discussions about fork process, and the parts people (historically) agreed
> with tend to be:
> (1) come up with an idea
> (2) socialize the idea in the technical community, see if anyone comes up
> with any major issues or can suggest better ideas which solve the same
> use-cases in cleaner ways
> (3) propose the concrete idea with a more well-defined strawman, socialize
> that, get some kind of rough consensus in the loosely-defined, subjective,
> "technical community" (ie just ask people and adapt to feedback until you
> have found some kind of average of the opinions of people you, the
> fork-champion, think are reasonably well-informed!).
> (4) okay, admittedly beyond this is a bit less defined, but we can deal with it when we get there.
> Turns out, the issue today is a lack of champions following steps 1-3, we
> can debate what the correct answer is to step (4) once we actually have
> people who want to be champions who are willing to (humbly) push an idea
> forward towards rough agreement of the world of technical bitcoiners
> (without which I highly doubt you'd ever see broader-community consensus).

Personally, I think this is easily refuted by contradiction.

1) If we did have a good answer for how to progress a soft-fork, then
the great consensus cleanup [0] would have made more progress over the
past 3.5 years. Maybe not all of the ideas in it were unambiguously good
[1], but personally, I'm convinced at least some of them are, and I
don't think I'm alone in thinking that. Even if the excuse is that its
original champion wasn't humble enough, there's something wrong with
the process if there doesn't exist some other potential champion with
the right balance of humility, confidence, interest and time who could
have taken it over in that timeframe.

2) Many will argue that CTV has already done steps (1) through (3) above:
certainly there's been an idea, it's been socialised through giving talks,
having discussion forums, having research workshops [2], documenting use
cases use cases; there's been a concrete implementation for years now,
with a test network that supports the proposed feature, and new tools
that demonstrate some of the proposed use cases, and while alternative
approaches have been suggested [3], none of them have even really made
it to step (2), let alone step (3). So that leaves a few possibilities
to my mind:

 * CTV should be in step (4), and its lack of definition is a problem,
   and trying the "deal with it when we get there" approach is precisely
   what didn't work back in April.

 * The evaluation process is too inconclusive: it should either be
   saying "CTV is not good enough, fix these problems", or "CTV hasn't
   sufficiently demonstrated its value/cost, work on X next", but it
   isn't.

 * Parts (2) to (3) are too hard, and that's preventing alternatives
   from making progress, which in turn is preventing people from
   being able to decide whether CTV is the superior approach, or some
   alternative is.

But each of those possibilities indicates a significant problem with
our answer for developing soft forks.

I guess my belief is that it's mostly (2) and (3) being too hard (which
taproot overcame because many were excited about it, and CTV overcame
because Jeremy's put a lot of effort into it; but consensus cleanup,
APO, simplicity, TXHASH, etc have not similarly overcome at this point),
which leads to the evaluation process being inconclusive when plausible
alternatives exist. 

(In particular, I think having the process be massively difficult is
going to naturally cause any "humble" champion to decide that they're
not up to the task of following the process through to completion)

Anyway, that's some additional reasons why I believe what I said above,
in case that's interesting. But like I said at the start, if you still
disagree, that's fine of course.

Cheers,
aj

[0] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-March/016714.html
    https://github.com/bitcoin/bitcoin/pull/15481
    https://github.com/bitcoin/bitcoin/pull/15482

[1] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-March/016765.html
    https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-March/016763.html
    https://github.com/bitcoin/bitcoin/pull/15482#issuecomment-469822630

[2] https://utxos.org/workshops/

[3] TXHASH https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019813.html
    TX https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-May/020450.html
    Elements-style opcodes https://twitter.com/rusty_twit/status/1518007923896578048
      cf https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-February/019851.html
    ANYPREVOUT? https://twitter.com/darosior/status/1474375301262151684
    Simplicity? https://twitter.com/Mario_Gibney/status/1403890965903859718
    Lisp? https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-March/020036.html


From c1.bitcoin at niftybox.net  Sat Sep 17 07:52:49 2022
From: c1.bitcoin at niftybox.net (Devrandom)
Date: Sat, 17 Sep 2022 09:52:49 +0200
Subject: [bitcoin-dev] On a new community process to specify covenants
In-Reply-To: <CALZpt+HaeyA8U_6G6RMZCzK944qs4i1ZtcQ=gvAYHm-NSFe4xw@mail.gmail.com>
References: <BQjnkZZajHKYBOUFAin8toHgNHhG346VUR4GQx6bSi2ftOuNTK1c1d4LWN4Zmr0tUg2w3xgtIZJSphBORYgWw4PPXq5pGFoZJk2Lx6AokuQ=@protonmail.com>
 <CALZpt+HaeyA8U_6G6RMZCzK944qs4i1ZtcQ=gvAYHm-NSFe4xw@mail.gmail.com>
Message-ID: <CAB0O3SVh6xgaUjG_8UyR_3FyG8mcvh7K6ydBkJBTmZXe+rU6Ew@mail.gmail.com>

On Fri, Sep 16, 2022 at 9:18 PM Antoine Riard via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Hi Buck,
>
[...]

>
> I would vote against Slack. IRC is probably the best but maybe too high a
> barrier to entry? Publishing logs at least would counter concerns of it
> being exclusive. Maybe discord as an alternative.
>
> I would say I really like IRC too. The strong text-based format, the lack
> of avatar emoji, the low-bar to participate pseudonymously, the leveling
> field for non-native speakers contrary to audio and the easiness to grab
> the mics, all features valuable for such a process I think.
>
> If IRC is still considered a technical high-bar for a standard
> communication organ by many community stakeholders, discord is an
> alternative.
>

I would rule out Discord, since it requires phone numbers.  It doesn't
require them for every user, but it's based on some risk measurement.  The
phone flow is probably more likely to be triggered by VPN / Tor.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220917/e432d554/attachment.html>

From lf-lists at mattcorallo.com  Sat Sep 17 08:39:07 2022
From: lf-lists at mattcorallo.com (Matt Corallo)
Date: Sat, 17 Sep 2022 04:39:07 -0400
Subject: [bitcoin-dev] bitcoin-inquistion: evaluating soft forks on
	signet
In-Reply-To: <YyVlra0AMIFO9Xid@erisian.com.au>
References: <YyQioS3F942wu1HW@erisian.com.au>
 <798e8c4a-78e2-b210-2202-4b358b95a581@mattcorallo.com>
 <YyVlra0AMIFO9Xid@erisian.com.au>
Message-ID: <8e4dc33b-2992-0380-de2a-0b8afa3db5b7@mattcorallo.com>



On 9/17/22 2:14 AM, Anthony Towns wrote:
> On Fri, Sep 16, 2022 at 12:46:53PM -0400, Matt Corallo via bitcoin-dev wrote:
>> On 9/16/22 3:15 AM, Anthony Towns via bitcoin-dev wrote:
>>> As we've seen from the attempt at a CHECKTEMPLATEVERIFY activation earlier
>>> in the year [0], the question of "how to successfully get soft fork
>>> ideas from concept to deployment" doesn't really have a good answer today.
>> I strongly disagree with this.
> 
> Okay? "X is good" is obviously just a statement of opinion, so if you
> want to disagree, that's obviously allowed.
> 
> I also kind of feel like that's the *least* interesting paragraph in the
> entire email to talk further about; if you think the current answer's
> already good, then the rest of the mail's just about (hopefully) making
> it better, which would be worthwhile anyway?

No, I think its at least a good chunk of the "statement of problem". Yes, more testing is good, and 
this project is a way to get that. Cool. But implying that lack of test frameworks is in any 
material way part of the lack of movement on forks in Bitcoin I think is very wrong, so its worth 
pointing out, whether the particular project is useful or not is separate.

>> Going back many, many years we've had many
>> discussions about fork process, and the parts people (historically) agreed
>> with tend to be:
>> (1) come up with an idea
>> (2) socialize the idea in the technical community, see if anyone comes up
>> with any major issues or can suggest better ideas which solve the same
>> use-cases in cleaner ways
>> (3) propose the concrete idea with a more well-defined strawman, socialize
>> that, get some kind of rough consensus in the loosely-defined, subjective,
>> "technical community" (ie just ask people and adapt to feedback until you
>> have found some kind of average of the opinions of people you, the
>> fork-champion, think are reasonably well-informed!).
>> (4) okay, admittedly beyond this is a bit less defined, but we can deal with it when we get there.
>> Turns out, the issue today is a lack of champions following steps 1-3, we
>> can debate what the correct answer is to step (4) once we actually have
>> people who want to be champions who are willing to (humbly) push an idea
>> forward towards rough agreement of the world of technical bitcoiners
>> (without which I highly doubt you'd ever see broader-community consensus).
> 
> Personally, I think this is easily refuted by contradiction.
> 
> 1) If we did have a good answer for how to progress a soft-fork, then
> the great consensus cleanup [0] would have made more progress over the
> past 3.5 years

No? Who is the champion for it? I haven't been. No one else is obliged to take up the reins and run 
with it, that's not how open-source works. And no one has emerged who has strong interest in doing 
so, and that's totally fine. It means it hasn't made any progress, but that's an indication that no 
one feels strongly enough about it that its risen to the top of their personal priority list so 
clearly doesn't *need* to make progress.

> Maybe not all of the ideas in it were unambiguously good
> [1], but personally, I'm convinced at least some of them are, and I
> don't think I'm alone in thinking that. Even if the excuse is that its
> original champion wasn't humble enough, there's something wrong with
> the process if there doesn't exist some other potential champion with
> the right balance of humility, confidence, interest and time who could
> have taken it over in that timeframe.

No? Its not up to the community to find a champion for someone who wants a fork to happen. Either 
someone thinks its a good enough idea that they step up, or no one does. If no one does, then so be 
it. If the original proper (me, in this case) thought it was that important then its *their* 
responsibility to be the champion, no one else's.

> 2) Many will argue that CTV has already done steps (1) through (3) above:
> certainly there's been an idea, it's been socialised through giving talks,
> having discussion forums, having research workshops [2], documenting use
> cases use cases; there's been a concrete implementation for years now,
> with a test network that supports the proposed feature, and new tools
> that demonstrate some of the proposed use cases, and while alternative
> approaches have been suggested [3], none of them have even really made
> it to step (2), let alone step (3).

I don't really see how you can make this argument seriously. Honestly, if a soft-fork BIP only has 
one author on the list, then I'm not sure one can argue that step (3) has really been completed, and 
maybe not even step (2).

> So that leaves a few possibilities
> to my mind:

>   * CTV should be in step (4), and its lack of definition is a problem,
>     and trying the "deal with it when we get there" approach is precisely
>     what didn't work back in April.
> 
>   * The evaluation process is too inconclusive: it should either be
>     saying "CTV is not good enough, fix these problems", or "CTV hasn't
>     sufficiently demonstrated its value/cost, work on X next", but it
>     isn't.
> 
>   * Parts (2) to (3) are too hard, and that's preventing alternatives
>     from making progress, which in turn is preventing people from
>     being able to decide whether CTV is the superior approach, or some
>     alternative is.

I think this is most of it, but its not that they're too hard, its that people are *too busy*. There 
seemed to be more positive feedback, for example, to Rusty's proposal, but being the champion for a 
soft-fork is a full-time job for months on end, and last I checked Rusty has a lightning 
implementation to maintain, which tends to be a more-than-full-time job already.

To my knowledge, no one but Jeremy has made any serious attempt at being the champion for a 
soft-fork since Taproot, and before that Segwit (if someone reading this who contributes to Core 
already wants to, and isn't sure how to, there's lots of people who would happily mentor you! I'm 
sure you can figure out who to reach out to!).

Matt

From michaelfolkson at protonmail.com  Sat Sep 17 15:53:48 2022
From: michaelfolkson at protonmail.com (Michael Folkson)
Date: Sat, 17 Sep 2022 15:53:48 +0000
Subject: [bitcoin-dev] bitcoin-inquistion: evaluating soft forks on
	signet
In-Reply-To: <8e4dc33b-2992-0380-de2a-0b8afa3db5b7@mattcorallo.com>
References: <YyQioS3F942wu1HW@erisian.com.au>
 <798e8c4a-78e2-b210-2202-4b358b95a581@mattcorallo.com>
 <YyVlra0AMIFO9Xid@erisian.com.au>
 <8e4dc33b-2992-0380-de2a-0b8afa3db5b7@mattcorallo.com>
Message-ID: <8cU3OEEtb7Q8CRBHqeWV6qe4JSRnOeMjh2PRdYj4rsnxF4DxzQd1Bo-1DAPMWGNxjXsZQuSuPrDK5TF4ez6tONZ5ACoLJ_FqV6Y1q7ybSwI=@protonmail.com>

I agree with Matt. The less said about the "Aw shucks Jeremy didn't know that CTV didn't have community consensus at the time" [0] and "it was the lack of process that was the problem" the better. If people don't care about lack of community consensus there is no process in a permissionless, open source community that can stop them or direct them down a more patient, productive path (I tried). I think it is a shame because I think (maybe I'm wrong) at least in the technical community there is an understanding that long term Bitcoin is far from finished in exhausting its potential and we do need people who will work on changes that we'll need in the long term.

There are a few interesting things in here though. I'm not convinced by the name (bitcoin-inquisition, shedpaint, shedpaint, let's park that for the moment) but I do like the idea of signet having soft fork proposals enabled on it [1] whether that be CTV, APO etc and if that requires more of the signet code to be moved out of the Core repo so be it. I'm surprised more isn't being done on Liquid already with what possible future functionality is (and could be) enabled [2] there but maybe there is more happening than I'm aware of. Protocols or use cases built out and demonstrated on signet (and/or Liquid/sidechains) seem an obvious stepping stone to me for convincing the community that it is potentially worth taking the chain split risk for a particular upgrade. It is a long slog to get community consensus on an upgrade (Taproot certainly was a slog) but I think the vast majority of us think Taproot was worth that slog and Bitcoin would be poorer today without it.

The Great Consensus Cleanup is an interesting example in that I get Matt doesn't have time to champion it or focus on it with his LDK commitments but I have no idea where it would rank on his long term priority list if he wasn't working on LDK. Similarly I have no idea what people who understand this evolving system much better than I do are thinking with regards to say adding new opcodes, sighash flags versus say waiting on Simplicity and possibly adding new functionality within that potential upgrade. For people like me who are extremely unlikely to propose their own consensus change(s) getting some signal on what to spend time digging into would be useful rather than second guessing what people are thinking. There is a danger that you flirt with perceived public roadmaps when possible authority figures stick their necks out and effectively say "I'm not in charge but in an imaginary world where I was this is my current thinking of the ordering in which we could improve this system long term. But this could change depending on x, y and z and possible upgrades are only ready when they're ready and they have community consensus." There is no way people don't play these exercises in their minds. I do, I just have very few answers :) I personally think APO is in prime position to improve Lightning channel state management with eltoo and if it enables some covenant schemes too that seems like an added bonus. On APO versus waiting for APO like functionality in Simplicity I have no idea. Work on APO/eltoo and Simplicity both seem to be progressing in parallel so the APO versus Simplicity discussion perhaps rests on whether people think certain covenants should only really be enabled once we have the security guarantees of Simplicity [3] (if at all).

Antoine's covenant R&D effort [4] seems really promising and I hope the shenanigans from earlier in the year don't put people off from engaging with that. Hopefully we can see more exploration, development and research in covenants (e.g. this excellent research paper "Bitcoin Covenants: Three Ways to Control the Future" [5]) and we can foster a community which has very high standards, is open to new ideas and new research but can avoid these months long resisting chain split fights. I think the discussion would be much more interesting and much more productive if people didn't have to think "If I express a view now it will be used to attack me personally later" or worse "If I express a view now it will be used to justify an upcoming chain split". 

[0]: https://gist.github.com/michaelfolkson/352a503f4f9fc5de89af528d86a1b718
[1]: https://bitcoin.stackexchange.com/questions/98642/can-we-experiment-on-signet-with-multiple-proposed-soft-forks-whilst-maintaining
[2]: https://bitcoin.stackexchange.com/questions/109764/what-opcodes-are-supported-on-liquid-but-not-yet-on-bitcoin
[3]: https://bitcoinops.org/en/topics/simplicity/
[4]: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-September/020912.html
[5]: https://arxiv.org/pdf/2006.16714.pdf

--
Michael Folkson
Email: michaelfolkson at protonmail.com
Keybase: michaelfolkson
PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3


------- Original Message -------
On Saturday, September 17th, 2022 at 09:39, Matt Corallo via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:


> 
> On 9/17/22 2:14 AM, Anthony Towns wrote:
> 
> > On Fri, Sep 16, 2022 at 12:46:53PM -0400, Matt Corallo via bitcoin-dev wrote:
> > 
> > > On 9/16/22 3:15 AM, Anthony Towns via bitcoin-dev wrote:
> > > 
> > > > As we've seen from the attempt at a CHECKTEMPLATEVERIFY activation earlier
> > > > in the year [0], the question of "how to successfully get soft fork
> > > > ideas from concept to deployment" doesn't really have a good answer today.
> > > > I strongly disagree with this.
> > 
> > Okay? "X is good" is obviously just a statement of opinion, so if you
> > want to disagree, that's obviously allowed.
> > 
> > I also kind of feel like that's the least interesting paragraph in the
> > entire email to talk further about; if you think the current answer's
> > already good, then the rest of the mail's just about (hopefully) making
> > it better, which would be worthwhile anyway?
> 
> 
> No, I think its at least a good chunk of the "statement of problem". Yes, more testing is good, and
> this project is a way to get that. Cool. But implying that lack of test frameworks is in any
> material way part of the lack of movement on forks in Bitcoin I think is very wrong, so its worth
> pointing out, whether the particular project is useful or not is separate.
> 
> > > Going back many, many years we've had many
> > > discussions about fork process, and the parts people (historically) agreed
> > > with tend to be:
> > > (1) come up with an idea
> > > (2) socialize the idea in the technical community, see if anyone comes up
> > > with any major issues or can suggest better ideas which solve the same
> > > use-cases in cleaner ways
> > > (3) propose the concrete idea with a more well-defined strawman, socialize
> > > that, get some kind of rough consensus in the loosely-defined, subjective,
> > > "technical community" (ie just ask people and adapt to feedback until you
> > > have found some kind of average of the opinions of people you, the
> > > fork-champion, think are reasonably well-informed!).
> > > (4) okay, admittedly beyond this is a bit less defined, but we can deal with it when we get there.
> > > Turns out, the issue today is a lack of champions following steps 1-3, we
> > > can debate what the correct answer is to step (4) once we actually have
> > > people who want to be champions who are willing to (humbly) push an idea
> > > forward towards rough agreement of the world of technical bitcoiners
> > > (without which I highly doubt you'd ever see broader-community consensus).
> > 
> > Personally, I think this is easily refuted by contradiction.
> > 
> > 1) If we did have a good answer for how to progress a soft-fork, then
> > the great consensus cleanup [0] would have made more progress over the
> > past 3.5 years
> 
> 
> No? Who is the champion for it? I haven't been. No one else is obliged to take up the reins and run
> with it, that's not how open-source works. And no one has emerged who has strong interest in doing
> so, and that's totally fine. It means it hasn't made any progress, but that's an indication that no
> one feels strongly enough about it that its risen to the top of their personal priority list so
> clearly doesn't need to make progress.
> 
> > Maybe not all of the ideas in it were unambiguously good
> > [1], but personally, I'm convinced at least some of them are, and I
> > don't think I'm alone in thinking that. Even if the excuse is that its
> > original champion wasn't humble enough, there's something wrong with
> > the process if there doesn't exist some other potential champion with
> > the right balance of humility, confidence, interest and time who could
> > have taken it over in that timeframe.
> 
> 
> No? Its not up to the community to find a champion for someone who wants a fork to happen. Either
> someone thinks its a good enough idea that they step up, or no one does. If no one does, then so be
> it. If the original proper (me, in this case) thought it was that important then its their
> responsibility to be the champion, no one else's.
> 
> > 2) Many will argue that CTV has already done steps (1) through (3) above:
> > certainly there's been an idea, it's been socialised through giving talks,
> > having discussion forums, having research workshops [2], documenting use
> > cases use cases; there's been a concrete implementation for years now,
> > with a test network that supports the proposed feature, and new tools
> > that demonstrate some of the proposed use cases, and while alternative
> > approaches have been suggested [3], none of them have even really made
> > it to step (2), let alone step (3).
> 
> 
> I don't really see how you can make this argument seriously. Honestly, if a soft-fork BIP only has
> one author on the list, then I'm not sure one can argue that step (3) has really been completed, and
> maybe not even step (2).
> 
> > So that leaves a few possibilities
> > to my mind:
> 
> > * CTV should be in step (4), and its lack of definition is a problem,
> > and trying the "deal with it when we get there" approach is precisely
> > what didn't work back in April.
> > 
> > * The evaluation process is too inconclusive: it should either be
> > saying "CTV is not good enough, fix these problems", or "CTV hasn't
> > sufficiently demonstrated its value/cost, work on X next", but it
> > isn't.
> > 
> > * Parts (2) to (3) are too hard, and that's preventing alternatives
> > from making progress, which in turn is preventing people from
> > being able to decide whether CTV is the superior approach, or some
> > alternative is.
> 
> 
> I think this is most of it, but its not that they're too hard, its that people are too busy. There
> seemed to be more positive feedback, for example, to Rusty's proposal, but being the champion for a
> soft-fork is a full-time job for months on end, and last I checked Rusty has a lightning
> implementation to maintain, which tends to be a more-than-full-time job already.
> 
> To my knowledge, no one but Jeremy has made any serious attempt at being the champion for a
> soft-fork since Taproot, and before that Segwit (if someone reading this who contributes to Core
> already wants to, and isn't sure how to, there's lots of people who would happily mentor you! I'm
> sure you can figure out who to reach out to!).
> 
> Matt
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

From alicexbt at protonmail.com  Sun Sep 18 12:27:43 2022
From: alicexbt at protonmail.com (alicexbt)
Date: Sun, 18 Sep 2022 12:27:43 +0000
Subject: [bitcoin-dev] bitcoin-inquistion: evaluating soft forks on
	signet
In-Reply-To: <8cU3OEEtb7Q8CRBHqeWV6qe4JSRnOeMjh2PRdYj4rsnxF4DxzQd1Bo-1DAPMWGNxjXsZQuSuPrDK5TF4ez6tONZ5ACoLJ_FqV6Y1q7ybSwI=@protonmail.com>
References: <YyQioS3F942wu1HW@erisian.com.au>
 <798e8c4a-78e2-b210-2202-4b358b95a581@mattcorallo.com>
 <YyVlra0AMIFO9Xid@erisian.com.au>
 <8e4dc33b-2992-0380-de2a-0b8afa3db5b7@mattcorallo.com>
 <8cU3OEEtb7Q8CRBHqeWV6qe4JSRnOeMjh2PRdYj4rsnxF4DxzQd1Bo-1DAPMWGNxjXsZQuSuPrDK5TF4ez6tONZ5ACoLJ_FqV6Y1q7ybSwI=@protonmail.com>
Message-ID: <T4meYqm1urcpCDED6kZjkjDt4hWkmRGKdRNMC2Y6SBHGqNm1t5id4v2GChIlCQwRiy20O9bR2PaT_jCCYEeG4sCkOp77fraTlunN7teZldQ=@protonmail.com>

Hi Michael,

> I agree with Matt. The less said about the "Aw shucks Jeremy didn't know that CTV didn't have community consensus at the time" [0] and "it was the lack of process that was the problem" the better. 

The linked gist cannot be taken seriously and I am not sure why you keep sharing it as some document to prove there was no technical consensus for BIP 119. Nadav has already mentioned this in the comments. If you care about community consensus, maybe feedback about the links in that gist should also be respected. There was chaos, misinformation and lot of drama on twitter. Some people that opposed CTV on twitter still have no clue what CTV actually does and a few were super enthusiastic because of the author for BIP 119.

> I'm not convinced by the name (bitcoin-inquisition, shedpaint, shedpaint, let's park that for the moment) but I do like the idea of signet having soft fork proposals enabled on it [1] whether that be CTV, APO etc and if that requires more of the signet code to be moved out of the Core repo so be it.

Good to see some positivity, finally. Because tx introspection aka covenants would help everyone involved in bitcoin. This idea of experimenting with soft forks on signet together with research and meetings suggested by Antoine should help in better evaluation phase with less drama, politics etc. and more technical discussions to reach a goal.

> I'm surprised more isn't being done on Liquid already with what possible future functionality is (and could be) enabled [2] there but maybe there is more happening than I'm aware of. 

1)Nobody uses Liquid. Signet has more activity than Liquid.
2)Testing something on Liquid will be completely different as its a separate blockchain with some similarities.

I have summarized a few other positives of testing soft forks on signet based on AJ's email:

a)Better evaluation
b)PR implementing soft fork could be reviewed and merged outside core
c)Testing on signet with pre-existing signet infrastructure
d)Can deploy multiple consensus changes so easier to compare alternative approaches (eg CTV vs ANYPREVOUT vs OP_TXHASH vs OP_TX, etc)
e)Pre-baked ability to abandon the soft fork
f)No need to regularly rebase consensus changes against bitcoin core's master branch

/dev/fd0

Sent with Proton Mail secure email.

------- Original Message -------
On Saturday, September 17th, 2022 at 3:53 PM, Michael Folkson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:


> I agree with Matt. The less said about the "Aw shucks Jeremy didn't know that CTV didn't have community consensus at the time" [0] and "it was the lack of process that was the problem" the better. If people don't care about lack of community consensus there is no process in a permissionless, open source community that can stop them or direct them down a more patient, productive path (I tried). I think it is a shame because I think (maybe I'm wrong) at least in the technical community there is an understanding that long term Bitcoin is far from finished in exhausting its potential and we do need people who will work on changes that we'll need in the long term.
> 
> There are a few interesting things in here though. I'm not convinced by the name (bitcoin-inquisition, shedpaint, shedpaint, let's park that for the moment) but I do like the idea of signet having soft fork proposals enabled on it [1] whether that be CTV, APO etc and if that requires more of the signet code to be moved out of the Core repo so be it. I'm surprised more isn't being done on Liquid already with what possible future functionality is (and could be) enabled [2] there but maybe there is more happening than I'm aware of. Protocols or use cases built out and demonstrated on signet (and/or Liquid/sidechains) seem an obvious stepping stone to me for convincing the community that it is potentially worth taking the chain split risk for a particular upgrade. It is a long slog to get community consensus on an upgrade (Taproot certainly was a slog) but I think the vast majority of us think Taproot was worth that slog and Bitcoin would be poorer today without it.
> 
> The Great Consensus Cleanup is an interesting example in that I get Matt doesn't have time to champion it or focus on it with his LDK commitments but I have no idea where it would rank on his long term priority list if he wasn't working on LDK. Similarly I have no idea what people who understand this evolving system much better than I do are thinking with regards to say adding new opcodes, sighash flags versus say waiting on Simplicity and possibly adding new functionality within that potential upgrade. For people like me who are extremely unlikely to propose their own consensus change(s) getting some signal on what to spend time digging into would be useful rather than second guessing what people are thinking. There is a danger that you flirt with perceived public roadmaps when possible authority figures stick their necks out and effectively say "I'm not in charge but in an imaginary world where I was this is my current thinking of the ordering in which we could improve this system
> long term. But this could change depending on x, y and z and possible upgrades are only ready when they're ready and they have community consensus." There is no way people don't play these exercises in their minds. I do, I just have very few answers :) I personally think APO is in prime position to improve Lightning channel state management with eltoo and if it enables some covenant schemes too that seems like an added bonus. On APO versus waiting for APO like functionality in Simplicity I have no idea. Work on APO/eltoo and Simplicity both seem to be progressing in parallel so the APO versus Simplicity discussion perhaps rests on whether people think certain covenants should only really be enabled once we have the security guarantees of Simplicity [3] (if at all).
> 
> Antoine's covenant R&D effort [4] seems really promising and I hope the shenanigans from earlier in the year don't put people off from engaging with that. Hopefully we can see more exploration, development and research in covenants (e.g. this excellent research paper "Bitcoin Covenants: Three Ways to Control the Future" [5]) and we can foster a community which has very high standards, is open to new ideas and new research but can avoid these months long resisting chain split fights. I think the discussion would be much more interesting and much more productive if people didn't have to think "If I express a view now it will be used to attack me personally later" or worse "If I express a view now it will be used to justify an upcoming chain split".
> 
> [0]: https://gist.github.com/michaelfolkson/352a503f4f9fc5de89af528d86a1b718
> [1]: https://bitcoin.stackexchange.com/questions/98642/can-we-experiment-on-signet-with-multiple-proposed-soft-forks-whilst-maintaining
> [2]: https://bitcoin.stackexchange.com/questions/109764/what-opcodes-are-supported-on-liquid-but-not-yet-on-bitcoin
> [3]: https://bitcoinops.org/en/topics/simplicity/
> [4]: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-September/020912.html
> [5]: https://arxiv.org/pdf/2006.16714.pdf
> 
> --
> Michael Folkson
> Email: michaelfolkson at protonmail.com
> Keybase: michaelfolkson
> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3
> 
> 
> ------- Original Message -------
> On Saturday, September 17th, 2022 at 09:39, Matt Corallo via bitcoin-dev bitcoin-dev at lists.linuxfoundation.org wrote:
> 
> 
> 
> > On 9/17/22 2:14 AM, Anthony Towns wrote:
> > 
> > > On Fri, Sep 16, 2022 at 12:46:53PM -0400, Matt Corallo via bitcoin-dev wrote:
> > > 
> > > > On 9/16/22 3:15 AM, Anthony Towns via bitcoin-dev wrote:
> > > > 
> > > > > As we've seen from the attempt at a CHECKTEMPLATEVERIFY activation earlier
> > > > > in the year [0], the question of "how to successfully get soft fork
> > > > > ideas from concept to deployment" doesn't really have a good answer today.
> > > > > I strongly disagree with this.
> > > 
> > > Okay? "X is good" is obviously just a statement of opinion, so if you
> > > want to disagree, that's obviously allowed.
> > > 
> > > I also kind of feel like that's the least interesting paragraph in the
> > > entire email to talk further about; if you think the current answer's
> > > already good, then the rest of the mail's just about (hopefully) making
> > > it better, which would be worthwhile anyway?
> > 
> > No, I think its at least a good chunk of the "statement of problem". Yes, more testing is good, and
> > this project is a way to get that. Cool. But implying that lack of test frameworks is in any
> > material way part of the lack of movement on forks in Bitcoin I think is very wrong, so its worth
> > pointing out, whether the particular project is useful or not is separate.
> > 
> > > > Going back many, many years we've had many
> > > > discussions about fork process, and the parts people (historically) agreed
> > > > with tend to be:
> > > > (1) come up with an idea
> > > > (2) socialize the idea in the technical community, see if anyone comes up
> > > > with any major issues or can suggest better ideas which solve the same
> > > > use-cases in cleaner ways
> > > > (3) propose the concrete idea with a more well-defined strawman, socialize
> > > > that, get some kind of rough consensus in the loosely-defined, subjective,
> > > > "technical community" (ie just ask people and adapt to feedback until you
> > > > have found some kind of average of the opinions of people you, the
> > > > fork-champion, think are reasonably well-informed!).
> > > > (4) okay, admittedly beyond this is a bit less defined, but we can deal with it when we get there.
> > > > Turns out, the issue today is a lack of champions following steps 1-3, we
> > > > can debate what the correct answer is to step (4) once we actually have
> > > > people who want to be champions who are willing to (humbly) push an idea
> > > > forward towards rough agreement of the world of technical bitcoiners
> > > > (without which I highly doubt you'd ever see broader-community consensus).
> > > 
> > > Personally, I think this is easily refuted by contradiction.
> > > 
> > > 1) If we did have a good answer for how to progress a soft-fork, then
> > > the great consensus cleanup [0] would have made more progress over the
> > > past 3.5 years
> > 
> > No? Who is the champion for it? I haven't been. No one else is obliged to take up the reins and run
> > with it, that's not how open-source works. And no one has emerged who has strong interest in doing
> > so, and that's totally fine. It means it hasn't made any progress, but that's an indication that no
> > one feels strongly enough about it that its risen to the top of their personal priority list so
> > clearly doesn't need to make progress.
> > 
> > > Maybe not all of the ideas in it were unambiguously good
> > > [1], but personally, I'm convinced at least some of them are, and I
> > > don't think I'm alone in thinking that. Even if the excuse is that its
> > > original champion wasn't humble enough, there's something wrong with
> > > the process if there doesn't exist some other potential champion with
> > > the right balance of humility, confidence, interest and time who could
> > > have taken it over in that timeframe.
> > 
> > No? Its not up to the community to find a champion for someone who wants a fork to happen. Either
> > someone thinks its a good enough idea that they step up, or no one does. If no one does, then so be
> > it. If the original proper (me, in this case) thought it was that important then its their
> > responsibility to be the champion, no one else's.
> > 
> > > 2) Many will argue that CTV has already done steps (1) through (3) above:
> > > certainly there's been an idea, it's been socialised through giving talks,
> > > having discussion forums, having research workshops [2], documenting use
> > > cases use cases; there's been a concrete implementation for years now,
> > > with a test network that supports the proposed feature, and new tools
> > > that demonstrate some of the proposed use cases, and while alternative
> > > approaches have been suggested [3], none of them have even really made
> > > it to step (2), let alone step (3).
> > 
> > I don't really see how you can make this argument seriously. Honestly, if a soft-fork BIP only has
> > one author on the list, then I'm not sure one can argue that step (3) has really been completed, and
> > maybe not even step (2).
> > 
> > > So that leaves a few possibilities
> > > to my mind:
> > 
> > > * CTV should be in step (4), and its lack of definition is a problem,
> > > and trying the "deal with it when we get there" approach is precisely
> > > what didn't work back in April.
> > > 
> > > * The evaluation process is too inconclusive: it should either be
> > > saying "CTV is not good enough, fix these problems", or "CTV hasn't
> > > sufficiently demonstrated its value/cost, work on X next", but it
> > > isn't.
> > > 
> > > * Parts (2) to (3) are too hard, and that's preventing alternatives
> > > from making progress, which in turn is preventing people from
> > > being able to decide whether CTV is the superior approach, or some
> > > alternative is.
> > 
> > I think this is most of it, but its not that they're too hard, its that people are too busy. There
> > seemed to be more positive feedback, for example, to Rusty's proposal, but being the champion for a
> > soft-fork is a full-time job for months on end, and last I checked Rusty has a lightning
> > implementation to maintain, which tends to be a more-than-full-time job already.
> > 
> > To my knowledge, no one but Jeremy has made any serious attempt at being the champion for a
> > soft-fork since Taproot, and before that Segwit (if someone reading this who contributes to Core
> > already wants to, and isn't sure how to, there's lots of people who would happily mentor you! I'm
> > sure you can figure out who to reach out to!).
> > 
> > Matt
> > _______________________________________________
> > bitcoin-dev mailing list
> > bitcoin-dev at lists.linuxfoundation.org
> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> 
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

From michaelfolkson at protonmail.com  Sun Sep 18 18:44:31 2022
From: michaelfolkson at protonmail.com (Michael Folkson)
Date: Sun, 18 Sep 2022 18:44:31 +0000
Subject: [bitcoin-dev] bitcoin-inquistion: evaluating soft forks on
	signet
In-Reply-To: <T4meYqm1urcpCDED6kZjkjDt4hWkmRGKdRNMC2Y6SBHGqNm1t5id4v2GChIlCQwRiy20O9bR2PaT_jCCYEeG4sCkOp77fraTlunN7teZldQ=@protonmail.com>
References: <YyQioS3F942wu1HW@erisian.com.au>
 <798e8c4a-78e2-b210-2202-4b358b95a581@mattcorallo.com>
 <YyVlra0AMIFO9Xid@erisian.com.au>
 <8e4dc33b-2992-0380-de2a-0b8afa3db5b7@mattcorallo.com>
 <8cU3OEEtb7Q8CRBHqeWV6qe4JSRnOeMjh2PRdYj4rsnxF4DxzQd1Bo-1DAPMWGNxjXsZQuSuPrDK5TF4ez6tONZ5ACoLJ_FqV6Y1q7ybSwI=@protonmail.com>
 <T4meYqm1urcpCDED6kZjkjDt4hWkmRGKdRNMC2Y6SBHGqNm1t5id4v2GChIlCQwRiy20O9bR2PaT_jCCYEeG4sCkOp77fraTlunN7teZldQ=@protonmail.com>
Message-ID: <O1zZVzh-olGF235lSIT4Y2C-Q91IACK1qhZbi4jOP5WMYOTD0-Zw9aqHs_1VKBn96h6kTiIRvQS10RkREaKAAQqMz-I58jW6nxr5HjmZlG4=@protonmail.com>

Hi alicexbt

> Good to see some positivity, finally.

I had enthusiasm for this concept of enabling proposed soft fork functionality on signet 2 years ago [0]. Nothing has changed, still enthusiastic :) Not enthusiastic about the months wasted on unnecessary contentious soft fork drama since but can't change the past.

> 1)Nobody uses Liquid. Signet has more activity than Liquid.
  2)Testing something on Liquid will be completely different as its 
  a separate blockchain with some similarities.

Perhaps you should take your own advice with regards to positivity (or at least have more of an open mind) with regards Liquid and sidechains. Signet Bitcoin are totally free [1] and experimentation doesn't ever result in loss of real monetary value so you would expect more experimentation on signet versus Liquid long term. However, building protocols and prototypes with real monetary value is a step up from doing so with worthless signet coins. So I don't really see them as direct competitors. Some things take a lot longer to come to fruition than others but the original vision [2] of sidechains still makes perfect sense to me. Competing sets of consensus rules aren't possible on a single mainnet blockchain. Hence you either go the sidechain(-like) route or you go the altcoin route if you want to take the step up from signet/testnet and start using real monetary value. I much prefer the sidechain model to the altcoin route myself. Especially when in say vaults you do want the equivalent of Bitcoin to be locked up rather than a more volatile altcoin.

Thanks
Michael

[0]: https://bitcoin.stackexchange.com/questions/98642/can-we-experiment-on-signet-with-multiple-proposed-soft-forks-whilst-maintaining
[1]: https://signetfaucet.com/
[2]: https://blockstream.com/sidechains.pdf

--
Michael Folkson
Email: michaelfolkson at protonmail.com
Keybase: michaelfolkson
PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3


------- Original Message -------
On Sunday, September 18th, 2022 at 13:27, alicexbt <alicexbt at protonmail.com> wrote:


> Hi Michael,
> 
> > I agree with Matt. The less said about the "Aw shucks Jeremy didn't know that CTV didn't have community consensus at the time" 0 and "it was the lack of process that was the problem" the better.
> 
> 
> The linked gist cannot be taken seriously and I am not sure why you keep sharing it as some document to prove there was no technical consensus for BIP 119. Nadav has already mentioned this in the comments. If you care about community consensus, maybe feedback about the links in that gist should also be respected. There was chaos, misinformation and lot of drama on twitter. Some people that opposed CTV on twitter still have no clue what CTV actually does and a few were super enthusiastic because of the author for BIP 119.
> 
> > I'm not convinced by the name (bitcoin-inquisition, shedpaint, shedpaint, let's park that for the moment) but I do like the idea of signet having soft fork proposals enabled on it 1 whether that be CTV, APO etc and if that requires more of the signet code to be moved out of the Core repo so be it.
> 
> 
> Good to see some positivity, finally. Because tx introspection aka covenants would help everyone involved in bitcoin. This idea of experimenting with soft forks on signet together with research and meetings suggested by Antoine should help in better evaluation phase with less drama, politics etc. and more technical discussions to reach a goal.
> 
> > I'm surprised more isn't being done on Liquid already with what possible future functionality is (and could be) enabled 2 there but maybe there is more happening than I'm aware of.
> 
> 
> 1)Nobody uses Liquid. Signet has more activity than Liquid.
> 2)Testing something on Liquid will be completely different as its a separate blockchain with some similarities.
> 
> I have summarized a few other positives of testing soft forks on signet based on AJ's email:
> 
> a)Better evaluation
> b)PR implementing soft fork could be reviewed and merged outside core
> c)Testing on signet with pre-existing signet infrastructure
> d)Can deploy multiple consensus changes so easier to compare alternative approaches (eg CTV vs ANYPREVOUT vs OP_TXHASH vs OP_TX, etc)
> e)Pre-baked ability to abandon the soft fork
> f)No need to regularly rebase consensus changes against bitcoin core's master branch
> 
> /dev/fd0
> 
> Sent with Proton Mail secure email.
> 
> ------- Original Message -------
> On Saturday, September 17th, 2022 at 3:53 PM, Michael Folkson via bitcoin-dev bitcoin-dev at lists.linuxfoundation.org wrote:
> 
> 
> 
> > I agree with Matt. The less said about the "Aw shucks Jeremy didn't know that CTV didn't have community consensus at the time" 0 and "it was the lack of process that was the problem" the better. If people don't care about lack of community consensus there is no process in a permissionless, open source community that can stop them or direct them down a more patient, productive path (I tried). I think it is a shame because I think (maybe I'm wrong) at least in the technical community there is an understanding that long term Bitcoin is far from finished in exhausting its potential and we do need people who will work on changes that we'll need in the long term.
> > 
> > There are a few interesting things in here though. I'm not convinced by the name (bitcoin-inquisition, shedpaint, shedpaint, let's park that for the moment) but I do like the idea of signet having soft fork proposals enabled on it 1 whether that be CTV, APO etc and if that requires more of the signet code to be moved out of the Core repo so be it. I'm surprised more isn't being done on Liquid already with what possible future functionality is (and could be) enabled 2 there but maybe there is more happening than I'm aware of. Protocols or use cases built out and demonstrated on signet (and/or Liquid/sidechains) seem an obvious stepping stone to me for convincing the community that it is potentially worth taking the chain split risk for a particular upgrade. It is a long slog to get community consensus on an upgrade (Taproot certainly was a slog) but I think the vast majority of us think Taproot was worth that slog and Bitcoin would be poorer today without it.
> > 
> > The Great Consensus Cleanup is an interesting example in that I get Matt doesn't have time to champion it or focus on it with his LDK commitments but I have no idea where it would rank on his long term priority list if he wasn't working on LDK. Similarly I have no idea what people who understand this evolving system much better than I do are thinking with regards to say adding new opcodes, sighash flags versus say waiting on Simplicity and possibly adding new functionality within that potential upgrade. For people like me who are extremely unlikely to propose their own consensus change(s) getting some signal on what to spend time digging into would be useful rather than second guessing what people are thinking. There is a danger that you flirt with perceived public roadmaps when possible authority figures stick their necks out and effectively say "I'm not in charge but in an imaginary world where I was this is my current thinking of the ordering in which we could improve this system
> > long term. But this could change depending on x, y and z and possible upgrades are only ready when they're ready and they have community consensus." There is no way people don't play these exercises in their minds. I do, I just have very few answers :) I personally think APO is in prime position to improve Lightning channel state management with eltoo and if it enables some covenant schemes too that seems like an added bonus. On APO versus waiting for APO like functionality in Simplicity I have no idea. Work on APO/eltoo and Simplicity both seem to be progressing in parallel so the APO versus Simplicity discussion perhaps rests on whether people think certain covenants should only really be enabled once we have the security guarantees of Simplicity 3 (if at all).
> > 
> > Antoine's covenant R&D effort 4 seems really promising and I hope the shenanigans from earlier in the year don't put people off from engaging with that. Hopefully we can see more exploration, development and research in covenants (e.g. this excellent research paper "Bitcoin Covenants: Three Ways to Control the Future" 5) and we can foster a community which has very high standards, is open to new ideas and new research but can avoid these months long resisting chain split fights. I think the discussion would be much more interesting and much more productive if people didn't have to think "If I express a view now it will be used to attack me personally later" or worse "If I express a view now it will be used to justify an upcoming chain split".
> > 
> > --
> > Michael Folkson
> > Email: michaelfolkson at protonmail.com
> > Keybase: michaelfolkson
> > PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3
> > 
> > ------- Original Message -------
> > On Saturday, September 17th, 2022 at 09:39, Matt Corallo via bitcoin-dev bitcoin-dev at lists.linuxfoundation.org wrote:
> > 
> > > On 9/17/22 2:14 AM, Anthony Towns wrote:
> > > 
> > > > On Fri, Sep 16, 2022 at 12:46:53PM -0400, Matt Corallo via bitcoin-dev wrote:
> > > > 
> > > > > On 9/16/22 3:15 AM, Anthony Towns via bitcoin-dev wrote:
> > > > > 
> > > > > > As we've seen from the attempt at a CHECKTEMPLATEVERIFY activation earlier
> > > > > > in the year 0, the question of "how to successfully get soft fork
> > > > > > ideas from concept to deployment" doesn't really have a good answer today.
> > > > > > I strongly disagree with this.
> > > > 
> > > > Okay? "X is good" is obviously just a statement of opinion, so if you
> > > > want to disagree, that's obviously allowed.
> > > > 
> > > > I also kind of feel like that's the least interesting paragraph in the
> > > > entire email to talk further about; if you think the current answer's
> > > > already good, then the rest of the mail's just about (hopefully) making
> > > > it better, which would be worthwhile anyway?
> > > 
> > > No, I think its at least a good chunk of the "statement of problem". Yes, more testing is good, and
> > > this project is a way to get that. Cool. But implying that lack of test frameworks is in any
> > > material way part of the lack of movement on forks in Bitcoin I think is very wrong, so its worth
> > > pointing out, whether the particular project is useful or not is separate.
> > > 
> > > > > Going back many, many years we've had many
> > > > > discussions about fork process, and the parts people (historically) agreed
> > > > > with tend to be:
> > > > > (1) come up with an idea
> > > > > (2) socialize the idea in the technical community, see if anyone comes up
> > > > > with any major issues or can suggest better ideas which solve the same
> > > > > use-cases in cleaner ways
> > > > > (3) propose the concrete idea with a more well-defined strawman, socialize
> > > > > that, get some kind of rough consensus in the loosely-defined, subjective,
> > > > > "technical community" (ie just ask people and adapt to feedback until you
> > > > > have found some kind of average of the opinions of people you, the
> > > > > fork-champion, think are reasonably well-informed!).
> > > > > (4) okay, admittedly beyond this is a bit less defined, but we can deal with it when we get there.
> > > > > Turns out, the issue today is a lack of champions following steps 1-3, we
> > > > > can debate what the correct answer is to step (4) once we actually have
> > > > > people who want to be champions who are willing to (humbly) push an idea
> > > > > forward towards rough agreement of the world of technical bitcoiners
> > > > > (without which I highly doubt you'd ever see broader-community consensus).
> > > > 
> > > > Personally, I think this is easily refuted by contradiction.
> > > > 
> > > > 1) If we did have a good answer for how to progress a soft-fork, then
> > > > the great consensus cleanup 0 would have made more progress over the
> > > > past 3.5 years
> > > 
> > > No? Who is the champion for it? I haven't been. No one else is obliged to take up the reins and run
> > > with it, that's not how open-source works. And no one has emerged who has strong interest in doing
> > > so, and that's totally fine. It means it hasn't made any progress, but that's an indication that no
> > > one feels strongly enough about it that its risen to the top of their personal priority list so
> > > clearly doesn't need to make progress.
> > > 
> > > > Maybe not all of the ideas in it were unambiguously good
> > > > 1, but personally, I'm convinced at least some of them are, and I
> > > > don't think I'm alone in thinking that. Even if the excuse is that its
> > > > original champion wasn't humble enough, there's something wrong with
> > > > the process if there doesn't exist some other potential champion with
> > > > the right balance of humility, confidence, interest and time who could
> > > > have taken it over in that timeframe.
> > > 
> > > No? Its not up to the community to find a champion for someone who wants a fork to happen. Either
> > > someone thinks its a good enough idea that they step up, or no one does. If no one does, then so be
> > > it. If the original proper (me, in this case) thought it was that important then its their
> > > responsibility to be the champion, no one else's.
> > > 
> > > > 2) Many will argue that CTV has already done steps (1) through (3) above:
> > > > certainly there's been an idea, it's been socialised through giving talks,
> > > > having discussion forums, having research workshops 2, documenting use
> > > > cases use cases; there's been a concrete implementation for years now,
> > > > with a test network that supports the proposed feature, and new tools
> > > > that demonstrate some of the proposed use cases, and while alternative
> > > > approaches have been suggested 3, none of them have even really made
> > > > it to step (2), let alone step (3).
> > > 
> > > I don't really see how you can make this argument seriously. Honestly, if a soft-fork BIP only has
> > > one author on the list, then I'm not sure one can argue that step (3) has really been completed, and
> > > maybe not even step (2).
> > > 
> > > > So that leaves a few possibilities
> > > > to my mind:
> > > 
> > > > * CTV should be in step (4), and its lack of definition is a problem,
> > > > and trying the "deal with it when we get there" approach is precisely
> > > > what didn't work back in April.
> > > > 
> > > > * The evaluation process is too inconclusive: it should either be
> > > > saying "CTV is not good enough, fix these problems", or "CTV hasn't
> > > > sufficiently demonstrated its value/cost, work on X next", but it
> > > > isn't.
> > > > 
> > > > * Parts (2) to (3) are too hard, and that's preventing alternatives
> > > > from making progress, which in turn is preventing people from
> > > > being able to decide whether CTV is the superior approach, or some
> > > > alternative is.
> > > 
> > > I think this is most of it, but its not that they're too hard, its that people are too busy. There
> > > seemed to be more positive feedback, for example, to Rusty's proposal, but being the champion for a
> > > soft-fork is a full-time job for months on end, and last I checked Rusty has a lightning
> > > implementation to maintain, which tends to be a more-than-full-time job already.
> > > 
> > > To my knowledge, no one but Jeremy has made any serious attempt at being the champion for a
> > > soft-fork since Taproot, and before that Segwit (if someone reading this who contributes to Core
> > > already wants to, and isn't sure how to, there's lots of people who would happily mentor you! I'm
> > > sure you can figure out who to reach out to!).
> > > 
> > > Matt
> > > _______________________________________________
> > > bitcoin-dev mailing list
> > > bitcoin-dev at lists.linuxfoundation.org
> > > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> > 
> > _______________________________________________
> > bitcoin-dev mailing list
> > bitcoin-dev at lists.linuxfoundation.org
> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

From antoine.riard at gmail.com  Sun Sep 18 18:47:38 2022
From: antoine.riard at gmail.com (Antoine Riard)
Date: Sun, 18 Sep 2022 14:47:38 -0400
Subject: [bitcoin-dev] bitcoin-inquistion: evaluating soft forks on
	signet
In-Reply-To: <YyQioS3F942wu1HW@erisian.com.au>
References: <YyQioS3F942wu1HW@erisian.com.au>
Message-ID: <CALZpt+HksJ8BFi-8jvKJQLskSiLnm5f-QR_zmFrsgLX19R630Q@mail.gmail.com>

Hi AJ,

Thanks to setup a new laboratory for consensus upgrades experiment! Idea
was exposed during the last LN Summit, glad to see there is a useful fork
now.

While I think one of the problem particular in the current stagnation about
consensus upgrades has been well scoped by your proposal, namely on
formalizing the thorough analysis process to which an upgrade proposal
should be subject too, there are more issues or bounds to wonder on, at
least from my perspective.

Laying out fine-grained stages of the development process (research,
development, evaluation, deployment) sounds compelling to bring clarity to
everyone. However, I doubt it captures well the more realistic, chaotic
process from which new Bitcoin ideas and techniques are emerging. In
practice, consensus upgrades, akin to the sustenance of new scientific
theories or engineering principles in the wider creative areas of life, are
following an uncertain path of hazardous steps: seminal half-baked
intuitions, whiteboard modeling, code or quantitative experiments, loose
set of ideas pollination, peers feedbacks integration, etc before to mature
in some solidified proposals.

Said succinctly, in the genesis of creative ideas, evaluation doesn't
happen at a single clear point but all along the idea lifetime, where this
evaluation is as much done by the original author than its peers and a
wider audience. Sometimes really formally, e.g in academics with PhD thesis
defense. For Bitcoin, rather than to "declare" on the when and where
upgrades evaluation should happen once for all, I think a more open
evaluation process we can carry on is gathering and maintaining the factual
material and reasoning frameworks around solidified proposals, on which
each community stakeholder individually can assign a grounded judgement.
Those judgments are likely sources of new refinement of the upgrades
themselves.

Under that perspective, I believe a functional upgrades experimentation
platform as proposed by bitcoin-inquisition is very valuable, as it should
allow upgrades "champions" (CTV, ANYPREVOUT, TLUV, "fraud proofs" ops
primitives, etc) to loop faster in the R&D cycles, raise earlier awareness
on their work existence and as it's all open to assemble team around their
proposals. (Effectively, covenants upgrades and their associated use-cases
offered so much complexity that it's becoming less and less a one-man
job...).

I would still expose a concern to not downgrade in the pure empiricism in
matter of consensus upgrades. I.e, slowly emerging the norm of a working
prototype running on bitcoin-inquisition` as a determining factor of the
soundness of a proposal. E.g with "upgrading lightning to support eltoo", a
running e2e won't save us to think the thousands variants of pinnings, the
game-theory soundness of a eltoo as mechanism in face of congestions, the
evolvability of APO with more known upgrades proposals or the
implementation complexity of a fully fleshed-out state machine and more
questions.

That said, a e2e implementation, partial or complete, would at least make
the serious analysis process easier. Moreover, the benefit of having e2e
implems runnable by everyone on bitcoin-inquisition would likely lower the
bar to have independent consensus upgrade analysis, likely a source of new
relevant feedback.

I can only share the sentiment expressed that this alternative open
approach of consensus changes avoids the gradual establishment of a trusted
group, even informal. In the past, to the best of my knowledge, most of the
substance of the Taproot softfork daily development happened on
semi-offline communication channels and the strong design rational
decisions at CoreDev editions. While not discrediting the high-quality
feedback than one can gather during those types of in-person engineering
meetings, for neutrality and openness of the Bitcoin upgrades process it
could be great to only consider them as source of feedbacks and move
progressively the crux of the upgrades R&D process online, open to anyone
interested. Moreover, it would bind more adequately the reality of a
growing development ecosystem, where we have to deal with an increasing
diversity of technical, social and geographical community stakeholders. I
acknowledge there is a hard challenge to maintain high-signal, low-noise
online communication channels and spaces about context-rich issues like
upgrades, however that might be the type of challenge we have to solve if
we care about everyone using Bitcoin to truly be peers. At least my 2 sats.

About the risk of latent centralization of global default signets
miners/bitcoin-inquisition maintainers, I don't think I'm worried about it.
With time, I would guess we might have multiple experimental signets with
different series of patches, as some patches might invalidate the
observations of another upgrade. E,g if one implements the "weird" ideas
about changes in the block reward issuance schedule discussed during the
summer, another one might not want "noise" interferences with new
fee-bumping primitives as the miner incentives are modified. About the
bitcoin-inquisition fork maintainers themselves becoming gatekeepers of
consensus upgrades changes, best we can do is maintain high-quality
documentation and knowledge base to lower the forking cost of the platform
for any community stakeholder.

Anyway, I hold the belief that the more initiatives we see to modernize the
"consensus-upgrades" production factory in order to scale with the current
dimensions of the Bitcoin ecosystem, better we're. I hope the upcoming
Contracting Primitives WG will be able to document and discuss some of the
relevant experiments run on bitcoin-inquisition. Time and work will tell
how they fit all together, where they complement each other and synergies
that are nurtured.

Speaking for myself, looking forward to experimenting with CoinPool code
components on bitcoin-inquistion in the future!

Best,
Antoine

Le ven. 16 sept. 2022 ? 03:16, Anthony Towns via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> a ?crit :

> Subhead: "Nobody expects a Bitcoin Inquistion? C'mon man, *everyone*
> expects a Bitcoin Inquisition."
>
> As we've seen from the attempt at a CHECKTEMPLATEVERIFY activation earlier
> in the year [0], the question of "how to successfully get soft fork
> ideas from concept to deployment" doesn't really have a good answer today.
>
> Obviously, a centralised solution to this problem exists: we could
> establish a trusted group, perhaps one containing devs, industry
> representatives, investors, etc, have them review proposals and their
> implementations, and follow their lead when they decide that a proposal
> has met their standards and should be widely deployed. Some might even
> say "sipa is precisely that group". The problem with having a group of
> that nature isn't one of effectiveness, but rather that they are then
> vulnerable to pressure and corruption, which isn't desirable if we want
> everyone using Bitcoin to truly be peers, and often isn't desirable for
> the prospective members of the group either. So that's not something we
> should want people to volunteer for, nor is it a duty we should thrust
> on people. Or at least, that's my opinion, anyway.
>
> I think any alternative approach to doing consensus changes (while
> avoiding a chain split) has to look something like this:
>
>  * propose an idea (research phase)
>  * implement the idea (development phase)
>  * demonstrate the idea is worthwhile (evaluation phase)
>  * once everyone is convinced, activate (deployment phase)
>
> Without an evaluation phase that is thorough enough to convince (almost)
> everyone, I think deployment becomes controversial and perhaps effectively
> impossible (at least without some trusted leadership group). But with an
> evaluation phase that demonstrates to everyone who's interested that the
> proposal has actual value, minimal cost and no risk, I think activation
> could be fairly easy and straightforward.
>
> I contend that the most significant problem we have is in the "evaluation
> phase". How do you convince enough people that a change is sufficiently
> beneficial to justify the risk of messing with their money? If you're
> only trying to convince a few experts, then perhaps you can do that with
> papers and talks; but limiting the evaluation to only a few experts is
> effectively just falling back to the centralised approach.
>
> So I think that means that part of the "evaluation phase" should involve
> implementing real systems on top of the proposed change, so that you
> can demonstrate real value from the change. It's easy to say that
> "CTV can enable vaults" or "CTV can make opening a lightning channel
> non-interactive" -- but it's harder to go from saying something
> is possible to actually making it happen, so, at least to me, it
> seems reasonable to be skeptical of people claiming benefits without
> demonstrating they're achievable in practice.
>
> I contend the easiest way we could make it easy to demonstrate a soft
> fork working as designed is to deploy it on the default global signet,
> essentially as soon as it has a fully specified proposal and a reasonably
> high-quality implementation.
>
> The problem with that idea is that creates a conundrum: you can't activate
> a soft fork on the default signet without first merging the code into
> bitcoin core, you can't merge the code into bitcoin core until it's been
> fully evaluated, and the way you evaluate it is by activating it on the
> default signet?
>
> I think the weakest link in that loop is the first one: what if we did
> activate soft forks on the default signet prior to the code being merged
> into core? To that end, I'm proposing a fork of core that I'm calling
> "bitcoin-inquisition", with the idea that it branches from stable
> releases of core and adds support for proposed changes to consensus
> (CTV, ANYPREVOUT, TLUV, OP_CAT, etc...) and potentially also relay
> policy (relay changes are often implied by consensus changes, but also
> potentially things like package relay).
>
>   https://github.com/bitcoin-inquisition/bitcoin/wiki
>   https://github.com/bitcoin-inquisition/bitcoin/pulls
>
> The idea being that if you're trying to work on "upgrading lightning
> to support eltoo", you can iterate through changes needed to consensus
> (via bitcoin-inquisition) and client apps (cln, lnd, eclair etc), while
> testing them in public (on signet) and having any/all the pre-existing
> signet infrastructure available (faucets, explorers etc) without having
> to redeploy it yourself. Having multiple consensus changes deployed in
> one place also seems like it might make it easier to compare alternative
> approaches (eg CTV vs ANYPREVOUT vs OP_TXHASH vs OP_TX, etc).
>
> So that's the concept. For practical purposes, I haven't yet merged
> either CTV or APO support into the bitcoin-inquisition 23.0 branch yet,
> and before actually mining blocks I want to make the signet miner able
> to automatically detect/recover if the bitcoin-inquisition node either
> crashes or starts producing incompatible blocks.
>
> Anyway, I wanted to post the idea publicly, both to give folks an
> opportunity to poke holes in the idea, or to suggest any further
> improvements or otherwise do any review before the CTV and APO patches
> get merged.
>
> Some other details that may be of interest.
>
> The biggest challenge with soft forks and the idea of "iterating
> through changes" is that making improvements can create a hard fork,
> which then forces everyone running old software to update, which can be
> pretty inconvenient, especially if you don't actually care about that
> change. Since signet (and regtest) mining is effectively permissioned,
> we can avoid that problem by having all these proposed soft forks
> come with a pre-baked ability to abandon the soft fork (much as David
> Harding described in [1]). Once a soft fork is abandoned, it can either
> be ignored forever (and later versions of the software can not include
> the code to enforce it at all), or it can be replaced by a new version
> of the soft fork.
>
> Another benefit that comes from signet chains being permissioned is
> that miners can be expected to coordinate upgrading out of band, so
> there is no need for a 90% signalling threshold. Instead, activation
> (and abandonment) of a soft fork can be triggered by a single block
> signalling. That further means there is no need for any individual
> block to signal for multiple forks, and instead of having 29 different
> signals, we can instead easily have up to 2**29. I've chosen to make
> the standard signal have 16 bits for specifying a bip number (0-65535)
> and 8 bits for specifying a version of that bip, which seems like it
> should be more than enough at least for a while. More details at [2].
>
> I'm basing bitcoin-inquisition solely off stable releases. This is partly
> because it can be annoying to constantly rebase consensus changes aginst
> bitcoin core's master branch, but also I think it might help consensus
> changes be easily backported once they pass the "evaluation phase"
> and move into the "deployment phase".
>
> I'm not sure what level of code quality PRs should have before being
> merged into bitcoin-inquisition. I think CTV is plenty good enough,
> but I'm not sure about APO, particularly its test coverage. If you want
> to influence what becomes the tradition here, contributing a review,
> or posting patches against the upsteam branch might be a good start?
>
> Does this make the global default signet miners, or perhaps the
> bitcoin-inquisition maintainers the "trusted group" that we want to
> avoid? Hopefully not -- anyone can run their own fork or do their own
> fork of bitcoin core, so if the miners/maintainers start trying to
> arbitrarily block proposals they can be worked around without too much
> hassle. And since they're clearly separate from any of the actions that
> need to be taken for actual deployment once activation is complete,
> they shouldn't have any ability to unduly promote fork proposals that
> people aren't fully satisfied are ready for deployment.
>
> Cheers,
> aj
>
> [0]
> https://bitcoinops.org/en/newsletters/2022/04/27/#discussion-about-activating-ctv
>
> [1]
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-April/020242.html
>
> [2]
> https://github.com/bitcoin-inquisition/bitcoin/wiki/Heretical-Deployments
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220918/e58b78ad/attachment-0001.html>

From aj at erisian.com.au  Mon Sep 19 10:05:47 2022
From: aj at erisian.com.au (Anthony Towns)
Date: Mon, 19 Sep 2022 20:05:47 +1000
Subject: [bitcoin-dev] bitcoin-inquistion: evaluating soft forks on
	signet
In-Reply-To: <CALZpt+HksJ8BFi-8jvKJQLskSiLnm5f-QR_zmFrsgLX19R630Q@mail.gmail.com>
References: <YyQioS3F942wu1HW@erisian.com.au>
 <CALZpt+HksJ8BFi-8jvKJQLskSiLnm5f-QR_zmFrsgLX19R630Q@mail.gmail.com>
Message-ID: <Yyg++7tqBC9WGOzc@erisian.com.au>

On Sun, Sep 18, 2022 at 02:47:38PM -0400, Antoine Riard via bitcoin-dev wrote:
> Said succinctly, in the genesis of creative ideas, evaluation doesn't
> happen at a single clear point but all along the idea lifetime, where this
> evaluation is as much done by the original author than its peers and a
> wider audience.

Sure. I definitely didn't mean to imply a waterfall development model,
or that the phases wouldn't overlap etc.

> I would still expose a concern to not downgrade in the pure empiricism in
> matter of consensus upgrades. I.e, slowly emerging the norm of a working
> prototype running on bitcoin-inquisition` as a determining factor of the
> soundness of a proposal. E.g with "upgrading lightning to support eltoo", a
> running e2e won't save us to think the thousands variants of pinnings, the
> game-theory soundness of a eltoo as mechanism in face of congestions, the
> evolvability of APO with more known upgrades proposals or the
> implementation complexity of a fully fleshed-out state machine and more
> questions.

I agree here; but I think not doing prototypes also hinders thinking
about all the thousands of details in a fork. It's easy to handwave
details away when describing things on a whiteboard; and only realise
they're trickier than you thought when you go to implement things.

> E,g if one implements the "weird" ideas
> about changes in the block reward issuance schedule discussed during the
> summer, another one might not want "noise" interferences with new
> fee-bumping primitives as the miner incentives are modified. 

(I don't think "miner incentives" are really something that can be
investigated on signet. You can assume how miners will respond to
incentives and program the mining software to act that way; but there's
no competitive pressure in signet mining so I don't think that really
demonstrates anything very much. Likewise, there's much less demand for
blockspace on signet than on mainnet, so it's probably hard to experiment
with "fee incentives" too)

> I hope the upcoming
> Contracting Primitives WG will be able to document and discuss some of the
> relevant experiments run on bitcoin-inquisition. 

Likewise.

(Lots trimmed due to either agreeing with it or having nothing to add)

Cheers,
aj


From antoine.riard at gmail.com  Mon Sep 19 01:22:43 2022
From: antoine.riard at gmail.com (Antoine Riard)
Date: Sun, 18 Sep 2022 21:22:43 -0400
Subject: [bitcoin-dev] More uses for CTV
In-Reply-To: <CAPfvXfLvYbKWSWatkunwdcOYN_YTCayr=B_Rm90R+1nUW_zFCg@mail.gmail.com>
References: <CAPfvXfLvYbKWSWatkunwdcOYN_YTCayr=B_Rm90R+1nUW_zFCg@mail.gmail.com>
Message-ID: <CALZpt+Gn0rSOBOkMsLyjbapJCU1NmzRn=aZ4ktS4iCKmFbzU2w@mail.gmail.com>

Hi James,

Thanks to bringing to awareness the atomic mining pool thing, it's
interesting.

> I'm not a mining expert and so I can't speak to the efficacy of the
> paper as a whole, but direct-from-coinbase payouts seem like a
> desirable feature which avoids some trust in pools. One limitation is
> the size of the coinbase outputs owed to constituent miners; this
> limits the number of participants in the pool.

I'm neither a mining expert, but I wonder if there is not some weird
dependency here. The coinbase output scriptpubkey being part of the
header's merkle root commitment, the CTV hash being part of the
scriptpubkey and the payout outputs being part of the CTV hash, everytime
the payout outputs as re-evaluated in function of the last work share
submitted, as Laurentia is proposing, the whole payout transaction must be
updated, then the CTV hash, then the merkle root commitment, leading all
the mining devices to re-fetch a header from the job negotiator (in Stratum
V2 parlance), I think ? I don't know the average shares submission
frequency for a local pool of size 100 as targeted by Laurentia though the
latency hit might downgrade the worthiness of this CTV-based atomic mining
pool payouts design...

Beyond, I'm not sure about the trust removal statement of this design, as
the job negotiator operator, sounds to always have malleability to select
the coinbase output scriptpubkey, therefore selecting any CTV hash
assigning all the reward to itself, at the detriment of other mining pool
participant. I believe this is not a downside of CTV usage itself, but the
fact that the coinbase output scriptpubkey is ultimately signed by the
proof-of-work itself.

About compactness, I wonder if an atomic payment pool payouts design
favoring the payouts settlement directly over Lightning channels wouldn't
offer a smaller on-chain footprint. E.g, maybe the mining pool operator
could send a long-term PTLC to each participant covering the period during
which a block has odds to be mined by the pool. The PTLCs amounts should be
stable once the block template is agreed on. The coinbase output is locked
with some scriptless script point. When it is spent by the mining operator,
the PTLCs could be fetched by the participant. If the mining operator
doesn't spend before time lock expiration, there could be some on-chain
fan-out transaction kicking-out. That type of scheme would allow you to
save on-chain fees and not to leak the mining pool hashrate distribution.
However, I believe it is more complex to make it fit with the SPLNS
"real-time"  calculation as it sounds to be proposed by the paper. Just a
strawman proposal, if relevant, deserves more thinking.

The paper would deserve to have a fully fleshed-out "coinbase generation"
scheme as the description is a bit loose, imo, like:

"Block solve reward is distributed directly from the block to each user,
meaning each user gets
a 'mined' transaction directly into their wallet as soon as the block is
solved so there is no wait
to get paid and no pool wallet storing user's rewards"

Anyway, left a scratch of further scheme analysis there:
https://github.com/ariard/bitcoin-contracting-primitives-wg/pull/8

Best,
Antoine

Le ven. 19 ao?t 2022 ? 12:33, James O'Beirne via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> a ?crit :

> Over the past few months there have been a few potential uses of
> OP_CHECKTEMPLATEVERIFY (BIP-119)
> (https://github.com/bitcoin/bitcoin/pull/21702) that I've found
> interesting.
>
> # Congestion control redux
>
> When I first heard of CTV, a presentation Jeremy did at Chaincode back
> in 2018 or '19, he cited congestion control as one of its main use
> cases.
>
> The pitch went something like
>
> > When there is a high demand for blockspace it becomes very expensive
> > to make transactions. By using OP_CHECKTEMPLATEVERIFY, a large volume
> > payment processor may aggregate all their payments into a single O(1)
> > transaction for purposes of confirmation. Then, some time later, the
> > payments can be expanded out of that UTXO when the demand for
> > blockspace is decreased.
>
> (from https://utxos.org/uses/scaling/)
>
> At the time that didn't particularly grab me; the idea of smoothing fee
> rates seemed nice but marginal.
>
> But recently, two particular cases have made me reassess the value of
> congestion control.
>
> The first stems from the necessity of L2 protocols (payment channels,
> vaults, etc.) to, under certain circumstances, settle to the chain in a
> timely way in order to prevent abuse of the protocol. If some
> unexpected condition (a protocol exploit, large network disconnect, en
> masse vault breach, etc.) creates a situation where a large number of
> contracts need to settle to the chain in short order, mempools could
> fill up and protocol failures could happen for want of mempool/block
> space
> (
> https://github.com/jamesob/mempool.work#failure-one-mempool-to-rule-them-all
> ).
>
> In such a case, CTV could be used effectively to "compress" settlement
> commitments, get them on-chain, and then facilitate later unpacking of
> the CTV ouputs into the contract's true end state.
>
> This amounts to `n` contract-control outputs (e.g. a lightning funding
> transaction outputs) being spent into a single CTV output, which
> commits to the final settlement state. Multiple parties could
> trustlessly collaborate to settle into a single CTV output using
> SIGHASH_ALL | ANYONECANPAY. This requires a level of interaction
> similar to coinjoins.
>
> Put simply, CTV allows deferring the chainspace required for the final
> settlement outputs, but still immediately requires space for the
> inputs. This might sound like a temporary reprieve from half-ish of the
> space required to settle, but in many (most?) cases the outputs require
> substantially more space than the inputs, given that often we're
> settling a single UTXO into multiple payouts per party. A 2, 3, or
> 4-fold increase (depending on the contracting pattern) in capacity
> isn't a silver bullet, but it could ameliorate the damage of unexpected
> settlement "tidal waves."
>
> Conceptually, CTV is the most parsimonious way to do such a scheme,
> since you can't really get smaller than a SHA256 commitment, and that's
> essentially all CTV is.
>
> The second congestion control case is related to a recent post Bram
> made about stability under a no-block-subsidy regime. He posted
>
> > If transaction fees came in at an even rate over time all at the
> > exact same level then they work fine for security, acting similarly
> > to fixed block rewards. Unfortunately that isn't how it works in the
> > real world. There's a very well established day/night cycle with fees
> > going to zero overnight and even longer gaps on weekends and
> > holidays. If in the future Bitcoin is entirely dependent on fees for
> > security (scheduled very strongly) and this pattern keeps up
> > (overwhelmingly likely) then this is going to become a serious
> > problem.
>
> (from
>
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-July/020702.html
> )
>
> Ryan Grant points out that CTV's congestion control use could help to
> smooth fees, creating a less spiky incentive to mine
> (
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-July/020702.html
> ).
>
> Admittedly the original concern is speculative and a ways off from now,
> as others in the thread pointed out. But having CTV-based fee smoothing
> as an option certainly doesn't seem like a bad thing.
>
>
> # Atomic mining pool payouts
>
> Laurentia is a mining pool design that pays participants out directly
> from the coinbase of found blocks.
>
> > Block solve reward is distributed directly from the block to each
> > user, meaning each user gets a 'mined' transaction directly into
> > their wallet as soon as the block is solved so there is no wait to
> > get paid and no pool wallet storing user's rewards.
>
> (from
>
> https://laurentiapool.org/wp-content/uploads/2020/05/laurentiapool_whitepaper.pdf
> )
>
> I'm not a mining expert and so I can't speak to the efficacy of the
> paper as a whole, but direct-from-coinbase payouts seem like a
> desirable feature which avoids some trust in pools. One limitation is
> the size of the coinbase outputs owed to constituent miners; this
> limits the number of participants in the pool.
>
> If the payout was instead a single OP_CTV output, an arbitrary number
> of pool participants could be paid out "atomically" within a single
> coinbase.
>
> ---
>
> CTV both in concept and implementation is very simple, and I think it
> is likely to continue to yield potential applications.
> "Settlement compression" seems like a useful thing, especially in light
> of a possible increase in L2 usage, and CTV seems like the simplest
> means to enable it.
>
> Interestingly, an analogue for this pattern going the other direction
> is possible, e.g. non-interactive channel openings
> (https://utxos.org/uses/non-interactive-channels/), which would allow
> e.g. opening a lightning channel with a merchant who doesn't want to
> have their spending keys constantly accessible from a point-of-sale,
> but can still parse/verify CTV commitments.
>
> Regards,
> James
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220918/abfc9232/attachment.html>

From ZmnSCPxj at protonmail.com  Mon Sep 19 22:43:44 2022
From: ZmnSCPxj at protonmail.com (ZmnSCPxj)
Date: Mon, 19 Sep 2022 22:43:44 +0000
Subject: [bitcoin-dev] Spookchains: Drivechain Analog with One-Time
	Trusted Setup & APO
In-Reply-To: <CAD5xwhgKGMx79+RLpb-hjd3Gc=EKxTVzkpME-=KuM_C5+d7mRQ@mail.gmail.com>
References: <CAD5xwhgKGMx79+RLpb-hjd3Gc=EKxTVzkpME-=KuM_C5+d7mRQ@mail.gmail.com>
Message-ID: <iy7h2Ef6lbbHkutZVhZQZgPo9FPKIsGWJwAiO1CnSdj6ljY884qlURJDP3ifnPHxK169_FY1Vi48-3kvuNO-Ekt6gz4uNQv66BE4mUDuWOY=@protonmail.com>

Good morning Jeremy,

Excellent work!



> # Terminal States / Thresholds
> 
> When a counter reaches the Nth state, it represents a certain amount
> of accumulated work over a period where progress was agreed on for
> some outcome.
> 
> There should be some viable state transition at this point.
> 
> One solution would be to have the money at this point sent to an
> `OP_TRUE` output, which the miner incrementing that state is
> responsible for following the rules of the spookchain.

This is not quite Drivechain, as Drivechains precommit to the final state transition when the counter reaches threshold and mainchain-level rules prevent the miner who does the final increment from "swerving the car" to a different output, whereas use of `OP_TRUE` would not prevent this; the Spookchain could vote for one transition, and then the lucky last miner can output a different one, and only other miners interested in the sidechain would reject them (whereas in the Drivechain case, even nodes that do not care about the sidechain would reject).

Still, it does come awfully close, and the "ultimate threat" ("nuclear option") in Drivechains is always that everyone upgrades sidechain rules to mainchain rules, which would still work for Spookchains.
Not sure how comfortable Drivechain proponents would be with this, though.

(But given the demonstrated difficulty in getting consensus changes for the blockchain, I wonder if this nuclear option is even a viable threat)

> Or, it could be
> specified to be some administrator key / federation for convenience,
> with a N block timeout that degrades it to fewer signers (eventually
> 0) if the federation is dead to allow recovery.

Seems similar to the Blockstream separation of the block-signing functionaries from the money-keeping functionaries.

Regards,
ZmnSCPxj

From hugo at nunchuk.io  Wed Sep 21 06:07:12 2022
From: hugo at nunchuk.io (Hugo Nguyen)
Date: Tue, 20 Sep 2022 23:07:12 -0700
Subject: [bitcoin-dev] BIP Proposal: Wallet Labels Export Format
In-Reply-To: <CAPR5oBPER9-WHdpzJ3MW2hjPJxj3ZuEouFUsu89Lb=8m5h2t-w@mail.gmail.com>
References: <mailman.9.1661342403.3868.bitcoin-dev@lists.linuxfoundation.org>
 <20220824190958.gklg3riadci3ttgm@artanis>
 <CAPR5oBPER9-WHdpzJ3MW2hjPJxj3ZuEouFUsu89Lb=8m5h2t-w@mail.gmail.com>
Message-ID: <CAPKmR9tmNLZumQHuJ58kgu1F8V-dcdACNBZenxZnpMV0TeCYyg@mail.gmail.com>

Hello Craig,
Thank you for putting this proposal together. It is indeed another big
missing piece of the puzzle.

I would like to echo some of the comments already made by others (and you
yourself) on this thread, that this proposal seems to have some inherent
conflicts between the 2 goals it tries to achieve.

> *Allowing users to import and export their labels in a standardized way
ensures that they do not experience lock-in to a particular wallet
application. As a secondary goal, by using common formats this BIP seeks to
make manual or bulk management of labels accessible to users outside of
wallet applications and without specific technical expertise.*

IMHO, the reason these conflicts exist is because the first one is an
engineering requirement, while the second one is a UX / product requirement.

Engineering requirements typically prioritize data integrity,
reliability/robustness and performance. Do we want some sort of error
detection / correction codes? What data format would be the most robust and
least error-prone? Is CSV a good fit or not for this purpose? etc.

UX requirements, on the other hand, typically prioritize convenience and
ease of use.

When we don?t separate these concerns it can backfire and we might end up
with a Frankenstein standard that is the worst of both worlds. That is: not
quite robust in engineering terms, but also not quite user-friendly in
product terms either.

SLIP-132 is one such example. It tries to solve what are inherently
engineering challenges ? how to manage the complexities that arose due to
the evolution of keys and scripts ? by sadly offloading those complexities
onto the end users. The end result is user confusion (what kind of [?]PUB
do I need here?) and a nightmare for engineers to maintain (the
complexities are better managed via a high level language such as Output
Descriptors).

Keeping in this mind, I also think having 2 separate BIPs for this is
better.

Cheers,
Hugo




On Mon, Aug 29, 2022 at 4:26 AM Craig Raw via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Thanks for your feedback @Ali.
>
> I am attempting to achieve two goals with this proposal, primarily for the
> benefit of wallet users:
>
> Goal #1. Transfer labels between different wallet implementations
> Goal #2. Manage labels in applications outside of Bitcoin wallets (such as
> Excel)
>
> Much of the feedback so far has indicated the tension between these two
> goals - it may be that it is too difficult to achieve both, in which case
> Goal #1 is the most important. That said, I think further exploration is
> still necessary before abandoning Goal #2, because removing it would
> significantly reduce the value of this proposal and mean users need to rely
> on application-specific workarounds.
>
> > it is important that a version byte is defined
> If Goal #2 is to be achieved it's difficult to mandate this, particularly
> if one requires bit flags to be set. Should an importing wallet fail to
> import if the version byte is not present, even if all the data is
> otherwise correct? Although it is difficult to know in advance how a format
> may be extended, it is certainly possible to extend this format with
> additional types where the nature of hashes serve as unique identifiers
> (more on this below).
>
>  > Don't mandate the file extension... There is no way to enforce this on
> a BIP level.
> I'm not quite sure what you mean here - for example BIP174, which is
> widely used, states "Binary PSBT files should use the .psbt file
> extension." Also, this contradicts Goal #2 - Excel and Numbers register as
> handlers for .csv, and so make it clear that the file is editable outside
> of a wallet.
>
> > ZIP does not have good performance or compression ratio
> Indeed, but it is very widely available. That said, gzip is supported
> widely too these days. Unfortunately, gzip does not offer encryption (see
> next answer).
>
> > ZIP is an archiving format, that happens to have its own compression
> format.
> I agree this is not ideal. My main reason for choosing ZIP was that it
> supports encryption. It seems to me that without considering encryption, an
> application must create label export files that allow privacy-sensitive
> wallet information to be readable in plain text. Being able to transfer
> labels without risking privacy is IMO valuable. I considered other
> encryption formats such as PGP, but they are much more niche and so again
> contradict Goal #2.
>
> > I don't see the benefit of encrypting addresses and labels together...
> additionally, the password you propose is insecure - anybody with access to
> the wallet can unlock it
> I'm not sure I understand your question, but both wallet addresses and
> wallet labels contain privacy-sensitive information that should be
> protected. Wrt to the password, there is actually a more fundamental
> problem with using the wallet xpub - there is no equivalent for multisig
> wallets. For this reason I'll remove that requirement in future iterations.
>
> > Why the need for input and output formats? There is no difference
> between them on the wallet level, because they are always identified with a
> txid and output index.
> The input refers to the txid and the input index (in the set of vin), so
> the difference is the context in which they are displayed. A wallet will
> not necessarily store the spent outputs for a funding transaction
> containing a UTXO coming into the wallet, but it will contain references to
> the inputs as part of that transaction.
>
> > Another important point is that practically nobody labels inputs or
> outputs
> To the contrary, UTXOs are very frequently labelled, as they link and
> reveal information when spent. Inputs are much less frequently labelled,
> but there is no particular reason to exclude them.
>
> > there is a net benefit for the addresses to be exported in ascending
> order
> Indeed, but it makes achieving Goal #2 much more difficult for marginal
> benefit.
>
> > It's better to mandate that they should always be double-quoted, since
> only wallets will generate label exports anyway.
> Rather I think it's better to mandate RFC4180 is followed, as per
> recommendations in other feedback.
>
> > The importing code is too naive... it should utilize a dedicate item
> type field that unambiguously identifies the item
> It's unclear to me what you mean here. As I've indicated it is currently
> possible to disambiguate between addresses/transactions/etc without the
> need for a 3rd column, but in any case the hash functions used ensure that
> labels will not be associated incorrectly. Even in the unlikely event of
> some future address type being indistinguishable from a txid, it will
> simply not match any txids in the wallet.
>
> Craig
>
>
>
> On Wed, Aug 24, 2022 at 9:10 PM Ali Sherief <ali at notatether.com> wrote:
>
>> Hi Craig,
>>
>> This a really good proposal. I studied your BIP and I have some feedback
>> on some parts of it.
>>
>> > The first line in the file is a header, and should be ignored on import.
>>
>> From past experience and lessons, most notably BIP39, it is important
>> that a version byte is defined somewhere in case someone wants to extend it
>> in the future, currently there is no version byte which someone can
>> increment if somebody wants to extend it. In the unique case of CSV files,
>> you should make the header line mandatory (I see you have already implied
>> this, but you should make it explicit in the BIP), but instead of a line
>> with columns in it, I suggest instead of Reference,Label, you make the
>> format like this:
>>
>> BIP-wallet-labels,<version>
>>
>> Since there are two columns per record, this works out nicely. The first
>> column can be the name of the BIP - BIPxxxx where the x's are numbers, and
>> the second column can be an unsigned 32-bit integer (most significant 8
>> bits reserved for version, the remaining for flags, or perhaps the entirety
>> for version - but I recommend leaving at least some bits for flags, even if
>> they all end up being just "reserved").
>>
>> You should make importing fail if the header line is not exactly as
>> specified - or appropriate, should you decide a different format for the
>> header.
>>
>> > Files exported should use the <tt>.csv</tt> file extension.
>> Don't mandate the file extension (read below for why):
>>
>> > In order to reduce file size while retaining wide accessibility, the CSV
>> > file may be compressed using the ZIP file format, using the
>> <tt>.zip</tt>
>> > file extension.
>> I see three problems with this. The first is more important than the
>> later two because it makes them moot points, but I'll mention them anyway
>> so you get a background of the situation:
>> - The BIP is trying to specify in what file format the export format can
>> be written in onto the filesystem. There is no way to enforce this on a BIP
>> level (besides, Unix operating systems don't even consider the file
>> extension, they use its mimetype). Also specifying this in the BIP will
>> prevent modular "Layer 2" protocols and schemes from encoding the Export
>> labels into another format - for example Base64 or with their own
>> compression algorithm.
>>
>> Now for the two "moot problems":
>> - ZIP does not have good performance or compression ratio, there are
>> better algorithms out there like gzip (which also happens to be more
>> ubiquitous; nearly all websites are serving HTML compressed with gzip
>> compression).
>> - ZIP is an archiving format, that happens to have its own compression
>> format. Archiving format parsers can have serious vulnerabilities in their
>> implementation that can allow malware to swipe private keys and passwords,
>> since the primary target for this BIP is wallets. For example, there was
>> Zip Slip[1] in 2018, which allows for remote code execution. So the malware
>> can even hide in memory until private keys or passwords are written to
>> memory, then send them accros the network. Assuming it's targeting a
>> specific wallet software it's not hard to carry out at all.
>>
>> There's two solutions for all this:
>> 1. The duck-tape solution: Use some compression algorithm like gzip
>> instead of ZIP archive format.
>> 2. The "throw it out and buy a new one" solution: Get rid of the optional
>> compression specs altogether, because users are responsible for supplying
>> the export labels in the first place, so all the compression stuff is
>> redundant and should be left up to the user use if they desire to.
>>
>> I prefer the second solution because it hits the nail at the problem
>> directly instead of putting duck tape on it like the first one.
>>
>> > This <tt>.zip</tt> file may optionally be encrypted using either
>> AES-128 or
>> > AES-256 encryption, which is supported by numerous applications
>> including
>> > Winzip and 7-zip.
>> > The textual representation of the wallet's extended public key (as
>> defined
>> > by BIP32, with an <tt>xpub</tt> header) should be used as the password.
>> Not specific to AES, but I don't see the benefit of encrypting addresses
>> and labels together. Can you please elaborate why this would be desireable?
>>
>> Like I said though, it's better to leave it up to users to decide how to
>> store their exports, since BIPs can't enforce that anyway (additionally,
>> the password you propose is insecure - anybody with access to the wallet
>> can unlock it, which is not desireable to some users who want their own
>> security).
>>
>> > * Transaction ID (<tt>txid</tt>)
>> > * Address
>> > * Input (rendered as <tt>txid<index</tt>)
>> > * Output (rendered as <tt>txid>index</tt> or <tt>txid:index</tt>)
>> Why the need for input and output formats? There is no difference between
>> them on the wallet level, because they are always identified with a txid
>> and output index. To distinguish between them and hence write them with the
>> correct format would require a UTXO set and thus access to a full node,
>> otherwise the CSV cannot be verified to be completely well-formed.
>>
>> Another important point is that practically nobody labels inputs or
>> outputs because most people do not know that those things even exist, and
>> the rest don't bother to label them.
>>
>> But the biggest downside to including them is related to the problem of
>> information leaking which you make reference to here:
>> > In both cases, care must be taken when spending to avoid undesirable
>> leaks
>> > of private information.
>> A CSV dump that has inputs/outputs and addresses mixed together can infer
>> the owner of all those items. In fact, A CVS label dump is basically a
>> personal information store so everything in it can be correlated as coming
>> from the same wallet, so it's important that unnecessary types are kept out
>> of the format. People are known to leave files lying around on their
>> computer that they don't need anymore, so these files can find their way
>> via telemetry to surveillence entities. While we can't specify what users
>> can do with their exports, we can control the information leak by
>> preventing certain types of items that we know most users will never use
>> from being exported in the first place.
>>
>> > The order in which these records appear is not defined.
>> Again, since the primary use case for this BIP is wallets, which likely
>> use heirarchical derivation schemes like BIP44, there is a net benefit for
>> the addresses to be exported in ascending order of their `address_type`. It
>> means that wallets can import them in O(n) time as opposed to O(n^2) time
>> spent serially checking in which index the address appears at. Of course,
>> this implies that all addresses up to a certain index have to be exported
>> into the CSV as well, but most wallets I know of like Core, Electrum
>> already store addresses like that.
>>
>> Also if you do this, you will need to group all the transaction records
>> before the address records or vice versa - you can use lexigraphical
>> sorting if you want (ie. Addresses before Transactions). The benefit of
>> this separation of parts is that wallets can split the imported address
>> records from the transaction records internally, and feed them to separate
>> functions which set these labels internally.
>>
>> If you decide on doing it this way, then you need a 3rd column to
>> identify the item type, and also you should quote the label (see below). I
>> strongly recommend using numbers for identification as opposed to character
>> strings, so you don't have to worry about localization or character case
>> issues. There is always one unique number, but there could be multiple
>> strings that reference the same type. This will complicate importing
>> functions.
>>
>> If you insist on include Input and Output types then they can both be
>> specified as <txid>:<index> if you do this change. They won't be used to
>> determine the type anyway.
>>
>> > The fields may be quoted, but this is unnecessary, as the first comma in
>> > the line will always be the delimiter.
>> Don't implement it like that, because that will break CSV parsers which
>> expect a fixed amount of rows in each record (2 in the header, and some
>> rows have >2 rows). It's better to mandate that they should always be
>> double-quoted, since only wallets will generate label exports anyway. If
>> you plan to use headers then the 3rd column can be blank for it (or you can
>> split the version and flags from each other).
>>
>> > ==Importing==
>> >
>> > When importing, a naive algorithm may simply match against any
>> reference,
>> > but it is possible to disambiguate between transactions, addresses,
>> inputs
>> > and outputs.
>> > For example in the following pseudocode:
>> > <pre>
>> >   if reference length < 64
>> >     Set address label
>> >   else if reference length == 64
>> >     Set transaction label
>> >   else if reference contains '<'
>> >     Set input label
>> >   else
>> >     Set output label
>> > </pre>
>> The importing code is too naive and in its current form will prevent the
>> BIP from getting a number. It is perhaps the single most important part of
>> a BIP. When implementing an importer, it should utilize a dedicate item
>> type field that unambiguously identifies the item. So the naive importer is
>> not good, you need use a 3rd column for that like I explained above, so
>> that the importer becomes robust.
>>
>> In summary (exclamation marks indicate severity - one means low, two
>> means medium, and three means high):
>>
>> 1. Convert the header into a version line with optional flags, otherwise
>> nobody can extend this format without compatibility issues (!)
>> 2. Get rid of the specs related to file compression (!!!)
>> 3. Add a 3rd column for item type (address, transaction etc.) preferably
>> as numeric constants and grouping items of one type after items of another
>> type, or if you insist on strings, then only recognize their Titlecase
>> ASCII versions <spreadsheet software like Excel always tries to titlecase
>> the words> (!!)
>> 4. Require double quotes around the label (or single quotes if you
>> prefer, as long as spreadsheet software doesn't choke on them) (!!)
>> 5. Require sorting the records according to the order they are stored in
>> the wallet implementation. (!)
>> 6. Consider getting rid of Input and Output item types. (!)
>> 7. And last and most importantly, please write a more robust importer
>> algorithm in the example given by the BIP, because code in BIPs are
>> frequently used as references for software. (!!!)
>>
>> I hope you will consider these points in future revisions of your BIP.
>>
>> - Ali
>>
>> [1] https://github.com/snyk/zip-slip-vulnerability
>>
>> On Wed, 24 Aug 2022 11:18:43 +0200, craigraw at gmail.com wrote:
>> > Hi all,
>> >
>> > I would like to propose a BIP that specifies a format for the export and
>> > import of labels from a wallet. While transferring access to funds
>> across
>> > wallet applications has been made simple through standards such as
>> BIP39,
>> > wallet labels remain siloed and difficult to extract despite their
>> value,
>> > particularly in a privacy context.
>> >
>> > The proposed format is a simple two column CSV file, with the reference
>> to
>> > a transaction, address, input or output in the first column, and the
>> label
>> > in the second column. CSV was chosen for its wide accessibility,
>> especially
>> > to users without specific technical expertise. Similarly, the CSV file
>> may
>> > be compressed using the ZIP format, and optionally encrypted using AES.
>> >
>> > The full text of the BIP can be found at
>> >
>> https://github.com/craigraw/bips/blob/master/bip-wallet-labels.mediawiki
>> > and also copied below.
>> >
>> > Feedback is appreciated.
>> >
>> > Thanks,
>> > Craig Raw
>> >
>> > ---
>> >
>> > <pre>
>> >   BIP: wallet-labels
>> >   Layer: Applications
>> >   Title: Wallet Labels Export Format
>> >   Author: Craig Raw <craig at sparrowwallet.com>
>> >   Comments-Summary: No comments yet.
>> >   Comments-URI:
>> > https://github.com/bitcoin/bips/wiki/Comments:BIP-wallet-labels
>> >   Status: Draft
>> >   Type: Informational
>> >   Created: 2022-08-23
>> >   License: BSD-2-Clause
>> > </pre>
>> >
>> > ==Abstract==
>> >
>> > This document specifies a format for the export of labels that may be
>> > attached to the transactions, addresses, input and outputs in a wallet.
>> >
>> > ==Copyright==
>> >
>> > This BIP is licensed under the BSD 2-clause license.
>> >
>> > ==Motivation==
>> >
>> > The export and import of funds across different Bitcoin wallet
>> applications
>> > is well defined through standards such as BIP39, BIP32, BIP44 etc.
>> > These standards are well supported and allow users to move easily
>> between
>> > different wallets.
>> > There is, however, no defined standard to transfer any labels the user
>> may
>> > have applied to the transactions, addresses, inputs or outputs in their
>> > wallet.
>> > The UTXO model that Bitcoin uses makes these labels particularly
>> valuable
>> > as they may indicate the source of funds, whether received externally
>> or as
>> > a result of change from a prior transaction.
>> > In both cases, care must be taken when spending to avoid undesirable
>> leaks
>> > of private information.
>> > Labels provide valuable guidance in this regard, and have even become
>> > mandatory when spending in several Bitcoin wallets.
>> > Allowing users to export their labels in a standardized way ensures that
>> > they do not experience lock-in to a particular wallet application.
>> > In addition, by using common formats, this BIP seeks to make manual or
>> bulk
>> > management of labels accessible to users without specific technical
>> > expertise.
>> >
>> > ==Specification==
>> >
>> > In order to make the import and export of labels as widely accessible as
>> > possible, this BIP uses the comma separated values (CSV) format, which
>> is
>> > widely supported by consumer, business, and scientific applications.
>> > Although the technical specification of CSV in RFC4180 is not always
>> > followed, the application of the format in this BIP is simple enough
>> that
>> > compatibility should not present a problem.
>> > Moreover, the simplicity and forgiving nature of CSV (over for example
>> > JSON) lends itself well to bulk label editing using spreadsheet and text
>> > editing tools.
>> >
>> > A CSV export of labels from a wallet must be a UTF-8 encoded text file,
>> > containing one record per line, with records containing two fields
>> > delimited by a comma.
>> > The fields may be quoted, but this is unnecessary, as the first comma in
>> > the line will always be the delimiter.
>> > The first line in the file is a header, and should be ignored on import.
>> > Thereafter, each line represents a record that refers to a label
>> applied in
>> > the wallet.
>> > The order in which these records appear is not defined.
>> >
>> > The first field in the record contains a reference to the transaction,
>> > address, input or output in the wallet.
>> > This is specified as one of the following:
>> > * Transaction ID (<tt>txid</tt>)
>> > * Address
>> > * Input (rendered as <tt>txid<index</tt>)
>> > * Output (rendered as <tt>txid>index</tt> or <tt>txid:index</tt>)
>> >
>> > The second field contains the label applied to the reference.
>> > Exporting applications may omit records with no labels or labels of zero
>> > length.
>> > Files exported should use the <tt>.csv</tt> file extension.
>> >
>> > In order to reduce file size while retaining wide accessibility, the CSV
>> > file may be compressed using the ZIP file format, using the
>> <tt>.zip</tt>
>> > file extension.
>> > This <tt>.zip</tt> file may optionally be encrypted using either
>> AES-128 or
>> > AES-256 encryption, which is supported by numerous applications
>> including
>> > Winzip and 7-zip.
>> > In order to ensure that weak encryption does not proliferate, importers
>> > following this standard must refuse to import <tt>.zip</tt> files
>> encrypted
>> > with the weaker Zip 2.0 standard.
>> > The textual representation of the wallet's extended public key (as
>> defined
>> > by BIP32, with an <tt>xpub</tt> header) should be used as the password.
>> >
>> > ==Importing==
>> >
>> > When importing, a naive algorithm may simply match against any
>> reference,
>> > but it is possible to disambiguate between transactions, addresses,
>> inputs
>> > and outputs.
>> > For example in the following pseudocode:
>> > <pre>
>> >   if reference length < 64
>> >     Set address label
>> >   else if reference length == 64
>> >     Set transaction label
>> >   else if reference contains '<'
>> >     Set input label
>> >   else
>> >     Set output label
>> > </pre>
>> >
>> > Importing applications may truncate labels if necessary.
>> >
>> > ==Test Vectors==
>> >
>> > The following fragment represents a wallet label export:
>> > <pre>
>> > Reference,Label
>> >
>> c3bdad6e7dcd7997e16a5b7b7cf4d8f6079820ff2eedd5fcbb2ad088f767b37b?,Transaction
>> > 1A69TXnEM2ms9fMaY9UuiJ7415X7xZaUSg,Address
>> >
>> c3bdad6e7dcd7997e16a5b7b7cf4d8f6079820ff2eedd5fcbb2ad088f767b37b?<0,Input
>> >
>> c3bdad6e7dcd7997e16a5b7b7cf4d8f6079820ff2eedd5fcbb2ad088f767b37b?>0,Output
>> >
>> c3bdad6e7dcd7997e16a5b7b7cf4d8f6079820ff2eedd5fcbb2ad088f767b37b?:0,Output
>> > (alternative)
>> > </pre>
>> >
>> > ==Reference Implementation==
>> >
>> > TBD
>>
>> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220920/d85742d6/attachment-0001.html>

From eloyesp at gmail.com  Thu Sep 22 03:06:50 2022
From: eloyesp at gmail.com (El_Hoy)
Date: Thu, 22 Sep 2022 00:06:50 -0300
Subject: [bitcoin-dev] RFC for a BIP32 recurrent address derivation scheme
Message-ID: <CAPapNH28iCxEcTOKt3YC+zuZzxbM=AudbbYByjS3aUZAgFHUag@mail.gmail.com>

There is a known issue on bitcoin, that is that every transaction requires
a new address to prevent address reuse, making it uncomfortable to make
recurring payments, as every payment requires a new off-chain interaction.
A scheme is already mentioned on the [on the BIP32 itself][1], but it
cannot be implemented as is.

Here I propose a scheme that follows the structure described on [BIP44]
that should make it possible to send recurring payments using a single
offline interaction.

The proposed scheme is:

    master / purpose' / coin_type' / contact' / index

Where the definitions of all the levels follow BIP44, except for `contact`
that is described below.

Example usage: Bob wants to make recurring payments to Carol, so he asks
her for a _contact address_, that is, an extended public key.

Bob can use that public key to generate multiple derived addresses to make
multiple recurring payments to Carol, the contact address is stored
off-chain, anyone inspecting the chain will just see normal transactions
on-chain.

## Considerations

[BIP47] tries to solve the same issue, but the solution is more complex and
involves more on-chain transactions that involve data, this implementation
simpler and requires less work to implement.

Also, the derivation path might need some adjustments for different address
types on bitcoin.

Finally, this only works in a single direction and does not make it
possible for Carol to send anything to Bob, as it would require Bob sending
her a contact address.

## Advantages

A positive side effect of using this, is that Bob can choose to send
payments to Carol using multiple outputs, giving him more privacy.

Also, those payments can be easily labeled by the receiving wallet, as they
are received.

Regards.

### References

[1]:
https://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki#recurrent-business-to-business-transactions-nmih0
[BIP47]: https://github.com/bitcoin/bips/blob/master/bip-0047.mediawiki
"Reusable Payment Codes for Hierarchical Deterministic Wallets"
[BIP43]:
https://github.com/bitcoin/bips/blob/master/bip-0043.mediawiki#Purpose

--- Eloy
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220922/4d4aee8b/attachment.html>

From gloriajzhao at gmail.com  Fri Sep 23 15:18:21 2022
From: gloriajzhao at gmail.com (Gloria Zhao)
Date: Fri, 23 Sep 2022 16:18:21 +0100
Subject: [bitcoin-dev] New transaction policies (nVersion=3) for contracting
	protocols
Message-ID: <CAFXO6=KDys2_dsrdxE9_q_MVZJOFMbg-MctxiokcicP=wd4Lkw@mail.gmail.com>

Hi everyone,

I'm writing to propose a very simple set of mempool/transaction relay
policies intended to aid L2/contract protocols. I realized that
the previously proposed Package Mempool Accept package RBF [1]
had a few remaining problems after digging into the RBF logic more [2].
This additional set of policies solves them without requiring a huge RBF
overhaul.

I've written an implementation (and docs) for Bitcoin Core:
https://github.com/bitcoin/bitcoin/pull/25038

(You may notice that this proposal incorporates feedback on the PR - thanks
Suhas Daftuar, Gregory Sanders, Bastien Teinturier, Anthony Towns, and
others.)

If you are interested in using package RBF/relay to bump presigned
transactions, I think you may be interested in reviewing this proposal.
This should solve Rule 3 pinning and perhaps allow us
to get rid of CPFP carve-out (yay!). I'm keen to hear if people find
the 1-anchor-output, 1000vB child limit too restrictive. Also, if you find a
pinning attack or something that makes it unusable for you, I would
really really like to know.

Note that transactions with nVersion=3 ("V3 transactions") are
currently non-standard in Bitcoin Core. That means **anything that was
standard before this policy change would still be standard
afterwards.** If you don't want your transactions to be subject to
these rules, just continue whatever you're doing and don't use
nVersion=3. AFAICT this shouldn't break anything, but let me know if
this would be disruptive for you?

**New Policies:**

This includes:
- a set of additional policy rules applying to V3 transactions
- modifications to package RBF rules

**V3 transactions:**

Existing standardness rules apply to V3 (e.g. min/max tx weight,
standard output types, cleanstack, etc.). The following additional
rules apply to V3:

1. A V3 transaction can be replaced, even if it does not signal BIP125
   replaceability. (It must also meet the other RBF rules around fees,
etc. for replacement to happen).

2. Any descendant of an unconfirmed V3 transaction must also be V3.

*Rationale*: Combined with Rule 1, this gives us the property of
"inherited" replaceability signaling when descendants of unconfirmed
transactions are created. Additionally, checking whether a transaction
signals replaceability this way does not require mempool traversal,
and does not change based on what transactions are mined. It also
makes subsequent rules about descendant limits much easier to check.

*Note*: The descendant of a *confirmed* V3 transaction does not need to be
V3.

3. An unconfirmed V3 transaction cannot have more than 1 descendant.

*Rationale*: (Upper bound) the larger the descendant limit, the more
transactions may need to be replaced. This is a problematic pinning
attack, i.e., a malicious counterparty prevents the transaction from
being replaced by adding many descendant transactions that aren't
fee-bumping.

(Lower bound) at least 1 descendant is required to allow CPFP of the
presigned transaction. The contract protocol can create presigned
transactions paying 0 fees and 1 output for attaching a CPFP at
broadcast time ("anchor output"). Without package RBF, multiple anchor
outputs would be required to allow each counterparty to fee-bump any
presigned transaction. With package RBF, since the presigned
transactions can replace each other, 1 anchor output is sufficient.

4. A V3 transaction that has an unconfirmed V3 ancestor cannot be
   larger than 1000 virtual bytes.

*Rationale*: (Upper bound) the larger the descendant size limit, the
more vbytes may need to be replaced. With default limits, if the child
is e.g. 100,000vB, that might be an additional 100,000sats (at
1sat/vbyte) or more, depending on the feerate.

(Lower bound) the smaller this limit, the fewer UTXOs a child may use
to fund this fee-bump. For example, only allowing the V3 child to have
2 inputs would require L2 protocols to manage a wallet with high-value
UTXOs and make batched fee-bumping impossible. However, as the
fee-bumping child only needs to fund fees (as opposed to payments),
just a few UTXOs should suffice.

With a limit of 1000 virtual bytes, depending on the output types, the
child can have 6-15 UTXOs, which should be enough to fund a fee-bump
without requiring a carefully-managed UTXO pool. With 1000 virtual
bytes as the descendant limit, the cost to replace a V3 transaction
has much lower variance.

*Rationale*: This makes the rule very easily "tacked on" to existing
logic for policy and wallets. A transaction may be up to 100KvB on its
own (`MAX_STANDARD_TX_WEIGHT`) and 101KvB with descendants
(`DEFAULT_DESCENDANT_SIZE_LIMIT_KVB`). If an existing V3 transaction
in the mempool is 100KvB, its descendant can only be 1000vB, even if
the policy is 10KvB.

**Package RBF modifications:**

1. The rule around unconfirmed inputs was
originally "A package may include new unconfirmed inputs, but the
ancestor feerate of the child must be at least as high as the ancestor
feerates of every transaction being replaced."

The package may still include new unconfirmed inputs. However,
the new rule is modified to be "The minimum between package feerate
and ancestor feerate of the child is not lower than the individual
feerates of all directly conflicting transactions and the ancestor
feerates of all original transactions."

*Rationale*: We are attempting to ensure that the replacement
transactions are not less incentive-compatible to mine. However, a
package/transaction's ancestor feerate is not perfectly representative
of its incentive compatibility; it may overestimate (some subset of
the ancestors could be included by itself if it has other high-feerate
descendants or are themselves higher feerate than this
package/transaction). Instead, we use the minimum between the package
feerate and ancestor feerate of the child as a more conservative value
than what was proposed originally.

2. A new rule is added, requiring that all package transactions with
mempool conflicts to be V3. This also means the "sponsoring"
child transaction must be V3.

*Note*: Combined with the V3 rules, this means the package must be
a child-with-parents package. Since package validation is only
attempted if the transactions do not pay sufficient fees to be
accepted on their own, this effectively means that only V3
transactions can pay to replace their ancestors' conflicts, and only
V3 transactions' replacements may be paid for by a descendant.

*Rationale*: The fee-related rules are economically rational for
ancestor packages, but not necessarily other types of packages.
A child-with-parents package is a type of ancestor package. It
may be fine to allow any ancestor package, but it's more difficult
to account for all of the possibilities. For example, it gets much
harder to see that we're applying the descendant limits correctly if
the package has a gnarly, many-generation, non-tree shape. I'm also
not sure if this policy is 100% incentive-compatible if the sponsor
is not a direct descendant of the sponsee.

Please see doc/policy/version3_transactions.md and
doc/policy/packages.md in the PR for the full set of rules.

**Intended usage for LN:**

Commitment transactions should be V3 and have 1 anchor output. They
can be signed with 0 fees (or 1sat/vbyte) once package relay is deployed
on a significant portion of the network. If the commitment tx must
be broadcast, determine the desired feerate at broadcast time and
spend the anchor output in a high feerate transaction. I'm going to
call the broadcasted commitment tx "the parent" and the attached
fee-bumping tx "the child."

- This child must be V3.
- This child must be at most 1000vB. Note this restricts the
  number of inputs you can use to fund the fee bump. Depending
on the output types, this is around 6-15.
- One child may fund fees for multiple commitment tx ("batched
  fee-bumping").
- To do a second fee-bump to add more fees, replace the
  *child* with a higher-feerate tx. Do not try to attach a grandchild.

Otherwise, never try to spend from an unconfirmed V3 transaction. The
descendant limits for V3 transactions are very restrictive.

**Expected Questions:**

"Does this fix Rule 3 Pinning?"
Yes. The V3 descendant limit restricts both you and your counterparty.
Assuming nodes adopted this policy, you may reasonably assume that you
only need to replace the commitment transaction + up to 1000vB.

"Only 1 anchor output? What if I need to bump counterparty's commitment tx
in mempool?"
You won't need to fee-bump a counterparty's commitment tx using CPFP.
You would just package RBF it by attaching a high-feerate child to
your commitment tx.

"Is this a privacy issue, i.e. doesn't it allow fingerprinting LN
transactions based on nVersion?"
Indeed it may be unrealistic to assume V3 transactions will be in
widespread use outside of L2. IIUC, unilateral closes are already
obvious LN transactions because of the HTLC inputs. For e.g.
cooperative closes and opens, I think it makes sense to continue using
V2. So, unless I'm missing something, this shouldn't make it worse.

"So a V3 transaction that doesn't signal BIP125 replaceability is
replaceable? Is that a backward compatibility issue?"
Yes it's replaceable. It's not an issue AFAICT because,
under previous policy, the V3 transaction wouldn't have been
in the mempool in the first place.

"Can a V2 transaction replace a V3 transaction and vice versa?"
Yes, otherwise someone can use V3 transactions to censor V2
transactions spending shared inputs. Note if the
original V3 transaction has an unconfirmed V3 parent, this would
violate the "inherited V3" rule and would be rejected.

Thanks for reading! Feedback and review would be much appreciated.

[1]:
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019464.html
[2]:
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019817.html

Best,
Gloria
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220923/9b52c0c4/attachment.html>

From gsanders87 at gmail.com  Fri Sep 23 18:48:39 2022
From: gsanders87 at gmail.com (Greg Sanders)
Date: Fri, 23 Sep 2022 14:48:39 -0400
Subject: [bitcoin-dev] New transaction policies (nVersion=3) for
 contracting protocols
In-Reply-To: <CAFXO6=KDys2_dsrdxE9_q_MVZJOFMbg-MctxiokcicP=wd4Lkw@mail.gmail.com>
References: <CAFXO6=KDys2_dsrdxE9_q_MVZJOFMbg-MctxiokcicP=wd4Lkw@mail.gmail.com>
Message-ID: <CAB3F3DtLR97voxBQOjsj_LdyPPYAgq_ACZGGqSa7nc_PqBxaYA@mail.gmail.com>

Hello Gloria,

Great work on synthesizing so much feedback into a proposal like this!

Death to carve-out rule.

I'd like to elaborate on some caveats and give a few incomplete thoughts.

There are basically two types of pinning in my estimation today:

1) rule#3 pinning: Make it uneconomical to replace whatever is in mempool
via large in size but low feerate junk that won't get mined anytime soon.
Replacing this with feerate-based policy seems apt, but fraught with DoS
risks.

2) package limit pinning: disallowing transaction propagation by package
limits being hit: size, ancestor count, descendant count. Today it is
mitigated by having all outputs be 1 csv timelocked, and having up to 2
anchor outputs(1 without carve-out rule).

Would kind of be nice if package RBF would detect a "sibling output spend"
conflict, and knock it out of the mempool via the other replacement rules?
Getting rid of the requirement to 1 block csv lock every output would be
quite nice from a smart contracting composability point of view.

> "Does this fix Rule 3 Pinning?"

As you likely know from previous discussions the biggest scenario this does
not fix in my estimation is ANYONECANPAY situations. If the parent
transaction can be "inflated" by tacking on additional inputs, this means
the total weight of the parent tx lowers the effective feerate of the
package. Due to this pinning attack there aren't many(?) deployed schemes
that use the signature type.

To mitigate this we would likely have to opt into a more complex policy
scheme, committing in the annex to "total mempool package weight", which
would allow mempool package limits to be picked at signing time.

Maybe ANYONECANPAY isn't a very useful paradigm in general, I cannot speak
to that, but it came up in eltoo-related designs using BIP118, which adopts
ACP-like signing behavior. This can be mitigated via straight forward
policy updates as well for BIP118 deployment, but off topic so will leave
it there.

The other scenario it doesn't really fix is where HTLC/commitment-like
transactions are being resolved in a batch, but due to relative time
constraints, you may want to accelerate some and not others. Now you must
pay higher rates to replace all of the transaction bumps. This is a
"self-pin" and "get good at utxos noob" type problem, but it's something
that axing rule#3 in favor of a Replace-by-ancestor-feerate system would
get us.

> "Can a V2 transaction replace a V3 transaction and vice versa?"

Circling back to my ACP point, this regime still allows pinning anytime you
are sharing a transaction with someone else where you don't have control
over *all* the inputs. So anytime you are doing a coinjoin-like
transaction, someone else's inputs can be self-double-spent, requiring you
to satisfy rule#3 when replacing theirs, if they're bip125-signaling. If
they're not bip125 signaling, you'll have to somehow detect this and/or
double-spend your input back to yourself.


Finally, a couple suggestions I've already made elsewhere:

1) I do think that we should seriously consider allowing OP_TRUE to become
a standard script type as part of this policy update. If pinning is solved,
then there's no reason to require all those extra bytes for "binding" an
anchor to a specific wallet/user. We can save quite a few bytes by having
the input be empty of witness data.

2) If we allow for a single dust-value(0 on up) output which is immediately
spent by the package, anchors become even easier to to design. No value has
to be "sapped" from contract participants to make an anchor output. There's
more complications for this, such as making sure the parent transaction is
dropped if the child spend is dropped, but maybe it's worth the squeeze. I
do think that any L2 uptake of these new rules will take significant
time... maybe we should be a bit more ambitious?

Cheers,
Greg

On Fri, Sep 23, 2022 at 11:27 AM Gloria Zhao via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Hi everyone,
>
> I'm writing to propose a very simple set of mempool/transaction relay
> policies intended to aid L2/contract protocols. I realized that
> the previously proposed Package Mempool Accept package RBF [1]
> had a few remaining problems after digging into the RBF logic more [2].
> This additional set of policies solves them without requiring a huge RBF
> overhaul.
>
> I've written an implementation (and docs) for Bitcoin Core:
> https://github.com/bitcoin/bitcoin/pull/25038
>
> (You may notice that this proposal incorporates feedback on the PR -
> thanks Suhas Daftuar, Gregory Sanders, Bastien Teinturier, Anthony Towns,
> and others.)
>
> If you are interested in using package RBF/relay to bump presigned
> transactions, I think you may be interested in reviewing this proposal.
> This should solve Rule 3 pinning and perhaps allow us
> to get rid of CPFP carve-out (yay!). I'm keen to hear if people find
> the 1-anchor-output, 1000vB child limit too restrictive. Also, if you find
> a
> pinning attack or something that makes it unusable for you, I would
> really really like to know.
>
> Note that transactions with nVersion=3 ("V3 transactions") are
> currently non-standard in Bitcoin Core. That means **anything that was
> standard before this policy change would still be standard
> afterwards.** If you don't want your transactions to be subject to
> these rules, just continue whatever you're doing and don't use
> nVersion=3. AFAICT this shouldn't break anything, but let me know if
> this would be disruptive for you?
>
> **New Policies:**
>
> This includes:
> - a set of additional policy rules applying to V3 transactions
> - modifications to package RBF rules
>
> **V3 transactions:**
>
> Existing standardness rules apply to V3 (e.g. min/max tx weight,
> standard output types, cleanstack, etc.). The following additional
> rules apply to V3:
>
> 1. A V3 transaction can be replaced, even if it does not signal BIP125
>    replaceability. (It must also meet the other RBF rules around fees,
> etc. for replacement to happen).
>
> 2. Any descendant of an unconfirmed V3 transaction must also be V3.
>
> *Rationale*: Combined with Rule 1, this gives us the property of
> "inherited" replaceability signaling when descendants of unconfirmed
> transactions are created. Additionally, checking whether a transaction
> signals replaceability this way does not require mempool traversal,
> and does not change based on what transactions are mined. It also
> makes subsequent rules about descendant limits much easier to check.
>
> *Note*: The descendant of a *confirmed* V3 transaction does not need to be
> V3.
>
> 3. An unconfirmed V3 transaction cannot have more than 1 descendant.
>
> *Rationale*: (Upper bound) the larger the descendant limit, the more
> transactions may need to be replaced. This is a problematic pinning
> attack, i.e., a malicious counterparty prevents the transaction from
> being replaced by adding many descendant transactions that aren't
> fee-bumping.
>
> (Lower bound) at least 1 descendant is required to allow CPFP of the
> presigned transaction. The contract protocol can create presigned
> transactions paying 0 fees and 1 output for attaching a CPFP at
> broadcast time ("anchor output"). Without package RBF, multiple anchor
> outputs would be required to allow each counterparty to fee-bump any
> presigned transaction. With package RBF, since the presigned
> transactions can replace each other, 1 anchor output is sufficient.
>
> 4. A V3 transaction that has an unconfirmed V3 ancestor cannot be
>    larger than 1000 virtual bytes.
>
> *Rationale*: (Upper bound) the larger the descendant size limit, the
> more vbytes may need to be replaced. With default limits, if the child
> is e.g. 100,000vB, that might be an additional 100,000sats (at
> 1sat/vbyte) or more, depending on the feerate.
>
> (Lower bound) the smaller this limit, the fewer UTXOs a child may use
> to fund this fee-bump. For example, only allowing the V3 child to have
> 2 inputs would require L2 protocols to manage a wallet with high-value
> UTXOs and make batched fee-bumping impossible. However, as the
> fee-bumping child only needs to fund fees (as opposed to payments),
> just a few UTXOs should suffice.
>
> With a limit of 1000 virtual bytes, depending on the output types, the
> child can have 6-15 UTXOs, which should be enough to fund a fee-bump
> without requiring a carefully-managed UTXO pool. With 1000 virtual
> bytes as the descendant limit, the cost to replace a V3 transaction
> has much lower variance.
>
> *Rationale*: This makes the rule very easily "tacked on" to existing
> logic for policy and wallets. A transaction may be up to 100KvB on its
> own (`MAX_STANDARD_TX_WEIGHT`) and 101KvB with descendants
> (`DEFAULT_DESCENDANT_SIZE_LIMIT_KVB`). If an existing V3 transaction
> in the mempool is 100KvB, its descendant can only be 1000vB, even if
> the policy is 10KvB.
>
> **Package RBF modifications:**
>
> 1. The rule around unconfirmed inputs was
> originally "A package may include new unconfirmed inputs, but the
> ancestor feerate of the child must be at least as high as the ancestor
> feerates of every transaction being replaced."
>
> The package may still include new unconfirmed inputs. However,
> the new rule is modified to be "The minimum between package feerate
> and ancestor feerate of the child is not lower than the individual
> feerates of all directly conflicting transactions and the ancestor
> feerates of all original transactions."
>
> *Rationale*: We are attempting to ensure that the replacement
> transactions are not less incentive-compatible to mine. However, a
> package/transaction's ancestor feerate is not perfectly representative
> of its incentive compatibility; it may overestimate (some subset of
> the ancestors could be included by itself if it has other high-feerate
> descendants or are themselves higher feerate than this
> package/transaction). Instead, we use the minimum between the package
> feerate and ancestor feerate of the child as a more conservative value
> than what was proposed originally.
>
> 2. A new rule is added, requiring that all package transactions with
> mempool conflicts to be V3. This also means the "sponsoring"
> child transaction must be V3.
>
> *Note*: Combined with the V3 rules, this means the package must be
> a child-with-parents package. Since package validation is only
> attempted if the transactions do not pay sufficient fees to be
> accepted on their own, this effectively means that only V3
> transactions can pay to replace their ancestors' conflicts, and only
> V3 transactions' replacements may be paid for by a descendant.
>
> *Rationale*: The fee-related rules are economically rational for
> ancestor packages, but not necessarily other types of packages.
> A child-with-parents package is a type of ancestor package. It
> may be fine to allow any ancestor package, but it's more difficult
> to account for all of the possibilities. For example, it gets much
> harder to see that we're applying the descendant limits correctly if
> the package has a gnarly, many-generation, non-tree shape. I'm also
> not sure if this policy is 100% incentive-compatible if the sponsor
> is not a direct descendant of the sponsee.
>
> Please see doc/policy/version3_transactions.md and
> doc/policy/packages.md in the PR for the full set of rules.
>
> **Intended usage for LN:**
>
> Commitment transactions should be V3 and have 1 anchor output. They
> can be signed with 0 fees (or 1sat/vbyte) once package relay is deployed
> on a significant portion of the network. If the commitment tx must
> be broadcast, determine the desired feerate at broadcast time and
> spend the anchor output in a high feerate transaction. I'm going to
> call the broadcasted commitment tx "the parent" and the attached
> fee-bumping tx "the child."
>
> - This child must be V3.
> - This child must be at most 1000vB. Note this restricts the
>   number of inputs you can use to fund the fee bump. Depending
> on the output types, this is around 6-15.
> - One child may fund fees for multiple commitment tx ("batched
>   fee-bumping").
> - To do a second fee-bump to add more fees, replace the
>   *child* with a higher-feerate tx. Do not try to attach a grandchild.
>
> Otherwise, never try to spend from an unconfirmed V3 transaction. The
> descendant limits for V3 transactions are very restrictive.
>
> **Expected Questions:**
>
> "Does this fix Rule 3 Pinning?"
> Yes. The V3 descendant limit restricts both you and your counterparty.
> Assuming nodes adopted this policy, you may reasonably assume that you
> only need to replace the commitment transaction + up to 1000vB.
>
> "Only 1 anchor output? What if I need to bump counterparty's commitment tx
> in mempool?"
> You won't need to fee-bump a counterparty's commitment tx using CPFP.
> You would just package RBF it by attaching a high-feerate child to
> your commitment tx.
>
> "Is this a privacy issue, i.e. doesn't it allow fingerprinting LN
> transactions based on nVersion?"
> Indeed it may be unrealistic to assume V3 transactions will be in
> widespread use outside of L2. IIUC, unilateral closes are already
> obvious LN transactions because of the HTLC inputs. For e.g.
> cooperative closes and opens, I think it makes sense to continue using
> V2. So, unless I'm missing something, this shouldn't make it worse.
>
> "So a V3 transaction that doesn't signal BIP125 replaceability is
> replaceable? Is that a backward compatibility issue?"
> Yes it's replaceable. It's not an issue AFAICT because,
> under previous policy, the V3 transaction wouldn't have been
> in the mempool in the first place.
>
> "Can a V2 transaction replace a V3 transaction and vice versa?"
> Yes, otherwise someone can use V3 transactions to censor V2
> transactions spending shared inputs. Note if the
> original V3 transaction has an unconfirmed V3 parent, this would
> violate the "inherited V3" rule and would be rejected.
>
> Thanks for reading! Feedback and review would be much appreciated.
>
> [1]:
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019464.html
> [2]:
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019817.html
>
> Best,
> Gloria
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220923/43403b3a/attachment-0001.html>

From antoine.riard at gmail.com  Sun Sep 25 23:59:22 2022
From: antoine.riard at gmail.com (Antoine Riard)
Date: Sun, 25 Sep 2022 19:59:22 -0400
Subject: [bitcoin-dev] New transaction policies (nVersion=3) for
 contracting protocols
In-Reply-To: <CAFXO6=KDys2_dsrdxE9_q_MVZJOFMbg-MctxiokcicP=wd4Lkw@mail.gmail.com>
References: <CAFXO6=KDys2_dsrdxE9_q_MVZJOFMbg-MctxiokcicP=wd4Lkw@mail.gmail.com>
Message-ID: <CALZpt+HYUti=foo+d5ER7Wj=PxsfgaU2CEqqG4_KRxmsWoaSxw@mail.gmail.com>

Hi Gloria,

Thanks for the progress on package RBF, few early questions.

> 2. Any descendant of an unconfirmed V3 transaction must also be V3.

> 3. An unconfirmed V3 transaction cannot have more than 1 descendant.

If you're a miner and you receive a non-V3, second descendant of an
unconfirmed V3 transaction, if the offered fee is in the top mempool
backlog, I think you would have an interest to accept such a transaction.

So I'm not sure if those two rules are compatible with miners incentives...

> 4. A V3 transaction that has an unconfirmed V3 ancestor cannot be
>    larger than 1000 virtual bytes.

If I understand correctly the 1000 vb upper bound rational, it would be to
constraint the pinning counterparty to attach a high fee to a child due to
the limited size, if they would like this transaction to be stuck in the
network mempools. By doing so  this child has high odds to confirm.

I still wonder if this compatible with miner incentives in period of empty
mempools, in the sense that if you've already a V3 transaction of size
100Kvb offering 2 sat/vb, it's more interesting than a V3 replacement
candidate of size 1000 vb offering 10 sat/vb. It could be argued the former
should be conserved.

(That said, the hard thing with any replacement strategy we might evict a
parent transaction *now* to which is attached a high-feerate child *latter*
making for a utxo considered the best ancestor set. Maybe in the long-term
miners should keep every transaction ever accepted...)

> (Lower bound) the smaller this limit, the fewer UTXOs a child may use
> to fund this fee-bump. For example, only allowing the V3 child to have
> 2 inputs would require L2 protocols to manage a wallet with high-value
> UTXOs and make batched fee-bumping impossible. However, as the
> fee-bumping child only needs to fund fees (as opposed to payments),
> just a few UTXOs should suffice.

Reminder for L2 devs, batched fee-bumping of time-sensitive confirmations
of commitment transactions is unsafe, as the counterparty could enter in a
"cat-and-mouse" game to replace one of the batch element at each block to
delay confirmation of the remaining elements in the batch, I think.

On the other hand, I wonder if we wouldn't want a higher bound. LN wallets
are likely to have one big UTXO in their fee-bumping reserve pool, as the
cost of acquiring UTXO is non-null and in the optimistic case, you don't
need to do unilateral closure. Let's say you close dozens of channels at
the same time, a UTXO pool management strategy might be to fan-out the
first spends UTXOs in N fan-out outputs ready to feed the remaining
in-flight channels.

> 1. The rule around unconfirmed inputs was
> originally "A package may include new unconfirmed inputs, but the
> ancestor feerate of the child must be at least as high as the ancestor
> feerates of every transaction being replaced."

Note, I think we would like this new RBF rule to also apply to single
transaction package, e.g second-stage HTLC transactions, where a
counterparty pins a HTLC-preimage by abusing rule 3. In that case, the
honest LN node should be able to broadcast a "at least as high ancestor
feerate" HTLC-timeout transaction. With `option_anchor_outputs" there is no
unconfirmed ancestor to replace, as the commitment transaction, whatever
the party it is originating from, should already be confirmed.

> "Is this a privacy issue, i.e. doesn't it allow fingerprinting LN
transactions based on nVersion?"

As of today, I think yes you can already fingerprint LN transactions on
the  spec-defined amount value of the anchor outputs, 330 sats. There is
always one of them on post-anchor commitment transactions. And sadly I
would say we'll always have tricky fingerprints leaking from unilateral LN
closures such as HTLC/PTLC timelocks...

> "Can a V2 transaction replace a V3 transaction and vice versa?"

IIUC, a V3 package could replace a V2 package, with the benefit of the new
package RBF rules applied. I think this would be a significant advantage
for LN, as for the current ~85k of opened channels, the old V2 states
shouldn't be pinning vectors. Currently, commitment transactions signal
replaceability.

Le ven. 23 sept. 2022 ? 11:26, Gloria Zhao via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> a ?crit :

> Hi everyone,
>
> I'm writing to propose a very simple set of mempool/transaction relay
> policies intended to aid L2/contract protocols. I realized that
> the previously proposed Package Mempool Accept package RBF [1]
> had a few remaining problems after digging into the RBF logic more [2].
> This additional set of policies solves them without requiring a huge RBF
> overhaul.
>
> I've written an implementation (and docs) for Bitcoin Core:
> https://github.com/bitcoin/bitcoin/pull/25038
>
> (You may notice that this proposal incorporates feedback on the PR -
> thanks Suhas Daftuar, Gregory Sanders, Bastien Teinturier, Anthony Towns,
> and others.)
>
> If you are interested in using package RBF/relay to bump presigned
> transactions, I think you may be interested in reviewing this proposal.
> This should solve Rule 3 pinning and perhaps allow us
> to get rid of CPFP carve-out (yay!). I'm keen to hear if people find
> the 1-anchor-output, 1000vB child limit too restrictive. Also, if you find
> a
> pinning attack or something that makes it unusable for you, I would
> really really like to know.
>
> Note that transactions with nVersion=3 ("V3 transactions") are
> currently non-standard in Bitcoin Core. That means **anything that was
> standard before this policy change would still be standard
> afterwards.** If you don't want your transactions to be subject to
> these rules, just continue whatever you're doing and don't use
> nVersion=3. AFAICT this shouldn't break anything, but let me know if
> this would be disruptive for you?
>
> **New Policies:**
>
> This includes:
> - a set of additional policy rules applying to V3 transactions
> - modifications to package RBF rules
>
> **V3 transactions:**
>
> Existing standardness rules apply to V3 (e.g. min/max tx weight,
> standard output types, cleanstack, etc.). The following additional
> rules apply to V3:
>
> 1. A V3 transaction can be replaced, even if it does not signal BIP125
>    replaceability. (It must also meet the other RBF rules around fees,
> etc. for replacement to happen).
>
> 2. Any descendant of an unconfirmed V3 transaction must also be V3.
>
> *Rationale*: Combined with Rule 1, this gives us the property of
> "inherited" replaceability signaling when descendants of unconfirmed
> transactions are created. Additionally, checking whether a transaction
> signals replaceability this way does not require mempool traversal,
> and does not change based on what transactions are mined. It also
> makes subsequent rules about descendant limits much easier to check.
>
> *Note*: The descendant of a *confirmed* V3 transaction does not need to be
> V3.
>
> 3. An unconfirmed V3 transaction cannot have more than 1 descendant.
>
> *Rationale*: (Upper bound) the larger the descendant limit, the more
> transactions may need to be replaced. This is a problematic pinning
> attack, i.e., a malicious counterparty prevents the transaction from
> being replaced by adding many descendant transactions that aren't
> fee-bumping.
>
> (Lower bound) at least 1 descendant is required to allow CPFP of the
> presigned transaction. The contract protocol can create presigned
> transactions paying 0 fees and 1 output for attaching a CPFP at
> broadcast time ("anchor output"). Without package RBF, multiple anchor
> outputs would be required to allow each counterparty to fee-bump any
> presigned transaction. With package RBF, since the presigned
> transactions can replace each other, 1 anchor output is sufficient.
>
> 4. A V3 transaction that has an unconfirmed V3 ancestor cannot be
>    larger than 1000 virtual bytes.
>
> *Rationale*: (Upper bound) the larger the descendant size limit, the
> more vbytes may need to be replaced. With default limits, if the child
> is e.g. 100,000vB, that might be an additional 100,000sats (at
> 1sat/vbyte) or more, depending on the feerate.
>
> (Lower bound) the smaller this limit, the fewer UTXOs a child may use
> to fund this fee-bump. For example, only allowing the V3 child to have
> 2 inputs would require L2 protocols to manage a wallet with high-value
> UTXOs and make batched fee-bumping impossible. However, as the
> fee-bumping child only needs to fund fees (as opposed to payments),
> just a few UTXOs should suffice.
>
> With a limit of 1000 virtual bytes, depending on the output types, the
> child can have 6-15 UTXOs, which should be enough to fund a fee-bump
> without requiring a carefully-managed UTXO pool. With 1000 virtual
> bytes as the descendant limit, the cost to replace a V3 transaction
> has much lower variance.
>
> *Rationale*: This makes the rule very easily "tacked on" to existing
> logic for policy and wallets. A transaction may be up to 100KvB on its
> own (`MAX_STANDARD_TX_WEIGHT`) and 101KvB with descendants
> (`DEFAULT_DESCENDANT_SIZE_LIMIT_KVB`). If an existing V3 transaction
> in the mempool is 100KvB, its descendant can only be 1000vB, even if
> the policy is 10KvB.
>
> **Package RBF modifications:**
>
> 1. The rule around unconfirmed inputs was
> originally "A package may include new unconfirmed inputs, but the
> ancestor feerate of the child must be at least as high as the ancestor
> feerates of every transaction being replaced."
>
> The package may still include new unconfirmed inputs. However,
> the new rule is modified to be "The minimum between package feerate
> and ancestor feerate of the child is not lower than the individual
> feerates of all directly conflicting transactions and the ancestor
> feerates of all original transactions."
>
> *Rationale*: We are attempting to ensure that the replacement
> transactions are not less incentive-compatible to mine. However, a
> package/transaction's ancestor feerate is not perfectly representative
> of its incentive compatibility; it may overestimate (some subset of
> the ancestors could be included by itself if it has other high-feerate
> descendants or are themselves higher feerate than this
> package/transaction). Instead, we use the minimum between the package
> feerate and ancestor feerate of the child as a more conservative value
> than what was proposed originally.
>
> 2. A new rule is added, requiring that all package transactions with
> mempool conflicts to be V3. This also means the "sponsoring"
> child transaction must be V3.
>
> *Note*: Combined with the V3 rules, this means the package must be
> a child-with-parents package. Since package validation is only
> attempted if the transactions do not pay sufficient fees to be
> accepted on their own, this effectively means that only V3
> transactions can pay to replace their ancestors' conflicts, and only
> V3 transactions' replacements may be paid for by a descendant.
>
> *Rationale*: The fee-related rules are economically rational for
> ancestor packages, but not necessarily other types of packages.
> A child-with-parents package is a type of ancestor package. It
> may be fine to allow any ancestor package, but it's more difficult
> to account for all of the possibilities. For example, it gets much
> harder to see that we're applying the descendant limits correctly if
> the package has a gnarly, many-generation, non-tree shape. I'm also
> not sure if this policy is 100% incentive-compatible if the sponsor
> is not a direct descendant of the sponsee.
>
> Please see doc/policy/version3_transactions.md and
> doc/policy/packages.md in the PR for the full set of rules.
>
> **Intended usage for LN:**
>
> Commitment transactions should be V3 and have 1 anchor output. They
> can be signed with 0 fees (or 1sat/vbyte) once package relay is deployed
> on a significant portion of the network. If the commitment tx must
> be broadcast, determine the desired feerate at broadcast time and
> spend the anchor output in a high feerate transaction. I'm going to
> call the broadcasted commitment tx "the parent" and the attached
> fee-bumping tx "the child."
>
> - This child must be V3.
> - This child must be at most 1000vB. Note this restricts the
>   number of inputs you can use to fund the fee bump. Depending
> on the output types, this is around 6-15.
> - One child may fund fees for multiple commitment tx ("batched
>   fee-bumping").
> - To do a second fee-bump to add more fees, replace the
>   *child* with a higher-feerate tx. Do not try to attach a grandchild.
>
> Otherwise, never try to spend from an unconfirmed V3 transaction. The
> descendant limits for V3 transactions are very restrictive.
>
> **Expected Questions:**
>
> "Does this fix Rule 3 Pinning?"
> Yes. The V3 descendant limit restricts both you and your counterparty.
> Assuming nodes adopted this policy, you may reasonably assume that you
> only need to replace the commitment transaction + up to 1000vB.
>
> "Only 1 anchor output? What if I need to bump counterparty's commitment tx
> in mempool?"
> You won't need to fee-bump a counterparty's commitment tx using CPFP.
> You would just package RBF it by attaching a high-feerate child to
> your commitment tx.
>
> "Is this a privacy issue, i.e. doesn't it allow fingerprinting LN
> transactions based on nVersion?"
> Indeed it may be unrealistic to assume V3 transactions will be in
> widespread use outside of L2. IIUC, unilateral closes are already
> obvious LN transactions because of the HTLC inputs. For e.g.
> cooperative closes and opens, I think it makes sense to continue using
> V2. So, unless I'm missing something, this shouldn't make it worse.
>
> "So a V3 transaction that doesn't signal BIP125 replaceability is
> replaceable? Is that a backward compatibility issue?"
> Yes it's replaceable. It's not an issue AFAICT because,
> under previous policy, the V3 transaction wouldn't have been
> in the mempool in the first place.
>
> "Can a V2 transaction replace a V3 transaction and vice versa?"
> Yes, otherwise someone can use V3 transactions to censor V2
> transactions spending shared inputs. Note if the
> original V3 transaction has an unconfirmed V3 parent, this would
> violate the "inherited V3" rule and would be rejected.
>
> Thanks for reading! Feedback and review would be much appreciated.
>
> [1]:
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019464.html
> [2]:
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019817.html
>
> Best,
> Gloria
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220925/a8ab458a/attachment-0001.html>

From craigraw at gmail.com  Mon Sep 26 08:23:18 2022
From: craigraw at gmail.com (Craig Raw)
Date: Mon, 26 Sep 2022 10:23:18 +0200
Subject: [bitcoin-dev] BIP Proposal: Wallet Labels Export Format
In-Reply-To: <CAPR5oBNKQEPCAXcMoneGv2vLVmOLZGyxNEoZ4_=tyQT_mkAkmw@mail.gmail.com>
References: <CAPR5oBNKQEPCAXcMoneGv2vLVmOLZGyxNEoZ4_=tyQT_mkAkmw@mail.gmail.com>
Message-ID: <CAPR5oBNuja7L9VAx+YEB=JmcCGStA0tZonHOuaabkwe1nxzyyA@mail.gmail.com>

Following discussion with several wallet developers, I have come to the
conclusion that the secondary goal of managing labels in non-specialized
applications must be sacrificed in order to achieve the primary goal of
wide implementation across different wallets. While this tradeoff was
perhaps inevitable, it was worth a try!

As such I have rewritten the specification to use JSON, specifically the
JSON Lines format suggested by Ryan Havar and others (thank you). This
allows documents to be split or streamed, and is convenient for
command-line processing. The format is also now self describing via a type
field, permitting simple type identification (thank you Ali Sherief and
others). Public keys and xpubs have been added as types following further
suggestions. To keep the specification simple, compression and encryption
have been removed - with the strong recommendation to consider protecting
the data in a way suitable to its application.

The rewritten BIP can be found at
https://github.com/craigraw/bips/blob/master/bip-wallet-labels.mediawiki

It is perhaps simplest to understand it by looking at an example export:

{ "type": "tx", "ref":
"f91d0a8a78462bc59398f2c5d7a84fcff491c26ba54c4833478b202796c8aafd",
"label": "Transaction" }
{ "type": "addr", "ref": "bc1q34aq5drpuwy3wgl9lhup9892qp6svr8ldzyy7c",
"label": "Address" }
{ "type": "pubkey", "ref":
"0283409659355b6d1cc3c32decd5d561abaac86c37a353b52895a5e6c196d6f448",
"label": "Public Key" }
{ "type": "input", "ref":
"f91d0a8a78462bc59398f2c5d7a84fcff491c26ba54c4833478b202796c8aafd:0",
"label": "Input" }
{ "type": "output", "ref":
"f91d0a8a78462bc59398f2c5d7a84fcff491c26ba54c4833478b202796c8aafd:1",
"label": "Output" }
{ "type": "xpub", "ref":
"xpub661MyMwAqRbcFtXgS5sYJABqqG9YLmC4Q1Rdap9gSE8Nq...", "label": "Extended
Public Key" }

Feedback is always appreciated.

Craig


On Wed, Aug 24, 2022 at 11:18 AM Craig Raw <craigraw at gmail.com> wrote:

> Hi all,
>
> I would like to propose a BIP that specifies a format for the export and
> import of labels from a wallet. While transferring access to funds across
> wallet applications has been made simple through standards such as BIP39,
> wallet labels remain siloed and difficult to extract despite their value,
> particularly in a privacy context.
>
> The proposed format is a simple two column CSV file, with the reference to
> a transaction, address, input or output in the first column, and the label
> in the second column. CSV was chosen for its wide accessibility, especially
> to users without specific technical expertise. Similarly, the CSV file may
> be compressed using the ZIP format, and optionally encrypted using AES.
>
> The full text of the BIP can be found at
> https://github.com/craigraw/bips/blob/master/bip-wallet-labels.mediawiki
> and also copied below.
>
> Feedback is appreciated.
>
> Thanks,
> Craig Raw
>
> ---
>
> <pre>
>   BIP: wallet-labels
>   Layer: Applications
>   Title: Wallet Labels Export Format
>   Author: Craig Raw <craig at sparrowwallet.com>
>   Comments-Summary: No comments yet.
>   Comments-URI:
> https://github.com/bitcoin/bips/wiki/Comments:BIP-wallet-labels
>   Status: Draft
>   Type: Informational
>   Created: 2022-08-23
>   License: BSD-2-Clause
> </pre>
>
> ==Abstract==
>
> This document specifies a format for the export of labels that may be
> attached to the transactions, addresses, input and outputs in a wallet.
>
> ==Copyright==
>
> This BIP is licensed under the BSD 2-clause license.
>
> ==Motivation==
>
> The export and import of funds across different Bitcoin wallet
> applications is well defined through standards such as BIP39, BIP32, BIP44
> etc.
> These standards are well supported and allow users to move easily between
> different wallets.
> There is, however, no defined standard to transfer any labels the user may
> have applied to the transactions, addresses, inputs or outputs in their
> wallet.
> The UTXO model that Bitcoin uses makes these labels particularly valuable
> as they may indicate the source of funds, whether received externally or as
> a result of change from a prior transaction.
> In both cases, care must be taken when spending to avoid undesirable leaks
> of private information.
> Labels provide valuable guidance in this regard, and have even become
> mandatory when spending in several Bitcoin wallets.
> Allowing users to export their labels in a standardized way ensures that
> they do not experience lock-in to a particular wallet application.
> In addition, by using common formats, this BIP seeks to make manual or
> bulk management of labels accessible to users without specific technical
> expertise.
>
> ==Specification==
>
> In order to make the import and export of labels as widely accessible as
> possible, this BIP uses the comma separated values (CSV) format, which is
> widely supported by consumer, business, and scientific applications.
> Although the technical specification of CSV in RFC4180 is not always
> followed, the application of the format in this BIP is simple enough that
> compatibility should not present a problem.
> Moreover, the simplicity and forgiving nature of CSV (over for example
> JSON) lends itself well to bulk label editing using spreadsheet and text
> editing tools.
>
> A CSV export of labels from a wallet must be a UTF-8 encoded text file,
> containing one record per line, with records containing two fields
> delimited by a comma.
> The fields may be quoted, but this is unnecessary, as the first comma in
> the line will always be the delimiter.
> The first line in the file is a header, and should be ignored on import.
> Thereafter, each line represents a record that refers to a label applied
> in the wallet.
> The order in which these records appear is not defined.
>
> The first field in the record contains a reference to the transaction,
> address, input or output in the wallet.
> This is specified as one of the following:
> * Transaction ID (<tt>txid</tt>)
> * Address
> * Input (rendered as <tt>txid<index</tt>)
> * Output (rendered as <tt>txid>index</tt> or <tt>txid:index</tt>)
>
> The second field contains the label applied to the reference.
> Exporting applications may omit records with no labels or labels of zero
> length.
> Files exported should use the <tt>.csv</tt> file extension.
>
> In order to reduce file size while retaining wide accessibility, the CSV
> file may be compressed using the ZIP file format, using the <tt>.zip</tt>
> file extension.
> This <tt>.zip</tt> file may optionally be encrypted using either AES-128
> or AES-256 encryption, which is supported by numerous applications
> including Winzip and 7-zip.
> In order to ensure that weak encryption does not proliferate, importers
> following this standard must refuse to import <tt>.zip</tt> files encrypted
> with the weaker Zip 2.0 standard.
> The textual representation of the wallet's extended public key (as defined
> by BIP32, with an <tt>xpub</tt> header) should be used as the password.
>
> ==Importing==
>
> When importing, a naive algorithm may simply match against any reference,
> but it is possible to disambiguate between transactions, addresses, inputs
> and outputs.
> For example in the following pseudocode:
> <pre>
>   if reference length < 64
>     Set address label
>   else if reference length == 64
>     Set transaction label
>   else if reference contains '<'
>     Set input label
>   else
>     Set output label
> </pre>
>
> Importing applications may truncate labels if necessary.
>
> ==Test Vectors==
>
> The following fragment represents a wallet label export:
> <pre>
> Reference,Label
>
> c3bdad6e7dcd7997e16a5b7b7cf4d8f6079820ff2eedd5fcbb2ad088f767b37b?,Transaction
> 1A69TXnEM2ms9fMaY9UuiJ7415X7xZaUSg,Address
> c3bdad6e7dcd7997e16a5b7b7cf4d8f6079820ff2eedd5fcbb2ad088f767b37b?<0,Input
> c3bdad6e7dcd7997e16a5b7b7cf4d8f6079820ff2eedd5fcbb2ad088f767b37b?>0,Output
> c3bdad6e7dcd7997e16a5b7b7cf4d8f6079820ff2eedd5fcbb2ad088f767b37b?:0,Output
> (alternative)
> </pre>
>
> ==Reference Implementation==
>
> TBD
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220926/96cc3f8d/attachment.html>

From bastien at acinq.fr  Mon Sep 26 15:27:40 2022
From: bastien at acinq.fr (Bastien TEINTURIER)
Date: Mon, 26 Sep 2022 17:27:40 +0200
Subject: [bitcoin-dev] New transaction policies (nVersion=3) for
 contracting protocols
In-Reply-To: <CALZpt+HYUti=foo+d5ER7Wj=PxsfgaU2CEqqG4_KRxmsWoaSxw@mail.gmail.com>
References: <CAFXO6=KDys2_dsrdxE9_q_MVZJOFMbg-MctxiokcicP=wd4Lkw@mail.gmail.com>
 <CALZpt+HYUti=foo+d5ER7Wj=PxsfgaU2CEqqG4_KRxmsWoaSxw@mail.gmail.com>
Message-ID: <CACdvm3PyP9yrxx_Yewtx_yQh=i2uwGYj-wtY7HBER1bmG46NEw@mail.gmail.com>

Thanks Gloria for this great post.

This is very valuable work for L2 contracts, and will greatly improve
their security model.

> "Only 1 anchor output? What if I need to bump counterparty's commitment
tx in mempool?"
> You won't need to fee-bump a counterparty's commitment tx using CPFP.
> You would just package RBF it by attaching a high-feerate child to
> your commitment tx.

Note that we can also very easily make that single anchor spendable by
both participants (or even anyone), so if you see your counterparty's
commitment in your mempool, you can bump it without publishing your
own commitment, which is quite desirable (your own commitment tx has
CSV delays on your outputs, whereas your counterparty's commitment tx
doesn't).

> "Is this a privacy issue, i.e. doesn't it allow fingerprinting LN
transactions based on nVersion?"

I agree with you, this isn't worse than today, unilateral closes will
probably always be identifiable on-chain.

> Would kind of be nice if package RBF would detect a "sibling output spend"
> conflict, and knock it out of the mempool via the other replacement rules?
> Getting rid of the requirement to 1 block csv lock every output would be
> quite nice from a smart contracting composability point of view.

+1, that would be very neat!

This may be already covered by the current package RBF logic, in that
scenario we are simply replacing [ParentTx, ChildTx1] with
[ParentTx, ChildTx2] that pays more fees, right?

> 1) I do think that we should seriously consider allowing OP_TRUE to become
> a standard script type as part of this policy update. If pinning is
solved,
> then there's no reason to require all those extra bytes for "binding" an
> anchor to a specific wallet/user. We can save quite a few bytes by having
> the input be empty of witness data.
> 2) If we allow for a single dust-value(0 on up) output which is
immediately
> spent by the package, anchors become even easier to to design. No value
has
> to be "sapped" from contract participants to make an anchor output.
There's
> more complications for this, such as making sure the parent transaction is
> dropped if the child spend is dropped, but maybe it's worth the squeeze.

I also think both of these could be quite useful. This would probably always
be used in combination with a parent transaction that pays 0 fees, so the
0-value output would always be spent in the same block.

But this means we could end up with 0-value outputs in the utxo set, if for
some reason the parent tx is CPFP-ed via another output than the 0-value
one,
which would be a utxo set bloat issue. But I'd argue that we're probably
already creating utxo set bloat with the 330 sat anchor outputs (especially
since we use two of them, but only one is usually spent), so it would
probably be *better* than what we're doing today.

Thanks,
Bastien

Le lun. 26 sept. 2022 ? 03:22, Antoine Riard via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> a ?crit :

> Hi Gloria,
>
> Thanks for the progress on package RBF, few early questions.
>
> > 2. Any descendant of an unconfirmed V3 transaction must also be V3.
>
> > 3. An unconfirmed V3 transaction cannot have more than 1 descendant.
>
> If you're a miner and you receive a non-V3, second descendant of an
> unconfirmed V3 transaction, if the offered fee is in the top mempool
> backlog, I think you would have an interest to accept such a transaction.
>
> So I'm not sure if those two rules are compatible with miners incentives...
>
> > 4. A V3 transaction that has an unconfirmed V3 ancestor cannot be
> >    larger than 1000 virtual bytes.
>
> If I understand correctly the 1000 vb upper bound rational, it would be to
> constraint the pinning counterparty to attach a high fee to a child due to
> the limited size, if they would like this transaction to be stuck in the
> network mempools. By doing so  this child has high odds to confirm.
>
> I still wonder if this compatible with miner incentives in period of empty
> mempools, in the sense that if you've already a V3 transaction of size
> 100Kvb offering 2 sat/vb, it's more interesting than a V3 replacement
> candidate of size 1000 vb offering 10 sat/vb. It could be argued the former
> should be conserved.
>
> (That said, the hard thing with any replacement strategy we might evict a
> parent transaction *now* to which is attached a high-feerate child *latter*
> making for a utxo considered the best ancestor set. Maybe in the long-term
> miners should keep every transaction ever accepted...)
>
> > (Lower bound) the smaller this limit, the fewer UTXOs a child may use
> > to fund this fee-bump. For example, only allowing the V3 child to have
> > 2 inputs would require L2 protocols to manage a wallet with high-value
> > UTXOs and make batched fee-bumping impossible. However, as the
> > fee-bumping child only needs to fund fees (as opposed to payments),
> > just a few UTXOs should suffice.
>
> Reminder for L2 devs, batched fee-bumping of time-sensitive confirmations
> of commitment transactions is unsafe, as the counterparty could enter in a
> "cat-and-mouse" game to replace one of the batch element at each block to
> delay confirmation of the remaining elements in the batch, I think.
>
> On the other hand, I wonder if we wouldn't want a higher bound. LN wallets
> are likely to have one big UTXO in their fee-bumping reserve pool, as the
> cost of acquiring UTXO is non-null and in the optimistic case, you don't
> need to do unilateral closure. Let's say you close dozens of channels at
> the same time, a UTXO pool management strategy might be to fan-out the
> first spends UTXOs in N fan-out outputs ready to feed the remaining
> in-flight channels.
>
> > 1. The rule around unconfirmed inputs was
> > originally "A package may include new unconfirmed inputs, but the
> > ancestor feerate of the child must be at least as high as the ancestor
> > feerates of every transaction being replaced."
>
> Note, I think we would like this new RBF rule to also apply to single
> transaction package, e.g second-stage HTLC transactions, where a
> counterparty pins a HTLC-preimage by abusing rule 3. In that case, the
> honest LN node should be able to broadcast a "at least as high ancestor
> feerate" HTLC-timeout transaction. With `option_anchor_outputs" there is no
> unconfirmed ancestor to replace, as the commitment transaction, whatever
> the party it is originating from, should already be confirmed.
>
> > "Is this a privacy issue, i.e. doesn't it allow fingerprinting LN
> transactions based on nVersion?"
>
> As of today, I think yes you can already fingerprint LN transactions on
> the  spec-defined amount value of the anchor outputs, 330 sats. There is
> always one of them on post-anchor commitment transactions. And sadly I
> would say we'll always have tricky fingerprints leaking from unilateral LN
> closures such as HTLC/PTLC timelocks...
>
> > "Can a V2 transaction replace a V3 transaction and vice versa?"
>
> IIUC, a V3 package could replace a V2 package, with the benefit of the new
> package RBF rules applied. I think this would be a significant advantage
> for LN, as for the current ~85k of opened channels, the old V2 states
> shouldn't be pinning vectors. Currently, commitment transactions signal
> replaceability.
>
> Le ven. 23 sept. 2022 ? 11:26, Gloria Zhao via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> a ?crit :
>
>> Hi everyone,
>>
>> I'm writing to propose a very simple set of mempool/transaction relay
>> policies intended to aid L2/contract protocols. I realized that
>> the previously proposed Package Mempool Accept package RBF [1]
>> had a few remaining problems after digging into the RBF logic more [2].
>> This additional set of policies solves them without requiring a huge RBF
>> overhaul.
>>
>> I've written an implementation (and docs) for Bitcoin Core:
>> https://github.com/bitcoin/bitcoin/pull/25038
>>
>> (You may notice that this proposal incorporates feedback on the PR -
>> thanks Suhas Daftuar, Gregory Sanders, Bastien Teinturier, Anthony Towns,
>> and others.)
>>
>> If you are interested in using package RBF/relay to bump presigned
>> transactions, I think you may be interested in reviewing this proposal.
>> This should solve Rule 3 pinning and perhaps allow us
>> to get rid of CPFP carve-out (yay!). I'm keen to hear if people find
>> the 1-anchor-output, 1000vB child limit too restrictive. Also, if you
>> find a
>> pinning attack or something that makes it unusable for you, I would
>> really really like to know.
>>
>> Note that transactions with nVersion=3 ("V3 transactions") are
>> currently non-standard in Bitcoin Core. That means **anything that was
>> standard before this policy change would still be standard
>> afterwards.** If you don't want your transactions to be subject to
>> these rules, just continue whatever you're doing and don't use
>> nVersion=3. AFAICT this shouldn't break anything, but let me know if
>> this would be disruptive for you?
>>
>> **New Policies:**
>>
>> This includes:
>> - a set of additional policy rules applying to V3 transactions
>> - modifications to package RBF rules
>>
>> **V3 transactions:**
>>
>> Existing standardness rules apply to V3 (e.g. min/max tx weight,
>> standard output types, cleanstack, etc.). The following additional
>> rules apply to V3:
>>
>> 1. A V3 transaction can be replaced, even if it does not signal BIP125
>>    replaceability. (It must also meet the other RBF rules around fees,
>> etc. for replacement to happen).
>>
>> 2. Any descendant of an unconfirmed V3 transaction must also be V3.
>>
>> *Rationale*: Combined with Rule 1, this gives us the property of
>> "inherited" replaceability signaling when descendants of unconfirmed
>> transactions are created. Additionally, checking whether a transaction
>> signals replaceability this way does not require mempool traversal,
>> and does not change based on what transactions are mined. It also
>> makes subsequent rules about descendant limits much easier to check.
>>
>> *Note*: The descendant of a *confirmed* V3 transaction does not need to
>> be V3.
>>
>> 3. An unconfirmed V3 transaction cannot have more than 1 descendant.
>>
>> *Rationale*: (Upper bound) the larger the descendant limit, the more
>> transactions may need to be replaced. This is a problematic pinning
>> attack, i.e., a malicious counterparty prevents the transaction from
>> being replaced by adding many descendant transactions that aren't
>> fee-bumping.
>>
>> (Lower bound) at least 1 descendant is required to allow CPFP of the
>> presigned transaction. The contract protocol can create presigned
>> transactions paying 0 fees and 1 output for attaching a CPFP at
>> broadcast time ("anchor output"). Without package RBF, multiple anchor
>> outputs would be required to allow each counterparty to fee-bump any
>> presigned transaction. With package RBF, since the presigned
>> transactions can replace each other, 1 anchor output is sufficient.
>>
>> 4. A V3 transaction that has an unconfirmed V3 ancestor cannot be
>>    larger than 1000 virtual bytes.
>>
>> *Rationale*: (Upper bound) the larger the descendant size limit, the
>> more vbytes may need to be replaced. With default limits, if the child
>> is e.g. 100,000vB, that might be an additional 100,000sats (at
>> 1sat/vbyte) or more, depending on the feerate.
>>
>> (Lower bound) the smaller this limit, the fewer UTXOs a child may use
>> to fund this fee-bump. For example, only allowing the V3 child to have
>> 2 inputs would require L2 protocols to manage a wallet with high-value
>> UTXOs and make batched fee-bumping impossible. However, as the
>> fee-bumping child only needs to fund fees (as opposed to payments),
>> just a few UTXOs should suffice.
>>
>> With a limit of 1000 virtual bytes, depending on the output types, the
>> child can have 6-15 UTXOs, which should be enough to fund a fee-bump
>> without requiring a carefully-managed UTXO pool. With 1000 virtual
>> bytes as the descendant limit, the cost to replace a V3 transaction
>> has much lower variance.
>>
>> *Rationale*: This makes the rule very easily "tacked on" to existing
>> logic for policy and wallets. A transaction may be up to 100KvB on its
>> own (`MAX_STANDARD_TX_WEIGHT`) and 101KvB with descendants
>> (`DEFAULT_DESCENDANT_SIZE_LIMIT_KVB`). If an existing V3 transaction
>> in the mempool is 100KvB, its descendant can only be 1000vB, even if
>> the policy is 10KvB.
>>
>> **Package RBF modifications:**
>>
>> 1. The rule around unconfirmed inputs was
>> originally "A package may include new unconfirmed inputs, but the
>> ancestor feerate of the child must be at least as high as the ancestor
>> feerates of every transaction being replaced."
>>
>> The package may still include new unconfirmed inputs. However,
>> the new rule is modified to be "The minimum between package feerate
>> and ancestor feerate of the child is not lower than the individual
>> feerates of all directly conflicting transactions and the ancestor
>> feerates of all original transactions."
>>
>> *Rationale*: We are attempting to ensure that the replacement
>> transactions are not less incentive-compatible to mine. However, a
>> package/transaction's ancestor feerate is not perfectly representative
>> of its incentive compatibility; it may overestimate (some subset of
>> the ancestors could be included by itself if it has other high-feerate
>> descendants or are themselves higher feerate than this
>> package/transaction). Instead, we use the minimum between the package
>> feerate and ancestor feerate of the child as a more conservative value
>> than what was proposed originally.
>>
>> 2. A new rule is added, requiring that all package transactions with
>> mempool conflicts to be V3. This also means the "sponsoring"
>> child transaction must be V3.
>>
>> *Note*: Combined with the V3 rules, this means the package must be
>> a child-with-parents package. Since package validation is only
>> attempted if the transactions do not pay sufficient fees to be
>> accepted on their own, this effectively means that only V3
>> transactions can pay to replace their ancestors' conflicts, and only
>> V3 transactions' replacements may be paid for by a descendant.
>>
>> *Rationale*: The fee-related rules are economically rational for
>> ancestor packages, but not necessarily other types of packages.
>> A child-with-parents package is a type of ancestor package. It
>> may be fine to allow any ancestor package, but it's more difficult
>> to account for all of the possibilities. For example, it gets much
>> harder to see that we're applying the descendant limits correctly if
>> the package has a gnarly, many-generation, non-tree shape. I'm also
>> not sure if this policy is 100% incentive-compatible if the sponsor
>> is not a direct descendant of the sponsee.
>>
>> Please see doc/policy/version3_transactions.md and
>> doc/policy/packages.md in the PR for the full set of rules.
>>
>> **Intended usage for LN:**
>>
>> Commitment transactions should be V3 and have 1 anchor output. They
>> can be signed with 0 fees (or 1sat/vbyte) once package relay is deployed
>> on a significant portion of the network. If the commitment tx must
>> be broadcast, determine the desired feerate at broadcast time and
>> spend the anchor output in a high feerate transaction. I'm going to
>> call the broadcasted commitment tx "the parent" and the attached
>> fee-bumping tx "the child."
>>
>> - This child must be V3.
>> - This child must be at most 1000vB. Note this restricts the
>>   number of inputs you can use to fund the fee bump. Depending
>> on the output types, this is around 6-15.
>> - One child may fund fees for multiple commitment tx ("batched
>>   fee-bumping").
>> - To do a second fee-bump to add more fees, replace the
>>   *child* with a higher-feerate tx. Do not try to attach a grandchild.
>>
>> Otherwise, never try to spend from an unconfirmed V3 transaction. The
>> descendant limits for V3 transactions are very restrictive.
>>
>> **Expected Questions:**
>>
>> "Does this fix Rule 3 Pinning?"
>> Yes. The V3 descendant limit restricts both you and your counterparty.
>> Assuming nodes adopted this policy, you may reasonably assume that you
>> only need to replace the commitment transaction + up to 1000vB.
>>
>> "Only 1 anchor output? What if I need to bump counterparty's commitment
>> tx in mempool?"
>> You won't need to fee-bump a counterparty's commitment tx using CPFP.
>> You would just package RBF it by attaching a high-feerate child to
>> your commitment tx.
>>
>> "Is this a privacy issue, i.e. doesn't it allow fingerprinting LN
>> transactions based on nVersion?"
>> Indeed it may be unrealistic to assume V3 transactions will be in
>> widespread use outside of L2. IIUC, unilateral closes are already
>> obvious LN transactions because of the HTLC inputs. For e.g.
>> cooperative closes and opens, I think it makes sense to continue using
>> V2. So, unless I'm missing something, this shouldn't make it worse.
>>
>> "So a V3 transaction that doesn't signal BIP125 replaceability is
>> replaceable? Is that a backward compatibility issue?"
>> Yes it's replaceable. It's not an issue AFAICT because,
>> under previous policy, the V3 transaction wouldn't have been
>> in the mempool in the first place.
>>
>> "Can a V2 transaction replace a V3 transaction and vice versa?"
>> Yes, otherwise someone can use V3 transactions to censor V2
>> transactions spending shared inputs. Note if the
>> original V3 transaction has an unconfirmed V3 parent, this would
>> violate the "inherited V3" rule and would be rejected.
>>
>> Thanks for reading! Feedback and review would be much appreciated.
>>
>> [1]:
>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019464.html
>> [2]:
>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019817.html
>>
>> Best,
>> Gloria
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220926/d99c55d5/attachment-0001.html>

From gsanders87 at gmail.com  Mon Sep 26 16:01:54 2022
From: gsanders87 at gmail.com (Greg Sanders)
Date: Mon, 26 Sep 2022 12:01:54 -0400
Subject: [bitcoin-dev] New transaction policies (nVersion=3) for
 contracting protocols
In-Reply-To: <CACdvm3PyP9yrxx_Yewtx_yQh=i2uwGYj-wtY7HBER1bmG46NEw@mail.gmail.com>
References: <CAFXO6=KDys2_dsrdxE9_q_MVZJOFMbg-MctxiokcicP=wd4Lkw@mail.gmail.com>
 <CALZpt+HYUti=foo+d5ER7Wj=PxsfgaU2CEqqG4_KRxmsWoaSxw@mail.gmail.com>
 <CACdvm3PyP9yrxx_Yewtx_yQh=i2uwGYj-wtY7HBER1bmG46NEw@mail.gmail.com>
Message-ID: <CAB3F3Du=+YYKbfgB5LZPnCg40=5YCn_0tkpJ4LO9bMK0U-3wXg@mail.gmail.com>

Bastien,

> This may be already covered by the current package RBF logic, in that
scenario we are simply replacing [ParentTx, ChildTx1] with
[ParentTx, ChildTx2] that pays more fees, right?

For clarification, package RBF is ParentTx*s*(plural), and
ChildTx(singular), so it might be a bit more complicated than we're
thinking, and currently the V3 proposal would first de-duplicate the
ParentTx based on what is in the mempool, then look at the "rest" of the
transactions as a package, then individually. Not the same, not sure how
different. I'll defer to experts.

Best,
Greg

On Mon, Sep 26, 2022 at 11:48 AM Bastien TEINTURIER via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Thanks Gloria for this great post.
>
> This is very valuable work for L2 contracts, and will greatly improve
> their security model.
>
> > "Only 1 anchor output? What if I need to bump counterparty's commitment
> tx in mempool?"
> > You won't need to fee-bump a counterparty's commitment tx using CPFP.
> > You would just package RBF it by attaching a high-feerate child to
> > your commitment tx.
>
> Note that we can also very easily make that single anchor spendable by
> both participants (or even anyone), so if you see your counterparty's
> commitment in your mempool, you can bump it without publishing your
> own commitment, which is quite desirable (your own commitment tx has
> CSV delays on your outputs, whereas your counterparty's commitment tx
> doesn't).
>
> > "Is this a privacy issue, i.e. doesn't it allow fingerprinting LN
> transactions based on nVersion?"
>
> I agree with you, this isn't worse than today, unilateral closes will
> probably always be identifiable on-chain.
>
> > Would kind of be nice if package RBF would detect a "sibling output
> spend"
> > conflict, and knock it out of the mempool via the other replacement
> rules?
> > Getting rid of the requirement to 1 block csv lock every output would be
> > quite nice from a smart contracting composability point of view.
>
> +1, that would be very neat!
>
> This may be already covered by the current package RBF logic, in that
> scenario we are simply replacing [ParentTx, ChildTx1] with
> [ParentTx, ChildTx2] that pays more fees, right?
>
> > 1) I do think that we should seriously consider allowing OP_TRUE to
> become
> > a standard script type as part of this policy update. If pinning is
> solved,
> > then there's no reason to require all those extra bytes for "binding" an
> > anchor to a specific wallet/user. We can save quite a few bytes by having
> > the input be empty of witness data.
> > 2) If we allow for a single dust-value(0 on up) output which is
> immediately
> > spent by the package, anchors become even easier to to design. No value
> has
> > to be "sapped" from contract participants to make an anchor output.
> There's
> > more complications for this, such as making sure the parent transaction
> is
> > dropped if the child spend is dropped, but maybe it's worth the squeeze.
>
> I also think both of these could be quite useful. This would probably
> always
> be used in combination with a parent transaction that pays 0 fees, so the
> 0-value output would always be spent in the same block.
>
> But this means we could end up with 0-value outputs in the utxo set, if for
> some reason the parent tx is CPFP-ed via another output than the 0-value
> one,
> which would be a utxo set bloat issue. But I'd argue that we're probably
> already creating utxo set bloat with the 330 sat anchor outputs (especially
> since we use two of them, but only one is usually spent), so it would
> probably be *better* than what we're doing today.
>
> Thanks,
> Bastien
>
> Le lun. 26 sept. 2022 ? 03:22, Antoine Riard via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> a ?crit :
>
>> Hi Gloria,
>>
>> Thanks for the progress on package RBF, few early questions.
>>
>> > 2. Any descendant of an unconfirmed V3 transaction must also be V3.
>>
>> > 3. An unconfirmed V3 transaction cannot have more than 1 descendant.
>>
>> If you're a miner and you receive a non-V3, second descendant of an
>> unconfirmed V3 transaction, if the offered fee is in the top mempool
>> backlog, I think you would have an interest to accept such a transaction.
>>
>> So I'm not sure if those two rules are compatible with miners
>> incentives...
>>
>> > 4. A V3 transaction that has an unconfirmed V3 ancestor cannot be
>> >    larger than 1000 virtual bytes.
>>
>> If I understand correctly the 1000 vb upper bound rational, it would be
>> to constraint the pinning counterparty to attach a high fee to a child due
>> to the limited size, if they would like this transaction to be stuck in the
>> network mempools. By doing so  this child has high odds to confirm.
>>
>> I still wonder if this compatible with miner incentives in period of
>> empty mempools, in the sense that if you've already a V3 transaction of
>> size 100Kvb offering 2 sat/vb, it's more interesting than a V3 replacement
>> candidate of size 1000 vb offering 10 sat/vb. It could be argued the former
>> should be conserved.
>>
>> (That said, the hard thing with any replacement strategy we might evict a
>> parent transaction *now* to which is attached a high-feerate child *latter*
>> making for a utxo considered the best ancestor set. Maybe in the long-term
>> miners should keep every transaction ever accepted...)
>>
>> > (Lower bound) the smaller this limit, the fewer UTXOs a child may use
>> > to fund this fee-bump. For example, only allowing the V3 child to have
>> > 2 inputs would require L2 protocols to manage a wallet with high-value
>> > UTXOs and make batched fee-bumping impossible. However, as the
>> > fee-bumping child only needs to fund fees (as opposed to payments),
>> > just a few UTXOs should suffice.
>>
>> Reminder for L2 devs, batched fee-bumping of time-sensitive confirmations
>> of commitment transactions is unsafe, as the counterparty could enter in a
>> "cat-and-mouse" game to replace one of the batch element at each block to
>> delay confirmation of the remaining elements in the batch, I think.
>>
>> On the other hand, I wonder if we wouldn't want a higher bound. LN
>> wallets are likely to have one big UTXO in their fee-bumping reserve pool,
>> as the cost of acquiring UTXO is non-null and in the optimistic case, you
>> don't need to do unilateral closure. Let's say you close dozens of channels
>> at the same time, a UTXO pool management strategy might be to fan-out the
>> first spends UTXOs in N fan-out outputs ready to feed the remaining
>> in-flight channels.
>>
>> > 1. The rule around unconfirmed inputs was
>> > originally "A package may include new unconfirmed inputs, but the
>> > ancestor feerate of the child must be at least as high as the ancestor
>> > feerates of every transaction being replaced."
>>
>> Note, I think we would like this new RBF rule to also apply to single
>> transaction package, e.g second-stage HTLC transactions, where a
>> counterparty pins a HTLC-preimage by abusing rule 3. In that case, the
>> honest LN node should be able to broadcast a "at least as high ancestor
>> feerate" HTLC-timeout transaction. With `option_anchor_outputs" there is no
>> unconfirmed ancestor to replace, as the commitment transaction, whatever
>> the party it is originating from, should already be confirmed.
>>
>> > "Is this a privacy issue, i.e. doesn't it allow fingerprinting LN
>> transactions based on nVersion?"
>>
>> As of today, I think yes you can already fingerprint LN transactions on
>> the  spec-defined amount value of the anchor outputs, 330 sats. There is
>> always one of them on post-anchor commitment transactions. And sadly I
>> would say we'll always have tricky fingerprints leaking from unilateral LN
>> closures such as HTLC/PTLC timelocks...
>>
>> > "Can a V2 transaction replace a V3 transaction and vice versa?"
>>
>> IIUC, a V3 package could replace a V2 package, with the benefit of the
>> new package RBF rules applied. I think this would be a significant
>> advantage for LN, as for the current ~85k of opened channels, the old V2
>> states shouldn't be pinning vectors. Currently, commitment transactions
>> signal replaceability.
>>
>> Le ven. 23 sept. 2022 ? 11:26, Gloria Zhao via bitcoin-dev <
>> bitcoin-dev at lists.linuxfoundation.org> a ?crit :
>>
>>> Hi everyone,
>>>
>>> I'm writing to propose a very simple set of mempool/transaction relay
>>> policies intended to aid L2/contract protocols. I realized that
>>> the previously proposed Package Mempool Accept package RBF [1]
>>> had a few remaining problems after digging into the RBF logic more [2].
>>> This additional set of policies solves them without requiring a huge RBF
>>> overhaul.
>>>
>>> I've written an implementation (and docs) for Bitcoin Core:
>>> https://github.com/bitcoin/bitcoin/pull/25038
>>>
>>> (You may notice that this proposal incorporates feedback on the PR -
>>> thanks Suhas Daftuar, Gregory Sanders, Bastien Teinturier, Anthony Towns,
>>> and others.)
>>>
>>> If you are interested in using package RBF/relay to bump presigned
>>> transactions, I think you may be interested in reviewing this proposal.
>>> This should solve Rule 3 pinning and perhaps allow us
>>> to get rid of CPFP carve-out (yay!). I'm keen to hear if people find
>>> the 1-anchor-output, 1000vB child limit too restrictive. Also, if you
>>> find a
>>> pinning attack or something that makes it unusable for you, I would
>>> really really like to know.
>>>
>>> Note that transactions with nVersion=3 ("V3 transactions") are
>>> currently non-standard in Bitcoin Core. That means **anything that was
>>> standard before this policy change would still be standard
>>> afterwards.** If you don't want your transactions to be subject to
>>> these rules, just continue whatever you're doing and don't use
>>> nVersion=3. AFAICT this shouldn't break anything, but let me know if
>>> this would be disruptive for you?
>>>
>>> **New Policies:**
>>>
>>> This includes:
>>> - a set of additional policy rules applying to V3 transactions
>>> - modifications to package RBF rules
>>>
>>> **V3 transactions:**
>>>
>>> Existing standardness rules apply to V3 (e.g. min/max tx weight,
>>> standard output types, cleanstack, etc.). The following additional
>>> rules apply to V3:
>>>
>>> 1. A V3 transaction can be replaced, even if it does not signal BIP125
>>>    replaceability. (It must also meet the other RBF rules around fees,
>>> etc. for replacement to happen).
>>>
>>> 2. Any descendant of an unconfirmed V3 transaction must also be V3.
>>>
>>> *Rationale*: Combined with Rule 1, this gives us the property of
>>> "inherited" replaceability signaling when descendants of unconfirmed
>>> transactions are created. Additionally, checking whether a transaction
>>> signals replaceability this way does not require mempool traversal,
>>> and does not change based on what transactions are mined. It also
>>> makes subsequent rules about descendant limits much easier to check.
>>>
>>> *Note*: The descendant of a *confirmed* V3 transaction does not need to
>>> be V3.
>>>
>>> 3. An unconfirmed V3 transaction cannot have more than 1 descendant.
>>>
>>> *Rationale*: (Upper bound) the larger the descendant limit, the more
>>> transactions may need to be replaced. This is a problematic pinning
>>> attack, i.e., a malicious counterparty prevents the transaction from
>>> being replaced by adding many descendant transactions that aren't
>>> fee-bumping.
>>>
>>> (Lower bound) at least 1 descendant is required to allow CPFP of the
>>> presigned transaction. The contract protocol can create presigned
>>> transactions paying 0 fees and 1 output for attaching a CPFP at
>>> broadcast time ("anchor output"). Without package RBF, multiple anchor
>>> outputs would be required to allow each counterparty to fee-bump any
>>> presigned transaction. With package RBF, since the presigned
>>> transactions can replace each other, 1 anchor output is sufficient.
>>>
>>> 4. A V3 transaction that has an unconfirmed V3 ancestor cannot be
>>>    larger than 1000 virtual bytes.
>>>
>>> *Rationale*: (Upper bound) the larger the descendant size limit, the
>>> more vbytes may need to be replaced. With default limits, if the child
>>> is e.g. 100,000vB, that might be an additional 100,000sats (at
>>> 1sat/vbyte) or more, depending on the feerate.
>>>
>>> (Lower bound) the smaller this limit, the fewer UTXOs a child may use
>>> to fund this fee-bump. For example, only allowing the V3 child to have
>>> 2 inputs would require L2 protocols to manage a wallet with high-value
>>> UTXOs and make batched fee-bumping impossible. However, as the
>>> fee-bumping child only needs to fund fees (as opposed to payments),
>>> just a few UTXOs should suffice.
>>>
>>> With a limit of 1000 virtual bytes, depending on the output types, the
>>> child can have 6-15 UTXOs, which should be enough to fund a fee-bump
>>> without requiring a carefully-managed UTXO pool. With 1000 virtual
>>> bytes as the descendant limit, the cost to replace a V3 transaction
>>> has much lower variance.
>>>
>>> *Rationale*: This makes the rule very easily "tacked on" to existing
>>> logic for policy and wallets. A transaction may be up to 100KvB on its
>>> own (`MAX_STANDARD_TX_WEIGHT`) and 101KvB with descendants
>>> (`DEFAULT_DESCENDANT_SIZE_LIMIT_KVB`). If an existing V3 transaction
>>> in the mempool is 100KvB, its descendant can only be 1000vB, even if
>>> the policy is 10KvB.
>>>
>>> **Package RBF modifications:**
>>>
>>> 1. The rule around unconfirmed inputs was
>>> originally "A package may include new unconfirmed inputs, but the
>>> ancestor feerate of the child must be at least as high as the ancestor
>>> feerates of every transaction being replaced."
>>>
>>> The package may still include new unconfirmed inputs. However,
>>> the new rule is modified to be "The minimum between package feerate
>>> and ancestor feerate of the child is not lower than the individual
>>> feerates of all directly conflicting transactions and the ancestor
>>> feerates of all original transactions."
>>>
>>> *Rationale*: We are attempting to ensure that the replacement
>>> transactions are not less incentive-compatible to mine. However, a
>>> package/transaction's ancestor feerate is not perfectly representative
>>> of its incentive compatibility; it may overestimate (some subset of
>>> the ancestors could be included by itself if it has other high-feerate
>>> descendants or are themselves higher feerate than this
>>> package/transaction). Instead, we use the minimum between the package
>>> feerate and ancestor feerate of the child as a more conservative value
>>> than what was proposed originally.
>>>
>>> 2. A new rule is added, requiring that all package transactions with
>>> mempool conflicts to be V3. This also means the "sponsoring"
>>> child transaction must be V3.
>>>
>>> *Note*: Combined with the V3 rules, this means the package must be
>>> a child-with-parents package. Since package validation is only
>>> attempted if the transactions do not pay sufficient fees to be
>>> accepted on their own, this effectively means that only V3
>>> transactions can pay to replace their ancestors' conflicts, and only
>>> V3 transactions' replacements may be paid for by a descendant.
>>>
>>> *Rationale*: The fee-related rules are economically rational for
>>> ancestor packages, but not necessarily other types of packages.
>>> A child-with-parents package is a type of ancestor package. It
>>> may be fine to allow any ancestor package, but it's more difficult
>>> to account for all of the possibilities. For example, it gets much
>>> harder to see that we're applying the descendant limits correctly if
>>> the package has a gnarly, many-generation, non-tree shape. I'm also
>>> not sure if this policy is 100% incentive-compatible if the sponsor
>>> is not a direct descendant of the sponsee.
>>>
>>> Please see doc/policy/version3_transactions.md and
>>> doc/policy/packages.md in the PR for the full set of rules.
>>>
>>> **Intended usage for LN:**
>>>
>>> Commitment transactions should be V3 and have 1 anchor output. They
>>> can be signed with 0 fees (or 1sat/vbyte) once package relay is deployed
>>> on a significant portion of the network. If the commitment tx must
>>> be broadcast, determine the desired feerate at broadcast time and
>>> spend the anchor output in a high feerate transaction. I'm going to
>>> call the broadcasted commitment tx "the parent" and the attached
>>> fee-bumping tx "the child."
>>>
>>> - This child must be V3.
>>> - This child must be at most 1000vB. Note this restricts the
>>>   number of inputs you can use to fund the fee bump. Depending
>>> on the output types, this is around 6-15.
>>> - One child may fund fees for multiple commitment tx ("batched
>>>   fee-bumping").
>>> - To do a second fee-bump to add more fees, replace the
>>>   *child* with a higher-feerate tx. Do not try to attach a grandchild.
>>>
>>> Otherwise, never try to spend from an unconfirmed V3 transaction. The
>>> descendant limits for V3 transactions are very restrictive.
>>>
>>> **Expected Questions:**
>>>
>>> "Does this fix Rule 3 Pinning?"
>>> Yes. The V3 descendant limit restricts both you and your counterparty.
>>> Assuming nodes adopted this policy, you may reasonably assume that you
>>> only need to replace the commitment transaction + up to 1000vB.
>>>
>>> "Only 1 anchor output? What if I need to bump counterparty's commitment
>>> tx in mempool?"
>>> You won't need to fee-bump a counterparty's commitment tx using CPFP.
>>> You would just package RBF it by attaching a high-feerate child to
>>> your commitment tx.
>>>
>>> "Is this a privacy issue, i.e. doesn't it allow fingerprinting LN
>>> transactions based on nVersion?"
>>> Indeed it may be unrealistic to assume V3 transactions will be in
>>> widespread use outside of L2. IIUC, unilateral closes are already
>>> obvious LN transactions because of the HTLC inputs. For e.g.
>>> cooperative closes and opens, I think it makes sense to continue using
>>> V2. So, unless I'm missing something, this shouldn't make it worse.
>>>
>>> "So a V3 transaction that doesn't signal BIP125 replaceability is
>>> replaceable? Is that a backward compatibility issue?"
>>> Yes it's replaceable. It's not an issue AFAICT because,
>>> under previous policy, the V3 transaction wouldn't have been
>>> in the mempool in the first place.
>>>
>>> "Can a V2 transaction replace a V3 transaction and vice versa?"
>>> Yes, otherwise someone can use V3 transactions to censor V2
>>> transactions spending shared inputs. Note if the
>>> original V3 transaction has an unconfirmed V3 parent, this would
>>> violate the "inherited V3" rule and would be rejected.
>>>
>>> Thanks for reading! Feedback and review would be much appreciated.
>>>
>>> [1]:
>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019464.html
>>> [2]:
>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019817.html
>>>
>>> Best,
>>> Gloria
>>> _______________________________________________
>>> bitcoin-dev mailing list
>>> bitcoin-dev at lists.linuxfoundation.org
>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220926/7e18188a/attachment-0001.html>

From gloriajzhao at gmail.com  Mon Sep 26 16:47:49 2022
From: gloriajzhao at gmail.com (Gloria Zhao)
Date: Mon, 26 Sep 2022 17:47:49 +0100
Subject: [bitcoin-dev] New transaction policies (nVersion=3) for
 contracting protocols
In-Reply-To: <CAB3F3Du=+YYKbfgB5LZPnCg40=5YCn_0tkpJ4LO9bMK0U-3wXg@mail.gmail.com>
References: <CAFXO6=KDys2_dsrdxE9_q_MVZJOFMbg-MctxiokcicP=wd4Lkw@mail.gmail.com>
 <CALZpt+HYUti=foo+d5ER7Wj=PxsfgaU2CEqqG4_KRxmsWoaSxw@mail.gmail.com>
 <CACdvm3PyP9yrxx_Yewtx_yQh=i2uwGYj-wtY7HBER1bmG46NEw@mail.gmail.com>
 <CAB3F3Du=+YYKbfgB5LZPnCg40=5YCn_0tkpJ4LO9bMK0U-3wXg@mail.gmail.com>
Message-ID: <CAFXO6=JGBPVpxTJnSMWCCZVPHZW_RyWQ2Cv18Ao_F=uQx3LVkg@mail.gmail.com>

Hi Greg, Antoine, Bastien,

Thanks very much for the feedback! I interpret most of the discussion
around limitations as ideas for future improvements rather than criticisms
of the proposal (please correct me if I'm wrong). I'll try to respond to as
much as possible.

Also I realize that I didn't contextualize this proposal clearly enough; it
is very tailored for LN Penalty and definitely doesn't close all pinning
attacks possible (sorry for confusing anyone). I also agree that some bits
can be a little ugly or tack-on; I would definitely prefer a comprehensive
RBF revamp to fix all our problems and enable other fee-bumping strategies
such as
sign-ANYONECANPAY-then-bring-your-own-fees-by-adding-inputs-at-broadcast. I
was hoping to get some ideas with the "RBF Improvements" post in January,
but it doesn't seem like we're much closer to a workable proposal. I think
this is a minimally-invasive step that works for Lightning today, a small
fix similar to CPFP carve out.

> As you likely know from previous discussions the biggest scenario this
does not fix in my estimation is ANYONECANPAY situations. If the parent
transaction can be "inflated" by tacking on additional inputs, this means
the total weight of the parent tx lowers the effective feerate of the
package.

(For more context to other readers I wrote an explanation for this in
"SIGHASH_ANYONECANPAY Pinning" section of RBF ML post).  Yes, this
unfortunately doesn't fix any of the existing pinning attacks for single
transaction RBF but also doesn't make them worse. This boils down to adding
an incentive compatibility rule that ensures you can't replace a
transaction with something that will confirm slower. Package RBF has an
ancestor feerate-based rule for this (note it is quite conservative and not
perfect).

So in the scenario above with the "inflated" parent that was signed ACP,
the replacement would be rejected because the package ancestor feerate is
lower than the feerate of what is being replaced. But it is imperfect
(explained below) and thus I wouldn't recommend it for single transaction
replacement. So that attack still exists for single transactions, yes.

The strategy of using ACP to bring-your-own-fees has its own challenges but
hopefully has no current use cases as you say. AFAIK LN Penalty is not
affected by this since it doesn't use ACP, though obviously I agree we
should fix it for the future.

So when I said "this is intended for fee-bumping presigned txns in
contracting protocols," I should have said "this is intended for
fee-bumping presigned txns specifically using CPFP and anchor outputs."
Apologies for forgetting to contextualize, I've been sitting on this for
too long.

> The other scenario it doesn't really fix is where HTLC/commitment-like
transactions are being resolved in a batch, but due to relative time
constraints, you may want to accelerate some and not others. Now you must
pay higher rates to replace all of the transaction bumps. This is a
"self-pin" and "get good at utxos noob" type problem, but it's something
that axing rule#3 in favor of a Replace-by-ancestor-feerate system would
get us.

I understand you to mean "if you don't have enough UTXOs and you're forced
to batch-bump, you over-pay because you need to bring them all to the
highest target feerate." Isn't this kind of separate, wallet-related
problem? Contracting or not, surely every wallet needs to have enough UTXOs
to not batch transactions that shouldn't be batched... I don't see how a
replace-by-ancestor-feerate policy would make any difference for this?

Also in general I'd like to reiterate that ancestor feerate is not a
panacea to all our RBF incentive compatibility concerns. Like individual
feerate, unless we run the mining algorithm, it cannot tell us exactly how
quickly this transaction would be mined.

We're estimating the incentive compatibility of the original transaction(s)
and replacement transaction(s), with the goal of not letting a transaction
replace something that would have been more incentive compatible to mine.
As such, we don't want to overestimate how good the replacement is, and we
don't want to underestimate how good the original transactions are. This
rule "The minimum between package feerate and ancestor feerate of the child
is not lower than the individual feerates of all directly conflicting
transactions and the ancestor feerates of all original transactions" is a
conservative estimate.

> Would kind of be nice if package RBF would detect a "sibling output
spend" conflict, and knock it out of the mempool via the other replacement
rules? Getting rid of the requirement to 1 block csv lock every output
would be quite nice from a smart contracting composability point of view.

Interesting, so when a transaction hits a mempool tx's descendant limit, we
consider evicting one of its descendants in favor of this transaction,
based on the RBF rules.
Cool idea! After chewing on this for a bit, I think this *also* just boils
down to the fact that RBF should require replacements to be better mining
candidates. As in, if we added this policy and it can make us evict the
sibling and accept a transaction with a bunch of low-feerate ancestor junk,
it would be a new pinning vector.

> If you're a miner and you receive a non-V3, second descendant of an
unconfirmed V3 transaction, if the offered fee is in the top mempool
backlog, I think you would have an interest to accept such a transaction.

> So I'm not sure if those two rules are compatible with miners
incentives...

The same argument can be made for the 26th descendant of a mempool
transaction; it's also not entirely incentive-compatible to reject it, but
that is not the *only* design goal in mempool policy. Of course, the
difference here is that the 25-descendant limit rule is a sensible DoS
protection, while this 1-descendant limit rule is more of a "help the
Bitcoin ecosystem" policy, just like CPFP carve-out, dust limit, etc. I can
of course understand why not everyone would be in favor of this, but I do
think it's worth it.

> > 4. A V3 transaction that has an unconfirmed V3 ancestor cannot be
> >    larger than 1000 virtual bytes.

> If I understand correctly the 1000 vb upper bound rational, it would be
to constraint the pinning counterparty to attach a high fee to a child due
to the limited size, if they would like this transaction to be stuck in the
network mempools. By doing so  this child has high odds to confirm.

Yeah exactly, the "Rule 3 pin" is done by adding a child that's high-fee
(so you have to pay that much to evict it). Because they *don't* want this
tx to confirm, normally, this child would be really large. If they only
have 1000vB for the child, they can't increase the replacement cost without
also fee-bumping the transaction to make it confirm faster.

> As of today, I think yes you can already fingerprint LN transactions on
the  spec-defined amount value of the anchor outputs, 330 sats. There is
always one of them on post-anchor commitment transactions. And sadly I
would say we'll always have tricky fingerprints leaking from unilateral LN
closures such as HTLC/PTLC timelocks...

> I agree with you, this isn't worse than today, unilateral closes will
probably always be identifiable on-chain.

Great to hear that there is no privacy worsening!

Best,
Gloria

On Mon, Sep 26, 2022 at 5:02 PM Greg Sanders <gsanders87 at gmail.com> wrote:

> Bastien,
>
> > This may be already covered by the current package RBF logic, in that
> scenario we are simply replacing [ParentTx, ChildTx1] with
> [ParentTx, ChildTx2] that pays more fees, right?
>
> For clarification, package RBF is ParentTx*s*(plural), and
> ChildTx(singular), so it might be a bit more complicated than we're
> thinking, and currently the V3 proposal would first de-duplicate the
> ParentTx based on what is in the mempool, then look at the "rest" of the
> transactions as a package, then individually. Not the same, not sure how
> different. I'll defer to experts.
>
> Best,
> Greg
>
> On Mon, Sep 26, 2022 at 11:48 AM Bastien TEINTURIER via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>> Thanks Gloria for this great post.
>>
>> This is very valuable work for L2 contracts, and will greatly improve
>> their security model.
>>
>> > "Only 1 anchor output? What if I need to bump counterparty's commitment
>> tx in mempool?"
>> > You won't need to fee-bump a counterparty's commitment tx using CPFP.
>> > You would just package RBF it by attaching a high-feerate child to
>> > your commitment tx.
>>
>> Note that we can also very easily make that single anchor spendable by
>> both participants (or even anyone), so if you see your counterparty's
>> commitment in your mempool, you can bump it without publishing your
>> own commitment, which is quite desirable (your own commitment tx has
>> CSV delays on your outputs, whereas your counterparty's commitment tx
>> doesn't).
>>
>> > "Is this a privacy issue, i.e. doesn't it allow fingerprinting LN
>> transactions based on nVersion?"
>>
>> I agree with you, this isn't worse than today, unilateral closes will
>> probably always be identifiable on-chain.
>>
>> > Would kind of be nice if package RBF would detect a "sibling output
>> spend"
>> > conflict, and knock it out of the mempool via the other replacement
>> rules?
>> > Getting rid of the requirement to 1 block csv lock every output would be
>> > quite nice from a smart contracting composability point of view.
>>
>> +1, that would be very neat!
>>
>> This may be already covered by the current package RBF logic, in that
>> scenario we are simply replacing [ParentTx, ChildTx1] with
>> [ParentTx, ChildTx2] that pays more fees, right?
>>
>> > 1) I do think that we should seriously consider allowing OP_TRUE to
>> become
>> > a standard script type as part of this policy update. If pinning is
>> solved,
>> > then there's no reason to require all those extra bytes for "binding" an
>> > anchor to a specific wallet/user. We can save quite a few bytes by
>> having
>> > the input be empty of witness data.
>> > 2) If we allow for a single dust-value(0 on up) output which is
>> immediately
>> > spent by the package, anchors become even easier to to design. No value
>> has
>> > to be "sapped" from contract participants to make an anchor output.
>> There's
>> > more complications for this, such as making sure the parent transaction
>> is
>> > dropped if the child spend is dropped, but maybe it's worth the squeeze.
>>
>> I also think both of these could be quite useful. This would probably
>> always
>> be used in combination with a parent transaction that pays 0 fees, so the
>> 0-value output would always be spent in the same block.
>>
>> But this means we could end up with 0-value outputs in the utxo set, if
>> for
>> some reason the parent tx is CPFP-ed via another output than the 0-value
>> one,
>> which would be a utxo set bloat issue. But I'd argue that we're probably
>> already creating utxo set bloat with the 330 sat anchor outputs
>> (especially
>> since we use two of them, but only one is usually spent), so it would
>> probably be *better* than what we're doing today.
>>
>> Thanks,
>> Bastien
>>
>> Le lun. 26 sept. 2022 ? 03:22, Antoine Riard via bitcoin-dev <
>> bitcoin-dev at lists.linuxfoundation.org> a ?crit :
>>
>>> Hi Gloria,
>>>
>>> Thanks for the progress on package RBF, few early questions.
>>>
>>> > 2. Any descendant of an unconfirmed V3 transaction must also be V3.
>>>
>>> > 3. An unconfirmed V3 transaction cannot have more than 1 descendant.
>>>
>>> If you're a miner and you receive a non-V3, second descendant of an
>>> unconfirmed V3 transaction, if the offered fee is in the top mempool
>>> backlog, I think you would have an interest to accept such a transaction.
>>>
>>> So I'm not sure if those two rules are compatible with miners
>>> incentives...
>>>
>>> > 4. A V3 transaction that has an unconfirmed V3 ancestor cannot be
>>> >    larger than 1000 virtual bytes.
>>>
>>> If I understand correctly the 1000 vb upper bound rational, it would be
>>> to constraint the pinning counterparty to attach a high fee to a child due
>>> to the limited size, if they would like this transaction to be stuck in the
>>> network mempools. By doing so  this child has high odds to confirm.
>>>
>>> I still wonder if this compatible with miner incentives in period of
>>> empty mempools, in the sense that if you've already a V3 transaction of
>>> size 100Kvb offering 2 sat/vb, it's more interesting than a V3 replacement
>>> candidate of size 1000 vb offering 10 sat/vb. It could be argued the former
>>> should be conserved.
>>>
>>> (That said, the hard thing with any replacement strategy we might evict
>>> a parent transaction *now* to which is attached a high-feerate child
>>> *latter* making for a utxo considered the best ancestor set. Maybe in the
>>> long-term miners should keep every transaction ever accepted...)
>>>
>>> > (Lower bound) the smaller this limit, the fewer UTXOs a child may use
>>> > to fund this fee-bump. For example, only allowing the V3 child to have
>>> > 2 inputs would require L2 protocols to manage a wallet with high-value
>>> > UTXOs and make batched fee-bumping impossible. However, as the
>>> > fee-bumping child only needs to fund fees (as opposed to payments),
>>> > just a few UTXOs should suffice.
>>>
>>> Reminder for L2 devs, batched fee-bumping of time-sensitive
>>> confirmations of commitment transactions is unsafe, as the counterparty
>>> could enter in a "cat-and-mouse" game to replace one of the batch element
>>> at each block to delay confirmation of the remaining elements in the batch,
>>> I think.
>>>
>>> On the other hand, I wonder if we wouldn't want a higher bound. LN
>>> wallets are likely to have one big UTXO in their fee-bumping reserve pool,
>>> as the cost of acquiring UTXO is non-null and in the optimistic case, you
>>> don't need to do unilateral closure. Let's say you close dozens of channels
>>> at the same time, a UTXO pool management strategy might be to fan-out the
>>> first spends UTXOs in N fan-out outputs ready to feed the remaining
>>> in-flight channels.
>>>
>>> > 1. The rule around unconfirmed inputs was
>>> > originally "A package may include new unconfirmed inputs, but the
>>> > ancestor feerate of the child must be at least as high as the ancestor
>>> > feerates of every transaction being replaced."
>>>
>>> Note, I think we would like this new RBF rule to also apply to single
>>> transaction package, e.g second-stage HTLC transactions, where a
>>> counterparty pins a HTLC-preimage by abusing rule 3. In that case, the
>>> honest LN node should be able to broadcast a "at least as high ancestor
>>> feerate" HTLC-timeout transaction. With `option_anchor_outputs" there is no
>>> unconfirmed ancestor to replace, as the commitment transaction, whatever
>>> the party it is originating from, should already be confirmed.
>>>
>>> > "Is this a privacy issue, i.e. doesn't it allow fingerprinting LN
>>> transactions based on nVersion?"
>>>
>>> As of today, I think yes you can already fingerprint LN transactions on
>>> the  spec-defined amount value of the anchor outputs, 330 sats. There is
>>> always one of them on post-anchor commitment transactions. And sadly I
>>> would say we'll always have tricky fingerprints leaking from unilateral LN
>>> closures such as HTLC/PTLC timelocks...
>>>
>>> > "Can a V2 transaction replace a V3 transaction and vice versa?"
>>>
>>> IIUC, a V3 package could replace a V2 package, with the benefit of the
>>> new package RBF rules applied. I think this would be a significant
>>> advantage for LN, as for the current ~85k of opened channels, the old V2
>>> states shouldn't be pinning vectors. Currently, commitment transactions
>>> signal replaceability.
>>>
>>> Le ven. 23 sept. 2022 ? 11:26, Gloria Zhao via bitcoin-dev <
>>> bitcoin-dev at lists.linuxfoundation.org> a ?crit :
>>>
>>>> Hi everyone,
>>>>
>>>> I'm writing to propose a very simple set of mempool/transaction relay
>>>> policies intended to aid L2/contract protocols. I realized that
>>>> the previously proposed Package Mempool Accept package RBF [1]
>>>> had a few remaining problems after digging into the RBF logic more [2].
>>>> This additional set of policies solves them without requiring a huge
>>>> RBF overhaul.
>>>>
>>>> I've written an implementation (and docs) for Bitcoin Core:
>>>> https://github.com/bitcoin/bitcoin/pull/25038
>>>>
>>>> (You may notice that this proposal incorporates feedback on the PR -
>>>> thanks Suhas Daftuar, Gregory Sanders, Bastien Teinturier, Anthony Towns,
>>>> and others.)
>>>>
>>>> If you are interested in using package RBF/relay to bump presigned
>>>> transactions, I think you may be interested in reviewing this proposal.
>>>> This should solve Rule 3 pinning and perhaps allow us
>>>> to get rid of CPFP carve-out (yay!). I'm keen to hear if people find
>>>> the 1-anchor-output, 1000vB child limit too restrictive. Also, if you
>>>> find a
>>>> pinning attack or something that makes it unusable for you, I would
>>>> really really like to know.
>>>>
>>>> Note that transactions with nVersion=3 ("V3 transactions") are
>>>> currently non-standard in Bitcoin Core. That means **anything that was
>>>> standard before this policy change would still be standard
>>>> afterwards.** If you don't want your transactions to be subject to
>>>> these rules, just continue whatever you're doing and don't use
>>>> nVersion=3. AFAICT this shouldn't break anything, but let me know if
>>>> this would be disruptive for you?
>>>>
>>>> **New Policies:**
>>>>
>>>> This includes:
>>>> - a set of additional policy rules applying to V3 transactions
>>>> - modifications to package RBF rules
>>>>
>>>> **V3 transactions:**
>>>>
>>>> Existing standardness rules apply to V3 (e.g. min/max tx weight,
>>>> standard output types, cleanstack, etc.). The following additional
>>>> rules apply to V3:
>>>>
>>>> 1. A V3 transaction can be replaced, even if it does not signal BIP125
>>>>    replaceability. (It must also meet the other RBF rules around fees,
>>>> etc. for replacement to happen).
>>>>
>>>> 2. Any descendant of an unconfirmed V3 transaction must also be V3.
>>>>
>>>> *Rationale*: Combined with Rule 1, this gives us the property of
>>>> "inherited" replaceability signaling when descendants of unconfirmed
>>>> transactions are created. Additionally, checking whether a transaction
>>>> signals replaceability this way does not require mempool traversal,
>>>> and does not change based on what transactions are mined. It also
>>>> makes subsequent rules about descendant limits much easier to check.
>>>>
>>>> *Note*: The descendant of a *confirmed* V3 transaction does not need to
>>>> be V3.
>>>>
>>>> 3. An unconfirmed V3 transaction cannot have more than 1 descendant.
>>>>
>>>> *Rationale*: (Upper bound) the larger the descendant limit, the more
>>>> transactions may need to be replaced. This is a problematic pinning
>>>> attack, i.e., a malicious counterparty prevents the transaction from
>>>> being replaced by adding many descendant transactions that aren't
>>>> fee-bumping.
>>>>
>>>> (Lower bound) at least 1 descendant is required to allow CPFP of the
>>>> presigned transaction. The contract protocol can create presigned
>>>> transactions paying 0 fees and 1 output for attaching a CPFP at
>>>> broadcast time ("anchor output"). Without package RBF, multiple anchor
>>>> outputs would be required to allow each counterparty to fee-bump any
>>>> presigned transaction. With package RBF, since the presigned
>>>> transactions can replace each other, 1 anchor output is sufficient.
>>>>
>>>> 4. A V3 transaction that has an unconfirmed V3 ancestor cannot be
>>>>    larger than 1000 virtual bytes.
>>>>
>>>> *Rationale*: (Upper bound) the larger the descendant size limit, the
>>>> more vbytes may need to be replaced. With default limits, if the child
>>>> is e.g. 100,000vB, that might be an additional 100,000sats (at
>>>> 1sat/vbyte) or more, depending on the feerate.
>>>>
>>>> (Lower bound) the smaller this limit, the fewer UTXOs a child may use
>>>> to fund this fee-bump. For example, only allowing the V3 child to have
>>>> 2 inputs would require L2 protocols to manage a wallet with high-value
>>>> UTXOs and make batched fee-bumping impossible. However, as the
>>>> fee-bumping child only needs to fund fees (as opposed to payments),
>>>> just a few UTXOs should suffice.
>>>>
>>>> With a limit of 1000 virtual bytes, depending on the output types, the
>>>> child can have 6-15 UTXOs, which should be enough to fund a fee-bump
>>>> without requiring a carefully-managed UTXO pool. With 1000 virtual
>>>> bytes as the descendant limit, the cost to replace a V3 transaction
>>>> has much lower variance.
>>>>
>>>> *Rationale*: This makes the rule very easily "tacked on" to existing
>>>> logic for policy and wallets. A transaction may be up to 100KvB on its
>>>> own (`MAX_STANDARD_TX_WEIGHT`) and 101KvB with descendants
>>>> (`DEFAULT_DESCENDANT_SIZE_LIMIT_KVB`). If an existing V3 transaction
>>>> in the mempool is 100KvB, its descendant can only be 1000vB, even if
>>>> the policy is 10KvB.
>>>>
>>>> **Package RBF modifications:**
>>>>
>>>> 1. The rule around unconfirmed inputs was
>>>> originally "A package may include new unconfirmed inputs, but the
>>>> ancestor feerate of the child must be at least as high as the ancestor
>>>> feerates of every transaction being replaced."
>>>>
>>>> The package may still include new unconfirmed inputs. However,
>>>> the new rule is modified to be "The minimum between package feerate
>>>> and ancestor feerate of the child is not lower than the individual
>>>> feerates of all directly conflicting transactions and the ancestor
>>>> feerates of all original transactions."
>>>>
>>>> *Rationale*: We are attempting to ensure that the replacement
>>>> transactions are not less incentive-compatible to mine. However, a
>>>> package/transaction's ancestor feerate is not perfectly representative
>>>> of its incentive compatibility; it may overestimate (some subset of
>>>> the ancestors could be included by itself if it has other high-feerate
>>>> descendants or are themselves higher feerate than this
>>>> package/transaction). Instead, we use the minimum between the package
>>>> feerate and ancestor feerate of the child as a more conservative value
>>>> than what was proposed originally.
>>>>
>>>> 2. A new rule is added, requiring that all package transactions with
>>>> mempool conflicts to be V3. This also means the "sponsoring"
>>>> child transaction must be V3.
>>>>
>>>> *Note*: Combined with the V3 rules, this means the package must be
>>>> a child-with-parents package. Since package validation is only
>>>> attempted if the transactions do not pay sufficient fees to be
>>>> accepted on their own, this effectively means that only V3
>>>> transactions can pay to replace their ancestors' conflicts, and only
>>>> V3 transactions' replacements may be paid for by a descendant.
>>>>
>>>> *Rationale*: The fee-related rules are economically rational for
>>>> ancestor packages, but not necessarily other types of packages.
>>>> A child-with-parents package is a type of ancestor package. It
>>>> may be fine to allow any ancestor package, but it's more difficult
>>>> to account for all of the possibilities. For example, it gets much
>>>> harder to see that we're applying the descendant limits correctly if
>>>> the package has a gnarly, many-generation, non-tree shape. I'm also
>>>> not sure if this policy is 100% incentive-compatible if the sponsor
>>>> is not a direct descendant of the sponsee.
>>>>
>>>> Please see doc/policy/version3_transactions.md and
>>>> doc/policy/packages.md in the PR for the full set of rules.
>>>>
>>>> **Intended usage for LN:**
>>>>
>>>> Commitment transactions should be V3 and have 1 anchor output. They
>>>> can be signed with 0 fees (or 1sat/vbyte) once package relay is deployed
>>>> on a significant portion of the network. If the commitment tx must
>>>> be broadcast, determine the desired feerate at broadcast time and
>>>> spend the anchor output in a high feerate transaction. I'm going to
>>>> call the broadcasted commitment tx "the parent" and the attached
>>>> fee-bumping tx "the child."
>>>>
>>>> - This child must be V3.
>>>> - This child must be at most 1000vB. Note this restricts the
>>>>   number of inputs you can use to fund the fee bump. Depending
>>>> on the output types, this is around 6-15.
>>>> - One child may fund fees for multiple commitment tx ("batched
>>>>   fee-bumping").
>>>> - To do a second fee-bump to add more fees, replace the
>>>>   *child* with a higher-feerate tx. Do not try to attach a grandchild.
>>>>
>>>> Otherwise, never try to spend from an unconfirmed V3 transaction. The
>>>> descendant limits for V3 transactions are very restrictive.
>>>>
>>>> **Expected Questions:**
>>>>
>>>> "Does this fix Rule 3 Pinning?"
>>>> Yes. The V3 descendant limit restricts both you and your counterparty.
>>>> Assuming nodes adopted this policy, you may reasonably assume that you
>>>> only need to replace the commitment transaction + up to 1000vB.
>>>>
>>>> "Only 1 anchor output? What if I need to bump counterparty's commitment
>>>> tx in mempool?"
>>>> You won't need to fee-bump a counterparty's commitment tx using CPFP.
>>>> You would just package RBF it by attaching a high-feerate child to
>>>> your commitment tx.
>>>>
>>>> "Is this a privacy issue, i.e. doesn't it allow fingerprinting LN
>>>> transactions based on nVersion?"
>>>> Indeed it may be unrealistic to assume V3 transactions will be in
>>>> widespread use outside of L2. IIUC, unilateral closes are already
>>>> obvious LN transactions because of the HTLC inputs. For e.g.
>>>> cooperative closes and opens, I think it makes sense to continue using
>>>> V2. So, unless I'm missing something, this shouldn't make it worse.
>>>>
>>>> "So a V3 transaction that doesn't signal BIP125 replaceability is
>>>> replaceable? Is that a backward compatibility issue?"
>>>> Yes it's replaceable. It's not an issue AFAICT because,
>>>> under previous policy, the V3 transaction wouldn't have been
>>>> in the mempool in the first place.
>>>>
>>>> "Can a V2 transaction replace a V3 transaction and vice versa?"
>>>> Yes, otherwise someone can use V3 transactions to censor V2
>>>> transactions spending shared inputs. Note if the
>>>> original V3 transaction has an unconfirmed V3 parent, this would
>>>> violate the "inherited V3" rule and would be rejected.
>>>>
>>>> Thanks for reading! Feedback and review would be much appreciated.
>>>>
>>>> [1]:
>>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019464.html
>>>> [2]:
>>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019817.html
>>>>
>>>> Best,
>>>> Gloria
>>>> _______________________________________________
>>>> bitcoin-dev mailing list
>>>> bitcoin-dev at lists.linuxfoundation.org
>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>>
>>> _______________________________________________
>>> bitcoin-dev mailing list
>>> bitcoin-dev at lists.linuxfoundation.org
>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220926/f053868f/attachment-0001.html>

From alicexbt at protonmail.com  Mon Sep 26 17:50:48 2022
From: alicexbt at protonmail.com (alicexbt)
Date: Mon, 26 Sep 2022 17:50:48 +0000
Subject: [bitcoin-dev] Packaged Transaction Relay
In-Reply-To: <005e01d87b89$3d99df60$b8cd9e20$@voskuil.org>
References: <005e01d87b89$3d99df60$b8cd9e20$@voskuil.org>
Message-ID: <EDCbz3IJLDkExNWyM1WLLSh5qUioK6HdMEh-eofWmete0baz1lo8uF1YFzLaTXxgQhzvtDtqpX2mTMaDpB7_4-SRNnpJX4F8zgL5e6NGS0U=@protonmail.com>

Hi Eric,


This email wasn't answered by anyone on mailing list however I did some research about packages yesterday including this email and below are my observations, questions etc.

> The sole objective, as expressed in the OP proposal, is to:
> 
> "Propagate transactions that are incentive-compatible to mine, even if they don't meet minimum feerate alone."


According to [bitcoinops][1]: Without package relay, it?s not possible to effectively CPFP fee bump a transaction that?s below the minimum feerate nodes accept.

Matt Corallo's thoughts in a bitcoin core [issue][2]:

"Matt Corallo recently wrote about an example on the bitcoin-dev mailing list involving lightning transactions, where pre-signed transactions might be broadcast to the blockchain long after they were generated, and thus not have been created with a fee that is sufficient to be confirmed quickly (or even be accepted to node mempools). In such situations, channel participants may need to use chained transactions (CPFP) in order to increase the confirmation speed of such transactions, and that implies we may need to introduce a mechanism for those parent transactions to be relayed along with their higher feerate children, even if the parent transaction would be rejected by itself."

1)Is it possible to have multiple pre-signed transactions with different fee rates in a range? Example: PSBT1: 5 sat/vbyte, PSBT2: 10 sat/vbyte, PSBT3: 20 sat/vbyte and PSBT4: 100 sat/vbyte
2)How would covenants affect this problem?
3)How often does it happen that a pre-signed tx gets rejected by nodes because it did not meet the minimum fee rate? Is it predictable and could be managed in a different way?

After reading several links related to packages and bitcoin core pull requests, I found it anti-bitcoin to introduce so much complexity because its not possible to CPFP fee bump a tx below minimum fee rate. 


> Furthermore any tx that is "stuck" can be freed by simply sending another tx. The nodes at which the tx has become stuck will just package it up and relay it to peers. In other words, there is no impact on wallet implementation apart from raising the aggregate fee using a descendant transaction.

It is easy to send another tx if there is only one user involved however packages are trying to fix issues in which multiple users and transaction pre-signed between them are involved. So, it will be difficult to coordinate and create new pre-signed transactions in some cases although it is possible for some use cases.


> This is barely a protocol change - it's primarily implementation. All that should be required is an additional INV element type, such as MSG_TX_PACKAGE.

> * All elements of MSG_TX_PACKAGE in one INV message MUST to be of the same package.
> * A package MUST must define a set that can be mined into one block (size/sigops constraint).
> * A package SHOULD not contain confirmed txs (a race may cause this).
> * A package MUST minimally satisfy peer.feerate.
> * A partial tx order, as in the manner of the block.txs ordering, MUST be imposed.
> * A node SHOULD drop a peer that sends a package (or tx) below node.feerate.
> * A node MAY drop a peer that sends a non-minimal package according to node.feerate.

This makes sense particularly if multiple node implementations are used in future. 

My other questions:

a)If a package has tx1, tx2, tx3, tx4 and tx5 and miner just include tx1 and tx2 in the block, how does this affect the projects considered for packages proposal?

b)How does changing the order of txs in a package affect these transactions?

c)Do packages introduce more attack vectors in bitcoin for front running or MEV? MEV in bitcoin currently only affects the projects that are considered in packages proposal.

d)What if the package contains a transactions with sanctioned address?

e)Why would miners use packages if the existing scenario in terms of fees per block is beneficial for them?


/dev/fd0

[1]: https://bitcoinops.org/en/topics/package-relay/
[2]: https://github.com/bitcoin/bitcoin/issues/14895

Sent with Proton Mail secure email.

------- Original Message -------
On Thursday, June 9th, 2022 at 4:13 AM, Eric Voskuil via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:


> Hi Suhas/Gloria,
> 
> Good questions. I've started a new thread because it became something else...
> 
> Various ideas about packaging seem to be focused on the idea of an atomic message that is gossiped around the network like a transaction or block. From my perspective that seems to create a set of problems without good solutions, and it is not a proper analogy to those atomic structures. It may be worth taking the time to step back and take a close look at the underlying objective.
> 
> The sole objective, as expressed in the OP proposal, is to:
> 
> "Propagate transactions that are incentive-compatible to mine, even if they don't meet minimum feerate alone."
> 
> Effectively producing this outcome with an atomic packaging approach while at the same time maintaining network invariants seems unlikely, if not impossible.
> 
> Fees:
> 
> A node knows what fee rate a peer will accept, and announces individual txs that satisfy peer.feerate. Similarly a node knows its own feerate, and SHOULD drop any peer that announces txs that do not satisfy node.feerate.
> 
> Orphans:
> 
> A node MAY drop a peer that announces txs that the node sees as orphans against its DAG. It SHOULD drop the orphan tx and MAY request missing ancestors. Presumably after some amount of time connected to peer, node does not expect to see any more orphans from that peer, so these choices could evolve with the channel. However, the design that can only consider each tx in isolation will continue to cause orphan announcements on the channel. A below peer.feerate tx does not get announced to peer, and later a descendant high peer.feerate does get announced to the peer - as an orphan.
> 
> BIP133 (feefilter):
> 
> "There could be a small number of edge cases where a node's mempool min fee is actually less than the filter value a peer is aware of and transactions with fee rates between these values will now be newly inhibited."
> 
> https://github.com/bitcoin/bips/blob/master/bip-0133.mediawiki
> 
> Whether the problem is "small" or not depends on the disparity between node fee rates, which is not a matter of protocol. This is an existing problem that can and should be dealt with in packaging, as part of the above objective.
> 
> Packaged Transaction Relay:
> 
> One might instead think of packaging as a per-connection function, operating over its transaction (input->output) DAG and the feerate of its own node and that of the peer. Logically a "package" is nothing more than a set of transactions (optimized by announcement). Only a node can effectively determine the packaging required by each of its peers, since only the node is aware of peer.feerate.
> 
> 
> The only way to avoid dead-ending packages (including individual transactions, as is the objective) is for a node to package txs for each peer. The origination of any package is then just a wallet peer doing what a node does - packaging transactions that satisfy peer.feerate (i.e. that of its node).
> 
> Current transaction relay (txB->txA):
> 
> ===============================
> Node0
> txA.feerate > node.feerate, and not orphaned (accept txA)
> 
> txA.feerate > peer1.feerate (announce txA to peer1)
> 
> txA.feerate < peer2.feerate (do not announce txA to peer2)
> -----
> txB.feerate > node.feerate (accept txB)
> 
> txB.feerate > peer1.feerate (announce txB to peer1)
> 
> txB.feerate > peer2.feerate (announce txB to peer2)
> 
> 
> Node1
> Sees/accepts txA and txB.
> 
> Node2
> Never sees txA, sees/rejects txB (as an orphan).
> 
> Packaged transaction relay (txB->txA):
> 
> ===============================
> Node0
> txA.feerate > node.feerate, and not orphaned (accept txA)
> 
> txA.feerate > peer1.feerate (announce txA to peer1)
> 
> txA.feerate < peer2.feerate (do not announce txA to peer2)
> -----
> txB.feerate > node1.feerate (accept txB)
> 
> txB.feerate > peer1.feerate (announce txB to peer1)
> 
> txB.feerate > peer2.feerate (do not announce txB to peer2) <== avoid predictable orphan
> 
> txA.feerate + txB.feerate > peer2.feerate (announce pkg(A, B) to peer2) <= create minimal package
> 
> 
> Node1
> Sees/accepts txA and txB.
> 
> Node2
> pkg(A, B) > node2.feerate (accept txA, txB)
> 
> txA.feerate > peer3.feerate (announce txA to peer3)
> 
> txB.feerate > peer3.feerate (announce txB to peer3)
> 
> 
> Sees/accepts pkg(A, B).
> 
> Node3
> Sees/accepts txA and txB. <= avoided unnecessary packaging
> 
> Summary:
> 
> In this design, any node that receives an announcement for a pkg (or tx) later determined to be less than node.feerate SHOULD drop the announcing peer. Unlike with existing tx relay, a node can become "current" and subsequently see few if any tx or pkg orphans, and MAY at some point decide to drop any peer that announces one. Notice that packages are created dynamically, and any package that doesn't need to be grouped gets trimmed down to individual transactions. Furthermore any tx that is "stuck" can be freed by simply sending another tx. The nodes at which the tx has become stuck will just package it up and relay it to peers. In other words, there is no impact on wallet implementation apart from raising the aggregate fee using a descendant transaction.
> 
> This is barely a protocol change - it's primarily implementation. All that should be required is an additional INV element type, such as MSG_TX_PACKAGE.
> 
> Additional constraints:
> 
> * All elements of MSG_TX_PACKAGE in one INV message MUST to be of the same package.
> * A package MUST must define a set that can be mined into one block (size/sigops constraint).
> * A package SHOULD not contain confirmed txs (a race may cause this).
> * A package MUST minimally satisfy peer.feerate.
> * A partial tx order, as in the manner of the block.txs ordering, MUST be imposed.
> * A node SHOULD drop a peer that sends a package (or tx) below node.feerate.
> * A node MAY drop a peer that sends a non-minimal package according to node.feerate.
> 
> The partial ordering of block.txs introduces an ordering constraint that precludes full parallelism in validating input attachment. This is an implementation artifact that made its way into consensus. However in the case of packaging, the set of txs is not presumed to be valid under the proof of work DoS guard. As such constraints should minimize the work/traffic required to invalidate the message. The partial order constraint ensures that the DAG can be built incrementally, dropping the attempt (and peer as desired) as soon as the first orphan is discovered. As a result the network traffic and work required is not materially different than with tx relay, with two exceptions.
> 
> These are the two central aspects of this approach (Avoiding Predictable Orphans and Creating Minimal Packages). These are graph search algorithms, some basic computer science. Minimality requires only that the package does not introduce txs that are not necessary to reach the peer.feerate (as these can always be packaged separately). It does not require that nodes all generate the same packages. It does not require negotiation, package identity, cryptography, or hashing. As a graph search it should be O(n) where n is the unconfirmed ancestry of the package, but should typically be much lower, if not a single step.
> 
> Sufficiently-low-fee nodes will see only single txs. Moderate-fee nodes may cause partial breakup of packages. Sufficiently high fee nodes will cause peers (having received and completed the acceptance of a tx/pkg with pkg.feerate < peer.feerate) to navigate from each tx/package external input until reaching txs above peer.feerate, or confirmed (both of which the peer is presumed to already have). If the pkg.feerate is sufficiently high to connect all external inputs to the intervening txs, they are added to the package and it is announced to the high fee peer. Note that the individual tx.feerate > peer.feerate is insufficient to ensure that the peer should have the tx, as there may be ancestor txs that do not, and for which the tx was insufficient to cause them to be packaged. So a non-caching algorithm must be able to chase each package external input to a confirmed tx (or cache the unconfirmed ancestry fee rate at each tx). Note that fee rates are not directly additive, both size/
> 
> weight and fee are required for summation (and aggregate sigops should be considered).
> 
> This makes no assumptions about current implementations. The design would call for maintenance of a transaction (input->output) DAG with tx.feerate on each tx. This could be the unconfirmed tx graph (i.e. "memory pool") though it does not require maintenance of anything more than the parameters necessary to confirm a set of validated txs within a block. It is very reasonable to require this of any participating node. A simple version negotiation can identify a package-accepting/sending nodes.
> 
> 
> I have thought about this for some time, but have not implemented either the graph search, source code, or BIP. Just wrote this off the top of my head. So I am sure there are some things I have incorrect or failed to consider. But I think it's worth discussing it at this point.
> 
> e
> 
> > -----Original Message-----
> > From: bitcoin-dev bitcoin-dev-bounces at lists.linuxfoundation.org On
> > Behalf Of Suhas Daftuar via bitcoin-dev
> > Sent: Wednesday, June 8, 2022 8:59 AM
> > To: Bitcoin Protocol Discussion bitcoin-dev at lists.linuxfoundation.org
> > Subject: Re: [bitcoin-dev] Package Relay Proposal
> > 
> > Hi,
> > 
> > Thanks again for your work on this!
> > 
> > One question I have is about potential bandwidth waste in the case of nodes
> > running with different policy rules. Here's my understanding of a scenario I
> > think could happen:
> > 
> > 1) Transaction A is both low-fee and non-standard to some nodes on the
> > network.
> > 2) Whenever a transaction T that spends A is relayed, new nodes will send
> > INV(PKGINFO1, T) to all package-relay peers.
> > 3) Nodes on the network that have implemented package relay, but do not
> > accept A, will send getdata(PKGINFO1, T) and learn all of T's unconfirmed
> > parents (~32 bytes * number of parents(T)).
> > 4) Such nodes will reject T. But because of transaction malleability, and to
> > avoid being blinded to a transaction unnecessarily, these nodes will likely still
> > send getdata(PKGINFO1, T) to every node that announces T, in case
> > someone has a transaction that includes an alternate set of parent
> > transactions that would pass policy checks.
> > 
> > Is that understanding correct? I think a good design goal would be to not
> > waste bandwidth in non-adversarial situations. In this case, there would be
> > bandwidth waste from downloading duplicate data from all your peers, just
> > because the announcement doesn't commit to the set of parent wtxids that
> > we'd get from the peer (and so we are unable to determine that all our peers
> > would be telling us the same thing, just based on the announcement).
> > 
> > Some ways to mitigate this might be to: (a) include a hash (maybe even just a
> > 20-byte hash -- is that enough security?) of the package wtxids (in some
> > canonical ordering) along with the wtxid of the child in the initial
> > announcement; (b) limit the use of v1 packages to transactions with very few
> > parents (I don't know if this is reasonable for the use cases we have in mind).
> > 
> > Another point I wanted to bring up is about the rules around v1 package
> > validation generally, and the use of a blockhash in transaction relay
> > specifically. My first observation is that it won't always be the case that a v1
> > package relay node will be able to validate that a set of package transactions
> > is fully sorted topologically, because there may be (non-parent) ancestors
> > that are missing from the package and the best a peer can validate is
> > topology within the package -- this means that a peer can validly (under this
> > BIP) relay transaction packages out of the true topological sort (if all
> > ancestors were included).
> > 
> > This makes me wonder how useful this topological rule is. I suppose there is
> > some value in preventing completely broken implementations from staying
> > connected and so there is no harm in having the rule, but perhaps it would
> > be helpful to add that nodes SHOULD order transactions based on topological
> > sort in the complete transaction graph, so that if missing-from-package
> > ancestors are already known by a peer (which is the expected case when
> > using v1 package relay on transactions that have more than one generation
> > of unconfirmed ancestor) then the remaining transactions are already
> > properly ordered, and this is helpful even if unenforceable in general.
> > 
> > The other observation I wanted to make was that having transaction relay
> > gated on whether two nodes agree on chain tip seems like an overly
> > restrictive criteria. I think an important design principle is that we want to
> > minimize disruption from network splits -- if there are competing blocks
> > found in a small window of time, it's likely that the utxo set is not materially
> > different on the two chains (assuming miners are selecting from roughly the
> > same sets of transactions when this happens, which is typical). Having
> > transaction relay bifurcate on the two network halves would seem to
> > exacerbate the difference between the two sides of the split -- users ought
> > to be agnostic about how benign splits are resolved and would likely want
> > their transactions to relay across the whole network.
> > 
> > Additionally, use of a chain tip might impose a larger burden than is necessary
> > on software that would seek to participate in transaction relay without
> > implementing headers sync/validation. I don't know what software exists on
> > the network, but I imagine there are a lot of scripts out there for transaction
> > submission to the public p2p network, and in thinking about modifying such a
> > script to utilize package relay it seems like an unnecessary added burden to
> > first learn a node's tip before trying to relay a transaction.
> > 
> > Could you explain again what the benefit of including the blockhash is? It
> > seems like it is just so that a node could prioritize transaction relay from
> > peers with the same chain tip to maximize the likelihood of transaction
> > acceptance, but in the common case this seems like a pretty negligible
> > concern, and in the case of a chain fork that persists for many minutes it
> > seems better to me that we not partition the network into package-relay
> > regimes and just risk a little extra bandwidth in one direction or the other. If
> > we solve the problem I brought up at the beginning (of de-duplicating
> > package data across peers with a package-wtxid-commitment in the
> > announcement), I think this is just some wasted pkginfo bandwidth on a
> > single-link, and not across links (as we could cache validation failure for a
> > package-hash to avoid re-requesting duplicate pkginfo1 messages).
> > 
> > Best,
> > Suhas
> > 
> > On Tue, Jun 7, 2022 at 1:57 PM Gloria Zhao via bitcoin-dev <bitcoin-
> > dev at lists.linuxfoundation.org <mailto:bitcoin-
> > dev at lists.linuxfoundation.org> > wrote:
> > 
> > Hi Eric, aj, all,
> > 
> > Sorry for the delayed response. @aj I'm including some paraphrased
> > points from our offline discussion (thanks).
> > 
> > > Other idea: what if you encode the parent txs as a short hash of the
> > > wtxid (something like bip152 short ids? perhaps seeded per peer so collisions
> > > will be different per peer?) and include that in the inv announcement?
> > > Would that work to avoid a round trip almost all of the time, while still giving
> > > you enough info to save bw by deduping parents?
> > 
> > > As I suggested earlier, a package is fundamentally a compact block
> > > (or
> > > block) announcement without the header. Compact block (BIP152)
> > > announcement
> > > is already well-defined and widely implemented...
> > 
> > > Let us not reinvent the wheel and/or introduce accidental
> > > complexity. I see
> > > no reason why packaging is not simply BIP152 without the 'header'
> > > field, an
> > > updated protocol version, and the following sort of changes to
> > > names
> > 
> > Interestingly, "why not use BIP 152 shortids to save bandwidth?" is
> > by far the most common suggestion I hear (including offline feedback).
> > Here's a full explanation:
> > 
> > BIP 152 shortens transaction hashes (32 bytes) to shortids (6 bytes)
> > to save a significant amount of network bandwidth, which is extremely
> > important in block relay. However, this comes at the expense of
> > computational complexity. There is no way to directly calculate a transaction
> > hash from a shortid; upon receipt of a compact block, a node is expected to
> > calculate the shortids of every unconfirmed transaction it knows about to
> > find the matches (BIP 152: 1, Bitcoin Core: [2]). This is expensive but
> > appropriate for block relay, since the block must have a valid Proof of Work
> > and new blocks only come every ~10 minutes. On the other hand, if we
> > require nodes to calculate shortids for every transaction in their mempools
> > every time they receive a package, we are creating a DoS vector.
> > Unconfirmed transactions don't need PoW and, to have a live transaction
> > relay network, we should expect nodes to handle transactions at a high-ish
> > rate (i.e. at least 1000s of times more transactions than blocks). We can't pre-
> > calculate or cache shortids for mempool transactions, since the SipHash key
> > depends on the block hash and a per-connection salt.
> > 
> > Additionally, shortid calculation is not designed to prevent intentional
> > individual collisions. If we were to use these shortids to deduplicate
> > transactions we've supposedly already seen, we may have a censorship
> > vector. Again, these tradeoffs make sense for compact block relay (see
> > shortid section in BIP 152 [3]), but not package relay.
> > 
> > TLDR: DoSy if we calculate shortids on every package and censorship
> > vector if we use shortids for deduplication.
> > 
> > > Given this message there is no reason
> > > to send a (potentially bogus) fee rate with every package. It can
> > > only be
> > > validated by obtaining the full set of txs, and the only recourse is
> > > dropping (etc.) the peer, as is the case with single txs.
> > 
> > Yeah, I agree with this. Combined with the previous discussion with
> > aj (i.e. we can't accurately communicate the incentive compatibility of a
> > package without sending the full graph, and this whole dance is to avoid
> > downloading a few low-fee transactions in uncommon edge cases), I've
> > realized I should remove the fee + weight information from pkginfo. Yay for
> > less complexity!
> > 
> > Also, this might be pedantic, but I said something incorrect earlier
> > and would like to correct myself:
> > 
> > > > In theory, yes, but maybe it was announced earlier (while our
> > > > node was down?) or had dropped from our mempool or similar, either way
> > > > we don't have those txs yet.
> > 
> > I said "It's fine if they have Erlay, since a sender would know in
> > advance that B is missing and announce it as a package." But this isn't true
> > since we're only using reconciliation in place of flooding to announce
> > transactions as they arrive, not for rebroadcast, and we're not doing full
> > mempool set reconciliation. In any case, making sure a node receives the
> > transactions announced when it was offline is not something we guarantee,
> > not an intended use case for package relay, and not worsened by this.
> > 
> > Thanks for your feedback!
> > 
> > Best,
> > 
> > Gloria
> > 
> > 0152.mediawiki#cmpctblock
> > [2]:
> > https://github.com/bitcoin/bitcoin/blob/master/src/blockencodings.cpp#L49
> > [3]: https://github.com/bitcoin/bips/blob/master/bip-
> > 0152.mediawiki#short-transaction-id-calculation
> > 
> > On Thu, May 26, 2022 at 3:59 AM <eric at voskuil.org
> > mailto:eric at voskuil.org > wrote:
> > 
> > Given that packages have no header, the package requires
> > identity in a
> > BIP152 scheme. For example 'header' and 'blockhash' fields
> > can be replaced
> > with a Merkle root (e.g. "identity" field) for the package,
> > uniquely
> > identifying the partially-ordered set of txs. And use of
> > 'getdata' (to
> > obtain a package by hash) can be eliminated (not a use case).
> > 
> > e
> > 
> > > -----Original Message-----
> > > From: eric at voskuil.org mailto:eric at voskuil.org
> > <eric at voskuil.org mailto:eric at voskuil.org >
> > > Sent: Wednesday, May 25, 2022 1:52 PM
> > > To: 'Anthony Towns' <aj at erisian.com.au
> > mailto:aj at erisian.com.au >; 'Bitcoin Protocol Discussion'
> > > <bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-
> > dev at lists.linuxfoundation.org> >; 'Gloria Zhao'
> > > <gloriajzhao at gmail.com mailto:gloriajzhao at gmail.com >
> > > Subject: RE: [bitcoin-dev] Package Relay Proposal
> > >
> > > > From: bitcoin-dev <bitcoin-dev-
> > bounces at lists.linuxfoundation.org <mailto:bitcoin-dev-
> > bounces at lists.linuxfoundation.org> > On
> > > Behalf
> > > > Of Anthony Towns via bitcoin-dev
> > > > Sent: Wednesday, May 25, 2022 11:56 AM
> > >
> > > > So the other thing is what happens if the peer
> > announcing packages to us
> > > is
> > > > dishonest?
> > > >
> > > > They announce pkg X, say X has parents A B C and the fee
> > rate is
> > garbage.
> > > But
> > > > actually X has parent D and the fee rate is excellent. Do
> > we request the
> > > > package from another peer, or every peer, to double
> > check? Otherwise
> > > we're
> > > > allowing the first peer we ask about a package to censor
> > that tx from
> > us?
> > > >
> > > > I think the fix for that is just to provide the fee and weight
> > when
> > > announcing
> > > > the package rather than only being asked for its info?
> > Then if one peer
> > > makes
> > > > it sound like a good deal you ask for the parent txids from
> > them,
> > dedupe,
> > > > request, and verify they were honest about the parents.
> > >
> > > Single tx broadcasts do not carry an advertised fee rate,
> > however the'
> > > feefilter' message (BIP133) provides this distinction. This
> > should be
> > > interpreted as applicable to packages. Given this message
> > there is no
> > reason
> > > to send a (potentially bogus) fee rate with every package. It
> > can only be
> > > validated by obtaining the full set of txs, and the only
> > recourse is
> > > dropping (etc.) the peer, as is the case with single txs.
> > Relying on the
> > > existing message is simpler, more consistent, and more
> > efficient.
> > >
> > > > >> Is it plausible to add the graph in?
> > > >
> > > > Likewise, I think you'd have to have the graph info from
> > many nodes if
> > > you're
> > > > going to make decisions based on it and don't want
> > hostile peers to be
> > > able to
> > > > trick you into ignoring txs.
> > > >
> > > > Other idea: what if you encode the parent txs as a short
> > hash of the
> > wtxid
> > > > (something like bip152 short ids? perhaps seeded per
> > peer so collisions
> > > will
> > > > be different per peer?) and include that in the inv
> > announcement? Would
> > > > that work to avoid a round trip almost all of the time,
> > while still
> > giving
> > > you
> > > > enough info to save bw by deduping parents?
> > >
> > > As I suggested earlier, a package is fundamentally a
> > compact block (or
> > > block) announcement without the header. Compact block
> > (BIP152)
> > > announcement
> > > is already well-defined and widely implemented. A node
> > should never be
> > > required to retain an orphan, and BIP152 ensures this is not
> > required.
> > >
> > > Once a validated set of txs within the package has been
> > obtained with
> > > sufficient fee, a fee-optimal node would accept the largest
> > subgraph of
> > the
> > > package that conforms to fee constraints and drop any
> > peer that provides a
> > > package for which the full graph does not.
> > >
> > > Let us not reinvent the wheel and/or introduce accidental
> > complexity. I
> > see
> > > no reason why packaging is not simply BIP152 without the
> > 'header' field,
> > an
> > > updated protocol version, and the following sort of changes
> > to names:
> > >
> > > sendpkg
> > > MSG_CMPCT_PKG
> > > cmpctpkg
> > > getpkgtxn
> > > pkgtxn
> > >
> > > > > For a maximum 25 transactions,
> > > > >2324/2 = 276, seems like 36 bytes for a child-with-
> > parents package.
> > > >
> > > > If you're doing short ids that's maybe 254B=100B
> > already, then the
> > above
> > > is
> > > > up to 36% overhead, I guess. Might be worth thinking
> > more about, but
> > > maybe
> > > > more interesting with ancestors than just parents.
> > > >
> > > > >Also side note, since there are no size/count params,
> > >
> > > Size is restricted in the same manner as block and
> > transaction broadcasts,
> > > by consensus. If the fee rate is sufficient there would be no
> > reason to
> > > preclude any valid size up to what can be mined in one
> > block (packaging
> > > across blocks is not economically rational under the
> > assumption that one
> > > miner cannot expect to mine multiple blocks in a row).
> > Count is
> > incorporated
> > > into BIP152 as 'shortids_length'.
> > >
> > > > > wondering if we
> > > > >should just have "version" in "sendpackages" be a bit
> > field instead of
> > > > >sending a message for each version. 32 versions should
> > be enough right?
> > >
> > > Adding versioning to individual protocols is just a reflection
> > of the
> > > insufficiency of the initial protocol versioning design, and
> > that of the
> > > various ad-hoc changes to it (including yet another
> > approach in this
> > > proposal) that have been introduced to compensate for it,
> > though I'll
> > > address this in an independent post at some point.
> > >
> > > Best,
> > > e
> > >
> > > > Maybe but a couple of messages per connection doesn't
> > really seem worth
> > > > arguing about?
> > > >
> > > > Cheers,
> > > > aj
> > > >
> > > >
> > > > --
> > > > Sent from my phone.
> > > >
> > _______________________________________________
> > > > bitcoin-dev mailing list
> > > > bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-
> > dev at lists.linuxfoundation.org>
> > > >
> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> > 
> > _______________________________________________
> > bitcoin-dev mailing list
> > bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-
> > dev at lists.linuxfoundation.org>
> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> 
> 
> 
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

From eric at voskuil.org  Mon Sep 26 21:19:39 2022
From: eric at voskuil.org (eric at voskuil.org)
Date: Mon, 26 Sep 2022 14:19:39 -0700
Subject: [bitcoin-dev] Packaged Transaction Relay
In-Reply-To: <EDCbz3IJLDkExNWyM1WLLSh5qUioK6HdMEh-eofWmete0baz1lo8uF1YFzLaTXxgQhzvtDtqpX2mTMaDpB7_4-SRNnpJX4F8zgL5e6NGS0U=@protonmail.com>
References: <005e01d87b89$3d99df60$b8cd9e20$@voskuil.org>
 <EDCbz3IJLDkExNWyM1WLLSh5qUioK6HdMEh-eofWmete0baz1lo8uF1YFzLaTXxgQhzvtDtqpX2mTMaDpB7_4-SRNnpJX4F8zgL5e6NGS0U=@protonmail.com>
Message-ID: <00cb01d8d1ed$b0191dc0$104b5940$@voskuil.org>

> Hi Eric,
> 
> 
> This email wasn't answered by anyone on mailing list however I did some
> research about packages yesterday including this email and below are my
> observations, questions etc.

Hello, thanks for the reply.

> > The sole objective, as expressed in the OP proposal, is to:
> >
> > "Propagate transactions that are incentive-compatible to mine, even if they
> don't meet minimum feerate alone."
> 
> According to [bitcoinops][1]: Without package relay, it?s not possible to
> effectively CPFP fee bump a transaction that?s below the minimum feerate
> nodes accept.

Yes, the problem statement is not in question, just the mechanism of resolution. The problem of stuck txs arises from minimum fee rate policy, which is a necessary DOS guard.

A secondary issue is that of orphan relay. As a node must allow receipt of orphans, it has no means to differentiate a flood of unconfirmable txs from those that are confirmable.

> Matt Corallo's thoughts in a bitcoin core [issue][2]:
> 
> "Matt Corallo recently wrote about an example on the bitcoin-dev mailing list
> involving lightning transactions, where pre-signed transactions might be
> broadcast to the blockchain long after they were generated, and thus not
> have been created with a fee that is sufficient to be confirmed quickly (or
> even be accepted to node mempools). In such situations, channel
> participants may need to use chained transactions (CPFP) in order to increase
> the confirmation speed of such transactions, and that implies we may need
> to introduce a mechanism for those parent transactions to be relayed along
> with their higher feerate children, even if the parent transaction would be
> rejected by itself."

While this is a valid scenario, the problems directly affect Bitcoin. Those problems propagate to layers, but are not unique to layering.

> 1)Is it possible to have multiple pre-signed transactions with different fee
> rates in a range? Example: PSBT1: 5 sat/vbyte, PSBT2: 10 sat/vbyte, PSBT3: 20
> sat/vbyte and PSBT4: 100 sat/vbyte

If by "range" you mean a connected tx subgraph, I don't see why not. But note that nodes only operate over signed txs. PSBT is a wallet workflow.

> 2)How would covenants affect this problem?

There are a good number of covenant proposals, though I assume they are all implemented within script. If a tx is confirmable and satisfies fee rate (for DOS protection), it is relayable. Covenants affect confirmability and should not have any unique impact on relay.

> 3)How often does it happen that a pre-signed tx gets rejected by nodes
> because it did not meet the minimum fee rate? Is it predictable and could be
> managed in a different way?

Always. Only signed transactions are accepted. But assuming you are referring to a transaction that has been produced by a pre-signing workflow, I'm not sure how this would be distinct from any other tx.

> After reading several links related to packages and bitcoin core pull requests,
> I found it anti-bitcoin to introduce so much complexity because its not
> possible to CPFP fee bump a tx below minimum fee rate.

I'm not sure I follow this, maybe you could reword it. But it seems that you are saying that CPFP fee-bumping is a problem scenario and the complexity of the proposed solutions are not justified by such scenarios.

I would say that the problem is real, and that the least complex option is generally preferred. There are always tradeoffs, and balancing these is part of protocol development. But as a rule, complexity within a protocol (communication) is to be avoided where possible.

> > Furthermore any tx that is "stuck" can be freed by simply sending another
> tx. The nodes at which the tx has become stuck will just package it up and
> relay it to peers. In other words, there is no impact on wallet implementation
> apart from raising the aggregate fee using a descendant transaction.
> 
> It is easy to send another tx if there is only one user involved however
> packages are trying to fix issues in which multiple users and transaction pre-
> signed between them are involved. So, it will be difficult to coordinate and
> create new pre-signed transactions in some cases although it is possible for
> some use cases.

Given that nodes do not deal in presigned txs, this coordination difficulty could not be increased in any scenario.

A node produces sets of txs ("packages") dynamically to satisfy its peer's feerate. When a wallet broadcasts a tx/package to a node, it is operating as a peer on the p2p network. The wallet simply implements the same dynamic packaging algorithm as any peer - because it is a peer. 

> > This is barely a protocol change - it's primarily implementation. All that
> should be required is an additional INV element type, such as
> MSG_TX_PACKAGE.
> 
> > * All elements of MSG_TX_PACKAGE in one INV message MUST to be of
> the same package.
> > * A package MUST must define a set that can be mined into one block
> (size/sigops constraint).
> > * A package SHOULD not contain confirmed txs (a race may cause this).
> > * A package MUST minimally satisfy peer.feerate.
> > * A partial tx order, as in the manner of the block.txs ordering, MUST be
> imposed.
> > * A node SHOULD drop a peer that sends a package (or tx) below
> node.feerate.
> > * A node MAY drop a peer that sends a non-minimal package according to
> node.feerate.
> 
> This makes sense particularly if multiple node implementations are used in
> future.

There are many node implementations used presently. And of course these are protocol proposals, which presumes more than one implementation.

> My other questions:
> 
> a)If a package has tx1, tx2, tx3, tx4 and tx5 and miner just include tx1 and tx2
> in the block, how does this affect the projects considered for packages
> proposal?

I will leave that to authors of such proposals to answer. However in what I have proposed it just means tx3/4/5 get considered for subsequent block inclusion to the extent that fee rate policy is satisfied.

One of the several problems with static construction of packages is that they can still get stuck by fee rate policy. This is just kicking the can down the road while complicating the protocol.

> b)How does changing the order of txs in a package affect these transactions?

There is no impact. I proposed the partial ordering to facilitate fail fast.

The partial ordering in block txs is unnecessary (given the PoW DOS guard). This is a consequence of the order imposed by Satoshi's implementation and only serves to slow validation (order constrains concurrency).

> c)Do packages introduce more attack vectors in bitcoin for front running or
> MEV? MEV in bitcoin currently only affects the projects that are considered
> in packages proposal.

I don't consider this relevant to any protocol considerations. Miners should always be expected to select the most optimal set of txs available in the time available to do so.

> d)What if the package contains a transactions with sanctioned address?

One can consider this a policy, much like fee rate. Any policy that is applied to transactions and not known to its peers will result in the node receiving orphans. As such the node either must allow orphans or drop peers sending orphans under the assumption that the peer is expected to have implemented the same policy.

> e)Why would miners use packages if the existing scenario in terms of fees
> per block is beneficial for them?

The presumption is that the miner is only ever seeing txs that satisfy its fee rate policy, so this is just more opportunity.

I'd add that the problem of "pinning" is related, but exacerbated by opaque policy (internal to certain implementations). Any node that ejects txs from its pool of valid but unconfirmed txs that satisfy fee rate policy is going to see orphans and going to cause txs to get stuck. This is one of the many problems with placing an arbitrary bound on the size of this pool.

A subset of this problem is RBF policy. It is nice to see some movement toward generalizing RBF. The term is really a misnomer. Conflicting txs and subgraphs of txs are only problematic in the case of DOS, which is also resolved through advertised fee policy. Any node that imposes policy beyond this will also see orphans and cause txs to get stuck.

The scenario and therefore complexity consequences of an implementation-specific memory-constrained tx pool are becoming increasingly apparent. These are implementation issues, not protocol issues. This can be observed in a recent thread: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-September/020937.html

Over time we are likely to see that the only policies that remain in widespread application are those that are necessary for DOS protection (fee rate), as other restrictions are not economically rational and cannot be enforced. We've seen recent debate regarding dust policy, and op_return policy. "non-standard" txs are perfectly valid but get stuck very easily. I'll reiterate, any policy beyond what is published via the protocol will cause the above problems.

e

> /dev/fd0
> 
> [1]: https://bitcoinops.org/en/topics/package-relay/
> [2]: https://github.com/bitcoin/bitcoin/issues/14895
> 
> Sent with Proton Mail secure email.
> 
> ------- Original Message -------
> On Thursday, June 9th, 2022 at 4:13 AM, Eric Voskuil via bitcoin-dev <bitcoin-
> dev at lists.linuxfoundation.org> wrote:
> 
> 
> > Hi Suhas/Gloria,
> >
> > Good questions. I've started a new thread because it became something
> else...
> >
> > Various ideas about packaging seem to be focused on the idea of an atomic
> message that is gossiped around the network like a transaction or block.
> From my perspective that seems to create a set of problems without good
> solutions, and it is not a proper analogy to those atomic structures. It may be
> worth taking the time to step back and take a close look at the underlying
> objective.
> >
> > The sole objective, as expressed in the OP proposal, is to:
> >
> > "Propagate transactions that are incentive-compatible to mine, even if they
> don't meet minimum feerate alone."
> >
> > Effectively producing this outcome with an atomic packaging approach
> while at the same time maintaining network invariants seems unlikely, if not
> impossible.
> >
> > Fees:
> >
> > A node knows what fee rate a peer will accept, and announces individual
> txs that satisfy peer.feerate. Similarly a node knows its own feerate, and
> SHOULD drop any peer that announces txs that do not satisfy node.feerate.
> >
> > Orphans:
> >
> > A node MAY drop a peer that announces txs that the node sees as orphans
> against its DAG. It SHOULD drop the orphan tx and MAY request missing
> ancestors. Presumably after some amount of time connected to peer, node
> does not expect to see any more orphans from that peer, so these choices
> could evolve with the channel. However, the design that can only consider
> each tx in isolation will continue to cause orphan announcements on the
> channel. A below peer.feerate tx does not get announced to peer, and later
> a descendant high peer.feerate does get announced to the peer - as an
> orphan.
> >
> > BIP133 (feefilter):
> >
> > "There could be a small number of edge cases where a node's mempool
> min fee is actually less than the filter value a peer is aware of and
> transactions with fee rates between these values will now be newly
> inhibited."
> >
> > https://github.com/bitcoin/bips/blob/master/bip-0133.mediawiki
> >
> > Whether the problem is "small" or not depends on the disparity between
> node fee rates, which is not a matter of protocol. This is an existing problem
> that can and should be dealt with in packaging, as part of the above
> objective.
> >
> > Packaged Transaction Relay:
> >
> > One might instead think of packaging as a per-connection function,
> operating over its transaction (input->output) DAG and the feerate of its
> own node and that of the peer. Logically a "package" is nothing more than a
> set of transactions (optimized by announcement). Only a node can
> effectively determine the packaging required by each of its peers, since only
> the node is aware of peer.feerate.
> >
> >
> > The only way to avoid dead-ending packages (including individual
> transactions, as is the objective) is for a node to package txs for each peer.
> The origination of any package is then just a wallet peer doing what a node
> does - packaging transactions that satisfy peer.feerate (i.e. that of its node).
> >
> > Current transaction relay (txB->txA):
> >
> > ===============================
> > Node0
> > txA.feerate > node.feerate, and not orphaned (accept txA)
> >
> > txA.feerate > peer1.feerate (announce txA to peer1)
> >
> > txA.feerate < peer2.feerate (do not announce txA to peer2)
> > -----
> > txB.feerate > node.feerate (accept txB)
> >
> > txB.feerate > peer1.feerate (announce txB to peer1)
> >
> > txB.feerate > peer2.feerate (announce txB to peer2)
> >
> >
> > Node1
> > Sees/accepts txA and txB.
> >
> > Node2
> > Never sees txA, sees/rejects txB (as an orphan).
> >
> > Packaged transaction relay (txB->txA):
> >
> > ===============================
> > Node0
> > txA.feerate > node.feerate, and not orphaned (accept txA)
> >
> > txA.feerate > peer1.feerate (announce txA to peer1)
> >
> > txA.feerate < peer2.feerate (do not announce txA to peer2)
> > -----
> > txB.feerate > node1.feerate (accept txB)
> >
> > txB.feerate > peer1.feerate (announce txB to peer1)
> >
> > txB.feerate > peer2.feerate (do not announce txB to peer2) <== avoid
> > predictable orphan
> >
> > txA.feerate + txB.feerate > peer2.feerate (announce pkg(A, B) to
> > peer2) <= create minimal package
> >
> >
> > Node1
> > Sees/accepts txA and txB.
> >
> > Node2
> > pkg(A, B) > node2.feerate (accept txA, txB)
> >
> > txA.feerate > peer3.feerate (announce txA to peer3)
> >
> > txB.feerate > peer3.feerate (announce txB to peer3)
> >
> >
> > Sees/accepts pkg(A, B).
> >
> > Node3
> > Sees/accepts txA and txB. <= avoided unnecessary packaging
> >
> > Summary:
> >
> > In this design, any node that receives an announcement for a pkg (or tx)
> later determined to be less than node.feerate SHOULD drop the announcing
> peer. Unlike with existing tx relay, a node can become "current" and
> subsequently see few if any tx or pkg orphans, and MAY at some point
> decide to drop any peer that announces one. Notice that packages are
> created dynamically, and any package that doesn't need to be grouped gets
> trimmed down to individual transactions. Furthermore any tx that is "stuck"
> can be freed by simply sending another tx. The nodes at which the tx has
> become stuck will just package it up and relay it to peers. In other words,
> there is no impact on wallet implementation apart from raising the aggregate
> fee using a descendant transaction.
> >
> > This is barely a protocol change - it's primarily implementation. All that
> should be required is an additional INV element type, such as
> MSG_TX_PACKAGE.
> >
> > Additional constraints:
> >
> > * All elements of MSG_TX_PACKAGE in one INV message MUST to be of
> the same package.
> > * A package MUST must define a set that can be mined into one block
> (size/sigops constraint).
> > * A package SHOULD not contain confirmed txs (a race may cause this).
> > * A package MUST minimally satisfy peer.feerate.
> > * A partial tx order, as in the manner of the block.txs ordering, MUST be
> imposed.
> > * A node SHOULD drop a peer that sends a package (or tx) below
> node.feerate.
> > * A node MAY drop a peer that sends a non-minimal package according to
> node.feerate.
> >
> > The partial ordering of block.txs introduces an ordering constraint that
> precludes full parallelism in validating input attachment. This is an
> implementation artifact that made its way into consensus. However in the
> case of packaging, the set of txs is not presumed to be valid under the proof
> of work DoS guard. As such constraints should minimize the work/traffic
> required to invalidate the message. The partial order constraint ensures that
> the DAG can be built incrementally, dropping the attempt (and peer as
> desired) as soon as the first orphan is discovered. As a result the network
> traffic and work required is not materially different than with tx relay, with
> two exceptions.
> >
> > These are the two central aspects of this approach (Avoiding Predictable
> Orphans and Creating Minimal Packages). These are graph search algorithms,
> some basic computer science. Minimality requires only that the package does
> not introduce txs that are not necessary to reach the peer.feerate (as these
> can always be packaged separately). It does not require that nodes all
> generate the same packages. It does not require negotiation, package
> identity, cryptography, or hashing. As a graph search it should be O(n) where
> n is the unconfirmed ancestry of the package, but should typically be much
> lower, if not a single step.
> >
> > Sufficiently-low-fee nodes will see only single txs. Moderate-fee
> > nodes may cause partial breakup of packages. Sufficiently high fee
> > nodes will cause peers (having received and completed the acceptance
> > of a tx/pkg with pkg.feerate < peer.feerate) to navigate from each
> > tx/package external input until reaching txs above peer.feerate, or
> > confirmed (both of which the peer is presumed to already have). If the
> > pkg.feerate is sufficiently high to connect all external inputs to the
> > intervening txs, they are added to the package and it is announced to
> > the high fee peer. Note that the individual tx.feerate > peer.feerate
> > is insufficient to ensure that the peer should have the tx, as there
> > may be ancestor txs that do not, and for which the tx was insufficient
> > to cause them to be packaged. So a non-caching algorithm must be able
> > to chase each package external input to a confirmed tx (or cache the
> > unconfirmed ancestry fee rate at each tx). Note that fee rates are not
> > directly additive, both size/
> >
> > weight and fee are required for summation (and aggregate sigops should
> be considered).
> >
> > This makes no assumptions about current implementations. The design
> would call for maintenance of a transaction (input->output) DAG with
> tx.feerate on each tx. This could be the unconfirmed tx graph (i.e. "memory
> pool") though it does not require maintenance of anything more than the
> parameters necessary to confirm a set of validated txs within a block. It is
> very reasonable to require this of any participating node. A simple version
> negotiation can identify a package-accepting/sending nodes.
> >
> >
> > I have thought about this for some time, but have not implemented either
> the graph search, source code, or BIP. Just wrote this off the top of my head.
> So I am sure there are some things I have incorrect or failed to consider. But I
> think it's worth discussing it at this point.
> >
> > e
> >
> > > -----Original Message-----
> > > From: bitcoin-dev bitcoin-dev-bounces at lists.linuxfoundation.org On
> > > Behalf Of Suhas Daftuar via bitcoin-dev
> > > Sent: Wednesday, June 8, 2022 8:59 AM
> > > To: Bitcoin Protocol Discussion
> > > bitcoin-dev at lists.linuxfoundation.org
> > > Subject: Re: [bitcoin-dev] Package Relay Proposal
> > >
> > > Hi,
> > >
> > > Thanks again for your work on this!
> > >
> > > One question I have is about potential bandwidth waste in the case
> > > of nodes running with different policy rules. Here's my
> > > understanding of a scenario I think could happen:
> > >
> > > 1) Transaction A is both low-fee and non-standard to some nodes on
> > > the network.
> > > 2) Whenever a transaction T that spends A is relayed, new nodes will
> > > send INV(PKGINFO1, T) to all package-relay peers.
> > > 3) Nodes on the network that have implemented package relay, but do
> > > not accept A, will send getdata(PKGINFO1, T) and learn all of T's
> > > unconfirmed parents (~32 bytes * number of parents(T)).
> > > 4) Such nodes will reject T. But because of transaction
> > > malleability, and to avoid being blinded to a transaction
> > > unnecessarily, these nodes will likely still send getdata(PKGINFO1,
> > > T) to every node that announces T, in case someone has a transaction
> > > that includes an alternate set of parent transactions that would pass
> policy checks.
> > >
> > > Is that understanding correct? I think a good design goal would be
> > > to not waste bandwidth in non-adversarial situations. In this case,
> > > there would be bandwidth waste from downloading duplicate data from
> > > all your peers, just because the announcement doesn't commit to the
> > > set of parent wtxids that we'd get from the peer (and so we are
> > > unable to determine that all our peers would be telling us the same thing,
> just based on the announcement).
> > >
> > > Some ways to mitigate this might be to: (a) include a hash (maybe
> > > even just a 20-byte hash -- is that enough security?) of the package
> > > wtxids (in some canonical ordering) along with the wtxid of the
> > > child in the initial announcement; (b) limit the use of v1 packages
> > > to transactions with very few parents (I don't know if this is reasonable
> for the use cases we have in mind).
> > >
> > > Another point I wanted to bring up is about the rules around v1
> > > package validation generally, and the use of a blockhash in
> > > transaction relay specifically. My first observation is that it
> > > won't always be the case that a v1 package relay node will be able
> > > to validate that a set of package transactions is fully sorted
> > > topologically, because there may be (non-parent) ancestors that are
> > > missing from the package and the best a peer can validate is
> > > topology within the package -- this means that a peer can validly
> > > (under this
> > > BIP) relay transaction packages out of the true topological sort (if
> > > all ancestors were included).
> > >
> > > This makes me wonder how useful this topological rule is. I suppose
> > > there is some value in preventing completely broken implementations
> > > from staying connected and so there is no harm in having the rule,
> > > but perhaps it would be helpful to add that nodes SHOULD order
> > > transactions based on topological sort in the complete transaction
> > > graph, so that if missing-from-package ancestors are already known
> > > by a peer (which is the expected case when using v1 package relay on
> > > transactions that have more than one generation of unconfirmed
> > > ancestor) then the remaining transactions are already properly ordered,
> and this is helpful even if unenforceable in general.
> > >
> > > The other observation I wanted to make was that having transaction
> > > relay gated on whether two nodes agree on chain tip seems like an
> > > overly restrictive criteria. I think an important design principle
> > > is that we want to minimize disruption from network splits -- if
> > > there are competing blocks found in a small window of time, it's
> > > likely that the utxo set is not materially different on the two
> > > chains (assuming miners are selecting from roughly the same sets of
> > > transactions when this happens, which is typical). Having
> > > transaction relay bifurcate on the two network halves would seem to
> > > exacerbate the difference between the two sides of the split --
> > > users ought to be agnostic about how benign splits are resolved and
> would likely want their transactions to relay across the whole network.
> > >
> > > Additionally, use of a chain tip might impose a larger burden than
> > > is necessary on software that would seek to participate in
> > > transaction relay without implementing headers sync/validation. I
> > > don't know what software exists on the network, but I imagine there
> > > are a lot of scripts out there for transaction submission to the
> > > public p2p network, and in thinking about modifying such a script to
> > > utilize package relay it seems like an unnecessary added burden to first
> learn a node's tip before trying to relay a transaction.
> > >
> > > Could you explain again what the benefit of including the blockhash
> > > is? It seems like it is just so that a node could prioritize
> > > transaction relay from peers with the same chain tip to maximize the
> > > likelihood of transaction acceptance, but in the common case this
> > > seems like a pretty negligible concern, and in the case of a chain
> > > fork that persists for many minutes it seems better to me that we
> > > not partition the network into package-relay regimes and just risk a
> > > little extra bandwidth in one direction or the other. If we solve
> > > the problem I brought up at the beginning (of de-duplicating package
> > > data across peers with a package-wtxid-commitment in the
> > > announcement), I think this is just some wasted pkginfo bandwidth on
> > > a single-link, and not across links (as we could cache validation failure for a
> package-hash to avoid re-requesting duplicate pkginfo1 messages).
> > >
> > > Best,
> > > Suhas
> > >
> > > On Tue, Jun 7, 2022 at 1:57 PM Gloria Zhao via bitcoin-dev <bitcoin-
> > > dev at lists.linuxfoundation.org <mailto:bitcoin-
> > > dev at lists.linuxfoundation.org> > wrote:
> > >
> > > Hi Eric, aj, all,
> > >
> > > Sorry for the delayed response. @aj I'm including some paraphrased
> > > points from our offline discussion (thanks).
> > >
> > > > Other idea: what if you encode the parent txs as a short hash of
> > > > the wtxid (something like bip152 short ids? perhaps seeded per
> > > > peer so collisions will be different per peer?) and include that in the inv
> announcement?
> > > > Would that work to avoid a round trip almost all of the time,
> > > > while still giving you enough info to save bw by deduping parents?
> > >
> > > > As I suggested earlier, a package is fundamentally a compact block
> > > > (or
> > > > block) announcement without the header. Compact block (BIP152)
> > > > announcement is already well-defined and widely implemented...
> > >
> > > > Let us not reinvent the wheel and/or introduce accidental
> > > > complexity. I see no reason why packaging is not simply BIP152
> > > > without the 'header'
> > > > field, an
> > > > updated protocol version, and the following sort of changes to
> > > > names
> > >
> > > Interestingly, "why not use BIP 152 shortids to save bandwidth?" is
> > > by far the most common suggestion I hear (including offline feedback).
> > > Here's a full explanation:
> > >
> > > BIP 152 shortens transaction hashes (32 bytes) to shortids (6 bytes)
> > > to save a significant amount of network bandwidth, which is
> > > extremely important in block relay. However, this comes at the
> > > expense of computational complexity. There is no way to directly
> > > calculate a transaction hash from a shortid; upon receipt of a
> > > compact block, a node is expected to calculate the shortids of every
> > > unconfirmed transaction it knows about to find the matches (BIP 152:
> > > 1, Bitcoin Core: [2]). This is expensive but appropriate for block
> > > relay, since the block must have a valid Proof of Work and new
> > > blocks only come every ~10 minutes. On the other hand, if we require
> > > nodes to calculate shortids for every transaction in their mempools every
> time they receive a package, we are creating a DoS vector.
> > > Unconfirmed transactions don't need PoW and, to have a live
> > > transaction relay network, we should expect nodes to handle
> > > transactions at a high-ish rate (i.e. at least 1000s of times more
> > > transactions than blocks). We can't pre- calculate or cache shortids
> > > for mempool transactions, since the SipHash key depends on the block
> hash and a per-connection salt.
> > >
> > > Additionally, shortid calculation is not designed to prevent
> > > intentional individual collisions. If we were to use these shortids
> > > to deduplicate transactions we've supposedly already seen, we may
> > > have a censorship vector. Again, these tradeoffs make sense for
> > > compact block relay (see shortid section in BIP 152 [3]), but not package
> relay.
> > >
> > > TLDR: DoSy if we calculate shortids on every package and censorship
> > > vector if we use shortids for deduplication.
> > >
> > > > Given this message there is no reason to send a (potentially
> > > > bogus) fee rate with every package. It can only be validated by
> > > > obtaining the full set of txs, and the only recourse is dropping
> > > > (etc.) the peer, as is the case with single txs.
> > >
> > > Yeah, I agree with this. Combined with the previous discussion with
> > > aj (i.e. we can't accurately communicate the incentive compatibility
> > > of a package without sending the full graph, and this whole dance is
> > > to avoid downloading a few low-fee transactions in uncommon edge
> > > cases), I've realized I should remove the fee + weight information
> > > from pkginfo. Yay for less complexity!
> > >
> > > Also, this might be pedantic, but I said something incorrect earlier
> > > and would like to correct myself:
> > >
> > > > > In theory, yes, but maybe it was announced earlier (while our
> > > > > node was down?) or had dropped from our mempool or similar,
> > > > > either way we don't have those txs yet.
> > >
> > > I said "It's fine if they have Erlay, since a sender would know in
> > > advance that B is missing and announce it as a package." But this
> > > isn't true since we're only using reconciliation in place of
> > > flooding to announce transactions as they arrive, not for
> > > rebroadcast, and we're not doing full mempool set reconciliation. In
> > > any case, making sure a node receives the transactions announced
> > > when it was offline is not something we guarantee, not an intended use
> case for package relay, and not worsened by this.
> > >
> > > Thanks for your feedback!
> > >
> > > Best,
> > >
> > > Gloria
> > >
> > > 0152.mediawiki#cmpctblock
> > > [2]:
> > > https://github.com/bitcoin/bitcoin/blob/master/src/blockencodings.cp
> > > p#L49
> > > [3]: https://github.com/bitcoin/bips/blob/master/bip-
> > > 0152.mediawiki#short-transaction-id-calculation
> > >
> > > On Thu, May 26, 2022 at 3:59 AM <eric at voskuil.org
> > > mailto:eric at voskuil.org > wrote:
> > >
> > > Given that packages have no header, the package requires identity in
> > > a
> > > BIP152 scheme. For example 'header' and 'blockhash' fields can be
> > > replaced with a Merkle root (e.g. "identity" field) for the package,
> > > uniquely identifying the partially-ordered set of txs. And use of
> > > 'getdata' (to obtain a package by hash) can be eliminated (not a use
> > > case).
> > >
> > > e
> > >
> > > > -----Original Message-----
> > > > From: eric at voskuil.org mailto:eric at voskuil.org
> > > <eric at voskuil.org mailto:eric at voskuil.org >
> > > > Sent: Wednesday, May 25, 2022 1:52 PM
> > > > To: 'Anthony Towns' <aj at erisian.com.au
> > > mailto:aj at erisian.com.au >; 'Bitcoin Protocol Discussion'
> > > > <bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-
> > > dev at lists.linuxfoundation.org> >; 'Gloria Zhao'
> > > > <gloriajzhao at gmail.com mailto:gloriajzhao at gmail.com >
> > > > Subject: RE: [bitcoin-dev] Package Relay Proposal
> > > >
> > > > > From: bitcoin-dev <bitcoin-dev-
> > > bounces at lists.linuxfoundation.org <mailto:bitcoin-dev-
> > > bounces at lists.linuxfoundation.org> > On
> > > > Behalf
> > > > > Of Anthony Towns via bitcoin-dev
> > > > > Sent: Wednesday, May 25, 2022 11:56 AM
> > > >
> > > > > So the other thing is what happens if the peer
> > > announcing packages to us
> > > > is
> > > > > dishonest?
> > > > >
> > > > > They announce pkg X, say X has parents A B C and the fee
> > > rate is
> > > garbage.
> > > > But
> > > > > actually X has parent D and the fee rate is excellent. Do
> > > we request the
> > > > > package from another peer, or every peer, to double
> > > check? Otherwise
> > > > we're
> > > > > allowing the first peer we ask about a package to censor
> > > that tx from
> > > us?
> > > > >
> > > > > I think the fix for that is just to provide the fee and weight
> > > when
> > > > announcing
> > > > > the package rather than only being asked for its info?
> > > Then if one peer
> > > > makes
> > > > > it sound like a good deal you ask for the parent txids from
> > > them,
> > > dedupe,
> > > > > request, and verify they were honest about the parents.
> > > >
> > > > Single tx broadcasts do not carry an advertised fee rate,
> > > however the'
> > > > feefilter' message (BIP133) provides this distinction. This
> > > should be
> > > > interpreted as applicable to packages. Given this message
> > > there is no
> > > reason
> > > > to send a (potentially bogus) fee rate with every package. It
> > > can only be
> > > > validated by obtaining the full set of txs, and the only
> > > recourse is
> > > > dropping (etc.) the peer, as is the case with single txs.
> > > Relying on the
> > > > existing message is simpler, more consistent, and more
> > > efficient.
> > > >
> > > > > >> Is it plausible to add the graph in?
> > > > >
> > > > > Likewise, I think you'd have to have the graph info from
> > > many nodes if
> > > > you're
> > > > > going to make decisions based on it and don't want
> > > hostile peers to be
> > > > able to
> > > > > trick you into ignoring txs.
> > > > >
> > > > > Other idea: what if you encode the parent txs as a short
> > > hash of the
> > > wtxid
> > > > > (something like bip152 short ids? perhaps seeded per
> > > peer so collisions
> > > > will
> > > > > be different per peer?) and include that in the inv
> > > announcement? Would
> > > > > that work to avoid a round trip almost all of the time,
> > > while still
> > > giving
> > > > you
> > > > > enough info to save bw by deduping parents?
> > > >
> > > > As I suggested earlier, a package is fundamentally a
> > > compact block (or
> > > > block) announcement without the header. Compact block
> > > (BIP152)
> > > > announcement
> > > > is already well-defined and widely implemented. A node
> > > should never be
> > > > required to retain an orphan, and BIP152 ensures this is not
> > > required.
> > > >
> > > > Once a validated set of txs within the package has been
> > > obtained with
> > > > sufficient fee, a fee-optimal node would accept the largest
> > > subgraph of
> > > the
> > > > package that conforms to fee constraints and drop any
> > > peer that provides a
> > > > package for which the full graph does not.
> > > >
> > > > Let us not reinvent the wheel and/or introduce accidental
> > > complexity. I
> > > see
> > > > no reason why packaging is not simply BIP152 without the
> > > 'header' field,
> > > an
> > > > updated protocol version, and the following sort of changes
> > > to names:
> > > >
> > > > sendpkg
> > > > MSG_CMPCT_PKG
> > > > cmpctpkg
> > > > getpkgtxn
> > > > pkgtxn
> > > >
> > > > > > For a maximum 25 transactions,
> > > > > >2324/2 = 276, seems like 36 bytes for a child-with-
> > > parents package.
> > > > >
> > > > > If you're doing short ids that's maybe 254B=100B
> > > already, then the
> > > above
> > > > is
> > > > > up to 36% overhead, I guess. Might be worth thinking
> > > more about, but
> > > > maybe
> > > > > more interesting with ancestors than just parents.
> > > > >
> > > > > >Also side note, since there are no size/count params,
> > > >
> > > > Size is restricted in the same manner as block and
> > > transaction broadcasts,
> > > > by consensus. If the fee rate is sufficient there would be no
> > > reason to
> > > > preclude any valid size up to what can be mined in one
> > > block (packaging
> > > > across blocks is not economically rational under the
> > > assumption that one
> > > > miner cannot expect to mine multiple blocks in a row).
> > > Count is
> > > incorporated
> > > > into BIP152 as 'shortids_length'.
> > > >
> > > > > > wondering if we
> > > > > >should just have "version" in "sendpackages" be a bit
> > > field instead of
> > > > > >sending a message for each version. 32 versions should
> > > be enough right?
> > > >
> > > > Adding versioning to individual protocols is just a reflection
> > > of the
> > > > insufficiency of the initial protocol versioning design, and
> > > that of the
> > > > various ad-hoc changes to it (including yet another
> > > approach in this
> > > > proposal) that have been introduced to compensate for it,
> > > though I'll
> > > > address this in an independent post at some point.
> > > >
> > > > Best,
> > > > e
> > > >
> > > > > Maybe but a couple of messages per connection doesn't
> > > really seem worth
> > > > > arguing about?
> > > > >
> > > > > Cheers,
> > > > > aj
> > > > >
> > > > >
> > > > > --
> > > > > Sent from my phone.
> > > > >
> > > _______________________________________________
> > > > > bitcoin-dev mailing list
> > > > > bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-
> > > dev at lists.linuxfoundation.org>
> > > > >
> > > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> > >
> > > _______________________________________________
> > > bitcoin-dev mailing list
> > > bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-
> > > dev at lists.linuxfoundation.org>
> > > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> >
> >
> >
> > _______________________________________________
> > bitcoin-dev mailing list
> > bitcoin-dev at lists.linuxfoundation.org
> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev



From alicexbt at protonmail.com  Tue Sep 27 09:29:19 2022
From: alicexbt at protonmail.com (alicexbt)
Date: Tue, 27 Sep 2022 09:29:19 +0000
Subject: [bitcoin-dev] Packaged Transaction Relay
In-Reply-To: <00cb01d8d1ed$b0191dc0$104b5940$@voskuil.org>
References: <005e01d87b89$3d99df60$b8cd9e20$@voskuil.org>
 <EDCbz3IJLDkExNWyM1WLLSh5qUioK6HdMEh-eofWmete0baz1lo8uF1YFzLaTXxgQhzvtDtqpX2mTMaDpB7_4-SRNnpJX4F8zgL5e6NGS0U=@protonmail.com>
 <00cb01d8d1ed$b0191dc0$104b5940$@voskuil.org>
Message-ID: <9H5VUe-D8MlzIgitIRj0Z_yT_dj5RYwAcp4HJHdXcseZB3Hl1Wxl1_vpcmPYCMaolnYA6R18MC3qIsQgkxBeew3s5GLirhAMaNiEq5LOm4U=@protonmail.com>

Hi Eric,


> If by "range" you mean a connected tx subgraph, I don't see why not. But note that nodes only operate over signed txs. PSBT is a wallet workflow.

Matt Corallo mentioned that pre-signed transactions created with low fee rate become an issue when they are broadcasted after a long time and there is a high demand for block space at that moment.

Example: 

Bob created PSBT1 in a multi party contract with fee rate 5 sat/vbyte however its taking hours/days to confirm the transaction with such low fee rate.

Carol created PSBT1 (5 sat/vbyte), PSBT2 (10 sat/vbyte) and PSBT3 (20 sat/vbyte) for spending same inputs. She broadcasted PSBT3 which got confirmed in a few minutes. 


> Always. Only signed transactions are accepted. But assuming you are referring to a transaction that has been produced by a pre-signing workflow, I'm not sure how this would be distinct from any other tx.


`minfeefilter` for all peers of my node was 0.00001000 at the time of writing this email. I am assuming nobody creates pre-signed transaction with fee rate below 1 sat/vbyte. How often does it happen that `minfeefilter` is above this default value?


> I'm not sure I follow this, maybe you could reword it. But it seems that you are saying that CPFP fee-bumping is a problem scenario and the complexity of the proposed solutions are not justified by such scenarios.


Sorry that sentence was confusing. Yes complexity isn't justified for CPFP fee-bumping txs below minimum fee rate.


> There are many node implementations used presently. And of course these are protocol proposals, which presumes more than one implementation.


Yes, a few implementations exist (knots, libbitcoin, btcd, bcoin etc.) however they aren't used by lot of nodes. Based on this [chart][1] 98% nodes use bitcoin core. Lot of bitcoin protocol proposals are influenced by bitcoin core contributors and things could be different if even 30% nodes used other implementations.


> I don't consider this relevant to any protocol considerations. Miners should always be expected to select the most optimal set of txs available in the time available to do so.


Agree, miners should be expected to select most optimal set of txs. However, according to one [comment][2] by Pieter Wuille, miners could affect the security of some bitcoin projects with MEV.


> Over time we are likely to see that the only policies that remain in widespread application are those that are necessary for DOS protection (fee rate), as other restrictions are not economically rational and cannot be enforced. We've seen recent debate regarding dust policy, and op_return policy. "non-standard" txs are perfectly valid but get stuck very easily. I'll reiterate, any policy beyond what is published via the protocol will cause the above problems.

I completely agree with this.


[1]: https://luke.dashjr.org/programs/bitcoin/files/charts/software.html
[2]: https://bitcoin.stackexchange.com/questions/107787/front-running-in-bitcoin#comment123441_107796


/dev/fd0

Sent with Proton Mail secure email.

------- Original Message -------
On Tuesday, September 27th, 2022 at 2:49 AM, <eric at voskuil.org> wrote:


> > Hi Eric,
> > 
> > This email wasn't answered by anyone on mailing list however I did some
> > research about packages yesterday including this email and below are my
> > observations, questions etc.
> 
> 
> Hello, thanks for the reply.
> 
> > > The sole objective, as expressed in the OP proposal, is to:
> > > 
> > > "Propagate transactions that are incentive-compatible to mine, even if they
> > > don't meet minimum feerate alone."
> > 
> > According to bitcoinops: Without package relay, it?s not possible to
> > effectively CPFP fee bump a transaction that?s below the minimum feerate
> > nodes accept.
> 
> 
> Yes, the problem statement is not in question, just the mechanism of resolution. The problem of stuck txs arises from minimum fee rate policy, which is a necessary DOS guard.
> 
> A secondary issue is that of orphan relay. As a node must allow receipt of orphans, it has no means to differentiate a flood of unconfirmable txs from those that are confirmable.
> 
> > Matt Corallo's thoughts in a bitcoin core issue:
> > 
> > "Matt Corallo recently wrote about an example on the bitcoin-dev mailing list
> > involving lightning transactions, where pre-signed transactions might be
> > broadcast to the blockchain long after they were generated, and thus not
> > have been created with a fee that is sufficient to be confirmed quickly (or
> > even be accepted to node mempools). In such situations, channel
> > participants may need to use chained transactions (CPFP) in order to increase
> > the confirmation speed of such transactions, and that implies we may need
> > to introduce a mechanism for those parent transactions to be relayed along
> > with their higher feerate children, even if the parent transaction would be
> > rejected by itself."
> 
> 
> While this is a valid scenario, the problems directly affect Bitcoin. Those problems propagate to layers, but are not unique to layering.
> 
> > 1)Is it possible to have multiple pre-signed transactions with different fee
> > rates in a range? Example: PSBT1: 5 sat/vbyte, PSBT2: 10 sat/vbyte, PSBT3: 20
> > sat/vbyte and PSBT4: 100 sat/vbyte
> 
> 
> If by "range" you mean a connected tx subgraph, I don't see why not. But note that nodes only operate over signed txs. PSBT is a wallet workflow.
> 
> > 2)How would covenants affect this problem?
> 
> 
> There are a good number of covenant proposals, though I assume they are all implemented within script. If a tx is confirmable and satisfies fee rate (for DOS protection), it is relayable. Covenants affect confirmability and should not have any unique impact on relay.
> 
> > 3)How often does it happen that a pre-signed tx gets rejected by nodes
> > because it did not meet the minimum fee rate? Is it predictable and could be
> > managed in a different way?
> 
> 
> Always. Only signed transactions are accepted. But assuming you are referring to a transaction that has been produced by a pre-signing workflow, I'm not sure how this would be distinct from any other tx.
> 
> > After reading several links related to packages and bitcoin core pull requests,
> > I found it anti-bitcoin to introduce so much complexity because its not
> > possible to CPFP fee bump a tx below minimum fee rate.
> 
> 
> I'm not sure I follow this, maybe you could reword it. But it seems that you are saying that CPFP fee-bumping is a problem scenario and the complexity of the proposed solutions are not justified by such scenarios.
> 
> I would say that the problem is real, and that the least complex option is generally preferred. There are always tradeoffs, and balancing these is part of protocol development. But as a rule, complexity within a protocol (communication) is to be avoided where possible.
> 
> > > Furthermore any tx that is "stuck" can be freed by simply sending another
> > > tx. The nodes at which the tx has become stuck will just package it up and
> > > relay it to peers. In other words, there is no impact on wallet implementation
> > > apart from raising the aggregate fee using a descendant transaction.
> > 
> > It is easy to send another tx if there is only one user involved however
> > packages are trying to fix issues in which multiple users and transaction pre-
> > signed between them are involved. So, it will be difficult to coordinate and
> > create new pre-signed transactions in some cases although it is possible for
> > some use cases.
> 
> 
> Given that nodes do not deal in presigned txs, this coordination difficulty could not be increased in any scenario.
> 
> A node produces sets of txs ("packages") dynamically to satisfy its peer's feerate. When a wallet broadcasts a tx/package to a node, it is operating as a peer on the p2p network. The wallet simply implements the same dynamic packaging algorithm as any peer - because it is a peer.
> 
> > > This is barely a protocol change - it's primarily implementation. All that
> > > should be required is an additional INV element type, such as
> > > MSG_TX_PACKAGE.
> > 
> > > * All elements of MSG_TX_PACKAGE in one INV message MUST to be of
> > > the same package.
> > > * A package MUST must define a set that can be mined into one block
> > > (size/sigops constraint).
> > > * A package SHOULD not contain confirmed txs (a race may cause this).
> > > * A package MUST minimally satisfy peer.feerate.
> > > * A partial tx order, as in the manner of the block.txs ordering, MUST be
> > > imposed.
> > > * A node SHOULD drop a peer that sends a package (or tx) below
> > > node.feerate.
> > > * A node MAY drop a peer that sends a non-minimal package according to
> > > node.feerate.
> > 
> > This makes sense particularly if multiple node implementations are used in
> > future.
> 
> 
> There are many node implementations used presently. And of course these are protocol proposals, which presumes more than one implementation.
> 
> > My other questions:
> > 
> > a)If a package has tx1, tx2, tx3, tx4 and tx5 and miner just include tx1 and tx2
> > in the block, how does this affect the projects considered for packages
> > proposal?
> 
> 
> I will leave that to authors of such proposals to answer. However in what I have proposed it just means tx3/4/5 get considered for subsequent block inclusion to the extent that fee rate policy is satisfied.
> 
> One of the several problems with static construction of packages is that they can still get stuck by fee rate policy. This is just kicking the can down the road while complicating the protocol.
> 
> > b)How does changing the order of txs in a package affect these transactions?
> 
> 
> There is no impact. I proposed the partial ordering to facilitate fail fast.
> 
> The partial ordering in block txs is unnecessary (given the PoW DOS guard). This is a consequence of the order imposed by Satoshi's implementation and only serves to slow validation (order constrains concurrency).
> 
> > c)Do packages introduce more attack vectors in bitcoin for front running or
> > MEV? MEV in bitcoin currently only affects the projects that are considered
> > in packages proposal.
> 
> 
> I don't consider this relevant to any protocol considerations. Miners should always be expected to select the most optimal set of txs available in the time available to do so.
> 
> > d)What if the package contains a transactions with sanctioned address?
> 
> 
> One can consider this a policy, much like fee rate. Any policy that is applied to transactions and not known to its peers will result in the node receiving orphans. As such the node either must allow orphans or drop peers sending orphans under the assumption that the peer is expected to have implemented the same policy.
> 
> > e)Why would miners use packages if the existing scenario in terms of fees
> > per block is beneficial for them?
> 
> 
> The presumption is that the miner is only ever seeing txs that satisfy its fee rate policy, so this is just more opportunity.
> 
> I'd add that the problem of "pinning" is related, but exacerbated by opaque policy (internal to certain implementations). Any node that ejects txs from its pool of valid but unconfirmed txs that satisfy fee rate policy is going to see orphans and going to cause txs to get stuck. This is one of the many problems with placing an arbitrary bound on the size of this pool.
> 
> A subset of this problem is RBF policy. It is nice to see some movement toward generalizing RBF. The term is really a misnomer. Conflicting txs and subgraphs of txs are only problematic in the case of DOS, which is also resolved through advertised fee policy. Any node that imposes policy beyond this will also see orphans and cause txs to get stuck.
> 
> The scenario and therefore complexity consequences of an implementation-specific memory-constrained tx pool are becoming increasingly apparent. These are implementation issues, not protocol issues. This can be observed in a recent thread: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-September/020937.html
> 
> Over time we are likely to see that the only policies that remain in widespread application are those that are necessary for DOS protection (fee rate), as other restrictions are not economically rational and cannot be enforced. We've seen recent debate regarding dust policy, and op_return policy. "non-standard" txs are perfectly valid but get stuck very easily. I'll reiterate, any policy beyond what is published via the protocol will cause the above problems.
> 
> e
> 
> > /dev/fd0
> > 
> > Sent with Proton Mail secure email.
> > 
> > ------- Original Message -------
> > On Thursday, June 9th, 2022 at 4:13 AM, Eric Voskuil via bitcoin-dev <bitcoin-
> > dev at lists.linuxfoundation.org> wrote:
> > 
> > > Hi Suhas/Gloria,
> > > 
> > > Good questions. I've started a new thread because it became something
> > > else...
> > > 
> > > Various ideas about packaging seem to be focused on the idea of an atomic
> > > message that is gossiped around the network like a transaction or block.
> > > From my perspective that seems to create a set of problems without good
> > > solutions, and it is not a proper analogy to those atomic structures. It may be
> > > worth taking the time to step back and take a close look at the underlying
> > > objective.
> > > 
> > > The sole objective, as expressed in the OP proposal, is to:
> > > 
> > > "Propagate transactions that are incentive-compatible to mine, even if they
> > > don't meet minimum feerate alone."
> > > 
> > > Effectively producing this outcome with an atomic packaging approach
> > > while at the same time maintaining network invariants seems unlikely, if not
> > > impossible.
> > > 
> > > Fees:
> > > 
> > > A node knows what fee rate a peer will accept, and announces individual
> > > txs that satisfy peer.feerate. Similarly a node knows its own feerate, and
> > > SHOULD drop any peer that announces txs that do not satisfy node.feerate.
> > > 
> > > Orphans:
> > > 
> > > A node MAY drop a peer that announces txs that the node sees as orphans
> > > against its DAG. It SHOULD drop the orphan tx and MAY request missing
> > > ancestors. Presumably after some amount of time connected to peer, node
> > > does not expect to see any more orphans from that peer, so these choices
> > > could evolve with the channel. However, the design that can only consider
> > > each tx in isolation will continue to cause orphan announcements on the
> > > channel. A below peer.feerate tx does not get announced to peer, and later
> > > a descendant high peer.feerate does get announced to the peer - as an
> > > orphan.
> > > 
> > > BIP133 (feefilter):
> > > 
> > > "There could be a small number of edge cases where a node's mempool
> > > min fee is actually less than the filter value a peer is aware of and
> > > transactions with fee rates between these values will now be newly
> > > inhibited."
> > > 
> > > https://github.com/bitcoin/bips/blob/master/bip-0133.mediawiki
> > > 
> > > Whether the problem is "small" or not depends on the disparity between
> > > node fee rates, which is not a matter of protocol. This is an existing problem
> > > that can and should be dealt with in packaging, as part of the above
> > > objective.
> > > 
> > > Packaged Transaction Relay:
> > > 
> > > One might instead think of packaging as a per-connection function,
> > > operating over its transaction (input->output) DAG and the feerate of its
> > > own node and that of the peer. Logically a "package" is nothing more than a
> > > set of transactions (optimized by announcement). Only a node can
> > > effectively determine the packaging required by each of its peers, since only
> > > the node is aware of peer.feerate.
> > > 
> > > The only way to avoid dead-ending packages (including individual
> > > transactions, as is the objective) is for a node to package txs for each peer.
> > > The origination of any package is then just a wallet peer doing what a node
> > > does - packaging transactions that satisfy peer.feerate (i.e. that of its node).
> > > 
> > > Current transaction relay (txB->txA):
> > > 
> > > ===============================
> > > Node0
> > > txA.feerate > node.feerate, and not orphaned (accept txA)
> > > 
> > > txA.feerate > peer1.feerate (announce txA to peer1)
> > > 
> > > txA.feerate < peer2.feerate (do not announce txA to peer2)
> > > -----
> > > txB.feerate > node.feerate (accept txB)
> > > 
> > > txB.feerate > peer1.feerate (announce txB to peer1)
> > > 
> > > txB.feerate > peer2.feerate (announce txB to peer2)
> > > 
> > > Node1
> > > Sees/accepts txA and txB.
> > > 
> > > Node2
> > > Never sees txA, sees/rejects txB (as an orphan).
> > > 
> > > Packaged transaction relay (txB->txA):
> > > 
> > > ===============================
> > > Node0
> > > txA.feerate > node.feerate, and not orphaned (accept txA)
> > > 
> > > txA.feerate > peer1.feerate (announce txA to peer1)
> > > 
> > > txA.feerate < peer2.feerate (do not announce txA to peer2)
> > > -----
> > > txB.feerate > node1.feerate (accept txB)
> > > 
> > > txB.feerate > peer1.feerate (announce txB to peer1)
> > > 
> > > txB.feerate > peer2.feerate (do not announce txB to peer2) <== avoid
> > > predictable orphan
> > > 
> > > txA.feerate + txB.feerate > peer2.feerate (announce pkg(A, B) to
> > > peer2) <= create minimal package
> > > 
> > > Node1
> > > Sees/accepts txA and txB.
> > > 
> > > Node2
> > > pkg(A, B) > node2.feerate (accept txA, txB)
> > > 
> > > txA.feerate > peer3.feerate (announce txA to peer3)
> > > 
> > > txB.feerate > peer3.feerate (announce txB to peer3)
> > > 
> > > Sees/accepts pkg(A, B).
> > > 
> > > Node3
> > > Sees/accepts txA and txB. <= avoided unnecessary packaging
> > > 
> > > Summary:
> > > 
> > > In this design, any node that receives an announcement for a pkg (or tx)
> > > later determined to be less than node.feerate SHOULD drop the announcing
> > > peer. Unlike with existing tx relay, a node can become "current" and
> > > subsequently see few if any tx or pkg orphans, and MAY at some point
> > > decide to drop any peer that announces one. Notice that packages are
> > > created dynamically, and any package that doesn't need to be grouped gets
> > > trimmed down to individual transactions. Furthermore any tx that is "stuck"
> > > can be freed by simply sending another tx. The nodes at which the tx has
> > > become stuck will just package it up and relay it to peers. In other words,
> > > there is no impact on wallet implementation apart from raising the aggregate
> > > fee using a descendant transaction.
> > > 
> > > This is barely a protocol change - it's primarily implementation. All that
> > > should be required is an additional INV element type, such as
> > > MSG_TX_PACKAGE.
> > > 
> > > Additional constraints:
> > > 
> > > * All elements of MSG_TX_PACKAGE in one INV message MUST to be of
> > > the same package.
> > > * A package MUST must define a set that can be mined into one block
> > > (size/sigops constraint).
> > > * A package SHOULD not contain confirmed txs (a race may cause this).
> > > * A package MUST minimally satisfy peer.feerate.
> > > * A partial tx order, as in the manner of the block.txs ordering, MUST be
> > > imposed.
> > > * A node SHOULD drop a peer that sends a package (or tx) below
> > > node.feerate.
> > > * A node MAY drop a peer that sends a non-minimal package according to
> > > node.feerate.
> > > 
> > > The partial ordering of block.txs introduces an ordering constraint that
> > > precludes full parallelism in validating input attachment. This is an
> > > implementation artifact that made its way into consensus. However in the
> > > case of packaging, the set of txs is not presumed to be valid under the proof
> > > of work DoS guard. As such constraints should minimize the work/traffic
> > > required to invalidate the message. The partial order constraint ensures that
> > > the DAG can be built incrementally, dropping the attempt (and peer as
> > > desired) as soon as the first orphan is discovered. As a result the network
> > > traffic and work required is not materially different than with tx relay, with
> > > two exceptions.
> > > 
> > > These are the two central aspects of this approach (Avoiding Predictable
> > > Orphans and Creating Minimal Packages). These are graph search algorithms,
> > > some basic computer science. Minimality requires only that the package does
> > > not introduce txs that are not necessary to reach the peer.feerate (as these
> > > can always be packaged separately). It does not require that nodes all
> > > generate the same packages. It does not require negotiation, package
> > > identity, cryptography, or hashing. As a graph search it should be O(n) where
> > > n is the unconfirmed ancestry of the package, but should typically be much
> > > lower, if not a single step.
> > > 
> > > Sufficiently-low-fee nodes will see only single txs. Moderate-fee
> > > nodes may cause partial breakup of packages. Sufficiently high fee
> > > nodes will cause peers (having received and completed the acceptance
> > > of a tx/pkg with pkg.feerate < peer.feerate) to navigate from each
> > > tx/package external input until reaching txs above peer.feerate, or
> > > confirmed (both of which the peer is presumed to already have). If the
> > > pkg.feerate is sufficiently high to connect all external inputs to the
> > > intervening txs, they are added to the package and it is announced to
> > > the high fee peer. Note that the individual tx.feerate > peer.feerate
> > > is insufficient to ensure that the peer should have the tx, as there
> > > may be ancestor txs that do not, and for which the tx was insufficient
> > > to cause them to be packaged. So a non-caching algorithm must be able
> > > to chase each package external input to a confirmed tx (or cache the
> > > unconfirmed ancestry fee rate at each tx). Note that fee rates are not
> > > directly additive, both size/
> > > 
> > > weight and fee are required for summation (and aggregate sigops should
> > > be considered).
> > > 
> > > This makes no assumptions about current implementations. The design
> > > would call for maintenance of a transaction (input->output) DAG with
> > > tx.feerate on each tx. This could be the unconfirmed tx graph (i.e. "memory
> > > pool") though it does not require maintenance of anything more than the
> > > parameters necessary to confirm a set of validated txs within a block. It is
> > > very reasonable to require this of any participating node. A simple version
> > > negotiation can identify a package-accepting/sending nodes.
> > > 
> > > I have thought about this for some time, but have not implemented either
> > > the graph search, source code, or BIP. Just wrote this off the top of my head.
> > > So I am sure there are some things I have incorrect or failed to consider. But I
> > > think it's worth discussing it at this point.
> > > 
> > > e
> > > 
> > > > -----Original Message-----
> > > > From: bitcoin-dev bitcoin-dev-bounces at lists.linuxfoundation.org On
> > > > Behalf Of Suhas Daftuar via bitcoin-dev
> > > > Sent: Wednesday, June 8, 2022 8:59 AM
> > > > To: Bitcoin Protocol Discussion
> > > > bitcoin-dev at lists.linuxfoundation.org
> > > > Subject: Re: [bitcoin-dev] Package Relay Proposal
> > > > 
> > > > Hi,
> > > > 
> > > > Thanks again for your work on this!
> > > > 
> > > > One question I have is about potential bandwidth waste in the case
> > > > of nodes running with different policy rules. Here's my
> > > > understanding of a scenario I think could happen:
> > > > 
> > > > 1) Transaction A is both low-fee and non-standard to some nodes on
> > > > the network.
> > > > 2) Whenever a transaction T that spends A is relayed, new nodes will
> > > > send INV(PKGINFO1, T) to all package-relay peers.
> > > > 3) Nodes on the network that have implemented package relay, but do
> > > > not accept A, will send getdata(PKGINFO1, T) and learn all of T's
> > > > unconfirmed parents (~32 bytes * number of parents(T)).
> > > > 4) Such nodes will reject T. But because of transaction
> > > > malleability, and to avoid being blinded to a transaction
> > > > unnecessarily, these nodes will likely still send getdata(PKGINFO1,
> > > > T) to every node that announces T, in case someone has a transaction
> > > > that includes an alternate set of parent transactions that would pass
> > > > policy checks.
> > > > 
> > > > Is that understanding correct? I think a good design goal would be
> > > > to not waste bandwidth in non-adversarial situations. In this case,
> > > > there would be bandwidth waste from downloading duplicate data from
> > > > all your peers, just because the announcement doesn't commit to the
> > > > set of parent wtxids that we'd get from the peer (and so we are
> > > > unable to determine that all our peers would be telling us the same thing,
> > > > just based on the announcement).
> > > > 
> > > > Some ways to mitigate this might be to: (a) include a hash (maybe
> > > > even just a 20-byte hash -- is that enough security?) of the package
> > > > wtxids (in some canonical ordering) along with the wtxid of the
> > > > child in the initial announcement; (b) limit the use of v1 packages
> > > > to transactions with very few parents (I don't know if this is reasonable
> > > > for the use cases we have in mind).
> > > > 
> > > > Another point I wanted to bring up is about the rules around v1
> > > > package validation generally, and the use of a blockhash in
> > > > transaction relay specifically. My first observation is that it
> > > > won't always be the case that a v1 package relay node will be able
> > > > to validate that a set of package transactions is fully sorted
> > > > topologically, because there may be (non-parent) ancestors that are
> > > > missing from the package and the best a peer can validate is
> > > > topology within the package -- this means that a peer can validly
> > > > (under this
> > > > BIP) relay transaction packages out of the true topological sort (if
> > > > all ancestors were included).
> > > > 
> > > > This makes me wonder how useful this topological rule is. I suppose
> > > > there is some value in preventing completely broken implementations
> > > > from staying connected and so there is no harm in having the rule,
> > > > but perhaps it would be helpful to add that nodes SHOULD order
> > > > transactions based on topological sort in the complete transaction
> > > > graph, so that if missing-from-package ancestors are already known
> > > > by a peer (which is the expected case when using v1 package relay on
> > > > transactions that have more than one generation of unconfirmed
> > > > ancestor) then the remaining transactions are already properly ordered,
> > > > and this is helpful even if unenforceable in general.
> > > > 
> > > > The other observation I wanted to make was that having transaction
> > > > relay gated on whether two nodes agree on chain tip seems like an
> > > > overly restrictive criteria. I think an important design principle
> > > > is that we want to minimize disruption from network splits -- if
> > > > there are competing blocks found in a small window of time, it's
> > > > likely that the utxo set is not materially different on the two
> > > > chains (assuming miners are selecting from roughly the same sets of
> > > > transactions when this happens, which is typical). Having
> > > > transaction relay bifurcate on the two network halves would seem to
> > > > exacerbate the difference between the two sides of the split --
> > > > users ought to be agnostic about how benign splits are resolved and
> > > > would likely want their transactions to relay across the whole network.
> > > > 
> > > > Additionally, use of a chain tip might impose a larger burden than
> > > > is necessary on software that would seek to participate in
> > > > transaction relay without implementing headers sync/validation. I
> > > > don't know what software exists on the network, but I imagine there
> > > > are a lot of scripts out there for transaction submission to the
> > > > public p2p network, and in thinking about modifying such a script to
> > > > utilize package relay it seems like an unnecessary added burden to first
> > > > learn a node's tip before trying to relay a transaction.
> > > > 
> > > > Could you explain again what the benefit of including the blockhash
> > > > is? It seems like it is just so that a node could prioritize
> > > > transaction relay from peers with the same chain tip to maximize the
> > > > likelihood of transaction acceptance, but in the common case this
> > > > seems like a pretty negligible concern, and in the case of a chain
> > > > fork that persists for many minutes it seems better to me that we
> > > > not partition the network into package-relay regimes and just risk a
> > > > little extra bandwidth in one direction or the other. If we solve
> > > > the problem I brought up at the beginning (of de-duplicating package
> > > > data across peers with a package-wtxid-commitment in the
> > > > announcement), I think this is just some wasted pkginfo bandwidth on
> > > > a single-link, and not across links (as we could cache validation failure for a
> > > > package-hash to avoid re-requesting duplicate pkginfo1 messages).
> > > > 
> > > > Best,
> > > > Suhas
> > > > 
> > > > On Tue, Jun 7, 2022 at 1:57 PM Gloria Zhao via bitcoin-dev <bitcoin-
> > > > dev at lists.linuxfoundation.org <mailto:bitcoin-
> > > > dev at lists.linuxfoundation.org> > wrote:
> > > > 
> > > > Hi Eric, aj, all,
> > > > 
> > > > Sorry for the delayed response. @aj I'm including some paraphrased
> > > > points from our offline discussion (thanks).
> > > > 
> > > > > Other idea: what if you encode the parent txs as a short hash of
> > > > > the wtxid (something like bip152 short ids? perhaps seeded per
> > > > > peer so collisions will be different per peer?) and include that in the inv
> > > > > announcement?
> > > > > Would that work to avoid a round trip almost all of the time,
> > > > > while still giving you enough info to save bw by deduping parents?
> > > > 
> > > > > As I suggested earlier, a package is fundamentally a compact block
> > > > > (or
> > > > > block) announcement without the header. Compact block (BIP152)
> > > > > announcement is already well-defined and widely implemented...
> > > > 
> > > > > Let us not reinvent the wheel and/or introduce accidental
> > > > > complexity. I see no reason why packaging is not simply BIP152
> > > > > without the 'header'
> > > > > field, an
> > > > > updated protocol version, and the following sort of changes to
> > > > > names
> > > > 
> > > > Interestingly, "why not use BIP 152 shortids to save bandwidth?" is
> > > > by far the most common suggestion I hear (including offline feedback).
> > > > Here's a full explanation:
> > > > 
> > > > BIP 152 shortens transaction hashes (32 bytes) to shortids (6 bytes)
> > > > to save a significant amount of network bandwidth, which is
> > > > extremely important in block relay. However, this comes at the
> > > > expense of computational complexity. There is no way to directly
> > > > calculate a transaction hash from a shortid; upon receipt of a
> > > > compact block, a node is expected to calculate the shortids of every
> > > > unconfirmed transaction it knows about to find the matches (BIP 152:
> > > > 1, Bitcoin Core: 2). This is expensive but appropriate for block
> > > > relay, since the block must have a valid Proof of Work and new
> > > > blocks only come every ~10 minutes. On the other hand, if we require
> > > > nodes to calculate shortids for every transaction in their mempools every
> > > > time they receive a package, we are creating a DoS vector.
> > > > Unconfirmed transactions don't need PoW and, to have a live
> > > > transaction relay network, we should expect nodes to handle
> > > > transactions at a high-ish rate (i.e. at least 1000s of times more
> > > > transactions than blocks). We can't pre- calculate or cache shortids
> > > > for mempool transactions, since the SipHash key depends on the block
> > > > hash and a per-connection salt.
> > > > 
> > > > Additionally, shortid calculation is not designed to prevent
> > > > intentional individual collisions. If we were to use these shortids
> > > > to deduplicate transactions we've supposedly already seen, we may
> > > > have a censorship vector. Again, these tradeoffs make sense for
> > > > compact block relay (see shortid section in BIP 152 [3]), but not package
> > > > relay.
> > > > 
> > > > TLDR: DoSy if we calculate shortids on every package and censorship
> > > > vector if we use shortids for deduplication.
> > > > 
> > > > > Given this message there is no reason to send a (potentially
> > > > > bogus) fee rate with every package. It can only be validated by
> > > > > obtaining the full set of txs, and the only recourse is dropping
> > > > > (etc.) the peer, as is the case with single txs.
> > > > 
> > > > Yeah, I agree with this. Combined with the previous discussion with
> > > > aj (i.e. we can't accurately communicate the incentive compatibility
> > > > of a package without sending the full graph, and this whole dance is
> > > > to avoid downloading a few low-fee transactions in uncommon edge
> > > > cases), I've realized I should remove the fee + weight information
> > > > from pkginfo. Yay for less complexity!
> > > > 
> > > > Also, this might be pedantic, but I said something incorrect earlier
> > > > and would like to correct myself:
> > > > 
> > > > > > In theory, yes, but maybe it was announced earlier (while our
> > > > > > node was down?) or had dropped from our mempool or similar,
> > > > > > either way we don't have those txs yet.
> > > > 
> > > > I said "It's fine if they have Erlay, since a sender would know in
> > > > advance that B is missing and announce it as a package." But this
> > > > isn't true since we're only using reconciliation in place of
> > > > flooding to announce transactions as they arrive, not for
> > > > rebroadcast, and we're not doing full mempool set reconciliation. In
> > > > any case, making sure a node receives the transactions announced
> > > > when it was offline is not something we guarantee, not an intended use
> > > > case for package relay, and not worsened by this.
> > > > 
> > > > Thanks for your feedback!
> > > > 
> > > > Best,
> > > > 
> > > > Gloria
> > > > 
> > > > 0152.mediawiki#cmpctblock
> > > > 2:
> > > > https://github.com/bitcoin/bitcoin/blob/master/src/blockencodings.cp
> > > > p#L49
> > > > [3]: https://github.com/bitcoin/bips/blob/master/bip-
> > > > 0152.mediawiki#short-transaction-id-calculation
> > > > 
> > > > On Thu, May 26, 2022 at 3:59 AM <eric at voskuil.org
> > > > mailto:eric at voskuil.org > wrote:
> > > > 
> > > > Given that packages have no header, the package requires identity in
> > > > a
> > > > BIP152 scheme. For example 'header' and 'blockhash' fields can be
> > > > replaced with a Merkle root (e.g. "identity" field) for the package,
> > > > uniquely identifying the partially-ordered set of txs. And use of
> > > > 'getdata' (to obtain a package by hash) can be eliminated (not a use
> > > > case).
> > > > 
> > > > e
> > > > 
> > > > > -----Original Message-----
> > > > > From: eric at voskuil.org mailto:eric at voskuil.org
> > > > > <eric at voskuil.org mailto:eric at voskuil.org >
> > > > > Sent: Wednesday, May 25, 2022 1:52 PM
> > > > > To: 'Anthony Towns' <aj at erisian.com.au
> > > > > mailto:aj at erisian.com.au >; 'Bitcoin Protocol Discussion'
> > > > > <bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-
> > > > > dev at lists.linuxfoundation.org> >; 'Gloria Zhao'
> > > > > <gloriajzhao at gmail.com mailto:gloriajzhao at gmail.com >
> > > > > Subject: RE: [bitcoin-dev] Package Relay Proposal
> > > > > 
> > > > > > From: bitcoin-dev <bitcoin-dev-
> > > > > > bounces at lists.linuxfoundation.org <mailto:bitcoin-dev-
> > > > > > bounces at lists.linuxfoundation.org> > On
> > > > > > Behalf
> > > > > > Of Anthony Towns via bitcoin-dev
> > > > > > Sent: Wednesday, May 25, 2022 11:56 AM
> > > > > 
> > > > > > So the other thing is what happens if the peer
> > > > > > announcing packages to us
> > > > > > is
> > > > > > dishonest?
> > > > > > 
> > > > > > They announce pkg X, say X has parents A B C and the fee
> > > > > > rate is
> > > > > > garbage.
> > > > > > But
> > > > > > actually X has parent D and the fee rate is excellent. Do
> > > > > > we request the
> > > > > > package from another peer, or every peer, to double
> > > > > > check? Otherwise
> > > > > > we're
> > > > > > allowing the first peer we ask about a package to censor
> > > > > > that tx from
> > > > > > us?
> > > > > > 
> > > > > > I think the fix for that is just to provide the fee and weight
> > > > > > when
> > > > > > announcing
> > > > > > the package rather than only being asked for its info?
> > > > > > Then if one peer
> > > > > > makes
> > > > > > it sound like a good deal you ask for the parent txids from
> > > > > > them,
> > > > > > dedupe,
> > > > > > request, and verify they were honest about the parents.
> > > > > 
> > > > > Single tx broadcasts do not carry an advertised fee rate,
> > > > > however the'
> > > > > feefilter' message (BIP133) provides this distinction. This
> > > > > should be
> > > > > interpreted as applicable to packages. Given this message
> > > > > there is no
> > > > > reason
> > > > > to send a (potentially bogus) fee rate with every package. It
> > > > > can only be
> > > > > validated by obtaining the full set of txs, and the only
> > > > > recourse is
> > > > > dropping (etc.) the peer, as is the case with single txs.
> > > > > Relying on the
> > > > > existing message is simpler, more consistent, and more
> > > > > efficient.
> > > > > 
> > > > > > > > Is it plausible to add the graph in?
> > > > > > 
> > > > > > Likewise, I think you'd have to have the graph info from
> > > > > > many nodes if
> > > > > > you're
> > > > > > going to make decisions based on it and don't want
> > > > > > hostile peers to be
> > > > > > able to
> > > > > > trick you into ignoring txs.
> > > > > > 
> > > > > > Other idea: what if you encode the parent txs as a short
> > > > > > hash of the
> > > > > > wtxid
> > > > > > (something like bip152 short ids? perhaps seeded per
> > > > > > peer so collisions
> > > > > > will
> > > > > > be different per peer?) and include that in the inv
> > > > > > announcement? Would
> > > > > > that work to avoid a round trip almost all of the time,
> > > > > > while still
> > > > > > giving
> > > > > > you
> > > > > > enough info to save bw by deduping parents?
> > > > > 
> > > > > As I suggested earlier, a package is fundamentally a
> > > > > compact block (or
> > > > > block) announcement without the header. Compact block
> > > > > (BIP152)
> > > > > announcement
> > > > > is already well-defined and widely implemented. A node
> > > > > should never be
> > > > > required to retain an orphan, and BIP152 ensures this is not
> > > > > required.
> > > > > 
> > > > > Once a validated set of txs within the package has been
> > > > > obtained with
> > > > > sufficient fee, a fee-optimal node would accept the largest
> > > > > subgraph of
> > > > > the
> > > > > package that conforms to fee constraints and drop any
> > > > > peer that provides a
> > > > > package for which the full graph does not.
> > > > > 
> > > > > Let us not reinvent the wheel and/or introduce accidental
> > > > > complexity. I
> > > > > see
> > > > > no reason why packaging is not simply BIP152 without the
> > > > > 'header' field,
> > > > > an
> > > > > updated protocol version, and the following sort of changes
> > > > > to names:
> > > > > 
> > > > > sendpkg
> > > > > MSG_CMPCT_PKG
> > > > > cmpctpkg
> > > > > getpkgtxn
> > > > > pkgtxn
> > > > > 
> > > > > > > For a maximum 25 transactions,
> > > > > > > 2324/2 = 276, seems like 36 bytes for a child-with-
> > > > > > > parents package.
> > > > > > 
> > > > > > If you're doing short ids that's maybe 254B=100B
> > > > > > already, then the
> > > > > > above
> > > > > > is
> > > > > > up to 36% overhead, I guess. Might be worth thinking
> > > > > > more about, but
> > > > > > maybe
> > > > > > more interesting with ancestors than just parents.
> > > > > > 
> > > > > > > Also side note, since there are no size/count params,
> > > > > 
> > > > > Size is restricted in the same manner as block and
> > > > > transaction broadcasts,
> > > > > by consensus. If the fee rate is sufficient there would be no
> > > > > reason to
> > > > > preclude any valid size up to what can be mined in one
> > > > > block (packaging
> > > > > across blocks is not economically rational under the
> > > > > assumption that one
> > > > > miner cannot expect to mine multiple blocks in a row).
> > > > > Count is
> > > > > incorporated
> > > > > into BIP152 as 'shortids_length'.
> > > > > 
> > > > > > > wondering if we
> > > > > > > should just have "version" in "sendpackages" be a bit
> > > > > > > field instead of
> > > > > > > sending a message for each version. 32 versions should
> > > > > > > be enough right?
> > > > > 
> > > > > Adding versioning to individual protocols is just a reflection
> > > > > of the
> > > > > insufficiency of the initial protocol versioning design, and
> > > > > that of the
> > > > > various ad-hoc changes to it (including yet another
> > > > > approach in this
> > > > > proposal) that have been introduced to compensate for it,
> > > > > though I'll
> > > > > address this in an independent post at some point.
> > > > > 
> > > > > Best,
> > > > > e
> > > > > 
> > > > > > Maybe but a couple of messages per connection doesn't
> > > > > > really seem worth
> > > > > > arguing about?
> > > > > > 
> > > > > > Cheers,
> > > > > > aj
> > > > > > 
> > > > > > --
> > > > > > Sent from my phone.
> > > > 
> > > > _______________________________________________
> > > > 
> > > > > > bitcoin-dev mailing list
> > > > > > bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-
> > > > > > dev at lists.linuxfoundation.org>
> > > > 
> > > > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> > > > 
> > > > _______________________________________________
> > > > bitcoin-dev mailing list
> > > > bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-
> > > > dev at lists.linuxfoundation.org>
> > > > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> > > 
> > > _______________________________________________
> > > bitcoin-dev mailing list
> > > bitcoin-dev at lists.linuxfoundation.org
> > > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev


From eric at voskuil.org  Tue Sep 27 19:21:35 2022
From: eric at voskuil.org (Eric Voskuil)
Date: Tue, 27 Sep 2022 12:21:35 -0700
Subject: [bitcoin-dev] Packaged Transaction Relay
In-Reply-To: <A485FF21-3B14-49B4-BC53-99AFAA90E38D@voskuil.org>
References: <A485FF21-3B14-49B4-BC53-99AFAA90E38D@voskuil.org>
Message-ID: <AA9BD913-E5BA-4D70-B3DB-9D83C1BBB62E@voskuil.org>

Thanks again for the feedback. Comments inline.

> On Sep 27, 2022, at 02:29, alicexbt <alicexbt at protonmail.com> wrote:
> 
> ?Hi Eric,
> 
> 
>> If by "range" you mean a connected tx subgraph, I don't see why not. But note that nodes only operate over signed txs. PSBT is a wallet workflow.
> 
> Matt Corallo mentioned that pre-signed transactions created with low fee rate become an issue when they are broadcasted after a long time and there is a high demand for block space at that moment.

Yes, I understood this. There are many ways that a fee may be created which is too low for propagation.

> Example: 
> 
> Bob created PSBT1 in a multi party contract with fee rate 5 sat/vbyte however its taking hours/days to confirm the transaction with such low fee rate.
> 
> Carol created PSBT1 (5 sat/vbyte), PSBT2 (10 sat/vbyte) and PSBT3 (20 sat/vbyte) for spending same inputs. She broadcasted PSBT3 which got confirmed in a few minutes. 
> 
> 
>> Always. Only signed transactions are accepted. But assuming you are referring to a transaction that has been produced by a pre-signing workflow, I'm not sure how this would be distinct from any other tx.
> 
> 
> `minfeefilter` for all peers of my node was 0.00001000 at the time of writing this email. I am assuming nobody creates pre-signed transaction with fee rate below 1 sat/vbyte. How often does it happen that `minfeefilter` is above this default value?

I don?t consider node configuration relevant, regardless of its apparent consistency.

>> I'm not sure I follow this, maybe you could reword it. But it seems that you are saying that CPFP fee-bumping is a problem scenario and the complexity of the proposed solutions are not justified by such scenarios.
> 
> 
> Sorry that sentence was confusing. Yes complexity isn't justified for CPFP fee-bumping txs below minimum fee rate.
> 
> 
>> There are many node implementations used presently. And of course these are protocol proposals, which presumes more than one implementation.
> 
> 
> Yes, a few implementations exist (knots, libbitcoin, btcd, bcoin etc.) however they aren't used by lot of nodes. Based on this [chart][1] 98% nodes use bitcoin core. Lot of bitcoin protocol proposals are influenced by bitcoin core contributors and things could be different if even 30% nodes used other implementations.

I don?t consider such a measure relevant. This is a protocol consideration. Also consider that many nodes are not visible, and aspects of nodes, such as for p2p communication, are embedded into applications such as wallets - which could easily exceed the number of visible nodes.

>> I don't consider this relevant to any protocol considerations. Miners should always be expected to select the most optimal set of txs available in the time available to do so.
> 
> 
> Agree, miners should be expected to select most optimal set of txs. However, according to one [comment][2] by Pieter Wuille, miners could affect the security of some bitcoin projects with MEV.

This would be a deficiency in such projects, by assuming economic irrationality. The fact that fees will become a greater percentage of the block reward is a surprise to no one.

>> Over time we are likely to see that the only policies that remain in widespread application are those that are necessary for DOS protection (fee rate), as other restrictions are not economically rational and cannot be enforced. We've seen recent debate regarding dust policy, and op_return policy. "non-standard" txs are perfectly valid but get stuck very easily. I'll reiterate, any policy beyond what is published via the protocol will cause the above problems.
> 
> I completely agree with this.
> 
> 
> [1]: https://luke.dashjr.org/programs/bitcoin/files/charts/software.html
> [2]: https://bitcoin.stackexchange.com/questions/107787/front-running-in-bitcoin#comment123441_107796
> 
> 
> /dev/fd0

From michaelfolkson at protonmail.com  Wed Sep 28 11:48:32 2022
From: michaelfolkson at protonmail.com (Michael Folkson)
Date: Wed, 28 Sep 2022 11:48:32 +0000
Subject: [bitcoin-dev] bitcoin-inquistion: evaluating soft forks on
	signet
In-Reply-To: <Yyg++7tqBC9WGOzc@erisian.com.au>
References: <YyQioS3F942wu1HW@erisian.com.au>
 <CALZpt+HksJ8BFi-8jvKJQLskSiLnm5f-QR_zmFrsgLX19R630Q@mail.gmail.com>
 <Yyg++7tqBC9WGOzc@erisian.com.au>
Message-ID: <lEYH8tZZf8onusZyemenCfTXz44xohxMwOflLeHnxcsk-MwNuOFLKId8GQnLBkAe10UOUjD6tQ-pJhbpMDQMA7Y5FIK7xvs2bAvQI2KBbQs=@protonmail.com>

I've given this some extra thought and discussed with others who may later chime in on this thread. I'm now convinced this should be done on a custom public signet rather than on the default signet. SegWit was added to a new testnet (Segnet) for testing rather than the pre-existing testnet and I think future soft fork proposals should follow a similar approach.

Even if there is community consensus on what soft fork proposals should be added to the default signet today (which may or may not be case) I find it highly unlikely this will always be the case. We then get into the situation where the block signers (currently AJ and Kalle) are the gatekeepers on what soft fork proposals are added. The default signet is directly supported with the -signet flag in Bitcoin Core. Even if we are moving the proposed soft fork code to an external repo (to avoid it being merged into Core prematurely) it is still determining what soft forks are accessible from the signet flag in Bitcoin Core. I don't think it is fair on the signet block signers to put them in that position and I don't think it is wise to put other Bitcoin Core contributors/maintainers in the position of having to defend why some proposed soft forks are accessible on the default signet while others aren't.

The default signet was a long term project to address the unreliability and weaknesses of testnet. Many default signet users won't be interested in testing soft fork proposals and it is not reasonable for them to be subject to a stalling or forked blockchain because changes to a soft fork proposal or a buggy soft fork proposal pushed to the default signet makes previous valid/invalid transactions invalid/valid. If they want to test proposed soft forks on a custom signet they are opting in to possible disruption rather than it being forced upon them.

By focusing on custom signets rather than the default signet it also allows for more experimentation. Don't like the choices of which soft fork proposals have been added to bitcoin-inquisition? Set up your own custom signet with a different set of soft fork proposals and get users for your custom signet on a level playing field to bitcoin-inquisition. A soft fork proposal is found to be strictly inferior to another soft fork proposal? Just spin down the custom signet with that inferior soft fork proposal on it without impacting default signet users.

So TL;DR still enthusiastic about this concept. Just with a strong preference that it is done on a custom signet rather than on the default signet.

Thanks
Michael

--
Michael Folkson
Email: michaelfolkson at protonmail.com
Keybase: michaelfolkson
PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3


------- Original Message -------
On Monday, September 19th, 2022 at 11:05, Anthony Towns via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:


> On Sun, Sep 18, 2022 at 02:47:38PM -0400, Antoine Riard via bitcoin-dev wrote:
> 
> > Said succinctly, in the genesis of creative ideas, evaluation doesn't
> > happen at a single clear point but all along the idea lifetime, where this
> > evaluation is as much done by the original author than its peers and a
> > wider audience.
> 
> 
> Sure. I definitely didn't mean to imply a waterfall development model,
> or that the phases wouldn't overlap etc.
> 
> > I would still expose a concern to not downgrade in the pure empiricism in
> > matter of consensus upgrades. I.e, slowly emerging the norm of a working
> > prototype running on bitcoin-inquisition` as a determining factor of the
> > soundness of a proposal. E.g with "upgrading lightning to support eltoo", a
> > running e2e won't save us to think the thousands variants of pinnings, the
> > game-theory soundness of a eltoo as mechanism in face of congestions, the
> > evolvability of APO with more known upgrades proposals or the
> > implementation complexity of a fully fleshed-out state machine and more
> > questions.
> 
> 
> I agree here; but I think not doing prototypes also hinders thinking
> about all the thousands of details in a fork. It's easy to handwave
> details away when describing things on a whiteboard; and only realise
> they're trickier than you thought when you go to implement things.
> 
> > E,g if one implements the "weird" ideas
> > about changes in the block reward issuance schedule discussed during the
> > summer, another one might not want "noise" interferences with new
> > fee-bumping primitives as the miner incentives are modified.
> 
> 
> (I don't think "miner incentives" are really something that can be
> investigated on signet. You can assume how miners will respond to
> incentives and program the mining software to act that way; but there's
> no competitive pressure in signet mining so I don't think that really
> demonstrates anything very much. Likewise, there's much less demand for
> blockspace on signet than on mainnet, so it's probably hard to experiment
> with "fee incentives" too)
> 
> > I hope the upcoming
> > Contracting Primitives WG will be able to document and discuss some of the
> > relevant experiments run on bitcoin-inquisition.
> 
> 
> Likewise.
> 
> (Lots trimmed due to either agreeing with it or having nothing to add)
> 
> Cheers,
> aj
> 
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

From alicexbt at protonmail.com  Wed Sep 28 20:01:46 2022
From: alicexbt at protonmail.com (alicexbt)
Date: Wed, 28 Sep 2022 20:01:46 +0000
Subject: [bitcoin-dev] bitcoin-inquistion: evaluating soft forks on
	signet
In-Reply-To: <lEYH8tZZf8onusZyemenCfTXz44xohxMwOflLeHnxcsk-MwNuOFLKId8GQnLBkAe10UOUjD6tQ-pJhbpMDQMA7Y5FIK7xvs2bAvQI2KBbQs=@protonmail.com>
References: <YyQioS3F942wu1HW@erisian.com.au>
 <CALZpt+HksJ8BFi-8jvKJQLskSiLnm5f-QR_zmFrsgLX19R630Q@mail.gmail.com>
 <Yyg++7tqBC9WGOzc@erisian.com.au>
 <lEYH8tZZf8onusZyemenCfTXz44xohxMwOflLeHnxcsk-MwNuOFLKId8GQnLBkAe10UOUjD6tQ-pJhbpMDQMA7Y5FIK7xvs2bAvQI2KBbQs=@protonmail.com>
Message-ID: <U3f8PdO0Wm3FyUH3FViPodLCWlvZckitTgchR8hqxGSBPVjV2WTtbyFRxx3OZUd9TEm-p_Juft9EqjjkWG1LdmFdPmDP0WfW3RW_TgXOqtI=@protonmail.com>

Hi Michael,

> We then get into the situation where the block signers (currently AJ and Kalle) are the gatekeepers on what soft fork proposals are added.

Things that could solve the gatekeeping issue:

1) Adding more maintainers that are experienced enough to review consensus code. 
2) Every soft fork that is implemented on signet should be discussed on mailing list before merging the pull request.
3) Pull request that implements a soft fork should have at least 2 ACKs from the maintainers, 3 ACKs from developers who have either authored or reviewed enough consensus related pull requests in bitcoin core and 1 ACK from maintainers of other implementations (knots, btcd, libbitcoin, bcoin etc.)
4) Every technical NACK from any developer or user in the pull request should be resolved/answered before merging the pull request.

This was not the case in [implementing BIP][1] 119 however it could be used in future or something similar that everyone agrees upon including AJ and Kalle. Pull request implementing BIP 119 in bitcoin core is already reviewed by lot of developers and I think AJ found a [bug][2] recently.

Gatekeeping at several levels already exists in bitcoin development and difficult to solve. If some developers believe a soft fork should have been implemented on global signet but it was not, there is always the possibility of running custom signet with certain trade-offs.

> The default signet is directly supported with the -signet flag in Bitcoin Core. Even if we are moving the proposed soft fork code to an external repo (to avoid it being merged into Core prematurely) it is still determining what soft forks are accessible from the signet flag in Bitcoin Core. I don't think it is fair on the signet block signers to put them in that position and I don't think it is wise to put other Bitcoin Core contributors/maintainers in the position of having to defend why some proposed soft forks are accessible on the default signet while others aren't.

Mainnet and Testnet have already been [removed][3] from the 'bitcoin-inquisition/bitcoin' repository, and signet in bitcoin core is largely used by developers or power users, thus it should not be a problem. Signet could also be removed from bitcoin core binaries that are released regularly while being available if built from source.

Since signet coins have no value, utilizing this chain to experiment with soft forks will only help the bitcoin development process. If we can't even agree to implement something on a network used for testing then it will be nearly impossible to do any soft forks on mainnet. This experiment has several advantages. We can implement many consensus changes and compare alternatives in a better way. Pre-baked ability to abandon the soft fork isn't implemented yet AFAIK, however that could further improve things.


[1]: https://github.com/bitcoin-inquisition/bitcoin/pull/3
[2]: https://github.com/bitcoin/bitcoin/pull/21702#discussion_r979273387
[3]: https://github.com/bitcoin-inquisition/bitcoin/pull/1

/dev/fd0

Sent with Proton Mail secure email.


------- Original Message -------
On Wednesday, September 28th, 2022 at 5:18 PM, Michael Folkson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:


> I've given this some extra thought and discussed with others who may later chime in on this thread. I'm now convinced this should be done on a custom public signet rather than on the default signet. SegWit was added to a new testnet (Segnet) for testing rather than the pre-existing testnet and I think future soft fork proposals should follow a similar approach.
> 
> Even if there is community consensus on what soft fork proposals should be added to the default signet today (which may or may not be case) I find it highly unlikely this will always be the case. We then get into the situation where the block signers (currently AJ and Kalle) are the gatekeepers on what soft fork proposals are added. The default signet is directly supported with the -signet flag in Bitcoin Core. Even if we are moving the proposed soft fork code to an external repo (to avoid it being merged into Core prematurely) it is still determining what soft forks are accessible from the signet flag in Bitcoin Core. I don't think it is fair on the signet block signers to put them in that position and I don't think it is wise to put other Bitcoin Core contributors/maintainers in the position of having to defend why some proposed soft forks are accessible on the default signet while others aren't.
> 
> The default signet was a long term project to address the unreliability and weaknesses of testnet. Many default signet users won't be interested in testing soft fork proposals and it is not reasonable for them to be subject to a stalling or forked blockchain because changes to a soft fork proposal or a buggy soft fork proposal pushed to the default signet makes previous valid/invalid transactions invalid/valid. If they want to test proposed soft forks on a custom signet they are opting in to possible disruption rather than it being forced upon them.
> 
> By focusing on custom signets rather than the default signet it also allows for more experimentation. Don't like the choices of which soft fork proposals have been added to bitcoin-inquisition? Set up your own custom signet with a different set of soft fork proposals and get users for your custom signet on a level playing field to bitcoin-inquisition. A soft fork proposal is found to be strictly inferior to another soft fork proposal? Just spin down the custom signet with that inferior soft fork proposal on it without impacting default signet users.
> 
> So TL;DR still enthusiastic about this concept. Just with a strong preference that it is done on a custom signet rather than on the default signet.
> 
> Thanks
> Michael
> 
> --
> Michael Folkson
> Email: michaelfolkson at protonmail.com
> Keybase: michaelfolkson
> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3
> 
> 
> ------- Original Message -------
> On Monday, September 19th, 2022 at 11:05, Anthony Towns via bitcoin-dev bitcoin-dev at lists.linuxfoundation.org wrote:
> 
> 
> 
> > On Sun, Sep 18, 2022 at 02:47:38PM -0400, Antoine Riard via bitcoin-dev wrote:
> > 
> > > Said succinctly, in the genesis of creative ideas, evaluation doesn't
> > > happen at a single clear point but all along the idea lifetime, where this
> > > evaluation is as much done by the original author than its peers and a
> > > wider audience.
> > 
> > Sure. I definitely didn't mean to imply a waterfall development model,
> > or that the phases wouldn't overlap etc.
> > 
> > > I would still expose a concern to not downgrade in the pure empiricism in
> > > matter of consensus upgrades. I.e, slowly emerging the norm of a working
> > > prototype running on bitcoin-inquisition` as a determining factor of the
> > > soundness of a proposal. E.g with "upgrading lightning to support eltoo", a
> > > running e2e won't save us to think the thousands variants of pinnings, the
> > > game-theory soundness of a eltoo as mechanism in face of congestions, the
> > > evolvability of APO with more known upgrades proposals or the
> > > implementation complexity of a fully fleshed-out state machine and more
> > > questions.
> > 
> > I agree here; but I think not doing prototypes also hinders thinking
> > about all the thousands of details in a fork. It's easy to handwave
> > details away when describing things on a whiteboard; and only realise
> > they're trickier than you thought when you go to implement things.
> > 
> > > E,g if one implements the "weird" ideas
> > > about changes in the block reward issuance schedule discussed during the
> > > summer, another one might not want "noise" interferences with new
> > > fee-bumping primitives as the miner incentives are modified.
> > 
> > (I don't think "miner incentives" are really something that can be
> > investigated on signet. You can assume how miners will respond to
> > incentives and program the mining software to act that way; but there's
> > no competitive pressure in signet mining so I don't think that really
> > demonstrates anything very much. Likewise, there's much less demand for
> > blockspace on signet than on mainnet, so it's probably hard to experiment
> > with "fee incentives" too)
> > 
> > > I hope the upcoming
> > > Contracting Primitives WG will be able to document and discuss some of the
> > > relevant experiments run on bitcoin-inquisition.
> > 
> > Likewise.
> > 
> > (Lots trimmed due to either agreeing with it or having nothing to add)
> > 
> > Cheers,
> > aj
> > 
> > _______________________________________________
> > bitcoin-dev mailing list
> > bitcoin-dev at lists.linuxfoundation.org
> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> 
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

From bastien at acinq.fr  Thu Sep 29 09:15:02 2022
From: bastien at acinq.fr (Bastien TEINTURIER)
Date: Thu, 29 Sep 2022 11:15:02 +0200
Subject: [bitcoin-dev] New transaction policies (nVersion=3) for
 contracting protocols
In-Reply-To: <CAFXO6=JGBPVpxTJnSMWCCZVPHZW_RyWQ2Cv18Ao_F=uQx3LVkg@mail.gmail.com>
References: <CAFXO6=KDys2_dsrdxE9_q_MVZJOFMbg-MctxiokcicP=wd4Lkw@mail.gmail.com>
 <CALZpt+HYUti=foo+d5ER7Wj=PxsfgaU2CEqqG4_KRxmsWoaSxw@mail.gmail.com>
 <CACdvm3PyP9yrxx_Yewtx_yQh=i2uwGYj-wtY7HBER1bmG46NEw@mail.gmail.com>
 <CAB3F3Du=+YYKbfgB5LZPnCg40=5YCn_0tkpJ4LO9bMK0U-3wXg@mail.gmail.com>
 <CAFXO6=JGBPVpxTJnSMWCCZVPHZW_RyWQ2Cv18Ao_F=uQx3LVkg@mail.gmail.com>
Message-ID: <CACdvm3OUpODbMzkcG+=qYzR9myrvSp-LpuGmETow94JavU2GDw@mail.gmail.com>

Hi Gloria, Greg,

> I interpret most of the discussion around limitations as ideas for
> future improvements rather than criticisms of the proposal

As far as I'm concerned, definitely!

My current understanding is that the main change/improvement that would
make sense here is restricting the whole v3 package's size (instead of
just the child) via committing to a specific value in the taproot annex
(also note that it's probably not just the v3 package's size, it should
be the whole unconfirmed package including potential v2 unconfirmed
ancestors).

While I think this would be very valuable and would like to see this
happen, I believe that can be done in a second, separate step since this
would make relay policy stricter (some v3 transactions that previously
propagated wouldn't propagate under this new rule). As long as you are
able to find a path to miners through upgraded peers that use this annex
approach, you should be able to resolve ACP pinning issues?

I'm curious to know how other people feel about that: is it ok to do
later or should we try to implement this for the first release of v3
transactions?

The other change mentioned (making OP_TRUE standard and allowing outputs
that are below dust) can be added later, as those won't be standard until
we start allowing them, so there shouldn't be any backwards-compatibility
issue with postponing this change. But maybe it's still worth having from
the get-go, even though it may take a bit more time? Again, I'm curious to
have other people's opinion here, I'd be happy to get all of those directly
in the first release of v3 transactions, but I don't know how much
implementation will have to go into that.

> For clarification, package RBF is ParentTx*s*(plural), and
ChildTx(singular),
> so it might be a bit more complicated than we're thinking

Right, good catch, this does require new logic to handle this case.
As Gloria points out, this should be doable, and is definitely worth
adding (those CSV 1 on every other output are really hacky, glad to
find a way to get rid of them).

Thanks,
Bastien

Le lun. 26 sept. 2022 ? 18:48, Gloria Zhao <gloriajzhao at gmail.com> a ?crit :

> Hi Greg, Antoine, Bastien,
>
> Thanks very much for the feedback! I interpret most of the discussion
> around limitations as ideas for future improvements rather than criticisms
> of the proposal (please correct me if I'm wrong). I'll try to respond to as
> much as possible.
>
> Also I realize that I didn't contextualize this proposal clearly enough;
> it is very tailored for LN Penalty and definitely doesn't close all pinning
> attacks possible (sorry for confusing anyone). I also agree that some bits
> can be a little ugly or tack-on; I would definitely prefer a comprehensive
> RBF revamp to fix all our problems and enable other fee-bumping strategies
> such as
> sign-ANYONECANPAY-then-bring-your-own-fees-by-adding-inputs-at-broadcast. I
> was hoping to get some ideas with the "RBF Improvements" post in January,
> but it doesn't seem like we're much closer to a workable proposal. I think
> this is a minimally-invasive step that works for Lightning today, a small
> fix similar to CPFP carve out.
>
> > As you likely know from previous discussions the biggest scenario this
> does not fix in my estimation is ANYONECANPAY situations. If the parent
> transaction can be "inflated" by tacking on additional inputs, this means
> the total weight of the parent tx lowers the effective feerate of the
> package.
>
> (For more context to other readers I wrote an explanation for this in
> "SIGHASH_ANYONECANPAY Pinning" section of RBF ML post).  Yes, this
> unfortunately doesn't fix any of the existing pinning attacks for single
> transaction RBF but also doesn't make them worse. This boils down to adding
> an incentive compatibility rule that ensures you can't replace a
> transaction with something that will confirm slower. Package RBF has an
> ancestor feerate-based rule for this (note it is quite conservative and not
> perfect).
>
> So in the scenario above with the "inflated" parent that was signed ACP,
> the replacement would be rejected because the package ancestor feerate is
> lower than the feerate of what is being replaced. But it is imperfect
> (explained below) and thus I wouldn't recommend it for single transaction
> replacement. So that attack still exists for single transactions, yes.
>
> The strategy of using ACP to bring-your-own-fees has its own challenges
> but hopefully has no current use cases as you say. AFAIK LN Penalty is not
> affected by this since it doesn't use ACP, though obviously I agree we
> should fix it for the future.
>
> So when I said "this is intended for fee-bumping presigned txns in
> contracting protocols," I should have said "this is intended for
> fee-bumping presigned txns specifically using CPFP and anchor outputs."
> Apologies for forgetting to contextualize, I've been sitting on this for
> too long.
>
> > The other scenario it doesn't really fix is where HTLC/commitment-like
> transactions are being resolved in a batch, but due to relative time
> constraints, you may want to accelerate some and not others. Now you must
> pay higher rates to replace all of the transaction bumps. This is a
> "self-pin" and "get good at utxos noob" type problem, but it's something
> that axing rule#3 in favor of a Replace-by-ancestor-feerate system would
> get us.
>
> I understand you to mean "if you don't have enough UTXOs and you're forced
> to batch-bump, you over-pay because you need to bring them all to the
> highest target feerate." Isn't this kind of separate, wallet-related
> problem? Contracting or not, surely every wallet needs to have enough UTXOs
> to not batch transactions that shouldn't be batched... I don't see how a
> replace-by-ancestor-feerate policy would make any difference for this?
>
> Also in general I'd like to reiterate that ancestor feerate is not a
> panacea to all our RBF incentive compatibility concerns. Like individual
> feerate, unless we run the mining algorithm, it cannot tell us exactly how
> quickly this transaction would be mined.
>
> We're estimating the incentive compatibility of the original
> transaction(s) and replacement transaction(s), with the goal of not letting
> a transaction replace something that would have been more incentive
> compatible to mine. As such, we don't want to overestimate how good the
> replacement is, and we don't want to underestimate how good the original
> transactions are. This rule "The minimum between package feerate and
> ancestor feerate of the child is not lower than the individual feerates of
> all directly conflicting transactions and the ancestor feerates of all
> original transactions" is a conservative estimate.
>
> > Would kind of be nice if package RBF would detect a "sibling output
> spend" conflict, and knock it out of the mempool via the other replacement
> rules? Getting rid of the requirement to 1 block csv lock every output
> would be quite nice from a smart contracting composability point of view.
>
> Interesting, so when a transaction hits a mempool tx's descendant limit,
> we consider evicting one of its descendants in favor of this transaction,
> based on the RBF rules.
> Cool idea! After chewing on this for a bit, I think this *also* just boils
> down to the fact that RBF should require replacements to be better mining
> candidates. As in, if we added this policy and it can make us evict the
> sibling and accept a transaction with a bunch of low-feerate ancestor junk,
> it would be a new pinning vector.
>
> > If you're a miner and you receive a non-V3, second descendant of an
> unconfirmed V3 transaction, if the offered fee is in the top mempool
> backlog, I think you would have an interest to accept such a transaction.
>
> > So I'm not sure if those two rules are compatible with miners
> incentives...
>
> The same argument can be made for the 26th descendant of a mempool
> transaction; it's also not entirely incentive-compatible to reject it, but
> that is not the *only* design goal in mempool policy. Of course, the
> difference here is that the 25-descendant limit rule is a sensible DoS
> protection, while this 1-descendant limit rule is more of a "help the
> Bitcoin ecosystem" policy, just like CPFP carve-out, dust limit, etc. I can
> of course understand why not everyone would be in favor of this, but I do
> think it's worth it.
>
> > > 4. A V3 transaction that has an unconfirmed V3 ancestor cannot be
> > >    larger than 1000 virtual bytes.
>
> > If I understand correctly the 1000 vb upper bound rational, it would be
> to constraint the pinning counterparty to attach a high fee to a child due
> to the limited size, if they would like this transaction to be stuck in the
> network mempools. By doing so  this child has high odds to confirm.
>
> Yeah exactly, the "Rule 3 pin" is done by adding a child that's high-fee
> (so you have to pay that much to evict it). Because they *don't* want this
> tx to confirm, normally, this child would be really large. If they only
> have 1000vB for the child, they can't increase the replacement cost without
> also fee-bumping the transaction to make it confirm faster.
>
> > As of today, I think yes you can already fingerprint LN transactions on
> the  spec-defined amount value of the anchor outputs, 330 sats. There is
> always one of them on post-anchor commitment transactions. And sadly I
> would say we'll always have tricky fingerprints leaking from unilateral LN
> closures such as HTLC/PTLC timelocks...
>
> > I agree with you, this isn't worse than today, unilateral closes will
> probably always be identifiable on-chain.
>
> Great to hear that there is no privacy worsening!
>
> Best,
> Gloria
>
> On Mon, Sep 26, 2022 at 5:02 PM Greg Sanders <gsanders87 at gmail.com> wrote:
>
>> Bastien,
>>
>> > This may be already covered by the current package RBF logic, in that
>> scenario we are simply replacing [ParentTx, ChildTx1] with
>> [ParentTx, ChildTx2] that pays more fees, right?
>>
>> For clarification, package RBF is ParentTx*s*(plural), and
>> ChildTx(singular), so it might be a bit more complicated than we're
>> thinking, and currently the V3 proposal would first de-duplicate the
>> ParentTx based on what is in the mempool, then look at the "rest" of the
>> transactions as a package, then individually. Not the same, not sure how
>> different. I'll defer to experts.
>>
>> Best,
>> Greg
>>
>> On Mon, Sep 26, 2022 at 11:48 AM Bastien TEINTURIER via bitcoin-dev <
>> bitcoin-dev at lists.linuxfoundation.org> wrote:
>>
>>> Thanks Gloria for this great post.
>>>
>>> This is very valuable work for L2 contracts, and will greatly improve
>>> their security model.
>>>
>>> > "Only 1 anchor output? What if I need to bump counterparty's
>>> commitment tx in mempool?"
>>> > You won't need to fee-bump a counterparty's commitment tx using CPFP.
>>> > You would just package RBF it by attaching a high-feerate child to
>>> > your commitment tx.
>>>
>>> Note that we can also very easily make that single anchor spendable by
>>> both participants (or even anyone), so if you see your counterparty's
>>> commitment in your mempool, you can bump it without publishing your
>>> own commitment, which is quite desirable (your own commitment tx has
>>> CSV delays on your outputs, whereas your counterparty's commitment tx
>>> doesn't).
>>>
>>> > "Is this a privacy issue, i.e. doesn't it allow fingerprinting LN
>>> transactions based on nVersion?"
>>>
>>> I agree with you, this isn't worse than today, unilateral closes will
>>> probably always be identifiable on-chain.
>>>
>>> > Would kind of be nice if package RBF would detect a "sibling output
>>> spend"
>>> > conflict, and knock it out of the mempool via the other replacement
>>> rules?
>>> > Getting rid of the requirement to 1 block csv lock every output would
>>> be
>>> > quite nice from a smart contracting composability point of view.
>>>
>>> +1, that would be very neat!
>>>
>>> This may be already covered by the current package RBF logic, in that
>>> scenario we are simply replacing [ParentTx, ChildTx1] with
>>> [ParentTx, ChildTx2] that pays more fees, right?
>>>
>>> > 1) I do think that we should seriously consider allowing OP_TRUE to
>>> become
>>> > a standard script type as part of this policy update. If pinning is
>>> solved,
>>> > then there's no reason to require all those extra bytes for "binding"
>>> an
>>> > anchor to a specific wallet/user. We can save quite a few bytes by
>>> having
>>> > the input be empty of witness data.
>>> > 2) If we allow for a single dust-value(0 on up) output which is
>>> immediately
>>> > spent by the package, anchors become even easier to to design. No
>>> value has
>>> > to be "sapped" from contract participants to make an anchor output.
>>> There's
>>> > more complications for this, such as making sure the parent
>>> transaction is
>>> > dropped if the child spend is dropped, but maybe it's worth the
>>> squeeze.
>>>
>>> I also think both of these could be quite useful. This would probably
>>> always
>>> be used in combination with a parent transaction that pays 0 fees, so the
>>> 0-value output would always be spent in the same block.
>>>
>>> But this means we could end up with 0-value outputs in the utxo set, if
>>> for
>>> some reason the parent tx is CPFP-ed via another output than the 0-value
>>> one,
>>> which would be a utxo set bloat issue. But I'd argue that we're probably
>>> already creating utxo set bloat with the 330 sat anchor outputs
>>> (especially
>>> since we use two of them, but only one is usually spent), so it would
>>> probably be *better* than what we're doing today.
>>>
>>> Thanks,
>>> Bastien
>>>
>>> Le lun. 26 sept. 2022 ? 03:22, Antoine Riard via bitcoin-dev <
>>> bitcoin-dev at lists.linuxfoundation.org> a ?crit :
>>>
>>>> Hi Gloria,
>>>>
>>>> Thanks for the progress on package RBF, few early questions.
>>>>
>>>> > 2. Any descendant of an unconfirmed V3 transaction must also be V3.
>>>>
>>>> > 3. An unconfirmed V3 transaction cannot have more than 1 descendant.
>>>>
>>>> If you're a miner and you receive a non-V3, second descendant of an
>>>> unconfirmed V3 transaction, if the offered fee is in the top mempool
>>>> backlog, I think you would have an interest to accept such a transaction.
>>>>
>>>> So I'm not sure if those two rules are compatible with miners
>>>> incentives...
>>>>
>>>> > 4. A V3 transaction that has an unconfirmed V3 ancestor cannot be
>>>> >    larger than 1000 virtual bytes.
>>>>
>>>> If I understand correctly the 1000 vb upper bound rational, it would be
>>>> to constraint the pinning counterparty to attach a high fee to a child due
>>>> to the limited size, if they would like this transaction to be stuck in the
>>>> network mempools. By doing so  this child has high odds to confirm.
>>>>
>>>> I still wonder if this compatible with miner incentives in period of
>>>> empty mempools, in the sense that if you've already a V3 transaction of
>>>> size 100Kvb offering 2 sat/vb, it's more interesting than a V3 replacement
>>>> candidate of size 1000 vb offering 10 sat/vb. It could be argued the former
>>>> should be conserved.
>>>>
>>>> (That said, the hard thing with any replacement strategy we might evict
>>>> a parent transaction *now* to which is attached a high-feerate child
>>>> *latter* making for a utxo considered the best ancestor set. Maybe in the
>>>> long-term miners should keep every transaction ever accepted...)
>>>>
>>>> > (Lower bound) the smaller this limit, the fewer UTXOs a child may use
>>>> > to fund this fee-bump. For example, only allowing the V3 child to have
>>>> > 2 inputs would require L2 protocols to manage a wallet with high-value
>>>> > UTXOs and make batched fee-bumping impossible. However, as the
>>>> > fee-bumping child only needs to fund fees (as opposed to payments),
>>>> > just a few UTXOs should suffice.
>>>>
>>>> Reminder for L2 devs, batched fee-bumping of time-sensitive
>>>> confirmations of commitment transactions is unsafe, as the counterparty
>>>> could enter in a "cat-and-mouse" game to replace one of the batch element
>>>> at each block to delay confirmation of the remaining elements in the batch,
>>>> I think.
>>>>
>>>> On the other hand, I wonder if we wouldn't want a higher bound. LN
>>>> wallets are likely to have one big UTXO in their fee-bumping reserve pool,
>>>> as the cost of acquiring UTXO is non-null and in the optimistic case, you
>>>> don't need to do unilateral closure. Let's say you close dozens of channels
>>>> at the same time, a UTXO pool management strategy might be to fan-out the
>>>> first spends UTXOs in N fan-out outputs ready to feed the remaining
>>>> in-flight channels.
>>>>
>>>> > 1. The rule around unconfirmed inputs was
>>>> > originally "A package may include new unconfirmed inputs, but the
>>>> > ancestor feerate of the child must be at least as high as the ancestor
>>>> > feerates of every transaction being replaced."
>>>>
>>>> Note, I think we would like this new RBF rule to also apply to single
>>>> transaction package, e.g second-stage HTLC transactions, where a
>>>> counterparty pins a HTLC-preimage by abusing rule 3. In that case, the
>>>> honest LN node should be able to broadcast a "at least as high ancestor
>>>> feerate" HTLC-timeout transaction. With `option_anchor_outputs" there is no
>>>> unconfirmed ancestor to replace, as the commitment transaction, whatever
>>>> the party it is originating from, should already be confirmed.
>>>>
>>>> > "Is this a privacy issue, i.e. doesn't it allow fingerprinting LN
>>>> transactions based on nVersion?"
>>>>
>>>> As of today, I think yes you can already fingerprint LN transactions on
>>>> the  spec-defined amount value of the anchor outputs, 330 sats. There is
>>>> always one of them on post-anchor commitment transactions. And sadly I
>>>> would say we'll always have tricky fingerprints leaking from unilateral LN
>>>> closures such as HTLC/PTLC timelocks...
>>>>
>>>> > "Can a V2 transaction replace a V3 transaction and vice versa?"
>>>>
>>>> IIUC, a V3 package could replace a V2 package, with the benefit of the
>>>> new package RBF rules applied. I think this would be a significant
>>>> advantage for LN, as for the current ~85k of opened channels, the old V2
>>>> states shouldn't be pinning vectors. Currently, commitment transactions
>>>> signal replaceability.
>>>>
>>>> Le ven. 23 sept. 2022 ? 11:26, Gloria Zhao via bitcoin-dev <
>>>> bitcoin-dev at lists.linuxfoundation.org> a ?crit :
>>>>
>>>>> Hi everyone,
>>>>>
>>>>> I'm writing to propose a very simple set of mempool/transaction relay
>>>>> policies intended to aid L2/contract protocols. I realized that
>>>>> the previously proposed Package Mempool Accept package RBF [1]
>>>>> had a few remaining problems after digging into the RBF logic more [2].
>>>>> This additional set of policies solves them without requiring a huge
>>>>> RBF overhaul.
>>>>>
>>>>> I've written an implementation (and docs) for Bitcoin Core:
>>>>> https://github.com/bitcoin/bitcoin/pull/25038
>>>>>
>>>>> (You may notice that this proposal incorporates feedback on the PR -
>>>>> thanks Suhas Daftuar, Gregory Sanders, Bastien Teinturier, Anthony Towns,
>>>>> and others.)
>>>>>
>>>>> If you are interested in using package RBF/relay to bump presigned
>>>>> transactions, I think you may be interested in reviewing this proposal.
>>>>> This should solve Rule 3 pinning and perhaps allow us
>>>>> to get rid of CPFP carve-out (yay!). I'm keen to hear if people find
>>>>> the 1-anchor-output, 1000vB child limit too restrictive. Also, if you
>>>>> find a
>>>>> pinning attack or something that makes it unusable for you, I would
>>>>> really really like to know.
>>>>>
>>>>> Note that transactions with nVersion=3 ("V3 transactions") are
>>>>> currently non-standard in Bitcoin Core. That means **anything that was
>>>>> standard before this policy change would still be standard
>>>>> afterwards.** If you don't want your transactions to be subject to
>>>>> these rules, just continue whatever you're doing and don't use
>>>>> nVersion=3. AFAICT this shouldn't break anything, but let me know if
>>>>> this would be disruptive for you?
>>>>>
>>>>> **New Policies:**
>>>>>
>>>>> This includes:
>>>>> - a set of additional policy rules applying to V3 transactions
>>>>> - modifications to package RBF rules
>>>>>
>>>>> **V3 transactions:**
>>>>>
>>>>> Existing standardness rules apply to V3 (e.g. min/max tx weight,
>>>>> standard output types, cleanstack, etc.). The following additional
>>>>> rules apply to V3:
>>>>>
>>>>> 1. A V3 transaction can be replaced, even if it does not signal BIP125
>>>>>    replaceability. (It must also meet the other RBF rules around fees,
>>>>> etc. for replacement to happen).
>>>>>
>>>>> 2. Any descendant of an unconfirmed V3 transaction must also be V3.
>>>>>
>>>>> *Rationale*: Combined with Rule 1, this gives us the property of
>>>>> "inherited" replaceability signaling when descendants of unconfirmed
>>>>> transactions are created. Additionally, checking whether a transaction
>>>>> signals replaceability this way does not require mempool traversal,
>>>>> and does not change based on what transactions are mined. It also
>>>>> makes subsequent rules about descendant limits much easier to check.
>>>>>
>>>>> *Note*: The descendant of a *confirmed* V3 transaction does not need
>>>>> to be V3.
>>>>>
>>>>> 3. An unconfirmed V3 transaction cannot have more than 1 descendant.
>>>>>
>>>>> *Rationale*: (Upper bound) the larger the descendant limit, the more
>>>>> transactions may need to be replaced. This is a problematic pinning
>>>>> attack, i.e., a malicious counterparty prevents the transaction from
>>>>> being replaced by adding many descendant transactions that aren't
>>>>> fee-bumping.
>>>>>
>>>>> (Lower bound) at least 1 descendant is required to allow CPFP of the
>>>>> presigned transaction. The contract protocol can create presigned
>>>>> transactions paying 0 fees and 1 output for attaching a CPFP at
>>>>> broadcast time ("anchor output"). Without package RBF, multiple anchor
>>>>> outputs would be required to allow each counterparty to fee-bump any
>>>>> presigned transaction. With package RBF, since the presigned
>>>>> transactions can replace each other, 1 anchor output is sufficient.
>>>>>
>>>>> 4. A V3 transaction that has an unconfirmed V3 ancestor cannot be
>>>>>    larger than 1000 virtual bytes.
>>>>>
>>>>> *Rationale*: (Upper bound) the larger the descendant size limit, the
>>>>> more vbytes may need to be replaced. With default limits, if the child
>>>>> is e.g. 100,000vB, that might be an additional 100,000sats (at
>>>>> 1sat/vbyte) or more, depending on the feerate.
>>>>>
>>>>> (Lower bound) the smaller this limit, the fewer UTXOs a child may use
>>>>> to fund this fee-bump. For example, only allowing the V3 child to have
>>>>> 2 inputs would require L2 protocols to manage a wallet with high-value
>>>>> UTXOs and make batched fee-bumping impossible. However, as the
>>>>> fee-bumping child only needs to fund fees (as opposed to payments),
>>>>> just a few UTXOs should suffice.
>>>>>
>>>>> With a limit of 1000 virtual bytes, depending on the output types, the
>>>>> child can have 6-15 UTXOs, which should be enough to fund a fee-bump
>>>>> without requiring a carefully-managed UTXO pool. With 1000 virtual
>>>>> bytes as the descendant limit, the cost to replace a V3 transaction
>>>>> has much lower variance.
>>>>>
>>>>> *Rationale*: This makes the rule very easily "tacked on" to existing
>>>>> logic for policy and wallets. A transaction may be up to 100KvB on its
>>>>> own (`MAX_STANDARD_TX_WEIGHT`) and 101KvB with descendants
>>>>> (`DEFAULT_DESCENDANT_SIZE_LIMIT_KVB`). If an existing V3 transaction
>>>>> in the mempool is 100KvB, its descendant can only be 1000vB, even if
>>>>> the policy is 10KvB.
>>>>>
>>>>> **Package RBF modifications:**
>>>>>
>>>>> 1. The rule around unconfirmed inputs was
>>>>> originally "A package may include new unconfirmed inputs, but the
>>>>> ancestor feerate of the child must be at least as high as the ancestor
>>>>> feerates of every transaction being replaced."
>>>>>
>>>>> The package may still include new unconfirmed inputs. However,
>>>>> the new rule is modified to be "The minimum between package feerate
>>>>> and ancestor feerate of the child is not lower than the individual
>>>>> feerates of all directly conflicting transactions and the ancestor
>>>>> feerates of all original transactions."
>>>>>
>>>>> *Rationale*: We are attempting to ensure that the replacement
>>>>> transactions are not less incentive-compatible to mine. However, a
>>>>> package/transaction's ancestor feerate is not perfectly representative
>>>>> of its incentive compatibility; it may overestimate (some subset of
>>>>> the ancestors could be included by itself if it has other high-feerate
>>>>> descendants or are themselves higher feerate than this
>>>>> package/transaction). Instead, we use the minimum between the package
>>>>> feerate and ancestor feerate of the child as a more conservative value
>>>>> than what was proposed originally.
>>>>>
>>>>> 2. A new rule is added, requiring that all package transactions with
>>>>> mempool conflicts to be V3. This also means the "sponsoring"
>>>>> child transaction must be V3.
>>>>>
>>>>> *Note*: Combined with the V3 rules, this means the package must be
>>>>> a child-with-parents package. Since package validation is only
>>>>> attempted if the transactions do not pay sufficient fees to be
>>>>> accepted on their own, this effectively means that only V3
>>>>> transactions can pay to replace their ancestors' conflicts, and only
>>>>> V3 transactions' replacements may be paid for by a descendant.
>>>>>
>>>>> *Rationale*: The fee-related rules are economically rational for
>>>>> ancestor packages, but not necessarily other types of packages.
>>>>> A child-with-parents package is a type of ancestor package. It
>>>>> may be fine to allow any ancestor package, but it's more difficult
>>>>> to account for all of the possibilities. For example, it gets much
>>>>> harder to see that we're applying the descendant limits correctly if
>>>>> the package has a gnarly, many-generation, non-tree shape. I'm also
>>>>> not sure if this policy is 100% incentive-compatible if the sponsor
>>>>> is not a direct descendant of the sponsee.
>>>>>
>>>>> Please see doc/policy/version3_transactions.md and
>>>>> doc/policy/packages.md in the PR for the full set of rules.
>>>>>
>>>>> **Intended usage for LN:**
>>>>>
>>>>> Commitment transactions should be V3 and have 1 anchor output. They
>>>>> can be signed with 0 fees (or 1sat/vbyte) once package relay is
>>>>> deployed
>>>>> on a significant portion of the network. If the commitment tx must
>>>>> be broadcast, determine the desired feerate at broadcast time and
>>>>> spend the anchor output in a high feerate transaction. I'm going to
>>>>> call the broadcasted commitment tx "the parent" and the attached
>>>>> fee-bumping tx "the child."
>>>>>
>>>>> - This child must be V3.
>>>>> - This child must be at most 1000vB. Note this restricts the
>>>>>   number of inputs you can use to fund the fee bump. Depending
>>>>> on the output types, this is around 6-15.
>>>>> - One child may fund fees for multiple commitment tx ("batched
>>>>>   fee-bumping").
>>>>> - To do a second fee-bump to add more fees, replace the
>>>>>   *child* with a higher-feerate tx. Do not try to attach a grandchild.
>>>>>
>>>>> Otherwise, never try to spend from an unconfirmed V3 transaction. The
>>>>> descendant limits for V3 transactions are very restrictive.
>>>>>
>>>>> **Expected Questions:**
>>>>>
>>>>> "Does this fix Rule 3 Pinning?"
>>>>> Yes. The V3 descendant limit restricts both you and your counterparty.
>>>>> Assuming nodes adopted this policy, you may reasonably assume that you
>>>>> only need to replace the commitment transaction + up to 1000vB.
>>>>>
>>>>> "Only 1 anchor output? What if I need to bump counterparty's
>>>>> commitment tx in mempool?"
>>>>> You won't need to fee-bump a counterparty's commitment tx using CPFP.
>>>>> You would just package RBF it by attaching a high-feerate child to
>>>>> your commitment tx.
>>>>>
>>>>> "Is this a privacy issue, i.e. doesn't it allow fingerprinting LN
>>>>> transactions based on nVersion?"
>>>>> Indeed it may be unrealistic to assume V3 transactions will be in
>>>>> widespread use outside of L2. IIUC, unilateral closes are already
>>>>> obvious LN transactions because of the HTLC inputs. For e.g.
>>>>> cooperative closes and opens, I think it makes sense to continue using
>>>>> V2. So, unless I'm missing something, this shouldn't make it worse.
>>>>>
>>>>> "So a V3 transaction that doesn't signal BIP125 replaceability is
>>>>> replaceable? Is that a backward compatibility issue?"
>>>>> Yes it's replaceable. It's not an issue AFAICT because,
>>>>> under previous policy, the V3 transaction wouldn't have been
>>>>> in the mempool in the first place.
>>>>>
>>>>> "Can a V2 transaction replace a V3 transaction and vice versa?"
>>>>> Yes, otherwise someone can use V3 transactions to censor V2
>>>>> transactions spending shared inputs. Note if the
>>>>> original V3 transaction has an unconfirmed V3 parent, this would
>>>>> violate the "inherited V3" rule and would be rejected.
>>>>>
>>>>> Thanks for reading! Feedback and review would be much appreciated.
>>>>>
>>>>> [1]:
>>>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019464.html
>>>>> [2]:
>>>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019817.html
>>>>>
>>>>> Best,
>>>>> Gloria
>>>>> _______________________________________________
>>>>> bitcoin-dev mailing list
>>>>> bitcoin-dev at lists.linuxfoundation.org
>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>>>
>>>> _______________________________________________
>>>> bitcoin-dev mailing list
>>>> bitcoin-dev at lists.linuxfoundation.org
>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>>
>>> _______________________________________________
>>> bitcoin-dev mailing list
>>> bitcoin-dev at lists.linuxfoundation.org
>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220929/dba37dc7/attachment-0001.html>

From gsanders87 at gmail.com  Thu Sep 29 14:41:28 2022
From: gsanders87 at gmail.com (Greg Sanders)
Date: Thu, 29 Sep 2022 10:41:28 -0400
Subject: [bitcoin-dev] New transaction policies (nVersion=3) for
 contracting protocols
In-Reply-To: <CACdvm3OUpODbMzkcG+=qYzR9myrvSp-LpuGmETow94JavU2GDw@mail.gmail.com>
References: <CAFXO6=KDys2_dsrdxE9_q_MVZJOFMbg-MctxiokcicP=wd4Lkw@mail.gmail.com>
 <CALZpt+HYUti=foo+d5ER7Wj=PxsfgaU2CEqqG4_KRxmsWoaSxw@mail.gmail.com>
 <CACdvm3PyP9yrxx_Yewtx_yQh=i2uwGYj-wtY7HBER1bmG46NEw@mail.gmail.com>
 <CAB3F3Du=+YYKbfgB5LZPnCg40=5YCn_0tkpJ4LO9bMK0U-3wXg@mail.gmail.com>
 <CAFXO6=JGBPVpxTJnSMWCCZVPHZW_RyWQ2Cv18Ao_F=uQx3LVkg@mail.gmail.com>
 <CACdvm3OUpODbMzkcG+=qYzR9myrvSp-LpuGmETow94JavU2GDw@mail.gmail.com>
Message-ID: <CAB3F3DvCw9Ms+HUMaFnqV0P-Oo+rfERY+j5S5CC_X2NKRd5u8g@mail.gmail.com>

> Right, good catch, this does require new logic to handle this case.
As Gloria points out, this should be doable, and is definitely worth
adding (those CSV 1 on every other output are really hacky, glad to
find a way to get rid of them).

For the record, it turns out ephemeral anchors + v3 solves this already, as
the anchor must be spent, and the parent tx may only have one child.
Somehow I missed this implication for a few months. It's great news if we
can directly source fees from any output claimable, including HTLCs!

On Thu, Sep 29, 2022 at 5:15 AM Bastien TEINTURIER <bastien at acinq.fr> wrote:

> Hi Gloria, Greg,
>
> > I interpret most of the discussion around limitations as ideas for
> > future improvements rather than criticisms of the proposal
>
> As far as I'm concerned, definitely!
>
> My current understanding is that the main change/improvement that would
> make sense here is restricting the whole v3 package's size (instead of
> just the child) via committing to a specific value in the taproot annex
> (also note that it's probably not just the v3 package's size, it should
> be the whole unconfirmed package including potential v2 unconfirmed
> ancestors).
>
> While I think this would be very valuable and would like to see this
> happen, I believe that can be done in a second, separate step since this
> would make relay policy stricter (some v3 transactions that previously
> propagated wouldn't propagate under this new rule). As long as you are
> able to find a path to miners through upgraded peers that use this annex
> approach, you should be able to resolve ACP pinning issues?
>
> I'm curious to know how other people feel about that: is it ok to do
> later or should we try to implement this for the first release of v3
> transactions?
>
> The other change mentioned (making OP_TRUE standard and allowing outputs
> that are below dust) can be added later, as those won't be standard until
> we start allowing them, so there shouldn't be any backwards-compatibility
> issue with postponing this change. But maybe it's still worth having from
> the get-go, even though it may take a bit more time? Again, I'm curious to
> have other people's opinion here, I'd be happy to get all of those directly
> in the first release of v3 transactions, but I don't know how much
> implementation will have to go into that.
>
> > For clarification, package RBF is ParentTx*s*(plural), and
> ChildTx(singular),
> > so it might be a bit more complicated than we're thinking
>
> Right, good catch, this does require new logic to handle this case.
> As Gloria points out, this should be doable, and is definitely worth
> adding (those CSV 1 on every other output are really hacky, glad to
> find a way to get rid of them).
>
> Thanks,
> Bastien
>
> Le lun. 26 sept. 2022 ? 18:48, Gloria Zhao <gloriajzhao at gmail.com> a
> ?crit :
>
>> Hi Greg, Antoine, Bastien,
>>
>> Thanks very much for the feedback! I interpret most of the discussion
>> around limitations as ideas for future improvements rather than criticisms
>> of the proposal (please correct me if I'm wrong). I'll try to respond to as
>> much as possible.
>>
>> Also I realize that I didn't contextualize this proposal clearly enough;
>> it is very tailored for LN Penalty and definitely doesn't close all pinning
>> attacks possible (sorry for confusing anyone). I also agree that some bits
>> can be a little ugly or tack-on; I would definitely prefer a comprehensive
>> RBF revamp to fix all our problems and enable other fee-bumping strategies
>> such as
>> sign-ANYONECANPAY-then-bring-your-own-fees-by-adding-inputs-at-broadcast. I
>> was hoping to get some ideas with the "RBF Improvements" post in January,
>> but it doesn't seem like we're much closer to a workable proposal. I think
>> this is a minimally-invasive step that works for Lightning today, a small
>> fix similar to CPFP carve out.
>>
>> > As you likely know from previous discussions the biggest scenario this
>> does not fix in my estimation is ANYONECANPAY situations. If the parent
>> transaction can be "inflated" by tacking on additional inputs, this means
>> the total weight of the parent tx lowers the effective feerate of the
>> package.
>>
>> (For more context to other readers I wrote an explanation for this in
>> "SIGHASH_ANYONECANPAY Pinning" section of RBF ML post).  Yes, this
>> unfortunately doesn't fix any of the existing pinning attacks for single
>> transaction RBF but also doesn't make them worse. This boils down to adding
>> an incentive compatibility rule that ensures you can't replace a
>> transaction with something that will confirm slower. Package RBF has an
>> ancestor feerate-based rule for this (note it is quite conservative and not
>> perfect).
>>
>> So in the scenario above with the "inflated" parent that was signed ACP,
>> the replacement would be rejected because the package ancestor feerate is
>> lower than the feerate of what is being replaced. But it is imperfect
>> (explained below) and thus I wouldn't recommend it for single transaction
>> replacement. So that attack still exists for single transactions, yes.
>>
>> The strategy of using ACP to bring-your-own-fees has its own challenges
>> but hopefully has no current use cases as you say. AFAIK LN Penalty is not
>> affected by this since it doesn't use ACP, though obviously I agree we
>> should fix it for the future.
>>
>> So when I said "this is intended for fee-bumping presigned txns in
>> contracting protocols," I should have said "this is intended for
>> fee-bumping presigned txns specifically using CPFP and anchor outputs."
>> Apologies for forgetting to contextualize, I've been sitting on this for
>> too long.
>>
>> > The other scenario it doesn't really fix is where HTLC/commitment-like
>> transactions are being resolved in a batch, but due to relative time
>> constraints, you may want to accelerate some and not others. Now you must
>> pay higher rates to replace all of the transaction bumps. This is a
>> "self-pin" and "get good at utxos noob" type problem, but it's something
>> that axing rule#3 in favor of a Replace-by-ancestor-feerate system would
>> get us.
>>
>> I understand you to mean "if you don't have enough UTXOs and you're
>> forced to batch-bump, you over-pay because you need to bring them all to
>> the highest target feerate." Isn't this kind of separate, wallet-related
>> problem? Contracting or not, surely every wallet needs to have enough UTXOs
>> to not batch transactions that shouldn't be batched... I don't see how a
>> replace-by-ancestor-feerate policy would make any difference for this?
>>
>> Also in general I'd like to reiterate that ancestor feerate is not a
>> panacea to all our RBF incentive compatibility concerns. Like individual
>> feerate, unless we run the mining algorithm, it cannot tell us exactly how
>> quickly this transaction would be mined.
>>
>> We're estimating the incentive compatibility of the original
>> transaction(s) and replacement transaction(s), with the goal of not letting
>> a transaction replace something that would have been more incentive
>> compatible to mine. As such, we don't want to overestimate how good the
>> replacement is, and we don't want to underestimate how good the original
>> transactions are. This rule "The minimum between package feerate and
>> ancestor feerate of the child is not lower than the individual feerates of
>> all directly conflicting transactions and the ancestor feerates of all
>> original transactions" is a conservative estimate.
>>
>> > Would kind of be nice if package RBF would detect a "sibling output
>> spend" conflict, and knock it out of the mempool via the other replacement
>> rules? Getting rid of the requirement to 1 block csv lock every output
>> would be quite nice from a smart contracting composability point of view.
>>
>> Interesting, so when a transaction hits a mempool tx's descendant limit,
>> we consider evicting one of its descendants in favor of this transaction,
>> based on the RBF rules.
>> Cool idea! After chewing on this for a bit, I think this *also* just
>> boils down to the fact that RBF should require replacements to be better
>> mining candidates. As in, if we added this policy and it can make us evict
>> the sibling and accept a transaction with a bunch of low-feerate ancestor
>> junk, it would be a new pinning vector.
>>
>> > If you're a miner and you receive a non-V3, second descendant of an
>> unconfirmed V3 transaction, if the offered fee is in the top mempool
>> backlog, I think you would have an interest to accept such a transaction.
>>
>> > So I'm not sure if those two rules are compatible with miners
>> incentives...
>>
>> The same argument can be made for the 26th descendant of a mempool
>> transaction; it's also not entirely incentive-compatible to reject it, but
>> that is not the *only* design goal in mempool policy. Of course, the
>> difference here is that the 25-descendant limit rule is a sensible DoS
>> protection, while this 1-descendant limit rule is more of a "help the
>> Bitcoin ecosystem" policy, just like CPFP carve-out, dust limit, etc. I can
>> of course understand why not everyone would be in favor of this, but I do
>> think it's worth it.
>>
>> > > 4. A V3 transaction that has an unconfirmed V3 ancestor cannot be
>> > >    larger than 1000 virtual bytes.
>>
>> > If I understand correctly the 1000 vb upper bound rational, it would be
>> to constraint the pinning counterparty to attach a high fee to a child due
>> to the limited size, if they would like this transaction to be stuck in the
>> network mempools. By doing so  this child has high odds to confirm.
>>
>> Yeah exactly, the "Rule 3 pin" is done by adding a child that's high-fee
>> (so you have to pay that much to evict it). Because they *don't* want this
>> tx to confirm, normally, this child would be really large. If they only
>> have 1000vB for the child, they can't increase the replacement cost without
>> also fee-bumping the transaction to make it confirm faster.
>>
>> > As of today, I think yes you can already fingerprint LN transactions on
>> the  spec-defined amount value of the anchor outputs, 330 sats. There is
>> always one of them on post-anchor commitment transactions. And sadly I
>> would say we'll always have tricky fingerprints leaking from unilateral LN
>> closures such as HTLC/PTLC timelocks...
>>
>> > I agree with you, this isn't worse than today, unilateral closes will
>> probably always be identifiable on-chain.
>>
>> Great to hear that there is no privacy worsening!
>>
>> Best,
>> Gloria
>>
>> On Mon, Sep 26, 2022 at 5:02 PM Greg Sanders <gsanders87 at gmail.com>
>> wrote:
>>
>>> Bastien,
>>>
>>> > This may be already covered by the current package RBF logic, in that
>>> scenario we are simply replacing [ParentTx, ChildTx1] with
>>> [ParentTx, ChildTx2] that pays more fees, right?
>>>
>>> For clarification, package RBF is ParentTx*s*(plural), and
>>> ChildTx(singular), so it might be a bit more complicated than we're
>>> thinking, and currently the V3 proposal would first de-duplicate the
>>> ParentTx based on what is in the mempool, then look at the "rest" of the
>>> transactions as a package, then individually. Not the same, not sure how
>>> different. I'll defer to experts.
>>>
>>> Best,
>>> Greg
>>>
>>> On Mon, Sep 26, 2022 at 11:48 AM Bastien TEINTURIER via bitcoin-dev <
>>> bitcoin-dev at lists.linuxfoundation.org> wrote:
>>>
>>>> Thanks Gloria for this great post.
>>>>
>>>> This is very valuable work for L2 contracts, and will greatly improve
>>>> their security model.
>>>>
>>>> > "Only 1 anchor output? What if I need to bump counterparty's
>>>> commitment tx in mempool?"
>>>> > You won't need to fee-bump a counterparty's commitment tx using CPFP.
>>>> > You would just package RBF it by attaching a high-feerate child to
>>>> > your commitment tx.
>>>>
>>>> Note that we can also very easily make that single anchor spendable by
>>>> both participants (or even anyone), so if you see your counterparty's
>>>> commitment in your mempool, you can bump it without publishing your
>>>> own commitment, which is quite desirable (your own commitment tx has
>>>> CSV delays on your outputs, whereas your counterparty's commitment tx
>>>> doesn't).
>>>>
>>>> > "Is this a privacy issue, i.e. doesn't it allow fingerprinting LN
>>>> transactions based on nVersion?"
>>>>
>>>> I agree with you, this isn't worse than today, unilateral closes will
>>>> probably always be identifiable on-chain.
>>>>
>>>> > Would kind of be nice if package RBF would detect a "sibling output
>>>> spend"
>>>> > conflict, and knock it out of the mempool via the other replacement
>>>> rules?
>>>> > Getting rid of the requirement to 1 block csv lock every output would
>>>> be
>>>> > quite nice from a smart contracting composability point of view.
>>>>
>>>> +1, that would be very neat!
>>>>
>>>> This may be already covered by the current package RBF logic, in that
>>>> scenario we are simply replacing [ParentTx, ChildTx1] with
>>>> [ParentTx, ChildTx2] that pays more fees, right?
>>>>
>>>> > 1) I do think that we should seriously consider allowing OP_TRUE to
>>>> become
>>>> > a standard script type as part of this policy update. If pinning is
>>>> solved,
>>>> > then there's no reason to require all those extra bytes for "binding"
>>>> an
>>>> > anchor to a specific wallet/user. We can save quite a few bytes by
>>>> having
>>>> > the input be empty of witness data.
>>>> > 2) If we allow for a single dust-value(0 on up) output which is
>>>> immediately
>>>> > spent by the package, anchors become even easier to to design. No
>>>> value has
>>>> > to be "sapped" from contract participants to make an anchor output.
>>>> There's
>>>> > more complications for this, such as making sure the parent
>>>> transaction is
>>>> > dropped if the child spend is dropped, but maybe it's worth the
>>>> squeeze.
>>>>
>>>> I also think both of these could be quite useful. This would probably
>>>> always
>>>> be used in combination with a parent transaction that pays 0 fees, so
>>>> the
>>>> 0-value output would always be spent in the same block.
>>>>
>>>> But this means we could end up with 0-value outputs in the utxo set, if
>>>> for
>>>> some reason the parent tx is CPFP-ed via another output than the
>>>> 0-value one,
>>>> which would be a utxo set bloat issue. But I'd argue that we're probably
>>>> already creating utxo set bloat with the 330 sat anchor outputs
>>>> (especially
>>>> since we use two of them, but only one is usually spent), so it would
>>>> probably be *better* than what we're doing today.
>>>>
>>>> Thanks,
>>>> Bastien
>>>>
>>>> Le lun. 26 sept. 2022 ? 03:22, Antoine Riard via bitcoin-dev <
>>>> bitcoin-dev at lists.linuxfoundation.org> a ?crit :
>>>>
>>>>> Hi Gloria,
>>>>>
>>>>> Thanks for the progress on package RBF, few early questions.
>>>>>
>>>>> > 2. Any descendant of an unconfirmed V3 transaction must also be V3.
>>>>>
>>>>> > 3. An unconfirmed V3 transaction cannot have more than 1 descendant.
>>>>>
>>>>> If you're a miner and you receive a non-V3, second descendant of an
>>>>> unconfirmed V3 transaction, if the offered fee is in the top mempool
>>>>> backlog, I think you would have an interest to accept such a transaction.
>>>>>
>>>>> So I'm not sure if those two rules are compatible with miners
>>>>> incentives...
>>>>>
>>>>> > 4. A V3 transaction that has an unconfirmed V3 ancestor cannot be
>>>>> >    larger than 1000 virtual bytes.
>>>>>
>>>>> If I understand correctly the 1000 vb upper bound rational, it would
>>>>> be to constraint the pinning counterparty to attach a high fee to a child
>>>>> due to the limited size, if they would like this transaction to be stuck in
>>>>> the network mempools. By doing so  this child has high odds to confirm.
>>>>>
>>>>> I still wonder if this compatible with miner incentives in period of
>>>>> empty mempools, in the sense that if you've already a V3 transaction of
>>>>> size 100Kvb offering 2 sat/vb, it's more interesting than a V3 replacement
>>>>> candidate of size 1000 vb offering 10 sat/vb. It could be argued the former
>>>>> should be conserved.
>>>>>
>>>>> (That said, the hard thing with any replacement strategy we might
>>>>> evict a parent transaction *now* to which is attached a high-feerate child
>>>>> *latter* making for a utxo considered the best ancestor set. Maybe in the
>>>>> long-term miners should keep every transaction ever accepted...)
>>>>>
>>>>> > (Lower bound) the smaller this limit, the fewer UTXOs a child may use
>>>>> > to fund this fee-bump. For example, only allowing the V3 child to
>>>>> have
>>>>> > 2 inputs would require L2 protocols to manage a wallet with
>>>>> high-value
>>>>> > UTXOs and make batched fee-bumping impossible. However, as the
>>>>> > fee-bumping child only needs to fund fees (as opposed to payments),
>>>>> > just a few UTXOs should suffice.
>>>>>
>>>>> Reminder for L2 devs, batched fee-bumping of time-sensitive
>>>>> confirmations of commitment transactions is unsafe, as the counterparty
>>>>> could enter in a "cat-and-mouse" game to replace one of the batch element
>>>>> at each block to delay confirmation of the remaining elements in the batch,
>>>>> I think.
>>>>>
>>>>> On the other hand, I wonder if we wouldn't want a higher bound. LN
>>>>> wallets are likely to have one big UTXO in their fee-bumping reserve pool,
>>>>> as the cost of acquiring UTXO is non-null and in the optimistic case, you
>>>>> don't need to do unilateral closure. Let's say you close dozens of channels
>>>>> at the same time, a UTXO pool management strategy might be to fan-out the
>>>>> first spends UTXOs in N fan-out outputs ready to feed the remaining
>>>>> in-flight channels.
>>>>>
>>>>> > 1. The rule around unconfirmed inputs was
>>>>> > originally "A package may include new unconfirmed inputs, but the
>>>>> > ancestor feerate of the child must be at least as high as the
>>>>> ancestor
>>>>> > feerates of every transaction being replaced."
>>>>>
>>>>> Note, I think we would like this new RBF rule to also apply to single
>>>>> transaction package, e.g second-stage HTLC transactions, where a
>>>>> counterparty pins a HTLC-preimage by abusing rule 3. In that case, the
>>>>> honest LN node should be able to broadcast a "at least as high ancestor
>>>>> feerate" HTLC-timeout transaction. With `option_anchor_outputs" there is no
>>>>> unconfirmed ancestor to replace, as the commitment transaction, whatever
>>>>> the party it is originating from, should already be confirmed.
>>>>>
>>>>> > "Is this a privacy issue, i.e. doesn't it allow fingerprinting LN
>>>>> transactions based on nVersion?"
>>>>>
>>>>> As of today, I think yes you can already fingerprint LN transactions
>>>>> on the  spec-defined amount value of the anchor outputs, 330 sats. There is
>>>>> always one of them on post-anchor commitment transactions. And sadly I
>>>>> would say we'll always have tricky fingerprints leaking from unilateral LN
>>>>> closures such as HTLC/PTLC timelocks...
>>>>>
>>>>> > "Can a V2 transaction replace a V3 transaction and vice versa?"
>>>>>
>>>>> IIUC, a V3 package could replace a V2 package, with the benefit of the
>>>>> new package RBF rules applied. I think this would be a significant
>>>>> advantage for LN, as for the current ~85k of opened channels, the old V2
>>>>> states shouldn't be pinning vectors. Currently, commitment transactions
>>>>> signal replaceability.
>>>>>
>>>>> Le ven. 23 sept. 2022 ? 11:26, Gloria Zhao via bitcoin-dev <
>>>>> bitcoin-dev at lists.linuxfoundation.org> a ?crit :
>>>>>
>>>>>> Hi everyone,
>>>>>>
>>>>>> I'm writing to propose a very simple set of mempool/transaction relay
>>>>>> policies intended to aid L2/contract protocols. I realized that
>>>>>> the previously proposed Package Mempool Accept package RBF [1]
>>>>>> had a few remaining problems after digging into the RBF logic more
>>>>>> [2].
>>>>>> This additional set of policies solves them without requiring a huge
>>>>>> RBF overhaul.
>>>>>>
>>>>>> I've written an implementation (and docs) for Bitcoin Core:
>>>>>> https://github.com/bitcoin/bitcoin/pull/25038
>>>>>>
>>>>>> (You may notice that this proposal incorporates feedback on the PR -
>>>>>> thanks Suhas Daftuar, Gregory Sanders, Bastien Teinturier, Anthony Towns,
>>>>>> and others.)
>>>>>>
>>>>>> If you are interested in using package RBF/relay to bump presigned
>>>>>> transactions, I think you may be interested in reviewing this
>>>>>> proposal.
>>>>>> This should solve Rule 3 pinning and perhaps allow us
>>>>>> to get rid of CPFP carve-out (yay!). I'm keen to hear if people find
>>>>>> the 1-anchor-output, 1000vB child limit too restrictive. Also, if you
>>>>>> find a
>>>>>> pinning attack or something that makes it unusable for you, I would
>>>>>> really really like to know.
>>>>>>
>>>>>> Note that transactions with nVersion=3 ("V3 transactions") are
>>>>>> currently non-standard in Bitcoin Core. That means **anything that was
>>>>>> standard before this policy change would still be standard
>>>>>> afterwards.** If you don't want your transactions to be subject to
>>>>>> these rules, just continue whatever you're doing and don't use
>>>>>> nVersion=3. AFAICT this shouldn't break anything, but let me know if
>>>>>> this would be disruptive for you?
>>>>>>
>>>>>> **New Policies:**
>>>>>>
>>>>>> This includes:
>>>>>> - a set of additional policy rules applying to V3 transactions
>>>>>> - modifications to package RBF rules
>>>>>>
>>>>>> **V3 transactions:**
>>>>>>
>>>>>> Existing standardness rules apply to V3 (e.g. min/max tx weight,
>>>>>> standard output types, cleanstack, etc.). The following additional
>>>>>> rules apply to V3:
>>>>>>
>>>>>> 1. A V3 transaction can be replaced, even if it does not signal BIP125
>>>>>>    replaceability. (It must also meet the other RBF rules around fees,
>>>>>> etc. for replacement to happen).
>>>>>>
>>>>>> 2. Any descendant of an unconfirmed V3 transaction must also be V3.
>>>>>>
>>>>>> *Rationale*: Combined with Rule 1, this gives us the property of
>>>>>> "inherited" replaceability signaling when descendants of unconfirmed
>>>>>> transactions are created. Additionally, checking whether a transaction
>>>>>> signals replaceability this way does not require mempool traversal,
>>>>>> and does not change based on what transactions are mined. It also
>>>>>> makes subsequent rules about descendant limits much easier to check.
>>>>>>
>>>>>> *Note*: The descendant of a *confirmed* V3 transaction does not need
>>>>>> to be V3.
>>>>>>
>>>>>> 3. An unconfirmed V3 transaction cannot have more than 1 descendant.
>>>>>>
>>>>>> *Rationale*: (Upper bound) the larger the descendant limit, the more
>>>>>> transactions may need to be replaced. This is a problematic pinning
>>>>>> attack, i.e., a malicious counterparty prevents the transaction from
>>>>>> being replaced by adding many descendant transactions that aren't
>>>>>> fee-bumping.
>>>>>>
>>>>>> (Lower bound) at least 1 descendant is required to allow CPFP of the
>>>>>> presigned transaction. The contract protocol can create presigned
>>>>>> transactions paying 0 fees and 1 output for attaching a CPFP at
>>>>>> broadcast time ("anchor output"). Without package RBF, multiple anchor
>>>>>> outputs would be required to allow each counterparty to fee-bump any
>>>>>> presigned transaction. With package RBF, since the presigned
>>>>>> transactions can replace each other, 1 anchor output is sufficient.
>>>>>>
>>>>>> 4. A V3 transaction that has an unconfirmed V3 ancestor cannot be
>>>>>>    larger than 1000 virtual bytes.
>>>>>>
>>>>>> *Rationale*: (Upper bound) the larger the descendant size limit, the
>>>>>> more vbytes may need to be replaced. With default limits, if the child
>>>>>> is e.g. 100,000vB, that might be an additional 100,000sats (at
>>>>>> 1sat/vbyte) or more, depending on the feerate.
>>>>>>
>>>>>> (Lower bound) the smaller this limit, the fewer UTXOs a child may use
>>>>>> to fund this fee-bump. For example, only allowing the V3 child to have
>>>>>> 2 inputs would require L2 protocols to manage a wallet with high-value
>>>>>> UTXOs and make batched fee-bumping impossible. However, as the
>>>>>> fee-bumping child only needs to fund fees (as opposed to payments),
>>>>>> just a few UTXOs should suffice.
>>>>>>
>>>>>> With a limit of 1000 virtual bytes, depending on the output types, the
>>>>>> child can have 6-15 UTXOs, which should be enough to fund a fee-bump
>>>>>> without requiring a carefully-managed UTXO pool. With 1000 virtual
>>>>>> bytes as the descendant limit, the cost to replace a V3 transaction
>>>>>> has much lower variance.
>>>>>>
>>>>>> *Rationale*: This makes the rule very easily "tacked on" to existing
>>>>>> logic for policy and wallets. A transaction may be up to 100KvB on its
>>>>>> own (`MAX_STANDARD_TX_WEIGHT`) and 101KvB with descendants
>>>>>> (`DEFAULT_DESCENDANT_SIZE_LIMIT_KVB`). If an existing V3 transaction
>>>>>> in the mempool is 100KvB, its descendant can only be 1000vB, even if
>>>>>> the policy is 10KvB.
>>>>>>
>>>>>> **Package RBF modifications:**
>>>>>>
>>>>>> 1. The rule around unconfirmed inputs was
>>>>>> originally "A package may include new unconfirmed inputs, but the
>>>>>> ancestor feerate of the child must be at least as high as the ancestor
>>>>>> feerates of every transaction being replaced."
>>>>>>
>>>>>> The package may still include new unconfirmed inputs. However,
>>>>>> the new rule is modified to be "The minimum between package feerate
>>>>>> and ancestor feerate of the child is not lower than the individual
>>>>>> feerates of all directly conflicting transactions and the ancestor
>>>>>> feerates of all original transactions."
>>>>>>
>>>>>> *Rationale*: We are attempting to ensure that the replacement
>>>>>> transactions are not less incentive-compatible to mine. However, a
>>>>>> package/transaction's ancestor feerate is not perfectly representative
>>>>>> of its incentive compatibility; it may overestimate (some subset of
>>>>>> the ancestors could be included by itself if it has other high-feerate
>>>>>> descendants or are themselves higher feerate than this
>>>>>> package/transaction). Instead, we use the minimum between the package
>>>>>> feerate and ancestor feerate of the child as a more conservative value
>>>>>> than what was proposed originally.
>>>>>>
>>>>>> 2. A new rule is added, requiring that all package transactions with
>>>>>> mempool conflicts to be V3. This also means the "sponsoring"
>>>>>> child transaction must be V3.
>>>>>>
>>>>>> *Note*: Combined with the V3 rules, this means the package must be
>>>>>> a child-with-parents package. Since package validation is only
>>>>>> attempted if the transactions do not pay sufficient fees to be
>>>>>> accepted on their own, this effectively means that only V3
>>>>>> transactions can pay to replace their ancestors' conflicts, and only
>>>>>> V3 transactions' replacements may be paid for by a descendant.
>>>>>>
>>>>>> *Rationale*: The fee-related rules are economically rational for
>>>>>> ancestor packages, but not necessarily other types of packages.
>>>>>> A child-with-parents package is a type of ancestor package. It
>>>>>> may be fine to allow any ancestor package, but it's more difficult
>>>>>> to account for all of the possibilities. For example, it gets much
>>>>>> harder to see that we're applying the descendant limits correctly if
>>>>>> the package has a gnarly, many-generation, non-tree shape. I'm also
>>>>>> not sure if this policy is 100% incentive-compatible if the sponsor
>>>>>> is not a direct descendant of the sponsee.
>>>>>>
>>>>>> Please see doc/policy/version3_transactions.md and
>>>>>> doc/policy/packages.md in the PR for the full set of rules.
>>>>>>
>>>>>> **Intended usage for LN:**
>>>>>>
>>>>>> Commitment transactions should be V3 and have 1 anchor output. They
>>>>>> can be signed with 0 fees (or 1sat/vbyte) once package relay is
>>>>>> deployed
>>>>>> on a significant portion of the network. If the commitment tx must
>>>>>> be broadcast, determine the desired feerate at broadcast time and
>>>>>> spend the anchor output in a high feerate transaction. I'm going to
>>>>>> call the broadcasted commitment tx "the parent" and the attached
>>>>>> fee-bumping tx "the child."
>>>>>>
>>>>>> - This child must be V3.
>>>>>> - This child must be at most 1000vB. Note this restricts the
>>>>>>   number of inputs you can use to fund the fee bump. Depending
>>>>>> on the output types, this is around 6-15.
>>>>>> - One child may fund fees for multiple commitment tx ("batched
>>>>>>   fee-bumping").
>>>>>> - To do a second fee-bump to add more fees, replace the
>>>>>>   *child* with a higher-feerate tx. Do not try to attach a grandchild.
>>>>>>
>>>>>> Otherwise, never try to spend from an unconfirmed V3 transaction. The
>>>>>> descendant limits for V3 transactions are very restrictive.
>>>>>>
>>>>>> **Expected Questions:**
>>>>>>
>>>>>> "Does this fix Rule 3 Pinning?"
>>>>>> Yes. The V3 descendant limit restricts both you and your counterparty.
>>>>>> Assuming nodes adopted this policy, you may reasonably assume that you
>>>>>> only need to replace the commitment transaction + up to 1000vB.
>>>>>>
>>>>>> "Only 1 anchor output? What if I need to bump counterparty's
>>>>>> commitment tx in mempool?"
>>>>>> You won't need to fee-bump a counterparty's commitment tx using CPFP.
>>>>>> You would just package RBF it by attaching a high-feerate child to
>>>>>> your commitment tx.
>>>>>>
>>>>>> "Is this a privacy issue, i.e. doesn't it allow fingerprinting LN
>>>>>> transactions based on nVersion?"
>>>>>> Indeed it may be unrealistic to assume V3 transactions will be in
>>>>>> widespread use outside of L2. IIUC, unilateral closes are already
>>>>>> obvious LN transactions because of the HTLC inputs. For e.g.
>>>>>> cooperative closes and opens, I think it makes sense to continue using
>>>>>> V2. So, unless I'm missing something, this shouldn't make it worse.
>>>>>>
>>>>>> "So a V3 transaction that doesn't signal BIP125 replaceability is
>>>>>> replaceable? Is that a backward compatibility issue?"
>>>>>> Yes it's replaceable. It's not an issue AFAICT because,
>>>>>> under previous policy, the V3 transaction wouldn't have been
>>>>>> in the mempool in the first place.
>>>>>>
>>>>>> "Can a V2 transaction replace a V3 transaction and vice versa?"
>>>>>> Yes, otherwise someone can use V3 transactions to censor V2
>>>>>> transactions spending shared inputs. Note if the
>>>>>> original V3 transaction has an unconfirmed V3 parent, this would
>>>>>> violate the "inherited V3" rule and would be rejected.
>>>>>>
>>>>>> Thanks for reading! Feedback and review would be much appreciated.
>>>>>>
>>>>>> [1]:
>>>>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019464.html
>>>>>> [2]:
>>>>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019817.html
>>>>>>
>>>>>> Best,
>>>>>> Gloria
>>>>>> _______________________________________________
>>>>>> bitcoin-dev mailing list
>>>>>> bitcoin-dev at lists.linuxfoundation.org
>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>>>>
>>>>> _______________________________________________
>>>>> bitcoin-dev mailing list
>>>>> bitcoin-dev at lists.linuxfoundation.org
>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>>>
>>>> _______________________________________________
>>>> bitcoin-dev mailing list
>>>> bitcoin-dev at lists.linuxfoundation.org
>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>>
>>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220929/fa260464/attachment-0001.html>

From rsomsen at gmail.com  Thu Sep 29 15:39:18 2022
From: rsomsen at gmail.com (Ruben Somsen)
Date: Thu, 29 Sep 2022 17:39:18 +0200
Subject: [bitcoin-dev] =?utf-8?q?Trustless_Address_Server_=E2=80=93_Outsou?=
	=?utf-8?q?rcing_handing_out_addresses_to_prevent_address_reuse?=
Message-ID: <CAPv7TjbOcH2mte8SWALc2o5aEKLO7qoZ-M_e1wHdGSp6EmMc2Q@mail.gmail.com>

Hi all,

In short, this is yet another way to hand out addresses without interaction
between sender and recipient (Silent Payments, BIP47). The idea here is
that in non-ideal cases where you're already exposing your xpub to a server
(most light clients today, unfortunately), you might as well rely on them
to hand out addresses on your behalf.

Other than BTCPay Server, I am not aware of any serious attempts of
exploring this direction. Perhaps this is justified, due to the difficulty
of dealing with the gap limit, but it seems worth discussing nonetheless.

The write-up is available (and kept up-to-date) here as a gist:
https://gist.github.com/RubenSomsen/960ae7eb52b79cc826d5b6eaa61291f6

And here's a copy for the list:


### Introduction

Address reuse prevention generally requires interacting with the recipient
in order to receive a fresh address for each payment. There are various
protocols that ensure no interaction is required such as BIP47[^1] and
Silent Payments[^2], though neither is without downsides.

One area that is seemingly underexplored is that of outsourced interaction.
BTCPay Server[^3] is an example of this. The sender interacts with a
server, which acts on behalf of the recipient and hands out an address from
an xpub. The recipient controls and therefore trusts the server, so
malicious addresses won't be given out.

### Outsourcing and Malicious Keys

The vast majority of light clients today (even ones that support BIP47,
curiously) already control the user's xpub, so it seems logical to think
the interaction can be outsourced to them. However, unlike when running
your own server, a third party server *could* potentially hand out
malicious addresses (i.e. addresses that belong to someone other than you).

The solution to this is identity. As long as the sender knows a public key
by which the recipient can be identified, the recipient can sign the
addresses that are derived from their xpub[^4]. This way the sender can be
sure that the address it receives from the server belongs to the recipient.

### Gap Limit

One big remaining problem is the gap limit[^5]. When an adversary
repeatedly requests addresses from the server but then never uses them,
this could result in a large gap of unused addresses. This is a problem
because when recovering from backup the wallet stops looking for payments
when a large enough gap is encountered. Unfortunately there is no perfect
solution, but mitigations are still possible.

Whenever a sender wants to make their first payment, they could be expected
to obtain an address at a cost (solving captchas, paying over LN,
proof-of-burn[^6]). If the sender doesn't mind (or maybe even desires)
having their payments correlated by the recipient, a fresh xpub[^7] can be
handed out instead of an address in order to enable repeated payments. If
non-correlated payments are preferable, after each successful payment the
server could hand out a blind ecash[^8] token that entitles the sender to
another address.

An alternative mitigation (more user friendly, but more implementation
complexity) would be to require the sender to reveal their intended
transaction to the server prior to receiving the address[^9]. This is not a
privacy degradation, since the server could already learn this information
regardless. If the transaction doesn't end up getting sent, any subsequent
attempt to reuse one of the inputs should either be (temporarily)
blacklisted or responded to with the same address that was given out
earlier[^10].

If despite best efforts the gap limit is inadvertently reached anyway, the
recipient may have to be instructed to ensure they properly receive a
payment to bridge the gap before new addresses can be handed out. The
alternative is to forego privacy when this happens, but this seems unwise.

### Use Case

This protocol seems useful for users that a.) want to use light clients,
b.) accept the privacy degradation of handing out their xpub to a third
party, and c.) want to receive payments non-interactively. If any one of
these is not true, other protocols are likely to be a better choice[^11].
Finally, it should be acknowledged that this protocol introduces more
friction on the sender side due to the need for a gap limit mitigation
strategy.

-- Ruben Somsen


[^1]: BIP47: https://github.com/bitcoin/bips/blob/master/bip-0047.mediawiki

[^2]: Silent Payments:
https://gist.github.com/RubenSomsen/c43b79517e7cb701ebf77eec6dbb46b8

[^3]: BTCPay Server https://btcpayserver.org/

[^4]: *Specifically, this could be a single signature on a merkle root, so
the amount of data that the recipient needs to send to the server can be
minimized and the server can just generate the same tree from the xpub and
hand out merkle proofs to senders. The order of the leaves should be
randomized so senders cannot learn how many payments were made.*

[^5]: Gap limit:
https://bitcoin.stackexchange.com/questions/111534/bitcoin-address-gap-limit

[^6]: Efficient Proof-of-Burn:
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-July/020746.html

[^7]: Xpub sharing:
https://gist.github.com/RubenSomsen/c43b79517e7cb701ebf77eec6dbb46b8#xpub-sharing

[^8]: Blind ecash:
https://gist.github.com/RubenSomsen/be7a4760dd4596d06963d67baf140406

[^9]: *This would essentially look like an incomplete but signed
transaction where the output address is still missing.*

[^10]: *Keep in mind the edge case where e.g. two inputs are presented but
not used, followed by two separate transactions which each use one of the
priorly presented inputs.*

[^11]: Protocol considerations:
https://twitter.com/SomsenRuben/status/1530096037414707200
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220929/896947be/attachment.html>

From woltx at protonmail.com  Thu Sep 29 22:19:38 2022
From: woltx at protonmail.com (woltx)
Date: Thu, 29 Sep 2022 22:19:38 +0000
Subject: [bitcoin-dev] Third version of Silent Payment implementation
Message-ID: <BkzIoBmDaBRo-URg9JqL1fZOyN-iu32rvsv7VNfEKsnX3HuBjXEPcREYIUftcQ6TvOHY1pcjKGd8ekUYfEObGqdDNGuJYhxOqYb9_s_c80w=@protonmail.com>

This new version addresses most (or all) requests made in PR:

. Implements the new scheme suggested by Ruben Somsen that allows multiple silent addresses per wallet with minimal overhead.
. Implements a new RPC to retrieve silent addresses, which allows users to assign different labels to different addresses. That way, the user knows which silent address the UTXO came from.

Example:

./src/bitcoin-cli -signet -rpcwallet="receiver" getspaddress
tsp001pjgcwd9p6f2rcgf35dlgvj77h2afylg6lp5cdn0cztrk4k54w99kqxn48tq

# This will return the same address as above (both have no label)
./src/bitcoin-cli -signet -rpcwallet="receiver" getspaddress
tsp001pjgcwd9p6f2rcgf35dlgvj77h2afylg6lp5cdn0cztrk4k54w99kqxn48tq

# New label, new address
./src/bitcoin-cli -signet -rpcwallet="receiver" getspaddress 'donation'
tsp011pjgcwd9p6f2rcgf35dlgvj77h2afylg6lp5cdn0cztrk4k54w99kq80t7lt

In this new scheme, the address has a new field called identifier, which tells the receiver and sender how to set the address correctly.

If the receiver, for whatever reason, doesn't know which identifiers have been used, there is no problem. The wallet can scan all identifiers from 0 to 99. Currently, only 100 different identifiers per wallet are allowed. This limit, however, can be increased at any time in the future.

Unlike address formats so far, sp addresses are not script-related and may eventually include any additional information needed, such as an expiration timestamp (or block height). That way, users don't have to track the address indefinitely.

As usual I wrote a step by step tutorial:
https://gist.github.com/w0xlt/c81277ae8677b6c0d3dd073893210875
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220929/bd368220/attachment.html>

From rsomsen at gmail.com  Thu Sep 29 22:41:29 2022
From: rsomsen at gmail.com (Ruben Somsen)
Date: Fri, 30 Sep 2022 00:41:29 +0200
Subject: [bitcoin-dev] RFC for a BIP32 recurrent address derivation
	scheme
In-Reply-To: <CAPapNH28iCxEcTOKt3YC+zuZzxbM=AudbbYByjS3aUZAgFHUag@mail.gmail.com>
References: <CAPapNH28iCxEcTOKt3YC+zuZzxbM=AudbbYByjS3aUZAgFHUag@mail.gmail.com>
Message-ID: <CAPv7TjZFN1r84EXON_gpNmJm2=x0x6-=5SqdCP5_n2EaObUEtA@mail.gmail.com>

Hi Eloy,

Nice idea.

Note I thought about and succinctly described a similar scheme here (which
in turn was derived from work by Kixunil):
https://gist.github.com/RubenSomsen/c43b79517e7cb701ebf77eec6dbb46b8#xpub-sharing

I agree with your general assessment that this is a scheme that seems like
an improvement over the status quo. Note that both BIP47 and Silent
Payments don't require any interaction with the sender, while this scheme
requires one-time interaction (e.g. this wouldn't be suitable for one-time
donations). I think this would mostly be a convenience feature that
improves the regular interactive payment flow (interact once, instead of
repeatedly asking for addresses with each payment).

>master / purpose' / coin_type' / contact' / index

Despite your explanation, it's still not fully clear to me how "contact" is
defined, but I assume it's just a counter? Just in case, note that you
can't let Bob define it for Carol, as then you can't deterministically
recover your payments without also backing up how it's defined (the seed
alone won't be enough).

The gap limit also needs to be kept in mind. If we allow each xpub to have
its own gap limit, you potentially get an exponential blowup (gaps in the
xpub * gaps in the addresses generated from the xpubs). It may be OK to
define a low default gap limit for these xpubs, since there should be no
reason to expect the same sender to leave any gaps, though this may depend
on how the xpubs are used (e.g. it may also be used to derive addresses for
others) so it's probably important to be explicit about this.

Cheers,
Ruben



On Thu, Sep 22, 2022 at 5:18 PM El_Hoy via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> There is a known issue on bitcoin, that is that every transaction requires
> a new address to prevent address reuse, making it uncomfortable to make
> recurring payments, as every payment requires a new off-chain interaction.
> A scheme is already mentioned on the [on the BIP32 itself][1], but it
> cannot be implemented as is.
>
> Here I propose a scheme that follows the structure described on [BIP44]
> that should make it possible to send recurring payments using a single
> offline interaction.
>
> The proposed scheme is:
>
>     master / purpose' / coin_type' / contact' / index
>
> Where the definitions of all the levels follow BIP44, except for `contact`
> that is described below.
>
> Example usage: Bob wants to make recurring payments to Carol, so he asks
> her for a _contact address_, that is, an extended public key.
>
> Bob can use that public key to generate multiple derived addresses to make
> multiple recurring payments to Carol, the contact address is stored
> off-chain, anyone inspecting the chain will just see normal transactions
> on-chain.
>
> ## Considerations
>
> [BIP47] tries to solve the same issue, but the solution is more complex
> and involves more on-chain transactions that involve data, this
> implementation simpler and requires less work to implement.
>
> Also, the derivation path might need some adjustments for different
> address types on bitcoin.
>
> Finally, this only works in a single direction and does not make it
> possible for Carol to send anything to Bob, as it would require Bob sending
> her a contact address.
>
> ## Advantages
>
> A positive side effect of using this, is that Bob can choose to send
> payments to Carol using multiple outputs, giving him more privacy.
>
> Also, those payments can be easily labeled by the receiving wallet, as
> they are received.
>
> Regards.
>
> ### References
>
> [1]:
> https://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki#recurrent-business-to-business-transactions-nmih0
> [BIP47]: https://github.com/bitcoin/bips/blob/master/bip-0047.mediawiki
> "Reusable Payment Codes for Hierarchical Deterministic Wallets"
> [BIP43]:
> https://github.com/bitcoin/bips/blob/master/bip-0043.mediawiki#Purpose
>
> --- Eloy
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220930/d73e6790/attachment-0001.html>

From rsomsen at gmail.com  Thu Sep 29 23:03:36 2022
From: rsomsen at gmail.com (Ruben Somsen)
Date: Fri, 30 Sep 2022 01:03:36 +0200
Subject: [bitcoin-dev] Third version of Silent Payment implementation
In-Reply-To: <BkzIoBmDaBRo-URg9JqL1fZOyN-iu32rvsv7VNfEKsnX3HuBjXEPcREYIUftcQ6TvOHY1pcjKGd8ekUYfEObGqdDNGuJYhxOqYb9_s_c80w=@protonmail.com>
References: <BkzIoBmDaBRo-URg9JqL1fZOyN-iu32rvsv7VNfEKsnX3HuBjXEPcREYIUftcQ6TvOHY1pcjKGd8ekUYfEObGqdDNGuJYhxOqYb9_s_c80w=@protonmail.com>
Message-ID: <CAPv7TjZOJSFeRjpJjY5Lkjpr4LRexsCuhi8t_1nkL9ys+qoYhA@mail.gmail.com>

Hi woltx,

Excellent work.

>Implements the new scheme suggested by Ruben Somsen that allows multiple
silent addresses per wallet with minimal overhead

To expand on this, the scheme basically allows the resulting address to be
recognizably marked (only recognizable by the recipient of course), which
enables you to distinguish between different payment purposes (e.g. some
people donate to you for purpose A, others for purpose B). Here's my
original comment describing it:

"Naively, the issue is that two keys means twice the scanning, but an
interesting alternative would be to simply use the same key (assuming
you're OK with using the same identity) but add a public identifier f to it
when tweaking. So instead of hash(i*X)*G + X you get hash(i*X)*G + X + f*G
. This means every additional "address" only costs one additional ECC
addition when scanning (relatively cheap compared to doing ECC
multiplications).

The main downside with this is that f becomes crucial for recovering from
backup. If we set f as an index (0, 1, 2, 3...) then you'd only have to
remember how many "addresses" you issued (and perhaps overshoot when
unsure) to ensure recovery of funds, though of course you'd rather also
remember which index is associated with what payment reason.

Absolute worst case scenario you could even do something similar to the gap
limit where you scan the full history (not just the UTXO set so you don't
miss spent outputs) with a default max index of e.g. 100, and then if you
find out most of them are in use, you scan the next 100, etc. Costly, but
thorough, and only needed as a last resort."

Original comment here:
https://gist.github.com/RubenSomsen/c43b79517e7cb701ebf77eec6dbb46b8#xpub-sharing

Also good to note that f needs to be communicated to the sender somehow,
perhaps as part of the address format.

Cheers,
Ruben

On Fri, Sep 30, 2022 at 12:35 AM woltx via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

>
> This new version addresses most (or all) requests made in PR:
>
> . Implements the new scheme suggested by Ruben Somsen that allows multiple
> silent addresses per wallet with minimal overhead.
> . Implements a new RPC to retrieve silent addresses, which allows users to
> assign different labels to different addresses. That way, the user knows
> which silent address the UTXO came from.
>
> Example:
>
> ./src/bitcoin-cli -signet -rpcwallet="receiver" getspaddress
> tsp001pjgcwd9p6f2rcgf35dlgvj77h2afylg6lp5cdn0cztrk4k54w99kqxn48tq
>
> # This will return the same address as above (both have no label)
> ./src/bitcoin-cli -signet -rpcwallet="receiver" getspaddress
> tsp001pjgcwd9p6f2rcgf35dlgvj77h2afylg6lp5cdn0cztrk4k54w99kqxn48tq
>
> # New label, new address
> ./src/bitcoin-cli -signet -rpcwallet="receiver" getspaddress 'donation'
> tsp011pjgcwd9p6f2rcgf35dlgvj77h2afylg6lp5cdn0cztrk4k54w99kq80t7lt
>
> In this new scheme, the address has a new field called identifier, which
> tells the receiver and sender how to set the address correctly.
>
> If the receiver, for whatever reason, doesn't know which identifiers have
> been used, there is no problem. The wallet can scan all identifiers from 0
> to 99. Currently, only 100 different identifiers per wallet are allowed.
> This limit, however, can be increased at any time in the future.
>
> Unlike address formats so far, sp addresses are not script-related and may
> eventually include any additional information needed, such as an expiration
> timestamp (or block height). That way, users don't have to track the
> address indefinitely.
>
> As usual I wrote a step by step tutorial:
> https://gist.github.com/w0xlt/c81277ae8677b6c0d3dd073893210875
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220930/2cf4fe86/attachment.html>

From apoelstra at wpsoftware.net  Thu Sep 29 23:56:51 2022
From: apoelstra at wpsoftware.net (Andrew Poelstra)
Date: Thu, 29 Sep 2022 23:56:51 +0000
Subject: [bitcoin-dev] Wallet policies for descriptor wallets
In-Reply-To: <osdF1jSCUyGyaLZ6YytSB7ub1MwdbaP6PMCYEJZXmMRaSs4vS7bs_SZTErxZh_K7oLYLAtAqqgl0Vcdl1ftAusM_1DHSDHtz1kSUzqnmwsk=@protonmail.com>
References: <CAMhCMoHfdsQMsVigFqPexTE_q-Cyg7pfRvORUoy2sZtvyzd1cg@mail.gmail.com>
 <osdF1jSCUyGyaLZ6YytSB7ub1MwdbaP6PMCYEJZXmMRaSs4vS7bs_SZTErxZh_K7oLYLAtAqqgl0Vcdl1ftAusM_1DHSDHtz1kSUzqnmwsk=@protonmail.com>
Message-ID: <YzYww1keXKYoX2tk@camus>


I'm really happy to see this discussion. I don't have any comments on the spec
because I think I'd have to be more in-the-weeds trying to implement a hww to
understand how well it works for realistic use cases. But a strong concept-ACk
from me and thanks to Salvatore for exploring this!

On Mon, May 09, 2022 at 11:36:47AM +0000, darosior via bitcoin-dev wrote:
> 
> Unrelated question, since you mentioned `musig2` descriptors in this context. I thought Musig2 wasn't really
> feasible for hardware signing devices, especially stateless ones. Do you think/know whether it is actually
> possible for a HW to take part in a Musig2?
>

As Salvatore mentioned in his reply, there are a couple ways that hwws can deal
with musig2 -- specifically, having state (and I believe you can get away with
as little state as a single monotonic counter) or having a RNG which is reliable
enough that it at least won't repeat values.

Because these aren't blockers for all hwws, even if they are blockers for some,
I'd really like to see musig2 support in these protocols, or at least for musig2
to be considered in their design.
 

-- 
Andrew Poelstra
Director of Research, Blockstream
Email: apoelstra at wpsoftware.net
Web:   https://www.wpsoftware.net/andrew

The sun is always shining in space
    -Justin Lewis-Webster

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 488 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220929/b9bc0273/attachment.sig>

From rsomsen at gmail.com  Fri Sep 30 00:13:53 2022
From: rsomsen at gmail.com (Ruben Somsen)
Date: Fri, 30 Sep 2022 02:13:53 +0200
Subject: [bitcoin-dev] New transaction policies (nVersion=3) for
 contracting protocols
In-Reply-To: <CAB3F3DvCw9Ms+HUMaFnqV0P-Oo+rfERY+j5S5CC_X2NKRd5u8g@mail.gmail.com>
References: <CAFXO6=KDys2_dsrdxE9_q_MVZJOFMbg-MctxiokcicP=wd4Lkw@mail.gmail.com>
 <CALZpt+HYUti=foo+d5ER7Wj=PxsfgaU2CEqqG4_KRxmsWoaSxw@mail.gmail.com>
 <CACdvm3PyP9yrxx_Yewtx_yQh=i2uwGYj-wtY7HBER1bmG46NEw@mail.gmail.com>
 <CAB3F3Du=+YYKbfgB5LZPnCg40=5YCn_0tkpJ4LO9bMK0U-3wXg@mail.gmail.com>
 <CAFXO6=JGBPVpxTJnSMWCCZVPHZW_RyWQ2Cv18Ao_F=uQx3LVkg@mail.gmail.com>
 <CACdvm3OUpODbMzkcG+=qYzR9myrvSp-LpuGmETow94JavU2GDw@mail.gmail.com>
 <CAB3F3DvCw9Ms+HUMaFnqV0P-Oo+rfERY+j5S5CC_X2NKRd5u8g@mail.gmail.com>
Message-ID: <CAPv7TjYM34qk5bGheMZhopotuCwxYyHmWAXcawA5UHQpQWiGCg@mail.gmail.com>

Hi Bastien,

>The other change mentioned (making OP_TRUE standard and allowing outputs
that are below dust) can be added later, as those won't be standard until
we start allowing them, so there shouldn't be any backwards-compatibility
issue with postponing this change. But maybe it's still worth having from
the get-go, even though it may take a bit more time? Again, I'm curious to
have other people's opinion here

I'm sensitive to not wanting to overload the current discussion but this
also interests me, provided it can be done in a way that is acceptable
(i.e. minimizing the potential UTXO set impact). It would solve a big cost
issue in my spacechains design if transactions could be 0 fees and have a 0
sat output that could be used in order to pay all the fees with CPFP.

My current view is that a tx containing a single 0 sat OP_TRUE output
should only get relayed if it is a package where the OP_TRUE output is
currently being spent in a way that increases the overall fee rate. But
even then, one theoretical edge case remains:
- Another CPFP tx can feebump the package on a different (non-OP_TRUE)
output with an even higher fee rate
- Subsequently, the tx that is spending the OP_TRUE might fall out of the
mempool if the mempool fee rate rises
- This could cause the 0 sat output to enter the UTXO set (specifically,
rational miners wouldn't refuse to mine such a tx)

It doesn't seem like this would happen much in practice (nor is there an
incentive to do it on purpose), but the chance isn't 0.

Cheers,
Ruben



On Thu, Sep 29, 2022 at 4:50 PM Greg Sanders via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> > Right, good catch, this does require new logic to handle this case.
> As Gloria points out, this should be doable, and is definitely worth
> adding (those CSV 1 on every other output are really hacky, glad to
> find a way to get rid of them).
>
> For the record, it turns out ephemeral anchors + v3 solves this already,
> as the anchor must be spent, and the parent tx may only have one child.
> Somehow I missed this implication for a few months. It's great news if we
> can directly source fees from any output claimable, including HTLCs!
>
> On Thu, Sep 29, 2022 at 5:15 AM Bastien TEINTURIER <bastien at acinq.fr>
> wrote:
>
>> Hi Gloria, Greg,
>>
>> > I interpret most of the discussion around limitations as ideas for
>> > future improvements rather than criticisms of the proposal
>>
>> As far as I'm concerned, definitely!
>>
>> My current understanding is that the main change/improvement that would
>> make sense here is restricting the whole v3 package's size (instead of
>> just the child) via committing to a specific value in the taproot annex
>> (also note that it's probably not just the v3 package's size, it should
>> be the whole unconfirmed package including potential v2 unconfirmed
>> ancestors).
>>
>> While I think this would be very valuable and would like to see this
>> happen, I believe that can be done in a second, separate step since this
>> would make relay policy stricter (some v3 transactions that previously
>> propagated wouldn't propagate under this new rule). As long as you are
>> able to find a path to miners through upgraded peers that use this annex
>> approach, you should be able to resolve ACP pinning issues?
>>
>> I'm curious to know how other people feel about that: is it ok to do
>> later or should we try to implement this for the first release of v3
>> transactions?
>>
>> The other change mentioned (making OP_TRUE standard and allowing outputs
>> that are below dust) can be added later, as those won't be standard until
>> we start allowing them, so there shouldn't be any backwards-compatibility
>> issue with postponing this change. But maybe it's still worth having from
>> the get-go, even though it may take a bit more time? Again, I'm curious to
>> have other people's opinion here, I'd be happy to get all of those
>> directly
>> in the first release of v3 transactions, but I don't know how much
>> implementation will have to go into that.
>>
>> > For clarification, package RBF is ParentTx*s*(plural), and
>> ChildTx(singular),
>> > so it might be a bit more complicated than we're thinking
>>
>> Right, good catch, this does require new logic to handle this case.
>> As Gloria points out, this should be doable, and is definitely worth
>> adding (those CSV 1 on every other output are really hacky, glad to
>> find a way to get rid of them).
>>
>> Thanks,
>> Bastien
>>
>> Le lun. 26 sept. 2022 ? 18:48, Gloria Zhao <gloriajzhao at gmail.com> a
>> ?crit :
>>
>>> Hi Greg, Antoine, Bastien,
>>>
>>> Thanks very much for the feedback! I interpret most of the discussion
>>> around limitations as ideas for future improvements rather than criticisms
>>> of the proposal (please correct me if I'm wrong). I'll try to respond to as
>>> much as possible.
>>>
>>> Also I realize that I didn't contextualize this proposal clearly enough;
>>> it is very tailored for LN Penalty and definitely doesn't close all pinning
>>> attacks possible (sorry for confusing anyone). I also agree that some bits
>>> can be a little ugly or tack-on; I would definitely prefer a comprehensive
>>> RBF revamp to fix all our problems and enable other fee-bumping strategies
>>> such as
>>> sign-ANYONECANPAY-then-bring-your-own-fees-by-adding-inputs-at-broadcast. I
>>> was hoping to get some ideas with the "RBF Improvements" post in January,
>>> but it doesn't seem like we're much closer to a workable proposal. I think
>>> this is a minimally-invasive step that works for Lightning today, a small
>>> fix similar to CPFP carve out.
>>>
>>> > As you likely know from previous discussions the biggest scenario this
>>> does not fix in my estimation is ANYONECANPAY situations. If the parent
>>> transaction can be "inflated" by tacking on additional inputs, this means
>>> the total weight of the parent tx lowers the effective feerate of the
>>> package.
>>>
>>> (For more context to other readers I wrote an explanation for this in
>>> "SIGHASH_ANYONECANPAY Pinning" section of RBF ML post).  Yes, this
>>> unfortunately doesn't fix any of the existing pinning attacks for single
>>> transaction RBF but also doesn't make them worse. This boils down to adding
>>> an incentive compatibility rule that ensures you can't replace a
>>> transaction with something that will confirm slower. Package RBF has an
>>> ancestor feerate-based rule for this (note it is quite conservative and not
>>> perfect).
>>>
>>> So in the scenario above with the "inflated" parent that was signed ACP,
>>> the replacement would be rejected because the package ancestor feerate is
>>> lower than the feerate of what is being replaced. But it is imperfect
>>> (explained below) and thus I wouldn't recommend it for single transaction
>>> replacement. So that attack still exists for single transactions, yes.
>>>
>>> The strategy of using ACP to bring-your-own-fees has its own challenges
>>> but hopefully has no current use cases as you say. AFAIK LN Penalty is not
>>> affected by this since it doesn't use ACP, though obviously I agree we
>>> should fix it for the future.
>>>
>>> So when I said "this is intended for fee-bumping presigned txns in
>>> contracting protocols," I should have said "this is intended for
>>> fee-bumping presigned txns specifically using CPFP and anchor outputs."
>>> Apologies for forgetting to contextualize, I've been sitting on this for
>>> too long.
>>>
>>> > The other scenario it doesn't really fix is where HTLC/commitment-like
>>> transactions are being resolved in a batch, but due to relative time
>>> constraints, you may want to accelerate some and not others. Now you must
>>> pay higher rates to replace all of the transaction bumps. This is a
>>> "self-pin" and "get good at utxos noob" type problem, but it's something
>>> that axing rule#3 in favor of a Replace-by-ancestor-feerate system would
>>> get us.
>>>
>>> I understand you to mean "if you don't have enough UTXOs and you're
>>> forced to batch-bump, you over-pay because you need to bring them all to
>>> the highest target feerate." Isn't this kind of separate, wallet-related
>>> problem? Contracting or not, surely every wallet needs to have enough UTXOs
>>> to not batch transactions that shouldn't be batched... I don't see how a
>>> replace-by-ancestor-feerate policy would make any difference for this?
>>>
>>> Also in general I'd like to reiterate that ancestor feerate is not a
>>> panacea to all our RBF incentive compatibility concerns. Like individual
>>> feerate, unless we run the mining algorithm, it cannot tell us exactly how
>>> quickly this transaction would be mined.
>>>
>>> We're estimating the incentive compatibility of the original
>>> transaction(s) and replacement transaction(s), with the goal of not letting
>>> a transaction replace something that would have been more incentive
>>> compatible to mine. As such, we don't want to overestimate how good the
>>> replacement is, and we don't want to underestimate how good the original
>>> transactions are. This rule "The minimum between package feerate and
>>> ancestor feerate of the child is not lower than the individual feerates of
>>> all directly conflicting transactions and the ancestor feerates of all
>>> original transactions" is a conservative estimate.
>>>
>>> > Would kind of be nice if package RBF would detect a "sibling output
>>> spend" conflict, and knock it out of the mempool via the other replacement
>>> rules? Getting rid of the requirement to 1 block csv lock every output
>>> would be quite nice from a smart contracting composability point of view.
>>>
>>> Interesting, so when a transaction hits a mempool tx's descendant limit,
>>> we consider evicting one of its descendants in favor of this transaction,
>>> based on the RBF rules.
>>> Cool idea! After chewing on this for a bit, I think this *also* just
>>> boils down to the fact that RBF should require replacements to be better
>>> mining candidates. As in, if we added this policy and it can make us evict
>>> the sibling and accept a transaction with a bunch of low-feerate ancestor
>>> junk, it would be a new pinning vector.
>>>
>>> > If you're a miner and you receive a non-V3, second descendant of an
>>> unconfirmed V3 transaction, if the offered fee is in the top mempool
>>> backlog, I think you would have an interest to accept such a transaction.
>>>
>>> > So I'm not sure if those two rules are compatible with miners
>>> incentives...
>>>
>>> The same argument can be made for the 26th descendant of a mempool
>>> transaction; it's also not entirely incentive-compatible to reject it, but
>>> that is not the *only* design goal in mempool policy. Of course, the
>>> difference here is that the 25-descendant limit rule is a sensible DoS
>>> protection, while this 1-descendant limit rule is more of a "help the
>>> Bitcoin ecosystem" policy, just like CPFP carve-out, dust limit, etc. I can
>>> of course understand why not everyone would be in favor of this, but I do
>>> think it's worth it.
>>>
>>> > > 4. A V3 transaction that has an unconfirmed V3 ancestor cannot be
>>> > >    larger than 1000 virtual bytes.
>>>
>>> > If I understand correctly the 1000 vb upper bound rational, it would
>>> be to constraint the pinning counterparty to attach a high fee to a child
>>> due to the limited size, if they would like this transaction to be stuck in
>>> the network mempools. By doing so  this child has high odds to confirm.
>>>
>>> Yeah exactly, the "Rule 3 pin" is done by adding a child that's high-fee
>>> (so you have to pay that much to evict it). Because they *don't* want this
>>> tx to confirm, normally, this child would be really large. If they only
>>> have 1000vB for the child, they can't increase the replacement cost without
>>> also fee-bumping the transaction to make it confirm faster.
>>>
>>> > As of today, I think yes you can already fingerprint LN transactions
>>> on the  spec-defined amount value of the anchor outputs, 330 sats. There is
>>> always one of them on post-anchor commitment transactions. And sadly I
>>> would say we'll always have tricky fingerprints leaking from unilateral LN
>>> closures such as HTLC/PTLC timelocks...
>>>
>>> > I agree with you, this isn't worse than today, unilateral closes will
>>> probably always be identifiable on-chain.
>>>
>>> Great to hear that there is no privacy worsening!
>>>
>>> Best,
>>> Gloria
>>>
>>> On Mon, Sep 26, 2022 at 5:02 PM Greg Sanders <gsanders87 at gmail.com>
>>> wrote:
>>>
>>>> Bastien,
>>>>
>>>> > This may be already covered by the current package RBF logic, in that
>>>> scenario we are simply replacing [ParentTx, ChildTx1] with
>>>> [ParentTx, ChildTx2] that pays more fees, right?
>>>>
>>>> For clarification, package RBF is ParentTx*s*(plural), and
>>>> ChildTx(singular), so it might be a bit more complicated than we're
>>>> thinking, and currently the V3 proposal would first de-duplicate the
>>>> ParentTx based on what is in the mempool, then look at the "rest" of the
>>>> transactions as a package, then individually. Not the same, not sure how
>>>> different. I'll defer to experts.
>>>>
>>>> Best,
>>>> Greg
>>>>
>>>> On Mon, Sep 26, 2022 at 11:48 AM Bastien TEINTURIER via bitcoin-dev <
>>>> bitcoin-dev at lists.linuxfoundation.org> wrote:
>>>>
>>>>> Thanks Gloria for this great post.
>>>>>
>>>>> This is very valuable work for L2 contracts, and will greatly improve
>>>>> their security model.
>>>>>
>>>>> > "Only 1 anchor output? What if I need to bump counterparty's
>>>>> commitment tx in mempool?"
>>>>> > You won't need to fee-bump a counterparty's commitment tx using CPFP.
>>>>> > You would just package RBF it by attaching a high-feerate child to
>>>>> > your commitment tx.
>>>>>
>>>>> Note that we can also very easily make that single anchor spendable by
>>>>> both participants (or even anyone), so if you see your counterparty's
>>>>> commitment in your mempool, you can bump it without publishing your
>>>>> own commitment, which is quite desirable (your own commitment tx has
>>>>> CSV delays on your outputs, whereas your counterparty's commitment tx
>>>>> doesn't).
>>>>>
>>>>> > "Is this a privacy issue, i.e. doesn't it allow fingerprinting LN
>>>>> transactions based on nVersion?"
>>>>>
>>>>> I agree with you, this isn't worse than today, unilateral closes will
>>>>> probably always be identifiable on-chain.
>>>>>
>>>>> > Would kind of be nice if package RBF would detect a "sibling output
>>>>> spend"
>>>>> > conflict, and knock it out of the mempool via the other replacement
>>>>> rules?
>>>>> > Getting rid of the requirement to 1 block csv lock every output
>>>>> would be
>>>>> > quite nice from a smart contracting composability point of view.
>>>>>
>>>>> +1, that would be very neat!
>>>>>
>>>>> This may be already covered by the current package RBF logic, in that
>>>>> scenario we are simply replacing [ParentTx, ChildTx1] with
>>>>> [ParentTx, ChildTx2] that pays more fees, right?
>>>>>
>>>>> > 1) I do think that we should seriously consider allowing OP_TRUE to
>>>>> become
>>>>> > a standard script type as part of this policy update. If pinning is
>>>>> solved,
>>>>> > then there's no reason to require all those extra bytes for
>>>>> "binding" an
>>>>> > anchor to a specific wallet/user. We can save quite a few bytes by
>>>>> having
>>>>> > the input be empty of witness data.
>>>>> > 2) If we allow for a single dust-value(0 on up) output which is
>>>>> immediately
>>>>> > spent by the package, anchors become even easier to to design. No
>>>>> value has
>>>>> > to be "sapped" from contract participants to make an anchor output.
>>>>> There's
>>>>> > more complications for this, such as making sure the parent
>>>>> transaction is
>>>>> > dropped if the child spend is dropped, but maybe it's worth the
>>>>> squeeze.
>>>>>
>>>>> I also think both of these could be quite useful. This would probably
>>>>> always
>>>>> be used in combination with a parent transaction that pays 0 fees, so
>>>>> the
>>>>> 0-value output would always be spent in the same block.
>>>>>
>>>>> But this means we could end up with 0-value outputs in the utxo set,
>>>>> if for
>>>>> some reason the parent tx is CPFP-ed via another output than the
>>>>> 0-value one,
>>>>> which would be a utxo set bloat issue. But I'd argue that we're
>>>>> probably
>>>>> already creating utxo set bloat with the 330 sat anchor outputs
>>>>> (especially
>>>>> since we use two of them, but only one is usually spent), so it would
>>>>> probably be *better* than what we're doing today.
>>>>>
>>>>> Thanks,
>>>>> Bastien
>>>>>
>>>>> Le lun. 26 sept. 2022 ? 03:22, Antoine Riard via bitcoin-dev <
>>>>> bitcoin-dev at lists.linuxfoundation.org> a ?crit :
>>>>>
>>>>>> Hi Gloria,
>>>>>>
>>>>>> Thanks for the progress on package RBF, few early questions.
>>>>>>
>>>>>> > 2. Any descendant of an unconfirmed V3 transaction must also be V3.
>>>>>>
>>>>>> > 3. An unconfirmed V3 transaction cannot have more than 1 descendant.
>>>>>>
>>>>>> If you're a miner and you receive a non-V3, second descendant of an
>>>>>> unconfirmed V3 transaction, if the offered fee is in the top mempool
>>>>>> backlog, I think you would have an interest to accept such a transaction.
>>>>>>
>>>>>> So I'm not sure if those two rules are compatible with miners
>>>>>> incentives...
>>>>>>
>>>>>> > 4. A V3 transaction that has an unconfirmed V3 ancestor cannot be
>>>>>> >    larger than 1000 virtual bytes.
>>>>>>
>>>>>> If I understand correctly the 1000 vb upper bound rational, it would
>>>>>> be to constraint the pinning counterparty to attach a high fee to a child
>>>>>> due to the limited size, if they would like this transaction to be stuck in
>>>>>> the network mempools. By doing so  this child has high odds to confirm.
>>>>>>
>>>>>> I still wonder if this compatible with miner incentives in period of
>>>>>> empty mempools, in the sense that if you've already a V3 transaction of
>>>>>> size 100Kvb offering 2 sat/vb, it's more interesting than a V3 replacement
>>>>>> candidate of size 1000 vb offering 10 sat/vb. It could be argued the former
>>>>>> should be conserved.
>>>>>>
>>>>>> (That said, the hard thing with any replacement strategy we might
>>>>>> evict a parent transaction *now* to which is attached a high-feerate child
>>>>>> *latter* making for a utxo considered the best ancestor set. Maybe in the
>>>>>> long-term miners should keep every transaction ever accepted...)
>>>>>>
>>>>>> > (Lower bound) the smaller this limit, the fewer UTXOs a child may
>>>>>> use
>>>>>> > to fund this fee-bump. For example, only allowing the V3 child to
>>>>>> have
>>>>>> > 2 inputs would require L2 protocols to manage a wallet with
>>>>>> high-value
>>>>>> > UTXOs and make batched fee-bumping impossible. However, as the
>>>>>> > fee-bumping child only needs to fund fees (as opposed to payments),
>>>>>> > just a few UTXOs should suffice.
>>>>>>
>>>>>> Reminder for L2 devs, batched fee-bumping of time-sensitive
>>>>>> confirmations of commitment transactions is unsafe, as the counterparty
>>>>>> could enter in a "cat-and-mouse" game to replace one of the batch element
>>>>>> at each block to delay confirmation of the remaining elements in the batch,
>>>>>> I think.
>>>>>>
>>>>>> On the other hand, I wonder if we wouldn't want a higher bound. LN
>>>>>> wallets are likely to have one big UTXO in their fee-bumping reserve pool,
>>>>>> as the cost of acquiring UTXO is non-null and in the optimistic case, you
>>>>>> don't need to do unilateral closure. Let's say you close dozens of channels
>>>>>> at the same time, a UTXO pool management strategy might be to fan-out the
>>>>>> first spends UTXOs in N fan-out outputs ready to feed the remaining
>>>>>> in-flight channels.
>>>>>>
>>>>>> > 1. The rule around unconfirmed inputs was
>>>>>> > originally "A package may include new unconfirmed inputs, but the
>>>>>> > ancestor feerate of the child must be at least as high as the
>>>>>> ancestor
>>>>>> > feerates of every transaction being replaced."
>>>>>>
>>>>>> Note, I think we would like this new RBF rule to also apply to single
>>>>>> transaction package, e.g second-stage HTLC transactions, where a
>>>>>> counterparty pins a HTLC-preimage by abusing rule 3. In that case, the
>>>>>> honest LN node should be able to broadcast a "at least as high ancestor
>>>>>> feerate" HTLC-timeout transaction. With `option_anchor_outputs" there is no
>>>>>> unconfirmed ancestor to replace, as the commitment transaction, whatever
>>>>>> the party it is originating from, should already be confirmed.
>>>>>>
>>>>>> > "Is this a privacy issue, i.e. doesn't it allow fingerprinting LN
>>>>>> transactions based on nVersion?"
>>>>>>
>>>>>> As of today, I think yes you can already fingerprint LN transactions
>>>>>> on the  spec-defined amount value of the anchor outputs, 330 sats. There is
>>>>>> always one of them on post-anchor commitment transactions. And sadly I
>>>>>> would say we'll always have tricky fingerprints leaking from unilateral LN
>>>>>> closures such as HTLC/PTLC timelocks...
>>>>>>
>>>>>> > "Can a V2 transaction replace a V3 transaction and vice versa?"
>>>>>>
>>>>>> IIUC, a V3 package could replace a V2 package, with the benefit of
>>>>>> the new package RBF rules applied. I think this would be a significant
>>>>>> advantage for LN, as for the current ~85k of opened channels, the old V2
>>>>>> states shouldn't be pinning vectors. Currently, commitment transactions
>>>>>> signal replaceability.
>>>>>>
>>>>>> Le ven. 23 sept. 2022 ? 11:26, Gloria Zhao via bitcoin-dev <
>>>>>> bitcoin-dev at lists.linuxfoundation.org> a ?crit :
>>>>>>
>>>>>>> Hi everyone,
>>>>>>>
>>>>>>> I'm writing to propose a very simple set of mempool/transaction relay
>>>>>>> policies intended to aid L2/contract protocols. I realized that
>>>>>>> the previously proposed Package Mempool Accept package RBF [1]
>>>>>>> had a few remaining problems after digging into the RBF logic more
>>>>>>> [2].
>>>>>>> This additional set of policies solves them without requiring a huge
>>>>>>> RBF overhaul.
>>>>>>>
>>>>>>> I've written an implementation (and docs) for Bitcoin Core:
>>>>>>> https://github.com/bitcoin/bitcoin/pull/25038
>>>>>>>
>>>>>>> (You may notice that this proposal incorporates feedback on the PR -
>>>>>>> thanks Suhas Daftuar, Gregory Sanders, Bastien Teinturier, Anthony Towns,
>>>>>>> and others.)
>>>>>>>
>>>>>>> If you are interested in using package RBF/relay to bump presigned
>>>>>>> transactions, I think you may be interested in reviewing this
>>>>>>> proposal.
>>>>>>> This should solve Rule 3 pinning and perhaps allow us
>>>>>>> to get rid of CPFP carve-out (yay!). I'm keen to hear if people find
>>>>>>> the 1-anchor-output, 1000vB child limit too restrictive. Also, if
>>>>>>> you find a
>>>>>>> pinning attack or something that makes it unusable for you, I would
>>>>>>> really really like to know.
>>>>>>>
>>>>>>> Note that transactions with nVersion=3 ("V3 transactions") are
>>>>>>> currently non-standard in Bitcoin Core. That means **anything that
>>>>>>> was
>>>>>>> standard before this policy change would still be standard
>>>>>>> afterwards.** If you don't want your transactions to be subject to
>>>>>>> these rules, just continue whatever you're doing and don't use
>>>>>>> nVersion=3. AFAICT this shouldn't break anything, but let me know if
>>>>>>> this would be disruptive for you?
>>>>>>>
>>>>>>> **New Policies:**
>>>>>>>
>>>>>>> This includes:
>>>>>>> - a set of additional policy rules applying to V3 transactions
>>>>>>> - modifications to package RBF rules
>>>>>>>
>>>>>>> **V3 transactions:**
>>>>>>>
>>>>>>> Existing standardness rules apply to V3 (e.g. min/max tx weight,
>>>>>>> standard output types, cleanstack, etc.). The following additional
>>>>>>> rules apply to V3:
>>>>>>>
>>>>>>> 1. A V3 transaction can be replaced, even if it does not signal
>>>>>>> BIP125
>>>>>>>    replaceability. (It must also meet the other RBF rules around
>>>>>>> fees,
>>>>>>> etc. for replacement to happen).
>>>>>>>
>>>>>>> 2. Any descendant of an unconfirmed V3 transaction must also be V3.
>>>>>>>
>>>>>>> *Rationale*: Combined with Rule 1, this gives us the property of
>>>>>>> "inherited" replaceability signaling when descendants of unconfirmed
>>>>>>> transactions are created. Additionally, checking whether a
>>>>>>> transaction
>>>>>>> signals replaceability this way does not require mempool traversal,
>>>>>>> and does not change based on what transactions are mined. It also
>>>>>>> makes subsequent rules about descendant limits much easier to check.
>>>>>>>
>>>>>>> *Note*: The descendant of a *confirmed* V3 transaction does not need
>>>>>>> to be V3.
>>>>>>>
>>>>>>> 3. An unconfirmed V3 transaction cannot have more than 1 descendant.
>>>>>>>
>>>>>>> *Rationale*: (Upper bound) the larger the descendant limit, the more
>>>>>>> transactions may need to be replaced. This is a problematic pinning
>>>>>>> attack, i.e., a malicious counterparty prevents the transaction from
>>>>>>> being replaced by adding many descendant transactions that aren't
>>>>>>> fee-bumping.
>>>>>>>
>>>>>>> (Lower bound) at least 1 descendant is required to allow CPFP of the
>>>>>>> presigned transaction. The contract protocol can create presigned
>>>>>>> transactions paying 0 fees and 1 output for attaching a CPFP at
>>>>>>> broadcast time ("anchor output"). Without package RBF, multiple
>>>>>>> anchor
>>>>>>> outputs would be required to allow each counterparty to fee-bump any
>>>>>>> presigned transaction. With package RBF, since the presigned
>>>>>>> transactions can replace each other, 1 anchor output is sufficient.
>>>>>>>
>>>>>>> 4. A V3 transaction that has an unconfirmed V3 ancestor cannot be
>>>>>>>    larger than 1000 virtual bytes.
>>>>>>>
>>>>>>> *Rationale*: (Upper bound) the larger the descendant size limit, the
>>>>>>> more vbytes may need to be replaced. With default limits, if the
>>>>>>> child
>>>>>>> is e.g. 100,000vB, that might be an additional 100,000sats (at
>>>>>>> 1sat/vbyte) or more, depending on the feerate.
>>>>>>>
>>>>>>> (Lower bound) the smaller this limit, the fewer UTXOs a child may use
>>>>>>> to fund this fee-bump. For example, only allowing the V3 child to
>>>>>>> have
>>>>>>> 2 inputs would require L2 protocols to manage a wallet with
>>>>>>> high-value
>>>>>>> UTXOs and make batched fee-bumping impossible. However, as the
>>>>>>> fee-bumping child only needs to fund fees (as opposed to payments),
>>>>>>> just a few UTXOs should suffice.
>>>>>>>
>>>>>>> With a limit of 1000 virtual bytes, depending on the output types,
>>>>>>> the
>>>>>>> child can have 6-15 UTXOs, which should be enough to fund a fee-bump
>>>>>>> without requiring a carefully-managed UTXO pool. With 1000 virtual
>>>>>>> bytes as the descendant limit, the cost to replace a V3 transaction
>>>>>>> has much lower variance.
>>>>>>>
>>>>>>> *Rationale*: This makes the rule very easily "tacked on" to existing
>>>>>>> logic for policy and wallets. A transaction may be up to 100KvB on
>>>>>>> its
>>>>>>> own (`MAX_STANDARD_TX_WEIGHT`) and 101KvB with descendants
>>>>>>> (`DEFAULT_DESCENDANT_SIZE_LIMIT_KVB`). If an existing V3 transaction
>>>>>>> in the mempool is 100KvB, its descendant can only be 1000vB, even if
>>>>>>> the policy is 10KvB.
>>>>>>>
>>>>>>> **Package RBF modifications:**
>>>>>>>
>>>>>>> 1. The rule around unconfirmed inputs was
>>>>>>> originally "A package may include new unconfirmed inputs, but the
>>>>>>> ancestor feerate of the child must be at least as high as the
>>>>>>> ancestor
>>>>>>> feerates of every transaction being replaced."
>>>>>>>
>>>>>>> The package may still include new unconfirmed inputs. However,
>>>>>>> the new rule is modified to be "The minimum between package feerate
>>>>>>> and ancestor feerate of the child is not lower than the individual
>>>>>>> feerates of all directly conflicting transactions and the ancestor
>>>>>>> feerates of all original transactions."
>>>>>>>
>>>>>>> *Rationale*: We are attempting to ensure that the replacement
>>>>>>> transactions are not less incentive-compatible to mine. However, a
>>>>>>> package/transaction's ancestor feerate is not perfectly
>>>>>>> representative
>>>>>>> of its incentive compatibility; it may overestimate (some subset of
>>>>>>> the ancestors could be included by itself if it has other
>>>>>>> high-feerate
>>>>>>> descendants or are themselves higher feerate than this
>>>>>>> package/transaction). Instead, we use the minimum between the package
>>>>>>> feerate and ancestor feerate of the child as a more conservative
>>>>>>> value
>>>>>>> than what was proposed originally.
>>>>>>>
>>>>>>> 2. A new rule is added, requiring that all package transactions with
>>>>>>> mempool conflicts to be V3. This also means the "sponsoring"
>>>>>>> child transaction must be V3.
>>>>>>>
>>>>>>> *Note*: Combined with the V3 rules, this means the package must be
>>>>>>> a child-with-parents package. Since package validation is only
>>>>>>> attempted if the transactions do not pay sufficient fees to be
>>>>>>> accepted on their own, this effectively means that only V3
>>>>>>> transactions can pay to replace their ancestors' conflicts, and only
>>>>>>> V3 transactions' replacements may be paid for by a descendant.
>>>>>>>
>>>>>>> *Rationale*: The fee-related rules are economically rational for
>>>>>>> ancestor packages, but not necessarily other types of packages.
>>>>>>> A child-with-parents package is a type of ancestor package. It
>>>>>>> may be fine to allow any ancestor package, but it's more difficult
>>>>>>> to account for all of the possibilities. For example, it gets much
>>>>>>> harder to see that we're applying the descendant limits correctly if
>>>>>>> the package has a gnarly, many-generation, non-tree shape. I'm also
>>>>>>> not sure if this policy is 100% incentive-compatible if the sponsor
>>>>>>> is not a direct descendant of the sponsee.
>>>>>>>
>>>>>>> Please see doc/policy/version3_transactions.md and
>>>>>>> doc/policy/packages.md in the PR for the full set of rules.
>>>>>>>
>>>>>>> **Intended usage for LN:**
>>>>>>>
>>>>>>> Commitment transactions should be V3 and have 1 anchor output. They
>>>>>>> can be signed with 0 fees (or 1sat/vbyte) once package relay is
>>>>>>> deployed
>>>>>>> on a significant portion of the network. If the commitment tx must
>>>>>>> be broadcast, determine the desired feerate at broadcast time and
>>>>>>> spend the anchor output in a high feerate transaction. I'm going to
>>>>>>> call the broadcasted commitment tx "the parent" and the attached
>>>>>>> fee-bumping tx "the child."
>>>>>>>
>>>>>>> - This child must be V3.
>>>>>>> - This child must be at most 1000vB. Note this restricts the
>>>>>>>   number of inputs you can use to fund the fee bump. Depending
>>>>>>> on the output types, this is around 6-15.
>>>>>>> - One child may fund fees for multiple commitment tx ("batched
>>>>>>>   fee-bumping").
>>>>>>> - To do a second fee-bump to add more fees, replace the
>>>>>>>   *child* with a higher-feerate tx. Do not try to attach a
>>>>>>> grandchild.
>>>>>>>
>>>>>>> Otherwise, never try to spend from an unconfirmed V3 transaction. The
>>>>>>> descendant limits for V3 transactions are very restrictive.
>>>>>>>
>>>>>>> **Expected Questions:**
>>>>>>>
>>>>>>> "Does this fix Rule 3 Pinning?"
>>>>>>> Yes. The V3 descendant limit restricts both you and your
>>>>>>> counterparty.
>>>>>>> Assuming nodes adopted this policy, you may reasonably assume that
>>>>>>> you
>>>>>>> only need to replace the commitment transaction + up to 1000vB.
>>>>>>>
>>>>>>> "Only 1 anchor output? What if I need to bump counterparty's
>>>>>>> commitment tx in mempool?"
>>>>>>> You won't need to fee-bump a counterparty's commitment tx using CPFP.
>>>>>>> You would just package RBF it by attaching a high-feerate child to
>>>>>>> your commitment tx.
>>>>>>>
>>>>>>> "Is this a privacy issue, i.e. doesn't it allow fingerprinting LN
>>>>>>> transactions based on nVersion?"
>>>>>>> Indeed it may be unrealistic to assume V3 transactions will be in
>>>>>>> widespread use outside of L2. IIUC, unilateral closes are already
>>>>>>> obvious LN transactions because of the HTLC inputs. For e.g.
>>>>>>> cooperative closes and opens, I think it makes sense to continue
>>>>>>> using
>>>>>>> V2. So, unless I'm missing something, this shouldn't make it worse.
>>>>>>>
>>>>>>> "So a V3 transaction that doesn't signal BIP125 replaceability is
>>>>>>> replaceable? Is that a backward compatibility issue?"
>>>>>>> Yes it's replaceable. It's not an issue AFAICT because,
>>>>>>> under previous policy, the V3 transaction wouldn't have been
>>>>>>> in the mempool in the first place.
>>>>>>>
>>>>>>> "Can a V2 transaction replace a V3 transaction and vice versa?"
>>>>>>> Yes, otherwise someone can use V3 transactions to censor V2
>>>>>>> transactions spending shared inputs. Note if the
>>>>>>> original V3 transaction has an unconfirmed V3 parent, this would
>>>>>>> violate the "inherited V3" rule and would be rejected.
>>>>>>>
>>>>>>> Thanks for reading! Feedback and review would be much appreciated.
>>>>>>>
>>>>>>> [1]:
>>>>>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019464.html
>>>>>>> [2]:
>>>>>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019817.html
>>>>>>>
>>>>>>> Best,
>>>>>>> Gloria
>>>>>>> _______________________________________________
>>>>>>> bitcoin-dev mailing list
>>>>>>> bitcoin-dev at lists.linuxfoundation.org
>>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>>>>>
>>>>>> _______________________________________________
>>>>>> bitcoin-dev mailing list
>>>>>> bitcoin-dev at lists.linuxfoundation.org
>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>>>>
>>>>> _______________________________________________
>>>>> bitcoin-dev mailing list
>>>>> bitcoin-dev at lists.linuxfoundation.org
>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>>>
>>>> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220930/a5096f54/attachment-0001.html>

From antoine.riard at gmail.com  Fri Sep 30 02:00:30 2022
From: antoine.riard at gmail.com (Antoine Riard)
Date: Thu, 29 Sep 2022 22:00:30 -0400
Subject: [bitcoin-dev] Spookchains: Drivechain Analog with One-Time
 Trusted Setup & APO
In-Reply-To: <CAD5xwhgKGMx79+RLpb-hjd3Gc=EKxTVzkpME-=KuM_C5+d7mRQ@mail.gmail.com>
References: <CAD5xwhgKGMx79+RLpb-hjd3Gc=EKxTVzkpME-=KuM_C5+d7mRQ@mail.gmail.com>
Message-ID: <CALZpt+E6KeyvAp-nBUdO3J79dKRKHEZJkUpcSasJ4TH9h=sU7g@mail.gmail.com>

Hi Jeremy,

Thanks for bringing back to awareness covenant-based drivechain designs
again!

I'm not super familiar with the thousands shades of sidechains, and
especially how the variants of pegging mechanisms influence the soundness
of the game-theory backing up the functionaries execution. However it could
be interesting to give security bounds to the defect of any trusted
component, such as the one-time trusted setup, and the impacts on funds. If
it's a full-blown loss, a timevalue loss, a privacy leak, etc...

Started at least an entry for the ZmnSCPxj design:
https://github.com/ariard/bitcoin-contracting-primitives-wg/pull/9

One interesting point from the OG post:
> The recursive covenant could, with the help of `OP_CAT` and
> `OP_CTV`, check that every transaction spending the UTXO has a
> second output that is an `OP_RETURN` with a commitment to the
> sidechain block.
> We can ensure that only one such transaction exists in each
> mainchain block by adding a `<1> OP_CSV`, ensuring that only one
> sidechain-commitment transaction can occur on each mainchain
> block.

Such recursive-covenant "embedded" sidechains could be used as solution to
the double-spend of payment pools and channel factories partitions, as an
instantiation of a "on-chain authoritative board" for partitions statement,
as described earlier this year, in a quest to solve the high interactivity
issue affecting those constructions [0].

Best,
Antoine

[0]
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-April/020370.html

Le mer. 14 sept. 2022 ? 14:32, Jeremy Rubin via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> a ?crit :

> *also available here on my blog with nicer
> formatting: https://rubin.io/bitcoin/2022/09/14/drivechain-apo/
> <https://rubin.io/bitcoin/2022/09/14/drivechain-apo/>*
>
> This post draws heavily from Zmnscpxj's fantastic post showing how to
> make drivechains with recursive covenants. In this post, I will show
> similar tricks that can accomplish something similar using ANYPREVOUT
> with a one time trusted setup ceremony.
>
> This post presents general techniques that could be applied to many
> different types of covenant.
>
> # Peano Counters
>
> The first component we need to build is a Peano counter graph. Instead
> of using sha-256, like in Zmnscpxj's scheme, we will use a key and
> build a simple 1 to 5 counter that has inc / dec.
>
> Assume a key K1...K5, and a point NUMS which is e.g.
> HashToCurve("Spookchains").
>
> Generate scripts as follows:
>
> ```
> <1 || K1> CHECKSIG
> ...
> <1 || K5> CHECKSIG
> ```
>
> Now generate 2 signatures under Ki with flags `SIGHASH_SINGLE |
> SIGHASH_ANYONECANPAY | SIGHASH_ANYPREVOUT`.
>
>
> ## Rule Increment
> For each Ki, when `i < 5`, create a signature that covers a
> transaction described as:
>
> ```
> Amount: 1 satoshi
> Key: Tr(NUMS, {<1 || K{i+1}> CHECKSIG})
> ```
>
> ## Rule Decrement
> For each Ki, when `i > 1` The second signature should cover:
> ```
> Amount: 1 satoshi
> Key: Tr(NUMS, {<1 || K{i-1}> CHECKSIG})
> ```
>
>
>
> _Are these really Peano?_ Sort of. While a traditional Peano numeral
> is defined as a structural type, e.g. `Succ(Succ(Zero))`, here we
> define them via a Inc / Dec transaction operator, and we have to
> explicitly bound these Peano numbers since we need a unique key per
> element. They're at least spiritually similar.
>
> ## Instantiation
> Publish a booklet of all the signatures for the Increment and
> Decrement rules.
>
> Honest parties should destroy the secret key sets `k`.
>
>
> To create a counter, simply spend to output C:
>
> ```
> Amount: 1 satoshi
> Key: Tr(NUMS, {<1 || K1> CHECKSIG})
> ```
>
>
> The signature from K1 can be bound to C to 'transition' it to (+1):
>
> ```
> Amount: 1 satoshi
> Key: Tr(NUMS, {<1 || K2> CHECKSIG})
> ```
>
> Which can then transition to (+1):
>
> ```
> Amount: 1 satoshi
> Key: Tr(NUMS, {<1 || K3> CHECKSIG})
> ```
>
> Which can then transition (-1) to:
>
> ```
> Amount: 1 satoshi
> Key: Tr(NUMS, {<1 || K2> CHECKSIG})
> ```
>
> This can repeat indefinitely.
>
>
> We can generalize this technique from `1...5` to `1...N`.
>
>
>
> # Handling Arbitrary Deposits / Withdrawals
>
>
> One issue with the design presented previously is that it does not
> handle arbitrary deposits well.
>
> One simple way to handle this is to instantiate the protocol for every
> amount you'd like to support.
>
> This is not particularly efficient and requires a lot of storage
> space.
>
> Alternatively, divide (using base 2 or another base) the deposit
> amount into a counter utxo per bit.
>
> For each bit, instead of creating outputs with 1 satoshi, create
> outputs with 2^i satoshis.
>
> Instead of using keys `K1...KN`, create keys `K^i_j`, where i
> represents the number of sats, and j represents the counter. Multiple
> keys are required per amount otherwise the signatures would be valid
> for burning funds.
>
> ## Splitting and Joining
>
> For each `K^i_j`, it may also be desirable to allow splitting or
> joining.
>
> Splitting can be accomplished by pre-signing, for every `K^i_j`, where
> `i!=0`, with `SIGHASH_ALL | SIGHASH_ANYPREVOUT`:
>
> ```
> Input: 2^i sats with key K^i_j
> Outputs:
>     - 2^i-1 sats to key K^{i-1}_j
>     - 2^i-1 sats to key K^{i-1}_j
> ```
>
> Joining can be accomplished by pre-signing, for every `K^i_j`, where
> `i!=MAX`, with `SIGHASH_ALL | SIGHASH_ANYPREVOUT`:
>
> ```
> Inputs:
>     - 2^i sats with key K^i_j
>     - 2^i sats with key K^i_j
> Outputs:
>     - 2^i+1 sats to key K^{i+1}_j
> ```
>
> N.B.: Joining allows for third parties to deposit money in externally,
> that is not a part of the covenant.
>
>
> The splitting and joining behavior means that spookchain operators
> would be empowered to consolidate UTXOs to a smaller number, while
> allowing arbitrary deposits.
>
>
> # One Vote Per Block
>
> To enforce that only one vote per block mined is allowed, ensure that
> all signatures set the input sequence to 1 block. No CSV is required
> because nSequence is in the signatures already.
>
> # Terminal States / Thresholds
>
> When a counter reaches the Nth state, it represents a certain amount
> of accumulated work over a period where progress was agreed on for
> some outcome.
>
> There should be some viable state transition at this point.
>
> One solution would be to have the money at this point sent to an
> `OP_TRUE` output, which the miner incrementing that state is
> responsible for following the rules of the spookchain. Or, it could be
> specified to be some administrator key / federation for convenience,
> with a N block timeout that degrades it to fewer signers (eventually
> 0) if the federation is dead to allow recovery.
>
> This would look like, from any `K^i_j`, a signature for a transaction
> putting it into an `OP_TRUE` and immediately spending it. Other
> spookchain miners would be expected to orphan that miner otherwise.
>
>
> # Open States / Proposals
>
> From a state `K^i_1`, the transaction transitioning to `K^i_2` can be
> treated as 'special' and the `OP_RETURN` output type can be used to
> commit to, e.g., the outputs that must be created in when the Terminal
> State is reached. This clarifies the issue of "what is being voted
> on".
>
> This method does not *lock in* at a consensus layer what Terminal
> State is being voted on.
>
> In certain circumstances, without violating the one-time-setup
> constraint, if a fixed list of withdrawer's addresses is known in
> advance, the Open States could cover withdrawals to specific
> participants, which then must collect a certain number of votes from
> miners.  However, it seems impossible, without new primitives, for an
> arbitrary transaction proposal to be voted on.
>
> # Setup Variants
>
> ## xpubs
>
> Instead of using randomly generated keys for each state, define each
> to be an xpub and derive a path where it is k/i/j for each
> state/satoshi amount. This saves some data, and also requires less
> entropy.
>
> ### Trustless Data Commit:
>
> commit to the hash of the entire program spec as a tweak to the xpub,
> so that someone can quickly verify if they have all the signatures you
> are expected to generate if honest.
>
> One way to do this is to convert a hash to a list of HD Child Numbers
> (9 of them) deterministically, and tweak the xpub by that. This is a
> convenient, yet inefficient, way to tweak an xpub because the child
> has a normal derivation path for signing devices.
>
> ## Single Party
>
> A single party pre-signs all the transactions for the spookchain, and
> then deletes their xpriv.
>
> You trust them to have deleted the key, and signed properly, but you
> do not trust whoever served you the spookchain blob to have given you
> all the state transitions because of the trustless data commitment.
>
> ## MuSig Multi-Party
>
> Define a MuSig among all participants in the setup ceremony, N-of-N.
>
> Now you simply trust that any one person in the one-time-setup was
> honest! Very good.
>
> ## Unaggregated Multi-Party
>
>
> Allow for unaggregated multi-sig keys in the spec. This grows with
> O(signers), however, it means that a-la-carte you can aggregate setups
> from random participants who never interacted / performed setup
> ceremonies independently if they signed the same specs.
>
> Can also combine multiple MuSig Multi-Parties in this way.
>
> This is nice because MuSig inherently implies the parties colluded at
> one point to do a MuSig setup, whereas unaggregated multi-sig could be
> performed with no connectivity between parties.
>
> ## Soft Forking Away Trust
>
> Suppose a spookchain becomes popular. You could configure your client
> to reject invalid state transitions, or restrict the spookchain keys
> to only sign with the known signatures. This soft fork would smoothly
> upgrade the trust assumption.
>
> ## Symmetry of State Transition Rules & DAG Covenants
>
> We could have our increment state transitions be done via a trustless
> covenant, and our backwards state transitions be done via the setup.
>
> This would look something like the following for state i:
>
> ```
> Tr(NUMS, {
>     `<sig for state K_{i+1}> <1 || PK_nonsecret> CHECKSIG`,
>     `<1 || Ki> CHECKSIG`
> })
> ```
>
> The advantage of such an optimization is theoretically nice because it
> means that *only* the non-destructuring recursive part of the
> computation is subject to the one-time-setup trust assumption, which
> might be of use in various other protocols, where recursivity might
> only be unlocked e.g. after a timeout (but for spookchains it is used
> at each step).
>
> A compiler writer might perform this task by starting with an
> arbitrary abstract graph, and then removing edges selectively (a
> number of heuristics may make sense, e.g., to minimize reliance on
> one-time-setup or minimize costs) until the graph is a Directed
> Acyclic Graph, consisting of one or more components, compiling those
> with committed covenants, and then adding the removed edges back using
> the one-time-setup key materials.
>
>
> # Commentary on Trust and Covenantiness
>
> Is this a covenant? I would say "yes". When I defined covenants in my
> _Calculus of Covenants_ post, it was with a particular set of
> assumptions per covenant.
>
> Under that model, you could, e.g., call a 7-10 multi-sig with specific
> committed instructions as 4-10 honest (requires 4 signatories to be
> honest to do invalid state transition) and 4-10 killable (requires 4
> signatories to die to have no way of recovering).
>
> For emulations that are pre-signed, like the varieties used to emulate
> CTV, it is a different model because if your program is correct and
> you've pre-gotten the signatures for N-N it is 1-N honest (only 1
> party must be honest to prevent an invalid state transition) and
> unkillable (all parties can safely delete keys).
>
> I model these types of assumptions around liveness and honesty as
> different 'complexity classes' than one another.
>
> What I would point out is that with the counter model presented above,
> this is entirely a pre-signed 1-N honest and unkillable covenant that
> requires no liveness from signers. Further, with APO, new instances of
> the covenant do not require a new set of signers, the setup is truly
> one-time. Therefore this type of covenant exists in an even lower
> trust-complexity class than CTV emulation via presigneds, which
> requires a new federation to sign off on each contract instance.
>
>
> With that preface, let us analyze this covenant:
>
>
> 1) A set of sets of transaction intents (a family), potentially
> recursive or co-recursive (e.g., the types of state transitions that
> can be generated).  These intents can also be represented by a
> language that generates the transactions, rather than the literal
> transactions themselves. We do the family rather than just sets at
> this level because to instantiate a covenant we must pick a member of
> the family to use.
>
>
> The set of sets of transaction intents is to increment / decrement to
> a successor or predecessor, or to halve into two instances or double
> value by adding funds. Each successor or predecessor is the same type
> of covenant, with the excetion of the first and last, which have some
> special rules.
>
>
> 2) A verifier generator function that generates a function that
> accepts an intent that is any element of one member of the family of
> intents and a proof for it and rejects others.
>
> The verifier generator is the simple APO CHECKSIG script.
>
> 3) A prover generator function that generates a function that takes an
> intent that is any element of one member of the family and some extra
> data and returns either a new prover function, a finished proof, or a
> rejection (if not a valid intent).
>
> The prover generator is the selection of the correct signature from a
> table for a given script.
>
> Run the prover generator with the private keys present *once* to
> initialize over all reachable states, and cache the signatures, then
> the keys may be deleted for future runs.
>
> 4) A set of proofs that the Prover, Verifier, and a set of intents are
> "impedance matched", that is, all statements the prover can prove and
> all statements the verifier can verify are one-to-one and onto (or
> something similar), and that this also is one-to-one and onto with one
> element of the intents (a set of transactions) and no other.
>
> At a given key state the only things that may happen are signed
> transactions, no other data is interpreted off of the stack. Therefore
> there is perfect impedance match.
>
>
> 5) A set of assumptions under which the covenant is verified (e.g., a
> multi-sig covenant with at least 1-n honesty, a multisig covenant with
> any 3-n honesty required, Sha256 collision resistance, Discrete Log
> Hardness, a SGX module being correct).
>
> Uniquely, that during the setup phase at least one of the keys
> were faithfully deleted.
>
> The usual suspects for any bitcoin transaction are also assumed for
> security.
>
>
> 6) Composability:
>
> The Terminal State can pay out into a pre-specified covenant if
> desired from any other family of covenants.
> --
> @JeremyRubin <https://twitter.com/JeremyRubin>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220929/0b793626/attachment-0001.html>

From bastien at acinq.fr  Fri Sep 30 12:08:41 2022
From: bastien at acinq.fr (Bastien TEINTURIER)
Date: Fri, 30 Sep 2022 14:08:41 +0200
Subject: [bitcoin-dev] New transaction policies (nVersion=3) for
 contracting protocols
In-Reply-To: <CAPv7TjYM34qk5bGheMZhopotuCwxYyHmWAXcawA5UHQpQWiGCg@mail.gmail.com>
References: <CAFXO6=KDys2_dsrdxE9_q_MVZJOFMbg-MctxiokcicP=wd4Lkw@mail.gmail.com>
 <CALZpt+HYUti=foo+d5ER7Wj=PxsfgaU2CEqqG4_KRxmsWoaSxw@mail.gmail.com>
 <CACdvm3PyP9yrxx_Yewtx_yQh=i2uwGYj-wtY7HBER1bmG46NEw@mail.gmail.com>
 <CAB3F3Du=+YYKbfgB5LZPnCg40=5YCn_0tkpJ4LO9bMK0U-3wXg@mail.gmail.com>
 <CAFXO6=JGBPVpxTJnSMWCCZVPHZW_RyWQ2Cv18Ao_F=uQx3LVkg@mail.gmail.com>
 <CACdvm3OUpODbMzkcG+=qYzR9myrvSp-LpuGmETow94JavU2GDw@mail.gmail.com>
 <CAB3F3DvCw9Ms+HUMaFnqV0P-Oo+rfERY+j5S5CC_X2NKRd5u8g@mail.gmail.com>
 <CAPv7TjYM34qk5bGheMZhopotuCwxYyHmWAXcawA5UHQpQWiGCg@mail.gmail.com>
Message-ID: <CACdvm3MTSVDOSLmpDTzs6Gj1Oz-9rDgPKY=ipMdV9iJzQhE-ew@mail.gmail.com>

Hey Ruben,

I discussed this further over IRC, and I now agree that this particular
change would be very desirable and can likely fit in the initial release
(even though I'm not the one writing that code, but I'd be happy to
review it and test it).

Greg already has a draft design that addresses your concerns: if there is
an "ephemeral output" (0-value, OP_TRUE) in an unconfirmed v3 transaction,
it MUST be spent by any child v3 transaction. This way, you ensure that
any child transaction spending the unconfirmed parent spends the ephemeral
output(s). @Greg, correct me if I misunderstood something here. Note that
we will need to precisely define the criteria for those "ephemeral outputs"
(it can probably simply be "outputs that are 0 sats").

Coupled with transactions that pay no fees (and thus require a child to
CPFP in order to be included in a block), this ensures those outputs can
never leak into the utxo set. How does that sound?

I'm curious why you would need more than one such output, can you detail?
I believe we only ever need one, spendable by anyone.

Cheers,
Bastien

Le ven. 30 sept. 2022 ? 02:14, Ruben Somsen <rsomsen at gmail.com> a ?crit :

> Hi Bastien,
>
> >The other change mentioned (making OP_TRUE standard and allowing outputs
> that are below dust) can be added later, as those won't be standard until
> we start allowing them, so there shouldn't be any backwards-compatibility
> issue with postponing this change. But maybe it's still worth having from
> the get-go, even though it may take a bit more time? Again, I'm curious to
> have other people's opinion here
>
> I'm sensitive to not wanting to overload the current discussion but this
> also interests me, provided it can be done in a way that is acceptable
> (i.e. minimizing the potential UTXO set impact). It would solve a big cost
> issue in my spacechains design if transactions could be 0 fees and have a 0
> sat output that could be used in order to pay all the fees with CPFP.
>
> My current view is that a tx containing a single 0 sat OP_TRUE output
> should only get relayed if it is a package where the OP_TRUE output is
> currently being spent in a way that increases the overall fee rate. But
> even then, one theoretical edge case remains:
> - Another CPFP tx can feebump the package on a different (non-OP_TRUE)
> output with an even higher fee rate
> - Subsequently, the tx that is spending the OP_TRUE might fall out of the
> mempool if the mempool fee rate rises
> - This could cause the 0 sat output to enter the UTXO set (specifically,
> rational miners wouldn't refuse to mine such a tx)
>
> It doesn't seem like this would happen much in practice (nor is there an
> incentive to do it on purpose), but the chance isn't 0.
>
> Cheers,
> Ruben
>
>
>
> On Thu, Sep 29, 2022 at 4:50 PM Greg Sanders via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>> > Right, good catch, this does require new logic to handle this case.
>> As Gloria points out, this should be doable, and is definitely worth
>> adding (those CSV 1 on every other output are really hacky, glad to
>> find a way to get rid of them).
>>
>> For the record, it turns out ephemeral anchors + v3 solves this already,
>> as the anchor must be spent, and the parent tx may only have one child.
>> Somehow I missed this implication for a few months. It's great news if we
>> can directly source fees from any output claimable, including HTLCs!
>>
>> On Thu, Sep 29, 2022 at 5:15 AM Bastien TEINTURIER <bastien at acinq.fr>
>> wrote:
>>
>>> Hi Gloria, Greg,
>>>
>>> > I interpret most of the discussion around limitations as ideas for
>>> > future improvements rather than criticisms of the proposal
>>>
>>> As far as I'm concerned, definitely!
>>>
>>> My current understanding is that the main change/improvement that would
>>> make sense here is restricting the whole v3 package's size (instead of
>>> just the child) via committing to a specific value in the taproot annex
>>> (also note that it's probably not just the v3 package's size, it should
>>> be the whole unconfirmed package including potential v2 unconfirmed
>>> ancestors).
>>>
>>> While I think this would be very valuable and would like to see this
>>> happen, I believe that can be done in a second, separate step since this
>>> would make relay policy stricter (some v3 transactions that previously
>>> propagated wouldn't propagate under this new rule). As long as you are
>>> able to find a path to miners through upgraded peers that use this annex
>>> approach, you should be able to resolve ACP pinning issues?
>>>
>>> I'm curious to know how other people feel about that: is it ok to do
>>> later or should we try to implement this for the first release of v3
>>> transactions?
>>>
>>> The other change mentioned (making OP_TRUE standard and allowing outputs
>>> that are below dust) can be added later, as those won't be standard until
>>> we start allowing them, so there shouldn't be any backwards-compatibility
>>> issue with postponing this change. But maybe it's still worth having from
>>> the get-go, even though it may take a bit more time? Again, I'm curious
>>> to
>>> have other people's opinion here, I'd be happy to get all of those
>>> directly
>>> in the first release of v3 transactions, but I don't know how much
>>> implementation will have to go into that.
>>>
>>> > For clarification, package RBF is ParentTx*s*(plural), and
>>> ChildTx(singular),
>>> > so it might be a bit more complicated than we're thinking
>>>
>>> Right, good catch, this does require new logic to handle this case.
>>> As Gloria points out, this should be doable, and is definitely worth
>>> adding (those CSV 1 on every other output are really hacky, glad to
>>> find a way to get rid of them).
>>>
>>> Thanks,
>>> Bastien
>>>
>>> Le lun. 26 sept. 2022 ? 18:48, Gloria Zhao <gloriajzhao at gmail.com> a
>>> ?crit :
>>>
>>>> Hi Greg, Antoine, Bastien,
>>>>
>>>> Thanks very much for the feedback! I interpret most of the discussion
>>>> around limitations as ideas for future improvements rather than criticisms
>>>> of the proposal (please correct me if I'm wrong). I'll try to respond to as
>>>> much as possible.
>>>>
>>>> Also I realize that I didn't contextualize this proposal clearly
>>>> enough; it is very tailored for LN Penalty and definitely doesn't close all
>>>> pinning attacks possible (sorry for confusing anyone). I also agree that
>>>> some bits can be a little ugly or tack-on; I would definitely prefer a
>>>> comprehensive RBF revamp to fix all our problems and enable other
>>>> fee-bumping strategies such as
>>>> sign-ANYONECANPAY-then-bring-your-own-fees-by-adding-inputs-at-broadcast. I
>>>> was hoping to get some ideas with the "RBF Improvements" post in January,
>>>> but it doesn't seem like we're much closer to a workable proposal. I think
>>>> this is a minimally-invasive step that works for Lightning today, a small
>>>> fix similar to CPFP carve out.
>>>>
>>>> > As you likely know from previous discussions the biggest scenario
>>>> this does not fix in my estimation is ANYONECANPAY situations. If the
>>>> parent transaction can be "inflated" by tacking on additional inputs, this
>>>> means the total weight of the parent tx lowers the effective feerate of the
>>>> package.
>>>>
>>>> (For more context to other readers I wrote an explanation for this in
>>>> "SIGHASH_ANYONECANPAY Pinning" section of RBF ML post).  Yes, this
>>>> unfortunately doesn't fix any of the existing pinning attacks for single
>>>> transaction RBF but also doesn't make them worse. This boils down to adding
>>>> an incentive compatibility rule that ensures you can't replace a
>>>> transaction with something that will confirm slower. Package RBF has an
>>>> ancestor feerate-based rule for this (note it is quite conservative and not
>>>> perfect).
>>>>
>>>> So in the scenario above with the "inflated" parent that was signed
>>>> ACP, the replacement would be rejected because the package ancestor feerate
>>>> is lower than the feerate of what is being replaced. But it is imperfect
>>>> (explained below) and thus I wouldn't recommend it for single transaction
>>>> replacement. So that attack still exists for single transactions, yes.
>>>>
>>>> The strategy of using ACP to bring-your-own-fees has its own challenges
>>>> but hopefully has no current use cases as you say. AFAIK LN Penalty is not
>>>> affected by this since it doesn't use ACP, though obviously I agree we
>>>> should fix it for the future.
>>>>
>>>> So when I said "this is intended for fee-bumping presigned txns in
>>>> contracting protocols," I should have said "this is intended for
>>>> fee-bumping presigned txns specifically using CPFP and anchor outputs."
>>>> Apologies for forgetting to contextualize, I've been sitting on this for
>>>> too long.
>>>>
>>>> > The other scenario it doesn't really fix is where
>>>> HTLC/commitment-like transactions are being resolved in a batch, but due to
>>>> relative time constraints, you may want to accelerate some and not others.
>>>> Now you must pay higher rates to replace all of the transaction bumps. This
>>>> is a "self-pin" and "get good at utxos noob" type problem, but it's
>>>> something that axing rule#3 in favor of a Replace-by-ancestor-feerate
>>>> system would get us.
>>>>
>>>> I understand you to mean "if you don't have enough UTXOs and you're
>>>> forced to batch-bump, you over-pay because you need to bring them all to
>>>> the highest target feerate." Isn't this kind of separate, wallet-related
>>>> problem? Contracting or not, surely every wallet needs to have enough UTXOs
>>>> to not batch transactions that shouldn't be batched... I don't see how a
>>>> replace-by-ancestor-feerate policy would make any difference for this?
>>>>
>>>> Also in general I'd like to reiterate that ancestor feerate is not a
>>>> panacea to all our RBF incentive compatibility concerns. Like individual
>>>> feerate, unless we run the mining algorithm, it cannot tell us exactly how
>>>> quickly this transaction would be mined.
>>>>
>>>> We're estimating the incentive compatibility of the original
>>>> transaction(s) and replacement transaction(s), with the goal of not letting
>>>> a transaction replace something that would have been more incentive
>>>> compatible to mine. As such, we don't want to overestimate how good the
>>>> replacement is, and we don't want to underestimate how good the original
>>>> transactions are. This rule "The minimum between package feerate and
>>>> ancestor feerate of the child is not lower than the individual feerates of
>>>> all directly conflicting transactions and the ancestor feerates of all
>>>> original transactions" is a conservative estimate.
>>>>
>>>> > Would kind of be nice if package RBF would detect a "sibling output
>>>> spend" conflict, and knock it out of the mempool via the other replacement
>>>> rules? Getting rid of the requirement to 1 block csv lock every output
>>>> would be quite nice from a smart contracting composability point of view.
>>>>
>>>> Interesting, so when a transaction hits a mempool tx's descendant
>>>> limit, we consider evicting one of its descendants in favor of this
>>>> transaction, based on the RBF rules.
>>>> Cool idea! After chewing on this for a bit, I think this *also* just
>>>> boils down to the fact that RBF should require replacements to be better
>>>> mining candidates. As in, if we added this policy and it can make us evict
>>>> the sibling and accept a transaction with a bunch of low-feerate ancestor
>>>> junk, it would be a new pinning vector.
>>>>
>>>> > If you're a miner and you receive a non-V3, second descendant of an
>>>> unconfirmed V3 transaction, if the offered fee is in the top mempool
>>>> backlog, I think you would have an interest to accept such a transaction.
>>>>
>>>> > So I'm not sure if those two rules are compatible with miners
>>>> incentives...
>>>>
>>>> The same argument can be made for the 26th descendant of a mempool
>>>> transaction; it's also not entirely incentive-compatible to reject it, but
>>>> that is not the *only* design goal in mempool policy. Of course, the
>>>> difference here is that the 25-descendant limit rule is a sensible DoS
>>>> protection, while this 1-descendant limit rule is more of a "help the
>>>> Bitcoin ecosystem" policy, just like CPFP carve-out, dust limit, etc. I can
>>>> of course understand why not everyone would be in favor of this, but I do
>>>> think it's worth it.
>>>>
>>>> > > 4. A V3 transaction that has an unconfirmed V3 ancestor cannot be
>>>>
>>>> > >    larger than 1000 virtual bytes.
>>>>
>>>> > If I understand correctly the 1000 vb upper bound rational, it would
>>>> be to constraint the pinning counterparty to attach a high fee to a child
>>>> due to the limited size, if they would like this transaction to be stuck in
>>>> the network mempools. By doing so  this child has high odds to confirm.
>>>>
>>>> Yeah exactly, the "Rule 3 pin" is done by adding a child that's
>>>> high-fee (so you have to pay that much to evict it). Because they *don't*
>>>> want this tx to confirm, normally, this child would be really large. If
>>>> they only have 1000vB for the child, they can't increase the replacement
>>>> cost without also fee-bumping the transaction to make it confirm faster.
>>>>
>>>> > As of today, I think yes you can already fingerprint LN transactions
>>>> on the  spec-defined amount value of the anchor outputs, 330 sats. There is
>>>> always one of them on post-anchor commitment transactions. And sadly I
>>>> would say we'll always have tricky fingerprints leaking from unilateral LN
>>>> closures such as HTLC/PTLC timelocks...
>>>>
>>>> > I agree with you, this isn't worse than today, unilateral closes will
>>>> probably always be identifiable on-chain.
>>>>
>>>> Great to hear that there is no privacy worsening!
>>>>
>>>> Best,
>>>> Gloria
>>>>
>>>> On Mon, Sep 26, 2022 at 5:02 PM Greg Sanders <gsanders87 at gmail.com>
>>>> wrote:
>>>>
>>>>> Bastien,
>>>>>
>>>>> > This may be already covered by the current package RBF logic, in that
>>>>> scenario we are simply replacing [ParentTx, ChildTx1] with
>>>>> [ParentTx, ChildTx2] that pays more fees, right?
>>>>>
>>>>> For clarification, package RBF is ParentTx*s*(plural), and
>>>>> ChildTx(singular), so it might be a bit more complicated than we're
>>>>> thinking, and currently the V3 proposal would first de-duplicate the
>>>>> ParentTx based on what is in the mempool, then look at the "rest" of the
>>>>> transactions as a package, then individually. Not the same, not sure how
>>>>> different. I'll defer to experts.
>>>>>
>>>>> Best,
>>>>> Greg
>>>>>
>>>>> On Mon, Sep 26, 2022 at 11:48 AM Bastien TEINTURIER via bitcoin-dev <
>>>>> bitcoin-dev at lists.linuxfoundation.org> wrote:
>>>>>
>>>>>> Thanks Gloria for this great post.
>>>>>>
>>>>>> This is very valuable work for L2 contracts, and will greatly improve
>>>>>> their security model.
>>>>>>
>>>>>> > "Only 1 anchor output? What if I need to bump counterparty's
>>>>>> commitment tx in mempool?"
>>>>>> > You won't need to fee-bump a counterparty's commitment tx using
>>>>>> CPFP.
>>>>>> > You would just package RBF it by attaching a high-feerate child to
>>>>>> > your commitment tx.
>>>>>>
>>>>>> Note that we can also very easily make that single anchor spendable by
>>>>>> both participants (or even anyone), so if you see your counterparty's
>>>>>> commitment in your mempool, you can bump it without publishing your
>>>>>> own commitment, which is quite desirable (your own commitment tx has
>>>>>> CSV delays on your outputs, whereas your counterparty's commitment tx
>>>>>> doesn't).
>>>>>>
>>>>>> > "Is this a privacy issue, i.e. doesn't it allow fingerprinting LN
>>>>>> transactions based on nVersion?"
>>>>>>
>>>>>> I agree with you, this isn't worse than today, unilateral closes will
>>>>>> probably always be identifiable on-chain.
>>>>>>
>>>>>> > Would kind of be nice if package RBF would detect a "sibling output
>>>>>> spend"
>>>>>> > conflict, and knock it out of the mempool via the other replacement
>>>>>> rules?
>>>>>> > Getting rid of the requirement to 1 block csv lock every output
>>>>>> would be
>>>>>> > quite nice from a smart contracting composability point of view.
>>>>>>
>>>>>> +1, that would be very neat!
>>>>>>
>>>>>> This may be already covered by the current package RBF logic, in that
>>>>>> scenario we are simply replacing [ParentTx, ChildTx1] with
>>>>>> [ParentTx, ChildTx2] that pays more fees, right?
>>>>>>
>>>>>> > 1) I do think that we should seriously consider allowing OP_TRUE to
>>>>>> become
>>>>>> > a standard script type as part of this policy update. If pinning is
>>>>>> solved,
>>>>>> > then there's no reason to require all those extra bytes for
>>>>>> "binding" an
>>>>>> > anchor to a specific wallet/user. We can save quite a few bytes by
>>>>>> having
>>>>>> > the input be empty of witness data.
>>>>>> > 2) If we allow for a single dust-value(0 on up) output which is
>>>>>> immediately
>>>>>> > spent by the package, anchors become even easier to to design. No
>>>>>> value has
>>>>>> > to be "sapped" from contract participants to make an anchor output.
>>>>>> There's
>>>>>> > more complications for this, such as making sure the parent
>>>>>> transaction is
>>>>>> > dropped if the child spend is dropped, but maybe it's worth the
>>>>>> squeeze.
>>>>>>
>>>>>> I also think both of these could be quite useful. This would probably
>>>>>> always
>>>>>> be used in combination with a parent transaction that pays 0 fees, so
>>>>>> the
>>>>>> 0-value output would always be spent in the same block.
>>>>>>
>>>>>> But this means we could end up with 0-value outputs in the utxo set,
>>>>>> if for
>>>>>> some reason the parent tx is CPFP-ed via another output than the
>>>>>> 0-value one,
>>>>>> which would be a utxo set bloat issue. But I'd argue that we're
>>>>>> probably
>>>>>> already creating utxo set bloat with the 330 sat anchor outputs
>>>>>> (especially
>>>>>> since we use two of them, but only one is usually spent), so it would
>>>>>> probably be *better* than what we're doing today.
>>>>>>
>>>>>> Thanks,
>>>>>> Bastien
>>>>>>
>>>>>> Le lun. 26 sept. 2022 ? 03:22, Antoine Riard via bitcoin-dev <
>>>>>> bitcoin-dev at lists.linuxfoundation.org> a ?crit :
>>>>>>
>>>>>>> Hi Gloria,
>>>>>>>
>>>>>>> Thanks for the progress on package RBF, few early questions.
>>>>>>>
>>>>>>> > 2. Any descendant of an unconfirmed V3 transaction must also be V3.
>>>>>>>
>>>>>>> > 3. An unconfirmed V3 transaction cannot have more than 1
>>>>>>> descendant.
>>>>>>>
>>>>>>> If you're a miner and you receive a non-V3, second descendant of an
>>>>>>> unconfirmed V3 transaction, if the offered fee is in the top mempool
>>>>>>> backlog, I think you would have an interest to accept such a transaction.
>>>>>>>
>>>>>>> So I'm not sure if those two rules are compatible with miners
>>>>>>> incentives...
>>>>>>>
>>>>>>> > 4. A V3 transaction that has an unconfirmed V3 ancestor cannot be
>>>>>>> >    larger than 1000 virtual bytes.
>>>>>>>
>>>>>>> If I understand correctly the 1000 vb upper bound rational, it would
>>>>>>> be to constraint the pinning counterparty to attach a high fee to a child
>>>>>>> due to the limited size, if they would like this transaction to be stuck in
>>>>>>> the network mempools. By doing so  this child has high odds to confirm.
>>>>>>>
>>>>>>> I still wonder if this compatible with miner incentives in period of
>>>>>>> empty mempools, in the sense that if you've already a V3 transaction of
>>>>>>> size 100Kvb offering 2 sat/vb, it's more interesting than a V3 replacement
>>>>>>> candidate of size 1000 vb offering 10 sat/vb. It could be argued the former
>>>>>>> should be conserved.
>>>>>>>
>>>>>>> (That said, the hard thing with any replacement strategy we might
>>>>>>> evict a parent transaction *now* to which is attached a high-feerate child
>>>>>>> *latter* making for a utxo considered the best ancestor set. Maybe in the
>>>>>>> long-term miners should keep every transaction ever accepted...)
>>>>>>>
>>>>>>> > (Lower bound) the smaller this limit, the fewer UTXOs a child may
>>>>>>> use
>>>>>>> > to fund this fee-bump. For example, only allowing the V3 child to
>>>>>>> have
>>>>>>> > 2 inputs would require L2 protocols to manage a wallet with
>>>>>>> high-value
>>>>>>> > UTXOs and make batched fee-bumping impossible. However, as the
>>>>>>> > fee-bumping child only needs to fund fees (as opposed to payments),
>>>>>>> > just a few UTXOs should suffice.
>>>>>>>
>>>>>>> Reminder for L2 devs, batched fee-bumping of time-sensitive
>>>>>>> confirmations of commitment transactions is unsafe, as the counterparty
>>>>>>> could enter in a "cat-and-mouse" game to replace one of the batch element
>>>>>>> at each block to delay confirmation of the remaining elements in the batch,
>>>>>>> I think.
>>>>>>>
>>>>>>> On the other hand, I wonder if we wouldn't want a higher bound. LN
>>>>>>> wallets are likely to have one big UTXO in their fee-bumping reserve pool,
>>>>>>> as the cost of acquiring UTXO is non-null and in the optimistic case, you
>>>>>>> don't need to do unilateral closure. Let's say you close dozens of channels
>>>>>>> at the same time, a UTXO pool management strategy might be to fan-out the
>>>>>>> first spends UTXOs in N fan-out outputs ready to feed the remaining
>>>>>>> in-flight channels.
>>>>>>>
>>>>>>> > 1. The rule around unconfirmed inputs was
>>>>>>> > originally "A package may include new unconfirmed inputs, but the
>>>>>>> > ancestor feerate of the child must be at least as high as the
>>>>>>> ancestor
>>>>>>> > feerates of every transaction being replaced."
>>>>>>>
>>>>>>> Note, I think we would like this new RBF rule to also apply to
>>>>>>> single transaction package, e.g second-stage HTLC transactions, where a
>>>>>>> counterparty pins a HTLC-preimage by abusing rule 3. In that case, the
>>>>>>> honest LN node should be able to broadcast a "at least as high ancestor
>>>>>>> feerate" HTLC-timeout transaction. With `option_anchor_outputs" there is no
>>>>>>> unconfirmed ancestor to replace, as the commitment transaction, whatever
>>>>>>> the party it is originating from, should already be confirmed.
>>>>>>>
>>>>>>> > "Is this a privacy issue, i.e. doesn't it allow fingerprinting LN
>>>>>>> transactions based on nVersion?"
>>>>>>>
>>>>>>> As of today, I think yes you can already fingerprint LN transactions
>>>>>>> on the  spec-defined amount value of the anchor outputs, 330 sats. There is
>>>>>>> always one of them on post-anchor commitment transactions. And sadly I
>>>>>>> would say we'll always have tricky fingerprints leaking from unilateral LN
>>>>>>> closures such as HTLC/PTLC timelocks...
>>>>>>>
>>>>>>> > "Can a V2 transaction replace a V3 transaction and vice versa?"
>>>>>>>
>>>>>>> IIUC, a V3 package could replace a V2 package, with the benefit of
>>>>>>> the new package RBF rules applied. I think this would be a significant
>>>>>>> advantage for LN, as for the current ~85k of opened channels, the old V2
>>>>>>> states shouldn't be pinning vectors. Currently, commitment transactions
>>>>>>> signal replaceability.
>>>>>>>
>>>>>>> Le ven. 23 sept. 2022 ? 11:26, Gloria Zhao via bitcoin-dev <
>>>>>>> bitcoin-dev at lists.linuxfoundation.org> a ?crit :
>>>>>>>
>>>>>>>> Hi everyone,
>>>>>>>>
>>>>>>>> I'm writing to propose a very simple set of mempool/transaction
>>>>>>>> relay
>>>>>>>> policies intended to aid L2/contract protocols. I realized that
>>>>>>>> the previously proposed Package Mempool Accept package RBF [1]
>>>>>>>> had a few remaining problems after digging into the RBF logic more
>>>>>>>> [2].
>>>>>>>> This additional set of policies solves them without requiring a
>>>>>>>> huge RBF overhaul.
>>>>>>>>
>>>>>>>> I've written an implementation (and docs) for Bitcoin Core:
>>>>>>>> https://github.com/bitcoin/bitcoin/pull/25038
>>>>>>>>
>>>>>>>> (You may notice that this proposal incorporates feedback on the PR
>>>>>>>> - thanks Suhas Daftuar, Gregory Sanders, Bastien Teinturier, Anthony Towns,
>>>>>>>> and others.)
>>>>>>>>
>>>>>>>> If you are interested in using package RBF/relay to bump presigned
>>>>>>>> transactions, I think you may be interested in reviewing this
>>>>>>>> proposal.
>>>>>>>> This should solve Rule 3 pinning and perhaps allow us
>>>>>>>> to get rid of CPFP carve-out (yay!). I'm keen to hear if people find
>>>>>>>> the 1-anchor-output, 1000vB child limit too restrictive. Also, if
>>>>>>>> you find a
>>>>>>>> pinning attack or something that makes it unusable for you, I would
>>>>>>>> really really like to know.
>>>>>>>>
>>>>>>>> Note that transactions with nVersion=3 ("V3 transactions") are
>>>>>>>> currently non-standard in Bitcoin Core. That means **anything that
>>>>>>>> was
>>>>>>>> standard before this policy change would still be standard
>>>>>>>> afterwards.** If you don't want your transactions to be subject to
>>>>>>>> these rules, just continue whatever you're doing and don't use
>>>>>>>> nVersion=3. AFAICT this shouldn't break anything, but let me know if
>>>>>>>> this would be disruptive for you?
>>>>>>>>
>>>>>>>> **New Policies:**
>>>>>>>>
>>>>>>>> This includes:
>>>>>>>> - a set of additional policy rules applying to V3 transactions
>>>>>>>> - modifications to package RBF rules
>>>>>>>>
>>>>>>>> **V3 transactions:**
>>>>>>>>
>>>>>>>> Existing standardness rules apply to V3 (e.g. min/max tx weight,
>>>>>>>> standard output types, cleanstack, etc.). The following additional
>>>>>>>> rules apply to V3:
>>>>>>>>
>>>>>>>> 1. A V3 transaction can be replaced, even if it does not signal
>>>>>>>> BIP125
>>>>>>>>    replaceability. (It must also meet the other RBF rules around
>>>>>>>> fees,
>>>>>>>> etc. for replacement to happen).
>>>>>>>>
>>>>>>>> 2. Any descendant of an unconfirmed V3 transaction must also be V3.
>>>>>>>>
>>>>>>>> *Rationale*: Combined with Rule 1, this gives us the property of
>>>>>>>> "inherited" replaceability signaling when descendants of unconfirmed
>>>>>>>> transactions are created. Additionally, checking whether a
>>>>>>>> transaction
>>>>>>>> signals replaceability this way does not require mempool traversal,
>>>>>>>> and does not change based on what transactions are mined. It also
>>>>>>>> makes subsequent rules about descendant limits much easier to check.
>>>>>>>>
>>>>>>>> *Note*: The descendant of a *confirmed* V3 transaction does not
>>>>>>>> need to be V3.
>>>>>>>>
>>>>>>>> 3. An unconfirmed V3 transaction cannot have more than 1 descendant.
>>>>>>>>
>>>>>>>> *Rationale*: (Upper bound) the larger the descendant limit, the more
>>>>>>>> transactions may need to be replaced. This is a problematic pinning
>>>>>>>> attack, i.e., a malicious counterparty prevents the transaction from
>>>>>>>> being replaced by adding many descendant transactions that aren't
>>>>>>>> fee-bumping.
>>>>>>>>
>>>>>>>> (Lower bound) at least 1 descendant is required to allow CPFP of the
>>>>>>>> presigned transaction. The contract protocol can create presigned
>>>>>>>> transactions paying 0 fees and 1 output for attaching a CPFP at
>>>>>>>> broadcast time ("anchor output"). Without package RBF, multiple
>>>>>>>> anchor
>>>>>>>> outputs would be required to allow each counterparty to fee-bump any
>>>>>>>> presigned transaction. With package RBF, since the presigned
>>>>>>>> transactions can replace each other, 1 anchor output is sufficient.
>>>>>>>>
>>>>>>>> 4. A V3 transaction that has an unconfirmed V3 ancestor cannot be
>>>>>>>>    larger than 1000 virtual bytes.
>>>>>>>>
>>>>>>>> *Rationale*: (Upper bound) the larger the descendant size limit, the
>>>>>>>> more vbytes may need to be replaced. With default limits, if the
>>>>>>>> child
>>>>>>>> is e.g. 100,000vB, that might be an additional 100,000sats (at
>>>>>>>> 1sat/vbyte) or more, depending on the feerate.
>>>>>>>>
>>>>>>>> (Lower bound) the smaller this limit, the fewer UTXOs a child may
>>>>>>>> use
>>>>>>>> to fund this fee-bump. For example, only allowing the V3 child to
>>>>>>>> have
>>>>>>>> 2 inputs would require L2 protocols to manage a wallet with
>>>>>>>> high-value
>>>>>>>> UTXOs and make batched fee-bumping impossible. However, as the
>>>>>>>> fee-bumping child only needs to fund fees (as opposed to payments),
>>>>>>>> just a few UTXOs should suffice.
>>>>>>>>
>>>>>>>> With a limit of 1000 virtual bytes, depending on the output types,
>>>>>>>> the
>>>>>>>> child can have 6-15 UTXOs, which should be enough to fund a fee-bump
>>>>>>>> without requiring a carefully-managed UTXO pool. With 1000 virtual
>>>>>>>> bytes as the descendant limit, the cost to replace a V3 transaction
>>>>>>>> has much lower variance.
>>>>>>>>
>>>>>>>> *Rationale*: This makes the rule very easily "tacked on" to existing
>>>>>>>> logic for policy and wallets. A transaction may be up to 100KvB on
>>>>>>>> its
>>>>>>>> own (`MAX_STANDARD_TX_WEIGHT`) and 101KvB with descendants
>>>>>>>> (`DEFAULT_DESCENDANT_SIZE_LIMIT_KVB`). If an existing V3 transaction
>>>>>>>> in the mempool is 100KvB, its descendant can only be 1000vB, even if
>>>>>>>> the policy is 10KvB.
>>>>>>>>
>>>>>>>> **Package RBF modifications:**
>>>>>>>>
>>>>>>>> 1. The rule around unconfirmed inputs was
>>>>>>>> originally "A package may include new unconfirmed inputs, but the
>>>>>>>> ancestor feerate of the child must be at least as high as the
>>>>>>>> ancestor
>>>>>>>> feerates of every transaction being replaced."
>>>>>>>>
>>>>>>>> The package may still include new unconfirmed inputs. However,
>>>>>>>> the new rule is modified to be "The minimum between package feerate
>>>>>>>> and ancestor feerate of the child is not lower than the individual
>>>>>>>> feerates of all directly conflicting transactions and the ancestor
>>>>>>>> feerates of all original transactions."
>>>>>>>>
>>>>>>>> *Rationale*: We are attempting to ensure that the replacement
>>>>>>>> transactions are not less incentive-compatible to mine. However, a
>>>>>>>> package/transaction's ancestor feerate is not perfectly
>>>>>>>> representative
>>>>>>>> of its incentive compatibility; it may overestimate (some subset of
>>>>>>>> the ancestors could be included by itself if it has other
>>>>>>>> high-feerate
>>>>>>>> descendants or are themselves higher feerate than this
>>>>>>>> package/transaction). Instead, we use the minimum between the
>>>>>>>> package
>>>>>>>> feerate and ancestor feerate of the child as a more conservative
>>>>>>>> value
>>>>>>>> than what was proposed originally.
>>>>>>>>
>>>>>>>> 2. A new rule is added, requiring that all package transactions with
>>>>>>>> mempool conflicts to be V3. This also means the "sponsoring"
>>>>>>>> child transaction must be V3.
>>>>>>>>
>>>>>>>> *Note*: Combined with the V3 rules, this means the package must be
>>>>>>>> a child-with-parents package. Since package validation is only
>>>>>>>> attempted if the transactions do not pay sufficient fees to be
>>>>>>>> accepted on their own, this effectively means that only V3
>>>>>>>> transactions can pay to replace their ancestors' conflicts, and only
>>>>>>>> V3 transactions' replacements may be paid for by a descendant.
>>>>>>>>
>>>>>>>> *Rationale*: The fee-related rules are economically rational for
>>>>>>>> ancestor packages, but not necessarily other types of packages.
>>>>>>>> A child-with-parents package is a type of ancestor package. It
>>>>>>>> may be fine to allow any ancestor package, but it's more difficult
>>>>>>>> to account for all of the possibilities. For example, it gets much
>>>>>>>> harder to see that we're applying the descendant limits correctly if
>>>>>>>> the package has a gnarly, many-generation, non-tree shape. I'm also
>>>>>>>> not sure if this policy is 100% incentive-compatible if the sponsor
>>>>>>>> is not a direct descendant of the sponsee.
>>>>>>>>
>>>>>>>> Please see doc/policy/version3_transactions.md and
>>>>>>>> doc/policy/packages.md in the PR for the full set of rules.
>>>>>>>>
>>>>>>>> **Intended usage for LN:**
>>>>>>>>
>>>>>>>> Commitment transactions should be V3 and have 1 anchor output. They
>>>>>>>> can be signed with 0 fees (or 1sat/vbyte) once package relay is
>>>>>>>> deployed
>>>>>>>> on a significant portion of the network. If the commitment tx must
>>>>>>>> be broadcast, determine the desired feerate at broadcast time and
>>>>>>>> spend the anchor output in a high feerate transaction. I'm going to
>>>>>>>> call the broadcasted commitment tx "the parent" and the attached
>>>>>>>> fee-bumping tx "the child."
>>>>>>>>
>>>>>>>> - This child must be V3.
>>>>>>>> - This child must be at most 1000vB. Note this restricts the
>>>>>>>>   number of inputs you can use to fund the fee bump. Depending
>>>>>>>> on the output types, this is around 6-15.
>>>>>>>> - One child may fund fees for multiple commitment tx ("batched
>>>>>>>>   fee-bumping").
>>>>>>>> - To do a second fee-bump to add more fees, replace the
>>>>>>>>   *child* with a higher-feerate tx. Do not try to attach a
>>>>>>>> grandchild.
>>>>>>>>
>>>>>>>> Otherwise, never try to spend from an unconfirmed V3 transaction.
>>>>>>>> The
>>>>>>>> descendant limits for V3 transactions are very restrictive.
>>>>>>>>
>>>>>>>> **Expected Questions:**
>>>>>>>>
>>>>>>>> "Does this fix Rule 3 Pinning?"
>>>>>>>> Yes. The V3 descendant limit restricts both you and your
>>>>>>>> counterparty.
>>>>>>>> Assuming nodes adopted this policy, you may reasonably assume that
>>>>>>>> you
>>>>>>>> only need to replace the commitment transaction + up to 1000vB.
>>>>>>>>
>>>>>>>> "Only 1 anchor output? What if I need to bump counterparty's
>>>>>>>> commitment tx in mempool?"
>>>>>>>> You won't need to fee-bump a counterparty's commitment tx using
>>>>>>>> CPFP.
>>>>>>>> You would just package RBF it by attaching a high-feerate child to
>>>>>>>> your commitment tx.
>>>>>>>>
>>>>>>>> "Is this a privacy issue, i.e. doesn't it allow fingerprinting LN
>>>>>>>> transactions based on nVersion?"
>>>>>>>> Indeed it may be unrealistic to assume V3 transactions will be in
>>>>>>>> widespread use outside of L2. IIUC, unilateral closes are already
>>>>>>>> obvious LN transactions because of the HTLC inputs. For e.g.
>>>>>>>> cooperative closes and opens, I think it makes sense to continue
>>>>>>>> using
>>>>>>>> V2. So, unless I'm missing something, this shouldn't make it worse.
>>>>>>>>
>>>>>>>> "So a V3 transaction that doesn't signal BIP125 replaceability is
>>>>>>>> replaceable? Is that a backward compatibility issue?"
>>>>>>>> Yes it's replaceable. It's not an issue AFAICT because,
>>>>>>>> under previous policy, the V3 transaction wouldn't have been
>>>>>>>> in the mempool in the first place.
>>>>>>>>
>>>>>>>> "Can a V2 transaction replace a V3 transaction and vice versa?"
>>>>>>>> Yes, otherwise someone can use V3 transactions to censor V2
>>>>>>>> transactions spending shared inputs. Note if the
>>>>>>>> original V3 transaction has an unconfirmed V3 parent, this would
>>>>>>>> violate the "inherited V3" rule and would be rejected.
>>>>>>>>
>>>>>>>> Thanks for reading! Feedback and review would be much appreciated.
>>>>>>>>
>>>>>>>> [1]:
>>>>>>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019464.html
>>>>>>>> [2]:
>>>>>>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019817.html
>>>>>>>>
>>>>>>>> Best,
>>>>>>>> Gloria
>>>>>>>> _______________________________________________
>>>>>>>> bitcoin-dev mailing list
>>>>>>>> bitcoin-dev at lists.linuxfoundation.org
>>>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> bitcoin-dev mailing list
>>>>>>> bitcoin-dev at lists.linuxfoundation.org
>>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>>>>>
>>>>>> _______________________________________________
>>>>>> bitcoin-dev mailing list
>>>>>> bitcoin-dev at lists.linuxfoundation.org
>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>>>>
>>>>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220930/2a6057da/attachment-0001.html>

From gsanders87 at gmail.com  Fri Sep 30 12:17:38 2022
From: gsanders87 at gmail.com (Greg Sanders)
Date: Fri, 30 Sep 2022 08:17:38 -0400
Subject: [bitcoin-dev] New transaction policies (nVersion=3) for
 contracting protocols
In-Reply-To: <CACdvm3MTSVDOSLmpDTzs6Gj1Oz-9rDgPKY=ipMdV9iJzQhE-ew@mail.gmail.com>
References: <CAFXO6=KDys2_dsrdxE9_q_MVZJOFMbg-MctxiokcicP=wd4Lkw@mail.gmail.com>
 <CALZpt+HYUti=foo+d5ER7Wj=PxsfgaU2CEqqG4_KRxmsWoaSxw@mail.gmail.com>
 <CACdvm3PyP9yrxx_Yewtx_yQh=i2uwGYj-wtY7HBER1bmG46NEw@mail.gmail.com>
 <CAB3F3Du=+YYKbfgB5LZPnCg40=5YCn_0tkpJ4LO9bMK0U-3wXg@mail.gmail.com>
 <CAFXO6=JGBPVpxTJnSMWCCZVPHZW_RyWQ2Cv18Ao_F=uQx3LVkg@mail.gmail.com>
 <CACdvm3OUpODbMzkcG+=qYzR9myrvSp-LpuGmETow94JavU2GDw@mail.gmail.com>
 <CAB3F3DvCw9Ms+HUMaFnqV0P-Oo+rfERY+j5S5CC_X2NKRd5u8g@mail.gmail.com>
 <CAPv7TjYM34qk5bGheMZhopotuCwxYyHmWAXcawA5UHQpQWiGCg@mail.gmail.com>
 <CACdvm3MTSVDOSLmpDTzs6Gj1Oz-9rDgPKY=ipMdV9iJzQhE-ew@mail.gmail.com>
Message-ID: <CAB3F3Dtx58n1U0sK4ev6UwSqLJ8nn=wgJJE8V6YrWt4yeZ_4Yw@mail.gmail.com>

It's likely better if the ephemeral output can be any value, including
dust. This lets contract designers put "trimmed output" value indirectly
towards CPFP fees without making the parent tx have fees itself.

On Fri, Sep 30, 2022, 8:08 AM Bastien TEINTURIER <bastien at acinq.fr> wrote:

> Hey Ruben,
>
> I discussed this further over IRC, and I now agree that this particular
> change would be very desirable and can likely fit in the initial release
> (even though I'm not the one writing that code, but I'd be happy to
> review it and test it).
>
> Greg already has a draft design that addresses your concerns: if there is
> an "ephemeral output" (0-value, OP_TRUE) in an unconfirmed v3 transaction,
> it MUST be spent by any child v3 transaction. This way, you ensure that
> any child transaction spending the unconfirmed parent spends the ephemeral
> output(s). @Greg, correct me if I misunderstood something here. Note that
> we will need to precisely define the criteria for those "ephemeral outputs"
> (it can probably simply be "outputs that are 0 sats").
>
> Coupled with transactions that pay no fees (and thus require a child to
> CPFP in order to be included in a block), this ensures those outputs can
> never leak into the utxo set. How does that sound?
>
> I'm curious why you would need more than one such output, can you detail?
> I believe we only ever need one, spendable by anyone.
>
> Cheers,
> Bastien
>
> Le ven. 30 sept. 2022 ? 02:14, Ruben Somsen <rsomsen at gmail.com> a ?crit :
>
>> Hi Bastien,
>>
>> >The other change mentioned (making OP_TRUE standard and allowing outputs
>> that are below dust) can be added later, as those won't be standard until
>> we start allowing them, so there shouldn't be any backwards-compatibility
>> issue with postponing this change. But maybe it's still worth having from
>> the get-go, even though it may take a bit more time? Again, I'm curious to
>> have other people's opinion here
>>
>> I'm sensitive to not wanting to overload the current discussion but this
>> also interests me, provided it can be done in a way that is acceptable
>> (i.e. minimizing the potential UTXO set impact). It would solve a big cost
>> issue in my spacechains design if transactions could be 0 fees and have a 0
>> sat output that could be used in order to pay all the fees with CPFP.
>>
>> My current view is that a tx containing a single 0 sat OP_TRUE output
>> should only get relayed if it is a package where the OP_TRUE output is
>> currently being spent in a way that increases the overall fee rate. But
>> even then, one theoretical edge case remains:
>> - Another CPFP tx can feebump the package on a different (non-OP_TRUE)
>> output with an even higher fee rate
>> - Subsequently, the tx that is spending the OP_TRUE might fall out of the
>> mempool if the mempool fee rate rises
>> - This could cause the 0 sat output to enter the UTXO set (specifically,
>> rational miners wouldn't refuse to mine such a tx)
>>
>> It doesn't seem like this would happen much in practice (nor is there an
>> incentive to do it on purpose), but the chance isn't 0.
>>
>> Cheers,
>> Ruben
>>
>>
>>
>> On Thu, Sep 29, 2022 at 4:50 PM Greg Sanders via bitcoin-dev <
>> bitcoin-dev at lists.linuxfoundation.org> wrote:
>>
>>> > Right, good catch, this does require new logic to handle this case.
>>> As Gloria points out, this should be doable, and is definitely worth
>>> adding (those CSV 1 on every other output are really hacky, glad to
>>> find a way to get rid of them).
>>>
>>> For the record, it turns out ephemeral anchors + v3 solves this already,
>>> as the anchor must be spent, and the parent tx may only have one child.
>>> Somehow I missed this implication for a few months. It's great news if we
>>> can directly source fees from any output claimable, including HTLCs!
>>>
>>> On Thu, Sep 29, 2022 at 5:15 AM Bastien TEINTURIER <bastien at acinq.fr>
>>> wrote:
>>>
>>>> Hi Gloria, Greg,
>>>>
>>>> > I interpret most of the discussion around limitations as ideas for
>>>> > future improvements rather than criticisms of the proposal
>>>>
>>>> As far as I'm concerned, definitely!
>>>>
>>>> My current understanding is that the main change/improvement that would
>>>> make sense here is restricting the whole v3 package's size (instead of
>>>> just the child) via committing to a specific value in the taproot annex
>>>> (also note that it's probably not just the v3 package's size, it should
>>>> be the whole unconfirmed package including potential v2 unconfirmed
>>>> ancestors).
>>>>
>>>> While I think this would be very valuable and would like to see this
>>>> happen, I believe that can be done in a second, separate step since this
>>>> would make relay policy stricter (some v3 transactions that previously
>>>> propagated wouldn't propagate under this new rule). As long as you are
>>>> able to find a path to miners through upgraded peers that use this annex
>>>> approach, you should be able to resolve ACP pinning issues?
>>>>
>>>> I'm curious to know how other people feel about that: is it ok to do
>>>> later or should we try to implement this for the first release of v3
>>>> transactions?
>>>>
>>>> The other change mentioned (making OP_TRUE standard and allowing outputs
>>>> that are below dust) can be added later, as those won't be standard
>>>> until
>>>> we start allowing them, so there shouldn't be any
>>>> backwards-compatibility
>>>> issue with postponing this change. But maybe it's still worth having
>>>> from
>>>> the get-go, even though it may take a bit more time? Again, I'm curious
>>>> to
>>>> have other people's opinion here, I'd be happy to get all of those
>>>> directly
>>>> in the first release of v3 transactions, but I don't know how much
>>>> implementation will have to go into that.
>>>>
>>>> > For clarification, package RBF is ParentTx*s*(plural), and
>>>> ChildTx(singular),
>>>> > so it might be a bit more complicated than we're thinking
>>>>
>>>> Right, good catch, this does require new logic to handle this case.
>>>> As Gloria points out, this should be doable, and is definitely worth
>>>> adding (those CSV 1 on every other output are really hacky, glad to
>>>> find a way to get rid of them).
>>>>
>>>> Thanks,
>>>> Bastien
>>>>
>>>> Le lun. 26 sept. 2022 ? 18:48, Gloria Zhao <gloriajzhao at gmail.com> a
>>>> ?crit :
>>>>
>>>>> Hi Greg, Antoine, Bastien,
>>>>>
>>>>> Thanks very much for the feedback! I interpret most of the discussion
>>>>> around limitations as ideas for future improvements rather than criticisms
>>>>> of the proposal (please correct me if I'm wrong). I'll try to respond to as
>>>>> much as possible.
>>>>>
>>>>> Also I realize that I didn't contextualize this proposal clearly
>>>>> enough; it is very tailored for LN Penalty and definitely doesn't close all
>>>>> pinning attacks possible (sorry for confusing anyone). I also agree that
>>>>> some bits can be a little ugly or tack-on; I would definitely prefer a
>>>>> comprehensive RBF revamp to fix all our problems and enable other
>>>>> fee-bumping strategies such as
>>>>> sign-ANYONECANPAY-then-bring-your-own-fees-by-adding-inputs-at-broadcast. I
>>>>> was hoping to get some ideas with the "RBF Improvements" post in January,
>>>>> but it doesn't seem like we're much closer to a workable proposal. I think
>>>>> this is a minimally-invasive step that works for Lightning today, a small
>>>>> fix similar to CPFP carve out.
>>>>>
>>>>> > As you likely know from previous discussions the biggest scenario
>>>>> this does not fix in my estimation is ANYONECANPAY situations. If the
>>>>> parent transaction can be "inflated" by tacking on additional inputs, this
>>>>> means the total weight of the parent tx lowers the effective feerate of the
>>>>> package.
>>>>>
>>>>> (For more context to other readers I wrote an explanation for this in
>>>>> "SIGHASH_ANYONECANPAY Pinning" section of RBF ML post).  Yes, this
>>>>> unfortunately doesn't fix any of the existing pinning attacks for single
>>>>> transaction RBF but also doesn't make them worse. This boils down to adding
>>>>> an incentive compatibility rule that ensures you can't replace a
>>>>> transaction with something that will confirm slower. Package RBF has an
>>>>> ancestor feerate-based rule for this (note it is quite conservative and not
>>>>> perfect).
>>>>>
>>>>> So in the scenario above with the "inflated" parent that was signed
>>>>> ACP, the replacement would be rejected because the package ancestor feerate
>>>>> is lower than the feerate of what is being replaced. But it is imperfect
>>>>> (explained below) and thus I wouldn't recommend it for single transaction
>>>>> replacement. So that attack still exists for single transactions, yes.
>>>>>
>>>>> The strategy of using ACP to bring-your-own-fees has its own
>>>>> challenges but hopefully has no current use cases as you say. AFAIK LN
>>>>> Penalty is not affected by this since it doesn't use ACP, though obviously
>>>>> I agree we should fix it for the future.
>>>>>
>>>>> So when I said "this is intended for fee-bumping presigned txns in
>>>>> contracting protocols," I should have said "this is intended for
>>>>> fee-bumping presigned txns specifically using CPFP and anchor outputs."
>>>>> Apologies for forgetting to contextualize, I've been sitting on this for
>>>>> too long.
>>>>>
>>>>> > The other scenario it doesn't really fix is where
>>>>> HTLC/commitment-like transactions are being resolved in a batch, but due to
>>>>> relative time constraints, you may want to accelerate some and not others.
>>>>> Now you must pay higher rates to replace all of the transaction bumps. This
>>>>> is a "self-pin" and "get good at utxos noob" type problem, but it's
>>>>> something that axing rule#3 in favor of a Replace-by-ancestor-feerate
>>>>> system would get us.
>>>>>
>>>>> I understand you to mean "if you don't have enough UTXOs and you're
>>>>> forced to batch-bump, you over-pay because you need to bring them all to
>>>>> the highest target feerate." Isn't this kind of separate, wallet-related
>>>>> problem? Contracting or not, surely every wallet needs to have enough UTXOs
>>>>> to not batch transactions that shouldn't be batched... I don't see how a
>>>>> replace-by-ancestor-feerate policy would make any difference for this?
>>>>>
>>>>> Also in general I'd like to reiterate that ancestor feerate is not a
>>>>> panacea to all our RBF incentive compatibility concerns. Like individual
>>>>> feerate, unless we run the mining algorithm, it cannot tell us exactly how
>>>>> quickly this transaction would be mined.
>>>>>
>>>>> We're estimating the incentive compatibility of the original
>>>>> transaction(s) and replacement transaction(s), with the goal of not letting
>>>>> a transaction replace something that would have been more incentive
>>>>> compatible to mine. As such, we don't want to overestimate how good the
>>>>> replacement is, and we don't want to underestimate how good the original
>>>>> transactions are. This rule "The minimum between package feerate and
>>>>> ancestor feerate of the child is not lower than the individual feerates of
>>>>> all directly conflicting transactions and the ancestor feerates of all
>>>>> original transactions" is a conservative estimate.
>>>>>
>>>>> > Would kind of be nice if package RBF would detect a "sibling output
>>>>> spend" conflict, and knock it out of the mempool via the other replacement
>>>>> rules? Getting rid of the requirement to 1 block csv lock every output
>>>>> would be quite nice from a smart contracting composability point of view.
>>>>>
>>>>> Interesting, so when a transaction hits a mempool tx's descendant
>>>>> limit, we consider evicting one of its descendants in favor of this
>>>>> transaction, based on the RBF rules.
>>>>> Cool idea! After chewing on this for a bit, I think this *also* just
>>>>> boils down to the fact that RBF should require replacements to be better
>>>>> mining candidates. As in, if we added this policy and it can make us evict
>>>>> the sibling and accept a transaction with a bunch of low-feerate ancestor
>>>>> junk, it would be a new pinning vector.
>>>>>
>>>>> > If you're a miner and you receive a non-V3, second descendant of an
>>>>> unconfirmed V3 transaction, if the offered fee is in the top mempool
>>>>> backlog, I think you would have an interest to accept such a transaction.
>>>>>
>>>>> > So I'm not sure if those two rules are compatible with miners
>>>>> incentives...
>>>>>
>>>>> The same argument can be made for the 26th descendant of a mempool
>>>>> transaction; it's also not entirely incentive-compatible to reject it, but
>>>>> that is not the *only* design goal in mempool policy. Of course, the
>>>>> difference here is that the 25-descendant limit rule is a sensible DoS
>>>>> protection, while this 1-descendant limit rule is more of a "help the
>>>>> Bitcoin ecosystem" policy, just like CPFP carve-out, dust limit, etc. I can
>>>>> of course understand why not everyone would be in favor of this, but I do
>>>>> think it's worth it.
>>>>>
>>>>> > > 4. A V3 transaction that has an unconfirmed V3 ancestor cannot be
>>>>>
>>>>> > >    larger than 1000 virtual bytes.
>>>>>
>>>>> > If I understand correctly the 1000 vb upper bound rational, it would
>>>>> be to constraint the pinning counterparty to attach a high fee to a child
>>>>> due to the limited size, if they would like this transaction to be stuck in
>>>>> the network mempools. By doing so  this child has high odds to confirm.
>>>>>
>>>>> Yeah exactly, the "Rule 3 pin" is done by adding a child that's
>>>>> high-fee (so you have to pay that much to evict it). Because they *don't*
>>>>> want this tx to confirm, normally, this child would be really large. If
>>>>> they only have 1000vB for the child, they can't increase the replacement
>>>>> cost without also fee-bumping the transaction to make it confirm faster.
>>>>>
>>>>> > As of today, I think yes you can already fingerprint LN transactions
>>>>> on the  spec-defined amount value of the anchor outputs, 330 sats. There is
>>>>> always one of them on post-anchor commitment transactions. And sadly I
>>>>> would say we'll always have tricky fingerprints leaking from unilateral LN
>>>>> closures such as HTLC/PTLC timelocks...
>>>>>
>>>>> > I agree with you, this isn't worse than today, unilateral closes will
>>>>> probably always be identifiable on-chain.
>>>>>
>>>>> Great to hear that there is no privacy worsening!
>>>>>
>>>>> Best,
>>>>> Gloria
>>>>>
>>>>> On Mon, Sep 26, 2022 at 5:02 PM Greg Sanders <gsanders87 at gmail.com>
>>>>> wrote:
>>>>>
>>>>>> Bastien,
>>>>>>
>>>>>> > This may be already covered by the current package RBF logic, in
>>>>>> that
>>>>>> scenario we are simply replacing [ParentTx, ChildTx1] with
>>>>>> [ParentTx, ChildTx2] that pays more fees, right?
>>>>>>
>>>>>> For clarification, package RBF is ParentTx*s*(plural), and
>>>>>> ChildTx(singular), so it might be a bit more complicated than we're
>>>>>> thinking, and currently the V3 proposal would first de-duplicate the
>>>>>> ParentTx based on what is in the mempool, then look at the "rest" of the
>>>>>> transactions as a package, then individually. Not the same, not sure how
>>>>>> different. I'll defer to experts.
>>>>>>
>>>>>> Best,
>>>>>> Greg
>>>>>>
>>>>>> On Mon, Sep 26, 2022 at 11:48 AM Bastien TEINTURIER via bitcoin-dev <
>>>>>> bitcoin-dev at lists.linuxfoundation.org> wrote:
>>>>>>
>>>>>>> Thanks Gloria for this great post.
>>>>>>>
>>>>>>> This is very valuable work for L2 contracts, and will greatly improve
>>>>>>> their security model.
>>>>>>>
>>>>>>> > "Only 1 anchor output? What if I need to bump counterparty's
>>>>>>> commitment tx in mempool?"
>>>>>>> > You won't need to fee-bump a counterparty's commitment tx using
>>>>>>> CPFP.
>>>>>>> > You would just package RBF it by attaching a high-feerate child to
>>>>>>> > your commitment tx.
>>>>>>>
>>>>>>> Note that we can also very easily make that single anchor spendable
>>>>>>> by
>>>>>>> both participants (or even anyone), so if you see your counterparty's
>>>>>>> commitment in your mempool, you can bump it without publishing your
>>>>>>> own commitment, which is quite desirable (your own commitment tx has
>>>>>>> CSV delays on your outputs, whereas your counterparty's commitment tx
>>>>>>> doesn't).
>>>>>>>
>>>>>>> > "Is this a privacy issue, i.e. doesn't it allow fingerprinting LN
>>>>>>> transactions based on nVersion?"
>>>>>>>
>>>>>>> I agree with you, this isn't worse than today, unilateral closes will
>>>>>>> probably always be identifiable on-chain.
>>>>>>>
>>>>>>> > Would kind of be nice if package RBF would detect a "sibling
>>>>>>> output spend"
>>>>>>> > conflict, and knock it out of the mempool via the other
>>>>>>> replacement rules?
>>>>>>> > Getting rid of the requirement to 1 block csv lock every output
>>>>>>> would be
>>>>>>> > quite nice from a smart contracting composability point of view.
>>>>>>>
>>>>>>> +1, that would be very neat!
>>>>>>>
>>>>>>> This may be already covered by the current package RBF logic, in that
>>>>>>> scenario we are simply replacing [ParentTx, ChildTx1] with
>>>>>>> [ParentTx, ChildTx2] that pays more fees, right?
>>>>>>>
>>>>>>> > 1) I do think that we should seriously consider allowing OP_TRUE
>>>>>>> to become
>>>>>>> > a standard script type as part of this policy update. If pinning
>>>>>>> is solved,
>>>>>>> > then there's no reason to require all those extra bytes for
>>>>>>> "binding" an
>>>>>>> > anchor to a specific wallet/user. We can save quite a few bytes by
>>>>>>> having
>>>>>>> > the input be empty of witness data.
>>>>>>> > 2) If we allow for a single dust-value(0 on up) output which is
>>>>>>> immediately
>>>>>>> > spent by the package, anchors become even easier to to design. No
>>>>>>> value has
>>>>>>> > to be "sapped" from contract participants to make an anchor
>>>>>>> output. There's
>>>>>>> > more complications for this, such as making sure the parent
>>>>>>> transaction is
>>>>>>> > dropped if the child spend is dropped, but maybe it's worth the
>>>>>>> squeeze.
>>>>>>>
>>>>>>> I also think both of these could be quite useful. This would
>>>>>>> probably always
>>>>>>> be used in combination with a parent transaction that pays 0 fees,
>>>>>>> so the
>>>>>>> 0-value output would always be spent in the same block.
>>>>>>>
>>>>>>> But this means we could end up with 0-value outputs in the utxo set,
>>>>>>> if for
>>>>>>> some reason the parent tx is CPFP-ed via another output than the
>>>>>>> 0-value one,
>>>>>>> which would be a utxo set bloat issue. But I'd argue that we're
>>>>>>> probably
>>>>>>> already creating utxo set bloat with the 330 sat anchor outputs
>>>>>>> (especially
>>>>>>> since we use two of them, but only one is usually spent), so it would
>>>>>>> probably be *better* than what we're doing today.
>>>>>>>
>>>>>>> Thanks,
>>>>>>> Bastien
>>>>>>>
>>>>>>> Le lun. 26 sept. 2022 ? 03:22, Antoine Riard via bitcoin-dev <
>>>>>>> bitcoin-dev at lists.linuxfoundation.org> a ?crit :
>>>>>>>
>>>>>>>> Hi Gloria,
>>>>>>>>
>>>>>>>> Thanks for the progress on package RBF, few early questions.
>>>>>>>>
>>>>>>>> > 2. Any descendant of an unconfirmed V3 transaction must also be
>>>>>>>> V3.
>>>>>>>>
>>>>>>>> > 3. An unconfirmed V3 transaction cannot have more than 1
>>>>>>>> descendant.
>>>>>>>>
>>>>>>>> If you're a miner and you receive a non-V3, second descendant of an
>>>>>>>> unconfirmed V3 transaction, if the offered fee is in the top mempool
>>>>>>>> backlog, I think you would have an interest to accept such a transaction.
>>>>>>>>
>>>>>>>> So I'm not sure if those two rules are compatible with miners
>>>>>>>> incentives...
>>>>>>>>
>>>>>>>> > 4. A V3 transaction that has an unconfirmed V3 ancestor cannot be
>>>>>>>> >    larger than 1000 virtual bytes.
>>>>>>>>
>>>>>>>> If I understand correctly the 1000 vb upper bound rational, it
>>>>>>>> would be to constraint the pinning counterparty to attach a high fee to a
>>>>>>>> child due to the limited size, if they would like this transaction to be
>>>>>>>> stuck in the network mempools. By doing so  this child has high odds to
>>>>>>>> confirm.
>>>>>>>>
>>>>>>>> I still wonder if this compatible with miner incentives in period
>>>>>>>> of empty mempools, in the sense that if you've already a V3 transaction of
>>>>>>>> size 100Kvb offering 2 sat/vb, it's more interesting than a V3 replacement
>>>>>>>> candidate of size 1000 vb offering 10 sat/vb. It could be argued the former
>>>>>>>> should be conserved.
>>>>>>>>
>>>>>>>> (That said, the hard thing with any replacement strategy we might
>>>>>>>> evict a parent transaction *now* to which is attached a high-feerate child
>>>>>>>> *latter* making for a utxo considered the best ancestor set. Maybe in the
>>>>>>>> long-term miners should keep every transaction ever accepted...)
>>>>>>>>
>>>>>>>> > (Lower bound) the smaller this limit, the fewer UTXOs a child may
>>>>>>>> use
>>>>>>>> > to fund this fee-bump. For example, only allowing the V3 child to
>>>>>>>> have
>>>>>>>> > 2 inputs would require L2 protocols to manage a wallet with
>>>>>>>> high-value
>>>>>>>> > UTXOs and make batched fee-bumping impossible. However, as the
>>>>>>>> > fee-bumping child only needs to fund fees (as opposed to
>>>>>>>> payments),
>>>>>>>> > just a few UTXOs should suffice.
>>>>>>>>
>>>>>>>> Reminder for L2 devs, batched fee-bumping of time-sensitive
>>>>>>>> confirmations of commitment transactions is unsafe, as the counterparty
>>>>>>>> could enter in a "cat-and-mouse" game to replace one of the batch element
>>>>>>>> at each block to delay confirmation of the remaining elements in the batch,
>>>>>>>> I think.
>>>>>>>>
>>>>>>>> On the other hand, I wonder if we wouldn't want a higher bound. LN
>>>>>>>> wallets are likely to have one big UTXO in their fee-bumping reserve pool,
>>>>>>>> as the cost of acquiring UTXO is non-null and in the optimistic case, you
>>>>>>>> don't need to do unilateral closure. Let's say you close dozens of channels
>>>>>>>> at the same time, a UTXO pool management strategy might be to fan-out the
>>>>>>>> first spends UTXOs in N fan-out outputs ready to feed the remaining
>>>>>>>> in-flight channels.
>>>>>>>>
>>>>>>>> > 1. The rule around unconfirmed inputs was
>>>>>>>> > originally "A package may include new unconfirmed inputs, but the
>>>>>>>> > ancestor feerate of the child must be at least as high as the
>>>>>>>> ancestor
>>>>>>>> > feerates of every transaction being replaced."
>>>>>>>>
>>>>>>>> Note, I think we would like this new RBF rule to also apply to
>>>>>>>> single transaction package, e.g second-stage HTLC transactions, where a
>>>>>>>> counterparty pins a HTLC-preimage by abusing rule 3. In that case, the
>>>>>>>> honest LN node should be able to broadcast a "at least as high ancestor
>>>>>>>> feerate" HTLC-timeout transaction. With `option_anchor_outputs" there is no
>>>>>>>> unconfirmed ancestor to replace, as the commitment transaction, whatever
>>>>>>>> the party it is originating from, should already be confirmed.
>>>>>>>>
>>>>>>>> > "Is this a privacy issue, i.e. doesn't it allow fingerprinting LN
>>>>>>>> transactions based on nVersion?"
>>>>>>>>
>>>>>>>> As of today, I think yes you can already fingerprint LN
>>>>>>>> transactions on the  spec-defined amount value of the anchor outputs, 330
>>>>>>>> sats. There is always one of them on post-anchor commitment transactions.
>>>>>>>> And sadly I would say we'll always have tricky fingerprints leaking from
>>>>>>>> unilateral LN closures such as HTLC/PTLC timelocks...
>>>>>>>>
>>>>>>>> > "Can a V2 transaction replace a V3 transaction and vice versa?"
>>>>>>>>
>>>>>>>> IIUC, a V3 package could replace a V2 package, with the benefit of
>>>>>>>> the new package RBF rules applied. I think this would be a significant
>>>>>>>> advantage for LN, as for the current ~85k of opened channels, the old V2
>>>>>>>> states shouldn't be pinning vectors. Currently, commitment transactions
>>>>>>>> signal replaceability.
>>>>>>>>
>>>>>>>> Le ven. 23 sept. 2022 ? 11:26, Gloria Zhao via bitcoin-dev <
>>>>>>>> bitcoin-dev at lists.linuxfoundation.org> a ?crit :
>>>>>>>>
>>>>>>>>> Hi everyone,
>>>>>>>>>
>>>>>>>>> I'm writing to propose a very simple set of mempool/transaction
>>>>>>>>> relay
>>>>>>>>> policies intended to aid L2/contract protocols. I realized that
>>>>>>>>> the previously proposed Package Mempool Accept package RBF [1]
>>>>>>>>> had a few remaining problems after digging into the RBF logic more
>>>>>>>>> [2].
>>>>>>>>> This additional set of policies solves them without requiring a
>>>>>>>>> huge RBF overhaul.
>>>>>>>>>
>>>>>>>>> I've written an implementation (and docs) for Bitcoin Core:
>>>>>>>>> https://github.com/bitcoin/bitcoin/pull/25038
>>>>>>>>>
>>>>>>>>> (You may notice that this proposal incorporates feedback on the PR
>>>>>>>>> - thanks Suhas Daftuar, Gregory Sanders, Bastien Teinturier, Anthony Towns,
>>>>>>>>> and others.)
>>>>>>>>>
>>>>>>>>> If you are interested in using package RBF/relay to bump presigned
>>>>>>>>> transactions, I think you may be interested in reviewing this
>>>>>>>>> proposal.
>>>>>>>>> This should solve Rule 3 pinning and perhaps allow us
>>>>>>>>> to get rid of CPFP carve-out (yay!). I'm keen to hear if people
>>>>>>>>> find
>>>>>>>>> the 1-anchor-output, 1000vB child limit too restrictive. Also, if
>>>>>>>>> you find a
>>>>>>>>> pinning attack or something that makes it unusable for you, I would
>>>>>>>>> really really like to know.
>>>>>>>>>
>>>>>>>>> Note that transactions with nVersion=3 ("V3 transactions") are
>>>>>>>>> currently non-standard in Bitcoin Core. That means **anything that
>>>>>>>>> was
>>>>>>>>> standard before this policy change would still be standard
>>>>>>>>> afterwards.** If you don't want your transactions to be subject to
>>>>>>>>> these rules, just continue whatever you're doing and don't use
>>>>>>>>> nVersion=3. AFAICT this shouldn't break anything, but let me know
>>>>>>>>> if
>>>>>>>>> this would be disruptive for you?
>>>>>>>>>
>>>>>>>>> **New Policies:**
>>>>>>>>>
>>>>>>>>> This includes:
>>>>>>>>> - a set of additional policy rules applying to V3 transactions
>>>>>>>>> - modifications to package RBF rules
>>>>>>>>>
>>>>>>>>> **V3 transactions:**
>>>>>>>>>
>>>>>>>>> Existing standardness rules apply to V3 (e.g. min/max tx weight,
>>>>>>>>> standard output types, cleanstack, etc.). The following additional
>>>>>>>>> rules apply to V3:
>>>>>>>>>
>>>>>>>>> 1. A V3 transaction can be replaced, even if it does not signal
>>>>>>>>> BIP125
>>>>>>>>>    replaceability. (It must also meet the other RBF rules around
>>>>>>>>> fees,
>>>>>>>>> etc. for replacement to happen).
>>>>>>>>>
>>>>>>>>> 2. Any descendant of an unconfirmed V3 transaction must also be V3.
>>>>>>>>>
>>>>>>>>> *Rationale*: Combined with Rule 1, this gives us the property of
>>>>>>>>> "inherited" replaceability signaling when descendants of
>>>>>>>>> unconfirmed
>>>>>>>>> transactions are created. Additionally, checking whether a
>>>>>>>>> transaction
>>>>>>>>> signals replaceability this way does not require mempool traversal,
>>>>>>>>> and does not change based on what transactions are mined. It also
>>>>>>>>> makes subsequent rules about descendant limits much easier to
>>>>>>>>> check.
>>>>>>>>>
>>>>>>>>> *Note*: The descendant of a *confirmed* V3 transaction does not
>>>>>>>>> need to be V3.
>>>>>>>>>
>>>>>>>>> 3. An unconfirmed V3 transaction cannot have more than 1
>>>>>>>>> descendant.
>>>>>>>>>
>>>>>>>>> *Rationale*: (Upper bound) the larger the descendant limit, the
>>>>>>>>> more
>>>>>>>>> transactions may need to be replaced. This is a problematic pinning
>>>>>>>>> attack, i.e., a malicious counterparty prevents the transaction
>>>>>>>>> from
>>>>>>>>> being replaced by adding many descendant transactions that aren't
>>>>>>>>> fee-bumping.
>>>>>>>>>
>>>>>>>>> (Lower bound) at least 1 descendant is required to allow CPFP of
>>>>>>>>> the
>>>>>>>>> presigned transaction. The contract protocol can create presigned
>>>>>>>>> transactions paying 0 fees and 1 output for attaching a CPFP at
>>>>>>>>> broadcast time ("anchor output"). Without package RBF, multiple
>>>>>>>>> anchor
>>>>>>>>> outputs would be required to allow each counterparty to fee-bump
>>>>>>>>> any
>>>>>>>>> presigned transaction. With package RBF, since the presigned
>>>>>>>>> transactions can replace each other, 1 anchor output is sufficient.
>>>>>>>>>
>>>>>>>>> 4. A V3 transaction that has an unconfirmed V3 ancestor cannot be
>>>>>>>>>    larger than 1000 virtual bytes.
>>>>>>>>>
>>>>>>>>> *Rationale*: (Upper bound) the larger the descendant size limit,
>>>>>>>>> the
>>>>>>>>> more vbytes may need to be replaced. With default limits, if the
>>>>>>>>> child
>>>>>>>>> is e.g. 100,000vB, that might be an additional 100,000sats (at
>>>>>>>>> 1sat/vbyte) or more, depending on the feerate.
>>>>>>>>>
>>>>>>>>> (Lower bound) the smaller this limit, the fewer UTXOs a child may
>>>>>>>>> use
>>>>>>>>> to fund this fee-bump. For example, only allowing the V3 child to
>>>>>>>>> have
>>>>>>>>> 2 inputs would require L2 protocols to manage a wallet with
>>>>>>>>> high-value
>>>>>>>>> UTXOs and make batched fee-bumping impossible. However, as the
>>>>>>>>> fee-bumping child only needs to fund fees (as opposed to payments),
>>>>>>>>> just a few UTXOs should suffice.
>>>>>>>>>
>>>>>>>>> With a limit of 1000 virtual bytes, depending on the output types,
>>>>>>>>> the
>>>>>>>>> child can have 6-15 UTXOs, which should be enough to fund a
>>>>>>>>> fee-bump
>>>>>>>>> without requiring a carefully-managed UTXO pool. With 1000 virtual
>>>>>>>>> bytes as the descendant limit, the cost to replace a V3 transaction
>>>>>>>>> has much lower variance.
>>>>>>>>>
>>>>>>>>> *Rationale*: This makes the rule very easily "tacked on" to
>>>>>>>>> existing
>>>>>>>>> logic for policy and wallets. A transaction may be up to 100KvB on
>>>>>>>>> its
>>>>>>>>> own (`MAX_STANDARD_TX_WEIGHT`) and 101KvB with descendants
>>>>>>>>> (`DEFAULT_DESCENDANT_SIZE_LIMIT_KVB`). If an existing V3
>>>>>>>>> transaction
>>>>>>>>> in the mempool is 100KvB, its descendant can only be 1000vB, even
>>>>>>>>> if
>>>>>>>>> the policy is 10KvB.
>>>>>>>>>
>>>>>>>>> **Package RBF modifications:**
>>>>>>>>>
>>>>>>>>> 1. The rule around unconfirmed inputs was
>>>>>>>>> originally "A package may include new unconfirmed inputs, but the
>>>>>>>>> ancestor feerate of the child must be at least as high as the
>>>>>>>>> ancestor
>>>>>>>>> feerates of every transaction being replaced."
>>>>>>>>>
>>>>>>>>> The package may still include new unconfirmed inputs. However,
>>>>>>>>> the new rule is modified to be "The minimum between package feerate
>>>>>>>>> and ancestor feerate of the child is not lower than the individual
>>>>>>>>> feerates of all directly conflicting transactions and the ancestor
>>>>>>>>> feerates of all original transactions."
>>>>>>>>>
>>>>>>>>> *Rationale*: We are attempting to ensure that the replacement
>>>>>>>>> transactions are not less incentive-compatible to mine. However, a
>>>>>>>>> package/transaction's ancestor feerate is not perfectly
>>>>>>>>> representative
>>>>>>>>> of its incentive compatibility; it may overestimate (some subset of
>>>>>>>>> the ancestors could be included by itself if it has other
>>>>>>>>> high-feerate
>>>>>>>>> descendants or are themselves higher feerate than this
>>>>>>>>> package/transaction). Instead, we use the minimum between the
>>>>>>>>> package
>>>>>>>>> feerate and ancestor feerate of the child as a more conservative
>>>>>>>>> value
>>>>>>>>> than what was proposed originally.
>>>>>>>>>
>>>>>>>>> 2. A new rule is added, requiring that all package transactions
>>>>>>>>> with
>>>>>>>>> mempool conflicts to be V3. This also means the "sponsoring"
>>>>>>>>> child transaction must be V3.
>>>>>>>>>
>>>>>>>>> *Note*: Combined with the V3 rules, this means the package must be
>>>>>>>>> a child-with-parents package. Since package validation is only
>>>>>>>>> attempted if the transactions do not pay sufficient fees to be
>>>>>>>>> accepted on their own, this effectively means that only V3
>>>>>>>>> transactions can pay to replace their ancestors' conflicts, and
>>>>>>>>> only
>>>>>>>>> V3 transactions' replacements may be paid for by a descendant.
>>>>>>>>>
>>>>>>>>> *Rationale*: The fee-related rules are economically rational for
>>>>>>>>> ancestor packages, but not necessarily other types of packages.
>>>>>>>>> A child-with-parents package is a type of ancestor package. It
>>>>>>>>> may be fine to allow any ancestor package, but it's more difficult
>>>>>>>>> to account for all of the possibilities. For example, it gets much
>>>>>>>>> harder to see that we're applying the descendant limits correctly
>>>>>>>>> if
>>>>>>>>> the package has a gnarly, many-generation, non-tree shape. I'm also
>>>>>>>>> not sure if this policy is 100% incentive-compatible if the sponsor
>>>>>>>>> is not a direct descendant of the sponsee.
>>>>>>>>>
>>>>>>>>> Please see doc/policy/version3_transactions.md and
>>>>>>>>> doc/policy/packages.md in the PR for the full set of rules.
>>>>>>>>>
>>>>>>>>> **Intended usage for LN:**
>>>>>>>>>
>>>>>>>>> Commitment transactions should be V3 and have 1 anchor output. They
>>>>>>>>> can be signed with 0 fees (or 1sat/vbyte) once package relay is
>>>>>>>>> deployed
>>>>>>>>> on a significant portion of the network. If the commitment tx must
>>>>>>>>> be broadcast, determine the desired feerate at broadcast time and
>>>>>>>>> spend the anchor output in a high feerate transaction. I'm going to
>>>>>>>>> call the broadcasted commitment tx "the parent" and the attached
>>>>>>>>> fee-bumping tx "the child."
>>>>>>>>>
>>>>>>>>> - This child must be V3.
>>>>>>>>> - This child must be at most 1000vB. Note this restricts the
>>>>>>>>>   number of inputs you can use to fund the fee bump. Depending
>>>>>>>>> on the output types, this is around 6-15.
>>>>>>>>> - One child may fund fees for multiple commitment tx ("batched
>>>>>>>>>   fee-bumping").
>>>>>>>>> - To do a second fee-bump to add more fees, replace the
>>>>>>>>>   *child* with a higher-feerate tx. Do not try to attach a
>>>>>>>>> grandchild.
>>>>>>>>>
>>>>>>>>> Otherwise, never try to spend from an unconfirmed V3 transaction.
>>>>>>>>> The
>>>>>>>>> descendant limits for V3 transactions are very restrictive.
>>>>>>>>>
>>>>>>>>> **Expected Questions:**
>>>>>>>>>
>>>>>>>>> "Does this fix Rule 3 Pinning?"
>>>>>>>>> Yes. The V3 descendant limit restricts both you and your
>>>>>>>>> counterparty.
>>>>>>>>> Assuming nodes adopted this policy, you may reasonably assume that
>>>>>>>>> you
>>>>>>>>> only need to replace the commitment transaction + up to 1000vB.
>>>>>>>>>
>>>>>>>>> "Only 1 anchor output? What if I need to bump counterparty's
>>>>>>>>> commitment tx in mempool?"
>>>>>>>>> You won't need to fee-bump a counterparty's commitment tx using
>>>>>>>>> CPFP.
>>>>>>>>> You would just package RBF it by attaching a high-feerate child to
>>>>>>>>> your commitment tx.
>>>>>>>>>
>>>>>>>>> "Is this a privacy issue, i.e. doesn't it allow fingerprinting LN
>>>>>>>>> transactions based on nVersion?"
>>>>>>>>> Indeed it may be unrealistic to assume V3 transactions will be in
>>>>>>>>> widespread use outside of L2. IIUC, unilateral closes are already
>>>>>>>>> obvious LN transactions because of the HTLC inputs. For e.g.
>>>>>>>>> cooperative closes and opens, I think it makes sense to continue
>>>>>>>>> using
>>>>>>>>> V2. So, unless I'm missing something, this shouldn't make it worse.
>>>>>>>>>
>>>>>>>>> "So a V3 transaction that doesn't signal BIP125 replaceability is
>>>>>>>>> replaceable? Is that a backward compatibility issue?"
>>>>>>>>> Yes it's replaceable. It's not an issue AFAICT because,
>>>>>>>>> under previous policy, the V3 transaction wouldn't have been
>>>>>>>>> in the mempool in the first place.
>>>>>>>>>
>>>>>>>>> "Can a V2 transaction replace a V3 transaction and vice versa?"
>>>>>>>>> Yes, otherwise someone can use V3 transactions to censor V2
>>>>>>>>> transactions spending shared inputs. Note if the
>>>>>>>>> original V3 transaction has an unconfirmed V3 parent, this would
>>>>>>>>> violate the "inherited V3" rule and would be rejected.
>>>>>>>>>
>>>>>>>>> Thanks for reading! Feedback and review would be much appreciated.
>>>>>>>>>
>>>>>>>>> [1]:
>>>>>>>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019464.html
>>>>>>>>> [2]:
>>>>>>>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019817.html
>>>>>>>>>
>>>>>>>>> Best,
>>>>>>>>> Gloria
>>>>>>>>> _______________________________________________
>>>>>>>>> bitcoin-dev mailing list
>>>>>>>>> bitcoin-dev at lists.linuxfoundation.org
>>>>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>>>>>>>
>>>>>>>> _______________________________________________
>>>>>>>> bitcoin-dev mailing list
>>>>>>>> bitcoin-dev at lists.linuxfoundation.org
>>>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> bitcoin-dev mailing list
>>>>>>> bitcoin-dev at lists.linuxfoundation.org
>>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>>>>>
>>>>>> _______________________________________________
>>> bitcoin-dev mailing list
>>> bitcoin-dev at lists.linuxfoundation.org
>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220930/10024929/attachment-0001.html>

