From alfie at alfie.wtf  Sun Jan  1 12:42:50 2023
From: alfie at alfie.wtf (Alfie John)
Date: Sun, 1 Jan 2023 23:42:50 +1100
Subject: [bitcoin-dev] Pseudocode for robust tail emission
In-Reply-To: <Y690OjY0MA/YQ9IL@petertodd.org>
References: <173552838-a7412589a40ea770709d0b227b056bd3@pmq5v.m5r2.onet>
 <Y690OjY0MA/YQ9IL@petertodd.org>
Message-ID: <2480C772-EE75-4350-BF11-FA9FEFC8A4EA@alfie.wtf>

On 31 Dec 2022, at 10:28 am, Peter Todd via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
> 
>> This way:
>> 
>> 1. system cannot be played
>> 2. only in case of destructive halving: system waits for the recovery of network security
> 
> The immediate danger we have with halvings is that in a competitive market,
> profit margins tend towards marginal costs - the cost to produce an additional
> unit of production - rather than total costs - the cost necessary to recover
> prior and future expenses. Since the halving is a sudden shock to the system,
> under the right conditions we could have a significant amount of hashing power
> just barely able to afford to hash prior to the halving, resulting in all that
> hashing power immediately having to shut down and fees increasing dramatically,
> and likely, chaotically.  Your proposal does not address that problem as it can
> only measure difficulty prior to the halving point.


> ... Since the halving is a sudden shock to the system

Is it though? Since everyone knows of the possible outcomes, wouldn't a possible halving be priced in? 

> resulting in all that hashing power immediately having to shut down and fees increasing dramatically

Which should cause that hashing power to come back because of this fee increases.

Alfie

--
Alfie John
https://www.alfie <https://www.alfie/>.wtf
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230101/383bbd29/attachment.html>

From jk_14 at op.pl  Sun Jan  1 21:23:37 2023
From: jk_14 at op.pl (jk_14 at op.pl)
Date: Sun, 01 Jan 2023 22:23:37 +0100
Subject: [bitcoin-dev] Pseudocode for robust tail emission
Message-ID: <174623371-de649b28ce46dea2e588f2ef794decdb@pmq1v.m5r2.onet>

Yes, the idea is:
if mining activity is growing - let's execute consecutive halvings
but if miner exodus has happened - let's delay next halving until mining activity is recovered to previous levels
If it gets to the point where a sudden drop in mining difficulty happens - delaying the next halving may be not sufficient to correct, but is surely better than not delaying it.
While Bitcoin is better and better money with every halving in comparision to other types of money - there is non-zero risk that people will hoard it more and more, according to old Gresham's law ("HODL"). And this way decreasing liquidity / transactions volume. The positive feedback loop - is my real concern here.
Regarding the relationship between difficulty and security - I fully agree.
But ASIC technology is already matured. And also any technology breakthrough is a short event within 4 years period.
So growth of difficulty could be gained by technology breakthrough, but any sudden drop of difficulty would be always an issue, while there is no such thing as: ASIC technology regression.
Obviously, not complicated solution would be better than complicated one.
?
?
W dniu 2022-12-30 19:21:10 u?ytkownik Billy Tetrud <billy.tetrud at gmail.com> napisa?:
If the idea is to ensure that a catastrophic miner exodus doesn't happen, the "difference" you're calculating should only care about downward differences. Upward differences indicate more mining activity and so shouldn't cause a halving skip. ?
But I don't think any scheme like this that only acts on the basis of difficulty will be sufficient. If it gets to the point where a sudden drop in mining difficulty happens, it is very likely that simply delaying the next halving or even ending halving all together will not be sufficient to correct for whatever is causing hashrate to tank. There is also the danger of simple difficulty stagnation, which this mechanism wouldn't detect.?
?
The relationship between difficulty and security becomes less and less predictable the longer you want to look ahead. There's no long term relation between difficulty and any reasonable security target. A security target might be something like "no colluding group with less than $1 trillion dollars at their disposal could successfully 51% attack the network (with a probability of blah blah)". There is no way to today program in any code that detects based on difficult alone when that criteria is violated. You would have to program in assumptions about the cost of hashrate projected into the future.
?
I can't think of any robust automatic way to do this. I think to a certain degree, it will have to be a change that happens in a fork of some kind (soft or hard) periodically (every 10 years? 30 years?). The basic relations needed is really the cost in Bitcoin of the security target (ie the minimum number of Bitcoin it should take to 51% attack the system) and the cost in Bitcoin of acquiring a unit of hashrate. This could be simply input into the code, or could use some complicated oracle system. But with that relation, the system could be programmed to calculate the difficulty necessary to keep the system secure.
?
Once that is in place, the system could automatically adjust the subsidy up or down to attract more or less miners, or it could adjust the block size up or down to change the fee market such that more or less total fees are collected each block to attract more or less miners.?
On Tue, Dec 27, 2022, 09:41 Jaroslaw via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
It seems like the more elegant solution could be by using a chainwork parameter instead.
i.e. comparison just before halving - if the last 210,000 block interval has a higher chainwork difference between the begining and the end of interval
than any other such inter-halving interval before.
LIttle digression yet:
A system in which all users participate in ensuring its security looks better than one in which only some (i.e. active) of them participate (and passive stakeholders are de facto free riders)
In my opinion this concept above is only the complement of currently missing mechanism: achieving equilibrium regarding costs of security between two parties with opposing interests.
It's easy to understand and - most important - it has no hardcoded value of tail emission - what is the clear proof it is based on a free market.
And last but not least, if someone is 100% sure that income from transactions will takeover security support from block subsidy - accepting such proposal is like putting the money where the mouth is: this safety measure will never be triggered, then (no risk of fork)
Best Regards
Jaroslaw
W dniu 2022-12-23 20:29:20 u?ytkownik Jaroslaw via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> napisa?:
>
Necessary or not - it doesn't hurt to plan the robust model, just in case. The proposal is:
Let every 210,000 the code calculate the average difficulty of 100 last retargets (100 fit well in 210,000 / 2016 = 104.166)
and compare with the maximum of all such values calculated before, every 210,000 blocks:
if average_diff_of_last_100_retargets > maximum_of_all_previous_average_diffs
? ? ? ? do halving
else
? ? ? ? do nothing
This way:
1. system cannot be played
2. only in case of destructive halving: system waits for the recovery of network security
Best Regards
Jaroslaw
_______________________________________________
bitcoin-dev mailing list
bitcoin-dev at lists.linuxfoundation.org
https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
_______________________________________________
bitcoin-dev mailing list
bitcoin-dev at lists.linuxfoundation.org
https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230101/b43f2863/attachment.html>

From jk_14 at op.pl  Sun Jan  1 22:27:38 2023
From: jk_14 at op.pl (jk_14 at op.pl)
Date: Sun, 01 Jan 2023 23:27:38 +0100
Subject: [bitcoin-dev] Pseudocode for robust tail emission
Message-ID: <149371042-9e9acf88755b97f4a249777ce88d0078@pmq8v.m5r2.onet>


Is a storage fee averaged out over many future blocks - but not hardcoded value and regulated by a free market?


The problem with demurrage I see is that the fee is taken when you spend. There is no additional income for miners if people are still hoarding.
In tail emission even if people are still hoarding - the fee is taken immediately and is distributed to miners.

We have a hope there is still the global adoption ahead (most of countries are like El Salvador). It may increase price and marketcap of Bitcoin by order of magnitude.
And that's why hoarding in demurrage may still exist: due to extremely appealing long-term risk/reward (i.e. relatively small, delayed tax versus huge possible profit)




W dniu 2022-12-31 00:29:08 u?ytkownik Peter Todd <pete at petertodd.org> napisa?:
> On Fri, Dec 23, 2022 at 07:43:36PM +0100, jk_14 at op.pl wrote:
> 
> Necessary or not - it doesn't hurt to plan the robust model, just in case. The proposal is:
> 
> Let every 210,000 the code calculate the average difficulty of 100 last retargets (100 fit well in 210,000 / 2016 = 104.166)
> and compare with the maximum of all such values calculated before, every 210,000 blocks:
> 
> 
> if average_diff_of_last_100_retargets > maximum_of_all_previous_average_diffs
> 	do halving
> else
> 	do nothing
> 
> 
> This way:
> 
> 1. system cannot be played
> 2. only in case of destructive halving: system waits for the recovery of network security

First of all - while I suspct you already understand this issue - I should
point out the following:

The immediate danger we have with halvings is that in a competitive market,
profit margins tend towards marginal costs - the cost to produce an additional
unit of production - rather than total costs - the cost necessary to recover
prior and future expenses. Since the halving is a sudden shock to the system,
under the right conditions we could have a significant amount of hashing power
just barely able to afford to hash prior to the halving, resulting in all that
hashing power immediately having to shut down and fees increasing dramatically,
and likely, chaotically.  Your proposal does not address that problem as it can
only measure difficulty prior to the halving point.


Other than that problem, I agree that this proposal would, at least in theory,
be a positive improvement on the status quo. But it is a hard fork and I don't
think there is much hope for such hard forks to be implemented. I believe that
a demmurrage soft-fork, implemented via a storage fee averaged out over many
future blocks, has a much more plausible route towards implementation.

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org



From billy.tetrud at gmail.com  Mon Jan  2 04:53:39 2023
From: billy.tetrud at gmail.com (Billy Tetrud)
Date: Sun, 1 Jan 2023 22:53:39 -0600
Subject: [bitcoin-dev] Pseudocode for robust tail emission
In-Reply-To: <174623371-de649b28ce46dea2e588f2ef794decdb@pmq1v.m5r2.onet>
References: <174623371-de649b28ce46dea2e588f2ef794decdb@pmq1v.m5r2.onet>
Message-ID: <CAGpPWDa6GusMVXAFxTQ=oakwApHyYQYieFwygj5CZwen6yZp6g@mail.gmail.com>

> is surely better than not delaying it.

I might agree, but I don't think it really solves the problem well enough
to be worth it. Any solution that would solve the problem better would make
delaying halvings unnecessary.

> there is non-zero risk that people will hoard it more and more, according
to old Gresham's law

Gresham's law doesn't apply here. Gresham's law is about the interaction
between two currencies with a fixed, usually government-enforced exchange
rate. You seem to be saying that Bitcoin will be hoarded because Bitcoin
inflation reduces every halving. But even with 0 inflation, it certainly
won't cause all Bitcoin to be hoarded. Also, "hoarding" is also known as
"saving", and there's nothing wrong with saving. The spectre of deflation
comes from a misunderstanding of deflation and why it happens during bad
economic times. It is an effect, not a cause.

On Sun, Jan 1, 2023, 15:23 <jk_14 at op.pl> wrote:

>
> Yes, the idea is:
> if mining activity is growing - let's execute consecutive halvings
> but if miner exodus has happened - let's delay next halving until mining
> activity is recovered to previous levels
>
> If it gets to the point where a sudden drop in mining difficulty happens -
> delaying the next halving may be not sufficient to correct, but is surely
> better than not delaying it.
>
> While Bitcoin is better and better money with every halving in comparision
> to other types of money - there is non-zero risk that people will hoard it
> more and more, according to old Gresham's law ("HODL"). And this way
> decreasing liquidity / transactions volume. The positive feedback loop - is
> my real concern here.
>
> Regarding the relationship between difficulty and security - I fully agree.
> But ASIC technology is already matured. And also any technology
> breakthrough is a short event within 4 years period.
> So growth of difficulty could be gained by technology breakthrough, but
> any sudden drop of difficulty would be always an issue, while there is no
> such thing as: ASIC technology regression.
>
> Obviously, not complicated solution would be better than complicated one.
>
>
> W dniu 2022-12-30 19:21:10 u?ytkownik Billy Tetrud <billy.tetrud at gmail.com>
> napisa?:
>
> If the idea is to ensure that a catastrophic miner exodus doesn't happen,
> the "difference" you're calculating should only care about downward
> differences. Upward differences indicate more mining activity and so
> shouldn't cause a halving skip.
>
> But I don't think any scheme like this that only acts on the basis of
> difficulty will be sufficient. If it gets to the point where a sudden drop
> in mining difficulty happens, it is very likely that simply delaying the
> next halving or even ending halving all together will not be sufficient to
> correct for whatever is causing hashrate to tank. There is also the danger
> of simple difficulty stagnation, which this mechanism wouldn't detect.
>
> The relationship between difficulty and security becomes less and less
> predictable the longer you want to look ahead. There's no long term
> relation between difficulty and any reasonable security target. A security
> target might be something like "no colluding group with less than $1
> trillion dollars at their disposal could successfully 51% attack the
> network (with a probability of blah blah)". There is no way to today
> program in any code that detects based on difficult alone when that
> criteria is violated. You would have to program in assumptions about the
> cost of hashrate projected into the future.
>
> I can't think of any robust automatic way to do this. I think to a certain
> degree, it will have to be a change that happens in a fork of some kind
> (soft or hard) periodically (every 10 years? 30 years?). The basic
> relations needed is really the cost in Bitcoin of the security target (ie
> the minimum number of Bitcoin it should take to 51% attack the system) and
> the cost in Bitcoin of acquiring a unit of hashrate. This could be simply
> input into the code, or could use some complicated oracle system. But with
> that relation, the system could be programmed to calculate the difficulty
> necessary to keep the system secure.
>
> Once that is in place, the system could automatically adjust the subsidy
> up or down to attract more or less miners, or it could adjust the block
> size up or down to change the fee market such that more or less total fees
> are collected each block to attract more or less miners.
>
> On Tue, Dec 27, 2022, 09:41 Jaroslaw via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>>
>> It seems like the more elegant solution could be by using a chainwork
>> parameter instead.
>> i.e. comparison just before halving - if the last 210,000 block interval
>> has a higher chainwork difference between the begining and the end of
>> interval
>> than any other such inter-halving interval before.
>>
>> LIttle digression yet:
>> A system in which all users participate in ensuring its security looks
>> better than one in which only some (i.e. active) of them participate (and
>> passive stakeholders are de facto free riders)
>> In my opinion this concept above is only the complement of currently
>> missing mechanism: achieving equilibrium regarding costs of security
>> between two parties with opposing interests.
>> It's easy to understand and - most important - it has no hardcoded value
>> of tail emission - what is the clear proof it is based on a free market.
>> And last but not least, if someone is 100% sure that income from
>> transactions will takeover security support from block subsidy - accepting
>> such proposal is like putting the money where the mouth is: this safety
>> measure will never be triggered, then (no risk of fork)
>>
>>
>> Best Regards
>> Jaroslaw
>>
>>
>>
>> W dniu 2022-12-23 20:29:20 u?ytkownik Jaroslaw via bitcoin-dev <
>> bitcoin-dev at lists.linuxfoundation.org> napisa?:
>> >
>> Necessary or not - it doesn't hurt to plan the robust model, just in
>> case. The proposal is:
>>
>> Let every 210,000 the code calculate the average difficulty of 100 last
>> retargets (100 fit well in 210,000 / 2016 = 104.166)
>> and compare with the maximum of all such values calculated before, every
>> 210,000 blocks:
>>
>>
>> if average_diff_of_last_100_retargets >
>> maximum_of_all_previous_average_diffs
>>         do halving
>> else
>>         do nothing
>>
>>
>> This way:
>>
>> 1. system cannot be played
>> 2. only in case of destructive halving: system waits for the recovery of
>> network security
>>
>>
>> Best Regards
>> Jaroslaw
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
>>
>>
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230101/6da1a895/attachment.html>

From jk_14 at op.pl  Mon Jan  2 23:02:48 2023
From: jk_14 at op.pl (jk_14 at op.pl)
Date: Tue, 03 Jan 2023 00:02:48 +0100
Subject: [bitcoin-dev] Pseudocode for robust tail emission
Message-ID: <174713476-5bd35a73599a0a65335d70e99a1bb44e@pmq1v.m5r2.onet>



Right now security comes from almost fully from ~1.8% inflation.
In November mempool was inflated to ~150MB and people were rather waiting for cheap transactions back.
Instead of being happy that system is closer for a while to default working area.

Deflation in Bitcoin is not 1:1 matter like in gold, for example.
If all plain gold available to mine would be finished - gold mines as unprofitable enterprices are immediately closed.
And it doesn't affect security of gold already in circulation.
In Bitcoin "the show must go on" and someone must pay for it.
Active and passive users together (balanced by market play) or: only active users (in current scenario, long-term).

Deflation (or more precisely: tiny inflation) in Bitcoin is more complex issue with more repercussions than in gold.
In case of drop of network security - the tax will be paid anyway, in Bitcoin price.
So, there is an self-regulating mechanism here. The harsh one, but still.



W dniu 2023-01-02 05:53:57 u?ytkownik Billy Tetrud <billy.tetrud at gmail.com> napisa?:
>?is surely better than not delaying it.
?
I might agree, but I don't think it really solves the problem well enough to be worth it. Any solution that would solve the problem better would make delaying halvings unnecessary.?
?
>?there is non-zero risk that people will hoard it more and more, according to old Gresham's law


Gresham's law doesn't apply here. Gresham's law is about the interaction between two currencies with a fixed, usually government-enforced exchange rate. You seem to be saying that Bitcoin will be hoarded because Bitcoin inflation reduces every halving. But even with 0 inflation, it certainly won't cause all Bitcoin to be hoarded. Also, "hoarding" is also known as "saving", and there's nothing wrong with saving. The spectre of deflation comes from a misunderstanding of deflation and why it happens during bad economic times. It is an effect, not a cause.


On Sun, Jan 1, 2023, 15:23 <jk_14 at op.pl> wrote:

Yes, the idea is:
if mining activity is growing - let's execute consecutive halvings
but if miner exodus has happened - let's delay next halving until mining activity is recovered to previous levels

If it gets to the point where a sudden drop in mining difficulty happens - delaying the next halving may be not sufficient to correct, but is surely better than not delaying it.

While Bitcoin is better and better money with every halving in comparision to other types of money - there is non-zero risk that people will hoard it more and more, according to old Gresham's law ("HODL"). And this way decreasing liquidity / transactions volume. The positive feedback loop - is my real concern here.

Regarding the relationship between difficulty and security - I fully agree.
But ASIC technology is already matured. And also any technology breakthrough is a short event within 4 years period.
So growth of difficulty could be gained by technology breakthrough, but any sudden drop of difficulty would be always an issue, while there is no such thing as: ASIC technology regression.

Obviously, not complicated solution would be better than complicated one.




W dniu 2022-12-30 19:21:10 u?ytkownik Billy Tetrud <billy.tetrud at gmail.com> napisa?:
If the idea is to ensure that a catastrophic miner exodus doesn't happen, the "difference" you're calculating should only care about downward differences. Upward differences indicate more mining activity and so shouldn't cause a halving skip.


But I don't think any scheme like this that only acts on the basis of difficulty will be sufficient. If it gets to the point where a sudden drop in mining difficulty happens, it is very likely that simply delaying the next halving or even ending halving all together will not be sufficient to correct for whatever is causing hashrate to tank. There is also the danger of simple difficulty stagnation, which this mechanism wouldn't detect.?


The relationship between difficulty and security becomes less and less predictable the longer you want to look ahead. There's no long term relation between difficulty and any reasonable security target. A security target might be something like "no colluding group with less than $1 trillion dollars at their disposal could successfully 51% attack the network (with a probability of blah blah)". There is no way to today program in any code that detects based on difficult alone when that criteria is violated. You would have to program in assumptions about the cost of hashrate projected into the future.


I can't think of any robust automatic way to do this. I think to a certain degree, it will have to be a change that happens in a fork of some kind (soft or hard) periodically (every 10 years? 30 years?). The basic relations needed is really the cost in Bitcoin of the security target (ie the minimum number of Bitcoin it should take to 51% attack the system) and the cost in Bitcoin of acquiring a unit of hashrate. This could be simply input into the code, or could use some complicated oracle system. But with that relation, the system could be programmed to calculate the difficulty necessary to keep the system secure.


Once that is in place, the system could automatically adjust the subsidy up or down to attract more or less miners, or it could adjust the block size up or down to change the fee market such that more or less total fees are collected each block to attract more or less miners.?


On Tue, Dec 27, 2022, 09:41 Jaroslaw via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:

It seems like the more elegant solution could be by using a chainwork parameter instead.
i.e. comparison just before halving - if the last 210,000 block interval has a higher chainwork difference between the begining and the end of interval
than any other such inter-halving interval before.

LIttle digression yet:
A system in which all users participate in ensuring its security looks better than one in which only some (i.e. active) of them participate (and passive stakeholders are de facto free riders)
In my opinion this concept above is only the complement of currently missing mechanism: achieving equilibrium regarding costs of security between two parties with opposing interests.
It's easy to understand and - most important - it has no hardcoded value of tail emission - what is the clear proof it is based on a free market.
And last but not least, if someone is 100% sure that income from transactions will takeover security support from block subsidy - accepting such proposal is like putting the money where the mouth is: this safety measure will never be triggered, then (no risk of fork)


Best Regards
Jaroslaw



W dniu 2022-12-23 20:29:20 u?ytkownik Jaroslaw via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> napisa?:
>
Necessary or not - it doesn't hurt to plan the robust model, just in case. The proposal is:

Let every 210,000 the code calculate the average difficulty of 100 last retargets (100 fit well in 210,000 / 2016 = 104.166)
and compare with the maximum of all such values calculated before, every 210,000 blocks:


if average_diff_of_last_100_retargets > maximum_of_all_previous_average_diffs
? ? ? ? do halving
else
? ? ? ? do nothing


This way:

1. system cannot be played
2. only in case of destructive halving: system waits for the recovery of network security


Best Regards
Jaroslaw
_______________________________________________
bitcoin-dev mailing list
bitcoin-dev at lists.linuxfoundation.org
https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev



_______________________________________________
bitcoin-dev mailing list
bitcoin-dev at lists.linuxfoundation.org
https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev



From billy.tetrud at gmail.com  Wed Jan  4 16:03:10 2023
From: billy.tetrud at gmail.com (Billy Tetrud)
Date: Wed, 4 Jan 2023 10:03:10 -0600
Subject: [bitcoin-dev] Pseudocode for robust tail emission
In-Reply-To: <174713476-5bd35a73599a0a65335d70e99a1bb44e@pmq1v.m5r2.onet>
References: <174713476-5bd35a73599a0a65335d70e99a1bb44e@pmq1v.m5r2.onet>
Message-ID: <CAGpPWDbpKXHMhOm_hTiJ+LPeWQff1T9GTDe8xKM0i8gGDfiwVg@mail.gmail.com>

> In Bitcoin "the show must go on" and someone must pay for it. Active
[and/or] passive users

I certainly agree.

> or more precisely: tiny inflation

?

> Right now security comes from almost fully from ~1.8% inflation.

Best I could find, fees make up about 13% of miner revenue
<https://decrypt.co/57740/bitcoin-miners-now-earn-1-btc-in-fees-per-block>.
So yes, the vast majority of security comes from coinbase rewards. I assume
you're implying that ~13% of today's security is not enough? I would love
to see any quantitative thoughts you have on how one might determine that.

Have there been any thoughts put out in the community as to what size of
threat is unlikely enough to arise that we don't need to worry about it?
Maybe 1% of the yearly government budgets
<https://en.wikipedia.org/wiki/List_of_countries_by_government_budget> of
the world would be an upper bound on how much anyone would expect could
realistically be brought to bear? Today that would be maybe around $350
billion.

Or perhaps a better way to estimate would be calculating the size of the
motivation of an attacker. For example, this paper
<https://files.stlouisfed.org/files/htdocs/publications/review/92/03/Seigniorage_Mar_Apr1992.pdf>
seems
to conclude that the US government was extracting a maximum of ~$20
billion/year in 1982 dollars (so maybe $60 billion/year in 2022 dollars if
you go by CPI). If we scale this up to the entire world of governments,
this seems like it would place an upper bound of $180 billion/year of
seigniorage extraction that would be at risk if bitcoin might put the
currencies they gain seigniorage from out of business. Over 10 years (about
as far as we can expect any government to think), that's almost $2
trillion.

Whereas it would currently cost probably less than $7 billion to purchase a
50% share of bitcoin miners. To eventually reach a level of $350 billion,
bitcoin's price would need to reach about $800,000 / bitcoin. That seems
within the realm of possibility. To reach a level of $2 trillion, you'd
need a price of $4.3 million/bitcoin. That's still probably within the
realm of possibility, but certainly not as likely.  If you then assume we
won't have significant coinbase rewards by that point, and only 13% of the
equivalent revenue (from fees) would be earned, then a price of ~$6 million
would be needed to support a $350 billion and $34 million to support a $2
trillion security. I think that second one is getting up towards the realm
of impossibility, so if we think that much security is necessary, we might
have to rethink things. Its also quite possible, as the network of people
who accept and use bitcoin as payment grows, that the fee market will grow
superlinearly in comparison to market cap, which would make these kind of
high levels of security more realistic.

Anyways if it turns out that fees alone don't look like they're supporting
enough security, we have a good amount of time to come to that conclusion
and do something about it.

> Deflation in Bitcoin is not 1:1 matter like in gold, for example...
Deflation in Bitcoin is more complex issue

It's helpful to keep our language precise here. Price inflation and
deflation act identically in bitcoin and gold and anything else. What you
seem to be talking about at this point is monetary inflation (specifically,
a reduction in it) which of course operates differently on the machinery of
bitcoin than it does in the machinery of gold or other things. Whereas my
comment about you mentioning Gresham's law was specifically talking about
price inflation, not the effects of the coin emission machinery in bitcoin.

On Mon, Jan 2, 2023 at 5:02 PM <jk_14 at op.pl> wrote:

>
>
> Right now security comes from almost fully from ~1.8% inflation.
> In November mempool was inflated to ~150MB and people were rather waiting
> for cheap transactions back.
> Instead of being happy that system is closer for a while to default
> working area.
>
> Deflation in Bitcoin is not 1:1 matter like in gold, for example.
> If all plain gold available to mine would be finished - gold mines as
> unprofitable enterprices are immediately closed.
> And it doesn't affect security of gold already in circulation.
> In Bitcoin "the show must go on" and someone must pay for it.
> Active and passive users together (balanced by market play) or: only
> active users (in current scenario, long-term).
>
> Deflation (or more precisely: tiny inflation) in Bitcoin is more complex
> issue with more repercussions than in gold.
> In case of drop of network security - the tax will be paid anyway, in
> Bitcoin price.
> So, there is an self-regulating mechanism here. The harsh one, but still.
>
>
>
> W dniu 2023-01-02 05:53:57 u?ytkownik Billy Tetrud <billy.tetrud at gmail.com>
> napisa?:
> > is surely better than not delaying it.
>
> I might agree, but I don't think it really solves the problem well enough
> to be worth it. Any solution that would solve the problem better would make
> delaying halvings unnecessary.
>
> > there is non-zero risk that people will hoard it more and more,
> according to old Gresham's law
>
>
> Gresham's law doesn't apply here. Gresham's law is about the interaction
> between two currencies with a fixed, usually government-enforced exchange
> rate. You seem to be saying that Bitcoin will be hoarded because Bitcoin
> inflation reduces every halving. But even with 0 inflation, it certainly
> won't cause all Bitcoin to be hoarded. Also, "hoarding" is also known as
> "saving", and there's nothing wrong with saving. The spectre of deflation
> comes from a misunderstanding of deflation and why it happens during bad
> economic times. It is an effect, not a cause.
>
>
> On Sun, Jan 1, 2023, 15:23 <jk_14 at op.pl> wrote:
>
> Yes, the idea is:
> if mining activity is growing - let's execute consecutive halvings
> but if miner exodus has happened - let's delay next halving until mining
> activity is recovered to previous levels
>
> If it gets to the point where a sudden drop in mining difficulty happens -
> delaying the next halving may be not sufficient to correct, but is surely
> better than not delaying it.
>
> While Bitcoin is better and better money with every halving in comparision
> to other types of money - there is non-zero risk that people will hoard it
> more and more, according to old Gresham's law ("HODL"). And this way
> decreasing liquidity / transactions volume. The positive feedback loop - is
> my real concern here.
>
> Regarding the relationship between difficulty and security - I fully agree.
> But ASIC technology is already matured. And also any technology
> breakthrough is a short event within 4 years period.
> So growth of difficulty could be gained by technology breakthrough, but
> any sudden drop of difficulty would be always an issue, while there is no
> such thing as: ASIC technology regression.
>
> Obviously, not complicated solution would be better than complicated one.
>
>
>
>
> W dniu 2022-12-30 19:21:10 u?ytkownik Billy Tetrud <billy.tetrud at gmail.com>
> napisa?:
> If the idea is to ensure that a catastrophic miner exodus doesn't happen,
> the "difference" you're calculating should only care about downward
> differences. Upward differences indicate more mining activity and so
> shouldn't cause a halving skip.
>
>
> But I don't think any scheme like this that only acts on the basis of
> difficulty will be sufficient. If it gets to the point where a sudden drop
> in mining difficulty happens, it is very likely that simply delaying the
> next halving or even ending halving all together will not be sufficient to
> correct for whatever is causing hashrate to tank. There is also the danger
> of simple difficulty stagnation, which this mechanism wouldn't detect.
>
>
> The relationship between difficulty and security becomes less and less
> predictable the longer you want to look ahead. There's no long term
> relation between difficulty and any reasonable security target. A security
> target might be something like "no colluding group with less than $1
> trillion dollars at their disposal could successfully 51% attack the
> network (with a probability of blah blah)". There is no way to today
> program in any code that detects based on difficult alone when that
> criteria is violated. You would have to program in assumptions about the
> cost of hashrate projected into the future.
>
>
> I can't think of any robust automatic way to do this. I think to a certain
> degree, it will have to be a change that happens in a fork of some kind
> (soft or hard) periodically (every 10 years? 30 years?). The basic
> relations needed is really the cost in Bitcoin of the security target (ie
> the minimum number of Bitcoin it should take to 51% attack the system) and
> the cost in Bitcoin of acquiring a unit of hashrate. This could be simply
> input into the code, or could use some complicated oracle system. But with
> that relation, the system could be programmed to calculate the difficulty
> necessary to keep the system secure.
>
>
> Once that is in place, the system could automatically adjust the subsidy
> up or down to attract more or less miners, or it could adjust the block
> size up or down to change the fee market such that more or less total fees
> are collected each block to attract more or less miners.
>
>
> On Tue, Dec 27, 2022, 09:41 Jaroslaw via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
> It seems like the more elegant solution could be by using a chainwork
> parameter instead.
> i.e. comparison just before halving - if the last 210,000 block interval
> has a higher chainwork difference between the begining and the end of
> interval
> than any other such inter-halving interval before.
>
> LIttle digression yet:
> A system in which all users participate in ensuring its security looks
> better than one in which only some (i.e. active) of them participate (and
> passive stakeholders are de facto free riders)
> In my opinion this concept above is only the complement of currently
> missing mechanism: achieving equilibrium regarding costs of security
> between two parties with opposing interests.
> It's easy to understand and - most important - it has no hardcoded value
> of tail emission - what is the clear proof it is based on a free market.
> And last but not least, if someone is 100% sure that income from
> transactions will takeover security support from block subsidy - accepting
> such proposal is like putting the money where the mouth is: this safety
> measure will never be triggered, then (no risk of fork)
>
>
> Best Regards
> Jaroslaw
>
>
>
> W dniu 2022-12-23 20:29:20 u?ytkownik Jaroslaw via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> napisa?:
> >
> Necessary or not - it doesn't hurt to plan the robust model, just in case.
> The proposal is:
>
> Let every 210,000 the code calculate the average difficulty of 100 last
> retargets (100 fit well in 210,000 / 2016 = 104.166)
> and compare with the maximum of all such values calculated before, every
> 210,000 blocks:
>
>
> if average_diff_of_last_100_retargets >
> maximum_of_all_previous_average_diffs
>         do halving
> else
>         do nothing
>
>
> This way:
>
> 1. system cannot be played
> 2. only in case of destructive halving: system waits for the recovery of
> network security
>
>
> Best Regards
> Jaroslaw
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230104/dfb173d9/attachment-0001.html>

From vincenzopalazzodev at gmail.com  Wed Jan  4 20:59:49 2023
From: vincenzopalazzodev at gmail.com (Vincenzo)
Date: Wed, 04 Jan 2023 21:59:49 +0100
Subject: [bitcoin-dev] A Bitcoin NFT System
In-Reply-To: <fb893a29-92d0-a24a-c23b-dc1d2dba21d6@peersm.com>
References: <fb893a29-92d0-a24a-c23b-dc1d2dba21d6@peersm.com>
Message-ID: <CPJPI27V6A4M.3R8QVF5TRF4K3@vincent>

On Thu Dec 29, 2022 at 5:49 PM CET, Aymeric Vitte via bitcoin-dev wrote:
> I am not a fan of NFTs as currently designed and used, centralized,
> insecure, duplicable, virtual, stealable, not signed, expensive
>
> But if you consider that a NFT is anything that you can buy or store, as
> something real, or electronic, or whatever, in the real world, web or
> metaverse, then it becomes interesting
>
> NFTs are mostly used on Ethereum, and a "mess" to describe this stuff is
> a weak word
>
> Then I wrote: "A Bitcoin NFT system": 
> https://gist.github.com/Ayms/01dbfebf219965054b4a3beed1bfeba7 ,
> decentralized, secure, not expensive
>
The link is gone or just private.

Cheers!

Vincent.

From aymeric at peersm.com  Thu Jan  5 10:46:59 2023
From: aymeric at peersm.com (Aymeric Vitte)
Date: Thu, 5 Jan 2023 11:46:59 +0100
Subject: [bitcoin-dev] A Bitcoin NFT System
In-Reply-To: <CPJPI27V6A4M.3R8QVF5TRF4K3@vincent>
References: <fb893a29-92d0-a24a-c23b-dc1d2dba21d6@peersm.com>
 <CPJPI27V6A4M.3R8QVF5TRF4K3@vincent>
Message-ID: <53fcbcb8-8ad7-3742-1682-ee12e8c449d8@peersm.com>

Hi Vincent,

Indeed the gist was recorded (by mistake) as secret but the link is
supposed to work anyway, I have made it public, thanks for confirming
that it's working now, just in case I am attaching the text file

Regards

Aymeric


Le 04/01/2023 ? 21:59, Vincenzo a ?crit :
> On Thu Dec 29, 2022 at 5:49 PM CET, Aymeric Vitte via bitcoin-dev wrote:
>> I am not a fan of NFTs as currently designed and used, centralized,
>> insecure, duplicable, virtual, stealable, not signed, expensive
>>
>> But if you consider that a NFT is anything that you can buy or store, as
>> something real, or electronic, or whatever, in the real world, web or
>> metaverse, then it becomes interesting
>>
>> NFTs are mostly used on Ethereum, and a "mess" to describe this stuff is
>> a weak word
>>
>> Then I wrote: "A Bitcoin NFT system": 
>> https://gist.github.com/Ayms/01dbfebf219965054b4a3beed1bfeba7 ,
>> decentralized, secure, not expensive
>>
> The link is gone or just private.
>
> Cheers!
>
> Vincent.

-- 
Sophia-Antipolis, France
LinkedIn: https://fr.linkedin.com/in/aymeric-vitte-05855b26
GitHub : https://www.github.com/Ayms
Move your coins by yourself (browser version): https://peersm.com/wallet
Bitcoin transactions made simple: https://github.com/Ayms/bitcoin-transactions
torrent-live: https://github.com/Ayms/torrent-live
node-Tor : https://www.github.com/Ayms/node-Tor
Zcash wallets made simple: https://github.com/Ayms/zcash-wallets
Bitcoin wallets made simple: https://github.com/Ayms/bitcoin-wallets
Anti-spies and private torrents, dynamic blocklist: http://torrent-live.peersm.com
Peersm : http://www.peersm.com

-------------- next part --------------
# A Bitcoin NFT system

## Introduction

NFT is another barbarous name invented by the crypto folks meaning quasi nothing, by NFT in this proposal we will refer to whatever can be sold or referenced from the real world, web and metaverse using a blockchain system

The easy way solution is usually to use Ethereum, create some NFT tokens via ERC-721/1155 contracts and/or use some marketplaces such as Opensea which always lead to a centralized and insecure system that can collapse at any moment, and which is still complicate since nobody understand what is behind, fortunately (or not) MetaMask will do the job for you without you understanding what you are doing, like wrapped ETH

This is explained here: [Bitcoin, Ethereum, smart contracts, lightning, sidechains, Defi, DApps, NFTs, DEX, DAO explained - Centralization vs Decentralization](https://gist.github.com/Ayms/04b3084a14ee202e707b3faec57ed26e)

Especially: [tokens and sidechains](https://gist.github.com/Ayms/04b3084a14ee202e707b3faec57ed26e#example-2-tokens-and-sidechains)

And: [Opensea](https://gist.github.com/Ayms/04b3084a14ee202e707b3faec57ed26e#example-6-opensea)

## Purpose

The purpose of this proposal is to propose <b>a simple NFT system based on the Bitcoin blockchain</b>, assuming that the main purpose of a NFT is to be sold/bought, but not only, it can be something that you keep for yourself proving your ownership on the blockchain, the advantages compared to using Ethereum or any blockchain/sidechain on both networks (or others) will be explained below

## Referencing a NFT

A NFT can be a physical good, an electronic item (such as image), something virtual or not, in fact anything

If we take a document or an image, a simple reference to the NFT is its hash (SHA-256), but it is not really relevant since it's easy for a thief to slightly modify the document or image which will lead to a different hash

Now in what follows we will allocate a hash to reference any NFT

## The final hash reference to a NFT

Depending on the conditions the hash can be known (public marketplace for example) or unknown (only the buyer and the seller know it or the owner)

Thererfore the reference to the NFT will be the SHA-256 of its hash, which then hides the original hash, this is of course useless if the hash is known but let's keep the same convention, called |reference| in what follows

## Minting a NFT on Bitcoin

"Minting a NFT" just means to record your ownership of the NFT in the blockchain

To mint a NFT that you own on Bitcoin, you can do a transaction whose output will be:

    From address A (the seller):
     OP_RETURN |reference|
     DUST (A or B) or refund to an address of yourself (A or B)

Since the transaction is signed by A, we know that A is the owner of the reference, but note that from this point the public key of A is known, therefore if the purpose is to store a long term NFT then use another address B of yourself (because in some time it will be easier to crack a bitcoin address for which we know the public key rather than one that holds some bitcoins but has not been spent, so knowing only the hash of this address)

An OP_RETURN output is just something where you can store some data, limited to 512B

A lot of variations are possible in this article, for example you can decide to allocate one A address per NFT, it just depends on the use cases

For all the transactions mentioned in this article, opt-in for Replace By Fee must not be used [Replace By Fee](https://bitcoin.fr/replace-by-fee-rbf/)

It would be possible not to use OP_RETURN and for example store the |reference| in scriptSig, then construct an address (scriptPubKey) that will drop it while executing, but this would be a non standard transaction, so you shoud rely on some miners to mine it, without stealing your NFT, since it's easy for a miner to change the transaction and mint the NFT for himself

## Minting several NFTs in one transaction

You can do the very same using the Chainpoint protocol, which is to build a Merkle tree from |reference1| |reference2|....|reference N| (for which we recall will be the SHA-256 of the original NFTs hash), and replace the root of this tree in |reference| above

How Chainpoint work is well described here: [Chainpoint Proof](https://github.com/chainpoint/whitepaper/issues/5#issuecomment-304452107), basically while making a Chainpoint tree you get a proof to rebuild it from any |reference| (that you must know), which is just the other hashes that you need to know to reach the root 

In that case only the owner of the multiple NFTs knows the proofs and/or the |references|, unless he decides to release them, which he should do as described in the next paragraph (because the hashes and proofs must be known to check the validity of NFT transfers)

In what follows we will make reference to a Chainpoint |reference|

## Avoiding double minting

Double minting of NFTs is quite trivial, as far as we know there are zero protections against this in existing systems (Ethereum and others), the principle is simple: you mint several time the same NFT and possibly sell it several time or get robbed (the thief does transactions using the |reference| that he saw), because it's easy for a malicious person to do the very same transaction that you did and pretend the ownership of the NFT, or it's easy for you to mint it to different marketplaces or mint it several time, and then sell it several time

To illustrate this, read [Solving the double minting problem](https://medium.com/geekculture/solving-the-nft-double-minting-problem-with-computer-vision-c57bbbb4652d)

Unfortunately the above article just refers to images and the solution does not work at all at the end, because associating the picture to the camera or whatever that took it does not work and is easy to fake

Coming back to our bitcoin case, it seems simple to elect you as the real owner of the NFT since you made the transaction first, then based on the timestamp you are definitely the owner, but no

The thief could intercept your transaction, decide not to broadcast it further, replace it by a transaction minting your NFT for himself, with higher network fees for example and more direct access to miners, then this transaction will be the first one and the thief would have stolen your NFT

You can't do anything against this without using a third party to record that you had the knowledge of the |reference| first

The same problematic exists for example for js code loading, see [Bitcoin-transactions wallet/tools](https://peersm.com/wallet), here our github account is used to check the code

Then the very same is proposed here, preferably using the [Wayback Machine](https://archive.org/web/) to store |reference| (that you are the only one to know at this stage) signed by A before minting the NFT, then for sure you are the owner of the NFT because you are the first one to have referenced |reference| and signed it with your address (note again that as soon as you sign something the public key of A is known)

You can use other systems, github, even Twitter

What if all of those systems disappear and I can't prove anything any longer? Well, then probably internet has disappeared too

Anyway like the WebRTC peer introduction mechanism you can do this by any means you like, your own website, even a letter, you just need to prove that A had the knowledge of the double hash first

Now the double minting case is supposed to be marginal, except if you are a thief yourself

## Transferring a NFT for free

For a gift or whatever other reason, A can decide to transfer a NFT for free to C, the transaction will be:

    From address A (the seller):
     OP_RETURN |some code||reference|
     DUST (C) and refund to an address of yourself (A or B)
		
|some code| is just used to make the distinction between a minting operation

A sends the original hash to C
		
## C Buying a NFT from A

The transaction will be:

    From address C (the buyer):
     OP_RETURN |price||some code||reference|- signed by A
     |price| to A and refund to C or other C address
		
Once A and C have agreed on a price then A should send to C the |price||some code||reference| signed by him, which proves that the deal is accepted

If C tries to cheat and does broadcast a transaction that does not match the agreed price (since C cannot fake the signature of A), then C is still not the owner of the NFT and has lost its bitcoin, if a thief intercepts the transaction and does another one for himself, that's the same, since he is not willing to pay for the price

If A receives the correct amount, then he will send to C the original hash of |reference|, the same principle applies for all following transactions

We can not really enforce this, A could not send the hash, but for what purpose? This represents the same trust model than when you are buying some goods (the hash is the ticket), now in normal conditions the original hash is not really mandatory

Note that we know from minting/signing the public key of A, therefore anybody can verify the signature in the OP_RETURN

Note again that the signature of A is enough to know its public key and check the signature, <b>therefore minting is not mandatory</b> (depending on the use cases again)

Note also that in Ethereum style, that's the other way around, where A would initiate the final transaction to the NFT contract that will transfer to C

## C selling a NFT to D

That's the same:

    From address D (the buyer):
     OP_RETURN |price||some code||reference|- signed by C
     |price| to C and refund to D or other D address
		
C sends the original hash to D

## C Buying a NFT from A from a Chainpoint |reference|

A sends to C the |price||some code||reference||Chainpoint proof| signed by him, C then do the following transaction:

    From address C (the buyer):
     OP_RETURN |price||some code||reference||Chainpoint proof|- signed by A
     |price| to A and refund to C or other C address
		
## Group/organization C of buyers

C is then a multisig address funded by the group, and as before:

	From address C (the buyers):
		OP_RETURN |price||some code||reference|- signed by A
		|price| to A and refund to C or other C address

Same principle would apply for Chainpoint |reference|

## But, in all of this, what is the purpose of the double hash for |reference|?

Just to hide (if applicable) that the hash is only known by the buyer and the seller if the transactions are correct, then if anything unexpected happens they can prove that they are the only one to know the original hash of the NFT

We can take here the example of Kering (luxury group): [Kering NFT solution](https://www.ulysse-nardin.com/zh_en/blockchain-technology ), this is a variation of what is proposed here, when you buy a luxury product you get a certificate, then you go to their website, use the certificate information + your name & co, then you get a second certificate and the associated hash, the hash is then stored in the bitcoin blockchain in an OP_RETURN using the Chainpoint protocol via [Woleet](https://www.woleet.io/fr/accueil/) service

So here you are the only one to know the hash (with Kering), the problem of this solution is that it is very centralized and you can't correlate the hash to the product. That's where the double hash method could be used, you print on the luxury product the double hash (QR code or whatever) and give the original hash to the buyer, then if the product is counterfeit (with the same double hash) or stolen you can detect it since the malicious seller does not know the original hash

## Costs

Currently the network fees are 6-12 satoshis per byte, and the dust limit can be set at 546 satoshis

It's not possible to give a precise number here since the transactions depend on the number of inputs but an [estimation](https://www.bitstamp.net/learn/blockchain/how-are-btc-transaction-fees-determined/) would be less than 1 USD per transaction (probably 0.5 USD) against 70 to 100 USD on gas fees in Ethereum

This is far less than Ethereum NFT tokens see [Moxie experience](https://gist.github.com/Ayms/04b3084a14ee202e707b3faec57ed26e#example-7-moxies-experience)

## Is this system centralized?

No unlike whatever exists about sidechains (except Lightning), Ethereum NFTs or Dstuff, it is not, because you do not rely on any centralized platform to use it (the third party is the one you choose and it can't interact with the transactions), or Oracles that would be involved in your transactions creation/confirmation/transfer

## Is this system anonymous?

Not totally as currently designed, like Lightning again, since buyer/seller must "know" each others, but they can do it via anonymous means like Signal, Protonmail, Telegram or other stuff, or Tor, the advise is to create a new good old gmail address for this purpose and use PGP keys

In any case others around do not know what is going on

## Why not a super sidechain instead?

You can read this conclusion from a previous article: [Conclusion](https://gist.github.com/Ayms/04b3084a14ee202e707b3faec57ed26e#conclusion)

We have different examples, but let's take a few, Binance Smart Chain, supposedly compatible with Ethereum is a mess (or FTT/FTX token, see [Collapse of FTX and others: the Fxcking Token Theory](
https://www.linkedin.com/posts/aymeric-vitte-05855b26_the-fxcking-token-theory-as-a-coincidence-activity-6996493598653317120-vCpA)), and [Stacks](https://protos.com/what-is-stacks-and-does-it-really-serve-as-defi-for-bitcoin/) for Bitcoin supposedly allowing "smart contracts" and NFT on bitcoin is the same, both centralized, insecure, making it difficult to swap the tokens between one chain to another

Let's hope this article shows how powerfull (and less costly) is bitcoin, if we elaborate on Stacks it's another blockchain on top of Bitcoin, they register the blocks inside OP_RETURN in Bitcoin via a "proof of transfer". Why do they do this? No idea but surely because their blockchain is neither secured neither decentralized, this is just flooding the Bitcoin network with useless transactions duplicating proofs on two blockchains

There are many "proof-of-whatever" that are just fake stuff (like Filecoin proof of replication https://github.com/protocol/research/issues/4), useless, quite dubious, as stated in our conclusion above the intermediate states shoud be burned and only the final/relevant result stored in Bitcoin, this is very exactly what is doing Lightning

In any case, whatever sidechain/blockchain is proposed can only lead to something funny, because even the worldwide networks bitcoin and ethereum are still not decentralized today, despite of their age, because something like a few thousands nodes is not what we can call a decentralized system, then proposing something decentralized on top of it or not does not look serious, the only real decentralized network remains Bittorrent

This proposal seems to contradict one of our article [How stablecoins really work (Tether example), how to crack them and why you should take care if you use them](https://www.linkedin.com/pulse/how-stablecoins-really-work-tether-example-crack-them-aymeric-vitte/), but no in fact since everything is signed here

## Local Bitcoin

We will not talk here about the craziness of the Bitcoin forks period, which we have described here: ["Bitcoin Tartuffe - User guide: How to create your bitcoin fork in 5mn, fool everybody and become rich](https://www.linkedin.com/pulse/user-guide-how-create-your-bitcoin-fork-5mn-fool-everybody-vitte)

But we can envision a local Bitcoin, which would be limited to an area and is just a fork of the Bitcoin code (and not the Bitcoin network), restarting from the beginning

Then it's possible to adapt the rules according to the local area, for example reducing the costs by eliminating the dust limit, network fees by mining at lowest difficulty, unlimited supply and no halving

This seems to contradict the good practices of Bitcoin but not really, since the area is limited to people that are supposed to cooperate together, then the risk of attack is limited also

You might say that we are criticizing in [Bitcoin, Ethereum, smart contracts, lightning, sidechains, Defi, DApps, NFTs, DEX, DAO explained - Centralization vs Decentralization](https://gist.github.com/Ayms/04b3084a14ee202e707b3faec57ed26e) the fact that most of ERC-20/NFT tokens are of zero value, because coming from nowhere, but we are proposing the same

Not exactly, the local Bitcoin could be seen as a barter money, with a stable value, mined by everybody in the area, then unlike ERC-20 tokens you cannot issue 1 Billion of them all of a sudden

It remains decentralized since everybody is participating and get rewarded according to the probability distribution

To a certain extent, since the local area management might decide to shut down the system

An example is a cruise boat (who might have limited connectivity to interact with an outside blockchain and is not willing to burn its batteries with mining) where each element of the boat (cabins, kitchen, etc) would mine the local Bitcoin, then you can buy/exchange NFTs on the boat, services, use the token for the casino, restaurants, shops, the boat metaverse, etc

The local Bitcoin can be crawled from the outside and transactions can be sent from the outside, so, for example, luxury vendors and others can propose NFTs on board (and deliver them on board or when the boat is at some harbour), and NFTs can be proposed inside the boat shops/metaverse

Indeed since the local Bitcoin is not a fork of Bitcoin network, you don't have to implement replay protection (SIGHASH), then usual Bitcoin transactions can be built and sent to the local Bitcoin, of course you must not make mistakes between both chains

How can we bridge this with the Bitcoin network ? The first answer is: why would you need to do this? If so, then you need to use a bridge which will be of course something centralized, right now we are not aware of other possible methods (like atomic swap or other bulls)

This can apply to planes and many other local areas

## License and funding

While this work is public, it is not in the public area and under any open source license, then to use it, please contact: aymeric peersm com, PGP Key fingerprint : 65EF AE3D 973F D36A AB25 1225 2A1D 7B34 2627 AC39

The goal here is to reference who did fund this proposal

https://web.archive.org/web/20221231185645/https://gist.github.com/Ayms/01dbfebf219965054b4a3beed1bfeba7

From bitcoin-dev at wuille.net  Thu Jan  5 22:06:29 2023
From: bitcoin-dev at wuille.net (Pieter Wuille)
Date: Thu, 05 Jan 2023 22:06:29 +0000
Subject: [bitcoin-dev] Refreshed BIP324
In-Reply-To: <Y3dBUXPhTskCx+Fu@erisian.com.au>
References: <56677685-619a-691f-d5bc-54b69fdb6ed2@bip324.com>
 <zxv58iXZ73hf9ge8S0QLTanW-uLzaWjNtMHuKONP9hrqS5RhwitxzfVaMH8hbi3yImgNrKme3lCuDcHYKkpxEQHyGZZHJ8xtReOcnAx3o4g=@wuille.net>
 <Y2nK99fHUKxbPHmw@erisian.com.au>
 <wDqcIVw-YGTsjdf5M2GO9NNRl_UQuBeka2CUQUyQ329u6u-o7RabW_7S4FD3EDfk02kUczb3bXf8LtHhKLtx773UhQ7djKOl-JPOIrXqBSc=@wuille.net>
 <JXfTBjsA71dHE3h9wkxnWXANrwTbMADO4s2w34gEvMbiduKu4PEt5t-KA3EAIz-Xs4urjBHZ15NDFZST2a7e0x_NqyJymUnEORuTp3SNfMs=@wuille.net>
 <Y3dBUXPhTskCx+Fu@erisian.com.au>
Message-ID: <gSxFQedPc72pTioi9vuxvLKpaRBsnKFL4gkPKPn2G-EJgz_2Y1pYQ7cHD5SnunyCaLln7UQEHIxnopqP74LlnK__Mf9BURbJW8B5MYTZvCU=@wuille.net>

------- Original Message -------
On Friday, November 18th, 2022 at 3:24 AM, Anthony Towns <aj at erisian.com.au> wrote:

> > * etc
> > So this gives a uniform space which commands can be assigned from, and there is no strict need for thinking of the short-binary and long-alphabetic commands as distinct. In v2, some short ones would be treated as aliases for old long-alphabetic ones. But new commands could also just be introduced as short ones only (even in v1).
> 
> Isn't that optimising for the wrong thing? Aren't the goals we want:
> 
> 1) it should be easy to come up with a message identifier without
> accidently conflicting with someone else's proposal
> 
> 2) commonly used messages on the wire should have a short encoding
> in order to save bandwidth
> 
> Depending on how much the p2p protocol ossifies, which messages are
> "commonly used on the wire" might be expected to change; and picking an
> otherwise meaningless value from a set of 102 elements seems likely to
> produce conflicts...

Oh, yes. I meant this as an encoding scheme, not as a (replacement for) the negotiation/coordination mechanism. There could still be an initial assignment for 1-byte encodings, and/or an explicit mechanism to negotiate other assignment, and/or nothing at all for now.

I just thought it would be interesting to have a uniform encoding without explicit distinction between "short commands" and "long commands" at that layer.

But maybe none of this is worth it, as it's perhaps more complexity than the alternative, and the alternative already has a working implementation and written-up specification.

Cheers,

-- 
Pieter


From aj at erisian.com.au  Thu Jan  5 23:12:50 2023
From: aj at erisian.com.au (Anthony Towns)
Date: Fri, 6 Jan 2023 09:12:50 +1000
Subject: [bitcoin-dev] Refreshed BIP324
In-Reply-To: <gSxFQedPc72pTioi9vuxvLKpaRBsnKFL4gkPKPn2G-EJgz_2Y1pYQ7cHD5SnunyCaLln7UQEHIxnopqP74LlnK__Mf9BURbJW8B5MYTZvCU=@wuille.net>
References: <56677685-619a-691f-d5bc-54b69fdb6ed2@bip324.com>
 <zxv58iXZ73hf9ge8S0QLTanW-uLzaWjNtMHuKONP9hrqS5RhwitxzfVaMH8hbi3yImgNrKme3lCuDcHYKkpxEQHyGZZHJ8xtReOcnAx3o4g=@wuille.net>
 <Y2nK99fHUKxbPHmw@erisian.com.au>
 <wDqcIVw-YGTsjdf5M2GO9NNRl_UQuBeka2CUQUyQ329u6u-o7RabW_7S4FD3EDfk02kUczb3bXf8LtHhKLtx773UhQ7djKOl-JPOIrXqBSc=@wuille.net>
 <JXfTBjsA71dHE3h9wkxnWXANrwTbMADO4s2w34gEvMbiduKu4PEt5t-KA3EAIz-Xs4urjBHZ15NDFZST2a7e0x_NqyJymUnEORuTp3SNfMs=@wuille.net>
 <Y3dBUXPhTskCx+Fu@erisian.com.au>
 <gSxFQedPc72pTioi9vuxvLKpaRBsnKFL4gkPKPn2G-EJgz_2Y1pYQ7cHD5SnunyCaLln7UQEHIxnopqP74LlnK__Mf9BURbJW8B5MYTZvCU=@wuille.net>
Message-ID: <Y7dZctMlZtH6PEsz@erisian.com.au>

On Thu, Jan 05, 2023 at 10:06:29PM +0000, Pieter Wuille via bitcoin-dev wrote:
> > > So this gives a uniform space which commands can be assigned from, and there is no strict need for thinking of the short-binary and long-alphabetic commands as distinct. In v2, some short ones would be treated as aliases for old long-alphabetic ones. But new commands could also just be introduced as short ones only (even in v1).
> Oh, yes. I meant this as an encoding scheme, not as a (replacement for) the negotiation/coordination mechanism. There could still be an initial assignment for 1-byte encodings, and/or an explicit mechanism to negotiate other assignment, and/or nothing at all for now.
> 
> I just thought it would be interesting to have a uniform encoding without explicit distinction between "short commands" and "long commands" at that layer.
> But maybe none of this is worth it, as it's perhaps more complexity than the alternative, and the alternative already has a working implementation and written-up specification.

Heh, I was just looking at this yesterday, but failing to quite reach
a conclusion.

One thing I hadn't realised about this was that it's not actually
a restriction compared to what we currently allow with p2p v1:
CMessageHeader::IsCommandValid() already rejects commands that use
characters outside of 0x20 to 0x7E, so the high bit is already available
for signalling when we reach the last byte.

The current implementation for 324 does the aliasing
as part of V2TransportDeserializer::GetMessage and
V2TransportSerializer::prepareForTransport. That makes a lot of sense,
but particularly if we were to negotiate short commands sometime around
VERSION or VERACK, it might make more sense for the aliasing to move up
to the protocol layer rather than have it close to the  wire layer. In
that case having a uniform encoding means we could just keep using
CSerializedNetMsg whether we're sending a short command or a multibyte
ascii command -- without a uniform encoding, if we wanted to move short
commands up a layer, I think we'd need to change CSerializedNetMsg to
have m_type be a `std::variant<uint8_t,std::string>` instead of just a
string, or something similar.

I think I'm leaning towards "it doesn't matter either way" though:

 * if we can negotiate short commands on a per-peer basis, then once
   negotiation's finished we'll only be using short commands so saving a
   byte on long commands doesn't matter much

 * if we've only got around 30 or 40 commands we understand anyway
   (even counting one-time-only negotiation stuff), then it doesn't
   matter if we can do 102, 126 or 242 short commands since those are
   all more than we need

 * whether we'd have to tweak an internal struct if we want to change
   the way our code is structured shouldn't really be much of an influence
   on protocol design...

Cheers,
aj

From antoine.riard at gmail.com  Fri Jan  6 00:26:03 2023
From: antoine.riard at gmail.com (Antoine Riard)
Date: Thu, 5 Jan 2023 19:26:03 -0500
Subject: [bitcoin-dev] Bitcoin Contracting Primitives WG 3rd Meeting,
	Tuesday 17 Jan. 18:00 UTC
Message-ID: <CALZpt+Eou=m9LnZfZoxfZcQLs7UL5Te53whNgYO1fro05iSvDw@mail.gmail.com>

Hi list,

I'm proposing Tuesday 17th January at 18:00 UTC, i.e week from now for the
3rd Bitcoin contracting primitives WG meeting (the third Tuesday of January
month, as done previously).

As a soft proposal for an agenda, it would be to start with the leftover of
the last meeting agenda. Namely, roaming over all the contracting protocol
and use-case, to ensure there is exhaustivity of the R&D effort w.r.t known
ideas issued by the community during the past years. If you have been
working on a use-case, and it's missing in the current listing, feel free
to open a PR or bump me to do so (still same with primitives themselves
ofc).

The second part could be to take time to listen to everyone blockers in
their contracting primitives/covenant research.

About the R&D effort, one of my personal goal for the coming year would be
to nurture some websites, with the archive material progressively gathered
in the repository. The website would present the contracting protocol
research according to the best engineering/scientific
standards and ensure ideas neutrality. Ideally, it would enable collection
of feedback on dimensions like privacy or economic scaling from the Bitcoin
community of stakeholders at large, with Pretty Graphics (tm).

Beyond, pursuing a "decentralized" spirit, looking forward to starting
rotating meetings host during the year, as we're doing with BOLTs where
it's rotating between Lightning implementations contributors. If you're
interested in hosting one of the monthly meetings, feel free to open an
issue against the repository or bump me.

Communication venue is #bitcoin-contracting-primitives-wg on Libera Chat.
Logs of the previous session are available here [0].

Let it know if you have more questions or feedback.

Cheers,
Antoine

[0]
https://github.com/ariard/bitcoin-contracting-primitives-wg/blob/main/meetings/meetings-20-12.md
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230105/f93e5e0c/attachment.html>

From alicexbt at protonmail.com  Sat Jan  7 05:11:00 2023
From: alicexbt at protonmail.com (alicexbt)
Date: Sat, 07 Jan 2023 05:11:00 +0000
Subject: [bitcoin-dev] Roles and procedures around adding a bitcoin core
	maintainer
In-Reply-To: <2r9jSI5Ruf_j2Rm4R4a0g33YYhdLq1AQzrWCRLyna1BffMhCqXVBrH7Rll9noJeISH4uRM2ElF06x9FIXZoJh1ylxR-D9GX4s_fWFcqScHI=@protonmail.com>
References: <XB9BYeJEzU3l3LRXVwzGf8jSZYC2Uo5IXPCuhtne3V8xXVlkQ7VY0vc11lldZRm52fmniEYWN9AntPbJdJZ8fEeIVVMHUfWsbbvEr8OKwzc=@protonmail.com>
 <2r9jSI5Ruf_j2Rm4R4a0g33YYhdLq1AQzrWCRLyna1BffMhCqXVBrH7Rll9noJeISH4uRM2ElF06x9FIXZoJh1ylxR-D9GX4s_fWFcqScHI=@protonmail.com>
Message-ID: <iBvDFVaV3N_Dck5M9_Ngust8O9YXcY3C3gMbvqKH5895WhyeYu-14_bJPt3cbeLoTNJtfdu9TwPqDqna8zPlAKydjJljuMpic4Gt5rBJ5xg=@protonmail.com>

Hi Michael,

> I don't think ranting and raving or throwing toys out the pram on the mailing list is the productive way to go though.

It was the best possible way I found to summarize everything, look for opinions to improve the process, feedback about PR #25871 open since 140 days and includes no raving.

> I'll chat to some people offline and see what the confusion is and hopefully this can be resolved without unnecessary drama. 

I like all my Bitcoin and Bitcoin Core communication to be public for transparency and documentation purposes. Except reporting vulnerabilities although some bitcoin core developers even post vulns in public as GitHub issue when it involves other implementations.


/dev/fd0
floppy disc guy

Sent with Proton Mail secure email.


------- Original Message -------
On Wednesday, December 21st, 2022 at 12:14 AM, Michael Folkson michaelfolkson at protonmail.com wrote:



> Hi alicexbt
> 
> There does seem to be some confusion on this which I'm going to look into. I don't think ranting and raving or throwing toys out the pram on the mailing list is the productive way to go though. I'll chat to some people offline and see what the confusion is and hopefully this can be resolved without unnecessary drama. I'll respond in the new year. I don't know if you celebrate but if you do Happy Holidays.
> 
> Thanks
> Michael
> 
> --
> Michael Folkson
> Email: michaelfolkson at protonmail.com
> Keybase: michaelfolkson
> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3
> 
> ------- Original Message -------
> On Monday, December 19th, 2022 at 23:58, alicexbt via bitcoin-dev bitcoin-dev at lists.linuxfoundation.org wrote:
> 
> > Hi Bitcoin Developers,
> > 
> > List of present bitcoin core maintainers:
> > 
> > Username
> > 
> > Focus Area
> > 
> > MarcoFalke
> > 
> > General, QA
> > 
> > fanquake
> > 
> > General, Build
> > 
> > hebasto
> > 
> > General, UI/UX
> > 
> > achow101
> > 
> > General, Wallet
> > 
> > glozow
> > 
> > General, Mempool
> > 
> > Last 2 developers that stepped down as bitcoin core maintainer:
> > 
> > Username
> > 
> > -------------
> > 
> > sipa
> > 
> > laanwj
> > 
> > Process followed in adding last maintainer:
> > 
> > 1) fanquake nominated glowzow as rbf/mempool/validation maintainer.
> > 
> > 2) It was discussed in an IRC meeting and most of the developers agreed to add her as new maintainer except mild NACK from Jeremy Rubin. Some contributors did not like different opinions being shared in the meeting.
> > 
> > 3) A pull request was opened by glowzow to add keys. There were several ACKs, 2 NACKs and 1 meta concept NACK.
> > 
> > My NACK: https://github.com/bitcoin/bitcoin/pull/25524#issuecomment-1172518409
> > 
> > NACK by jamesob: https://github.com/bitcoin/bitcoin/pull/25524#issuecomment-1172570635
> > 
> > Meta concept NACK by luke-jr: https://github.com/bitcoin/bitcoin/pull/25524#issuecomment-1175625779
> > 
> > Eventually everyone agreed to add glowzow as maintainer and improve the process of adding maintainers. Pull request was merged by MarcoFalke.
> > 
> > Initiatives to improve the process and documentation:
> > 
> > 1) Jeremy opened a pull request and there were lot of disagreements with the documentation. It was closed since a related PR with less changes could be easy to agree upon.
> > 
> > 2) Related pull request with minimal documentation was also closed by Jeremy with a comment that desire to improve docs seems to be missing based on reviews.
> > 
> > 3) Jeremy opened an issue with title 'Call for Maintainer: P2P & Networking + Privacy' which was changed later and 'Privacy' was removed. He nominated jonatack and vasild was already self nominated so mentioned in the pull request. Nobody appreciated this effort to nominate self or others for a new maintainer. Later this was closed.
> > 
> > 4) I had opened an issue with title Call for Maintainer: Privacy'. This even involved privacy of contributors and not just bitcoin core. It received some comments that made no sense and I eventually closed the issue.
> > 
> > Process being followed for adding vasild as maintainer:
> > 
> > 1) vasild volunteered to be a new maintainer on IRC
> > 
> > 2) It was discussed in IRC meeting, some developers ACKed it and there were no issues.
> > 
> > 3) A pull request was opened by vasild to add keys which is still open and its been 4 months. There were already some ACKs from the IRC meeting and pull request also received some ACKs (16 until now). fanquake, dergoegge and JeremyRubin had some disagreements. Jeremy had recently withdrawn all ACK/NACK from bitcoin core repository for some reasons, fanquake has not replied yet and dergoegge had some new disagreements although don't mind if the pull request is merged.
> > 
> > 4) Earlier disagreements were related to scoping and it was changed by vasild
> > 
> > 4) There was even a comment that disrespected vasild's contributions in bitcoin core and we had to literally share pull requests in which vasild has improved bitcoin core.
> > 
> > 5) I tried adding the topic for a bitcoin core dev weekly meeting but did not achieve anything.
> > 
> > Since Bitcoin Core is the reference implementation for Bitcoin and used by 90% nodes, what should be the ideal process or changes you would expect in roles, procedures etc.?
> > 
> > - 'Call for maintainers' issue should be opened if contributors or maintainers need a new maintainer.
> > 
> > - Discussion about nominated contributors in an IRC meeting where everyone is allowed to share their opinion.
> > 
> > - One of the nominated contributor that gets most ACKs could open pull request to add keys. Everyone can ACK/NACK this PR with reasons.
> > 
> > - Maintainers should be unbiased in merging these pull requests.
> > 
> > - New maintainer should not be funded by the organization that already does it for most of the maintainers.
> > 
> > - Long term contributors that are not living in a first world country should be encouraged.
> > 
> > - Either we should agree every maintainer is a general maintainer that can merge pull request from different modules or define scope for present and new maintainers. We can't do both.
> > 
> > - Self merging pull requests should be avoided.
> > 
> > Let me know if you have any thoughts that could improve this process and involve less politics.
> > 
> > /dev/fd0
> > 
> > 'floppy disc guy'
> > 
> > Sent with Proton Mail secure email.
> > 
> > _______________________________________________
> > 
> > bitcoin-dev mailing list
> > 
> > bitcoin-dev at lists.linuxfoundation.org
> > 
> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

From jk_14 at op.pl  Sat Jan  7 18:52:47 2023
From: jk_14 at op.pl (jk_14 at op.pl)
Date: Sat, 07 Jan 2023 19:52:47 +0100
Subject: [bitcoin-dev] Pseudocode for robust tail emission
Message-ID: <174889786-7eefd505bbf223af3d3a1101c7c3044d@pmq3v.m5r2.onet>


> Anyways if it turns out that fees alone don't look like they're supporting enough security, we have a good amount of time to come to that conclusion and do something about it.?

The worst-case scenario is that the first global hashrate regression may take place in 2028.
Instead of the average price increase at least x2 every halving - the global hashrate may gradually decrease from that point. Again, it would be the worst-case scenario.

In my proposal you don't need to think about any calculations - just simple logic which we have right now. No hardcoded values and the free market in its finest - self-regulating the level of taxation of parties involved, but with opposite interests. And the mechanism would try to fix a global hashrate regression if appear.
In other words: let's be optimistic regarding fees, but with emergency mechanism built-in just in case.
The only drawback here is that the system is already running.

In my personal opinion avoiding long-term global hashrate regression is more important for store of value feature than the 21M schelling point (or trap...)




W dniu 2023-01-04 17:03:33 u?ytkownik Billy Tetrud <billy.tetrud at gmail.com> napisa?:
> In Bitcoin "the show must go on" and someone must pay for it. Active [and/or] passive users?


I certainly?agree.?


> or more precisely: tiny inflation


?


> Right now security comes from almost fully from ~1.8% inflation.


Best I could find, fees make up about 13% of miner revenue. So yes, the vast majority of security comes from coinbase rewards. I assume you're implying that ~13% of today's security is not enough? I would love to see any quantitative?thoughts you have on how one might determine that.?


Have there been any thoughts put out in the community as to what size of threat is unlikely enough to arise?that we don't need to worry about it? Maybe 1% of the yearly?government budgets?of the world?would be an upper bound on how much anyone would expect could realistically be brought to bear? Today that would be maybe around $350 billion.?


Or perhaps a better way to estimate would be calculating the size of the motivation of an attacker. For example, this paper?seems to conclude that the US government was extracting a maximum of ~$20 billion/year in 1982 dollars (so maybe $60 billion/year in 2022 dollars if you go by CPI). If we scale this up to the entire world of governments, this seems like it would place an upper bound of $180 billion/year of seigniorage extraction that would be at risk if bitcoin might put the currencies they gain seigniorage from out of business. Over 10 years (about as far as we can expect any government to think), that's almost $2 trillion.?


Whereas it would currently cost probably less than $7 billion?to purchase a 50% share of bitcoin miners. To eventually reach a level of $350 billion, bitcoin's price would need to reach about $800,000 / bitcoin. That seems within the realm of possibility. To reach a level of $2 trillion, you'd need a price of $4.3 million/bitcoin. That's still probably within the realm of possibility, but certainly not as likely.? If you then assume we won't have significant coinbase rewards by that point, and only 13% of the equivalent revenue (from fees) would be earned, then a price of ~$6 million would be needed to support a $350 billion and $34 million to support a $2 trillion security. I think that second one is getting up towards the realm of impossibility, so if we think that much security is necessary, we might have to rethink things. Its also quite possible, as the network of people who accept and use bitcoin as payment grows, that the fee market will grow superlinearly in comparison to market cap, which would make these kind of high levels of security more realistic.?


Anyways if it turns out that fees alone don't look like they're supporting enough security, we have a good amount of time to come to that conclusion and do something about it.?


> Deflation in Bitcoin is not 1:1 matter like in gold, for example...? Deflation in Bitcoin is more complex issue


It's helpful to keep our language precise here. Price inflation and deflation act identically in bitcoin and gold and anything else. What you seem to be talking about at this point is monetary inflation (specifically, a reduction in it) which of course operates differently on the machinery of bitcoin than it does in the machinery of gold or other things. Whereas my comment about you mentioning Gresham's law was specifically talking about price inflation, not the effects of the coin emission machinery in bitcoin.?




_______________________________________________
bitcoin-dev mailing list
bitcoin-dev at lists.linuxfoundation.org
https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev





From aj at erisian.com.au  Mon Jan  9 08:11:05 2023
From: aj at erisian.com.au (Anthony Towns)
Date: Mon, 9 Jan 2023 18:11:05 +1000
Subject: [bitcoin-dev] Refreshed BIP324
In-Reply-To: <Y7dZctMlZtH6PEsz@erisian.com.au>
References: <56677685-619a-691f-d5bc-54b69fdb6ed2@bip324.com>
 <zxv58iXZ73hf9ge8S0QLTanW-uLzaWjNtMHuKONP9hrqS5RhwitxzfVaMH8hbi3yImgNrKme3lCuDcHYKkpxEQHyGZZHJ8xtReOcnAx3o4g=@wuille.net>
 <Y2nK99fHUKxbPHmw@erisian.com.au>
 <wDqcIVw-YGTsjdf5M2GO9NNRl_UQuBeka2CUQUyQ329u6u-o7RabW_7S4FD3EDfk02kUczb3bXf8LtHhKLtx773UhQ7djKOl-JPOIrXqBSc=@wuille.net>
 <JXfTBjsA71dHE3h9wkxnWXANrwTbMADO4s2w34gEvMbiduKu4PEt5t-KA3EAIz-Xs4urjBHZ15NDFZST2a7e0x_NqyJymUnEORuTp3SNfMs=@wuille.net>
 <Y3dBUXPhTskCx+Fu@erisian.com.au>
 <gSxFQedPc72pTioi9vuxvLKpaRBsnKFL4gkPKPn2G-EJgz_2Y1pYQ7cHD5SnunyCaLln7UQEHIxnopqP74LlnK__Mf9BURbJW8B5MYTZvCU=@wuille.net>
 <Y7dZctMlZtH6PEsz@erisian.com.au>
Message-ID: <Y7vMGVQz8TjS4Cad@erisian.com.au>

On Fri, Jan 06, 2023 at 09:12:50AM +1000, Anthony Towns via bitcoin-dev wrote:
> On Thu, Jan 05, 2023 at 10:06:29PM +0000, Pieter Wuille via bitcoin-dev wrote:
> > Oh, yes. I meant this as an encoding scheme, not as a (replacement for) the negotiation/coordination mechanism. There could still be an initial assignment for 1-byte encodings, and/or an explicit mechanism to negotiate other assignment, and/or nothing at all for now.

> The current implementation for 324 does the aliasing
> as part of V2TransportDeserializer::GetMessage and
> V2TransportSerializer::prepareForTransport. That makes a lot of sense,
> [...]

So I think you can make this setup work with a negotiated assignment of
shortids, perhaps starting off something like:

https://github.com/ajtowns/bitcoin/commit/6b8edd754bdcb582e293e4f5d0b41297711bdbb7

That has a 242 element array per peer giving the mappings (which
is just ~250 bytes per peer) for deserialization, which seems
workable. [0]

It also has a single global map for serialization, so we'll always shorten
CFILTER to shortid 39 for every peer that supports shortids, even, eg, for
a peer who's told us they'll send CFILTER as shortid 99 and that we should
interpret shortid 39 from them as NEWFEATUREX. That has three advantages:

 * each peer can choose a mapping that minimises their own outbound
   traffic, even potentially for asymmetric connections, and don't need
   to coordinate with the other peer to decide a common optimal mapping
   that they both use across their connection

 * you don't have to have different serialization tables per-peer,
   reducing memory usage / implementation complexity

 * you can leave V2TransportSerializer as a `const` object, and not have
   to introduce additional locking logic to be able to update its
   state...

I'm not seeing a good way to introduce shortids for future one-shot
negotiation messages though (like VERSION, VERACK, SENDADDRV2,
WTXIDRELAY, SENDTXRCNCL):

 * if you explicitly announce the mapping first, you're just wasting
   bytes ("99=FOOBAR; 99 baz quux" vs just "FOOBAR baz quux")
 * if you negotiate the tables you support between VERSION/VERACK and
   then choose a mutually supported table after VERACK, that's too late
   for pre-VERACK negotation messages
 * announcing the tables you support as part of the VERSION message
   would work, but seems a bit klunky

Also, if you did want to shift to a new table, you'd probably want to
always support sending/receiving {37, 44, 46, 47, 36} messages?

I guess I still kind-of think it'd make more sense to just reserve
shortids for post-VERACK messages that are going to be sent more
than once per connection... At that point, even if you don't have any
table in common with your peer, just following VERACK with an immediate
announcement of each shortid you want to use and its meaning would still
make reasonable sense.

If we included the ability to define your own shortids concurrently
with bip324 rollout, then I think nodes could always have a static set
of shortids they use for all their peers for outbound messages, which,
as above, seems like it would make for simpler implementations.

ie, you might send:

   VERSION
   SHORTIDTBLS ["","awesomeshortids"]
   WTXIDRELAY
   SENDADDRV2
   SENDPACKAGES 1
   VERACK
   SHORTID "" [(52,"getpkgtxns"), (53, "pkgtxns"), (54, "ancpkginfo")] 

...but you'd do all that long form, and only switch to shortids for
messages after you've declared exactly what your shortids are going to
be.

(where "" is the table name for bip324's table, and "awesomeshortids"
is an updated table that includes the package relay commands already,
perhaps)

Cheers,
aj

[0] m_deserializer is used from the SocketHandler thread in
    CNode::ReceiveMsgBytes(), but the p2p protocol is managed from the
    MessageHandler thread; with multiple messages potentially deserialized
    into vRecvMsg() at once -- but that means that if the first message
    redefines shortid decoding, and the second message uses one of the
    redefined shortids, it will have already been decoded incorrectly.
    So that would need some futzing about still.

From james.obeirne at gmail.com  Mon Jan  9 16:07:54 2023
From: james.obeirne at gmail.com (James O'Beirne)
Date: Mon, 9 Jan 2023 11:07:54 -0500
Subject: [bitcoin-dev] OP_VAULT: a new vault proposal
Message-ID: <CAPfvXfL65cneOabmxfOzTZq14xN4vXNaGboq_g15-frM14RqGA@mail.gmail.com>

For the last few years, I've been interested in vaults as a way to
substantially derisk custodying Bitcoin, both at personal and commercial
scales. Instead of abating with familiarity, as enthusiasm sometimes
does, my conviction that vaults are an almost necessary part of bitcoin's
viability has only grown over the years.

Since people first started discussing vaults, it's been pretty clear that
some kind of covenant-enabling consensus functionality is necessary to
provide the feature set necessary to make vault use practical.

Earlier last year I experimented with using OP_CTV[1], a limited covenant
mechanism, to implement a "minimum-viable" vault design. I found that the
inherent limitations of a precomputed covenant scheme left the resulting
vault implementation wanting, even though it was an improvement over
existing strategies that rely on presigned transactions and (hopefully)
ephemeral keys.

But I also found proposed "general" covenant schemes to be
unsuitable for this use. The bloated scriptPubKeys, both in size and
complexity, that would result when implementing something like a vault
weren't encouraging. Also importantly, the social-consensus quagmire
regarding which covenant proposal to actually deploy feels at times
intractable.

As a result, I wanted to explore a middle way: a design solely concerned
with making the best vault use possible, with covenant functionality as a
secondary consideration. In other words, a proposal that would deliver
the safety benefits of vaults to users without getting hung up on
trying to solve the general problem of covenants.

At first this design, OP_VAULT, was just sort of a pipe dream. But as I
did more thinking (and eventually implementing) I became more convinced
that, even if it isn't considered for soft-fork, it is a worthwhile
device to serve as a standard benchmark against which other proposals
might be judged.

I wrote a paper that summarizes my findings and the resulting proposal:
https://jameso.be/vaults.pdf

along with an accompanying draft implementation:
https://github.com/bitcoin/bitcoin/pull/26857

I might work on a BIP if there's interest.

James

[1]: https://github.com/jamesob/simple-ctv-vault
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230109/21bf137d/attachment.html>

From rot13maxi at protonmail.com  Mon Jan  9 19:02:26 2023
From: rot13maxi at protonmail.com (rot13maxi)
Date: Mon, 09 Jan 2023 19:02:26 +0000
Subject: [bitcoin-dev] OP_VAULT: a new vault proposal
In-Reply-To: <CAPfvXfL65cneOabmxfOzTZq14xN4vXNaGboq_g15-frM14RqGA@mail.gmail.com>
References: <CAPfvXfL65cneOabmxfOzTZq14xN4vXNaGboq_g15-frM14RqGA@mail.gmail.com>
Message-ID: <8Uq3KNRWS_WV393lP9wq820PE8KNK0bhQ7u7hMJhIfdfV3-ZhSI-4q9Mw5P_TXivKtyePE2Exha4rso2yi3iNnLJpUpBQ38lAuwG-lQPVUE=@protonmail.com>

Hey James,

Really cool proposal. I?ve been thinking a lot lately about script paths for inheritance. In a lot of the ?have a relative time lock that allows a different key to spend coins, or allows a smaller threshold of a multisig to spend? schemes, you have the problem of needing to ?refresh? all of your coins when the timelock is close to maturation. In a lot of the ?use multisig with ephemeral keys to emulate covenants? schemes, you have to pre-commit to the terminal destination well in advance of the spend-path being used, which leads to all kinds of thorny questions about security and availability of *those* keys. In other words, you either have to have unbound destinations but a timer that needs resetting, or you have unbound time but fixed destinations. This design gets you the best of both because the destination SPKs aren?t committed to until the unvaulting process starts. This (or something like this with destination binding at unvault-time) would be an incredibly useful tool for inheritance designs in wallets.

I need to think a bit more about the recovery path not having any real encumbrances on it. Maybe in practice if you?re worried about DoS, you have UTXOs that commit to multiple vault paths that have tweaked recovery destinations or something, or maybe it really is the right move to say that if recovery is triggered, you probably do want it for all of your inflight unvaultings.

Looking forward to reading this a few more times and talking more about it.

Thanks!
rijndael

On Mon, Jan 9, 2023 at 11:07 AM, James O'Beirne via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:

> For the last few years, I've been interested in vaults as a way to
> substantially derisk custodying Bitcoin, both at personal and commercial
> scales. Instead of abating with familiarity, as enthusiasm sometimes
> does, my conviction that vaults are an almost necessary part of bitcoin's
> viability has only grown over the years.
>
> Since people first started discussing vaults, it's been pretty clear that
> some kind of covenant-enabling consensus functionality is necessary to
> provide the feature set necessary to make vault use practical.
>
> Earlier last year I experimented with using OP_CTV[1], a limited covenant
> mechanism, to implement a "minimum-viable" vault design. I found that the
> inherent limitations of a precomputed covenant scheme left the resulting
> vault implementation wanting, even though it was an improvement over
> existing strategies that rely on presigned transactions and (hopefully)
> ephemeral keys.
>
> But I also found proposed "general" covenant schemes to be
> unsuitable for this use. The bloated scriptPubKeys, both in size and
> complexity, that would result when implementing something like a vault
> weren't encouraging. Also importantly, the social-consensus quagmire
> regarding which covenant proposal to actually deploy feels at times
> intractable.
>
> As a result, I wanted to explore a middle way: a design solely concerned
> with making the best vault use possible, with covenant functionality as a
> secondary consideration. In other words, a proposal that would deliver
> the safety benefits of vaults to users without getting hung up on
> trying to solve the general problem of covenants.
>
> At first this design, OP_VAULT, was just sort of a pipe dream. But as I
> did more thinking (and eventually implementing) I became more convinced
> that, even if it isn't considered for soft-fork, it is a worthwhile
> device to serve as a standard benchmark against which other proposals
> might be judged.
>
> I wrote a paper that summarizes my findings and the resulting proposal:
> https://jameso.be/vaults.pdf
>
> along with an accompanying draft implementation:
> https://github.com/bitcoin/bitcoin/pull/26857
>
> I might work on a BIP if there's interest.
>
> James
> [1]: https://github.com/jamesob/simple-ctv-vault
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230109/80a1b3e0/attachment.html>

From gsanders87 at gmail.com  Mon Jan  9 19:31:51 2023
From: gsanders87 at gmail.com (Greg Sanders)
Date: Mon, 9 Jan 2023 14:31:51 -0500
Subject: [bitcoin-dev] OP_VAULT: a new vault proposal
In-Reply-To: <8Uq3KNRWS_WV393lP9wq820PE8KNK0bhQ7u7hMJhIfdfV3-ZhSI-4q9Mw5P_TXivKtyePE2Exha4rso2yi3iNnLJpUpBQ38lAuwG-lQPVUE=@protonmail.com>
References: <CAPfvXfL65cneOabmxfOzTZq14xN4vXNaGboq_g15-frM14RqGA@mail.gmail.com>
 <8Uq3KNRWS_WV393lP9wq820PE8KNK0bhQ7u7hMJhIfdfV3-ZhSI-4q9Mw5P_TXivKtyePE2Exha4rso2yi3iNnLJpUpBQ38lAuwG-lQPVUE=@protonmail.com>
Message-ID: <CAB3F3DsyN_Nj0Fs4LseiwxUE96tFt079qbb0hKBnTBZdyaPcSQ@mail.gmail.com>

Hi James and co,

Currently there is no way to make this compatible with scripthashes of any
kind, since the script interpreter has no insight into the OP_UNVAULT
outputs' "execution script", and one of the arguments of OP_UNVAULT is
freeform, resulting in an unpredictable output scriptpubkey.

I think the fix is just requiring a single additional witness data item
during OP_VAULT spend(for unvault path), mandating the
<target-outputs-hash> to be included in the witness stack as an input to
OP_VAULT opcode, and transaction introspection then checks to make sure the
witness item and the corresponding output script template matches the
expected.

This would only be necessary for the unvaulting path, and not for the
recovery path.

Cheers,
Greg

On Mon, Jan 9, 2023 at 2:10 PM rot13maxi via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Hey James,
>
> Really cool proposal. I?ve been thinking a lot lately about script paths
> for inheritance. In a lot of the ?have a relative time lock that allows a
> different key to spend coins, or allows a smaller threshold of a multisig
> to spend? schemes, you have the problem of needing to ?refresh? all of your
> coins when the timelock is close to maturation. In a lot of the ?use
> multisig with ephemeral keys to emulate covenants? schemes, you have to
> pre-commit to the terminal destination well in advance of the spend-path
> being used, which leads to all kinds of thorny questions about security and
> availability of *those* keys. In other words, you either have to have
> unbound destinations but a timer that needs resetting, or you have unbound
> time but fixed destinations. This design gets you the best of both because
> the destination SPKs aren?t committed to until the unvaulting process
> starts. This (or something like this with destination binding at
> unvault-time) would be an incredibly useful tool for inheritance designs in
> wallets.
>
> I need to think a bit more about the recovery path not having any real
> encumbrances on it. Maybe in practice if you?re worried about DoS, you have
> UTXOs that commit to multiple vault paths that have tweaked recovery
> destinations or something, or maybe it really is the right move to say that
> if recovery is triggered, you probably do want it for all of your inflight
> unvaultings.
>
> Looking forward to reading this a few more times and talking more about
> it.
>
> Thanks!
> rijndael
>
>
> On Mon, Jan 9, 2023 at 11:07 AM, James O'Beirne via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
> For the last few years, I've been interested in vaults as a way to
> substantially derisk custodying Bitcoin, both at personal and commercial
> scales. Instead of abating with familiarity, as enthusiasm sometimes
> does, my conviction that vaults are an almost necessary part of bitcoin's
> viability has only grown over the years.
>
> Since people first started discussing vaults, it's been pretty clear that
> some kind of covenant-enabling consensus functionality is necessary to
> provide the feature set necessary to make vault use practical.
>
> Earlier last year I experimented with using OP_CTV[1], a limited covenant
> mechanism, to implement a "minimum-viable" vault design. I found that the
> inherent limitations of a precomputed covenant scheme left the resulting
> vault implementation wanting, even though it was an improvement over
> existing strategies that rely on presigned transactions and (hopefully)
> ephemeral keys.
>
> But I also found proposed "general" covenant schemes to be
> unsuitable for this use. The bloated scriptPubKeys, both in size and
> complexity, that would result when implementing something like a vault
> weren't encouraging. Also importantly, the social-consensus quagmire
> regarding which covenant proposal to actually deploy feels at times
> intractable.
>
> As a result, I wanted to explore a middle way: a design solely concerned
> with making the best vault use possible, with covenant functionality as a
> secondary consideration. In other words, a proposal that would deliver
> the safety benefits of vaults to users without getting hung up on
> trying to solve the general problem of covenants.
>
> At first this design, OP_VAULT, was just sort of a pipe dream. But as I
> did more thinking (and eventually implementing) I became more convinced
> that, even if it isn't considered for soft-fork, it is a worthwhile
> device to serve as a standard benchmark against which other proposals
> might be judged.
>
> I wrote a paper that summarizes my findings and the resulting proposal:
> https://jameso.be/vaults.pdf
>
> along with an accompanying draft implementation:
> https://github.com/bitcoin/bitcoin/pull/26857
>
> I might work on a BIP if there's interest.
>
> James
>
> [1]: https://github.com/jamesob/simple-ctv-vault
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230109/7ca41bc5/attachment-0001.html>

From james.obeirne at gmail.com  Mon Jan  9 20:32:34 2023
From: james.obeirne at gmail.com (James O'Beirne)
Date: Mon, 9 Jan 2023 15:32:34 -0500
Subject: [bitcoin-dev] OP_VAULT: a new vault proposal
In-Reply-To: <CAB3F3DsyN_Nj0Fs4LseiwxUE96tFt079qbb0hKBnTBZdyaPcSQ@mail.gmail.com>
References: <CAPfvXfL65cneOabmxfOzTZq14xN4vXNaGboq_g15-frM14RqGA@mail.gmail.com>
 <8Uq3KNRWS_WV393lP9wq820PE8KNK0bhQ7u7hMJhIfdfV3-ZhSI-4q9Mw5P_TXivKtyePE2Exha4rso2yi3iNnLJpUpBQ38lAuwG-lQPVUE=@protonmail.com>
 <CAB3F3DsyN_Nj0Fs4LseiwxUE96tFt079qbb0hKBnTBZdyaPcSQ@mail.gmail.com>
Message-ID: <CAPfvXfK=ykkFWEpRruudLBMt-DaUprFcF=XCJvQ65AFEbo0zpg@mail.gmail.com>

Hey Greg,

I think what you're trying to get at here is that the OP_UNVAULT
scriptPubKey *must* be a bare script so that the OP_VAULT spend logic can
verify that we're spending an OP_VAULT output into a compatible OP_UNVAULT
output, and that's true. The OP_UNVAULT scriptPubKey also must contain the
target hash because that has is used when validating that spend to ensure
that the final unvault target matches what was advertised when the
OP_UNVAULT output was created.

So I'm not sure what problem you're trying to solve by putting the target
hash  on the OP_VAULT spend witness stack. If it were placed there, it
wouldn't be accessible during OP_UNVAULT spend AFAICT. I agree it would be
nice to figure out a way to allow the OP_UNVAULT scriptPubKey to not be
bare, which may require moving the target hash out of it, but we'd have to
figure out a mechanism to properly forward the target hash for validation.

Best,
James

On Mon, Jan 9, 2023 at 2:32 PM Greg Sanders <gsanders87 at gmail.com> wrote:

> Hi James and co,
>
> Currently there is no way to make this compatible with scripthashes of any
> kind, since the script interpreter has no insight into the OP_UNVAULT
> outputs' "execution script", and one of the arguments of OP_UNVAULT is
> freeform, resulting in an unpredictable output scriptpubkey.
>
> I think the fix is just requiring a single additional witness data item
> during OP_VAULT spend(for unvault path), mandating the
> <target-outputs-hash> to be included in the witness stack as an input to
> OP_VAULT opcode, and transaction introspection then checks to make sure the
> witness item and the corresponding output script template matches the
> expected.
>
> This would only be necessary for the unvaulting path, and not for the
> recovery path.
>
> Cheers,
> Greg
>
> On Mon, Jan 9, 2023 at 2:10 PM rot13maxi via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>> Hey James,
>>
>> Really cool proposal. I?ve been thinking a lot lately about script paths
>> for inheritance. In a lot of the ?have a relative time lock that allows a
>> different key to spend coins, or allows a smaller threshold of a multisig
>> to spend? schemes, you have the problem of needing to ?refresh? all of your
>> coins when the timelock is close to maturation. In a lot of the ?use
>> multisig with ephemeral keys to emulate covenants? schemes, you have to
>> pre-commit to the terminal destination well in advance of the spend-path
>> being used, which leads to all kinds of thorny questions about security and
>> availability of *those* keys. In other words, you either have to have
>> unbound destinations but a timer that needs resetting, or you have unbound
>> time but fixed destinations. This design gets you the best of both because
>> the destination SPKs aren?t committed to until the unvaulting process
>> starts. This (or something like this with destination binding at
>> unvault-time) would be an incredibly useful tool for inheritance designs in
>> wallets.
>>
>> I need to think a bit more about the recovery path not having any real
>> encumbrances on it. Maybe in practice if you?re worried about DoS, you have
>> UTXOs that commit to multiple vault paths that have tweaked recovery
>> destinations or something, or maybe it really is the right move to say that
>> if recovery is triggered, you probably do want it for all of your inflight
>> unvaultings.
>>
>> Looking forward to reading this a few more times and talking more about
>> it.
>>
>> Thanks!
>> rijndael
>>
>>
>> On Mon, Jan 9, 2023 at 11:07 AM, James O'Beirne via bitcoin-dev <
>> bitcoin-dev at lists.linuxfoundation.org> wrote:
>>
>> For the last few years, I've been interested in vaults as a way to
>> substantially derisk custodying Bitcoin, both at personal and commercial
>> scales. Instead of abating with familiarity, as enthusiasm sometimes
>> does, my conviction that vaults are an almost necessary part of bitcoin's
>> viability has only grown over the years.
>>
>> Since people first started discussing vaults, it's been pretty clear that
>> some kind of covenant-enabling consensus functionality is necessary to
>> provide the feature set necessary to make vault use practical.
>>
>> Earlier last year I experimented with using OP_CTV[1], a limited covenant
>> mechanism, to implement a "minimum-viable" vault design. I found that the
>> inherent limitations of a precomputed covenant scheme left the resulting
>> vault implementation wanting, even though it was an improvement over
>> existing strategies that rely on presigned transactions and (hopefully)
>> ephemeral keys.
>>
>> But I also found proposed "general" covenant schemes to be
>> unsuitable for this use. The bloated scriptPubKeys, both in size and
>> complexity, that would result when implementing something like a vault
>> weren't encouraging. Also importantly, the social-consensus quagmire
>> regarding which covenant proposal to actually deploy feels at times
>> intractable.
>>
>> As a result, I wanted to explore a middle way: a design solely concerned
>> with making the best vault use possible, with covenant functionality as a
>> secondary consideration. In other words, a proposal that would deliver
>> the safety benefits of vaults to users without getting hung up on
>> trying to solve the general problem of covenants.
>>
>> At first this design, OP_VAULT, was just sort of a pipe dream. But as I
>> did more thinking (and eventually implementing) I became more convinced
>> that, even if it isn't considered for soft-fork, it is a worthwhile
>> device to serve as a standard benchmark against which other proposals
>> might be judged.
>>
>> I wrote a paper that summarizes my findings and the resulting proposal:
>> https://jameso.be/vaults.pdf
>>
>> along with an accompanying draft implementation:
>> https://github.com/bitcoin/bitcoin/pull/26857
>>
>> I might work on a BIP if there's interest.
>>
>> James
>>
>> [1]: https://github.com/jamesob/simple-ctv-vault
>>
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230109/b0fc1b4c/attachment.html>

From pete at petertodd.org  Mon Jan  9 22:18:52 2023
From: pete at petertodd.org (Peter Todd)
Date: Mon, 9 Jan 2023 17:18:52 -0500
Subject: [bitcoin-dev] Why Full-RBF Makes DoS Attacks on Multiparty
 Protocols Significantly More Expensive
Message-ID: <Y7ySzDjzx5eDjOH9@petertodd.org>

I was reminded recently that while Suhas Daftuar cited tx-pinning as a reason
to remove full-rbf, he neglected to mention that tx-pinning greatly increases
the cost of attacks on multi-party protocols. Him (rhetorically?) asking(4):

    "Does fullrbf offer any benefits other than breaking zeroconf business
     practices?"

...has caused a lot of confusion by implying that there were no benefits. So
I'm writing this to set the record straight and provide an easily cited
explanation as to why full-rbf - even with tx-pinning - is a valuable
improvement for multi-party protocols like coinjoins that rely on transactions
containing multiple inputs exclusively controlled(1) by different parties.

tl;dr: without full-rbf people can intentionally and unintentionally DoS attack
multi-party protocols by double-spending their inputs with low-fee txs, holding
up progress until that low-fee tx gets mined. This could take days, weeks, or
even worse. Modulo intentional tx-pinning, full-RBF fixes this by ensuring that
a higher fee transaction gets mined in a reasonable amount of time so the
protocol makes forward progress. And as for tx-pinning, exploiting it is very
expensive, so full-rbf still makes the situation much better than the status
quo.


# The Double-Spend DoS Attack on Multi-Party, Multi-Input, Transactions

If a protocol constructs transactions containing multiple inputs exclusively
controlled by different parties, those parties can intentionally and
unintentionally double-spend those inputs in alternate transactions. For
example, in a Wasabi coinjoin any one of the hundreds of participants could
sign and broadcast a transaction spending their input. If they do that at the
right time, as much as ~100% of the hashing power may see the double-spend
first, prior to the intended coinjoin transaction. This in fact does happen
regularly in production to Wasabi coinjoins, probably due to people
accidentally running different wallets at the same time using the same seed, as
well as people importing their seeds into alternative wallets.

By itself this isn't a significant problem: Wasabi coinjoins are a two phase
protocol, and, like any multi-step, multi-party protocol, they have to deal
with the fact that participants in the protocol may fail to complete all the
steps necessary for a transaction to be completed. It's very common for one or
more parties in a Wasabi coinjoin to fail to complete both steps of the
protocol, and a majority of Wasabi coinjoin rounds fail. Wasabi deals with this
economically by (temporarily or ~permanently) blacklisting UTXOs that failed to
complete a round, making DoS attacks expensive by forcing the attacker to tie
up funds/create new UTXOs.

Similarly, in use-cases such as multi-party-funded Lightning channels(5), an
attacker can always DoS attack the protocol by participating in a channel open,
and then failing to allow payments to be routed through it. The solution is
again to use economics to ensure the attack is sufficiently costly.

However, under the right circumstances double-spends are an unusually powerful
DoS attack on multi-party, multi-input, transaction. When mempool demand is
high, low fee transactions can take arbitrarily long to get mined. Bitcoin has
seen periods of mempool demand where low-fee transactions would take *months*
to get mined. Transaction expiry does not solve this problem, as anyone can
rebroadcast transactions at any time. In these circumstances without
transaction replacement a multi-party transaction such as a Wasabi coinjoin
could be held up indefinitely by a low-fee double-spend.


## How Full-RBF Mitigates the Double-Spend DoS Attack

Modulo tx-pinning, full-rbf mitigates the double-spend DoS attack in a very
straightforward way: the low fee transaction is replaced by the higher fee
transaction, resulting in the latter getting mined in a reasonable amount of
time and the protocol making forward progress.

Note that the converse is not a useful attack: if the attacker broadcasts a
high-fee double spend, higher than the intended multi-party transaction, the
transaction will get mined in a reasonable amount of time, costing the attacker
money and the defender nothing beyond wasted time. Multi-party protocols always
have the property that attackers can spend money to DoS attack by creating more
UTXOs/identities/etc, so this isn't any worse than the status quo!


## Transaction Pinning

So what about transaction pinning? The term actually refers to a few different
techniques that can make it difficult/expensive to fee-bump a transaction.
We're interested in the techniques relevant to replacements, namely
exploitation of:

1. BIP-125 RBF Rule #3: a replacement transaction is required to pay
the higher absolute fee (not just fee rate) than the sum of fees paid by all
transactions being replaced.

2. BIP-125 RBF Rule #5: the number of transactions replaced at one time must
not exceed 100. Note that this rule only exists due to limitations of the
existing Bitcoin Core implementation; it has absolute no economic rational and
should be removed by either improving the implementation's scalability issues,
or rejecting transactions that could make a transaction unreplaceable(2).

Exploiting either rule is expensive. To exploit rule #3 the attacker has to
broadcast fee-paying transactions paying a total amount of fees higher than the
defender is willing to pay. Since transactions don't expire, in almost all
circumstances those transactions will eventually be mined, costing the attacker
much more money than they would have spent without full-rbf.

To exploit rule #5, the attacker has to broadcast 100x more fee-paying
transactions than they otherwise would have. As with rule #3, those
transactions will almost always eventually be mined, costing the attacker
significantly more money than they would have spent without full-rbf. And, as
mentioned above(2), rule #5 is merely an artifact of the existing
implementation which can and should be fixed.

The only avenue for an attacker to avoid transaction pinning costs is
amortisation: reusing the extra transactions required for pinning for other
attacks/other purposes. But of course, amortisation is *already* a potent cost
reduction strategy for attacks on multi-party protocols such as coinjoin, so
the existence of transaction pinning doesn't appreciably change the situation.
Again, there are mitigations such as requiring participants to post nLockTime'd
fee-paying transactions(3), and limiting attacks to parties who are heavily
invested in Bitcoin for other reasons is a valuable improvement on the status
quo.


# Conclusion

Far from not "offering any benefits other than breaking zeroconf business
practices"(4), full-rbf clearly improves Bitcoin for multi-party protocols,
among the many other reasons to adopt it.


# Footnotes

1. What do I mean by "exclusively controlled"? Let's compare coinjoin, to an
   ordinary single-payer Lightning channel. In a coinjoin, the goal is to get a
   transaction mined containing multiple inputs from different parties. Each of
   these inputs is individually, exclusively controlled by a single party:
   without the cooperation of any other party that input that be spend. This is
   unlike an ordinary single-payer Lightning channel: while the commitment
   transactions are multi-party transactions, the multisig transaction outputs
   involved are *jointly* controlled by both parties, and thus neither party can
   spend it without the cooperation of the other at some point.

2. [bitcoin-dev] Removing BIP-125 Rule #5 Pinning with the Always-Replaceable
   Invariant, https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-November/021175.html

3. [bitcoin-dev] Using Full-RBF to fix BIP-125 Rule #3 Pinning with nLockTime,
   https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-November/021176.html

4. https://github.com/bitcoin/bitcoin/pull/26438

5. There are even more exotic proposed Lightning-related protocols where a failure
   of transaction replacement can cause the loss of funds. I'm not covering
   those scenarios because they have such strong requirements - beyond what
   full-rbf offers - that the technical community does not have consensus that
   these proposed protocols are even viable.

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230109/e2dd405c/attachment-0001.sig>

From dave at dtrt.org  Tue Jan 10 07:11:46 2023
From: dave at dtrt.org (David A. Harding)
Date: Mon, 09 Jan 2023 21:11:46 -1000
Subject: [bitcoin-dev] Why Full-RBF Makes DoS Attacks on Multiparty
 Protocols Significantly More Expensive
In-Reply-To: <Y7ySzDjzx5eDjOH9@petertodd.org>
References: <Y7ySzDjzx5eDjOH9@petertodd.org>
Message-ID: <aaaeda2950e61127a3218c523927a0d8@dtrt.org>

On 2023-01-09 12:18, Peter Todd via bitcoin-dev wrote:
> [The quote:]
> 
>     "Does fullrbf offer any benefits other than breaking zeroconf 
> business
>      practices?"
> 
> ...has caused a lot of confusion by implying that there were no 
> benefits. [...]
> 
> tl;dr: without full-rbf people can intentionally and unintentionally 
> DoS attack
> multi-party protocols by double-spending their inputs with low-fee txs, 
> holding
> up progress until that low-fee tx gets mined.

Hi Peter,

I'm confused.  Isn't this an easily solvable issue without full-RBF?
Let's say Alice, Bob, Carol, and Mallory create a coinjoin transaction.
Mallory either intentionally or unintentionally creates a conflicting
transaction that does not opt-in to RBF.

You seem to be proposing that the other participants force the coinjoin
to complete by having the coinjoin transaction replace Mallory's
conflicting transaction, which requires a full-RBF world.

But isn't it also possible in a non-full-RBF world for Alice, Bob, and
Carol to simply create a new coinjoin transaction which does not include
any of Mallory's inputs so it doesn't conflict with Mallory's
transaction?  That way their second coinjoin transaction can confirm
independently of Mallory's transaction.

Likewise, if Alice and Mallory attempt an LN dual funding and Mallory
creates a conflict, Alice can just create an alternative dual funding
with Bob rather than try to use full-RBF to force Mallory's earlier dual
funding to confirm.

> ## Transaction Pinning
> 
> Exploiting either rule is expensive.

I think this transaction pinning attack against coinjoins and dual
fundings is also solved in a non-full-RBF world by the honest
participants just creating a non-conflicting transaction.

That said, if I'm missing something and these attacks do actually apply,
then it might be worth putting price figures on the attack in terms most
people will understand.  The conflicting inputs attack you described in
the beginning as being solved by full-RBF costs about $0.05 USD at
$17,000/BTC.  The transaction pinning attack you imply is unsolved by
full-RBF costs about $17.00.  If both attacks apply, any protocol which
is vulnerable to a $17.00 attack still seems highly vulnerable to me, so
it doesn't feel like a stretch to say that full-RBF lacks significant
benefits for those protocols.

Thanks,

-Dave

From pete at petertodd.org  Tue Jan 10 08:47:48 2023
From: pete at petertodd.org (Peter Todd)
Date: Tue, 10 Jan 2023 03:47:48 -0500
Subject: [bitcoin-dev] Why Full-RBF Makes DoS Attacks on Multiparty
 Protocols Significantly More Expensive
In-Reply-To: <aaaeda2950e61127a3218c523927a0d8@dtrt.org>
References: <Y7ySzDjzx5eDjOH9@petertodd.org>
 <aaaeda2950e61127a3218c523927a0d8@dtrt.org>
Message-ID: <Y70mNHsX4JcKYZyi@petertodd.org>

On Mon, Jan 09, 2023 at 09:11:46PM -1000, David A. Harding wrote:
> On 2023-01-09 12:18, Peter Todd via bitcoin-dev wrote:
> > [The quote:]
> > 
> >     "Does fullrbf offer any benefits other than breaking zeroconf
> > business
> >      practices?"
> > 
> > ...has caused a lot of confusion by implying that there were no
> > benefits. [...]
> > 
> > tl;dr: without full-rbf people can intentionally and unintentionally DoS
> > attack
> > multi-party protocols by double-spending their inputs with low-fee txs,
> > holding
> > up progress until that low-fee tx gets mined.
> 
> Hi Peter,
> 
> I'm confused.  Isn't this an easily solvable issue without full-RBF?
> Let's say Alice, Bob, Carol, and Mallory create a coinjoin transaction.
> Mallory either intentionally or unintentionally creates a conflicting
> transaction that does not opt-in to RBF.
> 
> You seem to be proposing that the other participants force the coinjoin
> to complete by having the coinjoin transaction replace Mallory's
> conflicting transaction, which requires a full-RBF world.
> 
> But isn't it also possible in a non-full-RBF world for Alice, Bob, and
> Carol to simply create a new coinjoin transaction which does not include
> any of Mallory's inputs so it doesn't conflict with Mallory's
> transaction?  That way their second coinjoin transaction can confirm
> independently of Mallory's transaction.

How do you propose that the participants learn about the double-spend? Without
knowing that it happened, they can't respond as you suggested.

> Likewise, if Alice and Mallory attempt an LN dual funding and Mallory
> creates a conflict, Alice can just create an alternative dual funding
> with Bob rather than try to use full-RBF to force Mallory's earlier dual
> funding to confirm.

Same issue.

And of course, in both cases full-rbf makes Mallory have to actually pay full
price for the attack. Either because the intended transaction goes through. Or
because their double-spending DoS attack had to be much more expensive in the
first place.

> > ## Transaction Pinning
> > 
> > Exploiting either rule is expensive.
> 
> I think this transaction pinning attack against coinjoins and dual
> fundings is also solved in a non-full-RBF world by the honest
> participants just creating a non-conflicting transaction.
> 
> That said, if I'm missing something and these attacks do actually apply,
> then it might be worth putting price figures on the attack in terms most
> people will understand.  The conflicting inputs attack you described in
> the beginning as being solved by full-RBF costs about $0.05 USD at
> $17,000/BTC.  The transaction pinning attack you imply is unsolved by
> full-RBF costs about $17.00.  If both attacks apply, any protocol which
> is vulnerable to a $17.00 attack still seems highly vulnerable to me, so
> it doesn't feel like a stretch to say that full-RBF lacks significant
> benefits for those protocols.

Coinjoins are an automated process that happens constantly. As I described in
my email, it's totally normal for them to fail constantly - I was told by
Wasabi that only ~25% of coinjoin rounds succeed right now, a figure that
frankly was much higher than I expected. Being forced to spend $17/round rather
than $0.05/round is a huge improvement that adds up to serious money at the
scale at which Wasabi and similar protocols operate at.

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230110/9e0a6645/attachment.sig>

From pete at petertodd.org  Tue Jan 10 10:03:16 2023
From: pete at petertodd.org (Peter Todd)
Date: Tue, 10 Jan 2023 05:03:16 -0500
Subject: [bitcoin-dev] Why Full-RBF Makes DoS Attacks on Multiparty
 Protocols Significantly More Expensive
In-Reply-To: <OwgJwjPrZWRtBaIDDZ8g-xbFPlryUXUopqUuKYVUNE-mVHzCWHFXl77YzDlItEjHTHcGjpzIC5alGsnFEsOtSgHLm9We92gcWrLTahzPGFk=@protonmail.com>
References: <Y7ySzDjzx5eDjOH9@petertodd.org>
 <OwgJwjPrZWRtBaIDDZ8g-xbFPlryUXUopqUuKYVUNE-mVHzCWHFXl77YzDlItEjHTHcGjpzIC5alGsnFEsOtSgHLm9We92gcWrLTahzPGFk=@protonmail.com>
Message-ID: <Y7035Edqoq8CK+nl@petertodd.org>

On Tue, Jan 10, 2023 at 09:19:39AM +0000, alicexbt wrote:
> Hi Peter,
> 
> > ## How Full-RBF Mitigates the Double-Spend DoS Attack
> > 
> > Modulo tx-pinning, full-rbf mitigates the double-spend DoS attack in a very
> > straightforward way: the low fee transaction is replaced by the higher fee
> > transaction, resulting in the latter getting mined in a reasonable amount of
> > time and the protocol making forward progress.
> 
> Asking this question based on a [discussion on twitter][0]. How would you get extra sats to increase the fees?

You're misunderstanding the issue. There is no need for extra sats to increase
fees. Coinjoin transactions already have fees set at a level at which you'd
expect them to be mined in a reasonable amount of time. Full-RBF ensures that,
modulo tx pinning, either the coinjoin gets mined, or any double-spend has to
have a high enough feerate that it will be mined in a reasonable amount of time
as well.

> It seems this would be possible with Joinmarket, Wasabi and even joinstr although things would get worse for Whirlpool. Whirlpool coinjoin transactions do not signal BIP 125 RBF so they were not replaceable earlier

Bringing up Whirlpool here is silly. Everyone knows Samourai has made, at best,
some rather insane technical decisions. Quite likely downright malicious with
their xpub collection. Their opinion isn't relevant. Cite reputable sources.

Anyway, Wasabi would like to move to making coinjoins opt-in to RBF. Though
full-rbf may come sooner; for technical reasons opt-in RBF is ugly to implement
now as activation needs to be coordinated accross all clients:

https://github.com/zkSNACKs/WalletWasabi/issues/9041#issuecomment-1376653020

> however attacker would be able to perform DoS attacks now by double spending their inputs used in coinjoin.

As I explained, attackers can already do this with or without full-rbf simply
by picking the right time to broadcast the double spend. It's not an effective
attack anyway: with a UTXO you can already hold up a coinjoin round by simply
failing to complete stage #2 of the coinjoin. Actually doing a double-spend
simply guarantees that you're spending money on it. It's only effective with
low-fee double-spends in the absence of full-rbf.

> [0]: https://twitter.com/dammkewl/status/1599692908860706818

This tweet is nuts. Eg "Gives well connected mining pools an added advantage"
is simply false. Full-RBF does the exact opposite.

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230110/60b6077c/attachment.sig>

From pete at petertodd.org  Tue Jan 10 10:06:22 2023
From: pete at petertodd.org (Peter Todd)
Date: Tue, 10 Jan 2023 05:06:22 -0500
Subject: [bitcoin-dev] Why Full-RBF Makes DoS Attacks on Multiparty
 Protocols Significantly More Expensive
In-Reply-To: <6089e1f0140684435bf5e87b0c13d561@dtrt.org>
References: <Y7ySzDjzx5eDjOH9@petertodd.org>
 <aaaeda2950e61127a3218c523927a0d8@dtrt.org>
 <Y70mNHsX4JcKYZyi@petertodd.org>
 <6089e1f0140684435bf5e87b0c13d561@dtrt.org>
Message-ID: <Y704non5DD5mtxs1@petertodd.org>

On Tue, Jan 10, 2023 at 12:02:35AM -1000, David A. Harding wrote:
> On 2023-01-09 22:47, Peter Todd wrote:
> > How do you propose that the participants learn about the double-spend?
> > Without
> > knowing that it happened, they can't respond as you suggested.
> 
> I can think of various ways---many of them probably the same ideas that
> would occur to you.

Rather than playing games, how about you actually list those ways.

> More concise than listing them is to just assume
> they exist and realize that any protocol software which wants to defeat
> the $17.00 pinning attack needs to implement some sort of conflict
> monitoring system---but by using that monitoring system to defeat the
> $17.00 pinning attack, the software also defeats the $0.05 individual
> conflicting input attack without any need for full-RBF.

Remember, we'd like decentralized coinjoin implementations like Joinmarket to
work. How does a decentralized coinjoin implement "conflict monitoring"?

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230110/7315ce24/attachment-0001.sig>

From dave at dtrt.org  Tue Jan 10 10:02:35 2023
From: dave at dtrt.org (David A. Harding)
Date: Tue, 10 Jan 2023 00:02:35 -1000
Subject: [bitcoin-dev] Why Full-RBF Makes DoS Attacks on Multiparty
 Protocols Significantly More Expensive
In-Reply-To: <Y70mNHsX4JcKYZyi@petertodd.org>
References: <Y7ySzDjzx5eDjOH9@petertodd.org>
 <aaaeda2950e61127a3218c523927a0d8@dtrt.org> <Y70mNHsX4JcKYZyi@petertodd.org>
Message-ID: <6089e1f0140684435bf5e87b0c13d561@dtrt.org>

On 2023-01-09 22:47, Peter Todd wrote:
> How do you propose that the participants learn about the double-spend? 
> Without
> knowing that it happened, they can't respond as you suggested.

I can think of various ways---many of them probably the same ideas that
would occur to you.  More concise than listing them is to just assume
they exist and realize that any protocol software which wants to defeat
the $17.00 pinning attack needs to implement some sort of conflict
monitoring system---but by using that monitoring system to defeat the
$17.00 pinning attack, the software also defeats the $0.05 individual
conflicting input attack without any need for full-RBF.

Full-RBF provides no benefits here except those which are already
provided by other necessary tools.

Thanks,

-Dave

From aj at erisian.com.au  Tue Jan 10 12:29:52 2023
From: aj at erisian.com.au (Anthony Towns)
Date: Tue, 10 Jan 2023 22:29:52 +1000
Subject: [bitcoin-dev] OP_VAULT: a new vault proposal
In-Reply-To: <CAPfvXfL65cneOabmxfOzTZq14xN4vXNaGboq_g15-frM14RqGA@mail.gmail.com>
References: <CAPfvXfL65cneOabmxfOzTZq14xN4vXNaGboq_g15-frM14RqGA@mail.gmail.com>
Message-ID: <Y71aQAxPXI+9C7rd@erisian.com.au>

On Mon, Jan 09, 2023 at 11:07:54AM -0500, James O'Beirne via bitcoin-dev wrote:
> But I also found proposed "general" covenant schemes to be
> unsuitable for this use. The bloated scriptPubKeys,

I don't think that makes sense? With a general scheme, you'd only be
bloating the witness data (perhaps including the witness script) not
the scriptPubKey?



Terminology suggestion: instead of calling it the "recovery" path,
call it "freezing your funds". Then you're using your "hot wallet" (aka
unvault-spk-hash) for the unvault path for all your normal transactions,
but if there's a problem, you freeze your funds, and they're now only
accessible via your "cold wallet" (aka recovery-spk-hash).



As I understand it, your scheme is:

  scriptPubKey: <vault tag> <#recovery> (<delay> <#unvault>)

where #recovery is the sha256 hashes of an arbitrary scriptPubKey,
#unvault is the sha256 hash of a witness script, and delay is a relative
block count.

This scriptPubKey allows for two spend paths:

  recovery: spends directly to <recovery>; verified by checking it
    the hash of the sPK matches <#recovery> and the amount it preserved

  unvaulting:
    spends to a scriptPubKey of <unvault tag> <#recovery> (<delay> <#target>)
    verified by checking that the witness script hashes to #unvault and
    is satisfied, and #target is a CTV-ish commitment of the eventual
    withdrawal (any CHECKSIG operations in the unvault witness script will
    commit to the sPK output, preventing this from being modified by
    third parties). #recovery and delay must match the values from the
    vault scriptPubKey.

The unvault scriptPubKey likewise likewise allows for two spend paths:

  recovery: same as above

  withdrawal:
    verifies that all the outputs hash to #target, and that nSequence
    is set to a relative timelock of at least delay.



This means that as soon as your recovery address (the preimage to
#recovery) is revealed, anyone can move all your funds into cold storage
(presuming they're willing to pay the going feerate to do so). I think
this is a feature, not a bug, though: if your hot wallet is compromised,
moving all your funds to cold storage is desirable; and if you want to
have different hot wallets with a single cold wallet, then you can use
a HD cold-wallet so that revealing one address corresponding to one hot
wallet, doesn't reveal the addresses corresponding to other hot wallets.
(This is addressed in the "Denial-of-service protection" section)

It does however mean that the public key for your cold wallet needs to
be handled secretly though -- if you take the cold wallet xpub and send
it to a random electrum server to check your cold wallet balance, that
would allow a malicious party to lock up all your funds.

I think it might be better to use a pay-to-contract construction for
the recovery path, rather than an empty witness. That is, take your
recovery address R, and calculate #recovery=sha256(R, sha256(secret))
(where "secret" is something derived from the R's private key, so that
it can be easily recovered if you only have your cold wallet and lose
all your metadata). When you want to recover all your funds to address R,
you reveal sha256(secret) in the witness data and R in the scriptPubKey,
OP_VAULT hashes these together and checks the result matches #recovery,
and only then allows it. That would allow you to treat R as public
knowledge, without risking your funds getting randomly frozen.



This construct allows delayed withdrawals (ie "the cold wallet can
withdraw instantly, the hot wallet can withdraw only after delay blocks"),
but I don't think it provides any way to cap withdrawals ("the cold
wallet can withdraw all funds, the hot wallet can only withdraw up to
X funds per day/week").  Having a fixed limit probably isn't compatible
with having a multi-utxo vault ("you can withdraw $10k per day" doesn't
help if your $5M is split across 500 $10k utxos, and the limit is only
enforced per-utxo), but I think a percentage limit would be.



I think a generic OP_UNVAULT can be used to simulate OP_CTV: replace
"<h> OP_CTV" with "<000..0> 0 <h> OP_UNVAULT". The paper seems to put
"OP_UNVAULT" first, but the code seems to expect it to come last, not
sure what's up with that inconsistency.

I'm not sure why you'd want a generic opcode though; if you want the
data to be visible in the scriptPubKey, you need to use a new segwit
version with structured data, anyway; so why not just do that?



I think there's maybe a cleverer way of batching / generalising checking
that input/output amounts match. That is, rather than just checking that
"the input's a vault; so the corresponding output must be one of these
possibilities, and the input/output values must exactly match", that
it's generalised to be:

  * set A = the sum of each input that's taking the unvaulting path 
    from a vault scriptPubKey with #recovery=X
  * set B = the sum of each output that has an unvault tag with
    #recovery=X
  * set C = the sum of each output that has a vault tag with
    #recovery=X
  * check that A=B+C

(That allows consolidation of your vault via your hot wallet, just by not
having any unvault outputs, so B=0. I suspect that if you allowed for
keyless consolidation of your vault, that that would be a griefing/DoS
vector)

This differs from the actual proposal, AIUI, which instead requires that
there are just two outputs - an ephemeral anchor for attaching fees, and
the primary vault or unvault output, and that all the inputs are
vaulting/unvaulting txs.

I think one meaningful difference between these two approaches is that
the current proposal means unvaulting locks up the entire utxo for the
delay period, rather than just the amount you're trying to unvault. eg,
if you have a single vault utxo X with 1000 BTC, you have delay set to
1008 blocks (1 week), and you decide on Tuesday that you wish to withdraw
50 BTC, creating an unvault tx spending 50 BTC somewhere and 950 BTC back
to your vault, you can't spend any of the 950 BTC for another two weeks:
one week for the unvault to confirm and it to go back into your vault,
and another week for the next unvault to confirm.

Changing the unvault construction to have an optional OP_VAULT output
would remedy that, I think.



It would be fairly dangerous to combine a construction like this (which
encourages the vault sPK to be reused) with APO signatures on the hot
wallet -- in that case the signature could just be replayed against a
different vault utxo, and you'd be paying for things twice. But provided
that vault spends are only (1) signed by the hot wallet, or (2) being
frozen and moved to the recovery sPK, then you should have complete
control over your utxos/coins, and using APO probably isn't interesting
anyway.



What would it look like to just hide all this under taproot?

First you'd just leave the internal pubkey as your cold wallet key
(or a NUMS point if your cold wallet is complicated).

Working backwards, your unvault output needs two script paths:

  1) move_funds_to(recovery-spk)
  2) <D> OP_CSV; move_funds_to(X)

Your vault output also needs two paths:

  1) move_funds_to(recovery-spk)
  2) hot-wallet-script; move_funds_to(unvault[X])

That obviously requires a "move_funds_to" operator, which, using
liquid's operators (roughly), could be something like:

  PUSHCURRENTINPUTINDEX
  DUP2 INSPECTINPUTVALUE SWAP INSPECTOUTVALUE EQUALVERIFY
  INSPECTOUTPUTSCRIPTPUBKEY "x" EQUAL

which is just ~8 bytes overhead, or could perhaps be something fancier
that supports the batching/consolidation abilities discussed above.

It also needs some way of constructing "unvault[X]", which could be a
TLUV-like construction.

That all seems possible to me; though certainly needs more work/thought
than just having dedicated opcodes and stuffing the data directly in
the sPK.

Cheers,
aj

From james.obeirne at gmail.com  Tue Jan 10 13:35:04 2023
From: james.obeirne at gmail.com (James O'Beirne)
Date: Tue, 10 Jan 2023 08:35:04 -0500
Subject: [bitcoin-dev] OP_VAULT: a new vault proposal
In-Reply-To: <CAPfvXfK=ykkFWEpRruudLBMt-DaUprFcF=XCJvQ65AFEbo0zpg@mail.gmail.com>
References: <CAPfvXfL65cneOabmxfOzTZq14xN4vXNaGboq_g15-frM14RqGA@mail.gmail.com>
 <8Uq3KNRWS_WV393lP9wq820PE8KNK0bhQ7u7hMJhIfdfV3-ZhSI-4q9Mw5P_TXivKtyePE2Exha4rso2yi3iNnLJpUpBQ38lAuwG-lQPVUE=@protonmail.com>
 <CAB3F3DsyN_Nj0Fs4LseiwxUE96tFt079qbb0hKBnTBZdyaPcSQ@mail.gmail.com>
 <CAPfvXfK=ykkFWEpRruudLBMt-DaUprFcF=XCJvQ65AFEbo0zpg@mail.gmail.com>
Message-ID: <CAPfvXfJSj_CbHW+F4WhrX+NNcEUV14NSKLzRcPR6DqQ0tav5KQ@mail.gmail.com>

Greg explained his suggestion to me off-list, and I think it's a good one.
To summarize, consider the normal "output flow" of an expected vault use:

(i) output to be vaulted
  => (ii) OP_VAULT output
    => (iii) OP_UNVAULT "trigger" output
      => (iv) final output

In my existing draft implementation, all outputs aside from (iii), the
OP_UNVAULT trigger, can be P2TR or P2WSH. In other words, those outputs can
hide their true script until spend. In my draft, the OP_UNVAULT trigger had
to be bare so that the script interpreter could inspect part of it for
validity: "does this OP_UNVAULT have the same <recovery-spk-hash> and
<spend-delay> as the OP_VAULT?"

If that output wasn't bare, because the <target-hash> is variable at the
time of OP_UNVAULT output creation, the script interpreter would have no
way of constructing the expected scriptPubKey.

Greg's suggestion would allow that output to be any kind of script. He
suggests to put the <target-hash> onto the witness stack when spending the
OP_VAULT output (and creating the OP_UNVAULT output). If we did that, the
script interpreter could e.g. use a NUMS point (i.e. a publicly known point
with no usable private key) to construct a Taproot configuration that looks
like

  tr(NUMS, {<OP_UNVAULT <recovery-key> <spend-delay> <target-hash>})

and check if the scriptPubKey of the proposed OP_UNVAULT output matches
that. This would allow all outputs in vault lifecycles to be P2TR, for
example, which would conceal the operation of the vault - a very nice
feature!

This would also allow the OP_VAULT/OP_UNVAULT opcodes to be implemented as
Taproot-only OP_SUCCESSx opcodes, if that was decided to be preferable.

The problem is how to (and whether to) enable something similar for witness
v0 outputs. For example, if we want the (ii) and (iii) output scripts to
live behind P2WSH. One (kind of hacky) option to enable this is to have the
script interpreter construct the expected OP_UNVAULT scriptPubKey on the
basis of what witness version it sees. For example, if it sees "OP_0 <32
bytes data>", it would use <target-hash> on the witness stack to construct
a fitting P2WSH scriptPubKey that is compatible with the OP_VAULT being
spent, and then match against that. But if it detects "OP_1 <32 bytes
data>", it would do the same process for an expected Taproot-with-NUMS
output.

---

Anyway, sorry if that was more verbose than necessary, but I think it's a
really great suggestion from Greg. I'll look at modifying the
implementation accordingly. I'd be curious to hear what others think as
well.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230110/c1b0d445/attachment.html>

From james.obeirne at gmail.com  Tue Jan 10 14:17:49 2023
From: james.obeirne at gmail.com (James O'Beirne)
Date: Tue, 10 Jan 2023 09:17:49 -0500
Subject: [bitcoin-dev] OP_VAULT: a new vault proposal
In-Reply-To: <CAPfvXfL65cneOabmxfOzTZq14xN4vXNaGboq_g15-frM14RqGA@mail.gmail.com>
References: <CAPfvXfL65cneOabmxfOzTZq14xN4vXNaGboq_g15-frM14RqGA@mail.gmail.com>
Message-ID: <CAPfvXfKRmhHBP8KTKsGCac4OTPydxXQPDv0LqeOrzXNxgZxfrQ@mail.gmail.com>

Forwarding in some conceptual feedback from the pull request.

>From ariard:

> I've few open questions, like if the recovery path should be committed
with a signature rather than protected by a simple scriptpubkey preimage.

That's something I've wondered about too. I have to ruminate on AJ's good
post about this, but a pretty straightforward way of enabling this (at the
expense of some complexity) is to do something like "if
<recovery-path-hash> is 32 bytes, treat it as it's currently used. If it's
33 bytes, use the first byte as a parameter for how to interpret it." To
start with, an extra prefix byte of 0x00 could mean "require a witness
satisfying the scriptPubKey that hashes to the remaining 32 bytes" in the
same way we do the unvault signing. This would enable a "sign-to-recover"
flow at the option of the user, specified during vault creation.

> The current OP_VAULT implementation is using OP_NOP repurposing but this
doesn't seem compatible with Taproot-only extensions (e.g ANYPREVOUT) and
maybe a OP_SUCCESS could be used.

Yes, with Greg's suggestion of putting <target-hash> on the witness stack
during OP_VAULT (-> OP_UNVAULT) spend, we could conceivably move
OP_VAULT/OP_UNVAULT into Taproot-only OP_SUCCESSx opcodes. I haven't
thought hard about how worthwhile it is to preserve the ability to use
OP_VAULT in pre-Taproot contexts.

> There is a conceptual wonder, if a CTV and template malleability approach
wouldn't better suit the vault use-case and allow other ones, as such
better re-usability of primitives.

I dedicated a whole section of the paper ("Precomputed vaults with
covenants") to explaining why precomputed covenant mechanisms have big
shortcomings for vaults.

That said, a number of people have commented about OP_VAULT's ability to
(inefficiently) emulate CTV. I'm still very supportive of CTV, I just don't
really have any uses I personally understand inside and out aside from
vaults... so if others do, they should really post about it on this list
and we should resume working on an activation for CTV!

---

>From naumenkogs:

> I'm personally not sure batching withdrawals is that compelling... It's a
nice-to-have, but I'd think about the benefits dropping this feature would
provide.

Having familiarity with a few large-scale custodial operations, I think
batching is a really big deal. And if you're going to support multiple
deposits to the same vault, no support for batching is going to result in a
lot of unnecessary output creation even as a small user if you're, e.g.,
doing weekly automated deposits from an exchange to a vault you've
configured.

Darosior comments:

> On the contrary i think the batching feature is very compelling. The
impossibility to batch Unvaults in Revault is a major drawback: it
significantly increases the cost of any realistic operation (you need one
whole additional transaction per input, and each have likely more than one
output). It also potentially increases the cost on the network (you'd
likely want some sort of anchor output on each Unvault tx, that you might
not spend, so that's 2*n outputs created with n the number of coins spent):
we definitely don't want to prevent batching. The ability to batch the
recovery transactions (what we called Emergency tx in Revault) is also very
compelling but i think your comment was only about batched withdrawals.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230110/de2020d1/attachment-0001.html>

From dave at dtrt.org  Tue Jan 10 20:14:47 2023
From: dave at dtrt.org (David A. Harding)
Date: Tue, 10 Jan 2023 10:14:47 -1000
Subject: [bitcoin-dev] Why Full-RBF Makes DoS Attacks on Multiparty
 Protocols Significantly More Expensive
In-Reply-To: <Y704non5DD5mtxs1@petertodd.org>
References: <Y7ySzDjzx5eDjOH9@petertodd.org>
 <aaaeda2950e61127a3218c523927a0d8@dtrt.org> <Y70mNHsX4JcKYZyi@petertodd.org>
 <6089e1f0140684435bf5e87b0c13d561@dtrt.org> <Y704non5DD5mtxs1@petertodd.org>
Message-ID: <6cebd312ca960e634729cc574c2e97b0@dtrt.org>

On 2023-01-10 00:06, Peter Todd wrote:
> Remember, we'd like decentralized coinjoin implementations like 
> Joinmarket to
> work. How does a decentralized coinjoin implement "conflict 
> monitoring"?

1. Run a relay node with a conflict-detection patch.  Stock Bitcoin Core
    with -debug=mempoolrej will tell you when it rejects a transaction
    for conflicting with a transaction already in the mempool, e.g.:

       2022-11-01T02:53:17Z 
867b85d68d7a7244c1d65c4797006b56973110ac243ab5ee15a8c4d220060c58 from 
peer=58 was not accepted: txn-mempool-conflict

    I think it would be easy to extend this facility to list the inputs
    which conflicted.  So if Alice sees a conflict created by Mallory,
    she can create a new coinjoin transaction without Mallory.  This
    method has the advantage of being fast and attributing fault,
    although it does require Alice's node be online at the time Mallory's
    conflict is propagated.

2. Simply assume a conflict exists for otherwise unexplainable failures.
    For example, if Alice sees several new blocks whose bottom feerates
    are well below the feerates of an unconfirmed coinjoin transaction
    that Alice helped create and broadcast, she can assume it's a
    conflict that is preventing preventing confirmation of the coinjoin.
    She can find an entirely different set of collaborators and create a
    non-conflicting transaction without ever needing to know which inputs
    from the original transaction conflicted.  This method has the
    disadvantage of being slow (on the order of hours) and not 
attributing
    fault, although it doesn't require Alice has any information beyond 
copies
    of recent blocks.

I didn't list these methods or others before because the specific method 
used to
detect conflicts doesn't matter to the realization that software which
uses conflict detection and evasion to defeat the $17.00 attack also
defeats the $0.05 attack without any need for full-RBF.

-Dave

From james.obeirne at gmail.com  Tue Jan 10 20:22:54 2023
From: james.obeirne at gmail.com (James O'Beirne)
Date: Tue, 10 Jan 2023 15:22:54 -0500
Subject: [bitcoin-dev] OP_VAULT: a new vault proposal
In-Reply-To: <Y71aQAxPXI+9C7rd@erisian.com.au>
References: <CAPfvXfL65cneOabmxfOzTZq14xN4vXNaGboq_g15-frM14RqGA@mail.gmail.com>
 <Y71aQAxPXI+9C7rd@erisian.com.au>
Message-ID: <CAPfvXfJSJwJ=0wYev7RDBzvgoi5D3HS8sjKqMxM9wcuh3FHvGw@mail.gmail.com>

Thanks for the thoughtful reply AJ.


> I don't think that makes sense? With a general scheme, you'd only be
> bloating the witness data (perhaps including the witness script) not
> the scriptPubKey?

Sorry, sloppy language on my part. To be charitable, I'm talking about
the "figurative sPK," which of course these days lives in the witness
for script-path-ish spends. Maybe the witness discount means that
"complicated" scripts aren't as big a deal, depending on the actual
difference in raw script size.


> I think it might be better to use a pay-to-contract construction for
> the recovery path, rather than an empty witness.

So I guess the one advantage that what you're proposing has over just
using a recovery-path key signature is that it's all derivable from your
cold privkey; you don't have to worry about accidentally losing the
recovery-path key.

Of course you're still vulnerable to spurious sweeps if the
sha256(secret) value gets found out, which presumably you'd want in an
accessible cache to avoid touching the cold secret every time you want
to sweep.

What do you think about the idea of making the recovery-path
authorization behavior variable on a single byte flag preceding the 32
byte data push, as I mentioned in another post? I think it may make
sense to leave this option open to end-users (and also allow for some
upgradeability).


> I think a generic OP_UNVAULT can be used to simulate OP_CTV: replace
> "<h> OP_CTV" with "<000..0> 0 <h> OP_UNVAULT".

Yup, that's an inefficient way of emulating CTV. If people want CTV, we
should just look at activating CTV. Greg Sanders has a thing about
"jetting" CTV into this proposal (I think) so that the code-paths are
shared, but I haven't figured out how that would work. They really
don't share that much code AFAICT.


> The paper seems to put "OP_UNVAULT" first, but the code seems to
> expect it to come last, not sure what's up with that inconsistency.

Again some sloppy notation on my part. What I sort of meant in the paper
was a kind of functional notation `OP_VAULT(param1, param2, ...)`. Let's
chalk that up to my inexperience actually working on script stuff.


> I think there's maybe a cleverer way of batching / generalising
> checking that input/output amounts match.
>
> [...]
>
>  * set C = the sum of each output that has a vault tag with
>    #recovery=X

This would also need to take into account that the <spend-delay>s are
compatible, but your point is well taken.


> I think one meaningful difference between these two approaches is that
> the current proposal means unvaulting locks up the entire utxo for the
> delay period, rather than just the amount you're trying to unvault.

This is a really good point and I think is one that's important to
incorporate with a change to the existing proposal.

A simple fix for facilitating the use of a "partial revault" while the
OP_UNVAULT UTXO is outstanding would be to allow for an optional
third output that is a redeposit back to the identical OP_VAULT sPK that
is being spent by the OP_UNVAULT transaction, then the script
interpreter would just ensure that the nValue of those two outputs sums
to the sum of the input nValues.

I can see what you're saying about having more generic "group amounts by
compatible vault params, and then compare to similarly grouped outputs,"
but I'm just wondering if there are other uses that enables besides the
partial-revault thing I mentioned above. If not, I'd probably rather just
stick
with something simple like having the third optional re-vault output.


> Changing the unvault construction to have an optional OP_VAULT output
> would remedy that, I think.

Oh - okay, this is what you're saying. Right!

Is that a sufficient change, or are there other benefits that the more
complicated clever-I/O-vault-grouping would enable that you have in
mind?


> What would it look like to just hide all this under taproot?
>
> [...]
>
> It also needs some way of constructing "unvault[X]", which could be a
> TLUV-like construction.
>
> That all seems possible to me; though certainly needs more work/thought
> than just having dedicated opcodes and stuffing the data directly in
> the sPK.

I think this is a very important comparison to do, but I'm eager to see
code for things like this. There have been a lot of handwavey proposals
lately without tangible code artifacts. I'm eager to see what these
alternatives look like in practice - i.e. in functional tests.


Thanks again for the great mail.
James
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230110/a5579378/attachment.html>

From aj at erisian.com.au  Wed Jan 11 06:52:28 2023
From: aj at erisian.com.au (Anthony Towns)
Date: Wed, 11 Jan 2023 16:52:28 +1000
Subject: [bitcoin-dev] OP_VAULT: a new vault proposal
In-Reply-To: <CAPfvXfJSJwJ=0wYev7RDBzvgoi5D3HS8sjKqMxM9wcuh3FHvGw@mail.gmail.com>
References: <CAPfvXfL65cneOabmxfOzTZq14xN4vXNaGboq_g15-frM14RqGA@mail.gmail.com>
 <Y71aQAxPXI+9C7rd@erisian.com.au>
 <CAPfvXfJSJwJ=0wYev7RDBzvgoi5D3HS8sjKqMxM9wcuh3FHvGw@mail.gmail.com>
Message-ID: <Y75crCH6THK98oee@erisian.com.au>

On Tue, Jan 10, 2023 at 03:22:54PM -0500, James O'Beirne wrote:
> > I don't think that makes sense? With a general scheme, you'd only be
> > bloating the witness data (perhaps including the witness script) not
> > the scriptPubKey?
> Sorry, sloppy language on my part. To be charitable, I'm talking about
> the "figurative sPK," which of course these days lives in the witness
> for script-path-ish spends. Maybe the witness discount means that
> "complicated" scripts aren't as big a deal, depending on the actual
> difference in raw script size.

Sure. I think there's three aspects that matter for the witness script:

 1) it shouldn't be long/costly to do things that are common and easy:
    if you can express "OP_VAULT" in ~70 bytes, you shouldn't have to
    spend 1000 bytes to do so; if it can be cheap to validate, you
    shouldn't have to pay 100x markup in fees to use it. With the
    exception of things that build up from basics (like
    CAT/CHECKSIGFROMSTACK approaches), I think this is mostly fine
    though.

 2) once someone figures out a design, it should be easy to reuse;
    but I think that's not a big deal: you just write up a spec for
    your script, and people use that in their different wallet software,
    much like the specialised scripts for lightning HTLCs

 3) primitives should be designed to be easy to safely build on and
    scripts should be as easy as possible to analyse once written;
    ie, we want things more like miniscript than "The story of Mel,
    a Real Programmer"

With some caveats (like that using the cold wallet xpub to scan the
blockchain before you've frozen all your funds is dangerous), OP_VAULT
seems really good on all those fronts, of course.

> > I think it might be better to use a pay-to-contract construction for
> > the recovery path, rather than an empty witness.
> So I guess the one advantage that what you're proposing has over just
> using a recovery-path key signature is that it's all derivable from your
> cold privkey; you don't have to worry about accidentally losing the
> recovery-path key.
> Of course you're still vulnerable to spurious sweeps if the
> sha256(secret) value gets found out, which presumably you'd want in an
> accessible cache to avoid touching the cold secret every time you want
> to sweep.

Sure, "sha256(secret)" itself needs to be semi-secret -- it allows anyone
who knows it to freeze your funds, even if it doesn't allow anyone to
steal them. You could presumably do all the usual things to protect that
secret: split it up with secret sharing; put it in a hardware wallet;
keep it offline; etc.

> What do you think about the idea of making the recovery-path
> authorization behavior variable on a single byte flag preceding the 32
> byte data push, as I mentioned in another post?

] "if
] <recovery-path-hash> is 32 bytes, treat it as it's currently used. If it's
] 33 bytes, use the first byte as a parameter for how to interpret it." To
] start with, an extra prefix byte of 0x00 could mean "require a witness
] satisfying the scriptPubKey that hashes to the remaining 32 bytes" in the
] same way we do the unvault signing.

I don't think 33 bytes would be enough? There isn't really a way to
commit to the recovery destination within the script? So I think you'd
need "<32 byte recovery-path-hash><n byte scriptPubKey>"

Aside from that, my opinion's one/all of:

a) sounds fine

b) maybe you could just always have it include a scriptPubKey? for the
times when you just want "reveal the cold wallet preimage" just have
the scriptPubKey be the single byte "OP_TRUE"; for the times when you
it to be "reveal random preimage" you'd have it be the 22 byte "HASH160
<hash160(sha256(secret))> EQUAL"?

c) delegation to a script is a great idea, that's come up multiple times
(OP_EVAL, BIP117, graftroot) -- it's probably better to have it
available as a generic feature, than bolted on to particular features

> > I think a generic OP_UNVAULT can be used to simulate OP_CTV: replace
> > "<h> OP_CTV" with "<000..0> 0 <h> OP_UNVAULT".
> Yup, that's an inefficient way of emulating CTV.

Sure; I think it's only interesting in establishing how powerful the
construct is in the abstract. It's not an exact match for CTV since it
hashes some things differently.

I don't really think it's necessarily that inefficient fwiw; "0 SHA256
0 <h> UNVAULT" is only 3 more bytes than "<h> CTV", could give you an
unspendable recovery path, provided UNVAULT wants either a BIP341 tagged
hash (which is what the implementation does, by the looks), or a HASH256
for the recovery path.

(Again, this assumes UNVAULT is available in script, and isn't just a
special scriptPubKey type)

> > I think there's maybe a cleverer way of batching / generalising
> > checking that input/output amounts match.
> > [...]
> >  * set C = the sum of each output that has a vault tag with
> >    #recovery=X
> This would also need to take into account that the <spend-delay>s are
> compatible, but your point is well taken.

Sure, I guess output/UNVAULT delay >= input/VAULT delay would be
sufficient for that.

I guess having all that stuff exposed in the scriptPubKey would be
slightly annoying for griefing -- you set your wallet delay to be 1008
blocks, and someone sends to your vault with a 1007 block delay, or a
6 block delay: does your wallet notice the tx? if it does, what do you
do with those funds?

Maybe that would be a(nother) good reason to hide the OP_VAULT side of
things in taproot (or p2wsh): then you just have a (shorter) taproot
sPK that encodes both things, and people normally don't even have enough
information to correctly tweak your sPK to have a different delay.

> I can see what you're saying about having more generic "group amounts by
> compatible vault params, and then compare to similarly grouped outputs,"

I mostly wrote that up because that's what I imagined your batching
doing before I'd finished reading...

A big disadvantage of that approach compared to yours is that you have
to analyse a potentially arbitrarily large transaction as a whole while
validating each input -- this input uses recovery key XXX which output's
match; this input uses recovery key YYY; oh, this one uses XXX again;
etc. With your approach, you only have to look at particular outputs.

An advantage of that extra complexity is that you could combine operations
from multiple different vaults into a single transaction, potentially
along with fees or a coinjoin or whatever else. Maybe that would be
interesting if this were something you could code in script via some
generic opcodes; but here it would be extra complexity in consensus code,
and it doesn't seem like a good match for OP_VAULT's design parameters.

Cheers,
aj

From aj at erisian.com.au  Wed Jan 11 08:00:14 2023
From: aj at erisian.com.au (Anthony Towns)
Date: Wed, 11 Jan 2023 18:00:14 +1000
Subject: [bitcoin-dev] SIGHASH_GROUP vs Ephemeral anchors
Message-ID: <Y75sjuTjsJNT6M7I@erisian.com.au>

Hello world,

I think it's interesting to compare SIGHASH_GROUP [0] and Ephemeral
anchors [1].

[0] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-July/019243.html
[1] https://github.com/bitcoin/bitcoin/pull/26403

SIGHASH_GROUP is the idea that you provide a way for the inputs of a
transaction to divide the outputs of a transaction into non-overlapping
groups. So input 1 can specify "I'm starting a group of 3 outputs",
input 2 can specify "I'm using the same group as the previous input",
input 3 can specify "I'm starting a group of 2 outputs"; and each input
can use the SIGHASH_GROUP flag to specify their signature is signing
for the subgroup they've specified, rather than just a single output,
or all of them.

The idea behind this is that then you can use a signature to link a
set of inputs and outputs via a signature in a way that's more general
than SIGHASH_ANYONECANPAY (since you can have many inputs attesting to
the same subset of outputs), SIGHASH_SINGLE (since you can attest to
multiple outputs), and SIGHASH_ALL (since you don't have to attest to
all outputs). This means that (eg) you can have a tx closing a lightning
channel commit to a dozen outputs that specify where the channel's funds
end up, but are also able to add additional inputs to cover fees, and
additional outputs to collect the change from those fees.

Ephemeral anchors, by contrast, are just a realy policy level rule that a
transaction may create a single 0-value output with sPK of OP_TRUE (the
"ephemeral anchor"), and that that tx won't be rejected as being dust,
provided that the tx that introduces the anchor pays 0 fees (so it is not
profitable to mine on its own) and that it's relayed as a package with
another tx that spends that anchor. (And there are additional proposed
rules beyond those)

To some degree, this provides an alternative way of getting the same
benefits of SIGHASH_GROUP: if you were constructing a transaction
consisting of {i1,i2,i3,i4,f} -> {o1,o2,o3,c} with {i1,i2,i3} committing to
{o1} and {i4} committing to {o2,o3} and f providing the fees with c
collecting the change, you could instead create three transactions:

   {i1,i2,i3} -> {o1, eph1}
   {i4} -> {o2,o3, eph2}
   {eph1, eph2, f} -> {c}

(where eph1/eph2 are ephemeral anchors) and instead of signing with
SIGHASH_GROUP, you'd just sign with SIGHASH_ALL.

(This is likewise similar to the "sponsored transactions" concept [2],
where a transaction may "sponsor" another transaction, meaning it cannot
be included in a block unless the transaction it sponsors is also included
in the block. Given the "txs-may-only-have-one-sponsor" rule, ephemeral
anchors could be considered as "you can design a tx that always has a
sponsor, or never has a sponsor")

[2] https://bitcoinops.org/en/newsletters/2020/09/23/#transaction-fee-sponsorship

Ephemeral anchors aren't a complete replacement for SIGHASH_GROUP --
if i1 had two signatures, one signing with SIGHASH_GROUP, but the other
signing with SIGHASH_ALL, then it's difficult to duplicate that behaviour
exactly with ephemeral anchors. However, it's likely the only benefit
to using SIGHASH_ALL there is to reduce malleability risk, and ephemeral
anchors probably already achieve that.

Additionally, if the value of i1+i2+i3 was less than o1 or i4 was less
than o2+o3, then the introduction of f is too late to compensate for
that with ephemeral anchors, but would have been fine with SIGHASH_GROUP.

The detailed proposed rules for ephemeral anchors as they stand are,
I think:

> A transaction with one or more CScript([OP_2]) output MUST:
>  eph.1) Be 0-fee
>  eph.2) Have [the ephemeral anchor output] spent in the same memppol relay
>         package
>  eph.3) Be nversion==3
>  eph.4) Must not have more than one [such output]

 - https://github.com/bitcoin/bitcoin/pull/26403/commits/431a5e3e0376d8bf55563a0168e79dd73b04a1f8

And implied by "nversion==3":

> v3.1) A V3 transaction can be replaced, [...]
> v3.2) Any descendant of an unconfirmed V3 transaction must also be V3.
> v3.3) A V3 transaction's unconfirmed ancestors must all be V3.
> v3.4) A V3 transaction cannot have more than 1 descendant.
> v3.5) A V3 transaction that has an unconfirmed V3 ancestor cannot be
>    larger than 1000 virtual bytes.
> v3.4b) A V3 transaction cannot have more than 1 ancestor

 - https://github.com/bitcoin/bitcoin/blob/0c089a327a70d16f824b1b4dfd029d260cc43f09/doc/policy/version3_transactions.md

The v3.4b rule unfortunately prevents ephemeral anchors from being used
to provide fees for multiple input/output groups in the way I suggest
above. That's intended to prevent attaching large ancestors to a package,
allowing the descendent to be high fee / low feerate, thus preventing
that descendant from both being replaced (due to requiring a higher
absolute fee) and mined (due to having a low fee rate). (I suspect the
only way to remove that restriction without reinstating the pinning
vector is to allow replacements that have a higher fee rate, even though
they have a lower absolute fee)

Anyway, in theory, I think ephemeral anchors get most of the potential
benefits of SIGHASH_GROUP, particularly if the (v3.4b) rule can be removed
or loosened somehow. And it's obviously much less costly to implement:
it's relay policy only, rather than a consensus change; and it only
operates at the transaction level, so we don't have to start worrying
about pinning of inputs vs whole transactions.

Cheers,
aj


From antoine.riard at gmail.com  Thu Jan 12 02:06:21 2023
From: antoine.riard at gmail.com (Antoine Riard)
Date: Wed, 11 Jan 2023 21:06:21 -0500
Subject: [bitcoin-dev] SIGHASH_GROUP vs Ephemeral anchors
In-Reply-To: <Y75sjuTjsJNT6M7I@erisian.com.au>
References: <Y75sjuTjsJNT6M7I@erisian.com.au>
Message-ID: <CALZpt+E4pjhhCkVNs9aoU7DrtzXPnV-RC_yDXTw+q=ehta7kVw@mail.gmail.com>

Hi AJ,

> The idea behind this is that then you can use a signature to link a
> set of inputs and outputs via a signature in a way that's more general
> than SIGHASH_ANYONECANPAY (since you can have many inputs attesting to
> the same subset of outputs), SIGHASH_SINGLE (since you can attest to
> multiple outputs), and SIGHASH_ALL (since you don't have to attest to
> all outputs). This means that (eg) you can have a tx closing a lightning
> channel commit to a dozen outputs that specify where the channel's funds
> end up, but are also able to add additional inputs to cover fees, and
> additional outputs to collect the change from those fees.

To precise more one of the use-case for SIGHASH_GROUP, you can have one LSP
with hundreds of Lightning channels opened with as much (mobile)
counterparties, of which the majority are probably offline most of their
times to aggregate the LN commitment transaction in a single bundle with
one pair of input/output. Aggregation should be non-interactive,
fee-savings from a L2 viewpoint would be all the saved anchor outputs,
blockspace-savings from a full-node viewpoint would be those same anchor
outputs.

> To some degree, this provides an alternative way of getting the same
> benefits of SIGHASH_GROUP: if you were constructing a transaction
> consisting of {i1,i2,i3,i4,f} -> {o1,o2,o3,c} with {i1,i2,i3} committing
to
> {o1} and {i4} committing to {o2,o3} and f providing the fees with c
> collecting the change, you could instead create three transactions:
>
>    {i1,i2,i3} -> {o1, eph1}
>    {i4} -> {o2,o3, eph2}
>    {eph1, eph2, f} -> {c}

I think here a SIGHASH_GROUP-like would be: {i1, i2, i3, i4 i.f, o1, o2,
o3, o.f}. Where `i.f` is the input for feeding external value in the
bundle, `o.f` the output for output fees.

Compared to anchors, I believe you're saving 1-input/2-outputs of fees for
a construction expressing the same semantics ?

> However, it's likely the only benefit to using SIGHASH_ALL there is to
reduce
> malleability risk, and ephemeral anchors probably already achieve that.

If my understanding is correct with ephemeral anchors, we allow third-party
malleability (i.e a entity not owning any key in the funding channel
output) of the chain of transactions. If nversion=3 is robust against
"classic" pinnings at the commitment
transaction-level by a counterparty (scenario 2b in [0] iirc), it should
hold against external parties. However, it might introduce issues, where a
common CPFP is conflicted on one of its input, e.g in the example above
eph1 is replaced by  malicious better fee/feerate eph1', cancelling {i4,
o2, o3} fee-bumping.

[0]
https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-June/002758.html

> The v3.4b rule unfortunately prevents ephemeral anchors from being used
> to provide fees for multiple input/output groups in the way I suggest
> above

See point above, as providing fees for multiple input/output groups *might*
be unsafe, so I think this is a limited downside anyway.

> (I suspect the only way to remove that restriction without reinstating
the pinning
> vector is to allow replacements that have a higher fee rate, even though
> they have a lower absolute fee)

>From my memory, I think this is correct -- Though now you're introducing
the issue where one might be able to downgrade the fee content of your
miner mempool in a period of emptiness. However, I believe if we move to a
higher fee rate only, it might make
the cost of the replacement issue above.

> Anyway, in theory, I think ephemeral anchors get most of the potential
> benefits of SIGHASH_GROUP, particularly if the (v3.4b) rule can be removed
> or loosened somehow. And it's obviously much less costly to implement:
> it's relay policy only, rather than a consensus change; and it only
> operates at the transaction level, so we don't have to start worrying
> about pinning of inputs vs whole transactions.

Yes I think the only clear benefit of SIGHASH_GROUP over ephemeral anchors
is the fee/blockspace savings for some types of LN deployments. Comes at
far higher engineering resources as it's a consensus change rather than
relay policy only. However, in the future, if it is combined with other
changes like malleability of the output amounts, it could unlock use-cases
like "dynamic value reallocation" from unknown initial sending.

Best,
Antoine

Le mer. 11 janv. 2023 ? 03:00, Anthony Towns via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> a ?crit :

> Hello world,
>
> I think it's interesting to compare SIGHASH_GROUP [0] and Ephemeral
> anchors [1].
>
> [0]
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-July/019243.html
> [1] https://github.com/bitcoin/bitcoin/pull/26403
>
> SIGHASH_GROUP is the idea that you provide a way for the inputs of a
> transaction to divide the outputs of a transaction into non-overlapping
> groups. So input 1 can specify "I'm starting a group of 3 outputs",
> input 2 can specify "I'm using the same group as the previous input",
> input 3 can specify "I'm starting a group of 2 outputs"; and each input
> can use the SIGHASH_GROUP flag to specify their signature is signing
> for the subgroup they've specified, rather than just a single output,
> or all of them.
>
> The idea behind this is that then you can use a signature to link a
> set of inputs and outputs via a signature in a way that's more general
> than SIGHASH_ANYONECANPAY (since you can have many inputs attesting to
> the same subset of outputs), SIGHASH_SINGLE (since you can attest to
> multiple outputs), and SIGHASH_ALL (since you don't have to attest to
> all outputs). This means that (eg) you can have a tx closing a lightning
> channel commit to a dozen outputs that specify where the channel's funds
> end up, but are also able to add additional inputs to cover fees, and
> additional outputs to collect the change from those fees.
>
> Ephemeral anchors, by contrast, are just a realy policy level rule that a
> transaction may create a single 0-value output with sPK of OP_TRUE (the
> "ephemeral anchor"), and that that tx won't be rejected as being dust,
> provided that the tx that introduces the anchor pays 0 fees (so it is not
> profitable to mine on its own) and that it's relayed as a package with
> another tx that spends that anchor. (And there are additional proposed
> rules beyond those)
>
> To some degree, this provides an alternative way of getting the same
> benefits of SIGHASH_GROUP: if you were constructing a transaction
> consisting of {i1,i2,i3,i4,f} -> {o1,o2,o3,c} with {i1,i2,i3} committing to
> {o1} and {i4} committing to {o2,o3} and f providing the fees with c
> collecting the change, you could instead create three transactions:
>
>    {i1,i2,i3} -> {o1, eph1}
>    {i4} -> {o2,o3, eph2}
>    {eph1, eph2, f} -> {c}
>
> (where eph1/eph2 are ephemeral anchors) and instead of signing with
> SIGHASH_GROUP, you'd just sign with SIGHASH_ALL.
>
> (This is likewise similar to the "sponsored transactions" concept [2],
> where a transaction may "sponsor" another transaction, meaning it cannot
> be included in a block unless the transaction it sponsors is also included
> in the block. Given the "txs-may-only-have-one-sponsor" rule, ephemeral
> anchors could be considered as "you can design a tx that always has a
> sponsor, or never has a sponsor")
>
> [2]
> https://bitcoinops.org/en/newsletters/2020/09/23/#transaction-fee-sponsorship
>
> Ephemeral anchors aren't a complete replacement for SIGHASH_GROUP --
> if i1 had two signatures, one signing with SIGHASH_GROUP, but the other
> signing with SIGHASH_ALL, then it's difficult to duplicate that behaviour
> exactly with ephemeral anchors. However, it's likely the only benefit
> to using SIGHASH_ALL there is to reduce malleability risk, and ephemeral
> anchors probably already achieve that.
>
> Additionally, if the value of i1+i2+i3 was less than o1 or i4 was less
> than o2+o3, then the introduction of f is too late to compensate for
> that with ephemeral anchors, but would have been fine with SIGHASH_GROUP.
>
> The detailed proposed rules for ephemeral anchors as they stand are,
> I think:
>
> > A transaction with one or more CScript([OP_2]) output MUST:
> >  eph.1) Be 0-fee
> >  eph.2) Have [the ephemeral anchor output] spent in the same memppol
> relay
> >         package
> >  eph.3) Be nversion==3
> >  eph.4) Must not have more than one [such output]
>
>  -
> https://github.com/bitcoin/bitcoin/pull/26403/commits/431a5e3e0376d8bf55563a0168e79dd73b04a1f8
>
> And implied by "nversion==3":
>
> > v3.1) A V3 transaction can be replaced, [...]
> > v3.2) Any descendant of an unconfirmed V3 transaction must also be V3.
> > v3.3) A V3 transaction's unconfirmed ancestors must all be V3.
> > v3.4) A V3 transaction cannot have more than 1 descendant.
> > v3.5) A V3 transaction that has an unconfirmed V3 ancestor cannot be
> >    larger than 1000 virtual bytes.
> > v3.4b) A V3 transaction cannot have more than 1 ancestor
>
>  -
> https://github.com/bitcoin/bitcoin/blob/0c089a327a70d16f824b1b4dfd029d260cc43f09/doc/policy/version3_transactions.md
>
> The v3.4b rule unfortunately prevents ephemeral anchors from being used
> to provide fees for multiple input/output groups in the way I suggest
> above. That's intended to prevent attaching large ancestors to a package,
> allowing the descendent to be high fee / low feerate, thus preventing
> that descendant from both being replaced (due to requiring a higher
> absolute fee) and mined (due to having a low fee rate). (I suspect the
> only way to remove that restriction without reinstating the pinning
> vector is to allow replacements that have a higher fee rate, even though
> they have a lower absolute fee)
>
> Anyway, in theory, I think ephemeral anchors get most of the potential
> benefits of SIGHASH_GROUP, particularly if the (v3.4b) rule can be removed
> or loosened somehow. And it's obviously much less costly to implement:
> it's relay policy only, rather than a consensus change; and it only
> operates at the transaction level, so we don't have to start worrying
> about pinning of inputs vs whole transactions.
>
> Cheers,
> aj
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230111/46655b50/attachment.html>

From alicexbt at protonmail.com  Tue Jan 10 09:19:39 2023
From: alicexbt at protonmail.com (alicexbt)
Date: Tue, 10 Jan 2023 09:19:39 +0000
Subject: [bitcoin-dev] Why Full-RBF Makes DoS Attacks on Multiparty
	Protocols Significantly More Expensive
In-Reply-To: <Y7ySzDjzx5eDjOH9@petertodd.org>
References: <Y7ySzDjzx5eDjOH9@petertodd.org>
Message-ID: <OwgJwjPrZWRtBaIDDZ8g-xbFPlryUXUopqUuKYVUNE-mVHzCWHFXl77YzDlItEjHTHcGjpzIC5alGsnFEsOtSgHLm9We92gcWrLTahzPGFk=@protonmail.com>

Hi Peter,

> ## How Full-RBF Mitigates the Double-Spend DoS Attack
> 
> Modulo tx-pinning, full-rbf mitigates the double-spend DoS attack in a very
> straightforward way: the low fee transaction is replaced by the higher fee
> transaction, resulting in the latter getting mined in a reasonable amount of
> time and the protocol making forward progress.

Asking this question based on a [discussion on twitter][0]. How would you get extra sats to increase the fees? It seems this would be possible with Joinmarket, Wasabi and even joinstr although things would get worse for Whirlpool. Whirlpool coinjoin transactions do not signal BIP 125 RBF so they were not replaceable earlier, however attacker would be able to perform DoS attacks now by double spending their inputs used in coinjoin.

[0]: https://twitter.com/dammkewl/status/1599692908860706818

/dev/fd0
floppy disc guy

Sent with Proton Mail secure email.

------- Original Message -------
On Tuesday, January 10th, 2023 at 3:48 AM, Peter Todd via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:


> I was reminded recently that while Suhas Daftuar cited tx-pinning as a reason
> to remove full-rbf, he neglected to mention that tx-pinning greatly increases
> the cost of attacks on multi-party protocols. Him (rhetorically?) asking(4):
> 
> "Does fullrbf offer any benefits other than breaking zeroconf business
> practices?"
> 
> ...has caused a lot of confusion by implying that there were no benefits. So
> I'm writing this to set the record straight and provide an easily cited
> explanation as to why full-rbf - even with tx-pinning - is a valuable
> improvement for multi-party protocols like coinjoins that rely on transactions
> containing multiple inputs exclusively controlled(1) by different parties.
> 
> tl;dr: without full-rbf people can intentionally and unintentionally DoS attack
> multi-party protocols by double-spending their inputs with low-fee txs, holding
> up progress until that low-fee tx gets mined. This could take days, weeks, or
> even worse. Modulo intentional tx-pinning, full-RBF fixes this by ensuring that
> a higher fee transaction gets mined in a reasonable amount of time so the
> protocol makes forward progress. And as for tx-pinning, exploiting it is very
> expensive, so full-rbf still makes the situation much better than the status
> quo.
> 
> 
> # The Double-Spend DoS Attack on Multi-Party, Multi-Input, Transactions
> 
> If a protocol constructs transactions containing multiple inputs exclusively
> controlled by different parties, those parties can intentionally and
> unintentionally double-spend those inputs in alternate transactions. For
> example, in a Wasabi coinjoin any one of the hundreds of participants could
> sign and broadcast a transaction spending their input. If they do that at the
> right time, as much as ~100% of the hashing power may see the double-spend
> first, prior to the intended coinjoin transaction. This in fact does happen
> regularly in production to Wasabi coinjoins, probably due to people
> accidentally running different wallets at the same time using the same seed, as
> well as people importing their seeds into alternative wallets.
> 
> By itself this isn't a significant problem: Wasabi coinjoins are a two phase
> protocol, and, like any multi-step, multi-party protocol, they have to deal
> with the fact that participants in the protocol may fail to complete all the
> steps necessary for a transaction to be completed. It's very common for one or
> more parties in a Wasabi coinjoin to fail to complete both steps of the
> protocol, and a majority of Wasabi coinjoin rounds fail. Wasabi deals with this
> economically by (temporarily or ~permanently) blacklisting UTXOs that failed to
> complete a round, making DoS attacks expensive by forcing the attacker to tie
> up funds/create new UTXOs.
> 
> Similarly, in use-cases such as multi-party-funded Lightning channels(5), an
> attacker can always DoS attack the protocol by participating in a channel open,
> and then failing to allow payments to be routed through it. The solution is
> again to use economics to ensure the attack is sufficiently costly.
> 
> However, under the right circumstances double-spends are an unusually powerful
> DoS attack on multi-party, multi-input, transaction. When mempool demand is
> high, low fee transactions can take arbitrarily long to get mined. Bitcoin has
> seen periods of mempool demand where low-fee transactions would take months
> to get mined. Transaction expiry does not solve this problem, as anyone can
> rebroadcast transactions at any time. In these circumstances without
> transaction replacement a multi-party transaction such as a Wasabi coinjoin
> could be held up indefinitely by a low-fee double-spend.
> 
> 
> ## How Full-RBF Mitigates the Double-Spend DoS Attack
> 
> Modulo tx-pinning, full-rbf mitigates the double-spend DoS attack in a very
> straightforward way: the low fee transaction is replaced by the higher fee
> transaction, resulting in the latter getting mined in a reasonable amount of
> time and the protocol making forward progress.
> 
> Note that the converse is not a useful attack: if the attacker broadcasts a
> high-fee double spend, higher than the intended multi-party transaction, the
> transaction will get mined in a reasonable amount of time, costing the attacker
> money and the defender nothing beyond wasted time. Multi-party protocols always
> have the property that attackers can spend money to DoS attack by creating more
> UTXOs/identities/etc, so this isn't any worse than the status quo!
> 
> 
> ## Transaction Pinning
> 
> So what about transaction pinning? The term actually refers to a few different
> techniques that can make it difficult/expensive to fee-bump a transaction.
> We're interested in the techniques relevant to replacements, namely
> exploitation of:
> 
> 1. BIP-125 RBF Rule #3: a replacement transaction is required to pay
> the higher absolute fee (not just fee rate) than the sum of fees paid by all
> transactions being replaced.
> 
> 2. BIP-125 RBF Rule #5: the number of transactions replaced at one time must
> not exceed 100. Note that this rule only exists due to limitations of the
> existing Bitcoin Core implementation; it has absolute no economic rational and
> should be removed by either improving the implementation's scalability issues,
> or rejecting transactions that could make a transaction unreplaceable(2).
> 
> Exploiting either rule is expensive. To exploit rule #3 the attacker has to
> broadcast fee-paying transactions paying a total amount of fees higher than the
> defender is willing to pay. Since transactions don't expire, in almost all
> circumstances those transactions will eventually be mined, costing the attacker
> much more money than they would have spent without full-rbf.
> 
> To exploit rule #5, the attacker has to broadcast 100x more fee-paying
> transactions than they otherwise would have. As with rule #3, those
> transactions will almost always eventually be mined, costing the attacker
> significantly more money than they would have spent without full-rbf. And, as
> mentioned above(2), rule #5 is merely an artifact of the existing
> implementation which can and should be fixed.
> 
> The only avenue for an attacker to avoid transaction pinning costs is
> amortisation: reusing the extra transactions required for pinning for other
> attacks/other purposes. But of course, amortisation is already a potent cost
> reduction strategy for attacks on multi-party protocols such as coinjoin, so
> the existence of transaction pinning doesn't appreciably change the situation.
> Again, there are mitigations such as requiring participants to post nLockTime'd
> fee-paying transactions(3), and limiting attacks to parties who are heavily
> invested in Bitcoin for other reasons is a valuable improvement on the status
> quo.
> 
> 
> # Conclusion
> 
> Far from not "offering any benefits other than breaking zeroconf business
> practices"(4), full-rbf clearly improves Bitcoin for multi-party protocols,
> among the many other reasons to adopt it.
> 
> 
> # Footnotes
> 
> 1. What do I mean by "exclusively controlled"? Let's compare coinjoin, to an
> ordinary single-payer Lightning channel. In a coinjoin, the goal is to get a
> transaction mined containing multiple inputs from different parties. Each of
> these inputs is individually, exclusively controlled by a single party:
> without the cooperation of any other party that input that be spend. This is
> unlike an ordinary single-payer Lightning channel: while the commitment
> transactions are multi-party transactions, the multisig transaction outputs
> involved are jointly controlled by both parties, and thus neither party can
> spend it without the cooperation of the other at some point.
> 
> 2. [bitcoin-dev] Removing BIP-125 Rule #5 Pinning with the Always-Replaceable
> Invariant, https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-November/021175.html
> 
> 3. [bitcoin-dev] Using Full-RBF to fix BIP-125 Rule #3 Pinning with nLockTime,
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-November/021176.html
> 
> 4. https://github.com/bitcoin/bitcoin/pull/26438
> 
> 5. There are even more exotic proposed Lightning-related protocols where a failure
> of transaction replacement can cause the loss of funds. I'm not covering
> those scenarios because they have such strong requirements - beyond what
> full-rbf offers - that the technical community does not have consensus that
> these proposed protocols are even viable.
> 
> --
> https://petertodd.org 'peter'[:-1]@petertodd.org
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

From alicexbt at protonmail.com  Tue Jan 10 17:10:37 2023
From: alicexbt at protonmail.com (alicexbt)
Date: Tue, 10 Jan 2023 17:10:37 +0000
Subject: [bitcoin-dev] Why Full-RBF Makes DoS Attacks on Multiparty
	Protocols Significantly More Expensive
In-Reply-To: <Y7035Edqoq8CK+nl@petertodd.org>
References: <Y7ySzDjzx5eDjOH9@petertodd.org>
 <OwgJwjPrZWRtBaIDDZ8g-xbFPlryUXUopqUuKYVUNE-mVHzCWHFXl77YzDlItEjHTHcGjpzIC5alGsnFEsOtSgHLm9We92gcWrLTahzPGFk=@protonmail.com>
 <Y7035Edqoq8CK+nl@petertodd.org>
Message-ID: <b3dDOCk8uf5GYtk12iN_EvY9obWchVL-qrNzEJMSf9JqqdcE6uBT8-alz-uK8aNeG_WyUGPLCi1tUxdhjXIPf2uMTbzCaV_5JHUk-FM1wJg=@protonmail.com>

Hi Peter,

> Bringing up Whirlpool here is silly. Everyone knows Samourai has made, at best,
> some rather insane technical decisions. Quite likely downright malicious with
> their xpub collection. Their opinion isn't relevant. Cite reputable sources.

I didn't want this thread to become a wasabi vs samourai debate instead wanted to focus on full-rbf and how it affects different coinjoin implementations. Samourai wallet can be used with [dojo][0] that includes full node and Whirlpool can be used in [sparrow Wallet][1] as well. There are several reasons to not use wasabi and consider their opinion irrelevant. Wasabi has many privacy issues including address reuse and consolidation in a coinjoin tx. They completely lost their reputation after deciding to work with chain analysis firms that help governments for censorship of some UTXOs.

Even _nothingmuch_ who has contributed to Wasabi's coinjoin implementation has [no major issues][2] with whirlpool if used properly. Some [tweets][3] in this thread even show their incompetence and major issues with wabisabi.

Anyway thanks for responding to other things I mentioned in last email.


[0]: https://code.samourai.io/dojo/samourai-dojo
[1]: https://sparrowwallet.com/docs/mixing-whirlpool.html
[2]: https://twitter.com/search?lang=en&q=whirlpool%20(from%3AmHaGqnOACyFm0h5)&src=typed_query
[3]: https://twitter.com/mHaGqnOACyFm0h5/status/1538748210210013184


/dev/fd0
floppy disc guy

Sent with Proton Mail secure email.

------- Original Message -------
On Tuesday, January 10th, 2023 at 3:33 PM, Peter Todd <pete at petertodd.org> wrote:


> On Tue, Jan 10, 2023 at 09:19:39AM +0000, alicexbt wrote:
> 
> > Hi Peter,
> > 
> > > ## How Full-RBF Mitigates the Double-Spend DoS Attack
> > > 
> > > Modulo tx-pinning, full-rbf mitigates the double-spend DoS attack in a very
> > > straightforward way: the low fee transaction is replaced by the higher fee
> > > transaction, resulting in the latter getting mined in a reasonable amount of
> > > time and the protocol making forward progress.
> > 
> > Asking this question based on a discussion on twitter. How would you get extra sats to increase the fees?
> 
> 
> You're misunderstanding the issue. There is no need for extra sats to increase
> fees. Coinjoin transactions already have fees set at a level at which you'd
> expect them to be mined in a reasonable amount of time. Full-RBF ensures that,
> modulo tx pinning, either the coinjoin gets mined, or any double-spend has to
> have a high enough feerate that it will be mined in a reasonable amount of time
> as well.
> 
> > It seems this would be possible with Joinmarket, Wasabi and even joinstr although things would get worse for Whirlpool. Whirlpool coinjoin transactions do not signal BIP 125 RBF so they were not replaceable earlier
> 
> 
> Bringing up Whirlpool here is silly. Everyone knows Samourai has made, at best,
> some rather insane technical decisions. Quite likely downright malicious with
> their xpub collection. Their opinion isn't relevant. Cite reputable sources.
> 
> Anyway, Wasabi would like to move to making coinjoins opt-in to RBF. Though
> full-rbf may come sooner; for technical reasons opt-in RBF is ugly to implement
> now as activation needs to be coordinated accross all clients:
> 
> https://github.com/zkSNACKs/WalletWasabi/issues/9041#issuecomment-1376653020
> 
> > however attacker would be able to perform DoS attacks now by double spending their inputs used in coinjoin.
> 
> 
> As I explained, attackers can already do this with or without full-rbf simply
> by picking the right time to broadcast the double spend. It's not an effective
> attack anyway: with a UTXO you can already hold up a coinjoin round by simply
> failing to complete stage #2 of the coinjoin. Actually doing a double-spend
> simply guarantees that you're spending money on it. It's only effective with
> low-fee double-spends in the absence of full-rbf.
> 
> 
> This tweet is nuts. Eg "Gives well connected mining pools an added advantage"
> is simply false. Full-RBF does the exact opposite.
> 
> --
> https://petertodd.org 'peter'[:-1]@petertodd.org

From zhiguang53846 at gmail.com  Sat Jan  7 23:22:02 2023
From: zhiguang53846 at gmail.com (Eric)
Date: Sat, 7 Jan 2023 18:22:02 -0500
Subject: [bitcoin-dev] Pseudocode for robust tail emission
In-Reply-To: <174889786-7eefd505bbf223af3d3a1101c7c3044d@pmq3v.m5r2.onet>
References: <174889786-7eefd505bbf223af3d3a1101c7c3044d@pmq3v.m5r2.onet>
Message-ID: <CADv3YEbRX7fsG5ci6HH2RvU=PRZ=QQFkcEYY-dLQAaRsGHOi6A@mail.gmail.com>

if by security you mean the security of the currency, i don't think people
have much to worry about

coinbase as far as i know is starting to behave more bank-like.  i think
there is a nostr bot that does block updates and doesn't factor in coinbase
at all

On Sat, Jan 7, 2023 at 2:13 PM Jaroslaw via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

>
> > Anyways if it turns out that fees alone don't look like they're
> supporting enough security, we have a good amount of time to come to that
> conclusion and do something about it.
>
> The worst-case scenario is that the first global hashrate regression may
> take place in 2028.
> Instead of the average price increase at least x2 every halving - the
> global hashrate may gradually decrease from that point. Again, it would be
> the worst-case scenario.
>
> In my proposal you don't need to think about any calculations - just
> simple logic which we have right now. No hardcoded values and the free
> market in its finest - self-regulating the level of taxation of parties
> involved, but with opposite interests. And the mechanism would try to fix a
> global hashrate regression if appear.
> In other words: let's be optimistic regarding fees, but with emergency
> mechanism built-in just in case.
> The only drawback here is that the system is already running.
>
> In my personal opinion avoiding long-term global hashrate regression is
> more important for store of value feature than the 21M schelling point (or
> trap...)
>
>
>
>
> W dniu 2023-01-04 17:03:33 u?ytkownik Billy Tetrud <billy.tetrud at gmail.com>
> napisa?:
> > In Bitcoin "the show must go on" and someone must pay for it. Active
> [and/or] passive users
>
>
> I certainly agree.
>
>
> > or more precisely: tiny inflation
>
>
> ?
>
>
> > Right now security comes from almost fully from ~1.8% inflation.
>
>
> Best I could find, fees make up about 13% of miner revenue. So yes, the
> vast majority of security comes from coinbase rewards. I assume you're
> implying that ~13% of today's security is not enough? I would love to see
> any quantitative thoughts you have on how one might determine that.
>
>
> Have there been any thoughts put out in the community as to what size of
> threat is unlikely enough to arise that we don't need to worry about it?
> Maybe 1% of the yearly government budgets of the world would be an upper
> bound on how much anyone would expect could realistically be brought to
> bear? Today that would be maybe around $350 billion.
>
>
> Or perhaps a better way to estimate would be calculating the size of the
> motivation of an attacker. For example, this paper seems to conclude that
> the US government was extracting a maximum of ~$20 billion/year in 1982
> dollars (so maybe $60 billion/year in 2022 dollars if you go by CPI). If we
> scale this up to the entire world of governments, this seems like it would
> place an upper bound of $180 billion/year of seigniorage extraction that
> would be at risk if bitcoin might put the currencies they gain seigniorage
> from out of business. Over 10 years (about as far as we can expect any
> government to think), that's almost $2 trillion.
>
>
> Whereas it would currently cost probably less than $7 billion to purchase
> a 50% share of bitcoin miners. To eventually reach a level of $350 billion,
> bitcoin's price would need to reach about $800,000 / bitcoin. That seems
> within the realm of possibility. To reach a level of $2 trillion, you'd
> need a price of $4.3 million/bitcoin. That's still probably within the
> realm of possibility, but certainly not as likely.  If you then assume we
> won't have significant coinbase rewards by that point, and only 13% of the
> equivalent revenue (from fees) would be earned, then a price of ~$6 million
> would be needed to support a $350 billion and $34 million to support a $2
> trillion security. I think that second one is getting up towards the realm
> of impossibility, so if we think that much security is necessary, we might
> have to rethink things. Its also quite possible, as the network of people
> who accept and use bitcoin as payment grows, that the fee market will grow
> superlinearly in comparison to market cap, which would make these kind of
> high levels of security more realistic.
>
>
> Anyways if it turns out that fees alone don't look like they're supporting
> enough security, we have a good amount of time to come to that conclusion
> and do something about it.
>
>
> > Deflation in Bitcoin is not 1:1 matter like in gold, for example...
> Deflation in Bitcoin is more complex issue
>
>
> It's helpful to keep our language precise here. Price inflation and
> deflation act identically in bitcoin and gold and anything else. What you
> seem to be talking about at this point is monetary inflation (specifically,
> a reduction in it) which of course operates differently on the machinery of
> bitcoin than it does in the machinery of gold or other things. Whereas my
> comment about you mentioning Gresham's law was specifically talking about
> price inflation, not the effects of the coin emission machinery in bitcoin.
>
>
>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230107/2f281099/attachment.html>

From benthecarman at live.com  Thu Jan 12 12:32:06 2023
From: benthecarman at live.com (Ben Carman)
Date: Thu, 12 Jan 2023 12:32:06 +0000
Subject: [bitcoin-dev] Using OP_VAULT to improve DLCs
Message-ID: <SJ1P223MB0531F7DDDFEB49DCF8E92CE9A1FD9@SJ1P223MB0531.NAMP223.PROD.OUTLOOK.COM>

Hi list,

After reading through James's OP_VAULT proposal this week, I had a realization that this can be used for more than a deep cold storage wallet.

Instead of vaulting and unvaulting, we can just send to a OP_UNVAULT output.
When using OP_UNVAULT if we set the `recovery-spk-hash` to a burn address (ie OP_RETURN `<random value>`)
and the `delay-period` to `0` we can use it as a not-so simple covenant with the `unvault-target-hash` being
set to whatever output restrictions you want to create.

Given this we can recreate a lot of what CTV promises, one of my favorites being
[Lloyd's improvement to DLCs](https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019808.html)
(I recommend reading that first)

A similiar construction could be done by creating a taproot tree similiar to LLoyd's construction with each leaf looking like:

`<hash-of-burn-spk> 0 <CET-hash_i> OP_UNVAULT <CET_i> CHECKSIG`

In the same as Lloyd's proposal: when the oracle(s) reveals their attestations either party can combine them to get the secret key corresponding to `CET_i` and spend the coins to the CET (whose `unvault-target-hash`
hash is `CET-hash`) which distributes the funds according to the contract.

## Comparison

Compared to the original CTV proposal, this should get all the same computational savings. However, it would use more blockchain space.

The main downside I see is our final spending script will be slightly larger.
Instead of just having `<hash> OP_CTV` it will be replaced with `<hash> 0 <hash> OP_UNVAULT` (34 bytes extra, not including the witness discount).
However, this may be negligible in the case of a DLC with many outcomes as a lot of the input size will be coming from the control block.
This also can always be skipped by doing a cooperative close of the DLC if the internal-key of the taproot tree can be spent using something like MuSig.

I imagine a lot of the other applications for CTV can be recreated with OP_VAULT using this same trick.

# Credits

- Lloyd Fournier for the original proposal
- James O'Beirne for the OP_VAULT proposal and giving me the idea to skip the intial OP_VAULT and just use OP_UNVAULT



Best,

benthecarman
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230112/192b1f7f/attachment.html>

From pete at petertodd.org  Fri Jan 13 23:37:04 2023
From: pete at petertodd.org (Peter Todd)
Date: Fri, 13 Jan 2023 18:37:04 -0500
Subject: [bitcoin-dev] Why Full-RBF Makes DoS Attacks on Multiparty
 Protocols Significantly More Expensive
In-Reply-To: <6cebd312ca960e634729cc574c2e97b0@dtrt.org>
References: <Y7ySzDjzx5eDjOH9@petertodd.org>
 <aaaeda2950e61127a3218c523927a0d8@dtrt.org>
 <Y70mNHsX4JcKYZyi@petertodd.org>
 <6089e1f0140684435bf5e87b0c13d561@dtrt.org>
 <Y704non5DD5mtxs1@petertodd.org>
 <6cebd312ca960e634729cc574c2e97b0@dtrt.org>
Message-ID: <Y8HrINYYYiw+V9v+@petertodd.org>

On Tue, Jan 10, 2023 at 10:14:47AM -1000, David A. Harding wrote:
> On 2023-01-10 00:06, Peter Todd wrote:
> > Remember, we'd like decentralized coinjoin implementations like
> > Joinmarket to
> > work. How does a decentralized coinjoin implement "conflict monitoring"?
> 
> 1. Run a relay node with a conflict-detection patch.  Stock Bitcoin Core
>    with -debug=mempoolrej will tell you when it rejects a transaction
>    for conflicting with a transaction already in the mempool, e.g.:
> 
>       2022-11-01T02:53:17Z
> 867b85d68d7a7244c1d65c4797006b56973110ac243ab5ee15a8c4d220060c58 from
> peer=58 was not accepted: txn-mempool-conflict
> 
>    I think it would be easy to extend this facility to list the inputs
>    which conflicted.  So if Alice sees a conflict created by Mallory,
>    she can create a new coinjoin transaction without Mallory.  This
>    method has the advantage of being fast and attributing fault,
>    although it does require Alice's node be online at the time Mallory's
>    conflict is propagated.

So for something as simple as reliable coinjoining - an important privacy
feature that we'd like all wallets to use - you expect people to run
well-connected 24/7 nodes running specialty software?

Even if you run a node as you suggest, there's certainly no guarantee that
you'd learn about any double-spend without doing a severe sybil attack against
the network; the 8 outgoing nodes a typical node has samples a tiny fraction of
the network. And *even if* you sybil attack to try to detect conflicts there's
still no guarantee as attackers can use all kinds of special techniques to get
transactions into miner mempools and not others.

> 2. Simply assume a conflict exists for otherwise unexplainable failures.
>    For example, if Alice sees several new blocks whose bottom feerates
>    are well below the feerates of an unconfirmed coinjoin transaction
>    that Alice helped create and broadcast, she can assume it's a
>    conflict that is preventing preventing confirmation of the coinjoin.
>    She can find an entirely different set of collaborators and create a
>    non-conflicting transaction without ever needing to know which inputs
>    from the original transaction conflicted.  This method has the
>    disadvantage of being slow (on the order of hours) and not attributing
>    fault, although it doesn't require Alice has any information beyond
> copies
>    of recent blocks.

You're suggesting that to avoid enabling full-rbf, coinjoin's and other
decentralized multi-party protocols risk getting coins tied up for hours trying
to do conflict resolution rather than just fixing the underlying problem with
what's literally a one-line code change that 17% of the v24.x nodes have
decided to enable.

> I didn't list these methods or others before because the specific method
> used to
> detect conflicts doesn't matter to the realization that software which
> uses conflict detection and evasion to defeat the $17.00 attack also
> defeats the $0.05 attack without any need for full-RBF.

Fact is, full-rbf defeats those attacks much better. And I'm amazed that you
don't consider raising the cost of attacks on coinjoins and similar
decentralized protocols by almost three orders of magnitude to be important:
why are you prioritizing a few highly centralized, often AML/KYC'd, unconfirmed
tx acceptance services over decentralized protocols which provide privacy and
security to a lot more users?

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230113/5516cb92/attachment.sig>

From pete at petertodd.org  Fri Jan 13 23:46:58 2023
From: pete at petertodd.org (Peter Todd)
Date: Fri, 13 Jan 2023 18:46:58 -0500
Subject: [bitcoin-dev] Why Full-RBF Makes DoS Attacks on Multiparty
 Protocols Significantly More Expensive
In-Reply-To: <b3dDOCk8uf5GYtk12iN_EvY9obWchVL-qrNzEJMSf9JqqdcE6uBT8-alz-uK8aNeG_WyUGPLCi1tUxdhjXIPf2uMTbzCaV_5JHUk-FM1wJg=@protonmail.com>
References: <Y7ySzDjzx5eDjOH9@petertodd.org>
 <OwgJwjPrZWRtBaIDDZ8g-xbFPlryUXUopqUuKYVUNE-mVHzCWHFXl77YzDlItEjHTHcGjpzIC5alGsnFEsOtSgHLm9We92gcWrLTahzPGFk=@protonmail.com>
 <Y7035Edqoq8CK+nl@petertodd.org>
 <b3dDOCk8uf5GYtk12iN_EvY9obWchVL-qrNzEJMSf9JqqdcE6uBT8-alz-uK8aNeG_WyUGPLCi1tUxdhjXIPf2uMTbzCaV_5JHUk-FM1wJg=@protonmail.com>
Message-ID: <Y8HtctIz35tnOjlm@petertodd.org>

On Tue, Jan 10, 2023 at 05:10:37PM +0000, alicexbt via bitcoin-dev wrote:
> Hi Peter,
> 
> > Bringing up Whirlpool here is silly. Everyone knows Samourai has made, at best,
> > some rather insane technical decisions. Quite likely downright malicious with
> > their xpub collection. Their opinion isn't relevant. Cite reputable sources.
> 
> I didn't want this thread to become a wasabi vs samourai debate instead wanted to focus on full-rbf and how it affects different coinjoin implementations. Samourai wallet can be used with [dojo][0] that includes full node and Whirlpool can be used in [sparrow Wallet][1] as well. There are several reasons to not use wasabi and consider their opinion irrelevant. Wasabi has many privacy issues including address reuse and consolidation in a coinjoin tx.

Lol, the "address reuse" thing I actually mentioned in my email. Avoiding
address reuse from user errors like loading the same seed into different
wallets isn't realistic, and it has no real impact on other users.

No reasonable person things Samourai's default option of uploading xpubs is
sane. The debate here is over and arguing otherwise is just wasting everyone's
time on this mailing list.

> They completely lost their reputation after deciding to work with chain analysis firms that help governments for censorship of some UTXOs.

Citation on them working with chain analysis firms? Or did they just roll their
own blacklist?

Anyway, the blacklisting is just a bit of cowardness. That's not a big deal.
Lots of Bitcoin entitites have done the cowardly thing and implemented
blacklists on the suggestion of their lawyers.  We're probably better off if we
don't set the bar so high that while you're risking jail time implementing
coinjoin, we demand you to take even more risks by not implementing some mostly
symbolic blacklists that affect hardly anyone.

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230113/b1f4363e/attachment-0001.sig>

From pete at petertodd.org  Fri Jan 13 23:53:45 2023
From: pete at petertodd.org (Peter Todd)
Date: Fri, 13 Jan 2023 18:53:45 -0500
Subject: [bitcoin-dev] A proposal for Full RBF to not exclude Zero Conf
 use case
In-Reply-To: <CACkWPs_6z7UyXzejTqjy=i+SkSz-76VdzZ20K1DzcVJxan_HZg@mail.gmail.com>
References: <CACkWPs_F94t9Q8TfyYYGxQANUT78SWFGkTOh6qRwnt=6ct7aig@mail.gmail.com>
 <CAAQdECAspoRJRz7j1ubAe=Cen==AVF5bm-Q2=0TiKc7NtbU65A@mail.gmail.com>
 <CACkWPs_4pjTo50=S86KPEznBs0PU7rd30rBGHq2Q5=6n6hYMgQ@mail.gmail.com>
 <CAHTn92wH17Z+p5cFOLpzsVUuTf4-nZc7tOjQr+_xjSU5groa0Q@mail.gmail.com>
 <CACkWPs9VawCYt7maiNqzafkFnHTiGJQkXMT4VXQQcG-rE2TTNw@mail.gmail.com>
 <Y5jxmItJIpIUVY+x@petertodd.org>
 <CACkWPs_jSLDg3seON0uu=ri6iR9cytXo2MEPJ5PVeap+iDreeQ@mail.gmail.com>
 <Y5zfuVGpRGaknwaU@petertodd.org>
 <CACkWPs_6z7UyXzejTqjy=i+SkSz-76VdzZ20K1DzcVJxan_HZg@mail.gmail.com>
Message-ID: <Y8HvCbBd5+pm8Uj2@petertodd.org>

On Sun, Dec 18, 2022 at 10:06:15AM +0200, Daniel Lipshitz wrote:
> GAP600 is not a trxs processor or liquidity provider we service merchants,
> payment processors & non-custodial liquidity providers - our service is
> purely the 0-conf enabling our clients to accept 0-conf. Clients access our
> service via API - sending us the Trx hash & output address. Our service is
> not based on AML/KYC it is purely an analysis of the Bitcoin network.

I checked and to sign up for your service, you ask for the name, phone number,
email, and company name.

That is an example of AML/KYC. By learning the tx hash and output address, you
learn which addresses are associated with what real world entity is paying for
your service. You learning that information for what you claim is ~10% of all
transactions is a significant privacy concern. On that basiss alone, I would
argue that full-rbf should be implemented specifically to destroy your business
and stop the collection of that data.

> I am not at liberty to share names of other services which have developed
> their own 0-conf service - they include a payment processor on a gambling
> platform which services multiple gambling operators, a standalone gaming
> payment processor, and a payment processor recently I have come across. We
> also do not have a significant presence in Asia - so I don't have
> visibility there.

No, I asked you for information on what companies are actually using *your*
service. You claim to be involved with a huge % of all transactions. If that is
in fact true, obviously it shouldn't be hard to provide some examples of
merchants using GAP600 to accept unconfirmed txs.

> I don't see it being necessarily an either/or approach here. The risk
> looking to be mitigated with FullRBF seems to be able to be mitigated with
> FullRBF but with a swop limitation of at least the Inputs of Trx1 being in
> Trx2 - no flagging required. Added to this all these trxs always have the
> OptinRBF so if these platforms need to be able to recreate completely their
> trxs they have that option as well. The option to Swop out or bump up trxs
> seems to be well covered under those two options.

You are not correct. One of the most important use-cases for full-rbf is
multi-party transactions; adding that limitation to full-rbf negates that
usecase. See my post on why full-rbf makes DoS attacks on multiparty protocols
significantly more expensive:

https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2023-January/021322.html

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230113/bcc6cae8/attachment.sig>

From michaelfolkson at protonmail.com  Sat Jan 14 20:26:07 2023
From: michaelfolkson at protonmail.com (Michael Folkson)
Date: Sat, 14 Jan 2023 20:26:07 +0000
Subject: [bitcoin-dev] A new Bitcoin implementation integrated with Core
	Lightning
Message-ID: <aka4qP9Cig-OhfMlQ9y1kghZWExjpno4cs47KIgYwv4aLYtiQB37eHbj2X2hiDuoK0D1gSeKWP97P0bRADbTg1CZRBIpHGZ5WFFYPWIJ87Y=@protonmail.com>

I tweeted this [0] back in November 2022.

"With the btcd bugs and the analysis paralysis on a RBF policy option in Core increasingly thinking @BitcoinKnots and consensus compatible forks of Core are the future. Gonna chalk that one up to another thing @LukeDashjr was right about all along."

A new bare bones Knots style Bitcoin implementation (in C++/C) integrated with Core Lightning was a long term idea I had (and presumably many others have had) but the dysfunction on the Bitcoin Core project this week (if anything it has been getting worse over time, not better) has made me start to take the idea more seriously. It is clear to me that the current way the Bitcoin Core project is being managed is not how I would like an open source project to be managed. Very little discussion is public anymore and decisions seem to be increasingly made behind closed doors or in private IRC channels (to the extent that decisions are made at all). Core Lightning seems to have the opposite problem. It is managed effectively in the open (admittedly with fewer contributors) but doesn't have the eyeballs or the usage that Bitcoin Core does. Regardless, selfishly I at some point would like a bare bones Bitcoin and Lightning implementation integrated in one codebase. The Bitcoin Core codebase has collected a lot of cruft over time and the ultra conservatism that is needed when treating (potential) consensus code seems to permeate into parts of the codebase that no one is using, definitely isn't consensus code and should probably just be removed.

The libbitcoinkernel project was (is?) an attempt to extract the consensus engine out of Core but it seems like it won't achieve that as consensus is just too slippery a concept and Knots style consensus compatible codebase forks of Bitcoin Core seem to still the model. To what extent you can safely chop off this cruft and effectively maintain this less crufty fork of Bitcoin Core also isn't clear to me yet.

Then there is the question of whether it makes sense to mix C and C++ code that people have different views on. C++ is obviously a superset of C but assuming this merging of Bitcoin Core and Core Lightning is/was the optimal final destination it surely would have been better if Core Lightning was written in the same language (i.e. with classes) as Bitcoin Core.

I'm just floating the idea to (hopefully) hear from people who are much more familiar with the entirety of the Bitcoin Core and Core Lightning codebases. It would be an ambitious long term project but it would be nice to focus on some ambitious project(s) (even if just conceptually) for a while given (thankfully) there seems to be a lull in soft fork activation chaos.

Thanks
Michael

[0]: https://twitter.com/michaelfolkson/status/1589220155006910464?s=20&t=GbPm7w5BqS7rS3kiVFTNcw

--
Michael Folkson
Email: michaelfolkson at [protonmail.com](http://protonmail.com/)
Keybase: michaelfolkson
PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230114/306cd5ac/attachment-0001.html>

From michaelfolkson at protonmail.com  Sat Jan 14 20:45:38 2023
From: michaelfolkson at protonmail.com (Michael Folkson)
Date: Sat, 14 Jan 2023 20:45:38 +0000
Subject: [bitcoin-dev] [Lightning-dev] A new Bitcoin implementation
	integrated with Core Lightning
In-Reply-To: <MP0sjW-onVrtLWZxABUP2ywxGEXWAqm-UEZbHVG4nTt9fkdiz9qrCW7mXj1Rwhug_U0aQIeRPGnlYO15ZWH4SKHiv2w-Or-fHbtrR8vJjAo=@protonmail.com>
References: <aka4qP9Cig-OhfMlQ9y1kghZWExjpno4cs47KIgYwv4aLYtiQB37eHbj2X2hiDuoK0D1gSeKWP97P0bRADbTg1CZRBIpHGZ5WFFYPWIJ87Y=@protonmail.com>
 <MP0sjW-onVrtLWZxABUP2ywxGEXWAqm-UEZbHVG4nTt9fkdiz9qrCW7mXj1Rwhug_U0aQIeRPGnlYO15ZWH4SKHiv2w-Or-fHbtrR8vJjAo=@protonmail.com>
Message-ID: <AK-TM5w44E8q6d0xXTAf79Z-GNo3VlSFQBTJtaGSEgtTWQ7RESJ5nMdzfv3pCGMYVBhJBq0mKl_GyWsSLUeyCxbtn8MPxiYeKGRwnhIZ8QA=@protonmail.com>

I saw it was announced, yes. The author is brilliant, he has now managed two alternative implementations of Core in two different languages :)

The problem though and why I and many others think the Knots style fork of Core is the better option is because you avoid reimplementing consensus code in a different language. If you're ultra conservative about consensus code you either want to run Core in parallel with your alternative implementation to check they don't go out of consensus or you want to run the same consensus code as Core in a Knots like fork. Hence a Knots like fork of Core in C++ integrated with Core Lightning in C seems like the better option to me for serious running in production like use cases.

--
Michael Folkson
Email: michaelfolkson at [protonmail.com](http://protonmail.com/)
Keybase: michaelfolkson
PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3

------- Original Message -------
On Saturday, January 14th, 2023 at 20:34, Fabian <fjahr at protonmail.com> wrote:

> Hi Michael,
>
> have you seen Mako? It might at least be a good start for what you would like to achieve: https://github.com/chjj/mako
>
> Best,
> Fabian
> ------- Original Message -------
> On Saturday, January 14th, 2023 at 9:26 PM, Michael Folkson via Lightning-dev <lightning-dev at lists.linuxfoundation.org> wrote:
>
>> I tweeted this [0] back in November 2022.
>>
>> "With the btcd bugs and the analysis paralysis on a RBF policy option in Core increasingly thinking @BitcoinKnots and consensus compatible forks of Core are the future. Gonna chalk that one up to another thing @LukeDashjr was right about all along."
>>
>> A new bare bones Knots style Bitcoin implementation (in C++/C) integrated with Core Lightning was a long term idea I had (and presumably many others have had) but the dysfunction on the Bitcoin Core project this week (if anything it has been getting worse over time, not better) has made me start to take the idea more seriously. It is clear to me that the current way the Bitcoin Core project is being managed is not how I would like an open source project to be managed. Very little discussion is public anymore and decisions seem to be increasingly made behind closed doors or in private IRC channels (to the extent that decisions are made at all). Core Lightning seems to have the opposite problem. It is managed effectively in the open (admittedly with fewer contributors) but doesn't have the eyeballs or the usage that Bitcoin Core does. Regardless, selfishly I at some point would like a bare bones Bitcoin and Lightning implementation integrated in one codebase. The Bitcoin Core codebase has collected a lot of cruft over time and the ultra conservatism that is needed when treating (potential) consensus code seems to permeate into parts of the codebase that no one is using, definitely isn't consensus code and should probably just be removed.
>>
>> The libbitcoinkernel project was (is?) an attempt to extract the consensus engine out of Core but it seems like it won't achieve that as consensus is just too slippery a concept and Knots style consensus compatible codebase forks of Bitcoin Core seem to still the model. To what extent you can safely chop off this cruft and effectively maintain this less crufty fork of Bitcoin Core also isn't clear to me yet.
>>
>> Then there is the question of whether it makes sense to mix C and C++ code that people have different views on. C++ is obviously a superset of C but assuming this merging of Bitcoin Core and Core Lightning is/was the optimal final destination it surely would have been better if Core Lightning was written in the same language (i.e. with classes) as Bitcoin Core.
>>
>> I'm just floating the idea to (hopefully) hear from people who are much more familiar with the entirety of the Bitcoin Core and Core Lightning codebases. It would be an ambitious long term project but it would be nice to focus on some ambitious project(s) (even if just conceptually) for a while given (thankfully) there seems to be a lull in soft fork activation chaos.
>>
>> Thanks
>> Michael
>>
>> [0]: https://twitter.com/michaelfolkson/status/1589220155006910464?s=20&t=GbPm7w5BqS7rS3kiVFTNcw
>>
>> --
>> Michael Folkson
>> Email: michaelfolkson at [protonmail.com](http://protonmail.com/)
>> Keybase: michaelfolkson
>> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230114/f701a6df/attachment-0001.html>

From fjahr at protonmail.com  Sat Jan 14 20:34:38 2023
From: fjahr at protonmail.com (Fabian)
Date: Sat, 14 Jan 2023 20:34:38 +0000
Subject: [bitcoin-dev] [Lightning-dev] A new Bitcoin implementation
	integrated with Core Lightning
In-Reply-To: <aka4qP9Cig-OhfMlQ9y1kghZWExjpno4cs47KIgYwv4aLYtiQB37eHbj2X2hiDuoK0D1gSeKWP97P0bRADbTg1CZRBIpHGZ5WFFYPWIJ87Y=@protonmail.com>
References: <aka4qP9Cig-OhfMlQ9y1kghZWExjpno4cs47KIgYwv4aLYtiQB37eHbj2X2hiDuoK0D1gSeKWP97P0bRADbTg1CZRBIpHGZ5WFFYPWIJ87Y=@protonmail.com>
Message-ID: <MP0sjW-onVrtLWZxABUP2ywxGEXWAqm-UEZbHVG4nTt9fkdiz9qrCW7mXj1Rwhug_U0aQIeRPGnlYO15ZWH4SKHiv2w-Or-fHbtrR8vJjAo=@protonmail.com>

Hi Michael,

have you seen Mako? It might at least be a good start for what you would like to achieve: https://github.com/chjj/mako

Best,
Fabian
------- Original Message -------
On Saturday, January 14th, 2023 at 9:26 PM, Michael Folkson via Lightning-dev <lightning-dev at lists.linuxfoundation.org> wrote:

> I tweeted this [0] back in November 2022.
>
> "With the btcd bugs and the analysis paralysis on a RBF policy option in Core increasingly thinking @BitcoinKnots and consensus compatible forks of Core are the future. Gonna chalk that one up to another thing @LukeDashjr was right about all along."
>
> A new bare bones Knots style Bitcoin implementation (in C++/C) integrated with Core Lightning was a long term idea I had (and presumably many others have had) but the dysfunction on the Bitcoin Core project this week (if anything it has been getting worse over time, not better) has made me start to take the idea more seriously. It is clear to me that the current way the Bitcoin Core project is being managed is not how I would like an open source project to be managed. Very little discussion is public anymore and decisions seem to be increasingly made behind closed doors or in private IRC channels (to the extent that decisions are made at all). Core Lightning seems to have the opposite problem. It is managed effectively in the open (admittedly with fewer contributors) but doesn't have the eyeballs or the usage that Bitcoin Core does. Regardless, selfishly I at some point would like a bare bones Bitcoin and Lightning implementation integrated in one codebase. The Bitcoin Core codebase has collected a lot of cruft over time and the ultra conservatism that is needed when treating (potential) consensus code seems to permeate into parts of the codebase that no one is using, definitely isn't consensus code and should probably just be removed.
>
> The libbitcoinkernel project was (is?) an attempt to extract the consensus engine out of Core but it seems like it won't achieve that as consensus is just too slippery a concept and Knots style consensus compatible codebase forks of Bitcoin Core seem to still the model. To what extent you can safely chop off this cruft and effectively maintain this less crufty fork of Bitcoin Core also isn't clear to me yet.
>
> Then there is the question of whether it makes sense to mix C and C++ code that people have different views on. C++ is obviously a superset of C but assuming this merging of Bitcoin Core and Core Lightning is/was the optimal final destination it surely would have been better if Core Lightning was written in the same language (i.e. with classes) as Bitcoin Core.
>
> I'm just floating the idea to (hopefully) hear from people who are much more familiar with the entirety of the Bitcoin Core and Core Lightning codebases. It would be an ambitious long term project but it would be nice to focus on some ambitious project(s) (even if just conceptually) for a while given (thankfully) there seems to be a lull in soft fork activation chaos.
>
> Thanks
> Michael
>
> [0]: https://twitter.com/michaelfolkson/status/1589220155006910464?s=20&t=GbPm7w5BqS7rS3kiVFTNcw
>
> --
> Michael Folkson
> Email: michaelfolkson at [protonmail.com](http://protonmail.com/)
> Keybase: michaelfolkson
> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230114/acc6e73d/attachment.html>

From daniel at gap600.com  Sat Jan 14 20:15:30 2023
From: daniel at gap600.com (Daniel Lipshitz)
Date: Sat, 14 Jan 2023 22:15:30 +0200
Subject: [bitcoin-dev] A proposal for Full RBF to not exclude Zero Conf
 use case
In-Reply-To: <Y8HvCbBd5+pm8Uj2@petertodd.org>
References: <CACkWPs_F94t9Q8TfyYYGxQANUT78SWFGkTOh6qRwnt=6ct7aig@mail.gmail.com>
 <CAAQdECAspoRJRz7j1ubAe=Cen==AVF5bm-Q2=0TiKc7NtbU65A@mail.gmail.com>
 <CACkWPs_4pjTo50=S86KPEznBs0PU7rd30rBGHq2Q5=6n6hYMgQ@mail.gmail.com>
 <CAHTn92wH17Z+p5cFOLpzsVUuTf4-nZc7tOjQr+_xjSU5groa0Q@mail.gmail.com>
 <CACkWPs9VawCYt7maiNqzafkFnHTiGJQkXMT4VXQQcG-rE2TTNw@mail.gmail.com>
 <Y5jxmItJIpIUVY+x@petertodd.org>
 <CACkWPs_jSLDg3seON0uu=ri6iR9cytXo2MEPJ5PVeap+iDreeQ@mail.gmail.com>
 <Y5zfuVGpRGaknwaU@petertodd.org>
 <CACkWPs_6z7UyXzejTqjy=i+SkSz-76VdzZ20K1DzcVJxan_HZg@mail.gmail.com>
 <Y8HvCbBd5+pm8Uj2@petertodd.org>
Message-ID: <CACkWPs_Nqm1663c1q8xHX=A0Gpa7m1kV_QX6t0s8uPOEh3WQLA@mail.gmail.com>

On Sat, Jan 14, 2023 at 1:53 AM Peter Todd <pete at petertodd.org> wrote:

> On Sun, Dec 18, 2022 at 10:06:15AM +0200, Daniel Lipshitz wrote:
> > GAP600 is not a trxs processor or liquidity provider we service
> merchants,
> > payment processors & non-custodial liquidity providers - our service is
> > purely the 0-conf enabling our clients to accept 0-conf. Clients access
> our
> > service via API - sending us the Trx hash & output address. Our service
> is
> > not based on AML/KYC it is purely an analysis of the Bitcoin network.
>
> I checked and to sign up for your service, you ask for the name, phone
> number,
> email, and company name.
>
> That is an example of AML/KYC. By learning the tx hash and output address,
> you
> learn which addresses are associated with what real world entity is paying
> for
> your service. You learning that information for what you claim is ~10% of
> all
> transactions is a significant privacy concern. On that basiss alone, I
> would
> argue that full-rbf should be implemented specifically to destroy your
> business
> and stop the collection of that data.
>
> We have standard commercial information about the payment processors, non
custodial liquidity providers and merchants which become our clients - we
do not have any kyc/aml information or telephone number on who is sending
our clients the bitcoin for deposit.  For us these are just bitcoin Trx
which our clients choose to benefit from 0-conf deposit recognition. Our
service is provided via API with the only information our clients share
with us, regarding a specific bitcoin transaction, being public bitcoin
information like trx hash and output address.

> I am not at liberty to share names of other services which have developed
> > their own 0-conf service - they include a payment processor on a gambling
> > platform which services multiple gambling operators, a standalone gaming
> > payment processor, and a payment processor recently I have come across.
> We
> > also do not have a significant presence in Asia - so I don't have
> > visibility there.
>
> No, I asked you for information on what companies are actually using *your*
> service. You claim to be involved with a huge % of all transactions. If
> that is
> in fact true, obviously it shouldn't be hard to provide some examples of
> merchants using GAP600 to accept unconfirmed txs.
>

As already posted here
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-December/021240.html
Max CEO from Coinspaid who has provided Cpoinspaid address clusters, see
link, is available to discuss further and may choose to share further
information on the merchants they support.

>
> > I don't see it being necessarily an either/or approach here. The risk
> > looking to be mitigated with FullRBF seems to be able to be mitigated
> with
> > FullRBF but with a swop limitation of at least the Inputs of Trx1 being
> in
> > Trx2 - no flagging required. Added to this all these trxs always have the
> > OptinRBF so if these platforms need to be able to recreate completely
> their
> > trxs they have that option as well. The option to Swop out or bump up
> trxs
> > seems to be well covered under those two options.
>
> You are not correct. One of the most important use-cases for full-rbf is
> multi-party transactions; adding that limitation to full-rbf negates that
> usecase. See my post on why full-rbf makes DoS attacks on multiparty
> protocols
> significantly more expensive:
>
>
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2023-January/021322.html


I also note that there is ongoing debate as to the need for full RBF see
here
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2023-January/021331.html
.

This seems to be an extreme edge case - with Opt-in RBF, FSS Full RBF and
common sense - offering enough coverage to mitigate.

0-conf although may not be liked by some actors in Bitcoin, is engaged with
free choice and understanding of the risks. 0-conf is a long standing and
significant use case which should not be ignored. 0-conf demise should be
viewed as being a major and unnecessary cost to FullRBF as currently
implemented.

> --
> https://petertodd.org 'peter'[:-1]@petertodd.org
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230114/70440238/attachment-0001.html>

From alicexbt at protonmail.com  Sun Jan 15 13:04:05 2023
From: alicexbt at protonmail.com (alicexbt)
Date: Sun, 15 Jan 2023 13:04:05 +0000
Subject: [bitcoin-dev] A new Bitcoin implementation integrated with Core
	Lightning
In-Reply-To: <aka4qP9Cig-OhfMlQ9y1kghZWExjpno4cs47KIgYwv4aLYtiQB37eHbj2X2hiDuoK0D1gSeKWP97P0bRADbTg1CZRBIpHGZ5WFFYPWIJ87Y=@protonmail.com>
References: <aka4qP9Cig-OhfMlQ9y1kghZWExjpno4cs47KIgYwv4aLYtiQB37eHbj2X2hiDuoK0D1gSeKWP97P0bRADbTg1CZRBIpHGZ5WFFYPWIJ87Y=@protonmail.com>
Message-ID: <TuO1JqgNYiASRsqGmtEMG6Wxjxj4GYJpsmn_2aQgBnf899qwPKVShhraTiSXOTMKll0qZSKWv9k-Q1K11Nt13Pooic87ErynC5l0ugrxaaw=@protonmail.com>

Hi Michael,

If I were to fork bitcoin core and maintain an implementation, I wouldn't integrate any lightning implementation with it. Instead remove some things from bitcoin core and keep it simple. There is also scope for improving privacy. Example: https://github.com/bitcoinknots/bitcoin/issues/50

You might find the commits in this branch interesting if you are looking to remove things from bitcoin core and maintain an implementation with no gui, wallet, less RPCs etc.

https://github.com/jeremyRubin/bitcoin/commits/delete-it-all


/dev/fd0
floppy disc guy


Sent with Proton Mail secure email.

------- Original Message -------
On Sunday, January 15th, 2023 at 1:56 AM, Michael Folkson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:


> I tweeted this [0] back in November 2022.
> 
> "With the btcd bugs and the analysis paralysis on a RBF policy option in Core increasingly thinking @BitcoinKnots and consensus compatible forks of Core are the future. Gonna chalk that one up to another thing @LukeDashjr was right about all along."
> 
> A new bare bones Knots style Bitcoin implementation (in C++/C) integrated with Core Lightning was a long term idea I had (and presumably many others have had) but the dysfunction on the Bitcoin Core project this week (if anything it has been getting worse over time, not better) has made me start to take the idea more seriously. It is clear to me that the current way the Bitcoin Core project is being managed is not how I would like an open source project to be managed. Very little discussion is public anymore and decisions seem to be increasingly made behind closed doors or in private IRC channels (to the extent that decisions are made at all). Core Lightning seems to have the opposite problem. It is managed effectively in the open (admittedly with fewer contributors) but doesn't have the eyeballs or the usage that Bitcoin Core does. Regardless, selfishly I at some point would like a bare bones Bitcoin and Lightning implementation integrated in one codebase. The Bitcoin Core codebase has collected a lot of cruft over time and the ultra conservatism that is needed when treating (potential) consensus code seems to permeate into parts of the codebase that no one is using, definitely isn't consensus code and should probably just be removed.
> 
> The libbitcoinkernel project was (is?) an attempt to extract the consensus engine out of Core but it seems like it won't achieve that as consensus is just too slippery a concept and Knots style consensus compatible codebase forks of Bitcoin Core seem to still the model. To what extent you can safely chop off this cruft and effectively maintain this less crufty fork of Bitcoin Core also isn't clear to me yet.
> 
> Then there is the question of whether it makes sense to mix C and C++ code that people have different views on. C++ is obviously a superset of C but assuming this merging of Bitcoin Core and Core Lightning is/was the optimal final destination it surely would have been better if Core Lightning was written in the same language (i.e. with classes) as Bitcoin Core.
> 
> I'm just floating the idea to (hopefully) hear from people who are much more familiar with the entirety of the Bitcoin Core and Core Lightning codebases. It would be an ambitious long term project but it would be nice to focus on some ambitious project(s) (even if just conceptually) for a while given (thankfully) there seems to be a lull in soft fork activation chaos.
> 
> Thanks
> Michael
> 
> [0]:?https://twitter.com/michaelfolkson/status/1589220155006910464?s=20&t=GbPm7w5BqS7rS3kiVFTNcw
> 
> --
> Michael Folkson
> Email: michaelfolkson at protonmail.com
> Keybase: michaelfolkson
> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3

From michaelfolkson at protonmail.com  Mon Jan 16 15:45:36 2023
From: michaelfolkson at protonmail.com (Michael Folkson)
Date: Mon, 16 Jan 2023 15:45:36 +0000
Subject: [bitcoin-dev] [Lightning-dev] A new Bitcoin implementation
	integrated with Core Lightning
In-Reply-To: <KdDQGItU-BH7EotUQ9DoiUZRPM9TRnflf4P664Ue2ynCyj6ts1zFIoHxf4q-EsaM8b_GVrvXZZA9TtPX6BVY6CfSvXcme12lxLe_1RoAwZw=@protonmail.com>
References: <aka4qP9Cig-OhfMlQ9y1kghZWExjpno4cs47KIgYwv4aLYtiQB37eHbj2X2hiDuoK0D1gSeKWP97P0bRADbTg1CZRBIpHGZ5WFFYPWIJ87Y=@protonmail.com>
 <KdDQGItU-BH7EotUQ9DoiUZRPM9TRnflf4P664Ue2ynCyj6ts1zFIoHxf4q-EsaM8b_GVrvXZZA9TtPX6BVY6CfSvXcme12lxLe_1RoAwZw=@protonmail.com>
Message-ID: <tU0pTKOODHenOeHhFqEIC0uBDz_jj5mjVpQJcJun4uDm9YaNNHXSsLXsCSY-tMzb5dgQVcaEEdYF5zwGvlJ-OUfDH6KlJqzEpiArB3Kv2cA=@protonmail.com>

Hi alicexbt

Thanks for the suggestion. I'll take a look at the branch.

I'm personally pretty bullish on Lightning and Core Lightning is criminally underused. Plus it is more exciting (and hopefully will attract more contributors) to try something ambitious than just trim Core. I'll see if it is something the Core Lightning contributors might be interested in helping out on. I remember that Rusty said on a podcast that if he had another life he'd have liked to have worked on Core. This way he could potentially do both :)

Thanks
Michael

--
Michael Folkson
Email: michaelfolkson at protonmail.com
Keybase: michaelfolkson
PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3


------- Original Message -------
On Sunday, January 15th, 2023 at 12:58, alicexbt <alicexbt at protonmail.com> wrote:


> Hi Michael,
> 
> If I were to fork bitcoin core and maintain an implementation, I wouldn't integrate any lightning implementation with it. Instead remove some things from bitcoin core and keep it simple. There is also scope for improving privacy. Example: https://github.com/bitcoinknots/bitcoin/issues/50
> 
> You might find the commits in this branch interesting if you are looking to remove things from bitcoin core and maintain an implementation with no gui, wallet, less RPCs etc.
> 
> https://github.com/jeremyRubin/bitcoin/commits/delete-it-all
> 
> 
> /dev/fd0
> floppy disc guy
> 
> Sent with Proton Mail secure email.
> 
> ------- Original Message -------
> On Sunday, January 15th, 2023 at 1:56 AM, Michael Folkson via Lightning-dev lightning-dev at lists.linuxfoundation.org wrote:
> 
> 
> 
> > I tweeted this 0 back in November 2022.
> > 
> > "With the btcd bugs and the analysis paralysis on a RBF policy option in Core increasingly thinking @BitcoinKnots and consensus compatible forks of Core are the future. Gonna chalk that one up to another thing @LukeDashjr was right about all along."
> > 
> > A new bare bones Knots style Bitcoin implementation (in C++/C) integrated with Core Lightning was a long term idea I had (and presumably many others have had) but the dysfunction on the Bitcoin Core project this week (if anything it has been getting worse over time, not better) has made me start to take the idea more seriously. It is clear to me that the current way the Bitcoin Core project is being managed is not how I would like an open source project to be managed. Very little discussion is public anymore and decisions seem to be increasingly made behind closed doors or in private IRC channels (to the extent that decisions are made at all). Core Lightning seems to have the opposite problem. It is managed effectively in the open (admittedly with fewer contributors) but doesn't have the eyeballs or the usage that Bitcoin Core does. Regardless, selfishly I at some point would like a bare bones Bitcoin and Lightning implementation integrated in one codebase. The Bitcoin Core codebase has collected a lot of cruft over time and the ultra conservatism that is needed when treating (potential) consensus code seems to permeate into parts of the codebase that no one is using, definitely isn't consensus code and should probably just be removed.
> > 
> > The libbitcoinkernel project was (is?) an attempt to extract the consensus engine out of Core but it seems like it won't achieve that as consensus is just too slippery a concept and Knots style consensus compatible codebase forks of Bitcoin Core seem to still the model. To what extent you can safely chop off this cruft and effectively maintain this less crufty fork of Bitcoin Core also isn't clear to me yet.
> > 
> > Then there is the question of whether it makes sense to mix C and C++ code that people have different views on. C++ is obviously a superset of C but assuming this merging of Bitcoin Core and Core Lightning is/was the optimal final destination it surely would have been better if Core Lightning was written in the same language (i.e. with classes) as Bitcoin Core.
> > 
> > I'm just floating the idea to (hopefully) hear from people who are much more familiar with the entirety of the Bitcoin Core and Core Lightning codebases. It would be an ambitious long term project but it would be nice to focus on some ambitious project(s) (even if just conceptually) for a while given (thankfully) there seems to be a lull in soft fork activation chaos.
> > 
> > Thanks
> > Michael
> > 
> > --
> > Michael Folkson
> > Email: michaelfolkson at protonmail.com
> > Keybase: michaelfolkson
> > PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3

From daniel at gap600.com  Mon Jan 16 10:19:35 2023
From: daniel at gap600.com (Daniel Lipshitz)
Date: Mon, 16 Jan 2023 12:19:35 +0200
Subject: [bitcoin-dev] A proposal for Full RBF to not exclude Zero Conf
 use case
In-Reply-To: <CACkWPs_Nqm1663c1q8xHX=A0Gpa7m1kV_QX6t0s8uPOEh3WQLA@mail.gmail.com>
References: <CACkWPs_F94t9Q8TfyYYGxQANUT78SWFGkTOh6qRwnt=6ct7aig@mail.gmail.com>
 <CAAQdECAspoRJRz7j1ubAe=Cen==AVF5bm-Q2=0TiKc7NtbU65A@mail.gmail.com>
 <CACkWPs_4pjTo50=S86KPEznBs0PU7rd30rBGHq2Q5=6n6hYMgQ@mail.gmail.com>
 <CAHTn92wH17Z+p5cFOLpzsVUuTf4-nZc7tOjQr+_xjSU5groa0Q@mail.gmail.com>
 <CACkWPs9VawCYt7maiNqzafkFnHTiGJQkXMT4VXQQcG-rE2TTNw@mail.gmail.com>
 <Y5jxmItJIpIUVY+x@petertodd.org>
 <CACkWPs_jSLDg3seON0uu=ri6iR9cytXo2MEPJ5PVeap+iDreeQ@mail.gmail.com>
 <Y5zfuVGpRGaknwaU@petertodd.org>
 <CACkWPs_6z7UyXzejTqjy=i+SkSz-76VdzZ20K1DzcVJxan_HZg@mail.gmail.com>
 <Y8HvCbBd5+pm8Uj2@petertodd.org>
 <CACkWPs_Nqm1663c1q8xHX=A0Gpa7m1kV_QX6t0s8uPOEh3WQLA@mail.gmail.com>
Message-ID: <CACkWPs94npkm9b--vfAraoKxXK-2A0fgv-NBcyRHzSCASuO1Bw@mail.gmail.com>

Some further clarity on our unique trx hashes queried to our platform, our
initial and followup numbers on unique trx hashes queried were not accurate
- apologies. Bitcoin addresses queried and Usd value and unique were
accurate. This is as a result of our platform viewing each queried bitcoin
address as a transaction from our point of view.

 November 2022
  Total queried unique bitcoin address- circa 1.5m trxs
  Unique Bitcoin trx hashes queried- circa 500k
  USD value - circa 220m
  December 2022
   Total queried unique bitcoin address- circa 1.7m trxs
   Unique Bitcoin trx hashes queried - circa 500k
   USD value - circa 200m

There are further merchants and service providers who enable 0-conf on
Bitcoin who are not working via our platform - I do not know their numbers
but believe they are significant. 0-conf on Bitcoin with its understood
risks is a significant use case.

For third party clarification please see
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-December/021239.html
and
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-December/021238.html
________________________________

Daniel Lipshitz
GAP600| www.gap600.com




On Sat, Jan 14, 2023 at 10:15 PM Daniel Lipshitz <daniel at gap600.com> wrote:

>
>
>
> On Sat, Jan 14, 2023 at 1:53 AM Peter Todd <pete at petertodd.org> wrote:
>
>> On Sun, Dec 18, 2022 at 10:06:15AM +0200, Daniel Lipshitz wrote:
>> > GAP600 is not a trxs processor or liquidity provider we service
>> merchants,
>> > payment processors & non-custodial liquidity providers - our service is
>> > purely the 0-conf enabling our clients to accept 0-conf. Clients access
>> our
>> > service via API - sending us the Trx hash & output address. Our service
>> is
>> > not based on AML/KYC it is purely an analysis of the Bitcoin network.
>>
>> I checked and to sign up for your service, you ask for the name, phone
>> number,
>> email, and company name.
>>
>> That is an example of AML/KYC. By learning the tx hash and output
>> address, you
>> learn which addresses are associated with what real world entity is
>> paying for
>> your service. You learning that information for what you claim is ~10% of
>> all
>> transactions is a significant privacy concern. On that basiss alone, I
>> would
>> argue that full-rbf should be implemented specifically to destroy your
>> business
>> and stop the collection of that data.
>>
>> We have standard commercial information about the payment processors, non
> custodial liquidity providers and merchants which become our clients - we
> do not have any kyc/aml information or telephone number on who is sending
> our clients the bitcoin for deposit.  For us these are just bitcoin Trx
> which our clients choose to benefit from 0-conf deposit recognition. Our
> service is provided via API with the only information our clients share
> with us, regarding a specific bitcoin transaction, being public bitcoin
> information like trx hash and output address.
>
> > I am not at liberty to share names of other services which have developed
>> > their own 0-conf service - they include a payment processor on a
>> gambling
>> > platform which services multiple gambling operators, a standalone gaming
>> > payment processor, and a payment processor recently I have come across.
>> We
>> > also do not have a significant presence in Asia - so I don't have
>> > visibility there.
>>
>> No, I asked you for information on what companies are actually using
>> *your*
>> service. You claim to be involved with a huge % of all transactions. If
>> that is
>> in fact true, obviously it shouldn't be hard to provide some examples of
>> merchants using GAP600 to accept unconfirmed txs.
>>
>
> As already posted here
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-December/021240.html
> Max CEO from Coinspaid who has provided Cpoinspaid address clusters, see
> link, is available to discuss further and may choose to share further
> information on the merchants they support.
>
>>
>> > I don't see it being necessarily an either/or approach here. The risk
>> > looking to be mitigated with FullRBF seems to be able to be mitigated
>> with
>> > FullRBF but with a swop limitation of at least the Inputs of Trx1 being
>> in
>> > Trx2 - no flagging required. Added to this all these trxs always have
>> the
>> > OptinRBF so if these platforms need to be able to recreate completely
>> their
>> > trxs they have that option as well. The option to Swop out or bump up
>> trxs
>> > seems to be well covered under those two options.
>>
>> You are not correct. One of the most important use-cases for full-rbf is
>> multi-party transactions; adding that limitation to full-rbf negates that
>> usecase. See my post on why full-rbf makes DoS attacks on multiparty
>> protocols
>> significantly more expensive:
>>
>>
>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2023-January/021322.html
>
>
> I also note that there is ongoing debate as to the need for full RBF see
> here
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2023-January/021331.html
> .
>
> This seems to be an extreme edge case - with Opt-in RBF, FSS Full RBF and
> common sense - offering enough coverage to mitigate.
>
> 0-conf although may not be liked by some actors in Bitcoin, is engaged
> with free choice and understanding of the risks. 0-conf is a long standing
> and significant use case which should not be ignored. 0-conf demise should
> be viewed as being a major and unnecessary cost to FullRBF as currently
> implemented.
>
>> --
>> https://petertodd.org 'peter'[:-1]@petertodd.org
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230116/f3948317/attachment.html>

From lists at achow101.com  Mon Jan 16 23:47:09 2023
From: lists at achow101.com (Andrew Chow)
Date: Mon, 16 Jan 2023 23:47:09 +0000
Subject: [bitcoin-dev] OP_VAULT: a new vault proposal
Message-ID: <afde051e-4e63-368c-3251-70f829a51c4e@achow101.com>

Hi James,

This seems like a promising proposal, but I noticed have a few issues
regarding batching and privacy.

It seems like this proposal will encourage address reuse for vaults, at
least in some parts. It seems like it would not be difficult to ensure
that each vault address was unique through the use of key derivation.
The recovery and unvault scripts could be produced from ranged
descriptors and so there would each vault address would be unique as
each recovery and unvault script is unique. It would not be hard to have
descriptors for vaults, which would then allow for usage of other
descriptors and miniscript into the recovery and unvault scripts.

However the current construction makes it impossible to spend these
vaults together. Since OP_VAULT requires the recovery script of the
unvault output to match what's provided in the input, if there are
multiple inputs with different recovery scripts, then the transaction
will fail. I'm not sure how this could be solved though.

But from my reading of the code, it looks like the unvault scripts can
be unique, so at least address reuse can be avoided here. It just means
that the recovery scripts must be the same, and this would leave an
identifying mark on chain for every unvault. An observer would be able
to correlate unvault transactions by the hashes of the recovery scripts,
and I think this would be rather detrimental to user privacy, not to
mention that sweeping to recovery would also reveal all of your coins too.

On the topic of address reuse, the implemented optional re-vault output
explicitly requires address reuse, as well as breaking the batched
unvaulting of scripts that have different unvault scripts. It's
currently implemented as requiring the unvault script to exactly match
the prevout script of the inputs being spent. This means that all inputs
must have the same script. I think it would be sufficient to do the same
check as the OP_UNVAULT script and just require that the recovery script
and the delay are the same, with the hash of the trigger script being
provided in the input in the same way the target hash is provided for
OP_UNVAULT. This would break the address reuse requirement.

I'm also not convinced that OP_VAULT and OP_UNVAULT should be allowed
for bare and P2WSH outputs. It seems like it would make sense to just
limit their usage to tapscripts as this would simply their implementation.


Andrew

On 01/09/2023 11:07 AM, James O'Beirne via bitcoin-dev wrote:
> For the last few years, I've been interested in vaults as a way to
> substantially derisk custodying Bitcoin, both at personal and commercial
> scales. Instead of abating with familiarity, as enthusiasm sometimes
> does, my conviction that vaults are an almost necessary part of bitcoin's
> viability has only grown over the years.
>
> Since people first started discussing vaults, it's been pretty clear that
> some kind of covenant-enabling consensus functionality is necessary to
> provide the feature set necessary to make vault use practical.
>
> Earlier last year I experimented with using OP_CTV[1], a limited covenant
> mechanism, to implement a "minimum-viable" vault design. I found that the
> inherent limitations of a precomputed covenant scheme left the resulting
> vault implementation wanting, even though it was an improvement over
> existing strategies that rely on presigned transactions and (hopefully)
> ephemeral keys.
>
> But I also found proposed "general" covenant schemes to be
> unsuitable for this use. The bloated scriptPubKeys, both in size and
> complexity, that would result when implementing something like a vault
> weren't encouraging. Also importantly, the social-consensus quagmire
> regarding which covenant proposal to actually deploy feels at times
> intractable.
>
> As a result, I wanted to explore a middle way: a design solely concerned
> with making the best vault use possible, with covenant functionality as a
> secondary consideration. In other words, a proposal that would deliver
> the safety benefits of vaults to users without getting hung up on
> trying to solve the general problem of covenants.
>
> At first this design, OP_VAULT, was just sort of a pipe dream. But as I
> did more thinking (and eventually implementing) I became more convinced
> that, even if it isn't considered for soft-fork, it is a worthwhile
> device to serve as a standard benchmark against which other proposals
> might be judged.
>
> I wrote a paper that summarizes my findings and the resulting proposal:
> https://jameso.be/vaults.pdf
>
> along with an accompanying draft implementation:
> https://github.com/bitcoin/bitcoin/pull/26857
>
> I might work on a BIP if there's interest.
>
> James
>
> [1]: https://github.com/jamesob/simple-ctv-vault



From antoine.riard at gmail.com  Tue Jan 17 01:50:05 2023
From: antoine.riard at gmail.com (Antoine Riard)
Date: Tue, 17 Jan 2023 01:50:05 +0000
Subject: [bitcoin-dev] Bitcoin Contracting Primitives WG 3rd Meeting,
 Tuesday 17 Jan. 18:00 UTC
In-Reply-To: <CALZpt+Eou=m9LnZfZoxfZcQLs7UL5Te53whNgYO1fro05iSvDw@mail.gmail.com>
References: <CALZpt+Eou=m9LnZfZoxfZcQLs7UL5Te53whNgYO1fro05iSvDw@mail.gmail.com>
Message-ID: <CALZpt+GLUAqJv2GUqGLyziQ7BZgdifxvV-8fbzxqAR9Usx8LYg@mail.gmail.com>

Reminder: this is happening this _upcoming_ Tuesday.

Looking forward to the third session to roam over all the contracting
protocol use-cases and then listen to everyone doing research in the
contracting primitives/covenant spaces, where they would like more brain
power!

Best,
Antoine

Le ven. 6 janv. 2023 ? 00:26, Antoine Riard <antoine.riard at gmail.com> a
?crit :

> Hi list,
>
> I'm proposing Tuesday 17th January at 18:00 UTC, i.e week from now for the
> 3rd Bitcoin contracting primitives WG meeting (the third Tuesday of January
> month, as done previously).
>
> As a soft proposal for an agenda, it would be to start with the leftover
> of the last meeting agenda. Namely, roaming over all the contracting
> protocol and use-case, to ensure there is exhaustivity of the R&D effort
> w.r.t known ideas issued by the community during the past years. If you
> have been working on a use-case, and it's missing in the current listing,
> feel free to open a PR or bump me to do so (still same with primitives
> themselves ofc).
>
> The second part could be to take time to listen to everyone blockers in
> their contracting primitives/covenant research.
>
> About the R&D effort, one of my personal goal for the coming year would be
> to nurture some websites, with the archive material progressively gathered
> in the repository. The website would present the contracting protocol
> research according to the best engineering/scientific
> standards and ensure ideas neutrality. Ideally, it would enable collection
> of feedback on dimensions like privacy or economic scaling from the Bitcoin
> community of stakeholders at large, with Pretty Graphics (tm).
>
> Beyond, pursuing a "decentralized" spirit, looking forward to starting
> rotating meetings host during the year, as we're doing with BOLTs where
> it's rotating between Lightning implementations contributors. If you're
> interested in hosting one of the monthly meetings, feel free to open an
> issue against the repository or bump me.
>
> Communication venue is #bitcoin-contracting-primitives-wg on Libera Chat.
> Logs of the previous session are available here [0].
>
> Let it know if you have more questions or feedback.
>
> Cheers,
> Antoine
>
> [0]
> https://github.com/ariard/bitcoin-contracting-primitives-wg/blob/main/meetings/meetings-20-12.md
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230117/1feabd0b/attachment.html>

From aj at erisian.com.au  Tue Jan 17 07:46:38 2023
From: aj at erisian.com.au (Anthony Towns)
Date: Tue, 17 Jan 2023 17:46:38 +1000
Subject: [bitcoin-dev] OP_VAULT: a new vault proposal
In-Reply-To: <afde051e-4e63-368c-3251-70f829a51c4e@achow101.com>
References: <afde051e-4e63-368c-3251-70f829a51c4e@achow101.com>
Message-ID: <Y8ZSXrxfR8HrB8zD@erisian.com.au>

On Mon, Jan 16, 2023 at 11:47:09PM +0000, Andrew Chow via bitcoin-dev wrote:
> It seems like this proposal will encourage address reuse for vaults,

(That is listed as an explicit goal: "A single vault scriptPubKey should
be able to "receive" multiple deposits")

> However the current construction makes it impossible to spend these
> vaults together. Since OP_VAULT requires the recovery script of the
> unvault output to match what's provided in the input,

I don't think this part is a big problem -- the recovery path requires
revealing a secret, but if you separate that secret from the recovery
path sPK, you could vary the secret. ie:

  unvault1 delay recovery1 VAULT
  unvault2 delay recovery2 VAULT

where recovery1 = SHA256(SHA256(secret1), rSPK) and recovery2 =
SHA256(SHA256(secret2), rSPK), and both are spendable when the top stack
element is secretN and the first output pays at least the sum of all
the OP_VAULT using inputs to rSPK. So batched recovery could work fine,
I think.

(If you're using the same "recovery" parameter to each VAULT, then
you're revealing which txs are in your vault at spend time, rather than
at receive time, which doesn't seem all that much better to me)

But the problem with this is it prevents you from combining vaults when
spending normally: so if you've got a bunch of vaults with 1 BTC each,
and want to spend 10 BTC on a house, you'll need to make 11 separate
transactions:

  * 10 txs each spending a single vault utxo, satisfying
      <uN> <delay> <rN> OP_VAULT
    via the uN path, creating an output of
      <outhash> <delay> <rN> OP_UNVAULT

  * 1 tx spending all the OP_UNVAULT outputs to a common set of outputs
    <uN>, with nSequence set to a relative timelock of at least <delay>

Whereas if you use an identical OP_VAULT script for all the utxos in
your vault, that can look like:

  * 1 tx, spending all the vault utxos, to a single OP_UNVAULT output,
    with the same <delay> <rN> that all the inputs share.

  * 1 tx spending the OP_UNVAULT output after a delay

But maybe you can get the best of both worlds just by having the unvault
path for OP_VAULT require you to put the vout number for its corresponding
OP_UNVAULT output on the stack? Then if you're doing address reuse, you
use a single vout for multiple inputs; and if you're avoiding address
reuse, you use multiple outputs, and provide the mapping between inputs
and outputs explicitly.

Cheers,
aj


From erik at q32.com  Tue Jan 17 17:07:54 2023
From: erik at q32.com (Erik Aronesty)
Date: Tue, 17 Jan 2023 12:07:54 -0500
Subject: [bitcoin-dev] A proposal for Full RBF to not exclude Zero Conf
 use case
In-Reply-To: <CACkWPs94npkm9b--vfAraoKxXK-2A0fgv-NBcyRHzSCASuO1Bw@mail.gmail.com>
References: <CACkWPs_F94t9Q8TfyYYGxQANUT78SWFGkTOh6qRwnt=6ct7aig@mail.gmail.com>
 <CAAQdECAspoRJRz7j1ubAe=Cen==AVF5bm-Q2=0TiKc7NtbU65A@mail.gmail.com>
 <CACkWPs_4pjTo50=S86KPEznBs0PU7rd30rBGHq2Q5=6n6hYMgQ@mail.gmail.com>
 <CAHTn92wH17Z+p5cFOLpzsVUuTf4-nZc7tOjQr+_xjSU5groa0Q@mail.gmail.com>
 <CACkWPs9VawCYt7maiNqzafkFnHTiGJQkXMT4VXQQcG-rE2TTNw@mail.gmail.com>
 <Y5jxmItJIpIUVY+x@petertodd.org>
 <CACkWPs_jSLDg3seON0uu=ri6iR9cytXo2MEPJ5PVeap+iDreeQ@mail.gmail.com>
 <Y5zfuVGpRGaknwaU@petertodd.org>
 <CACkWPs_6z7UyXzejTqjy=i+SkSz-76VdzZ20K1DzcVJxan_HZg@mail.gmail.com>
 <Y8HvCbBd5+pm8Uj2@petertodd.org>
 <CACkWPs_Nqm1663c1q8xHX=A0Gpa7m1kV_QX6t0s8uPOEh3WQLA@mail.gmail.com>
 <CACkWPs94npkm9b--vfAraoKxXK-2A0fgv-NBcyRHzSCASuO1Bw@mail.gmail.com>
Message-ID: <CAJowKgK9VQ3bgZZnnmTBkhF8DFrv08ywEQEC5oTvXX66d=mkoQ@mail.gmail.com>

> 0-conf on Bitcoin with its understood risks is a significant use case

and that use case doesn't change, at all, with full rbf.   the risk profile
will, likely, remain the same.   observation of the fee paid, history of
doing business with the customer, transaction size are all needed.

On Mon, Jan 16, 2023 at 1:50 PM Daniel Lipshitz via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Some further clarity on our unique trx hashes queried to our platform, our
> initial and followup numbers on unique trx hashes queried were not accurate
> - apologies. Bitcoin addresses queried and Usd value and unique were
> accurate. This is as a result of our platform viewing each queried bitcoin
> address as a transaction from our point of view.
>
>  November 2022
>   Total queried unique bitcoin address- circa 1.5m trxs
>   Unique Bitcoin trx hashes queried- circa 500k
>   USD value - circa 220m
>   December 2022
>    Total queried unique bitcoin address- circa 1.7m trxs
>    Unique Bitcoin trx hashes queried - circa 500k
>    USD value - circa 200m
>
> There are further merchants and service providers who enable 0-conf on
> Bitcoin who are not working via our platform - I do not know their numbers
> but believe they are significant. 0-conf on Bitcoin with its understood
> risks is a significant use case.
>
> For third party clarification please see
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-December/021239.html
> and
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-December/021238.html
> ________________________________
>
> Daniel Lipshitz
> GAP600| www.gap600.com
>
>
>
>
> On Sat, Jan 14, 2023 at 10:15 PM Daniel Lipshitz <daniel at gap600.com>
> wrote:
>
>>
>>
>>
>> On Sat, Jan 14, 2023 at 1:53 AM Peter Todd <pete at petertodd.org> wrote:
>>
>>> On Sun, Dec 18, 2022 at 10:06:15AM +0200, Daniel Lipshitz wrote:
>>> > GAP600 is not a trxs processor or liquidity provider we service
>>> merchants,
>>> > payment processors & non-custodial liquidity providers - our service is
>>> > purely the 0-conf enabling our clients to accept 0-conf. Clients
>>> access our
>>> > service via API - sending us the Trx hash & output address. Our
>>> service is
>>> > not based on AML/KYC it is purely an analysis of the Bitcoin network.
>>>
>>> I checked and to sign up for your service, you ask for the name, phone
>>> number,
>>> email, and company name.
>>>
>>> That is an example of AML/KYC. By learning the tx hash and output
>>> address, you
>>> learn which addresses are associated with what real world entity is
>>> paying for
>>> your service. You learning that information for what you claim is ~10%
>>> of all
>>> transactions is a significant privacy concern. On that basiss alone, I
>>> would
>>> argue that full-rbf should be implemented specifically to destroy your
>>> business
>>> and stop the collection of that data.
>>>
>>> We have standard commercial information about the payment processors,
>> non custodial liquidity providers and merchants which become our clients -
>> we do not have any kyc/aml information or telephone number on who is
>> sending our clients the bitcoin for deposit.  For us these are just bitcoin
>> Trx which our clients choose to benefit from 0-conf deposit recognition.
>> Our service is provided via API with the only information our clients share
>> with us, regarding a specific bitcoin transaction, being public bitcoin
>> information like trx hash and output address.
>>
>> > I am not at liberty to share names of other services which have
>>> developed
>>> > their own 0-conf service - they include a payment processor on a
>>> gambling
>>> > platform which services multiple gambling operators, a standalone
>>> gaming
>>> > payment processor, and a payment processor recently I have come
>>> across. We
>>> > also do not have a significant presence in Asia - so I don't have
>>> > visibility there.
>>>
>>> No, I asked you for information on what companies are actually using
>>> *your*
>>> service. You claim to be involved with a huge % of all transactions. If
>>> that is
>>> in fact true, obviously it shouldn't be hard to provide some examples of
>>> merchants using GAP600 to accept unconfirmed txs.
>>>
>>
>> As already posted here
>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-December/021240.html
>> Max CEO from Coinspaid who has provided Cpoinspaid address clusters, see
>> link, is available to discuss further and may choose to share further
>> information on the merchants they support.
>>
>>>
>>> > I don't see it being necessarily an either/or approach here. The risk
>>> > looking to be mitigated with FullRBF seems to be able to be mitigated
>>> with
>>> > FullRBF but with a swop limitation of at least the Inputs of Trx1
>>> being in
>>> > Trx2 - no flagging required. Added to this all these trxs always have
>>> the
>>> > OptinRBF so if these platforms need to be able to recreate completely
>>> their
>>> > trxs they have that option as well. The option to Swop out or bump up
>>> trxs
>>> > seems to be well covered under those two options.
>>>
>>> You are not correct. One of the most important use-cases for full-rbf is
>>> multi-party transactions; adding that limitation to full-rbf negates that
>>> usecase. See my post on why full-rbf makes DoS attacks on multiparty
>>> protocols
>>> significantly more expensive:
>>>
>>>
>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2023-January/021322.html
>>
>>
>> I also note that there is ongoing debate as to the need for full RBF see
>> here
>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2023-January/021331.html
>> .
>>
>> This seems to be an extreme edge case - with Opt-in RBF, FSS Full RBF and
>> common sense - offering enough coverage to mitigate.
>>
>> 0-conf although may not be liked by some actors in Bitcoin, is engaged
>> with free choice and understanding of the risks. 0-conf is a long standing
>> and significant use case which should not be ignored. 0-conf demise should
>> be viewed as being a major and unnecessary cost to FullRBF as currently
>> implemented.
>>
>>> --
>>> https://petertodd.org 'peter'[:-1]@petertodd.org
>>>
>> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230117/fd2d84ef/attachment-0001.html>

From daniel at gap600.com  Tue Jan 17 17:27:13 2023
From: daniel at gap600.com (Daniel Lipshitz)
Date: Tue, 17 Jan 2023 19:27:13 +0200
Subject: [bitcoin-dev] A proposal for Full RBF to not exclude Zero Conf
 use case
In-Reply-To: <CAJowKgK9VQ3bgZZnnmTBkhF8DFrv08ywEQEC5oTvXX66d=mkoQ@mail.gmail.com>
References: <CACkWPs_F94t9Q8TfyYYGxQANUT78SWFGkTOh6qRwnt=6ct7aig@mail.gmail.com>
 <CAAQdECAspoRJRz7j1ubAe=Cen==AVF5bm-Q2=0TiKc7NtbU65A@mail.gmail.com>
 <CACkWPs_4pjTo50=S86KPEznBs0PU7rd30rBGHq2Q5=6n6hYMgQ@mail.gmail.com>
 <CAHTn92wH17Z+p5cFOLpzsVUuTf4-nZc7tOjQr+_xjSU5groa0Q@mail.gmail.com>
 <CACkWPs9VawCYt7maiNqzafkFnHTiGJQkXMT4VXQQcG-rE2TTNw@mail.gmail.com>
 <Y5jxmItJIpIUVY+x@petertodd.org>
 <CACkWPs_jSLDg3seON0uu=ri6iR9cytXo2MEPJ5PVeap+iDreeQ@mail.gmail.com>
 <Y5zfuVGpRGaknwaU@petertodd.org>
 <CACkWPs_6z7UyXzejTqjy=i+SkSz-76VdzZ20K1DzcVJxan_HZg@mail.gmail.com>
 <Y8HvCbBd5+pm8Uj2@petertodd.org>
 <CACkWPs_Nqm1663c1q8xHX=A0Gpa7m1kV_QX6t0s8uPOEh3WQLA@mail.gmail.com>
 <CACkWPs94npkm9b--vfAraoKxXK-2A0fgv-NBcyRHzSCASuO1Bw@mail.gmail.com>
 <CAJowKgK9VQ3bgZZnnmTBkhF8DFrv08ywEQEC5oTvXX66d=mkoQ@mail.gmail.com>
Message-ID: <CACkWPs867CH+haR8ZEjnX7kzsruX=TbrhnRX+-XFJpnv=EBHnw@mail.gmail.com>

> > 0-conf on Bitcoin with its understood risks is a significant use case
>
> and that use case doesn't change, at all, with full rbf.   the risk
> profile will, likely, remain the same.   observation of the fee paid,
> history of doing business with the customer, transaction size are all
> needed.
>

Currently 0-conf recognition is done without any KYC on the payor, this
includes activities like, gaming, non-custodial trading and applications.
In general OptinRBF is not possible to offer 0-conf since as soon as it is
recognised it can be double spent. Full RBF would make all trxs just like
OptinRBF. FullRBF but with FSS implemented will still enable 0-conf
acceptance.

>
> On Mon, Jan 16, 2023 at 1:50 PM Daniel Lipshitz via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>> Some further clarity on our unique trx hashes queried to our platform,
>> our initial and followup numbers on unique trx hashes queried were not
>> accurate - apologies. Bitcoin addresses queried and Usd value and unique
>> were accurate. This is as a result of our platform viewing each queried
>> bitcoin address as a transaction from our point of view.
>>
>>  November 2022
>>   Total queried unique bitcoin address- circa 1.5m trxs
>>   Unique Bitcoin trx hashes queried- circa 500k
>>   USD value - circa 220m
>>   December 2022
>>    Total queried unique bitcoin address- circa 1.7m trxs
>>    Unique Bitcoin trx hashes queried - circa 500k
>>    USD value - circa 200m
>>
>> There are further merchants and service providers who enable 0-conf on
>> Bitcoin who are not working via our platform - I do not know their numbers
>> but believe they are significant. 0-conf on Bitcoin with its understood
>> risks is a significant use case.
>>
>> For third party clarification please see
>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-December/021239.html
>> and
>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-December/021238.html
>> ________________________________
>>
>> Daniel Lipshitz
>> GAP600| www.gap600.com
>>
>>
>>
>>
>> On Sat, Jan 14, 2023 at 10:15 PM Daniel Lipshitz <daniel at gap600.com>
>> wrote:
>>
>>>
>>>
>>>
>>> On Sat, Jan 14, 2023 at 1:53 AM Peter Todd <pete at petertodd.org> wrote:
>>>
>>>> On Sun, Dec 18, 2022 at 10:06:15AM +0200, Daniel Lipshitz wrote:
>>>> > GAP600 is not a trxs processor or liquidity provider we service
>>>> merchants,
>>>> > payment processors & non-custodial liquidity providers - our service
>>>> is
>>>> > purely the 0-conf enabling our clients to accept 0-conf. Clients
>>>> access our
>>>> > service via API - sending us the Trx hash & output address. Our
>>>> service is
>>>> > not based on AML/KYC it is purely an analysis of the Bitcoin network.
>>>>
>>>> I checked and to sign up for your service, you ask for the name, phone
>>>> number,
>>>> email, and company name.
>>>>
>>>> That is an example of AML/KYC. By learning the tx hash and output
>>>> address, you
>>>> learn which addresses are associated with what real world entity is
>>>> paying for
>>>> your service. You learning that information for what you claim is ~10%
>>>> of all
>>>> transactions is a significant privacy concern. On that basiss alone, I
>>>> would
>>>> argue that full-rbf should be implemented specifically to destroy your
>>>> business
>>>> and stop the collection of that data.
>>>>
>>>> We have standard commercial information about the payment processors,
>>> non custodial liquidity providers and merchants which become our clients -
>>> we do not have any kyc/aml information or telephone number on who is
>>> sending our clients the bitcoin for deposit.  For us these are just bitcoin
>>> Trx which our clients choose to benefit from 0-conf deposit recognition.
>>> Our service is provided via API with the only information our clients share
>>> with us, regarding a specific bitcoin transaction, being public bitcoin
>>> information like trx hash and output address.
>>>
>>> > I am not at liberty to share names of other services which have
>>>> developed
>>>> > their own 0-conf service - they include a payment processor on a
>>>> gambling
>>>> > platform which services multiple gambling operators, a standalone
>>>> gaming
>>>> > payment processor, and a payment processor recently I have come
>>>> across. We
>>>> > also do not have a significant presence in Asia - so I don't have
>>>> > visibility there.
>>>>
>>>> No, I asked you for information on what companies are actually using
>>>> *your*
>>>> service. You claim to be involved with a huge % of all transactions. If
>>>> that is
>>>> in fact true, obviously it shouldn't be hard to provide some examples of
>>>> merchants using GAP600 to accept unconfirmed txs.
>>>>
>>>
>>> As already posted here
>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-December/021240.html
>>> Max CEO from Coinspaid who has provided Cpoinspaid address clusters, see
>>> link, is available to discuss further and may choose to share further
>>> information on the merchants they support.
>>>
>>>>
>>>> > I don't see it being necessarily an either/or approach here. The risk
>>>> > looking to be mitigated with FullRBF seems to be able to be mitigated
>>>> with
>>>> > FullRBF but with a swop limitation of at least the Inputs of Trx1
>>>> being in
>>>> > Trx2 - no flagging required. Added to this all these trxs always have
>>>> the
>>>> > OptinRBF so if these platforms need to be able to recreate completely
>>>> their
>>>> > trxs they have that option as well. The option to Swop out or bump up
>>>> trxs
>>>> > seems to be well covered under those two options.
>>>>
>>>> You are not correct. One of the most important use-cases for full-rbf is
>>>> multi-party transactions; adding that limitation to full-rbf negates
>>>> that
>>>> usecase. See my post on why full-rbf makes DoS attacks on multiparty
>>>> protocols
>>>> significantly more expensive:
>>>>
>>>>
>>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2023-January/021322.html
>>>
>>>
>>> I also note that there is ongoing debate as to the need for full RBF see
>>> here
>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2023-January/021331.html
>>> .
>>>
>>> This seems to be an extreme edge case - with Opt-in RBF, FSS Full RBF
>>> and common sense - offering enough coverage to mitigate.
>>>
>>> 0-conf although may not be liked by some actors in Bitcoin, is engaged
>>> with free choice and understanding of the risks. 0-conf is a long standing
>>> and significant use case which should not be ignored. 0-conf demise should
>>> be viewed as being a major and unnecessary cost to FullRBF as currently
>>> implemented.
>>>
>>>> --
>>>> https://petertodd.org 'peter'[:-1]@petertodd.org
>>>>
>>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230117/d31b7aba/attachment-0001.html>

From billy.tetrud at gmail.com  Wed Jan 18 19:00:29 2023
From: billy.tetrud at gmail.com (Billy Tetrud)
Date: Wed, 18 Jan 2023 13:00:29 -0600
Subject: [bitcoin-dev] OP_VAULT: a new vault proposal
In-Reply-To: <Y8ZSXrxfR8HrB8zD@erisian.com.au>
References: <afde051e-4e63-368c-3251-70f829a51c4e@achow101.com>
 <Y8ZSXrxfR8HrB8zD@erisian.com.au>
Message-ID: <CAGpPWDbLC-om+SR5boRv8U0RptqRUMYJhYvnLbpvm3AKOuX4Fg@mail.gmail.com>

I like the proposal of a targeted wallet vault opcode. It keeps things
constrained, limiting objections to those of the form "but if we had X it
would do all this and more so why add this complexity when it will be
obsoleted in the future?"

> An idealized vault
> no existing vault design meets this set of features.

My proposal for efficient wallet vaults
<https://github.com/fresheneesz/bip-efficient-bitcoin-vaults> was designed
to meet all of those criteria, and allows batching as well. It also allows
sending in a single transaction vs the two it would take with OP_VAULT and
several other benefits. However, it uses a general covenant opcode to do
it, along with several other new opcodes specified in that write up.

>  it must first be spent into an OP_UNVAULT output

I don't see in the write up how a node verifies that the destination of a
spend using an OP_VAULT output uses an appropriate OP_UNVAULT script. I see
you mentioned above (but not in the write up) that the script pub key needs
to be bare. But it would be very helpful if you detailed exactly how this
is intended to be done in that document.

It seems that Greg Sanders noticed the same thing. I like his suggestion as
you reworded it above, makes a lot of sense.

> I think the fix is just requiring a single additional witness data item
during OP_VAULT spend (for unvault path), mandating the
<target-outputs-hash> to be included in the witness stack as an input to
OP_VAULT opcode, and transaction introspection then checks to make sure the
witness item and the corresponding output script template matches the
expected.

>  If it becomes necessary to make use of the recovery path, the recovery
scriptPubKey will be revealed, which means that any other vaults with that
recovery path may be swept there by an unauthenticated party.

Another issue is that the recovery path becomes the easiest mechanism of
attack. It would usually be prudent to store this recovery address with
every key to the vault, and potentially in other places as well, so as to
minimize the possibility that the funds are lost or stolen. In such a
situation, this means that an attacker that finds any key can grief the
vault by spending it to its recovery address. My "efficient wallet vault"
design I mentioned above doesn't have this issue, nor the associated
batching DoS attack.

> if the recovery path should be committed with a signature
> This would enable a "sign-to-recover" flow at the option of the user,
specified during vault creation.

This is rather limiting isn't it? Losing the key required to sign loses
your recovery option. Seems brittle. It seems better to me to include a
<recovery-initiation-spk-hash> that operates similarly to
<recovery-spk-hash> - where some arbitrary script must be fulfilled to
allow the recovery path to be spent. For a recovery path, you'd probably
often want one of the keys required to spend from the recovery address,
since without access to one of those keys, you can't spend from the
recovery address anyway (and the spend path is an effective burn). Having
some ability to allow an n-of-m situation for triggering the recovery path
seems desirable.

>  What do you think about the idea of making the recovery-path
authorization behavior variable on a single byte flag preceding the 32 byte
data push, as I mentioned in another post?

A more arbitrary construct here that allows you to use any kind of recovery
script would be much more flexible and preclude the need for any kind of
switching like this. It seems like it would also solve the issue Andrew
Chow mentioned where recovery transactions can only be batched if they all
share the same recovery output, since each output can simply include the
appropriate witness matching its recovery scriptPubkey.

Tho I don't think I quite understand why you mention the constraint
requiring recovery batching to only be done with vault outputs that have
matching recovery destinations. Wouldn't it be reasonably possible to allow
recovery outputs with any recovery address to be batched, and the amount
sums sent to each to be added up and verified?

>  1. script validation rules could require some allowable ?range? of
amount discounts
>  seems like a bad design

> 2. script validation rules could require that the unvault/recovery
outputs preserve the full value
> seems like the preferable approach

Both have tradeoffs. I would not call #1 an inherently bad design. I would
point out that for 2, disallowing the spending of vault funds without
access to already-unvaulted bitcoin seems like a very inconvenient design,
since it would require you in the best of cases to create more complex
transactions (or cpfp transaction chains) involving a 2nd wallet that you
involve in the unvaulting process, and in the worst case (if you have no
other bitcoin or other money on hand) you have to go asking a 3rd party for
their bitcoin to use in the unvaulting process. If someday wallet vaults
are the standard wallet construct, people might not even want to have a
non-vault wallet just for use in unvaulting.

#1 is the approach I used to design OP_LIMITFEECONTRIBUTION
<https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/lfc/bip-limit-fee-contribution.md>,
which allows for a fee-range specification that depends on recent median
fees included in blocks. This allows rather flexibly limiting fees to a
particular range of "priorities" regardless of fee environment.

For #2, it seems like Jeremy Rubin's Sponsor transactions would be ideal
for facilitation of adding a fee to an unvaulting transaction.

>  In the case of a withdrawal, unvaulted funds can skip the ?warm? wallet
step that precomputed vault funds must pass through on their way to
destinations only known at unvault time.

Hmm, it seems inaccurate to say that step is "skipped". While there isn't a
warm wallet step, its replaced with an OP_UNVAULT script step. So its not
skipped as much as modified I think, right?

It looks like the way the OP_UNVAULT is specified prevents any use where
you don't know the full set of outputs, which might happen in cases where
certain sighash flags might be useful (signing some outputs you know, but
allowing outputs that you don't know to be added later). This is another
thing my "efficient wallet vault" design should allow.





On Tue, Jan 17, 2023 at 1:47 AM Anthony Towns via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> On Mon, Jan 16, 2023 at 11:47:09PM +0000, Andrew Chow via bitcoin-dev
> wrote:
> > It seems like this proposal will encourage address reuse for vaults,
>
> (That is listed as an explicit goal: "A single vault scriptPubKey should
> be able to "receive" multiple deposits")
>
> > However the current construction makes it impossible to spend these
> > vaults together. Since OP_VAULT requires the recovery script of the
> > unvault output to match what's provided in the input,
>
> I don't think this part is a big problem -- the recovery path requires
> revealing a secret, but if you separate that secret from the recovery
> path sPK, you could vary the secret. ie:
>
>   unvault1 delay recovery1 VAULT
>   unvault2 delay recovery2 VAULT
>
> where recovery1 = SHA256(SHA256(secret1), rSPK) and recovery2 =
> SHA256(SHA256(secret2), rSPK), and both are spendable when the top stack
> element is secretN and the first output pays at least the sum of all
> the OP_VAULT using inputs to rSPK. So batched recovery could work fine,
> I think.
>
> (If you're using the same "recovery" parameter to each VAULT, then
> you're revealing which txs are in your vault at spend time, rather than
> at receive time, which doesn't seem all that much better to me)
>
> But the problem with this is it prevents you from combining vaults when
> spending normally: so if you've got a bunch of vaults with 1 BTC each,
> and want to spend 10 BTC on a house, you'll need to make 11 separate
> transactions:
>
>   * 10 txs each spending a single vault utxo, satisfying
>       <uN> <delay> <rN> OP_VAULT
>     via the uN path, creating an output of
>       <outhash> <delay> <rN> OP_UNVAULT
>
>   * 1 tx spending all the OP_UNVAULT outputs to a common set of outputs
>     <uN>, with nSequence set to a relative timelock of at least <delay>
>
> Whereas if you use an identical OP_VAULT script for all the utxos in
> your vault, that can look like:
>
>   * 1 tx, spending all the vault utxos, to a single OP_UNVAULT output,
>     with the same <delay> <rN> that all the inputs share.
>
>   * 1 tx spending the OP_UNVAULT output after a delay
>
> But maybe you can get the best of both worlds just by having the unvault
> path for OP_VAULT require you to put the vout number for its corresponding
> OP_UNVAULT output on the stack? Then if you're doing address reuse, you
> use a single vout for multiple inputs; and if you're avoiding address
> reuse, you use multiple outputs, and provide the mapping between inputs
> and outputs explicitly.
>
> Cheers,
> aj
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230118/17d1061b/attachment.html>

From pete at petertodd.org  Wed Jan 18 20:58:07 2023
From: pete at petertodd.org (Peter Todd)
Date: Wed, 18 Jan 2023 15:58:07 -0500
Subject: [bitcoin-dev] Pseudocode for robust tail emission
In-Reply-To: <2480C772-EE75-4350-BF11-FA9FEFC8A4EA@alfie.wtf>
References: <173552838-a7412589a40ea770709d0b227b056bd3@pmq5v.m5r2.onet>
 <Y690OjY0MA/YQ9IL@petertodd.org>
 <2480C772-EE75-4350-BF11-FA9FEFC8A4EA@alfie.wtf>
Message-ID: <Y8hdX55fT/Rssh1q@petertodd.org>

On Sun, Jan 01, 2023 at 11:42:50PM +1100, Alfie John wrote:
> On 31 Dec 2022, at 10:28 am, Peter Todd via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
> > 
> >> This way:
> >> 
> >> 1. system cannot be played
> >> 2. only in case of destructive halving: system waits for the recovery of network security
> > 
> > The immediate danger we have with halvings is that in a competitive market,
> > profit margins tend towards marginal costs - the cost to produce an additional
> > unit of production - rather than total costs - the cost necessary to recover
> > prior and future expenses. Since the halving is a sudden shock to the system,
> > under the right conditions we could have a significant amount of hashing power
> > just barely able to afford to hash prior to the halving, resulting in all that
> > hashing power immediately having to shut down and fees increasing dramatically,
> > and likely, chaotically.  Your proposal does not address that problem as it can
> > only measure difficulty prior to the halving point.
> 
> 
> > ... Since the halving is a sudden shock to the system
> 
> Is it though? Since everyone knows of the possible outcomes, wouldn't a possible halving be priced in? 

Re-read that I said. That explains why despite the halving being a forseeable
event, there's no mechanism to "price it in" when it comes to hashing power.

> > resulting in all that hashing power immediately having to shut down and fees increasing dramatically
> 
> Which should cause that hashing power to come back because of this fee increases.

Right now the total reward per transaction is $63, three orders of magnitude
higher than typical fees. Sufficient fee increases to bring back hashing power
in a scenario like that would cause enormous disruption to many things,
including Lightning channels.

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230118/8746a7e7/attachment-0001.sig>

From james.obeirne at gmail.com  Wed Jan 18 22:45:01 2023
From: james.obeirne at gmail.com (James O'Beirne)
Date: Wed, 18 Jan 2023 17:45:01 -0500
Subject: [bitcoin-dev] OP_VAULT: a new vault proposal
In-Reply-To: <Y8ZSXrxfR8HrB8zD@erisian.com.au>
References: <afde051e-4e63-368c-3251-70f829a51c4e@achow101.com>
 <Y8ZSXrxfR8HrB8zD@erisian.com.au>
Message-ID: <CAPfvXfKMsOF1g85Td8UpZdWSH+a0sRXK9Rur1ODduMauJhM+6A@mail.gmail.com>

I've implemented three changes based on suggestions from Greg Sanders
and AJ Towns.

I've segmented the changes into commits that should be
reasonable to follow, even though I'll probably rearrange the commit
structure later on.

1. Greg's suggestion: OP_UNVAULT outputs can now live behind
scripthashes. This means that the lifecycle of a vault can live entirely
within, say, Taproot. In this case the only thing that would reveal
the operation of the vault would be the content of the witness stack
when triggering an unvault or recovering. So I think no real privacy
benefits over the previous scheme, but certainly some efficiency ones
since we're moving more content from the scriptPubKey into the witness.

 Commit here:
https://github.com/bitcoin/bitcoin/pull/26857/commits/cd33d120c67cda7eb5c6bbfe3a1ea9fb6c5b93d1

2. AJ's suggestion: unvault trigger transactions can now have an extra
"revault" output that redeposits some balance to the same vault
scriptPubKey from which it came. This is nice because if the delay
period is long, you may want to manage a remaining vault balance
separately while the spent balance is pending an unvault.

 Commit here:
https://github.com/bitcoin/bitcoin/pull/26857/commits/cf3764fb503bc17c4438d1322ecf780b9dc3ef30

3. AJ's suggestion: instead of specifying <recovery-spk-hash>, introduce
a replacement parameter: <recovery-params>. This contains the same
target recovery sPK hash as before, but the remaining bytes contain a
scriptPubKey that functions as authorization for the recovery process.
This allows users to optionally avoid the risk of "recovery replays" at
the expense of having to maintain a recovery key. Users can opt out of
this by passing OP_TRUE for the recovery sPK. I guess maybe I could even
support just omitting an sPK altogether for the legacy behavior.

Commit here:
https://github.com/bitcoin/bitcoin/pull/26857/commits/fdfd5e93f96856fbb41243441177a40ebbac6085


The suggestions were good ones, and I think they've improved the
proposal.

My next steps are to do minor updates to the paper and start writing a
BIP draft.

Thanks to achow for the valuable feedback, which I'm still mulling on.

James
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230118/a1c7719a/attachment.html>

From james.obeirne at gmail.com  Wed Jan 18 23:37:51 2023
From: james.obeirne at gmail.com (James O'Beirne)
Date: Wed, 18 Jan 2023 18:37:51 -0500
Subject: [bitcoin-dev] OP_VAULT: a new vault proposal
In-Reply-To: <CAGpPWDbLC-om+SR5boRv8U0RptqRUMYJhYvnLbpvm3AKOuX4Fg@mail.gmail.com>
References: <afde051e-4e63-368c-3251-70f829a51c4e@achow101.com>
 <Y8ZSXrxfR8HrB8zD@erisian.com.au>
 <CAGpPWDbLC-om+SR5boRv8U0RptqRUMYJhYvnLbpvm3AKOuX4Fg@mail.gmail.com>
Message-ID: <CAPfvXf+GaJ-fO9TJVpSaKKhQU79p7krzFQg7+92PA5wHS3ps0Q@mail.gmail.com>

> I don't see in the write up how a node verifies that the destination
> of a spend using an OP_VAULT output uses an appropriate OP_UNVAULT
> script.

It's probably quicker for you to just read through the
implementation that I reference in the last section of the paper.

https://github.com/bitcoin/bitcoin/blob/fdfd5e93f96856fbb41243441177a40ebbac6085/src/script/interpreter.cpp#L1419-L1456

> It would usually be prudent to store this recovery address with every
> key to the vault, ...

I'm not sure I really follow here. Worth noting now that in OP_VAULT the
recovery path can be optionally gated by an arbitrary scriptPubKey.

> This is rather limiting isn't it? Losing the key required to sign
> loses your recovery option.

This functionality is optional in OP_VAULT as of today. You can specify
OP_TRUE (or maybe I should allow empty?) in the <recovery-params> to
disable any signing necessary for recovery.

> Wouldn't it be reasonably possible to allow recovery outputs with any
> recovery address to be batched, and the amount sums sent to each to be
> added up and verified?

I think the space savings from this is pretty negligible, since you're
just saving on the transaction overhead, and it makes the implementation
decently more complicated. One benefit might be sharing a common
fee-management output (e.g. ephemeral anchor) across the separate vaults
being recovered.

> If someday wallet vaults are the standard wallet construct, people
> might not even want to have a non-vault wallet just for use in
> unvaulting.

If you truly lacked any non-vaulted UTXOs and couldn't get any at a
reasonable price (?), I can imagine there might be a mechanism where you
include a payout output to some third party in a drafted unvault trigger
transaction, and they provide a spend of the ephemeral output.

Though you do raise a good point that this construction as written may
not be compatible with SIGHASH_GROUP... I'd have to think about that
one.

> Hmm, it seems inaccurate to say that step is "skipped". While there
> isn't a warm wallet step, its replaced with an OP_UNVAULT script step.

It is "skipped" in the sense that your bitcoin can't be stolen by having
to pass through some intermediate wallet during an authorized withdrawal
to a given target, in the way that they could if you had to prespecify
an unvault target when creating the vault.


---


> My proposal for efficient wallet vaults was designed to meet all of
> those criteria, and allows batching as well.

Probably a discussion of your proposal merits a different thread, but
some thoughts that occur:


> [from the README]
>
> OP_BEFOREBLOCKVERIFY - Verifies that the block the transaction is
> within has a block height below a particular number. This allows a
> spend-path to expire.

I think this breaks fundamental reorgability of transactions. I think
some of the other opcodes, e.g the one that limits fee contribution on
the basis of historical feerate, are going to be similarly
controversial.

> This is done by using a static intermediate address that has no values
> that are unique to the particular wallet vault address.

Does mean either that (i) this proposal doesn't have dynamic unvaulting
targets or, (ii) if you do, in order to be batch unvaulted, vaulted
coins need to first be spent into this intermediate output?

It sounds like (ii) is the case, given that your unvault target
specification lives in (I think?) the witness for the spend creating the
intermediate output.

If the intermediate address doesn't have any values which are unique to
a particular vault, how do you authorize recoveries from it?

---

Personally I think if you'd like to pursue your proposal, it'd be
valuable to see a full implementation. Might also make it easier to
assess the viability of the proposal.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230118/f32b1cef/attachment.html>

From billy.tetrud at gmail.com  Thu Jan 19 22:42:43 2023
From: billy.tetrud at gmail.com (Billy Tetrud)
Date: Thu, 19 Jan 2023 16:42:43 -0600
Subject: [bitcoin-dev] Using OP_VAULT to improve DLCs
In-Reply-To: <SJ1P223MB0531F7DDDFEB49DCF8E92CE9A1FD9@SJ1P223MB0531.NAMP223.PROD.OUTLOOK.COM>
References: <SJ1P223MB0531F7DDDFEB49DCF8E92CE9A1FD9@SJ1P223MB0531.NAMP223.PROD.OUTLOOK.COM>
Message-ID: <CAGpPWDZNHLpdmN=T_J8pJ2v1+RpekMeOQLY-wLjf5rRHTiXbNA@mail.gmail.com>

That's an interesting mechanism. Since the goal of OP_VAULT was to avoid
being another general covenant proposal, that avenue could be blocked by
requiring that for a transaction spending a utxo with a script using
OP_UNVAULT, the script (or taproot tree) must *only* contain that one
opcode call (perhaps with an escape hatch that OP_UNVAULT turns into a NOOP
if that constraint isn't satisfied). If no other conditions can be placed
on the utxo, then the only relevant condition is the delay (and the
prescribed output targets).

Even with this restriction, it could be used for Jeremy Rubin's congestion
control transactions, which just commits to a list of future outputs, to be
sent when the fee environment is cheaper.

However, James mentioned adding <recovery-params> that includes a
scriptPubKey for authorizing recovery. With that addition, OP_UNVAULT can
be used to do more general covenants by making `unvault-target-hash`
unsatisfiable (set to some random number that isn't derived from a hash)
the delay wouldn't matter, but arbitrary conditions can be set on spending
the utxo to the "recovery address" which could be another OP_UNVAULT. It
seems like that could be used as a general CTV-like covenant.

On Fri, Jan 13, 2023 at 2:04 PM Ben Carman via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Hi list,
>
> After reading through James's OP_VAULT proposal this week, I had a realization that this can be used for more than a deep cold storage wallet.
>
> Instead of vaulting and unvaulting, we can just send to a OP_UNVAULT output.
> When using OP_UNVAULT if we set the `recovery-spk-hash` to a burn address (ie OP_RETURN `<random value>`)
> and the `delay-period` to `0` we can use it as a not-so simple covenant with the `unvault-target-hash` being
> set to whatever output restrictions you want to create.
>
> Given this we can recreate a lot of what CTV promises, one of my favorites being
> [Lloyd's improvement to DLCs](https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019808.html)
> (I recommend reading that first)
>
> A similiar construction could be done by creating a taproot tree similiar to LLoyd's construction with each leaf looking like:
>
> `<hash-of-burn-spk> 0 <CET-hash_i> OP_UNVAULT <CET_i> CHECKSIG`
>
> In the same as Lloyd's proposal: when the oracle(s) reveals their attestations either party can combine them to get the secret key corresponding to `CET_i` and spend the coins to the CET (whose `unvault-target-hash`
> hash is `CET-hash`) which distributes the funds according to the contract.
>
> ## Comparison
>
> Compared to the original CTV proposal, this *should *get all the same computational savings. However, it would use more blockchain space.
>
> The main downside I see is our final spending script will be slightly larger.
> Instead of just having `<hash> OP_CTV` it will be replaced with `<hash> 0 <hash> OP_UNVAULT` (34 bytes extra, not including the witness discount).
> However, this may be negligible in the case of a DLC with many outcomes as a lot of the input size will be coming from the control block.
> This also can always be skipped by doing a cooperative close of the DLC if the internal-key of the taproot tree can be spent using something like MuSig.
>
> I imagine a lot of the other applications for CTV can be recreated with OP_VAULT using this same trick.
>
> # Credits
>
> - Lloyd Fournier for the original proposal
> - James O'Beirne for the OP_VAULT proposal and giving me the idea to skip the intial OP_VAULT and just use OP_UNVAULT
>
>
>
> Best,
>
> benthecarman
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230119/ca21c32f/attachment-0001.html>

From billy.tetrud at gmail.com  Thu Jan 19 22:49:30 2023
From: billy.tetrud at gmail.com (Billy Tetrud)
Date: Thu, 19 Jan 2023 16:49:30 -0600
Subject: [bitcoin-dev] OP_VAULT: a new vault proposal
In-Reply-To: <CAPfvXf+GaJ-fO9TJVpSaKKhQU79p7krzFQg7+92PA5wHS3ps0Q@mail.gmail.com>
References: <afde051e-4e63-368c-3251-70f829a51c4e@achow101.com>
 <Y8ZSXrxfR8HrB8zD@erisian.com.au>
 <CAGpPWDbLC-om+SR5boRv8U0RptqRUMYJhYvnLbpvm3AKOuX4Fg@mail.gmail.com>
 <CAPfvXf+GaJ-fO9TJVpSaKKhQU79p7krzFQg7+92PA5wHS3ps0Q@mail.gmail.com>
Message-ID: <CAGpPWDadhSxt3OsUYnDT4ee59DcXCw7wVGyV+Zu5jBx2en0eqA@mail.gmail.com>

>> It would usually be prudent to store this recovery address with every key
to the vault, ...
> Worth noting now that in OP_VAULT the recovery path can be optionally
gated by an arbitrary scriptPubKey.

Gating by a scriptPubKey solves the problem I was talking about there.
However, thinking about it more, I realized doing this basically turns
OP_VAULT into something able to do general covenants. By making
`unvault-target-hash`
unsatisfiable (set to some random number that isn't derived from a hash)
the delay wouldn't matter, but arbitrary conditions can be set on spending
the utxo to the "recovery address" which could be another OP_UNVAULT
destination. It seems like that could be used as a general CTV-like
covenant.

>> Wouldn't it be reasonably possible to allow recovery outputs with any
>> recovery address to be batched, and the amount sums sent to each to be
>> added up and verified?
> I think the space savings from this is pretty negligible

Besides space savings, there's the consideration of the usability of the
vault and downstream code complexity. One of the criteria I designed the
"efficient wallet vaults" opcodes for is that the vault spend should be
spendable in situations where a normal output is spendable as much as
possible. Having a constraint that prevents one type of otherwise spendable
output from being combined with another type would add complexity to all
downstream code which now has to have special cases - either a simple error
and recovery if they just want to disallow that type of opcode being
combined with other types (which may degrade the user experience by asking
them to provide a different utxo or do an unvaulting first), or some kind
of special case handling to make it work. Any kind of hybrid wallet
incorporating a vault (eg a wallet that combines a vault and a hot address
or lightning channel, kind of like Phoenix combines a lightning channel and
a normal onchain wallet) would need to deal with this kind of extra
complexity during utxo selection.

Are there currently any situations where one otherwise-spendable utxo can't
be mixed with another? If not, this added edge case deserves some extra
consideration I think.

> I can imagine there might be a mechanism where you include a payout
output to some third party in a drafted unvault trigger transaction, and
they provide a spend of the ephemeral output.

I agree that's doable. I just think it merits some consideration as to
whether that complexity (both for downstream code and for users) is a
favorable trade off vs having a solution to reasonably bound fees spendable
from the vault.

Consider the case where a self-custodying user would have a small set of
keys (2? 3?) and use all those keys to secure their vault, and just 1 of
them to secure their hot wallet. It doesn't seem an implausible case and I
could imagine that kind of set up becoming quite common. In such a case, if
the hot wallet key is stolen, it means one vault key is also stolen and the
hot wallets funds could be stolen at the same time as an unvaulting is
triggered. The need to figure out how to coordinate a 3rd party's help to
recover is at best an added difficulty and delay.

An alternative would be to keep a completely separate hot wallet key that
isn't use as part of the vault. But because key storage is by far the most
difficult and costly part of self-custody, every additional key that needs
to be stored is a significant additional burden (that's one of the benefits
of wallet vaults - fewer seeds needed for a given amount of
security/redundancy).

Another alternative would be to have a hot wallet that for its primary
spend-path uses a memory-only passphrase on one of the vault seeds (so
compromise of a vault seed won't compromise the hot wallet) and has a
recovery spend path that uses multiple (or all) vault seeds to recover if
you forget the passphrase. It certainly seems like something can be worked
out here to make the end user experience reasonable, but the additional
operational complexity this would entail still deserves consideration.

>> OP_BEFOREBLOCKVERIFY
> I think this breaks fundamental reorgability of transactions.

I discuss this in the Reorg Safety section here
<https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/bbv/bip-beforeblockverify.md#reorg-safety>
.

>> This is done by using a static intermediate address that has no values
>> that are unique to the particular wallet vault address.
> Does mean .. that (ii) .. in order to be batch unvaulted [with dynamic
unvaulting
targets], vaulted
> coins need to first be spent into this intermediate output?

It does support dynamic unvaulting using OP_PUSHOUTPUTSTACK
<https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/pos/bip-pushoutputstack.md>,
which adds data to an output that carries over to the execution when
spending the output created by a utxo that uses OP_PUSHOUTPUTSTACK. So the
design is done such that once the intermediate output has been confirmed
and the unvaulting delay has passed, it is then fully owned by the
recipient without a second transaction (because of the use of
OP_BEFOREBLOCKVERIFY). If OP_BEFOREBLOCKVERIFY is deemed to be
unacceptable, then the intermediate output is fully intermediate and a 2nd
transaction would be required to get it to its committed recipient.

> it'd be valuable to see a full implementation

While OP_BEFOREBLOCKVERIFY can be dropped with only somewhat minor degraded
usability, OP_PUSHOUTPUTSTACK is necessary for the proposal to work as
intended. I would want to see some support for the high-level concepts it
introduces before spending significant time on an implementation. It does
something fundamentally new that other opcodes haven't done: add "hidden"
data onto the output that allows for committing to destination addresses.
Maybe something along the line of Greg Sanders' suggestion for your
proposal could replace the need for this, but I'm not sure its possible
with how OP_CD is designed.

On Wed, Jan 18, 2023 at 5:38 PM James O'Beirne <james.obeirne at gmail.com>
wrote:

> > I don't see in the write up how a node verifies that the destination
> > of a spend using an OP_VAULT output uses an appropriate OP_UNVAULT
> > script.
>
> It's probably quicker for you to just read through the
> implementation that I reference in the last section of the paper.
>
>
> https://github.com/bitcoin/bitcoin/blob/fdfd5e93f96856fbb41243441177a40ebbac6085/src/script/interpreter.cpp#L1419-L1456
>
> > It would usually be prudent to store this recovery address with every
> > key to the vault, ...
>
> I'm not sure I really follow here. Worth noting now that in OP_VAULT the
> recovery path can be optionally gated by an arbitrary scriptPubKey.
>
> > This is rather limiting isn't it? Losing the key required to sign
> > loses your recovery option.
>
> This functionality is optional in OP_VAULT as of today. You can specify
> OP_TRUE (or maybe I should allow empty?) in the <recovery-params> to
> disable any signing necessary for recovery.
>
> > Wouldn't it be reasonably possible to allow recovery outputs with any
> > recovery address to be batched, and the amount sums sent to each to be
> > added up and verified?
>
> I think the space savings from this is pretty negligible, since you're
> just saving on the transaction overhead, and it makes the implementation
> decently more complicated. One benefit might be sharing a common
> fee-management output (e.g. ephemeral anchor) across the separate vaults
> being recovered.
>
> > If someday wallet vaults are the standard wallet construct, people
> > might not even want to have a non-vault wallet just for use in
> > unvaulting.
>
> If you truly lacked any non-vaulted UTXOs and couldn't get any at a
> reasonable price (?), I can imagine there might be a mechanism where you
> include a payout output to some third party in a drafted unvault trigger
> transaction, and they provide a spend of the ephemeral output.
>
> Though you do raise a good point that this construction as written may
> not be compatible with SIGHASH_GROUP... I'd have to think about that
> one.
>
> > Hmm, it seems inaccurate to say that step is "skipped". While there
> > isn't a warm wallet step, its replaced with an OP_UNVAULT script step.
>
> It is "skipped" in the sense that your bitcoin can't be stolen by having
> to pass through some intermediate wallet during an authorized withdrawal
> to a given target, in the way that they could if you had to prespecify
> an unvault target when creating the vault.
>
>
> ---
>
>
> > My proposal for efficient wallet vaults was designed to meet all of
> > those criteria, and allows batching as well.
>
> Probably a discussion of your proposal merits a different thread, but
> some thoughts that occur:
>
>
> > [from the README]
> >
> > OP_BEFOREBLOCKVERIFY - Verifies that the block the transaction is
> > within has a block height below a particular number. This allows a
> > spend-path to expire.
>
> I think this breaks fundamental reorgability of transactions. I think
> some of the other opcodes, e.g the one that limits fee contribution on
> the basis of historical feerate, are going to be similarly
> controversial.
>
> > This is done by using a static intermediate address that has no values
> > that are unique to the particular wallet vault address.
>
> Does mean either that (i) this proposal doesn't have dynamic unvaulting
> targets or, (ii) if you do, in order to be batch unvaulted, vaulted
> coins need to first be spent into this intermediate output?
>
> It sounds like (ii) is the case, given that your unvault target
> specification lives in (I think?) the witness for the spend creating the
> intermediate output.
>
> If the intermediate address doesn't have any values which are unique to
> a particular vault, how do you authorize recoveries from it?
>
> ---
>
> Personally I think if you'd like to pursue your proposal, it'd be
> valuable to see a full implementation. Might also make it easier to
> assess the viability of the proposal.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230119/acfb7455/attachment-0001.html>

From james.obeirne at gmail.com  Fri Jan 20 17:43:14 2023
From: james.obeirne at gmail.com (James O'Beirne)
Date: Fri, 20 Jan 2023 12:43:14 -0500
Subject: [bitcoin-dev] OP_VAULT: a new vault proposal
In-Reply-To: <afde051e-4e63-368c-3251-70f829a51c4e@achow101.com>
References: <afde051e-4e63-368c-3251-70f829a51c4e@achow101.com>
Message-ID: <CAPfvXf+7WRGYOHsYT8cfsaeO+eycPVuXsK_K-Kpe7vLUEL=6AQ@mail.gmail.com>

Andrew, thanks for taking the time.

> It seems like this proposal will encourage address reuse for vaults,
> at least in some parts. It seems like it would not be difficult to
> ensure that each vault address was unique through the use of key
> derivation.

I think it's worth stepping back and noting that this proposal defers
the level of privacy-vs.-efficiency to be decided by the end user.

For users who are very privacy conscious and are doing fairly low volume
(a few vaulted coins a month?), trading the ability to do batched
operations for no privacy loss seems reasonable. They can use a ranged
descriptor to generate recovery paths and unvault sPKs and reveal no
marginal information during recoveries or unvaults.

Though of course there still may be an obvious temporal association
across transactions in the case of recovery - everything with the same
unvault key has to be recovered at once.

For users who expect to have large numbers of vaulted coins and maybe
don't care as much about privacy (e.g. many commercial users), revealing
the related nature of coins that are being unvaulted or recovered seems
like an okay cost to pay. Such users might decide to create "tranches"
of vaults with different parameters in whatever manner makes sense for
their use.

Importantly: in either case, you can always keep the nature of
still-vaulted coins hidden by burying the OP_VAULT script in a taptree
and varying the internal key you use for each coin with a ranged
descriptor. This way, only the revealed contents of unvaults and
recoveries can be associated. So I think that's your worst case, which
really doesn't seem bad to me.

As an aside, a goal in supporting address reuse wasn't for address reuse
*per se* - it was to remove potential catastrophe resulting from the
case where you give someone a vault address to deposit to, and they wind
up depositing to it multiple times - whether you warned them against it
or not.


> I'm not sure how [batching without privacy loss] could be solved
> though.

For recovery, I think it might be intractable at the moment.

Seemingly unrelated vaults which have the same recovery parameters will
presumably be recovered together if the unvault key is compromised. The
simple fact that these outputs are being spent together and are OP_VAULT
scripts fundamentally reveals their association during recovery, no way
around that AFAICT.

Similarly for the unvaulting, you can't get around revealing that you're
spending a group of outputs that contain an OP_VAULT script.

As mentioned above, unvaulting -- regardless of whether your vault
configuration supports batching or not -- *never* has to correlate
unvaulted coins to still-vaulted coins if you are either

  (i) varying the internal key used for the OP_VAULT taptrees, or
  (ii) using the optional "authorized recovery" feature and are varying
       that sPK with a ranged descriptor.

So there's really never a case where unvaults have to reveal a
relationship to, or between, still-vaulted coins. Subsequent unvaults
may be able to be correlated though on the basis of the recovery sPK
target hash.


> It just means that the recovery scripts must be the same, and this
> would leave an identifying mark on chain for every unvault.

This is only true if the user decides to create vaults which share
"literal" recovery paths. At the risk of belaboring the point for
clarity, you can avoid this by generating the different "literal"
recovery paths from a ranged descriptor which is controlled by a single
private key -- of course at the cost of no batched recovery.


> not to mention that sweeping to recovery would also reveal all of your
> coins too.

Maybe it's worth contextualizing that recovery sweeps really only happen
as a final fallback in catastrophic cases that, in a world without
vaults, would result in the coins simply being stolen. In this case I
would guess most users are willing to make the privacy trade to retain
ownership of their coins.


> I think it would be sufficient to do the same check as the OP_UNVAULT
> script [when validating the revault output in the unvault trigger
> transaction] and just require that the recovery script and the delay
> are the same

Consider that this allows the holder of the unvault key (possibly an
attacker) to immediately spend the vault into a new vault configuration
with a different unvault key.

Obviously the recovery path would still be the same, and so the owner of
the vault could still sweep if the unvault key switch was unauthorized,
but I'll need to think a little bit more about whether this change is
more fundamental.

Generally that would be easy to implement, though. I'll think on it. My
suspicion is that you're right and this would be a good change.


> I'm also not convinced that OP_VAULT and OP_UNVAULT should be allowed
> for bare and P2WSH outputs. It seems like it would make sense to just
> limit their usage to tapscripts as this would simply their
> implementation.

I think you're right, and accordingly I'll shortly be reimplementing
this with OP_SUCCESSx overrides instead of OP_NOPs. I'd be curious to
know if anyone has any objections to this - i.e. if there's a solid case
for vaults in a pre-taproot context.

James
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230120/b645548b/attachment.html>

From jk_14 at op.pl  Sat Jan 21 10:20:02 2023
From: jk_14 at op.pl (jk_14 at op.pl)
Date: Sat, 21 Jan 2023 11:20:02 +0100
Subject: [bitcoin-dev] Pseudocode for robust tail emission
Message-ID: <82931557-3188a24755a7c83182882dc9296aa6e0@pmq6v.m5r2.onet>


This is the phrase that should be recalled very often:

"the total reward per transaction is Three Orders of Magnitude
higher than typical fees. Sufficient fee increases to bring back hashing power
in a scenario like that would cause Enormous Disruption to many things,
including Lightning channels"

> Your proposal does not address that problem as it can only measure difficulty prior to the halving point

Yes, my proposal of fixing the inevitable (but only spreaded over the long time) failure - is quite conservative, surprisingly.

Simplifying it to the edge case:
If in a four-year perspective there is no the average price +100% increase - to properly compensate last halving,
but instead there is a hashrate -50% drop - another possible and "proper" (!) compensation

- absolutely don't worse the situation by executing next halving,
accept such drop because there is nothing you can do about it
and wait with halvings for the hashrate to recover. As long as it takes.
Maybe even 20 years if necessary (fortunately we are at mature phase of ASIC technology right now),
And iterate.

This way we land at lowest possible annual inflation and set by a free market.

As I said this is quite conservative approach. It would suit bitcoin,.
Too bad it wasn't foreseen at the beginning...




W dniu 2023-01-18 21:58:15 u?ytkownik Peter Todd <pete at petertodd.org> napisa?:
> On Sun, Jan 01, 2023 at 11:42:50PM +1100, Alfie John wrote:
> On 31 Dec 2022, at 10:28 am, Peter Todd via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
> > 
> >> This way:
> >> 
> >> 1. system cannot be played
> >> 2. only in case of destructive halving: system waits for the recovery of network security
> > 
> > The immediate danger we have with halvings is that in a competitive market,
> > profit margins tend towards marginal costs - the cost to produce an additional
> > unit of production - rather than total costs - the cost necessary to recover
> > prior and future expenses. Since the halving is a sudden shock to the system,
> > under the right conditions we could have a significant amount of hashing power
> > just barely able to afford to hash prior to the halving, resulting in all that
> > hashing power immediately having to shut down and fees increasing dramatically,
> > and likely, chaotically.  Your proposal does not address that problem as it can
> > only measure difficulty prior to the halving point.
> 
> 
> > ... Since the halving is a sudden shock to the system
> 
> Is it though? Since everyone knows of the possible outcomes, wouldn't a possible halving be priced in? 

Re-read that I said. That explains why despite the halving being a forseeable
event, there's no mechanism to "price it in" when it comes to hashing power.

> > resulting in all that hashing power immediately having to shut down and fees increasing dramatically
> 
> Which should cause that hashing power to come back because of this fee increases.

Right now the total reward per transaction is $63, three orders of magnitude
higher than typical fees. Sufficient fee increases to bring back hashing power
in a scenario like that would cause enormous disruption to many things,
including Lightning channels.

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org



From john.tromp at gmail.com  Sun Jan 22 14:13:27 2023
From: john.tromp at gmail.com (John Tromp)
Date: Sun, 22 Jan 2023 15:13:27 +0100
Subject: [bitcoin-dev] Pseudocode for robust tail emission
In-Reply-To: <mailman.9.1674388803.14535.bitcoin-dev@lists.linuxfoundation.org>
References: <mailman.9.1674388803.14535.bitcoin-dev@lists.linuxfoundation.org>
Message-ID: <CAOU__fxuLinERszjCsLYStL-0vNG1Nbi5kdJG5MFCK3zz1q1Ww@mail.gmail.com>

> Right now the total reward per transaction is $63, three orders of magnitude
> higher than typical fees.

No need to exaggerate; this is only two orders of magnitude higher
than current fees, which are typically over $0.50

From d at ngould.dev  Sun Jan 22 20:50:44 2023
From: d at ngould.dev (Dan Gould)
Date: Sun, 22 Jan 2023 20:50:44 +0000
Subject: [bitcoin-dev] Serverless Payjoin
Message-ID: <3C0A6E4C-444E-4E75-829C-1A21D8EE40E0@ngould.dev>


Hi all,

I'm publishing a payjoin upgrade in response to a request from this list. The payjoin receiver no longer has to run a public server. They lean on a relay for the connection and share a symmetric-key for security rather than a TLS certificate or a Tor hidden service.

I think this work raises a greater problem which is that payjoin assumes synchronous communication while it?s an asynchronous world.

I added the full write-up in plain text below, though I recommend reading the gist for improved formatting and in order to benefit from future edits:
https://gist.github.com/DanGould/243e418752fff760c9f6b23bba8a32f9

Best regards,
Dan



Serverless Payjoin


Receive surveillance-busting bitcoin transfers without hosting a secure endpoint



OVERVIEW


Payjoin[1] solves the sole privacy problem left open in the bitcoin paper, that transactions with multiple inputs "necessarily reveal that their inputs were owned by the same owner."[2] Breaking that common-input ownership assumption requires contributions from multiple owners via interaction, namely hosting a server endpoint secured by a certificate on the receiving side. This problem has been singled out on this list as a barrier to greater payjoin adoption.[3]

Instead of a peer-hosted endpoint, this scheme weilds a TURN[4] relay for connectivity and symmetric cryptography for security. Without a replacement for secured networking, the relay could steal funds. Aside from a pre-shared secret and relayed networking, the protocol takes the same form as the existing BIP 78 payjoin spec.



BASIC SCHEME


The recipient requests that the relay allocate them an endpoint at which they may be reached by UDP. Once allocated, they listen on it. They then generate a 256-bit key, psk. Out of band, they share a BIP 21[5] payjoin uri including their unique relay allocation endpoint in the pj query parameter and psk in a new psk query parameter.

The sender constructs their request containing an original PSBT as in BIP 78. Instead of sending it over TLS or Tor, they follow noise framework NNpsk0[6] pattern. They encrypt the request using psk alongside an ephemeral sender key and MAC. The resulting ciphertext ensures message secrecy and integrity when relayed to the recipient by the pj endpoint.

The pay-to-endpoint protocol proceeds to produce a payjoin as in BIP 78 except that messages are secured by the noise NNpsk0 pattern rather than TLS or Tor.



IMPROVEMENTS


HTTP/3

TURN defaults to UDP. In order to adhere to the BIP 78 protocol HTTP messaging, HTTP/3 should be used on top of TURN/UDP.
Offline Asynchronous Payjoins

It may be possible for a relay to hold a requeust for an offline payjoin peer until that peer comes online. However, the BIP 78 spec recommends broadcasting request PSBTs in the case of an offline counterparty. Doing so exposes a na?ve, surveillance-vulnerable transaction which payjoin intends to avoid. More research needs to be done before such a protocol can be recommended.


Nostr

While a custom Nostr relay could in theory replace the TURN relay while sharing shnorr crypto with bitcoin, it would require another protocol to synchronize networking, since Nostr makes no assumptions about whether a peer is online or not, and a careful cryptography audit to secure. TURN and Noise are already well understood, tested, and have production library support across multiple popular languages and other bitcoin-related projects. Noise even has tooling for formal verification. Nostr relays may prove more likely to allow public access and more robust if we figure out async payjoin, however.



NOTEWORTHY DETAILS


Attack vectors

Since TURN relays can be used for any kind of internet traffic they are vulnerable to the tragedy of the commons. Relay operators may impose authentication requirements for endpoint allocation provisions.

Since psk is a symmetric key, the first message containing the sender's original PSBT does not have forward secrecy.


Network Privacy

Peers will only see the IP address of the TURN relay but not their peer's. TURN relays may be made available via Tor hidden service in addition to IP to allow either of the peers to protect their IP with Tor without forcing the other to use it too.



IMPLEMENTATION


I've published working proof of concept sender, receiver clients and relay code in rust[7]



ACKNOWLEDGEMENTS


Deepest gratitude to Ethan Heilman for sitting down with me to help get to the bottom of the requirements of this problem, to Ruben Somsen for this slick format, and to all those engaged in defending the right to privacy.



REFERENCES


[1]  BIP 78 A Simple Payjoin Proposal, Nicolas Doier:
https://github.com/bitcoin/bips/blob/master/bip-0078.mediawiki

[2]  Bitcoin: A Peer-to-Peer Electronic Cash System, Satoshi Nakamoto:
https://chaincase.app/bitcoin.pdf

[3]  [bitcoin-dev] PayJoin adoption, Craig Raw:
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-January/018358.html

[4]  RFC 5766: Traversal Using Relays around NAT (TURN):
https://www.rfc-editor.org/rfc/rfc5766

[5]  BIP 21 URI Scheme, Nils Schneider, Matt Corallo:
 https://github.com/bitcoin/bips/blob/master/bip-0021.mediawiki

[6]  Noise Explorer: NNpsk0:
https://noiseexplorer.com/patterns/NNpsk0

[7]  Serverless PayJoin PoC:
https://github.com/chaincase-app/payjoin/pull/21



From billy.tetrud at gmail.com  Mon Jan 23 17:39:41 2023
From: billy.tetrud at gmail.com (Billy Tetrud)
Date: Mon, 23 Jan 2023 11:39:41 -0600
Subject: [bitcoin-dev] Wallet vaults with pre-signed transactions but no
	ephemeral keys
Message-ID: <CAGpPWDY+4G1Lb3J5XU_vHVgsOtbwhM=_WCt4-sbk17T3SoxaNw@mail.gmail.com>

In the discussion around James' OP_VAULT proposal, it was implied that
precomputed vaults must use ephemeral keys that must be deleted as part of
the vaulting protocol, like Bryan Bishop's proposal
<https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-August/017229.html>.
Looking around, I haven't been able to find any wallet vault proposal that
doesn't require ephemeral keys, so at the risk of posting something that's
obvious to everyone, I wanted to share a simple way to do a wallet vault
without requiring any key deletion.

The basic idea is to create an N-of-N multisig address, and pre-sign some
transactions from it with N-1 keys to an address with several timelocked
spend paths. This has the fallback that funds can always be spent
immediately if you use all the keys, just like a normal N-of-N multisig
address (since that's what it is at its core), but the usage of any of the
pre-signed transactions leads to an address that guarantees a clawback
within a time window. Here's a 3-of-3 example:

*Vault Initialization*:
1. Create 3 of 3 Vault Address
2. Create an Interim Address that can send with:
 * 1 of 3 keys after a timelock of 1 month
 * 2 of 3 keys after a timelock of 1 week
 * 3 of 3 keys with no timelock

*Vaulting*:
1. Create a transaction sending an output to the Vault Address
2. Create a transaction spending that Vault Address output to the Interim
Address
3. Presign one copy of the step-2 transaction for each of the three
combinations of two keys.
4. Store seeds separately, store the wallet config as well as the three
presigned transactions with each seed.

*Unvaulting*:
1. Sign one of the pre-signed transactions with the missing signature.
2. Broadcast
3. Wait the appropriate timelock for the number of keys you want to sign
with.
4. Create a transaction sending from the Interim Address.
5. Broadcast

*Recovering *(after unvaulting step 2 after the broadcasted transaction to
the Interim Address has been mined):
1. Sign the utxo with all three keys to any destination. Alternatively sign
with two keys, wait 1 week.
2. Broadcast it

This has the usual downsides of pre-signed vaults that you need to backup
these transactions for each vaulting, complications involving the
flexibility (or lack thereof) of fees, and inflexibility in how much to
unvault (must be the whole utxo, no change). This could of course be
augmented with various techniques to make fee handling more flexible
(anchor outputs, multiple versions of the presigned transactions with
different fees, etc). More complicated presigning schemes could allow for
some flexibility in unvaulting amount (eg by sending change back into the
vault, and creating additional pre-signed transactions for that new output).

It also has the same downside that OP_CTV vaults have, where a stolen key
can steal funds from the interim address by racing the owner with their own
transaction once the necessary delay has passed. Note that James' OP_VAULT
opcode wouldn't have this problem.

But not requiring any toxic waste keys seems like a pretty good benefit
over Bryan Bishop's original proposal.

Anyways sorry if this was already on people's radar and just too obvious to
post about.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230123/eb519e3d/attachment.html>

From darosior at protonmail.com  Mon Jan 23 19:53:18 2023
From: darosior at protonmail.com (darosior)
Date: Mon, 23 Jan 2023 19:53:18 +0000
Subject: [bitcoin-dev] Wallet policies for descriptor wallets
In-Reply-To: <CAMhCMoFWHUKVg0n2jVwxfAsuFqsCXPWHg4Bw_sk0xfTs4FPnkw@mail.gmail.com>
References: <CAMhCMoHfdsQMsVigFqPexTE_q-Cyg7pfRvORUoy2sZtvyzd1cg@mail.gmail.com>
 <CAMhCMoFWHUKVg0n2jVwxfAsuFqsCXPWHg4Bw_sk0xfTs4FPnkw@mail.gmail.com>
Message-ID: <4UmvJ86zmTfQzopOERA87HTBVOWo169DjJRc9Q778Hi60ZCuXjaiGyUqu7ZNGROxXqo_Ah_LtSg58wqfNba5avO6vStn_N4eL1J7YfvI7F0=@protonmail.com>

Hello Salvatore,

It's not something about the specifications of wallet policies, but regarding the guidelines for implementers on signing devices. Quoting BIP-wallet-policies:

> Moreover, other limitations like the limited size of the screen might affect what design choices are available in practice. Therefore, minimizing the size of the information shown on-screen is important for a good user experience; that is crucial since the ability for the user to completely validate on-screen the kind of script used (and each of the involved keys) is a prerequisite for secure usage, as the machine that is interacting with the hardware signer (and running the software wallet) is considered untrusted.

> The device shows the wallet policy to the user using the secure screen.

?

> - Template with miniscript for "1 of 2 equally likely keys":
>   wsh(or_b(pk(@0/**),s:pk(@1/**)))

?

Actually you can save a few more characters, and gain some clarity, by showing the "semantic policy" instead of the actual Miniscript.

If the intent is for the user to verify the semantic of the Bitcoin Script they are importing, you can just drop all the type information.

For instance, for a Miniscript representing the Miniscript policy "a 3-of-3 that becomes a 2-of-3 after 90 days" instead of showing:

thresh(3,pk(Alice),s:pk(Bob),s:pk(Carol),sln:older(12960))

You could show:

thresh(3,pk(Alice),pk(Bob),pk(Carol),older(12960))

For this specific example you'd save 8 (confusing) characters to be verified on the signing device.

I wonder if signing devices could even go further and display a plain english verification to the user, like "This policy contains 4 spending paths. Be ready to verify the 4 spending paths. The first spending path is Alice, Bob and Carol signing together. The second spending path is Bob and Carol signing together after 90 days. The third spending path is Alice and Carol signing together after 90 days.

The third spending path is Alice and Bob signing together after 90 days

."

It seems feasible to be doable in a general manner from a Miniscript "semantic policy".

I guess it clashes with the user willing to check their backup against the policy registered on the device. You could always have the user-friendly policy check at first and have an option to show the raw descriptor for them to be able to cross-check it with their backup.

PS: the numerous usage of the word "policy" is getting complex lol, is it a Miniscript concrete policy, a Miniscript semantic policy, a BIP-wallet-policies policy? :)

Antoine Poinsot

------- Original Message -------
Le lundi 21 novembre 2022 ? 12:27 PM, Salvatore Ingala via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> a ?crit :

> Hi list,
>
> Following up on this topic, I now opened a pull request with the BIP proposal:
>
> https://github.com/bitcoin/bips/pull/1389
>
> I also attempted a proof-of-concept of how an integration of wallet policies to HWI might look like:
>
> https://github.com/bitcoin-core/HWI/pull/647
>
> which might help to provide context, and also serves as a demo of the possible UX flows with hardware signers (as currently implemented in the Ledger bitcoin app).
>
> There are no substantial changes to the initial version proposed to the list:
> - some additional restrictions to the allowed descriptors were added as further simplifications;
> - added test vectors and observations on backwards compatibility;
> - general improvements to the text.
>
> I look forward to your comments and improvements.
> Salvatore Ingala
>
> On Thu, 5 May 2022 at 16:32, Salvatore Ingala <salvatore.ingala at gmail.com> wrote:
>
>> In the implementation work to implement descriptors and miniscript support in hardware wallets [a][b], I encountered a number of challenges. Some of them are technical in nature (e.g. due to constraints of embedded development). Others are related to the attempts of shaping a good user experience; with bitcoin reaching more people who are not tech-savvy, self-custody is only as secure as what those newcomers can use easily enough.
>>
>> The main tool that I am using to address some of these challenges is a layer that sits _on top_ of descriptors/miniscript, while staying very close to it. Since there is nothing that is vendor-specific in the vast majority of the approach I'm currently using, I tried to distill it here for your comments, and will propose a BIP if this is deemed valuable.
>>
>> I called the language "wallet policies" (suggestions for a better name are welcome). I believe an approach based on wallet policies can benefit all hardware wallets (stateless or not) that want to securely support complex scripts; moreover, wallet policies are close enough to descriptors that their integration should be extremely easy for any software wallet that is currently using descriptors.
>>
>> [a]: https://blog.ledger.com/bitcoin-2 - early demo
>> [b]: https://blog.ledger.com/miniscript-is-coming - miniscript example
>>
>> Salvatore Ingala
>>
>> ======================================================
>>
>> This document starts with a discussion on the motivation for wallet policies, followed by their formal definition, and some recommendations for implementations.
>>
>> == Rationale ==
>> Output script descriptors [1] were introduced in bitcoin-core as a way to represent collections of output scripts. It is a very general and flexible language, designed to catch all the possible use-cases of bitcoin wallets (that is, if you know the script and you have the necessary keys, it will be possible to sign transactions with bitcoin-core's descriptor-based wallets).
>>
>> Unfortunately, descriptors are not a perfect match for the typical usage of hardware wallets. Most hardware wallets have the following limitations compared to a general-purpose machine running bitcoin-core:
>>
>> - they are embedded devices with limited RAM and computational power;
>> - they might not be able to import additional private keys (all the keys are generated from a single seed via [BIP-32](https://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki));
>> - they might not have permanent storage (*stateless* hardware wallet design).
>>
>> Moreover, other limitations like the limited size of the screen might affect what design choices are available in practice. Therefore, minimizing the size of the information shown on-screen is important for a good user experience.
>>
>> A more native, compact representation of the wallet receive/change would also benefit the UX of software wallets using descriptors to represent software wallets using descriptors/miniscript for multisignature or other complex locking conditions.
>>
>> === Security and UX concerns of scripts in hardware wallets ===
>> For a hardware wallet, allowing the usage of complex scripts presents challenges in terms of both security and user experience.
>>
>> ==== Security issues ====
>>
>> One of the security properties that hardware wallets strive to guarantee is the following: **as long as the user correctly verifies the information that is shown on the hardware wallet's screen before approving, no action can be performed without the user's consent**.
>> This must hold even in scenarios where the attacker has full control of the machine that is connected to the hardware wallet, and can execute arbitrary requests or tamper with the legitimate user's requests.
>>
>> Therefore, it is not at all trivial to allow complex scripts, especially if they contain keys that belong to third parties.
>> The hardware wallet must guarantee that the user knows precisely *what* "policy" is being used to spend the funds, and that the "unspent" funds (if any) will be protected by the same policy. This makes it impossible for an attacker to surreptitiously modify the policy, therefore stealing or burning user's funds.
>>
>> ==== UX issues ====
>>
>> With miniscript (and taproot trees) allowing substantially more complex spending policies to be used, it becomes more challenging to make sure that the user is able _in practice_ to verify the information on the screen. Therefore, there are two fundamental design goals to strive for:
>> - Minimize the amount of information that is shown on screen - so that the user can actually validate it.
>> - Minimize the number of times the user has to validate such information.
>>
>> Designing a secure protocol for the coordination of a descriptor wallet among distant parties is also a challenging problem that is out of scope in this document. See BIP-129 [2] for an approach designed for multisignature wallets.
>>
>> === Policy registration as a solution ===
>>
>> A solution to address the security concerns, and part of the UX concerns, is to have a *registration* flow for the wallet policy in the hardware wallet. The "wallet policy" must contain enough information to generate all the relevant addresses/scripts, and for the hardware wallet to identify the keys that it controls and that are needed to spend the funds sent to those addresses.
>>
>> Before a new policy is used for the first time, the user will register a `wallet policy` into the hardware wallet. While the details of the process are out of scope in this document, the flow should be something similar to the following:
>>
>> 1) The software wallet initiates a _wallet policy registration_ on the hardware wallet; the information should include the wallet policy, but also a unique *name* that identifies the policy.
>> 2) The hardware wallet shows the wallet policy to the user using the secure screen.
>> 3) After inspecting the policy and comparing it with a trusted source (for example a printed backup), the user approves the policy.
>> 4) If stateful, the hardware wallet persists the policy in its permanent memory; if stateless, it returns a "proof of registration".
>>
>> The details of how to create a proof of registration are out of scope for this document; using a *message authentication codes* on a hash committing to the wallet policy, its name and any additional metadata is an effective solution if correctly executed.
>>
>> Once a policy is registered, the hardware wallet can perform the usual operations securely:
>> - generating receive and change addresses;
>> - showing addresses on the secure screen;
>> - sign transactions spending from a wallet, while correctly identifying change addresses and computing the transaction fees.
>>
>> Before any of the actions mentioned above, the hardware wallet will retrieve the policy from its permanent storage if stateful; if stateless it will validate the _proof of registration_ before using the wallet policy provided by the client.
>> Once the previously registered policy is correctly identified and approved by the user (for example by its name), and *as long as the policy registration was executed securely*, hardware wallets can provide a user experience similar to the usual one for single-signature transactions.
>>
>> === Avoiding blowup in descriptor size ===
>>
>> While reusing a pubkey in different branches of a miniscript is explicitly forbidden by miniscript (as it has certain negative security implications), it is still reasonable to reuse the same *xpub* in multiple places, albeit with different final steps of derivation (so that the actual pubkeys that are used in the script are indeed different).
>>
>> For example, using Taproot, a *3*-of-*5* multisignature wallet could use:
>> - a key path with a 5-of-5 MuSig
>> - a script tree with a tree of 10 different 3-of-3 MuSig2 scripts, that are generated, plus a leaf with a fallback *3*-of-*5* multisignature using plain multisignature (with `OP_CHECKSIGADD`).
>>
>> This could look similar to:
>>
>> ```
>> tr(musig2(xpubA,xpubB,xpubC,xpubD,xpubE)/<0;1>/*), {
>> {
>> {
>> pk(musig2(xpubA,xpubB,xpubC)/<2;3>/*),
>> {
>> pk(musig2(xpubA,xpubB,xpubD)/<4;5>/*)
>> pk(musig2(xpubA,xpubB,xpubE)/<6;7>/*),
>> }
>> },
>> {
>> pk(musig2(xpubA,xpubC,xpubD)/<8;9>/*),
>> {
>> pk(musig2(xpubA,xpubC,xpubE)/<10;11>/*),
>> pk(musig2(xpubA,xpubD,xpubE)/<12;13>/*)
>> }
>> }
>> },
>> {
>> {
>> pk(musig2(xpubB,xpubC,xpubD)/<14;15>/*),
>> pk(musig2(xpubB,xpubC,xpubE)/<16;17>/*)
>> },
>> {
>> pk(musig2(xpubB,xpubD,xpubE)/<18;19>/*),
>> {
>> pk(musig2(xpubC,xpubD,xpubE)/<20;21>/*),
>> sortedmulti_a(3,
>> xpubA/<22;23>/*,
>> xpubB/<22;23>/*,
>> xpubC/<22;23>/*,
>> xpubD/<22;23>/*,
>> xpubE/<22;23>/*)
>> }
>> }
>> }
>> })
>> ```
>>
>> Note that each root xpub appears 8 times. With xpubs being up to 118 bytes long, the length of the full descriptor can get extremely long (the problem gets *exponentially* worse with larger multisignature schemes).
>>
>> Replacing the common part of the key with a short key placeholder and moving the key expression separately helps to keep the size of the wallet policy small, which is crucial to allow human inspection in the registration flow.
>>
>> === Restrictions on the supported descriptors ====
>>
>> The policy language proposed in this document purposely targets only a stricter subset of the output descriptors language, and it attempts to generalize in the most natural way the approach that is already used for single-signature *accounts* (as described in BIP-44 [3], BIP-49 [4], BIP-84 [5], or BIP-86 [6]), or in multisignature setups (see for example BIP-48 [7] and BIP-87 [8]).
>>
>> Unlike the BIPs mentioned above, it is not tied to any specific script template, as it applies to arbitrary scripts that can be represented with descriptors and miniscript.
>>
>> Supporting only a reduced feature set when compared to output descriptors helps in implementations (especially on hardware wallets), while attempting to capture all the common use cases. More features can be added in the future if motivated by real world necessity.
>>
>> By keeping the structure of the wallet policy language very close to that of descriptors, it should be straightforward to:
>> - write wallet policy parsers;
>> - extract the descriptors defined by a wallet policy;
>> - convert a pair of descriptors describing a wallet "account" used in current implementations into the corresponding wallet policy.
>>
>> == Wallet policies ==
>>
>> This section formally defines wallet policies, and how they relate to output script descriptors.
>>
>> === Formal definition ===
>>
>> A wallet policy is composed by a wallet descriptor template, together with a vector of key information items.
>>
>> ==== Wallet descriptor template ====
>>
>> A wallet descriptor template is a `SCRIPT` expression.
>>
>> `SCRIPT` expressions:
>> - `sh(SCRIPT)` (top level only): P2SH embed the argument.
>> - `wsh(SCRIPT)` (top level or inside `sh` only): P2WSH embed the argument.
>> - `pkh(KP)` (not inside `tr`): P2PKH output for the given public key (use `addr` if you only know the pubkey hash).
>> - `wpkh(KP)` (top level or inside `sh` only): P2WPKH output for the given compressed pubkey.
>> - `multi(k,KP_1,KP_2,...,KP_n)`: k-of-n multisig script.
>> - `sortedmulti(k,KP_1,KP_2,...,KP_n)`: k-of-n multisig script with keys sorted lexicographically in the resulting script.
>> - `tr(KP)` or `tr(KP,TREE)` (top level only): P2TR output with the specified key as internal key, and optionally a tree of script paths.
>> - any valid miniscript template (inside `wsh` or `tr` only).
>>
>> `TREE` expressions:
>> - any `SCRIPT` expression
>> - An open brace `{`, a `TREE` expression, a comma `,`, a `TREE` expression, and a closing brace `}`
>>
>> Note: "miniscript templates" are not formally defined in this version of the document, but it is straightforward to adapt this approach.
>> `KP` expressions (key placeholders) consist of
>> - a single character `@`
>> - followed by a non-negative decimal number, with no leading zeros (except for `@0`).
>> - possibly followed by either:
>> - the string `/**`, or
>> - a string of the form `/<NUM;NUM>/*`, for two distinct decimal numbers `NUM` representing unhardened derivations
>>
>> The `/**` in the placeholder template represents commonly used paths for receive/change addresses, and is equivalent to `<0;1>`.
>>
>> The placeholder `@i` for some number *i* represents the *i*-th key in the vector of key origin information (which must be of size at least *i* + 1, or the wallet policy is invalid).
>>
>> ==== Key informations vector ====
>>
>> Each element of the key origin information vector is a `KEY` expression.
>>
>> - Optionally, key origin information, consisting of:
>> - An open bracket `[`
>> - Exactly 8 hex characters for the fingerprint of the master key from which this key is derived from (see [BIP32](https://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki) for details)
>> - Followed by zero or more `/NUM'` path elements to indicate hardened derivation steps between the fingerprint and the xpub that follows
>> - A closing bracket `]`
>> - Followed by the actual key, which is either
>> - a hex-encoded pubkey, which is either
>> - inside `wpkh` and `wsh`, only compressed public keys are permitted (exactly 66 hex characters starting with `02` or `03`.
>> - inside `tr`, x-only pubkeys are also permitted (exactly 64 hex characters).
>> - a serialized extended public key (`xpub`) (as defined in [BIP 32](https://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki))
>>
>> The placeholder `@i` for some number *i* represents the *i*-th key in the vector of key orIgin information (which must be of size at least *i* + 1, or the wallet policy is invalid).
>>
>> The policy template is invalid if any placeholder `@i` has derivation steps while the corresponding `(i+1)`-th element of the keys vector is not an xpub.
>>
>> ==== Additional rules ====
>>
>> The wallet policy is invalid if any placeholder expression with additional derivation steps is used when the corresponding key information is not an xpub.
>>
>> The key information vector *should* be ordered so that placeholder `@i` never appear for the first time before an occurrence of `@j` for some `j < i`; for example, the first placeholder is always `@0`, the next one is `@1`, etc.
>>
>> === Descriptor derivation ===
>>
>> From a wallet descriptor template (and the associated vector of key informations), one can therefore obtain the 1-dimensional descriptor for receive and change addresses by:
>>
>> - replacing each key placeholder with the corresponding key origin information;
>> - replacing every `/**` with `/0/*` for the receive descriptor, and `/1/*` for the change descriptor;
>> - replacing every `/<M,N>` with `/M` for the receive descriptor, and `/N` for the change descriptor.
>>
>> For example, the wallet descriptor `pkh(@0/**)` with key information `["[d34db33f/44'/0'/0']xpub6ERApfZwUNrhLCkDtcHTcxd75RbzS1ed54G1LkBUHQVHQKqhMkhgbmJbZRkrgZw4koxb5JaHWkY4ALHY2grBGRjaDMzQLcgJvLJuZZvRcEL"]` produces the following two descriptors:
>>
>> - Receive descriptor: `pkh([d34db33f/44'/0'/0']xpub6ERApfZwUNrhLCkDtcHTcxd75RbzS1ed54G1LkBUHQVHQKqhMkhgbmJbZRkrgZw4koxb5JaHWkY4ALHY2grBGRjaDMzQLcgJvLJuZZvRcEL/0/*)`
>>
>> - Change descriptor: `pkh([d34db33f/44'/0'/0']xpub6ERApfZwUNrhLCkDtcHTcxd75RbzS1ed54G1LkBUHQVHQKqhMkhgbmJbZRkrgZw4koxb5JaHWkY4ALHY2grBGRjaDMzQLcgJvLJuZZvRcEL/1/*)`
>>
>> === Implementation guidelines ===
>>
>> Implementations must not necessarily implement all of the possible wallet policies defined by this standard, but it is recommended to clearly document any limitation.
>>
>> Implementations can add additional metadata that is stored together with the wallet policy for the purpose of wallet policy registration and later usage. Metadata can be vendor-specific and is out of the scope of this document.
>>
>> Any implementation in a general-purpose software wallet allowing arbitrary scripts (or any scripts that involve external cosigners) should put great care into a process for backing up a wallet policy. In fact, unlike typical single-signature scenarios, the seed alone is no longer enough to discover wallet policies with existing funds, and the loss of the backup is likely to lead to permanent loss of funds.
>>
>> Avoiding key reuse among different wallet accounts is also extremely important, but out of scope for this document.
>>
>> == Examples ==
>>
>> Some examples of wallet descriptor templates (vectors of keys omitted for simplicity):
>> - Template for a native segwit account:
>> wpkh(@0/**)
>>
>> - Template for a taproot BIP86 account:
>> tr(@0/**)
>> - Template for a native segwit 2-of-3:
>> wsh(sortedmulti(2, at 0/**, at 1/**, at 2/**))
>> - Template with miniscript for "1 of 2 equally likely keys":
>> wsh(or_b(pk(@0/**),s:pk(@1/**)))
>>
>> More examples (esp. targeting miniscript on taproot) will be added in the future.
>>
>> == References ==
>>
>> * [1] - Output Script Descriptors: https://github.com/bitcoin/bitcoin/blob/master/doc/descriptors.md
>> * [2] - BIP-129 (Bitcoin Secure Multisig Setup): https://github.com/bitcoin/bips/blob/master/bip-0129.mediawiki
>> * [3] - BIP-44: https://github.com/bitcoin/bips/blob/master/bip-0044.mediawiki
>> * [4] - BIP-49: https://github.com/bitcoin/bips/blob/master/bip-0049.mediawiki
>> * [5] - BIP-84: https://github.com/bitcoin/bips/blob/master/bip-0084.mediawiki
>> * [6] - BIP-86: https://github.com/bitcoin/bips/blob/master/bip-0086.mediawiki
>> * [7] - BIP-48: https://github.com/bitcoin/bips/blob/master/bip-0048.mediawiki
>> * [8] - BIP-87: https://github.com/bitcoin/bips/blob/master/bip-0087.mediawiki
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230123/90a326ef/attachment-0001.html>

From salvatore.ingala at gmail.com  Tue Jan 24 08:38:29 2023
From: salvatore.ingala at gmail.com (Salvatore Ingala)
Date: Tue, 24 Jan 2023 09:38:29 +0100
Subject: [bitcoin-dev] Wallet policies for descriptor wallets
In-Reply-To: <4UmvJ86zmTfQzopOERA87HTBVOWo169DjJRc9Q778Hi60ZCuXjaiGyUqu7ZNGROxXqo_Ah_LtSg58wqfNba5avO6vStn_N4eL1J7YfvI7F0=@protonmail.com>
References: <CAMhCMoHfdsQMsVigFqPexTE_q-Cyg7pfRvORUoy2sZtvyzd1cg@mail.gmail.com>
 <CAMhCMoFWHUKVg0n2jVwxfAsuFqsCXPWHg4Bw_sk0xfTs4FPnkw@mail.gmail.com>
 <4UmvJ86zmTfQzopOERA87HTBVOWo169DjJRc9Q778Hi60ZCuXjaiGyUqu7ZNGROxXqo_Ah_LtSg58wqfNba5avO6vStn_N4eL1J7YfvI7F0=@protonmail.com>
Message-ID: <CAMhCMoGWNzXsiVCEhxZQ+WDzUp92m74F1-xLC4wdUjHsj+EDnQ@mail.gmail.com>

Hi Antoine,

Thanks for your very interesting suggestions!

On Mon, 23 Jan 2023 at 20:53, darosior <darosior at protonmail.com> wrote:

> Actually you can save a few more characters, and gain some clarity, by showing the "semantic policy" instead of the actual Miniscript. If the intent is for the user to verify the semantic of the Bitcoin Script they are importing, you can just drop all the type information.
> For instance, for a Miniscript representing the Miniscript policy "a 3-of-3 that becomes a 2-of-3 after 90 days" instead of showing:
>
> thresh(3,pk(Alice),s:pk(Bob),s:pk(Carol),sln:older(12960))
> You could show:
>
> thresh(3,pk(Alice),pk(Bob),pk(Carol),older(12960))
> For this specific example you'd save 8 (confusing) characters to be verified on the signing device.
>
>
I thought about that, and I still consider it a possible future improvement
in UX. However, I wasn't comfortable deploying it in this way for the
following reason: if there is malware in your software wallet at policy
registration time, the malware could find a different miniscript with the
same semantic policy.
The result is now a mismatch between the wallet policy in the user's backup
and the one where funds are actually received. The user might see funds
mysteriously disappear, while the attacker would know the actual miniscript
policy, enabling ransom attacks.

The attack seems very unlikely today, and for many interesting semantic
policies, there are probably not many miniscript policies to sift through
in case of recovery.
However, I suspect it will become more realistic in a taproot world, where
the semantic policy of each tapleaf could have multiple options, resulting
in combinatorial explosion.
For example, if there are 2 options for the miniscript of each leaf, and n
leaves, you would have 2^n possible descriptors with the same semantic
policy.

One solution might be to explicitly enumerate (or at least upper-bound) the
number of possible descriptors that are lifted to the same policy, and use
the simplified UX if this number is not too large.
Having a set of standard recovery tools for those situations might make
this approach more viable in my opinion.

I wonder if signing devices could even go further and display a plain
english verification to the user, like "This policy contains 4
spending paths. Be ready to verify the 4 spending paths. The first
spending path is Alice, Bob and Carol signing together. The second
spending path is Bob and Carol signing together after 90 days. The
third spending path is Alice and Carol signing together after 90 days.
The third spending path is Alice and Bob signing together after 90
days."
> It seems feasible to be doable in a general manner from a Miniscript "semantic policy".
>
> A lower-hanging fruit might be to find ways of registering
xpubs/identities on the device, so that one could replace xpubs with
"Alice" and "Bob".
Once that's done, that might be one of the possible approaches to simplify
the UX flow.
I suspect the design space to be quite large and I have not yet put enough
thought into it.

I guess it clashes with the user willing to check their backup against
the policy registered on the device. You could always have the
user-friendly policy check at first and have an option to show the raw
descriptor for them to be able to cross-check it with their backup.
>
> I'm assuming the user will do the minimum amount of work they are forced
to do, therefore I only consider this safe iff we address the
miniscript-combinatorial-explosion issues above.

PS: the numerous usage of the word "policy" is getting complex lol, is
it a Miniscript concrete policy, a Miniscript semantic policy, a
BIP-wallet-policies policy? :)
>
> ...yeah, we should have a policy against that!

Salvatore Ingala
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230124/4f44543a/attachment.html>

From darosior at protonmail.com  Thu Jan 26 14:30:56 2023
From: darosior at protonmail.com (darosior)
Date: Thu, 26 Jan 2023 14:30:56 +0000
Subject: [bitcoin-dev] Wallet vaults with pre-signed transactions but no
	ephemeral keys
In-Reply-To: <CAGpPWDY+4G1Lb3J5XU_vHVgsOtbwhM=_WCt4-sbk17T3SoxaNw@mail.gmail.com>
References: <CAGpPWDY+4G1Lb3J5XU_vHVgsOtbwhM=_WCt4-sbk17T3SoxaNw@mail.gmail.com>
Message-ID: <rs4K-Lg4t58J2gfeXUPHK0CuctCn_sq6IlyZ7wobDR_cCCAkd_3JrRM4LVCrhxhd3PE4fnVveTEc0sYDmS9fqpIEUPFikC5PDUOlC9D_mhU=@protonmail.com>

Hello Billy,

Yes it's basically a (simple) instantiation of Revault. You can find more at [https://github.com/revault](https://github.com/revault/) (you most likely want the `practical-revault` repo). There is a description of the concept, the specification of a communication protocol between the participants as well as the implementation of the whole.

Such a design presents some advantages, but it has two major issues:

- You need to make sure all your watchtowers received the Cancel signature before you sign the Unvault transaction. But how can you get this guarantee in the usual (and reasonable) model of an untrusted laptop?
- You can only have policies on the Unvault transaction (eg "You can only Unvault up to X BTC during working hours"), not on the Spend transaction (eg "You can only send coins to a Script with pubkey Y required in all spending paths"). Revault allows to use cosigning servers that act as anti-replay oracles to have policies on the spend, but this is obviously *very* suboptimal.

Both issues are solvable with covenants.

Antoine Poinsot
------- Original Message -------
Le lundi 23 janvier 2023 ? 6:39 PM, Billy Tetrud via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> a ?crit :

> In the discussion around James' OP_VAULT proposal, it was implied that precomputed vaults must use ephemeral keys that must be deleted as part of the vaulting protocol, like [Bryan Bishop's proposal](https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-August/017229.html). Looking around, I haven't been able to find any wallet vault proposal that doesn't require ephemeral keys, so at the risk of posting something that's obvious to everyone, I wanted to share a simple way to do a wallet vault without requiring any key deletion.
>
> The basic idea is to create an N-of-N multisig address, and pre-sign some transactions from it with N-1 keys to an address with several timelocked spend paths. This has the fallback that funds can always be spent immediately if you use all the keys, just like a normal N-of-N multisig address (since that's what it is at its core), but the usage of any of the pre-signed transactions leads to an address that guarantees a clawback within a time window. Here's a 3-of-3 example:
>
> Vault Initialization:
> 1. Create 3 of 3 Vault Address
> 2. Create an Interim Address that can send with:
> * 1 of 3 keys after a timelock of 1 month
> * 2 of 3 keys after a timelock of 1 week
> * 3 of 3 keys with no timelock
>
> Vaulting:
> 1. Create a transaction sending an output to the Vault Address
> 2. Create a transaction spending that Vault Address output to the Interim Address
> 3. Presign one copy of the step-2 transaction for each of the three combinations of two keys.
> 4. Store seeds separately, store the wallet config as well as the three presigned transactions with each seed.
>
> Unvaulting:
> 1. Sign one of the pre-signed transactions with the missing signature.
> 2. Broadcast
> 3. Wait the appropriate timelock for the number of keys you want to sign with.
> 4. Create a transaction sending from the Interim Address.
> 5. Broadcast
> Recovering (after unvaulting step 2 after the broadcasted transaction to the Interim Address has been mined):
> 1. Sign the utxo with all three keys to any destination. Alternatively sign with two keys, wait 1 week.
> 2. Broadcast it
>
> This has the usual downsides of pre-signed vaults that you need to backup these transactions for each vaulting, complications involving the flexibility (or lack thereof) of fees, and inflexibility in how much to unvault (must be the whole utxo, no change). This could of course be augmented with various techniques to make fee handling more flexible (anchor outputs, multiple versions of the presigned transactions with different fees, etc). More complicated presigning schemes could allow for some flexibility in unvaulting amount (eg by sending change back into the vault, and creating additional pre-signed transactions for that new output).
>
> It also has the same downside that OP_CTV vaults have, where a stolen key can steal funds from the interim address by racing the owner with their own transaction once the necessary delay has passed. Note that James' OP_VAULT opcode wouldn't have this problem.
>
> But not requiring any toxic waste keys seems like a pretty good benefit over Bryan Bishop's original proposal.
>
> Anyways sorry if this was already on people's radar and just too obvious to post about.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230126/01be3f93/attachment.html>

From aymeric at peersm.com  Thu Jan 26 20:15:38 2023
From: aymeric at peersm.com (Aymeric Vitte)
Date: Thu, 26 Jan 2023 21:15:38 +0100
Subject: [bitcoin-dev] A Universal Coin Swap system based on bitcoin and a
 Bitcoin NFT system
Message-ID: <ff4e7a30-47b1-39f4-97cc-27f7ec2cc326@peersm.com>

Please see:

"A Bitcoin NFT system"
https://gist.github.com/Ayms/01dbfebf219965054b4a3beed1bfeba7 "The
purpose of this proposal is to propose a simple NFT system based on the
Bitcoin blockchain, assuming that the main purpose of a NFT is to be
sold/bought, but not only, it can be something that you keep for
yourself proving your ownership on the blockchain, or something that you
offer to someone else, the advantages compared to using Ethereum or any
blockchain/sidechain on both networks (or others) will be explained below"

And the continuation:

"A Universal Coin Swap system based on bitcoin"
https://gist.github.com/Ayms/029125db2583e1cf9c3209769eb2cdd7 "The
purpose here is to propose a simple Coin Swap decentralized system based
on Bitcoin but that works for all blockchains/tokens"

The idea is to propose something simple, that people can understand,
secured, decentralized, easy to implement/use, not expensive for the
users, unlike Ethereum solutions, showing also that bitcoin can easily
do in a much more simple manner what ethereum is doing

It's a bit similar to Lightning but not as sophisticated, basically the
proof of deals are stored in OP_RETURN (looks trivial, yes, but unlike
other solutions the proposals store a real proof and does not flood the
bitcoin network with funny stuff, it could be turned into bitcoin
contracts which most likely will not be recognized as standard), we
cannot enforce everything like Lightning but the trust here is more
based on a reputation model, and same as Lightning the cheater just lose
its bitcoin or get tagged as a cheater, will be tracked and might assume
the consequences later

As written, I am a fan of Lightning but see it more as a middle/long
term relationship between people since coins must be locked into a
multisig transaction while here we are more talking about a one time
deal, where you don't know if you will buy something else to the seller,
with which coin and where (metaverse for example)

For your review and comments, here or in private, no real inventions
here but some non usual ideas like the double hash, the third party and
others, solving also one of my personal problematic since years: "how to
sell a secret NFT?"

In any case it remains decentralized (but of course some tools/wallets
must ease the process for the users), like Lightning, and unlike
everything that is existing today in those areas to my knowledge, except
Lightning again

Regards

Aymeric


-- 
Sophia-Antipolis, France
CV: https://www.peersm.com/CVAV.pdf
LinkedIn: https://fr.linkedin.com/in/aymeric-vitte-05855b26
GitHub : https://www.github.com/Ayms
A Universal Coin Swap system based on Bitcoin: https://gist.github.com/Ayms/029125db2583e1cf9c3209769eb2cdd7
A bitcoin NFT system: https://gist.github.com/Ayms/01dbfebf219965054b4a3beed1bfeba7
Move your coins by yourself (browser version): https://peersm.com/wallet
Bitcoin transactions made simple: https://github.com/Ayms/bitcoin-transactions
torrent-live: https://github.com/Ayms/torrent-live
node-Tor : https://www.github.com/Ayms/node-Tor
Anti-spies and private torrents, dynamic blocklist: http://torrent-live.peersm.com
Peersm : http://www.peersm.com



From robert.lee.dickinson at gmail.com  Fri Jan 27 12:44:10 2023
From: robert.lee.dickinson at gmail.com (Robert Dickinson)
Date: Fri, 27 Jan 2023 09:44:10 -0300
Subject: [bitcoin-dev] Ordinal Inscription Size Limits
Message-ID: <CABHetKwan91zqm=0y=_84vG7ffveWTPYONZP_hLQx5o40iAnuQ@mail.gmail.com>

I'm curious what opinions exist and what actions might be taken by core
developers regarding storing unlimited amounts of NFT (or other?) content
as witness data (https://docs.ordinals.com/inscriptions.html). The ordinal
scheme is elegant and genius IMHO, but when I think about the future disk
use of all unpruned nodes, I question whether unlimited storage is wise to
allow for such use cases. Wouldn't it be better to find a way to impose a
size limit similar to OP_RETURN for such inscriptions?

I think it would be useful to link a sat to a deed or other legal construct
for proof of ownership in the real world, so that real property can be
transferred on the blockchain using ordinals, but storing the property
itself on the blockchain seems nonsensical to me.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230127/a6a99a6c/attachment.html>

From rot13maxi at protonmail.com  Fri Jan 27 12:58:49 2023
From: rot13maxi at protonmail.com (rot13maxi)
Date: Fri, 27 Jan 2023 12:58:49 +0000
Subject: [bitcoin-dev] Ordinal Inscription Size Limits
In-Reply-To: <CABHetKwan91zqm=0y=_84vG7ffveWTPYONZP_hLQx5o40iAnuQ@mail.gmail.com>
References: <CABHetKwan91zqm=0y=_84vG7ffveWTPYONZP_hLQx5o40iAnuQ@mail.gmail.com>
Message-ID: <hhgUoi2km8Iv3HQ0aTaZiBXOHq8baEXtG5SEX_VkyYxw-4G0dewhLaj-IiFvAJsZSHW5fXSS3tukOvgzkLcvwdJIzRdBMscd2QMpA_iQBk0=@protonmail.com>

Hello,

?Unlimited storage? isn?t really accurate. It?s witness data in a taproot transaction, so the block size limit still applies. Anyone who runs an unpruned bitcoin node should be capacity-planning their disk space assuming that in the future blocks will be more full - as demand for blockspace increases, people will make better use of the space that we already have and average block weight will trend upwards. If you?re thinking about how much disk you will need when we have consistently full blocks, ordinal inscriptions don?t change that number.

- rijndael

On Fri, Jan 27, 2023 at 7:44 AM, Robert Dickinson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:

> I'm curious what opinions exist and what actions might be taken by core developers regarding storing unlimited amounts of NFT (or other?) content as witness data (https://docs.ordinals.com/inscriptions.html). The ordinal scheme is elegant and genius IMHO, but when I think about the future disk use of all unpruned nodes, I question whether unlimited storage is wise to allow for such use cases. Wouldn't it be better to find a way to impose a size limit similar to OP_RETURN for such inscriptions?
>
> I think it would be useful to link a sat to a deed or other legal construct for proof of ownership in the real world, so that real property can be transferred on the blockchain using ordinals, but storing the property itself on the blockchain seems nonsensical to me.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230127/88503ad3/attachment.html>

From apoelstra at wpsoftware.net  Fri Jan 27 13:21:00 2023
From: apoelstra at wpsoftware.net (Andrew Poelstra)
Date: Fri, 27 Jan 2023 13:21:00 +0000
Subject: [bitcoin-dev] Ordinal Inscription Size Limits
In-Reply-To: <CABHetKwan91zqm=0y=_84vG7ffveWTPYONZP_hLQx5o40iAnuQ@mail.gmail.com>
References: <CABHetKwan91zqm=0y=_84vG7ffveWTPYONZP_hLQx5o40iAnuQ@mail.gmail.com>
Message-ID: <Y9PPvBiWOXpBefmD@camus>

On Fri, Jan 27, 2023 at 09:44:10AM -0300, Robert Dickinson via bitcoin-dev wrote:
> I'm curious what opinions exist and what actions might be taken by core
> developers regarding storing unlimited amounts of NFT (or other?) content
> as witness data (https://docs.ordinals.com/inscriptions.html). The ordinal
> scheme is elegant and genius IMHO, but when I think about the future disk
> use of all unpruned nodes, I question whether unlimited storage is wise to
> allow for such use cases. Wouldn't it be better to find a way to impose a
> size limit similar to OP_RETURN for such inscriptions?
> 
> I think it would be useful to link a sat to a deed or other legal construct
> for proof of ownership in the real world, so that real property can be
> transferred on the blockchain using ordinals, but storing the property
> itself on the blockchain seems nonsensical to me.

Unfortunately, as near as I can tell there is no sensible way to prevent
people from storing arbitrary data in witnesses without incentivizing
even worse behavior and/or breaking legitimate use cases.

If we ban "useless data" then it would be easy for would-be data storers
to instead embed their data inside "useful" data such as dummy
signatures or public keys. Doing so would incur a ~2x cost to them, but
if 2x is enough to disincentivize storage, then there's no need to have
this discussion because they will will be forced to stop due to fee
market competition anyway. (And if not, it means there is little demand
for Bitcoin blockspace, so what's the problem with paying miners to fill
it with data that validators don't even need to perform real computation
on?).

But if we were to ban "useful" data, for example, saying that a witness
can't have more than 20 signatures in it, then we are into the same
problem we had pre-Taproot: that it is effectively impossible construct
signing policies in a general and composeable way, because any software
that does so will need to account for multiple independent limits. We
deliberately replaced such limits with "you need to pay 50 weight for
each signature" to makes this sort of analysis tractable.

There's a reasonable argument that this sort of data is toxic to the
network, since even though "the market is willing to bear" the price of
scares blockspace, if people were storing NFTs and other crap on the
chain, then the Bitcoin fee market would become entangled with random
pump&dump markets, undermining legitimate use cases and potentially
preventing new technology like LN from gaining a strong foothold. But
from a technical point of view, I don't see any principled way to stop
this.



-- 
Andrew Poelstra
Director of Research, Blockstream
Email: apoelstra at wpsoftware.net
Web:   https://www.wpsoftware.net/andrew

The sun is always shining in space
    -Justin Lewis-Webster

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 488 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230127/1ca9b7cf/attachment.sig>

From gsanders87 at gmail.com  Fri Jan 27 14:05:20 2023
From: gsanders87 at gmail.com (Greg Sanders)
Date: Fri, 27 Jan 2023 09:05:20 -0500
Subject: [bitcoin-dev] Ephemeral Anchors: Fixing V3 Package RBF
 againstpackage limit pinning
In-Reply-To: <CAB3F3DtrSFPmperGJJAUDZj7vt9aHgvkc0b5Pts3+mq5fTuWXA@mail.gmail.com>
References: <CAB3F3Dukoz3P3Ne7tCxMiwwAGm3Fv8r_fUkNbGAtGhAZDYDgCQ@mail.gmail.com>
 <ec952a9c-d810-4996-9ca9-1e9c6f6faca4@app.fastmail.com>
 <CAB3F3DvH3FnK8krykbcRVKc-z8F4yjt9mzYHevpYxaWkH4w9tw@mail.gmail.com>
 <CAD5xwhgFBQ-ScyBU5=WnREGsN-T=Nv=oR6vOsnHJ-ZMzDF8Vqg@mail.gmail.com>
 <CAPfvXf+N8aF+bqjGzpfDrhCYg7ngciSDCpUnCMHD+k5F+m3oWA@mail.gmail.com>
 <CAB3F3DuDODUxB5aK4VFWa8sKFCkZfOj6Vjb+Wp39opyt8MNnEA@mail.gmail.com>
 <CAB3F3DtrSFPmperGJJAUDZj7vt9aHgvkc0b5Pts3+mq5fTuWXA@mail.gmail.com>
Message-ID: <CAB3F3DvToF_fia+X5SQi-L=BDYGLpzr8nNHqjtFBUjLMbyPE9Q@mail.gmail.com>

Hello again dev,

Due to the interest in the proposal and the prodding of certain folks, I've
written up a short draft BIP of the Ephemeral Anchors idea here:
https://github.com/instagibbs/bips/blob/ephemeral_anchor/bip-ephemeralanchors.mediawiki

The pull request at https://github.com/bitcoin/bitcoin/pull/26403 has been
refreshed on top of the latest V3 proposal, but the BIP itself is
unaffected.

Cheers,
Greg

On Wed, Nov 30, 2022 at 10:32 AM Greg Sanders <gsanders87 at gmail.com> wrote:

> Small update.
>
> A bit ago I went ahead and implemented ephemeral anchors on top of the V3
> proposal to see what the complexity looks like:
> https://github.com/bitcoin/bitcoin/pull/26403
>
> Roughly 130 loc excluding tests, using OP_2 instead of OP_TRUE to not camp
> the value that is used elsewhere.
>
> Please let me know if you have any early feedback on this!
>
> Greg
>
> On Thu, Oct 20, 2022 at 9:42 AM Greg Sanders <gsanders87 at gmail.com> wrote:
>
>> So it doesn't look like I'm ignoring a good question:
>>
>> No solid noninteractive ideas, unless we get some very flexible sighash
>> softfork. Interactively, I think you can get collaborative fee bumps under
>> the current consensus regime and ephemeral anchors. The child will just be
>> built with inputs from different people.
>>
>> On Wed, Oct 19, 2022 at 11:12 AM James O'Beirne <james.obeirne at gmail.com>
>> wrote:
>>
>>> I'm also very happy to see this proposal, since it gets us closer to
>>> having a mechanism that allows the contribution to feerate in an
>>> "unauthenticated" way, which seems to be a very helpful feature for vaults
>>> and other contracting protocols.
>>>
>>> One possible advantage of the sponsors interface -- and I'm curious for
>>> your input here Greg -- is that with sponsors, assuming we relaxed the "one
>>> sponsor per sponsoree" constraint, multiple uncoordinated parties can
>>> collaboratively bump a tx's feerate. A simple example would be a batch
>>> withdrawal from an exchange could be created with a low feerate, and then
>>> multiple users with a vested interest of expedited confirmation could all
>>> "chip in" to raise the feerate with multiple sponsor transactions.
>>>
>>> Having a single ephemeral output seems to create a situation where a
>>> single UTXO has to shoulder the burden of CPFPing a package. Is there some
>>> way we could (possibly later) amend the ephemeral anchor interface to allow
>>> for this kind of collaborative sponsoring? Could you maybe see "chained"
>>> ephemeral anchors that would allow this?
>>>
>>>
>>> On Tue, Oct 18, 2022 at 12:52 PM Jeremy Rubin via bitcoin-dev <
>>> bitcoin-dev at lists.linuxfoundation.org> wrote:
>>>
>>>> Excellent proposal and I agree it does capture much of the spirit of
>>>> sponsors w.r.t. how they might be used for V3 protocols.
>>>>
>>>> The only drawbacks I see is they don't work for lower tx version
>>>> contracts, so there's still something to be desired there, and that the
>>>> requirement to sweep the output must be incentive compatible for the miner,
>>>> or else they won't enforce it (pass the buck onto the future bitcoiners).
>>>> The Ephemeral UTXO concept can be a consensus rule (see
>>>> https://rubin.io/public/pdfs/multi-txn-contracts.pdf "Intermediate
>>>> UTXO") we add later on in lieu of managing them by incentive, so maybe it's
>>>> a cleanup one can punt.
>>>>
>>>> One question I have is if V3 is designed for lightning, and this is
>>>> designed for lightning, is there any sense in requiring these outputs for
>>>> v3? That might help with e.g. anonymity set, as well as potentially keep
>>>> the v3 surface smaller.
>>>>
>>>> On Tue, Oct 18, 2022 at 11:51 AM Greg Sanders via bitcoin-dev <
>>>> bitcoin-dev at lists.linuxfoundation.org> wrote:
>>>>
>>>>> > does that effectively mark output B as unspendable once the child
>>>>> gets confirmed?
>>>>>
>>>>> Not at all. It's a normal spend like before, since the parent has been
>>>>> confirmed. It's completely unrestricted, not being bound to any
>>>>> V3/ephemeral anchor restrictions on size, version, etc.
>>>>>
>>>>> On Tue, Oct 18, 2022 at 11:47 AM Arik Sosman via bitcoin-dev <
>>>>> bitcoin-dev at lists.linuxfoundation.org> wrote:
>>>>>
>>>>>> Hi Greg,
>>>>>>
>>>>>> Thank you very much for sharing your proposal!
>>>>>>
>>>>>> I think there's one thing about the second part of your proposal that
>>>>>> I'm missing. Specifically, assuming the scenario of a v3 transaction with
>>>>>> three outputs, A, B, and the ephemeral anchor OP_TRUE. If a child
>>>>>> transaction spends A and OP_TRUE, does that effectively mark output B as
>>>>>> unspendable once the child gets confirmed? If so, isn't the implication
>>>>>> therefore that to safely spend a transaction with an ephemeral anchor, all
>>>>>> outputs must be spent? Thanks!
>>>>>>
>>>>>> Best,
>>>>>> Arik
>>>>>>
>>>>>> On Tue, Oct 18, 2022, at 6:52 AM, Greg Sanders via bitcoin-dev wrote:
>>>>>>
>>>>>> Hello Everyone,
>>>>>>
>>>>>> Following up on the "V3 Transaction" discussion here
>>>>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-September/020937.html
>>>>>> , I would like to elaborate a bit further on some potential follow-on work
>>>>>> that would make pinning severely constrained in many setups].
>>>>>>
>>>>>> V3 transactions may solve bip125 rule#3 and rule#5 pinning attacks
>>>>>> under some constraints[0]. This means that when a replacement is to be made
>>>>>> and propagated, it costs the expected amount of fees to do so. This is a
>>>>>> great start. What's left in this subset of pinning is *package limit*
>>>>>> pinning. In other words, a fee-paying transaction cannot enter the mempool
>>>>>> due to the existing mempool package it is being added to already being too
>>>>>> large in count or vsize.
>>>>>>
>>>>>> Zooming into the V3 simplified scenario for sake of discussion,
>>>>>> though this problem exists in general today:
>>>>>>
>>>>>> V3 transactions restrict the package limit of a V3 package to one
>>>>>> parent and one child. If the parent transaction includes two outputs which
>>>>>> can be immediately spent by separate parties, this allows one party to
>>>>>> disallow a spend from the other. In Gloria's proposal for ln-penalty, this
>>>>>> is worked around by reducing the number of anchors per commitment
>>>>>> transaction to 1, and each version of the commitment transaction has a
>>>>>> unique party's key on it. The honest participant can spend their version
>>>>>> with their anchor and package RBF the other commitment transaction safely.
>>>>>>
>>>>>> What if there's only one version of the commitment transaction, such
>>>>>> as in other protocols like duplex payment channels, eltoo? What about multi
>>>>>> party payments?
>>>>>>
>>>>>> In the package RBF proposal, if the parent transaction is identical
>>>>>> to an existing transaction in the mempool, the parent will be detected and
>>>>>> removed from the package proposal. You are then left with a single V3 child
>>>>>> transaction, which is then proposed for entry into the mempool. In the case
>>>>>> of another parent output already being spent, this is simply rejected,
>>>>>> regardless of feerate of the new child.
>>>>>>
>>>>>> I have two proposed solutions, of which I strongly prefer the latter:
>>>>>>
>>>>>> 1) Expand a carveout for "sibling eviction", where if the new child
>>>>>> is paying "enough" to bump spends from the same parent, it knocks its
>>>>>> sibling out of the mempool and takes the one child slot. This would solve
>>>>>> it, but is a new eviction paradigm that would need to be carefully worked
>>>>>> through.
>>>>>>
>>>>>> 2) Ephemeral Anchors (my real policy-only proposal)
>>>>>>
>>>>>> Ephemeral Anchors is a term which means an output is watermarked as
>>>>>> an output that MUST be spent in a V3 package. We mark this anchor by being
>>>>>> the bare script `OP_TRUE` and of course make these outputs standard to
>>>>>> relay and spend with empty witness data.
>>>>>>
>>>>>> Also as a simplifying assumption, we require the parent transaction
>>>>>> with such an output to be 0-fee. This makes mempool reasoning simpler in
>>>>>> case the child-spend is somehow evicted, guaranteeing the parent will be as
>>>>>> well.
>>>>>>
>>>>>> Implications:
>>>>>>
>>>>>> a) If the ephemeral anchor MUST be spent, we can allow *any* value,
>>>>>> even dust, even 0, without worrying about bloating the utxo set. We relax
>>>>>> this policy for maximum smart contract flexibility and specification
>>>>>> simplicity..
>>>>>>
>>>>>> b) Since this anchor MUST be spent, any spending of other outputs in
>>>>>> the same parent transaction MUST directly double-spend prior spends of the
>>>>>> ephemeral anchor. This causes the 1 block CSV timelock on outputs to be
>>>>>> removed in these situations. This greatly magnifies composability of smart
>>>>>> contracts, as now we can do things like safely splice directly into new
>>>>>> channels, into statechains, your custodial wallet account, your cold
>>>>>> wallet, wherever, without requiring other wallets to support arbitrary
>>>>>> scripts. Also it hurts that 1 CSV time locked scripts may not be miniscript
>>>>>> compatible to begin with...
>>>>>>
>>>>>> c) *Anyone* can bump the transaction, without any transaction key
>>>>>> material. This is essentially achieving Jeremy's Transaction Sponsors (
>>>>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-September/018168.html)
>>>>>> proposal without consensus changes. As long as someone gets a fully signed
>>>>>> parent, they can execute a bump with minimal wallet tooling. If a
>>>>>> transaction author doesn?t want a ?sponsor?, do not include the output.
>>>>>>
>>>>>> d) Lightning Carve-out(
>>>>>> https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-October/002240.html)
>>>>>> is superseded by this logic, as we are not restricted to two immediately
>>>>>> spendable output scenarios. In its place, robust multi-party fee bumping is
>>>>>> possible.
>>>>>>
>>>>>> e) This also benefits more traditional wallet scenarios, as change
>>>>>> outputs can no longer be pinned, and RBF/CPFP becomes robust. Payees in
>>>>>> simple spends cannot pin you. Batched payouts become a lot less painful.
>>>>>> This was one of the motivating use cases that created the term ?pinning? in
>>>>>> the first place(
>>>>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-February/015717.html),
>>>>>> even if LN/L2 discussion has largely overtaken it due to HTLC theft risks.
>>>>>>
>>>>>> Open Question(s):
>>>>>>
>>>>>>
>>>>>>    1.
>>>>>>
>>>>>>    If we allow non-zero value in ephemeral outputs, does this open
>>>>>>    up a MEV we are worried about? Wallets should toss all the value directly
>>>>>>    to fees, and add their own additional fees on top, otherwise miners have
>>>>>>    incentive to make the smallest utxo burn transaction to claim those funds.
>>>>>>    They just confirmed your parent transaction anyways, so do we care?
>>>>>>    2.
>>>>>>
>>>>>>    SIGHASH_GROUP like constructs would allow uncommitted ephemeral
>>>>>>    anchors to be added at spend time, depending on spending requirements.
>>>>>>    SIGHASH_SINGLE already allows this.
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> Hopefully this gives people something to consider as we move forward
>>>>>> in thinking about mempool design within the constraints we have today.
>>>>>>
>>>>>>
>>>>>> Greg
>>>>>>
>>>>>> 0: With V3 transactions where you have "veto power" over all the
>>>>>> inputs in that transaction. Therefore something like ANYONECANPAY is still
>>>>>> broken. We need a more complex solution, which I?m punting for the sake of
>>>>>> progress.
>>>>>> _______________________________________________
>>>>>> bitcoin-dev mailing list
>>>>>> bitcoin-dev at lists.linuxfoundation.org
>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>>>>
>>>>>>
>>>>>> _______________________________________________
>>>>>> bitcoin-dev mailing list
>>>>>> bitcoin-dev at lists.linuxfoundation.org
>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>>>>
>>>>> _______________________________________________
>>>>> bitcoin-dev mailing list
>>>>> bitcoin-dev at lists.linuxfoundation.org
>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>>>
>>>> _______________________________________________
>>>> bitcoin-dev mailing list
>>>> bitcoin-dev at lists.linuxfoundation.org
>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>>
>>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230127/63147572/attachment-0001.html>

From aymeric at peersm.com  Fri Jan 27 15:43:46 2023
From: aymeric at peersm.com (Aymeric Vitte)
Date: Fri, 27 Jan 2023 16:43:46 +0100
Subject: [bitcoin-dev] Ordinal Inscription Size Limits
In-Reply-To: <Y9PPvBiWOXpBefmD@camus>
References: <CABHetKwan91zqm=0y=_84vG7ffveWTPYONZP_hLQx5o40iAnuQ@mail.gmail.com>
 <Y9PPvBiWOXpBefmD@camus>
Message-ID: <3e3acd36-44d7-6823-4eb6-69affe111204@peersm.com>



Le 27/01/2023 ? 14:21, Andrew Poelstra via bitcoin-dev a ?crit :
> if people were storing NFTs and other crap on the
> chain, then the Bitcoin fee market would become entangled with random
> pump&dump markets
So you mean that Bitcoin is out for NFTs, Metaverse and "web3"?

LN is good but I don't think it can really adapt to everything, what I
proposed yesterday looks complementary

I clearly dislike the current NFTs existing systems, and to make it
short NFTs as a whole until recently, it depends on what people mean by
"NFT", and I did dislike any solution based on OP_RETURN (shxtty stuff
flooding bitcoin with stupid proofs of nothing)

BUT I changed my mind, one can say that I am contradicting myself
everywhere (links in the proposals), but no, explaining why in the proposals

Note that in my proposals you don't need to "mint" the NFTs (using a
third party but not a stupid ethereum/bitcoin like super sidechain) and
that you can reference millions of them in one transaction (low value
NFTs like loyalty programms, discount coupons) in that case of course
the low value NFTs are centralized

That's the future, Bitcoin being out of this does not look plausible,
currently NOBODY envisions bitcoin or LN for a web3 system, so people
here might destroy my proposals, then please do, but I find them quite
good compared to whatever exist

 

-- 
Sophia-Antipolis, France
CV: https://www.peersm.com/CVAV.pdf
LinkedIn: https://fr.linkedin.com/in/aymeric-vitte-05855b26
GitHub : https://www.github.com/Ayms
A Universal Coin Swap system based on Bitcoin: https://gist.github.com/Ayms/029125db2583e1cf9c3209769eb2cdd7
A bitcoin NFT system: https://gist.github.com/Ayms/01dbfebf219965054b4a3beed1bfeba7
Move your coins by yourself (browser version): https://peersm.com/wallet
Bitcoin transactions made simple: https://github.com/Ayms/bitcoin-transactions
torrent-live: https://github.com/Ayms/torrent-live
node-Tor : https://www.github.com/Ayms/node-Tor
Anti-spies and private torrents, dynamic blocklist: http://torrent-live.peersm.com
Peersm : http://www.peersm.com



From robert.lee.dickinson at gmail.com  Sat Jan 28 04:26:15 2023
From: robert.lee.dickinson at gmail.com (Robert Dickinson)
Date: Sat, 28 Jan 2023 01:26:15 -0300
Subject: [bitcoin-dev] Ordinal Inscription Size Limits
In-Reply-To: <Y9PPvBiWOXpBefmD@camus>
References: <CABHetKwan91zqm=0y=_84vG7ffveWTPYONZP_hLQx5o40iAnuQ@mail.gmail.com>
 <Y9PPvBiWOXpBefmD@camus>
Message-ID: <CABHetKxtRMgKC2myYd04UQQ3T2AvVSC7kpN_4_2p4MnHVnANRA@mail.gmail.com>

On Fri, Jan 27, 2023 at 10:21 AM Andrew Poelstra
<apoelstra at wpsoftware.net> wrote:

8<

> Unfortunately, as near as I can tell there is no sensible way to prevent
> people from storing arbitrary data in witnesses without incentivizing
> even worse behavior and/or breaking legitimate use cases.

8<

> There's a reasonable argument that this sort of data is toxic to the
> network, since even though "the market is willing to bear" the price of
> scares blockspace, if people were storing NFTs and other crap on the
> chain, then the Bitcoin fee market would become entangled with random
> pump&dump markets, undermining legitimate use cases and potentially
> preventing new technology like LN from gaining a strong foothold. But
> from a technical point of view, I don't see any principled way to stop
> this.
>
>
>
> --
> Andrew Poelstra
> Director of Research, Blockstream
> Email: apoelstra at wpsoftware.net
> Web:   https://www.wpsoftware.net/andrew
>
> The sun is always shining in space
>     -Justin Lewis-Webster
>

Thank you for your reply and explanations. If it be so, then I think
the principled route would be to make it a priority to continuously
educate people on the morals of the matter. Rather than for fads and
scams, the world would be a better place if ordinal inscriptions were
used for enduring, practical, and universally beneficial purposes,
such as for domain name inscription to solve the DNS centralization
problem.

From alicexbt at protonmail.com  Sat Jan 28 10:58:12 2023
From: alicexbt at protonmail.com (alicexbt)
Date: Sat, 28 Jan 2023 10:58:12 +0000
Subject: [bitcoin-dev] Ordinal Inscription Size Limits
In-Reply-To: <hhgUoi2km8Iv3HQ0aTaZiBXOHq8baEXtG5SEX_VkyYxw-4G0dewhLaj-IiFvAJsZSHW5fXSS3tukOvgzkLcvwdJIzRdBMscd2QMpA_iQBk0=@protonmail.com>
References: <CABHetKwan91zqm=0y=_84vG7ffveWTPYONZP_hLQx5o40iAnuQ@mail.gmail.com>
 <hhgUoi2km8Iv3HQ0aTaZiBXOHq8baEXtG5SEX_VkyYxw-4G0dewhLaj-IiFvAJsZSHW5fXSS3tukOvgzkLcvwdJIzRdBMscd2QMpA_iQBk0=@protonmail.com>
Message-ID: <dVxjcXpVSms-352cXBUbHI893qnlQ7uuF8V9dER5-MgWc2dgXecGCUu1TMIF8z3m_hWUvtAnILxGpcQlV_KIMdUS2D-UCCf24N8JIOTnpS4=@protonmail.com>

Hi Bitcoin Developers,

> Anyone who runs an unpruned bitcoin node should be capacity-planning their disk space assuming that in the future blocks will be more full - as demand for blockspace increases, people will make better use of the space that we already have and average block weight will trend upwards. If you?re thinking about how much disk you will need when we have consistently full blocks, ordinal inscriptions don?t change that number.?

I completely agree with this.

> If we ban "useless data" then it would be easy for would-be data storers
to instead embed their data inside "useful" data such as dummy
signatures or public keys.

> There's a reasonable argument that this sort of data is toxic to the
network, since even though "the market is willing to bear" the price of
scares blockspace, if people were storing NFTs and other crap on the
chain, then the Bitcoin fee market would become entangled with random
pump&dump markets, undermining legitimate use cases and potentially
preventing new technology like LN from gaining a strong foothold.

Initially I considered ordinals and the use of witness for inscriptions useless and harmful. However I have changed my opinion after looking at different things and reading several comments. I do not consider such things 'useless' or 'crap' and it won't affect bitcoin fee market negatively. There is no threat to LN as well.

I consider every bitcoin transaction a legit use case and would like to share an example and different perspective of how such inscriptions might be used at different places:

During the festival of Diwali, it is a common tradition among many Indian families to buy gold coins with the image of the goddess Laxmi, the goddess of wealth and prosperity. The coins are often bought as a symbol of good luck and prosperity for the upcoming year. They may also be given as gifts to family and friends or used as a form of investment. The coins can be purchased from a variety of sources, including jewelry stores and online retailers.

If people start buying bitcoin during Diwali, and sellers use the witness to include the image of Laxmi in the inputs used, it would be an innovative way of combining traditional customs with modern technology. Since some users consider bitcoin as digital gold, I won't be surprised if this really happens in future and won't consider it bad as the transactions are paying for block space used.

/dev/fd0
floppy disc guy

Sent with Proton Mail secure email.

------- Original Message -------
On Friday, January 27th, 2023 at 6:28 PM, rot13maxi via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:


> Hello,
> 
> ?Unlimited storage? isn?t really accurate. It?s witness data in a taproot transaction, so the block size limit still applies. Anyone who runs an unpruned bitcoin node should be capacity-planning their disk space assuming that in the future blocks will be more full - as demand for blockspace increases, people will make better use of the space that we already have and average block weight will trend upwards. If you?re thinking about how much disk you will need when we have consistently full blocks, ordinal inscriptions don?t change that number.?
> 
> - rijndael
> 
> On Fri, Jan 27, 2023 at 7:44 AM, Robert Dickinson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
> 
> > I'm curious what opinions exist and what actions might be taken by core developers regarding storing unlimited amounts of NFT (or other?) content as witness data (https://docs.ordinals.com/inscriptions.html). The ordinal scheme is elegant and genius IMHO, but when I think about the future disk use of all unpruned nodes, I question whether unlimited storage is wise to allow for such use cases. Wouldn't it be better to find a way to impose a size limit similar to OP_RETURN for such inscriptions?
> > 
> > I think it would be useful to link a sat to a deed or other legal construct for proof of ownership in the real world, so that real property can be transferred on the blockchain using ordinals, but storing the property itself on the blockchain seems nonsensical to me.

From aymeric at peersm.com  Sat Jan 28 16:47:46 2023
From: aymeric at peersm.com (Aymeric Vitte)
Date: Sat, 28 Jan 2023 17:47:46 +0100
Subject: [bitcoin-dev] Ordinal Inscription Size Limits
In-Reply-To: <3e3acd36-44d7-6823-4eb6-69affe111204@peersm.com>
References: <CABHetKwan91zqm=0y=_84vG7ffveWTPYONZP_hLQx5o40iAnuQ@mail.gmail.com>
 <Y9PPvBiWOXpBefmD@camus> <3e3acd36-44d7-6823-4eb6-69affe111204@peersm.com>
Message-ID: <b00ac602-30d5-829e-664e-d18f0e4dd762@peersm.com>

I saw the other posts, then storage in witness, no, ordinals no for now,
let's keep things simple and understandable

I forgot to mention that the proposals envision a "local bitcoin" (for a
metaverse for example) wich is a fork of Bitcoin code, but of course not
a fork of Bitcoin, and which of course does not store anything in the
main Bitcoin chain, but which remains compatible (tx format) and coins
between chains can be swapped

Maybe nobody care, but the idea is to put bitcoin into the party as an
alternative to this ethereum mess


Le 27/01/2023 ? 16:43, Aymeric Vitte a ?crit :
>
> Le 27/01/2023 ? 14:21, Andrew Poelstra via bitcoin-dev a ?crit :
>> if people were storing NFTs and other crap on the
>> chain, then the Bitcoin fee market would become entangled with random
>> pump&dump markets
> So you mean that Bitcoin is out for NFTs, Metaverse and "web3"?
>
> LN is good but I don't think it can really adapt to everything, what I
> proposed yesterday looks complementary
>
> I clearly dislike the current NFTs existing systems, and to make it
> short NFTs as a whole until recently, it depends on what people mean by
> "NFT", and I did dislike any solution based on OP_RETURN (shxtty stuff
> flooding bitcoin with stupid proofs of nothing)
>
> BUT I changed my mind, one can say that I am contradicting myself
> everywhere (links in the proposals), but no, explaining why in the proposals
>
> Note that in my proposals you don't need to "mint" the NFTs (using a
> third party but not a stupid ethereum/bitcoin like super sidechain) and
> that you can reference millions of them in one transaction (low value
> NFTs like loyalty programms, discount coupons) in that case of course
> the low value NFTs are centralized
>
> That's the future, Bitcoin being out of this does not look plausible,
> currently NOBODY envisions bitcoin or LN for a web3 system, so people
> here might destroy my proposals, then please do, but I find them quite
> good compared to whatever exist
>
>  
>

-- 
Sophia-Antipolis, France
CV: https://www.peersm.com/CVAV.pdf
LinkedIn: https://fr.linkedin.com/in/aymeric-vitte-05855b26
GitHub : https://www.github.com/Ayms
A Universal Coin Swap system based on Bitcoin: https://gist.github.com/Ayms/029125db2583e1cf9c3209769eb2cdd7
A bitcoin NFT system: https://gist.github.com/Ayms/01dbfebf219965054b4a3beed1bfeba7
Move your coins by yourself (browser version): https://peersm.com/wallet
Bitcoin transactions made simple: https://github.com/Ayms/bitcoin-transactions
torrent-live: https://github.com/Ayms/torrent-live
node-Tor : https://www.github.com/Ayms/node-Tor
Anti-spies and private torrents, dynamic blocklist: http://torrent-live.peersm.com
Peersm : http://www.peersm.com



From robert.lee.dickinson at gmail.com  Sun Jan 29 10:34:54 2023
From: robert.lee.dickinson at gmail.com (Robert Dickinson)
Date: Sun, 29 Jan 2023 07:34:54 -0300
Subject: [bitcoin-dev] Ordinal Inscription Size Limits
In-Reply-To: <dVxjcXpVSms-352cXBUbHI893qnlQ7uuF8V9dER5-MgWc2dgXecGCUu1TMIF8z3m_hWUvtAnILxGpcQlV_KIMdUS2D-UCCf24N8JIOTnpS4=@protonmail.com>
References: <CABHetKwan91zqm=0y=_84vG7ffveWTPYONZP_hLQx5o40iAnuQ@mail.gmail.com>
 <hhgUoi2km8Iv3HQ0aTaZiBXOHq8baEXtG5SEX_VkyYxw-4G0dewhLaj-IiFvAJsZSHW5fXSS3tukOvgzkLcvwdJIzRdBMscd2QMpA_iQBk0=@protonmail.com>
 <dVxjcXpVSms-352cXBUbHI893qnlQ7uuF8V9dER5-MgWc2dgXecGCUu1TMIF8z3m_hWUvtAnILxGpcQlV_KIMdUS2D-UCCf24N8JIOTnpS4=@protonmail.com>
Message-ID: <CABHetKw2n7MHb-u-RjA89zwO4+VE+cJMY9Bc5h1tBptrhzgrmw@mail.gmail.com>

On Sat, Jan 28, 2023 at 7:58 AM alicexbt <alicexbt at protonmail.com> wrote:
>
> Hi Bitcoin Developers,
>
> > Anyone who runs an unpruned bitcoin node should be capacity-planning their disk space assuming that in the future blocks will be more full - as demand for blockspace increases, people will make better use of the space that we already have and average block weight will trend upwards. If you?re thinking about how much disk you will need when we have consistently full blocks, ordinal inscriptions don?t change that number.
>
> I completely agree with this.

I fully agree with this too. It was a sloppy remark on my part--
thanks for claifying. Underlying my remark was a bit of disgust from
knowing that in the future, a (perhaps large) X number of GB of what
should have been financial data will actually turn out to be something
else entirely. Time/space on the Bitcoin blockchain is a shared
limited resource and should be treated accordingly. We can say "no
worries...the price and demand will sort everything out," but
hopefully we all want Bitcoin to be the best financial tool it can be.

?If the ax is not sharp and he does not make it sharp, then he must
use more strength. Wisdom helps one to do well.?

From dave at dtrt.org  Tue Jan 31 00:02:51 2023
From: dave at dtrt.org (David A. Harding)
Date: Mon, 30 Jan 2023 14:02:51 -1000
Subject: [bitcoin-dev] Reference example bech32m address for future segwit
	versions
Message-ID: <e6da74da025355472a81e613fe7683b9@dtrt.org>

Hi y'all!,

One of the benefits proposed for bech32 (and, by extension, bech32m) is
that spender wallets shouldn't need to be upgraded to pay segwit outputs
defined in future soft forks.  For example, Bitcoin Core today can pay a
bech32m address for a segwit v2 output, even though no meaning has been
assigned to output scripts matching a segwit v2 template.

However, testing this behavior in production[1] can create an annoyance
for developers of future soft forks.  They will need to deal with any
existing outputs paid to the templates used in that proposed soft fork.
See, for example, some discussion by developer 0xB10C about payments to
segwit v1 addresses before activation of the taproot soft fork:
https://b10c.me/blog/007-spending-p2tr-pre-activation/

I was wondering if it would be useful to have a canonical examples of
future segwit addresses that are designed to be very unlikely to
interfere with future soft forks but which would still reasonably
exercise wallets supporting bech32m.  I think of this as the rough
equivalent of the RFC2606 domain "example.com" which has been reserved
for examples in documentation.

Specifically, I'm thinking of the following addresses, one each for
mainnet and testnet:

- HRP: bc for mainnet; tb for testent
- Witness version: 16 (the last segwit version)
- Witness program: 0x0000.  Two bytes is the minimum allowed
   by BIP141, but it's far too small to make any sort of secure 
commitment,
   so I'm hoping it won't conflict with any future use

I think we should try to start with just one reserved address per
network, but if that isn't enough, I think we could allow any two-byte
witness program with witness version 16.

Outputs paid to reserved addresses will still be anyone-can-spend, so
there's no change required to Bitcoin Core or other software and those
outputs can still be cleaned out of the UTXO set.  Additionally, if we
ever *really* need that address space for a soft fork, it will be
available.

Are there any objections to this idea, or suggestions for a better way
to go about it?

Thanks!,

-Dave

[1] Testing in production should be avoided because it uses block space
that could otherwise be used by actual value transfers.  Also, it costs
money and pollutes the UTXO set (at least temporarily).  However, when
testing whether proprietary third-party software, such as an exchange,
supports payments to future segwit versions, sometimes the only
convenient method is to actually pay the address for a future segwit
version.  Additionally, my specific use case is just to write 
documentation
about bech32m---but I worry that people will pay my example of a future 
segwit
version address.

From erik at q32.com  Tue Jan 31 08:58:46 2023
From: erik at q32.com (Erik Aronesty)
Date: Tue, 31 Jan 2023 03:58:46 -0500
Subject: [bitcoin-dev] Ordinal Inscription Size Limits
In-Reply-To: <CABHetKw2n7MHb-u-RjA89zwO4+VE+cJMY9Bc5h1tBptrhzgrmw@mail.gmail.com>
References: <CABHetKwan91zqm=0y=_84vG7ffveWTPYONZP_hLQx5o40iAnuQ@mail.gmail.com>
 <hhgUoi2km8Iv3HQ0aTaZiBXOHq8baEXtG5SEX_VkyYxw-4G0dewhLaj-IiFvAJsZSHW5fXSS3tukOvgzkLcvwdJIzRdBMscd2QMpA_iQBk0=@protonmail.com>
 <dVxjcXpVSms-352cXBUbHI893qnlQ7uuF8V9dER5-MgWc2dgXecGCUu1TMIF8z3m_hWUvtAnILxGpcQlV_KIMdUS2D-UCCf24N8JIOTnpS4=@protonmail.com>
 <CABHetKw2n7MHb-u-RjA89zwO4+VE+cJMY9Bc5h1tBptrhzgrmw@mail.gmail.com>
Message-ID: <CAJowKgLe9NRHG9uo5TVj39NceLNfAKF1Y6nzLzi6=GfwEroy3Q@mail.gmail.com>

my only concern is that as block space gets limited the likelihood of soft
fork opcode tech improvement proposals getting accepted by the community
goes down

schnorr sigs are extremely useful to me (anon, cheap multisig)

and some sort of vault tech would be very helpful as well
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230131/8dfd128b/attachment.html>

From gsanders87 at gmail.com  Tue Jan 31 14:30:34 2023
From: gsanders87 at gmail.com (Greg Sanders)
Date: Tue, 31 Jan 2023 09:30:34 -0500
Subject: [bitcoin-dev] Reference example bech32m address for future
	segwit versions
In-Reply-To: <e6da74da025355472a81e613fe7683b9@dtrt.org>
References: <e6da74da025355472a81e613fe7683b9@dtrt.org>
Message-ID: <CAB3F3Dtfu+kaJ8jgi-qRiZBXvuYaEVEa32q_UPkwA5MLAP9RSg@mail.gmail.com>

Hi David,

>From practical experience, I think you'll find that most exchanges will not
enable sends to future segwit versions,
as from a risk perspective it's likely a mistake to send funds there. That
said, as long as we don't change
the checksum again(!), updating to new versions should be fairly straight
forward. Every update will be a matter
of allowing a new version and a new length instead of requiring
library updates. Making sure the most popular
open source libraries support it is probably the best way to spend energy
ensuring that future upgrades go smoothly.

Best,
Greg

On Mon, Jan 30, 2023 at 8:25 PM David A. Harding via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Hi y'all!,
>
> One of the benefits proposed for bech32 (and, by extension, bech32m) is
> that spender wallets shouldn't need to be upgraded to pay segwit outputs
> defined in future soft forks.  For example, Bitcoin Core today can pay a
> bech32m address for a segwit v2 output, even though no meaning has been
> assigned to output scripts matching a segwit v2 template.
>
> However, testing this behavior in production[1] can create an annoyance
> for developers of future soft forks.  They will need to deal with any
> existing outputs paid to the templates used in that proposed soft fork.
> See, for example, some discussion by developer 0xB10C about payments to
> segwit v1 addresses before activation of the taproot soft fork:
> https://b10c.me/blog/007-spending-p2tr-pre-activation/
>
> I was wondering if it would be useful to have a canonical examples of
> future segwit addresses that are designed to be very unlikely to
> interfere with future soft forks but which would still reasonably
> exercise wallets supporting bech32m.  I think of this as the rough
> equivalent of the RFC2606 domain "example.com" which has been reserved
> for examples in documentation.
>
> Specifically, I'm thinking of the following addresses, one each for
> mainnet and testnet:
>
> - HRP: bc for mainnet; tb for testent
> - Witness version: 16 (the last segwit version)
> - Witness program: 0x0000.  Two bytes is the minimum allowed
>    by BIP141, but it's far too small to make any sort of secure
> commitment,
>    so I'm hoping it won't conflict with any future use
>
> I think we should try to start with just one reserved address per
> network, but if that isn't enough, I think we could allow any two-byte
> witness program with witness version 16.
>
> Outputs paid to reserved addresses will still be anyone-can-spend, so
> there's no change required to Bitcoin Core or other software and those
> outputs can still be cleaned out of the UTXO set.  Additionally, if we
> ever *really* need that address space for a soft fork, it will be
> available.
>
> Are there any objections to this idea, or suggestions for a better way
> to go about it?
>
> Thanks!,
>
> -Dave
>
> [1] Testing in production should be avoided because it uses block space
> that could otherwise be used by actual value transfers.  Also, it costs
> money and pollutes the UTXO set (at least temporarily).  However, when
> testing whether proprietary third-party software, such as an exchange,
> supports payments to future segwit versions, sometimes the only
> convenient method is to actually pay the address for a future segwit
> version.  Additionally, my specific use case is just to write
> documentation
> about bech32m---but I worry that people will pay my example of a future
> segwit
> version address.
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230131/28cd677c/attachment.html>

From billy.tetrud at gmail.com  Tue Jan 31 15:02:51 2023
From: billy.tetrud at gmail.com (Billy Tetrud)
Date: Tue, 31 Jan 2023 09:02:51 -0600
Subject: [bitcoin-dev] Wallet vaults with pre-signed transactions but no
 ephemeral keys
In-Reply-To: <rs4K-Lg4t58J2gfeXUPHK0CuctCn_sq6IlyZ7wobDR_cCCAkd_3JrRM4LVCrhxhd3PE4fnVveTEc0sYDmS9fqpIEUPFikC5PDUOlC9D_mhU=@protonmail.com>
References: <CAGpPWDY+4G1Lb3J5XU_vHVgsOtbwhM=_WCt4-sbk17T3SoxaNw@mail.gmail.com>
 <rs4K-Lg4t58J2gfeXUPHK0CuctCn_sq6IlyZ7wobDR_cCCAkd_3JrRM4LVCrhxhd3PE4fnVveTEc0sYDmS9fqpIEUPFikC5PDUOlC9D_mhU=@protonmail.com>
Message-ID: <CAGpPWDaaBKbc_evP94xHS9h_pJogPre0YiE1+Pe27WV4dn6MHA@mail.gmail.com>

Ah good to know someone's put work into this kind of idea. Thanks for the
reference!

On Thu, Jan 26, 2023 at 8:31 AM darosior <darosior at protonmail.com> wrote:

> Hello Billy,
>
> Yes it's basically a (simple) instantiation of Revault. You can find more
> at https://github.com/revault (you most likely want the
> `practical-revault` repo). There is a description of the concept, the
> specification of a communication protocol between the participants as well
> as the implementation of the whole.
>
> Such a design presents some advantages, but it has two major issues:
>
>    - You need to make sure all your watchtowers received the Cancel
>    signature before you sign the Unvault transaction. But how can you get this
>    guarantee in the usual (and reasonable) model of an untrusted laptop?
>    - You can only have policies on the Unvault transaction (eg "You can
>    only Unvault up to X BTC during working hours"), not on the Spend
>    transaction (eg "You can only send coins to a Script with pubkey Y required
>    in all spending paths"). Revault allows to use cosigning servers that act
>    as anti-replay oracles to have policies on the spend, but this is obviously
>    *very* suboptimal.
>
>
> Both issues are solvable with covenants.
>
> Antoine Poinsot
> ------- Original Message -------
> Le lundi 23 janvier 2023 ? 6:39 PM, Billy Tetrud via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> a ?crit :
>
> In the discussion around James' OP_VAULT proposal, it was implied that
> precomputed vaults must use ephemeral keys that must be deleted as part of
> the vaulting protocol, like Bryan Bishop's proposal
> <https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-August/017229.html>.
> Looking around, I haven't been able to find any wallet vault proposal that
> doesn't require ephemeral keys, so at the risk of posting something that's
> obvious to everyone, I wanted to share a simple way to do a wallet vault
> without requiring any key deletion.
>
> The basic idea is to create an N-of-N multisig address, and pre-sign some
> transactions from it with N-1 keys to an address with several timelocked
> spend paths. This has the fallback that funds can always be spent
> immediately if you use all the keys, just like a normal N-of-N multisig
> address (since that's what it is at its core), but the usage of any of the
> pre-signed transactions leads to an address that guarantees a clawback
> within a time window. Here's a 3-of-3 example:
>
> *Vault Initialization*:
> 1. Create 3 of 3 Vault Address
> 2. Create an Interim Address that can send with:
> * 1 of 3 keys after a timelock of 1 month
> * 2 of 3 keys after a timelock of 1 week
> * 3 of 3 keys with no timelock
>
> *Vaulting*:
> 1. Create a transaction sending an output to the Vault Address
> 2. Create a transaction spending that Vault Address output to the Interim
> Address
> 3. Presign one copy of the step-2 transaction for each of the three
> combinations of two keys.
> 4. Store seeds separately, store the wallet config as well as the three
> presigned transactions with each seed.
>
> *Unvaulting*:
> 1. Sign one of the pre-signed transactions with the missing signature.
> 2. Broadcast
> 3. Wait the appropriate timelock for the number of keys you want to sign
> with.
> 4. Create a transaction sending from the Interim Address.
> 5. Broadcast
>
> *Recovering *(after unvaulting step 2 after the broadcasted transaction
> to the Interim Address has been mined):
> 1. Sign the utxo with all three keys to any destination. Alternatively
> sign with two keys, wait 1 week.
> 2. Broadcast it
>
> This has the usual downsides of pre-signed vaults that you need to backup
> these transactions for each vaulting, complications involving the
> flexibility (or lack thereof) of fees, and inflexibility in how much to
> unvault (must be the whole utxo, no change). This could of course be
> augmented with various techniques to make fee handling more flexible
> (anchor outputs, multiple versions of the presigned transactions with
> different fees, etc). More complicated presigning schemes could allow for
> some flexibility in unvaulting amount (eg by sending change back into the
> vault, and creating additional pre-signed transactions for that new output).
>
> It also has the same downside that OP_CTV vaults have, where a stolen key
> can steal funds from the interim address by racing the owner with their own
> transaction once the necessary delay has passed. Note that James' OP_VAULT
> opcode wouldn't have this problem.
>
> But not requiring any toxic waste keys seems like a pretty good benefit
> over Bryan Bishop's original proposal.
>
> Anyways sorry if this was already on people's radar and just too obvious
> to post about.
>
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230131/3f850526/attachment.html>

From aymeric at peersm.com  Tue Jan 31 18:36:28 2023
From: aymeric at peersm.com (Aymeric Vitte)
Date: Tue, 31 Jan 2023 19:36:28 +0100
Subject: [bitcoin-dev] A Universal Coin Swap system based on bitcoin and
 a Bitcoin NFT system
In-Reply-To: <ff4e7a30-47b1-39f4-97cc-27f7ec2cc326@peersm.com>
References: <ff4e7a30-47b1-39f4-97cc-27f7ec2cc326@peersm.com>
Message-ID: <ecce4c01-2715-4c6b-3c2e-8986e275561b@peersm.com>

I am not sure to understand the current discussion about ordinals
relayed by the press, it's from my standpoint a no for storing things in
witness, and a no to use ordinals as a NFT system

Please remember that NFTs are not only electronic things, it can be real
things, or whatever you like, just referenced in the blockchain by a
"double hash" for my proposal

Bitcoin is currently completely out of the future: the so-called "web3",
and lightning will not solve everything

Then please see my two proposals and comment, it's simple and easy to
read, and just complies with all comments related to/against the
ordinals proposal (storing things for my proposals in a good old
OP_RETURN the hashes and signatures only, not flooding bitcoin with
proofs of nothing, docs, images, etc), or just point out other better
systems based on bitcoin

It just shows again that bitcoin is better in all aspects compared to
other systems

I am not against ordinals but don't see it for "web3"


Le 26/01/2023 ? 21:15, Aymeric Vitte a ?crit :
> Please see:
>
> "A Bitcoin NFT system"
> https://gist.github.com/Ayms/01dbfebf219965054b4a3beed1bfeba7 "The
> purpose of this proposal is to propose a simple NFT system based on the
> Bitcoin blockchain, assuming that the main purpose of a NFT is to be
> sold/bought, but not only, it can be something that you keep for
> yourself proving your ownership on the blockchain, or something that you
> offer to someone else, the advantages compared to using Ethereum or any
> blockchain/sidechain on both networks (or others) will be explained below"
>
> And the continuation:
>
> "A Universal Coin Swap system based on bitcoin"
> https://gist.github.com/Ayms/029125db2583e1cf9c3209769eb2cdd7 "The
> purpose here is to propose a simple Coin Swap decentralized system based
> on Bitcoin but that works for all blockchains/tokens"
>
> The idea is to propose something simple, that people can understand,
> secured, decentralized, easy to implement/use, not expensive for the
> users, unlike Ethereum solutions, showing also that bitcoin can easily
> do in a much more simple manner what ethereum is doing
>
> It's a bit similar to Lightning but not as sophisticated, basically the
> proof of deals are stored in OP_RETURN (looks trivial, yes, but unlike
> other solutions the proposals store a real proof and does not flood the
> bitcoin network with funny stuff, it could be turned into bitcoin
> contracts which most likely will not be recognized as standard), we
> cannot enforce everything like Lightning but the trust here is more
> based on a reputation model, and same as Lightning the cheater just lose
> its bitcoin or get tagged as a cheater, will be tracked and might assume
> the consequences later
>
> As written, I am a fan of Lightning but see it more as a middle/long
> term relationship between people since coins must be locked into a
> multisig transaction while here we are more talking about a one time
> deal, where you don't know if you will buy something else to the seller,
> with which coin and where (metaverse for example)
>
> For your review and comments, here or in private, no real inventions
> here but some non usual ideas like the double hash, the third party and
> others, solving also one of my personal problematic since years: "how to
> sell a secret NFT?"
>
> In any case it remains decentralized (but of course some tools/wallets
> must ease the process for the users), like Lightning, and unlike
> everything that is existing today in those areas to my knowledge, except
> Lightning again
>
> Regards
>
> Aymeric
>
>

-- 
Sophia-Antipolis, France
CV: https://www.peersm.com/CVAV.pdf
LinkedIn: https://fr.linkedin.com/in/aymeric-vitte-05855b26
GitHub : https://www.github.com/Ayms
A Universal Coin Swap system based on Bitcoin: https://gist.github.com/Ayms/029125db2583e1cf9c3209769eb2cdd7
A bitcoin NFT system: https://gist.github.com/Ayms/01dbfebf219965054b4a3beed1bfeba7
Move your coins by yourself (browser version): https://peersm.com/wallet
Bitcoin transactions made simple: https://github.com/Ayms/bitcoin-transactions
torrent-live: https://github.com/Ayms/torrent-live
node-Tor : https://www.github.com/Ayms/node-Tor
Anti-spies and private torrents, dynamic blocklist: http://torrent-live.peersm.com
Peersm : http://www.peersm.com



From dave at dtrt.org  Tue Jan 31 23:33:13 2023
From: dave at dtrt.org (David A. Harding)
Date: Tue, 31 Jan 2023 13:33:13 -1000
Subject: [bitcoin-dev] Reference example bech32m address for future
 segwit versions
In-Reply-To: <CAB3F3Dtfu+kaJ8jgi-qRiZBXvuYaEVEa32q_UPkwA5MLAP9RSg@mail.gmail.com>
References: <e6da74da025355472a81e613fe7683b9@dtrt.org>
 <CAB3F3Dtfu+kaJ8jgi-qRiZBXvuYaEVEa32q_UPkwA5MLAP9RSg@mail.gmail.com>
Message-ID: <c9ddddce1ad797671431335fe95cf2b7@dtrt.org>

On 2023-01-31 04:30, Greg Sanders wrote:
> Hi David,
> 
> From practical experience, I think you'll find that most exchanges
> will not enable sends to future segwit versions,
> as from a risk perspective it's likely a mistake to send funds there.

Hi Greg!,

I thought the best practice[1] was that wallets would spend to the 
output indicated by any valid bech32m address.  You seem to implying 
that the best practice is the opposite: that wallets should only send to 
outputs they know can be secured (i.e., which are not currently 
anyone-can-spend).  The more restrictive approach seems kind of sad to 
me since any problem which can result in a user accidentally withdrawing 
to a future segwit version could even more easily result in them 
withdrawing to a witness program for which there is no solution (i.e., 
no key or script is known to spend).

If it is a best practice, then I think there's a benefit to being able 
to test it even when other people's proprietary software is involved.  A 
wallet or service likely to follow that best practice may be more likely 
to follow other best practices which cannot be as easily tested for.  
But, if it's going to be tested, I want the testing to use the address 
least likely to cause problems for protocol developers in the future.  
Do you (and others on this list) have any reason to believe OP_16 
OP_PUSH2 0000 would be a problematic script, or can you think of a 
better script?

Thanks!,

-Dave

[1] BIP350, emphasis in original: "[...] we emphatically recommend [...] 
ensuring that your implementation supports sending to v1 **and higher 
versions.**"

