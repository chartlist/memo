From contact at taoeffect.com  Fri Dec  1 00:00:26 2017
From: contact at taoeffect.com (Tao Effect)
Date: Thu, 30 Nov 2017 16:00:26 -0800
Subject: [bitcoin-dev] A DNS-like decentralized mapping for wallet
 addresses?
In-Reply-To: <CAHneDF3qH9OUxqLthY6hEzzFr21QJFLV5wOP8jw+p5eOtpb2oQ@mail.gmail.com>
References: <CAHneDF3qH9OUxqLthY6hEzzFr21QJFLV5wOP8jw+p5eOtpb2oQ@mail.gmail.com>
Message-ID: <BDF3ADC8-FFBA-445D-A607-164E7FB34328@taoeffect.com>

Check out Blockstack, they're doing something like that.

--
Please do not email me anything that you are not comfortable also sharing with the NSA.

> On Nov 30, 2017, at 2:20 PM, mandar mulherkar via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:
> 
> Hello,
> 
> I am new, so apologies if this has been asked before.
> 
> Here are a few questions to start with -
> 
> I was wondering in terms of mass adoption, instead of long wallet addresses, maybe there should be a DNS-like decentralized mapping service to provide a user at crypto address?
> 
> This address translation can happen with confirmations from the network. So instead of providing a long string, or a QR code that needs an app, you simply type in a human readable address, and the wallet software converts it to a wallet address.
> 
> Please let me know where I can research this more - if there already is literature about this somewhere.
> 
> thanks!
> 
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/a79f414b/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: Message signed with OpenPGP
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/a79f414b/attachment-0001.sig>

From justin at netki.com  Fri Dec  1 00:10:29 2017
From: justin at netki.com (Justin Newton)
Date: Fri, 1 Dec 2017 08:10:29 +0800
Subject: [bitcoin-dev] A DNS-like decentralized mapping for wallet
	addresses?
In-Reply-To: <CAHneDF3qH9OUxqLthY6hEzzFr21QJFLV5wOP8jw+p5eOtpb2oQ@mail.gmail.com>
References: <CAHneDF3qH9OUxqLthY6hEzzFr21QJFLV5wOP8jw+p5eOtpb2oQ@mail.gmail.com>
Message-ID: <CABqynxJLohwv=kw38GCV5g4L6UnfMTgSkCS0DUqNYCgb48=5ug@mail.gmail.com>

https://www.walletnames.com

Based on a standard that can support blockchain based or traditional ICANN
DNS.



On Fri, Dec 1, 2017 at 6:20 AM, mandar mulherkar via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Hello,
>
> I am new, so apologies if this has been asked before.
>
> Here are a few questions to start with -
>
> I was wondering in terms of mass adoption, instead of long wallet
> addresses, maybe there should be a DNS-like decentralized mapping service
> to provide a user at crypto address?
>
> This address translation can happen with confirmations from the network.
> So instead of providing a long string, or a QR code that needs an app, you
> simply type in a human readable address, and the wallet software converts
> it to a wallet address.
>
> Please let me know where I can research this more - if there already is
> literature about this somewhere.
>
> thanks!
>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>


-- 

Justin W. Newton
Founder/CEO
Netki, Inc.

justin@ <justin at netki.com>netki.com <justin at netki.com>

*+1.818.927.2646*
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171201/8ec413e8/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: PastedGraphic-1.tiff
Type: image/tiff
Size: 10972 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171201/8ec413e8/attachment.tiff>

From joroark at vt.edu  Fri Dec  1 03:08:24 2017
From: joroark at vt.edu (Douglas Roark)
Date: Thu, 30 Nov 2017 19:08:24 -0800
Subject: [bitcoin-dev] A DNS-like decentralized mapping for wallet
 addresses?
In-Reply-To: <CAHneDF3qH9OUxqLthY6hEzzFr21QJFLV5wOP8jw+p5eOtpb2oQ@mail.gmail.com>
References: <CAHneDF3qH9OUxqLthY6hEzzFr21QJFLV5wOP8jw+p5eOtpb2oQ@mail.gmail.com>
Message-ID: <c889543b-8dbe-b88c-5f47-7aee1db697aa@vt.edu>

On 2017/11/30 14:20, mandar mulherkar via bitcoin-dev wrote:
> I was wondering in terms of mass adoption, instead of long wallet
> addresses, maybe there should be a DNS-like decentralized mapping
> service to provide a user at crypto address?

A few years ago, I was part of an effort with Armory and Verisign to
make something similar to what you're describing.
https://tools.ietf.org/html/draft-wiley-paymentassoc-00 is where you can
find the one and only official draft. I worked on a follow-up with some
changes and some nice appendices, explaining some nice tricks one could
use to make payment management flexible. For various reasons, it never
got published. I think it's an interesting draft that could be turned
into something useful. Among other things, it was able to leverage BIP32
and allow payment requests to be generated that automatically pointed
payees to the correct branch. DNSSEC may have some issues but, AFAIK,
it's as the easiest way to bootstrap identity to a common, reasonably
secure standard.

-- 
---
Douglas Roark
Cryptocurrency, network security, travel, and art.
https://onename.com/droark
joroark at vt.edu
PGP key ID: 26623924

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 895 bytes
Desc: OpenPGP digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/ee8ac2e0/attachment-0001.sig>

From lvella at gmail.com  Fri Dec  1 03:15:00 2017
From: lvella at gmail.com (Lucas Clemente Vella)
Date: Fri, 1 Dec 2017 01:15:00 -0200
Subject: [bitcoin-dev] A DNS-like decentralized mapping for wallet
	addresses?
In-Reply-To: <CAHneDF3qH9OUxqLthY6hEzzFr21QJFLV5wOP8jw+p5eOtpb2oQ@mail.gmail.com>
References: <CAHneDF3qH9OUxqLthY6hEzzFr21QJFLV5wOP8jw+p5eOtpb2oQ@mail.gmail.com>
Message-ID: <CAGCathwjmj_f0TWZF=BhdCq=dSZ_R53Frd3A9b2SgFtus-AH=g@mail.gmail.com>

The original altcoin, Namecoin, aimed a building a bitcoin-like, blockchain
based decentralized DNS system. Unfortunately it didn't catch, but it would
be the most logical choice for the name registry database.

2017-11-30 20:20 GMT-02:00 mandar mulherkar via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org>:

> Hello,
>
> I am new, so apologies if this has been asked before.
>
> Here are a few questions to start with -
>
> I was wondering in terms of mass adoption, instead of long wallet
> addresses, maybe there should be a DNS-like decentralized mapping service
> to provide a user at crypto address?
>
> This address translation can happen with confirmations from the network.
> So instead of providing a long string, or a QR code that needs an app, you
> simply type in a human readable address, and the wallet software converts
> it to a wallet address.
>
> Please let me know where I can research this more - if there already is
> literature about this somewhere.
>
> thanks!
>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>


-- 
Lucas Clemente Vella
lvella at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171201/4f29dac1/attachment.html>

From rjmarti2 at millersville.edu  Fri Dec  1 07:58:01 2017
From: rjmarti2 at millersville.edu (Ryan J Martin)
Date: Fri, 1 Dec 2017 07:58:01 +0000
Subject: [bitcoin-dev] BIP Idea: Marginal Pricing
In-Reply-To: <CADpM8jr_RrbPXLx6Up8HMW-fv=noFLjy817dfsFdYTg216Pu7w@mail.gmail.com>
References: <CADpM8jr_RrbPXLx6Up8HMW-fv=noFLjy817dfsFdYTg216Pu7w@mail.gmail.com>
Message-ID: <127281C1AA02374F8AAD9EE04FAE878A0218FACE16@STUDMail1.muad.local>

Interesting thoughts William, however much of what you describe already exists:
"I predict that this scheme would result in two markets: a backlog market and a real-time market. Users targeting the backlog market would match the price of the largest backlog section in order to be included in the next backlog block."
This happens with users deciding to pay (essentially) a fee smaller or larger than the 1999th tx in the mempool. If user is willing to pay more than the 1999th highest fee tx in mempool (or whatever tx byte 1,000,000 in a mempool ranked by tx fee) then they will get to be on the next block. This is a simplification but you get the idea.

Further, Greg Maxwell's one reply covers alot of the biggest pitfalls well. Especially that much of this already happens and that behavior in response to such a change could be hairy to predict. So I'm not sure that---what is basically--- a multi-unit Vickrey auction is the best way to go... but it is an interesting idea worth further examination.

Second, minimizing invididual user tx fees and maximizing total tx fees are essentially incompatible within the current development structure. Even if the block limit is increased to 3mb the same problem will eventually occur. While I agree it would be ideal to maximize social benefit (i.e. maximize both consumer and producer surplus) through more simple protocol changes---at least in the medium term, that isn't on the table so it is better to move on.

  This is not an easy optimization problem to solve though. The difficulty is trying to model a market like bitcoin; the only thing that comes close is electricity markets. With 2,000 tx in the pool, users aren't willing to pay shit to send a tx; there is always a miner to process it. So at 2,000tx per 10 min (3.333 txps, 1mb/10min,etc) and below users price elasticity is flat. Once the pool has >2,000 tx in it, especially for any extended amount of time, users price elasticity is about as elastic as a brick and goes near vertical. This creates a situation where miners are always better off when there is a significant backlog (this can be seen in miners revenue from tx fees anytime there is an ongoing backlog).
Simply put, it would take some very large blocks to have total fees/block exceed total fees/block for constrained size blocks given the near vertical price elasticity users face when there is a backlog.

So I suspect that the multi-unit Vickrey would potentially do some to help this, but likely not much:
Users willingness to pay is what they pay---no surplus. Miner elasticity is more or less flat but we can call their willingness to accept whatever the lowest fee tx is in a block. Say it is 180 sat/b (NL), and the highest tx fee in a block (NH)is 320 sat/b. If you subtract each tx in the block (N) greater than NL
and sum the result you get surplus to miners:  ?(N1,2...- NL)
So, yes, the multi-unit Vickrey simply shifts the surplus to users. However, a case could be made that since---as mentioned in an earlier reply, the optimal strategy for miners is to accept zero fees (given their flat elasticity), and therefore all fees are surplus benefit to miners---shifting this surplus over to consumers could create some good effects. Primarily pushing users' price elasticity away from near vertical inelasticity as it would take some of the upward pressure off rapidly increasing fees in a backlog scenario.
It would be interesting to see a simulation of how this would play out, but without that this is too risky to implement.

Regards,
Ryan J. Martin (tunafizz / ohituna)


________________________________
From: bitcoin-dev-bounces at lists.linuxfoundation.org [bitcoin-dev-bounces at lists.linuxfoundation.org] on behalf of William Morriss via bitcoin-dev [bitcoin-dev at lists.linuxfoundation.org]
Sent: Wednesday, November 29, 2017 7:47 PM
To: bitcoin-dev at lists.linuxfoundation.org
Subject: [bitcoin-dev] BIP Idea: Marginal Pricing

Comrades,

Long term, tx fees must support hash power by themselves. The following is an economic approach to maximize total fee collection, and therefore hashpower.

Goals
Maximize total transaction fees
Reduce pending transaction time
Reduce individual transaction fees

Challenges
Validators must agree on the maximum block size, else miners can cheat and include extra transactions.
Allowing too many transactions per block will increase the cost of the mining without collecting much income for the network.

Problem
In the transaction market, users are the demand curve, because they will transact less when fees are higher, and prefer altcoins. The block size is the supply curve, because it represents miners' willingness to accept transactions.
Currently, the supply curve is inelastic:
[cid:ii_jalpxsnl1_1600a3d9def1eaff]
?Increasing the block size will not affect the inelasticity for any fixed block size. The downsides of a fixed block size limit are well-known:
- Unpredictable transaction settlement time
- Variable transaction fees depending on network congestion
- Frequent overpay

Proposal
1. Miners implicitly choose the market sat/byte rate with the cheapest-fee transaction included in their block. Excess transaction fees are refunded to the inputs.
2. Remove the block size limit, which is no longer necessary.

Benefits
- Dynamic block size limit regulated by profit motive
- Transaction fees maximized for every block
- No overpay; all fees are fair
[cid:ii_jalqir4g2_1600a4c89811347a]
?Miners individually will make decisions to maximize their block-reward profit.
Miners are incentivized to ignore low-fee transactions because they would shave the profits of their other transactions and increase their hash time.
Users and services are free to bid higher transaction fees in order to reach the next block, since their excess bid will be refunded.

The block size limit was added as a spam-prevention measure, but in order for an attacker to spam the network with low-fee transactions, they would have to offset the marginal cost of reducing the price with their own transaction fees. Anti-spam is thus built into the marginal system without the need for an explicit limit.

Rarely, sections of the backlog would become large enough to be profitable. This means every so many blocks, lower-fee transactions would be included en masse after having been ignored long enough. Low-fee transactions thus gain a liveness property not previously enjoyed: low-fee transactions will eventually confirm. Miners targeting these transactions would be at a noteworthy disadvantage because they would be hashing a larger block. I predict that this scheme would result in two markets: a backlog market and a real-time market. Users targeting the backlog market would match the price of the largest backlog section in order to be included in the next backlog block.

Examples

Scenario 1
Sat/byte        Bytes   Reward
400     500000  200000000
300     700000  210000000
200     1000000 200000000
100     1500000 150000000
50      5000000 250000000
20      10000000        200000000
A miner would create a 5MB block and receive 0.25 BTC

Scenario 2
Sat/byte        Bytes   Reward
400     600000  240000000
300     700000  210000000
200     1000000 200000000
100     1800000 180000000
50      4000000 200000000
20      10000000        200000000
A miner would create a 600KB block and receive 0.24 BTC

Thanks,
William Morriss


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171201/d32a6976/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: fixedblocksize.png
Type: image/png
Size: 18199 bytes
Desc: fixedblocksize.png
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171201/d32a6976/attachment-0003.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: fixedblocksize.png
Type: image/png
Size: 18199 bytes
Desc: fixedblocksize.png
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171201/d32a6976/attachment-0004.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: marginal.png
Type: image/png
Size: 21403 bytes
Desc: marginal.png
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171201/d32a6976/attachment-0005.png>

From truthcoin at gmail.com  Fri Dec  1 18:38:16 2017
From: truthcoin at gmail.com (Paul Sztorc)
Date: Fri, 1 Dec 2017 13:38:16 -0500
Subject: [bitcoin-dev] Two Drivechain BIPs
Message-ID: <d3497397-33c3-90c1-1be8-a733736eac0b@gmail.com>

Hello,

First, Drivechain has vaguely escaped vaporware status. If you've ever
thought "I'd like to take a look into Drivechain when there is code",
then now is a pretty good time. (Unfinished items include M1, and M8_V2.)

https://github.com/drivechain-project/bitcoin/tree/mainchainBMM

Also,
Site:? http://www.drivechain.info/
Blank sidechain:
https://github.com/drivechain-project/bitcoin/tree/sidechainBMM

Second, I think drivechain's documentation / BIP-Drafts are tolerably
readable.

Here they are:

1.
https://github.com/drivechain-project/docs/blob/master/bip1-hashrate-escrow.md
2.
https://github.com/drivechain-project/docs/blob/master/bip2-blind-merged-mining.md

cc: Luke, I think they are ready to be assigned formal BIP Numbers.

This is also a request for code review. The most helpful review will
probably take place on GitHub.

Regular review is also welcome. Although, please read our
recently-updated FAQ, at: http://www.drivechain.info/faq .
And also see major earlier discussions:
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-May/014364.html
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-June/014559.html

Have a nice weekend everyone,
Paul



From willtech at live.com.au  Sat Dec  2 03:55:22 2017
From: willtech at live.com.au (Damian Williamson)
Date: Sat, 2 Dec 2017 03:55:22 +0000
Subject: [bitcoin-dev] BIP Idea: Marginal Pricing
In-Reply-To: <CADpM8jr_RrbPXLx6Up8HMW-fv=noFLjy817dfsFdYTg216Pu7w@mail.gmail.com>
References: <CADpM8jr_RrbPXLx6Up8HMW-fv=noFLjy817dfsFdYTg216Pu7w@mail.gmail.com>
Message-ID: <PS2P216MB01795C34139200B8537AF2549D3E0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>

I also am for the idea of removing blocksize limits if it is workable, however, would propose an alternative method for selecting transactions to be included in a block.


Some of the issues discussed in other replies to this thread are valid.


Alternative proposal:

Provide each transaction with a transaction weight, being a function of the fee paid (on a curve), and the time waiting in the pool (also on a curve) out to n days (n=30 ?), the transaction weight serving as the likelihood of a transaction being included in the current block, and then use an uncapped block size. The curve allows that the higher a fee allows a transaction to be much more likely to be included, the highest fee gets 100%, and, transactions at the n days limit get near 100%. Would need protocol enforcement since, as I understand, no miner would mine more transactions than are necessary to meet min blocksize. Other than that it should function fine. Non-urgent transactions pay a lower fee, people choose fees from fee recommendation based on how many days before a tx begins confirmation, all transactions are eventually included in the blockchain.


Regards,

Damian Williamson

________________________________
From: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of William Morriss via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>
Sent: Thursday, 30 November 2017 11:47:43 AM
To: bitcoin-dev at lists.linuxfoundation.org
Subject: [bitcoin-dev] BIP Idea: Marginal Pricing

Comrades,

Long term, tx fees must support hash power by themselves. The following is an economic approach to maximize total fee collection, and therefore hashpower.

Goals
Maximize total transaction fees
Reduce pending transaction time
Reduce individual transaction fees

Challenges
Validators must agree on the maximum block size, else miners can cheat and include extra transactions.
Allowing too many transactions per block will increase the cost of the mining without collecting much income for the network.

Problem
In the transaction market, users are the demand curve, because they will transact less when fees are higher, and prefer altcoins. The block size is the supply curve, because it represents miners' willingness to accept transactions.
Currently, the supply curve is inelastic:
[cid:ii_jalpxsnl1_1600a3d9def1eaff]
?Increasing the block size will not affect the inelasticity for any fixed block size. The downsides of a fixed block size limit are well-known:
- Unpredictable transaction settlement time
- Variable transaction fees depending on network congestion
- Frequent overpay

Proposal
1. Miners implicitly choose the market sat/byte rate with the cheapest-fee transaction included in their block. Excess transaction fees are refunded to the inputs.
2. Remove the block size limit, which is no longer necessary.

Benefits
- Dynamic block size limit regulated by profit motive
- Transaction fees maximized for every block
- No overpay; all fees are fair
[cid:ii_jalqir4g2_1600a4c89811347a]
?Miners individually will make decisions to maximize their block-reward profit.
Miners are incentivized to ignore low-fee transactions because they would shave the profits of their other transactions and increase their hash time.
Users and services are free to bid higher transaction fees in order to reach the next block, since their excess bid will be refunded.

The block size limit was added as a spam-prevention measure, but in order for an attacker to spam the network with low-fee transactions, they would have to offset the marginal cost of reducing the price with their own transaction fees. Anti-spam is thus built into the marginal system without the need for an explicit limit.

Rarely, sections of the backlog would become large enough to be profitable. This means every so many blocks, lower-fee transactions would be included en masse after having been ignored long enough. Low-fee transactions thus gain a liveness property not previously enjoyed: low-fee transactions will eventually confirm. Miners targeting these transactions would be at a noteworthy disadvantage because they would be hashing a larger block. I predict that this scheme would result in two markets: a backlog market and a real-time market. Users targeting the backlog market would match the price of the largest backlog section in order to be included in the next backlog block.

Examples

Scenario 1
Sat/byte        Bytes   Reward
400     500000  200000000
300     700000  210000000
200     1000000 200000000
100     1500000 150000000
50      5000000 250000000
20      10000000        200000000
A miner would create a 5MB block and receive 0.25 BTC

Scenario 2
Sat/byte        Bytes   Reward
400     600000  240000000
300     700000  210000000
200     1000000 200000000
100     1800000 180000000
50      4000000 200000000
20      10000000        200000000
A miner would create a 600KB block and receive 0.24 BTC

Thanks,
William Morriss
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171202/4d3b164f/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: fixedblocksize.png
Type: image/png
Size: 18199 bytes
Desc: fixedblocksize.png
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171202/4d3b164f/attachment-0003.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: fixedblocksize.png
Type: image/png
Size: 18199 bytes
Desc: fixedblocksize.png
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171202/4d3b164f/attachment-0004.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: marginal.png
Type: image/png
Size: 21403 bytes
Desc: marginal.png
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171202/4d3b164f/attachment-0005.png>

From cannon at cannon-ciota.info  Fri Dec  1 04:12:24 2017
From: cannon at cannon-ciota.info (CANNON)
Date: Fri, 1 Dec 2017 04:12:24 +0000
Subject: [bitcoin-dev] A DNS-like decentralized mapping for wallet
 addresses?
In-Reply-To: <CAHneDF3qH9OUxqLthY6hEzzFr21QJFLV5wOP8jw+p5eOtpb2oQ@mail.gmail.com>
References: <CAHneDF3qH9OUxqLthY6hEzzFr21QJFLV5wOP8jw+p5eOtpb2oQ@mail.gmail.com>
Message-ID: <88db7e18-e290-a81a-7f71-a9a66e564464@cannon-ciota.info>

On 11/30/2017 10:20 PM, mandar mulherkar via bitcoin-dev wrote:
> Hello,
> 
> I am new, so apologies if this has been asked before.
> 
> Here are a few questions to start with -
> 
> I was wondering in terms of mass adoption, instead of long wallet
> addresses, maybe there should be a DNS-like decentralized mapping service
> to provide a user at crypto address?

Check out namecoin, there is also blockstack as someone mentioned, but I personally feel namecoin is technologically better.

If do not want a static bitcoin address mapped to a username, could use a stealth address (we need more
support for stealth addresses in bitcoin wallets).

From cannon at cannon-ciota.info  Fri Dec  1 04:17:37 2017
From: cannon at cannon-ciota.info (CANNON)
Date: Fri, 1 Dec 2017 04:17:37 +0000
Subject: [bitcoin-dev] A DNS-like decentralized mapping for wallet
 addresses?
In-Reply-To: <CAGCathwjmj_f0TWZF=BhdCq=dSZ_R53Frd3A9b2SgFtus-AH=g@mail.gmail.com>
References: <CAHneDF3qH9OUxqLthY6hEzzFr21QJFLV5wOP8jw+p5eOtpb2oQ@mail.gmail.com>
	<CAGCathwjmj_f0TWZF=BhdCq=dSZ_R53Frd3A9b2SgFtus-AH=g@mail.gmail.com>
Message-ID: <143c8bc4-77a7-a097-fbc1-75a1210e60ca@cannon-ciota.info>

On 12/01/2017 03:15 AM, Lucas Clemente Vella via bitcoin-dev wrote:
> Unfortunately it didn't catch, but it would

Interesting, I just mentioned namecoin literally seconds before this email arrived.
Saying "it did not catch" is not accurate I'd say. It still works great, and namecoin
has actually made great progress this year 2017. I'd say that namecoin has great potential
but just not widely adopted yet.

Would be real nice to have namecion support in major bitcoin wallets for name to data mapping.

From jeremie.dl at gmail.com  Fri Dec  1 08:24:44 2017
From: jeremie.dl at gmail.com (=?UTF-8?B?SsOpcsOpbWllIER1Ym9pcy1MYWNvc3Rl?=)
Date: Fri, 1 Dec 2017 09:24:44 +0100
Subject: [bitcoin-dev] A DNS-like decentralized mapping for wallet
	addresses?
In-Reply-To: <CAGCathwjmj_f0TWZF=BhdCq=dSZ_R53Frd3A9b2SgFtus-AH=g@mail.gmail.com>
References: <CAHneDF3qH9OUxqLthY6hEzzFr21QJFLV5wOP8jw+p5eOtpb2oQ@mail.gmail.com>
	<CAGCathwjmj_f0TWZF=BhdCq=dSZ_R53Frd3A9b2SgFtus-AH=g@mail.gmail.com>
Message-ID: <CAJqsvLAswAOKM-1Yfi57gSxJe07CoKxe=xehDRe26ReJEYvzng@mail.gmail.com>

https://openalias.org/


2017-12-01 4:15 GMT+01:00 Lucas Clemente Vella via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org>:

> The original altcoin, Namecoin, aimed a building a bitcoin-like,
> blockchain based decentralized DNS system. Unfortunately it didn't catch,
> but it would be the most logical choice for the name registry database.
>
> 2017-11-30 20:20 GMT-02:00 mandar mulherkar via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org>:
>
>> Hello,
>>
>> I am new, so apologies if this has been asked before.
>>
>> Here are a few questions to start with -
>>
>> I was wondering in terms of mass adoption, instead of long wallet
>> addresses, maybe there should be a DNS-like decentralized mapping service
>> to provide a user at crypto address?
>>
>> This address translation can happen with confirmations from the network.
>> So instead of providing a long string, or a QR code that needs an app, you
>> simply type in a human readable address, and the wallet software converts
>> it to a wallet address.
>>
>> Please let me know where I can research this more - if there already is
>> literature about this somewhere.
>>
>> thanks!
>>
>>
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
>>
>
>
> --
> Lucas Clemente Vella
> lvella at gmail.com
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171201/d3907753/attachment.html>

From antanst at antanst.com  Fri Dec  1 11:07:14 2017
From: antanst at antanst.com (Antonis Anastasiadis)
Date: Fri, 1 Dec 2017 13:07:14 +0200
Subject: [bitcoin-dev] A DNS-like decentralized mapping for wallet
 addresses?
In-Reply-To: <CAHneDF3qH9OUxqLthY6hEzzFr21QJFLV5wOP8jw+p5eOtpb2oQ@mail.gmail.com>
References: <CAHneDF3qH9OUxqLthY6hEzzFr21QJFLV5wOP8jw+p5eOtpb2oQ@mail.gmail.com>
Message-ID: <946e99ed-0b02-75bf-1c5f-00bb4c451f2c@antanst.com>

Also check the Open Alias project. It's based on DNS+DNSSEC but it
offers the usability feature you mention (nice addresses).

https://openalias.org/

On 01/12/2017 00:20, mandar mulherkar via bitcoin-dev wrote:
> Hello,?
>
> I am new, so apologies if this has been asked before.
>
> Here are a few questions to start with -?
>
> I was wondering in terms of mass adoption, instead of long wallet
> addresses, maybe there should be a DNS-like decentralized mapping
> service to provide a user at crypto address?
>
> This address translation can happen with confirmations from the
> network. So instead of providing a long string, or a QR code that
> needs an app, you simply type in a human readable address, and the
> wallet software converts it to a wallet address.
>
> Please let me know where I can research this more - if there already
> is literature about this somewhere.
>
> thanks!
>
>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171201/bac2e69b/attachment.html>

From lf-lists at mattcorallo.com  Sun Dec  3 21:32:15 2017
From: lf-lists at mattcorallo.com (Matt Corallo)
Date: Sun, 3 Dec 2017 16:32:15 -0500
Subject: [bitcoin-dev] Two Drivechain BIPs
In-Reply-To: <d3497397-33c3-90c1-1be8-a733736eac0b@gmail.com>
References: <d3497397-33c3-90c1-1be8-a733736eac0b@gmail.com>
Message-ID: <1bb6cccd-3f6d-d62a-2825-4e6f46a4b525@mattcorallo.com>

Process note: It looks like the BIPs have never been posted to
bitcoin-dev, only high-level discussion around the idea. As I understand
it, this is *not* sufficient for BIP number assignment nor
(realistically) sufficient to call it a hard "proposal" for a change to
consensus rules.

Would love to get feedback from some others who are looking at deploying
real-world sidechains, eg the RSK folks. We can't end up with *two*
protocols for sidechains in Bitcoin.

Comments on BIP 1:

At a high level, I'm rather dissapointed by the amount of data that is
going into the main chain here. Things such as a human readable name
have no place in the chain, IMO. Further, the use of a well-known
private key seems misplaced, why not just track the sidechain balance
with something that looks like `OP_NOPX genesis_block_hash`?

I'm not convinced by the full semantics of proposal/ack of new
sidechains. Given the lack of convincing evidence of that "Risk of
centralisation of mining" drawback in section 4.3 of the sidechains
paper has been meaningfully addressed, I'd say its pretty important that
new sidechains be an incredibly rare event. Thus, a much simpler system
(eg a version-bits-based upgrade cycle with high threshold) could be
used to add new sidechains based on well-known public parameters.

The semantics of the deposit process seem very suboptimal. You note that
only one user can deposit at a time, but this seems entirely
unnecessary. As implemented in the first Elements Alpha release (though
I believe subsequently removed in later versions due to the nature of
Elements of targeting asymmetric "federated" sidechains), if you have
outputs that look like `OP_NOPX genesis_block_hash` as the sidechain
deposit/storage address, deposit can be fully parallel. To reduce
blockchain bloat, spending them for the purpose of combining such
outputs is also allowed. You could even go further and allow some new
sighash type to define something like SIGHASH_ALL|SIGHASH_ANYONECANPAY
which further specifies some semantics for combining inputs which all
pay into the same output.

Finally, you may also want to explore some process for the removal of
sidechain balances from the main chain. As proposed it seems like a
sidechain might, over time, fade into an insecure state as mining power
shifts and new miners no longer consider it worth the value to mine an
old sidechain (as has happened over time with namecoin, arguably).


Comments on BIP 2:

I may be missing something, but I find the security model here kind of
depressing...Not only do hashpower-secured sidechains already have a
significantly reduced security level, but now you're proposing to
further (drastically) reduce it by requiring users to potentially pay in
excess of the value an attacker is willing to pay to keep their chain
secure, on a recurring basis? It seems like if a chain has 10 BTC stored
in it, and I wish to reorg it for a potential gain of, lets say, 6 BTC,
I can pay 6 * 1 BTC (1 per block) to reorg it, and users on the chain
would be forced to pay >6 BTC to avoid this?

While I appreciate the desire to implement the proposed mitigation in
section 4.3 of the sidechains paper (delegating the mining effort of a
merge-mined sidechain to an external entity), I believe it was primarily
referencing pooling the sidechain work, not blindly taking the highest
bidder. I suppose, indeed, that, ultimately, as long as the sidechain is
of relatively small value in comparison to BTC, miners do not risk the
value of their BTC/mining investment in simply taking the highest bidder
of a merge-mined block, even if its a clear attack, but I don't think
thats something to be celebrated, encouraged, or designed to be possible
by default. Instead, I'd, in line with Peter Todd's (and others')
objection to merged mining generally, call this one of the most critical
issues with the security model.

Ultimately, I dont believe your proposal here really solves the drawback
in section 4.3 of the paper, and possibly makes it worse. Instead, it
may be more useful to rely on a high threshold for the addition of new
sidechains, though I'd love to see discussion on this point specifically
on this list. Further, I'd say, at a minimum, a very stable
default-available low-bandwidth implementation of at least the
pool-based mitigation suggested in the paper must exist for something
like this to be considered readily stable enough to be deployed into the
Bitcoin ecosystem.

Matt

On 12/01/17 13:38, Paul Sztorc via bitcoin-dev wrote:
> Hello,
> 
> First, Drivechain has vaguely escaped vaporware status. If you've ever
> thought "I'd like to take a look into Drivechain when there is code",
> then now is a pretty good time. (Unfinished items include M1, and M8_V2.)
> 
> https://github.com/drivechain-project/bitcoin/tree/mainchainBMM
> 
> Also,
> Site:? http://www.drivechain.info/
> Blank sidechain:
> https://github.com/drivechain-project/bitcoin/tree/sidechainBMM
> 
> Second, I think drivechain's documentation / BIP-Drafts are tolerably
> readable.
> 
> Here they are:
> 
> 1.
> https://github.com/drivechain-project/docs/blob/master/bip1-hashrate-escrow.md
> 2.
> https://github.com/drivechain-project/docs/blob/master/bip2-blind-merged-mining.md
> 
> cc: Luke, I think they are ready to be assigned formal BIP Numbers.
> 
> This is also a request for code review. The most helpful review will
> probably take place on GitHub.
> 
> Regular review is also welcome. Although, please read our
> recently-updated FAQ, at: http://www.drivechain.info/faq .
> And also see major earlier discussions:
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-May/014364.html
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-June/014559.html
> 
> Have a nice weekend everyone,
> Paul
> 
> 
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> 

From apoelstra at wpsoftware.net  Mon Dec  4 17:17:11 2017
From: apoelstra at wpsoftware.net (Andrew Poelstra)
Date: Mon, 4 Dec 2017 17:17:11 +0000
Subject: [bitcoin-dev] Updates on Confidential Transactions efficiency
In-Reply-To: <CAAS2fgQ0Cb2B=Ye2TnpfQqP4=kpZCxMWRXYB0CcFa71sQJaGuw@mail.gmail.com>
References: <CAAS2fgQ0Cb2B=Ye2TnpfQqP4=kpZCxMWRXYB0CcFa71sQJaGuw@mail.gmail.com>
Message-ID: <20171204171711.GX20660@boulet>

To follow up on the remarkable work Greg announced from Benedikt B?nz (Stanford)
and Jonathan Bootle (UCL) on Bulletproofs: https://eprint.iacr.org/2017/1066

Summary
=========

Over the last couple weeks, along with Jonas Nick, Pieter Wuille, Greg Maxwell
and Peter Dettmann, I've implemented the single-output version of Bulletproofs
at https://github.com/ElementsProject/secp256k1-zkp/pull/16 and have some
performance numbers.

All of these benchmarks were performed on one core of an Intel i7-6820MQ
throttled to 2.00Ghz, and reflect verification of a single 64-bit rangeproof.


Old Rangeproof    14.592 ms
     with endo    10.304 ms
Bulletproof        4.208 ms
     with endo     4.031 ms
ECDSA verify       0.117 ms
     with endo     0.084 ms


Here "with endo" refers to use of the GLV endomorphism supported by the curve
secp256k1, which libsecp256k1 (and therefore Bitcoin) supports but does not
enable by default, out of an abundance of caution regarding potential patents.

As we can see, without the endomorphism this reflects a 3.47x speedup over
the verification speed of the old rangeproofs. Because Bulletproof verification
scales with O(N/log(N)) while the old rangeproof scales with O(N), we can
extrapolate forward to say that a 2-output aggregate would verify with 4.10x
the speed of the old rangeproofs.

By the way, even without aggregation, we can verify two rangeproofs nearly 15%
faster than verifying one twice (so a 3.95x speedup) because the nature of the
verification equation makes it amenable to batch verification. This number
improves with the more proofs that you're verifying simultaneously (assuming
you have enough RAM), such that for example you can batch-verify 10000
bulletproofs 9.9 times as fast as you could verify 10000 of the old proofs.


While this is a remarkable speedup which greatly improves the feasibility of
CT for Bitcoin (though still not to the point where I'd expect a serious
proposal to get anywhere, IMHO), the concerns highlighted by Greg regarding
unconditional versus computational soundness remain. I won't expand on that
more than it has already been discussed in this thread, I just want to tamp
down any irrational exhuberance about these result.


People who only care about numbers can stop reading here. What follows is a
discussion about how this speedup is possible and why we weren't initially
sure that we'd get any speedup at all.


Details
=========

Section 6 of the linked preprint discusses performance vs our old rangeproofs. As
Greg mentioned, it is possible to fit two 64-bit bulletproofs into 738 bytes,
with logarithmic scaling. (So one proof would take 674 bytes, but eight proofs
only 866 bytes.)

However, this section does not give performance numbers, because at the time
the preprint was written, there was no optimized implementation on which to
benchmark. It was known that verification time would be roughly linear in the
size of the proof: 141 scalar-multiplies for a 64-bit proof, 270 for an
aggregate of two proofs, and so on [*]. Our old rangeproofs required only 128
multiplies for a 64-bit proof, then 256 for two, and so on. So naively we were
concerned that the new Bulletproofs, despite being fantastically smaller than
the original rangeproofs, might wind up taking a bit longer to verify.

For reference, an ordinary ECDSA signature verification involves 2 multiplies.
So roughly speaking, the naive expectation was that a N-bit rangeproof would
require N-many signature verifications' worth of CPU time, even with this new
research. Worse, we initially expected bulletproofs to require 1.5x this much,
which we avoided with a trick that I'll describe at the end of this mail.

As you can see in the above numbers, the old rangeproofs actually perform worse
than this expectation, while the new Bulletproofs perform significantly **better**.
These are for the same reason: when performing a series of scalar multiplications
of the form

  a*G + b*H + c*I + ...

where G, H, I are curvepoints and a, b, c are scalars, it is possible to compute
this sum much more quickly than simply computing a*G, b*H, c*I separately and
then adding the results. Signature validation takes advantage of this speedup,
using a technique called Strauss' algorithm, to compute the sum of two multiplies
much faster than twice the multiple-speed. Similarly, as we have learned, the
141 scalar-multiplies in a single-output Bulletproof can also be done in a single
sum. To contrast, the old rangeproofs required we do each multiplication separately,
as the result of one would be hashed to determine the multiplier for the next.

libsecp256k1 has supported Strauss' algorithm for two points since its inception
in 2013, since this was needed for ECDSA verification. Extending it to many points
was a nontrivial task which Pieter, Greg and Jonas Nick took on this year as part
of our aggregate signatures project. Of the algorithms that we tested, we found
that Strauss was fastest up to about 100 points, at which point Pippenger's was
fastest. You can see our initial benchmarks here

https://user-images.githubusercontent.com/2582071/32731185-12c0f108-c881-11e7-83c7-c2432b5fadf5.png

though this does not reflect some optimizations from Peter Dettmann in the last
week.


It was a happy coincidence that the Bulletproofs paper was published at nearly
the same time that we had working multi-point code to test with.


Finally, the Bulletproof verification process, as written in the paper, is a
recursive process which does not appear to be expressible as a single multiproduct,
and in fact it appears to require nearly twice as many multiplications as I claim
above. I want to draw attention to two optimizations in particular which made this
possible.

1. By expanding out the recursive process, one can see that the inner-product argument
   (Protocol 1 in the paper) is actually one multiproduct: you hash each (L_i, R_i)
   pair to obtain logarithmically many scalars, invert these, and then each scalar in
   the final multiproduct is a product containing either the inverse or original of
   each scalar.

   Peter Dettmann found a way to reduce this to one scalar inversion, from which
   every single scalar was obtainable from a single multiplication or squaring of a
   previous result. I was able to implement this in a way that cached only log-many
   previous results.

2. Next, line (62) of the Bulletproofs paper appears to require N multiplications
   beyond the 2N multiplications already done in the recursive step. But since
   these multiplications used the same basepoints that were used in the recursive
   step, we could use the distributive property to combine them. This sounds
   trivial but took a fair bit of care to ensure that all the right data was still
   committed to at the right stage of proof verification.



Further Work
=========

There are still a few open issues I plan to help resolve in the coming month:

  - Bulletproof aggregation is not compatible with Confidential Assets, where each
    output has a unique asset tag associated with it. There are a couple possible
    solutions to this but nothing public-ready.

  - Bulletproofs, as described in the paper, work only when proving 2^n-many bits.
    I believe there is a straightforward and verifier-efficient way to extend it
    to support non-powers-of-2, but this requires some work to modify the proof in
    the paper.

  - Bulletproofs are actually much more general than rangeproofs. They can be used
    to prove results of arbitrary arithmetic circuits, which is something we are
    very interested in implementing.


[*] By "and so on", I mean that N bits require 2N + 2log_2(N) + 6 scalar multiplies.


Cheers
Andrew



-- 
Andrew Poelstra
Mathematics Department, Blockstream
Email: apoelstra at wpsoftware.net
Web:   https://www.wpsoftware.net/andrew

"A goose alone, I suppose, can know the loneliness of geese
 who can never find their peace,
 whether north or south or west or east"
       --Joanna Newsom

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 455 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171204/42dfe0d1/attachment.sig>

From truthcoin at gmail.com  Mon Dec  4 19:05:09 2017
From: truthcoin at gmail.com (Paul Sztorc)
Date: Mon, 4 Dec 2017 14:05:09 -0500
Subject: [bitcoin-dev] Two Drivechain BIPs
In-Reply-To: <1bb6cccd-3f6d-d62a-2825-4e6f46a4b525@mattcorallo.com>
References: <d3497397-33c3-90c1-1be8-a733736eac0b@gmail.com>
	<1bb6cccd-3f6d-d62a-2825-4e6f46a4b525@mattcorallo.com>
Message-ID: <dd2781a6-3e10-9f0c-6ee0-a2c070b7cf67@gmail.com>

Hi Matt,

Thanks for very much for your thoughtful review

Comments below.

On 12/3/2017 4:32 PM, Matt Corallo wrote:
> ...
>
> ...
>
> Comments on BIP 1:
>
> At a high level, I'm rather dissapointed by the amount of data that is
> going into the main chain here. Things such as a human readable name
> have no place in the chain, IMO.

Well, that is quite a minor quibble, because it is just a one-time cost
of 120 bytes per sidechain.

To address it, there could instead be a hash commitment to this
information. That commitment could be "optional", in that old nodes
wouldn't need to possess the 120 bytes. Although, all of the sidechains
are themselves optional. And old nodes will be ignoring all of this data
anyways. So I do not think

The inclusion of this field is deliberate. Probably, you do not buy my
lengthy argument about "categorical control".

http://www.drivechain.info/faq/#categorical-control

Perhaps you have seen my May 2016 presentation on the topic. It was
itself a lengthy reply to comments that Greg Maxwell made about the
original Nov 2015 Drivechain post.

https://www.youtube.com/watch?v=xGu0o8HH10U&list=PLw8-6ARlyVciMH79ZyLOpImsMug3LgNc4&index=1

Either you aren't aware [of why I want each sidechain to have a
comprehensible category]. Or, you are aware and you disagree. But if it
is the latter we might just have to agree to disagree.

> ....???????????????????????????????? Further, the use of a well-known
> private key seems misplaced, why not just track the sidechain balance
> with something that looks like `OP_NOPX genesis_block_hash`?

I agree. I myself am unhappy with the private key approach, as it
results in a totally pointless signature being generated, and a
pointless CheckSig operation. (Somewhere, buried in
documentation/GitHub-issue purgatory, there is a discussion of replacing
it with OP TRUE.)

Basically, our way was just a hack to make sure uses knew where they had
to send the money, and also to get the balances to show up in all user's
wallets. I do not pretend to have any expertise in this area (or even
experience) so it is surely an area for improvement.

>
> I'm not convinced by the full semantics of proposal/ack of new
> sidechains.? ...?????????? I'd say its pretty important that
> new sidechains be an incredibly rare event.

Well, I partially agree.

However, if drivechain is a soft fork, and if 51% hashrate can add new
softforks at any time, then our ability to alter the rate of
sidechain-creation is very low. While we might use the rules of
"Drivechain I" to impose restrictions on the "add a sidechain" process,
nothing prevents 51% hashrate from re-adding Drivechain to Core a second
time, creating a "Drivechain II" system with its own "add a sidechain"
rules. Thus, the activation speed can increase, even if miners are
incapable of writing any code. Or, miners might add "Drivechain I" to
one of the sidechains. (And of course the new-sidechain-rate can
decrease, through mere miner-censorship.)

So, I think there really is no threat model, other than to say: we
either open Pandora's box or we do not. My vision (for any Redditors who
may be reading this, years in the future!!) is of a stable, conservative
Bitcoin Core with 3-8 sidechains, of which at least one is rather
experimental, and at least one of which has its own sidechains. But who
knows.

More importantly, the problem you've outlined is much much worse for
extension blocks.

(It can scarcely be denied that hashrate wants more block space, and
that they can easily add one or many extension blocks, in public or in
secret, at any time. Will a UASF really be able to disable an in-use
extension block? I think the UASF-case is much less persuasive,
especially since it involves loss/freezing of user funds.)

So I would argue that one of *the* greatest benefits of Drivechain is
that it neutralizes the threat of extension blocks by giving everyone a
better alternative. In fact, I do not know of any other way to
neutralize this threat.

>? ... Thus, a much simpler system
> (eg a version-bits-based upgrade cycle with high threshold) could be
> used to add new sidechains based on well-known public parameters.

I don't have a problem with this. In fact that is mostly how we have it
today.

My concern is a scenario where:

Person A: is running the latest version of Bitcoin (which has
drivechain), and full nodes for 3 out of 3 sidechains
Person B: is running the 2nd-latest version of Bitcoin (which has
drivechain), and was disconnected when the 3rd sidechain activated
Person C: is running the 3rd-latest version of Bitcoin (which has
drivechain), but was disconnected for the activation of all sidechains.
Person D: is running 0.5.3 and has no idea what drivechain is.

Then, we consider a case where someone attempts a side-to-main
withdrawal from sidechain #2, but which tries to cheat the drivechain
rules (which are mainchain-enforced).

In one setup, C's security is downgraded. But in other settings it is
not. And in other settings it might do something complicated.

(Although, I also plan to introduce minimum parameter values, both to
prevent C from being harassed in this case, and to force all
drivechain-killing actions to be comparable to each other.)

My thought was to have all drivechain parts to either stand or fall by
themselves. But I am open-minded on this.

> The semantics of the deposit process seem very suboptimal. You note that
> only one user can deposit at a time, but this seems entirely
> unnecessary. As implemented in the first Elements Alpha release (though
> I believe subsequently removed in later versions due to the nature of
> Elements of targeting asymmetric "federated" sidechains), if you have
> outputs that look like `OP_NOPX genesis_block_hash` as the sidechain
> deposit/storage address, deposit can be fully parallel. To reduce
> blockchain bloat, spending them for the purpose of combining such
> outputs is also allowed. ....

Well, your proposal doesn't reduce the bloat, it merely makes
bloat-reduction possible. And your way relies (slightly) on
miner-charity, because it imposes an opportunity cost on miners. (Miners
could sell their blockspace for fees, but instead they must use it to
make these combinations you describe.)

In contrast, the one-user-deposits-at-a-time not only allows bloat to be
addressed, but also forces it to be addressed. It is like forcing
someone who uses a shared kitchen to leave it exactly as clean as they
found it.

While I am concerned by the one-at-a-time concept, I would point out:

* It is NOT one deposit per block. Just one at a time. In general, there
can be as many deposits as needed.
* It will not be a problem if [a] transactions propagate very quickly,
and [b] transactions are signed very quickly.
* If the deposit fails, it will likely be easy for the user to re-do it
(or, this will be made easy, in the UX eventually).
* It may ultimately be the case, that the task of shepherding the coins
around is one that is only ever performed by specialists. They would
have their own ways of batching txns to deal with this issue. In
contrast, regular users might always use atomic swaps / ShapeShift-like
tools.

Nonetheless, I think this is another opportunity for improvement.
Probably, if someone goes deeper into the scripting language and block
validation rules, they will be able to achieve all of the objectives
simultaneously. As you say:

> ...?????????????????????? You could even go further and allow some new
> sighash type to define something like SIGHASH_ALL|SIGHASH_ANYONECANPAY
> which further specifies some semantics for combining inputs which all
> pay into the same output.


> Finally, you may also want to explore some process for the removal of
> sidechain balances from the main chain. As proposed it seems like a
> sidechain might, over time, fade into an insecure state as mining power
> shifts and new miners no longer consider it worth the value to mine an
> old sidechain (as has happened over time with namecoin, arguably).

Yes, I think there should be some kind of switch for saying "please
withdraw all of your funds because this chain is being closed down".
However, if miners stopped mining a chain, I think sidechain-users would
notice because their blocktimes would start to increase (under blind
merged mining, anyway).


> Comments on BIP 2:
>
> I may be missing something, but I find the security model here kind of
> depressing...Not only do hashpower-secured sidechains already have a
> significantly reduced security level, but now you're proposing to
> further (drastically) reduce it by requiring users to potentially pay in
> excess of the value an attacker is willing to pay to keep their chain
> secure, on a recurring basis?

I think you are missing a few things.

First of all, I think the security model for sidechains is the same as
that of every blockchain

People will say things, like "but with sidechains 51% hashrate can steal
your coins!", but as I have repeated many times, this is also true of
mainchain btc-tx. As I say on drivechain.info:

?""" In theory, the incentives of miners and investors are very strongly
aligned: both are compensated most when the exchange rate is highest.
And, in practice, we do not see large reorganizations (where miners can
?steal?, by first depositing BTC to major exchanges, then selling that
BTC for fiat (which they withdraw), and finally rewriting the last 3 or
4 days of chain history, to un-confirm the original deposits). These
reorgs would devastate the exchange rate, as they would cast doubt on
the entire Bitcoin experiment. The thesis of Drivechain is that
sidechain-theft would also devastate the exchange rate, as it would cast
doubt on the entire sidechain experiment (which would itself cast doubt
on the Bitcoin experiment, given the anti-competitive power of
sidechains). """

In fact, it is true of everything, including the lightning network. LN
has the advantage of allowing victims to spend the attacker's funds on
tx fees (as these victims desperately try to get their txn included).
But the LN loses the blockchain's "strength in numbers" advantage --
miners can single-out unpopular individuals, figure out their channels,
and steal from them (and only them) at an inopportune time.

This is not to knock the lightning network -- I believe it is
well-designed and likely to be secure. I am merely saying that this
concept of stringing these security models on a line from "most secure"
to "least secure" is a concept which is reductionist and incorrect.

Drivechain will be more secure if sidechains are popular. But if they
are not popular, the question of how secure they are is not really
interesting, is it?

Secondly, I think you have overlooked something very important indeed.
Sidechains are optional, and so their use should be up to each
individual user, and no one else. Users should be free to make their own
mistakes -- specifically, they should be the ones to decide for
themselves if they want to use an "insecure" system or not.

It would be another matter, if you had a competing sidechain idea which
accomplished the same goal. But you do not.

Thirdly, I do not agree with your claim that the security model is
reduced by BMM. In fact, the way I see it, it is the same as the model
we already have, if not better.

To make this point, let me ask: Who determines the contents (valid or
otherwise) of "the next block that meets the difficulty requirement"?

In Mainchain Bitcoin Core: "Highest Cumulative Difficulty"
BMM Sidechain: "Highest BTC Payment"

But these are actually the very same thing! We merely need to clarify
our thinking with a few simplifications. First, substitute "Most Hashes"
for "Cumulative Difficulty" (as these are expected converge to each
other). Second, ignore *unexpected* fluctuations in the two denominator
prices in the following:

"Most Hashes" = "Most USD Spent on Mining" / (hashes-per-usd price)
"Highest BTC Payment" = "Most USD Spent on Mining" / (btc-per-usd price)

"Most Hashes" = "Highest BTC Payment" = "Most USD Spent on Mining"

It should be clearer now that they are the same model. While the
mainchain follows the heaviest chain, measured in hashes, the sidechain
follows the heaviest chain, measured in BTC. Both are expressions of the
same concept ("value sacrificed")...just expressed in different units.

With that explained, let me bring in this:

>????? ...????????????????? It seems like if a chain has 10 BTC stored
> in it, and I wish to reorg it for a potential gain of, lets say, 6 BTC,
> I can pay 6 * 1 BTC (1 per block) to reorg it, and users on the chain
> would be forced to pay >6 BTC to avoid this?

Your example (which is a great example) sounds bleak, but it is in fact
the security model of Bitcoin itself, in the long future without the
block subsidy. Likely, Bitcoin will have new advantages by then
(assuming it survives that long). But this is a problem that just
*can't* be solved without a new block subsidy (which can't be added to
sidechains).

So, you may be successfully arguing that sidechains can never work. (But
that is different from saying that users should be prohibited from
trying them out, as I said above). Or, you may be successfully arguing
that Bitcoin itself will stop working when fees overwhelm the block
subsidy. (Since that hour is rapidly approaching, we might as well start
running experiments now).

The equivalence between hashes and purchases is not perfect. Certainly,
regular miners might be better-behaved than BM-miners, because r-miners
stand to lose their entire hardware investment if the system fails,
whereas BM-miners do not. On the other hand, BMM is *better* in a few
ways, namely that it makes "mining" much more competitive, because it
lowers the barriers to entry for sidechain-mining all the way to zero.
Any node can do it. Furthermore, BM-miners are more cypherpunk-like:
they will not be confined to any physical location, they do not give
away their location (via power usage or thermal exhaust), when they
greedily move into high-efficiency spaces (data centers, EC2 instances)
they can instantly destroy themselves and reappear somewhere else.

I'm not sure if that made you more, or less depressed. But here is a
smiley face :-] .

> While I appreciate the desire to implement the proposed mitigation in
> section 4.3 of the sidechains paper (delegating the mining effort of a
> merge-mined sidechain to an external entity), I believe it was primarily
> referencing pooling the sidechain work, not blindly taking the highest
> bidder.

Well, BMM is more efficient when there are pools. Without them, the
sidechain nodes would be trying to connect to all mainchain miners.

And there's no need for that. In my view, pools are cannot really do
anything wrong (ie, pools cannot do anything except what their members
want them to do). If a pool operator goes rogue and attempts to censor a
transaction, what has actually happened is just that the transaction is
delayed (until the hashers learn about the inefficient policy, and
switch pools). Same for everything else.

In other words, yes pool operators would almost certainly be running a
node of each sidechain.

>? ...? I suppose, indeed, that, ultimately, as long as the sidechain is
> of relatively small value in comparison to BTC, miners do not risk the
> value of their BTC/mining investment in simply taking the highest bidder
> of a merge-mined block, even if its a clear attack, ...

It is not about the amount of BTC on the sidechain. It is about miner's
estimations of user's valuation of their option to use the sidechain at
any point in the future. The idea of "911 emergency response" is
valuable, and people would complain about a motion to get rid of it,
even though most of those people wouldn't currently be using it.

> Ultimately, I dont believe your proposal here really solves the drawback
> in section 4.3 of the paper, and possibly makes it worse.

That is interesting because that section reads:

?""" As miners provide work for more blockchains, more resources are
needed to track and validate them all. Miners that provide work for a
subset of blockchains are compensated less than those which provide work
for every possible blockchain. Smaller-scale miners may be unable to
afford the full costs to mine every blockchain, and could thus be put at
a disadvantage compared to larger, established miners who are able to
claim greater compensation from a larger set of blockchains. """

?Which is exactly what BMM does address. It allows miners to ignore the
resource-cost of the sidechain, and therefore smaller miners will not be
at a revenue-disadvantage.

Do you think that the drawback is something else?

And, are you ever going to define "miner centralization"? Is it "the
economic barrier-to-entry for mining", to you?

Paul

>
> On 12/01/17 13:38, Paul Sztorc via bitcoin-dev wrote:
>> Hello,
>>
>> First, Drivechain has vaguely escaped vaporware status. If you've ever
>> thought "I'd like to take a look into Drivechain when there is code",
>> then now is a pretty good time. (Unfinished items include M1, and M8_V2.)
>>
>> https://github.com/drivechain-project/bitcoin/tree/mainchainBMM
>>
>> Also,
>> Site:? http://www.drivechain.info/
>> Blank sidechain:
>> https://github.com/drivechain-project/bitcoin/tree/sidechainBMM
>>
>> Second, I think drivechain's documentation / BIP-Drafts are tolerably
>> readable.
>>
>> Here they are:
>>
>> 1.
>>
https://github.com/drivechain-project/docs/blob/master/bip1-hashrate-escrow.md
>> 2.
>>
https://github.com/drivechain-project/docs/blob/master/bip2-blind-merged-mining.md
>>
>> cc: Luke, I think they are ready to be assigned formal BIP Numbers.
>>
>> This is also a request for code review. The most helpful review will
>> probably take place on GitHub.
>>
>> Regular review is also welcome. Although, please read our
>> recently-updated FAQ, at: http://www.drivechain.info/faq .
>> And also see major earlier discussions:
>>
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-May/014364.html
>>
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-June/014559.html
>>
>> Have a nice weekend everyone,
>> Paul
>>
>>
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>



From ctpacia at gmail.com  Mon Dec  4 19:36:31 2017
From: ctpacia at gmail.com (Chris Pacia)
Date: Mon, 4 Dec 2017 14:36:31 -0500
Subject: [bitcoin-dev] Two Drivechain BIPs
In-Reply-To: <dd2781a6-3e10-9f0c-6ee0-a2c070b7cf67@gmail.com>
References: <d3497397-33c3-90c1-1be8-a733736eac0b@gmail.com>
	<1bb6cccd-3f6d-d62a-2825-4e6f46a4b525@mattcorallo.com>
	<dd2781a6-3e10-9f0c-6ee0-a2c070b7cf67@gmail.com>
Message-ID: <CAB+qUq4wNv=-ZSibUvVCwYSE7Qw8xe8EH91KG6znUp1d7X=mdA@mail.gmail.com>

I think you are missing a few things.

First of all, I think the security model for sidechains is the same as
that of every blockchain

People will say things, like "but with sidechains 51% hashrate can steal
your coins!", but as I have repeated many times, this is also true of
mainchain btc-tx.  is something else?


There are substantial opportunity costs as well as a collective action
problem when it comes to re-writing the mainchain.

Is there anything similar for drivechains? As far as I can tell there is no
opportunity cost to casting a malicious vote, no repercussions, and no
collective action barrier that needs to be overcome.

Unless I'm missing something I wouldn't liken the security of a drivechain
to that of the mainchain.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171204/2f0566b4/attachment.html>

From luke at dashjr.org  Tue Dec  5 07:41:59 2017
From: luke at dashjr.org (Luke Dashjr)
Date: Tue, 5 Dec 2017 07:41:59 +0000
Subject: [bitcoin-dev] Two Drivechain BIPs
In-Reply-To: <1bb6cccd-3f6d-d62a-2825-4e6f46a4b525@mattcorallo.com>
References: <d3497397-33c3-90c1-1be8-a733736eac0b@gmail.com>
	<1bb6cccd-3f6d-d62a-2825-4e6f46a4b525@mattcorallo.com>
Message-ID: <201712050742.00854.luke@dashjr.org>

On Sunday 03 December 2017 9:32:15 PM Matt Corallo wrote:
> Given the lack of convincing evidence of that "Risk of centralisation of
> mining" drawback in section 4.3 of the sidechains paper has been
> meaningfully addressed, I'd say its pretty important that new sidechains be
> an incredibly rare event.

This is impossible to guarantee. Federated sidechains are already possible 
with simple multisig (and they could very well be merge-mined chains instead 
of simply signed). At the same time, the value of permissionless sidechain 
innovation is potentially huge.

Luke

From pete at petertodd.org  Tue Dec  5 10:15:51 2017
From: pete at petertodd.org (Peter Todd)
Date: Tue, 5 Dec 2017 05:15:51 -0500
Subject: [bitcoin-dev] Scalable Semi-Trustless Asset Transfer via
 Single-Use-Seals and Proof-of-Publication
Message-ID: <20171205101551.GA10265@fedora-23-dvm>

I recently wrote this up for a client, and although the material has been
covered elsewhere, I thought being a worked example it might be of interest,
particularly while sidechains are being discussed again.

As per (1) I've perhaps foolishly committed to making an even more fleshed out
example, so peer review here before it gets to an even wider audience would be
appreciated. :)

1) https://twitter.com/petertoddbtc/status/937401676042039296


tl;dr: We can do trustless with respect to validity, trusted with respect to
censorship resistance, indivisible asset transfer with less than 5MB/year/token
of proof data, assuming token ownership is updated every two hours, at a rate
of ~500,000 transfers per second. The scalability of this scheme is linear with
respect to update interval, and logarithmic with respect to overall transfer
rate.


## Single-Use-Seal Definition

Analogous to the real-world, physical, single-use-seals used to secure shipping
containers, a single-use-seal primitive is a unique object that can be closed
over a message exactly once. In short, a single-use-seal is an abstract
mechanism to prevent double-spends.

A single-use-seal implementation supports two fundamental operations:

    Close(l,m) -> w_l
        Close seal l over message m, producing a witness w_l

    Verify(l,w_l,m) -> bool
        Verify that the seal l was closed over message m

A single-use-seal implementation is secure if it is impossible for an attacker
to cause the Verify function to return true for two distinct messages m_1, m_2,
when applied to the same seal (it _is_ acceptable, although non-ideal, for
there to exist multiple witnesses for the same seal/message pair).

Practical single-use-seal implementations will also obviously require some way
of generating new single-use-seals. Secondly, authentication is generally
useful. Thus we have:

    Gen(p) -> l
        Generate a new seal bound to pubkey p

    Close(l,m,s) -> w_l
        Close seal l over message m, authenticated by signature s valid for pubkey p

Obviously, in the above, pubkey can be replaced by any cryptographic identity
scheme, such as a Bitcoin-style predicate script, zero-knowledge proof, etc.

Finally, _some_ single-use-seal implementations may support the ability to
prove that a seal is _open_, e.g. as of a given block height or point in time.
This however is optional, and as it can be difficult to implement, it is
suggested that seal-using protocols avoid depending on this functionality
existing.


## Indivisible Token Transfer

With a secure single-use-seal primitive we can build a indivisible token
transfer system, allowing the secure transfer of a token from one party to
another, with the seals preventing double-spends of that indivisible token.

Each token is identified by its genesis seal l_0. To transfer a token, the most
recent seal l_n is closed over a message committing to a new seal, l_{n+1},
producing a witness w_{l_n} attesting to that transfer. This allows a recipient
to securely verify that they have received the desired token as follows:

1. Generate a fresh, open, seal l_{n+1} that only they can close.
2. Ask the sender to close their seal, l_n, over the seal l_{n+1}
3. Verify that there exist a set of valid witnesses w_0 .. w_n, and seals
   l_0 .. l_n, such that for each seal l_i in i = 0 .. n, Verify(l_i, w_i, l_{i+1})
   returns true.

Since a secure single-use-seal protocol prohibits the closure of a single seal
over multiple messages, the above protocol ensures that the token can not be
double-spent. Secondly, by ensuring that seal l_{n+1} can be closed by the
recipient and only the recipient, the receipient of the token knows that they
and they alone have the ability to send that token to the next owner.


## Divisible Asset Transfer

In the case of a divisible asset, rather than transferring a single, unique,
token we want to transfer a _quantity_ of an asset. We can accomplish this in a
manner similar how Bitcoin's UTXO-based transactions, in which one or more
inputs are combined in a single transaction, then split amongst zero or more
outputs.

We define the concept of an _output_. Each output x is associated with a seal l
and value v. For each asset we define a set of _genesis outputs_, X_G, whose
validity is assumed.

To transfer divisible assets we further define the concepts of a _spend_ and a
_split_. A spend, D, is a commitment to a set of outputs x_i .. x_j; the value
of a spend is simply the sum of the values of all outputs in the spend. A split
commitments to a set of zero or seal/value, (l_i,v_i), tuples, with the sum
value of the split being the sum of a values in the split.

Spends and splits are used to define a _split output_. While a genesis output
is simply assumed valid, a split output x is then the tuple (D,V,i), committing
to a spend D, split V, and within that split, a particular output i.

A split output is valid if:

1. Each output in the spend set D is a valid output.
2. The sum value of the spend set D is >= the sum value of the split V.
3. i corresponds to a valid output in the split.
4. There exists a set of witnesses w_i .. w_j, such that each seal in the spend
   set closed over the message (D,V) (the spend and split).

As with the indivisible asset transfer, a recipient can verify that an asset
has been securely transferred to them by generating a fresh seal, asking the
sender to create a new split output for that seal and requested output amount,
and verifying that the newly created split output is in fact valid. As with
Bitcoin transactions, in most transfers will also result in a change output.

Note how an actual implementation can usefully use a merkle-sum-tree to commit
to the split set, allowing outputs to be proven to the recipient by giving only
a single branch of the tree, with other outputs pruned. This can have both
efficiency and privacy advantages.



## Single-Use-Seal Implementation

An obvious single-use-seal implementation is to simply have a trusted notary,
with each seal committing to that notary's identity, and witnesses being
cryptographic signatures produced by that notary. A further obvious refinement
is to use disposable keys, with a unique private key being generated by the
notary for each seal, and the private key being securely destroyed when the
seal is closed.

Secondly Bitcoin (or similar) transaction outputs can implement
single-use-seals, with each seal being uniquely identified by outpoint
(txid:n), and witnesses being transactions spending that outpoint in a
specified way (e.g. the first output being an OP_RETURN committing to the
message).


### Proof-of-Publication Ledger

For a scalable, trust-minimized, single-use-seal implementation we can use a
proof-of-publication ledger, where consensus over the state of the ledger is
achieved with a second single-use-seal implementation (e.g. Bitcoin).

Such a ledger is associated with a genesis seal, L_0, with each entry M_i in
the ledger being committed by closing the most recent seal over that entry,
producing W_i such that Verify(L_i, (L_{i+1}, M_i), W_i) returns true.
Thus we achieve consensus over the state of the ledger as we can prove the
contents of the ledger.

Specifically, given starting point L_i we can prove that the subsequent ledger
entries M_i .. M_j are valid with witnesses W_i .. W_j and seals L_{i+1} .. L_{j+1}.

A proof-of-publication-based seal can then be constructed via the tuple (L_i,
p), where L_i is one of the ledger's seals, and p is a pubkey (or similar). To
close a proof-of-publication ledger seal a valid signature for that pubkey and
message m is published in the ledger in entry M_j.

Thus the seal witness is proof that:

1. Entry M_j contained a valid signature by pubkey p, for message m.
2. All prior entries M_i .. M_{j-1} (possibly an empty set) did _not_ contain
   valid signatures.

Finally, for the purpose of scalability, instead of each ledger entry M_i
consisting of a unstructured message, we can instead commit to a merkelized
key:value tree, with each key being a pubkey p, and each value being an
alleged signature (possibly invalid). Now the non-publication condition is
proven by showing that either:

1. Tree M_i does not contain key p.
2. Tree M_i does contain key p, but alleged signature s is invalid.

The publication condition is proven by showing that tree M_j does contain key
p, and that key is associated with valid signature s.

A merkelized key:value tree can prove both statements with a log2(n) sized
proof, and thus we achieve log2(n) size scalability, with the constant factor
growing by the age of the seals, the ledger update frequency, the rate at which
seals are closed, and the maximum size allowed for signatures.

Note how a number of simple optimizations are possible, such as preventing the
creation of "spam" invalid signatures by blinding the actual pubkey with a
nonce, ensuring only valid signatures are published, etc. Also note how it is
_not_ necessary to validate all entries in the ledger form a chain: the
single-use-seals guarantees that a particular range of ledger entries will be
unique, regardless of whether all ledger history was unique.

Proof-of-Publication ledgers are trustless with regard to false seal witnesses:
the ledger maintainer(s) are unable to falsify a witness because they are
unable to produce a valid signature. They are however trusted with regard to
censorship: the ledger maintainer can prevent the publication of a signature
and/or or withhold data necessary to prove the state of the seal.


# Performance Figures

Assume a indivisible token transfer via a PoP ledger using Bitcoin-based
single-use-seals, with the ledger updated 12 times a day (every two hours).
Assume each ledger update corresponds to 2^32, 4 billion, transfers.

The data required to prove publication/non-publication for a given ledger
update is less than:

    lite-client BTC tx proof:                            = ~1KB
    merkle path down k/v tree: 32 levels * 32bytes/level =  1KB
    key/value: 32 bytes predicate hash + 1KB script sig  = ~1KB
                                                   Total = ~3KB/ledger update

        * 356 days/year * 12 updates/day = 13MB/year

Now, those are *absolute worst case* numbers, and there's a number of ways that
they can be substantially reduced such as only publishing valid signatures, or
just assuming you're not being attacked constantly... Also, note how for a
client with multiple tokens, much of the data can be shared amongst each token.
But even then, being able to prove the ownership status of a token, in a
trustless fashion, with just 13MB/year of data is an excellent result for many
use-cases.

With these optimizations, the marginal cost per token after the first one is
just 1KB/ledger update, 4.4MB/year.

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 488 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171205/8de5b811/attachment.sig>

From truthcoin at gmail.com  Tue Dec  5 18:05:39 2017
From: truthcoin at gmail.com (Paul Sztorc)
Date: Tue, 5 Dec 2017 13:05:39 -0500
Subject: [bitcoin-dev] Two Drivechain BIPs
In-Reply-To: <CAB+qUq4wNv=-ZSibUvVCwYSE7Qw8xe8EH91KG6znUp1d7X=mdA@mail.gmail.com>
References: <d3497397-33c3-90c1-1be8-a733736eac0b@gmail.com>
	<1bb6cccd-3f6d-d62a-2825-4e6f46a4b525@mattcorallo.com>
	<dd2781a6-3e10-9f0c-6ee0-a2c070b7cf67@gmail.com>
	<CAB+qUq4wNv=-ZSibUvVCwYSE7Qw8xe8EH91KG6znUp1d7X=mdA@mail.gmail.com>
Message-ID: <c898cc1c-d71c-de5c-aede-a2a4235656e0@gmail.com>

Hello Chris,

1. Marginal Cost

There actually is a very small cost to casting a malicious vote,
relative to an honest vote. This is because the software (when run
as-is), will automatically vote correctly. But to vote fraudulently you
must decide on what to do instead, and configure that! This might not be
as easy as it seems (see collective action part, below).

It is true that there is no *marginal* cost to creating a bad vote, in
the fraudulent withdrawal case. But then again there is no marginal cost
to creating a good vote either -- in fact there is no cost at all. In
fact, there is no marginal cost to creating a bad block either, in the
51% hashrate reorganization case. Epistemologically, the protocol has no
way of differentiating a "bad" block/vote from a good one. So one cannot
"cost" more than the other, in a narrow sense.

I suppose in the reorganization case there is the risk of lost mining
effort on a chain that actually does *not* have 51% and therefore won't
catch up. But this only encourages conformity to the longest chain,
including fraudulent chains. For example, imagine that the
reorganization is done via secretly mining a longer chain -- once that
chain is published, it will be the longest. Then, according to your
framework, there will be a "marginal cost" to doing the *right* thing
(trying to preserve the honest, transparent chain). So I'm afraid I
don't understand what you mean.

2. Repercussions

As for there being no repercussions, that is incorrect. The miner's
choice to engage in a fraudulent withdraw is one that has several
negative consequences. They take a variety of forms and likelihoods, but
they definitely exist and are very relevant.

The first repercussion is the loss of victim-sidechain future tx-fees. A
second is the loss of all future tx fees on all sidechains. A third is
that the Bitcoin super-network is changed from being a "sidechain
enabled" network to a "sidechain disabled" network.

The impact of these repercussions is still unclear and open to
interpretation. On one hand, the impact may be small and therefore not
very persuasive (as in the case where a sidechain has few tx-fees, few
sidechains are used, few are expected to be created/used, and so little
is lost by attacking). On the other hand, a single fraudulent withdrawal
might motivate the creation of a new spinoff network that is exactly the
same as the old network, but with merely two changes: the fraudulent
withdrawal surgically removed (as if it were never attempted) AND a new
proof of work algorithm. Since the withdrawals are so slow, there would
be plenty of time to organize such an option (and people who already
want a pow-change would jump at this glaring opportunity). Will the
repercussions be small or large? Even if there is only a *risk* of large
repercussions, it can be very persuasive. (Just as the IRS is very
persuasive to tax-paying Americans, even though only a tiny proportion
of tax returns are audited.)

0. Useless Sidechain Fallacy

Finally, you are joining the long list of people who are committing the
"useless sidechain fallacy". You are saying that because you believe the
sidechain is useless, therefore everyone must believe as you do, and
therefore the option to use a sidechain must be one that has zero value.
However, in the real world people are heterogeneous. They may decide
that your interpretation contains errors, or else their circumstances
might incline them towards a different risk-reward tradeoff. Finally,
this fallacy obfuscates the main benefit of sidechains, which is that
they are optional -- the sidechain-designer must convince users to
deposit funds there.

3. Collective Action Problem

There actually is a collective action problem inherent to fraudulent
withdrawals.

If miners wish to fraudulently withdraw from the sidechain, they need to
choose the destination addresses (on mainchain Bitcoin Core) months in
advance. Then they need to upvote/downvote this destination, despite
that fact that --during this time-- new hashpower might be coming
online/offline, and/or hashers might be joining/leaving specific pools.
I bring this up to demonstrate that even the most straightforward attack
(of "a 51% hashrate group attacks a sidechain and distributes the
proceeds to the group proportional to hashpower") is actually one that
contains a difficult (and potentially interminable) negotiation. The
effort required to initiate the negotiation is the source of the
collective action problem here.

I think that this collective action problem is actually more burdensome
than Bitcoin's -- for mainchain Bitcoin miners merely need to decide
which block height they intend to reorganize from.

You may wish to read Drivechain's security model to learn more:
http://www.truthcoin.info/blog/drivechain/#drivechains-security

In this case, I don't see a way to measure "security" cardinally or
ordinally. Instead, I am only able to see it as either "secure enough"
or "not secure enough". But perhaps someone can enlighten me as to the
math they are using to produce these cardinal/ordinal rankings.

--Paul

On 12/4/2017 2:36 PM, Chris Pacia wrote:
>
>     I think you are missing a few things.
>
>     First of all, I think the security model for sidechains is the same as
>     that of every blockchain
>
>     People will say things, like "but with sidechains 51% hashrate can
>     steal
>     your coins!", but as I have repeated many times, this is also true of
>     mainchain btc-tx. ?is something else?
>
>
> There are substantial opportunity costs as well as a collective action
> problem when it comes to re-writing the mainchain.?
>
> Is there anything similar for drivechains? As far as I can tell there
> is no opportunity cost to casting a malicious vote, no repercussions,
> and no collective action barrier that needs to be overcome.?
>
> Unless I'm missing something I wouldn't liken the security of a
> drivechain to that of the mainchain.


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171205/cabb88c2/attachment.html>

From sjors at sprovoost.nl  Tue Dec  5 19:24:04 2017
From: sjors at sprovoost.nl (Sjors Provoost)
Date: Tue, 5 Dec 2017 20:24:04 +0100
Subject: [bitcoin-dev] BIP-21 amendment proposal: -no125
Message-ID: <AE14915B-37DF-4D94-A0B1-E32A26903807@sprovoost.nl>

One way to reduce fees is to encourage usage of Replace-By-Fee, BIP 125 [0]. It allows wallets to recommend lower fees, because if a transaction gets stuck due to underestimation, the fee can easily be bumped.

Bitcoin Core has had support for RBF for a while, and as of v0.15.0 recommends lower fees [1] when the user chooses to use RBF.

I recently submitted a pull request that would turn on RBF by default, which triggered some discussion [2]. To ease the transition for merchants who are reluctant to see their customers use RBF, Matt Corallo suggested that wallets honor a no125=1 flag.

So a BIP-21 URI would look like this: bitcoin:175t...45W?amount=20.3&no125=1

When this flag is set, wallets should not use RBF, regardless of their default, unless the user explicitly overrides the merchant's preference.

Afaik adding this flag won't break existing BIP-21 support. It doesn't use the req- prefix, because it's optional. I'm also not aware of any ad hoc standards that use no125 in BIP-21-ish URIs.

- Sjors

P.S. I'd similarly suggest adding a bech32 param, but that's for another discussion

[0] https://github.com/bitcoin/bips/blob/master/bip-0125.mediawiki
[1] https://bitcoincore.org/en/2017/09/01/release-0.15.0/#better-fee-estimates
[2] https://github.com/bitcoin/bitcoin/pull/11605
[3] https://github.com/bitcoin/bitcoin/issues/11828
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: Message signed with OpenPGP
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171205/5beec6ce/attachment.sig>

From chris at suredbits.com  Mon Dec  4 20:11:13 2017
From: chris at suredbits.com (Chris Stewart)
Date: Mon, 4 Dec 2017 14:11:13 -0600
Subject: [bitcoin-dev] Two Drivechain BIPs
In-Reply-To: <CAB+qUq4wNv=-ZSibUvVCwYSE7Qw8xe8EH91KG6znUp1d7X=mdA@mail.gmail.com>
References: <d3497397-33c3-90c1-1be8-a733736eac0b@gmail.com>
	<1bb6cccd-3f6d-d62a-2825-4e6f46a4b525@mattcorallo.com>
	<dd2781a6-3e10-9f0c-6ee0-a2c070b7cf67@gmail.com>
	<CAB+qUq4wNv=-ZSibUvVCwYSE7Qw8xe8EH91KG6znUp1d7X=mdA@mail.gmail.com>
Message-ID: <CAGL6+mF1YbjZ28MtvPxTye-HndEqmd6LkaFVr9BWvPiK-kfVTA@mail.gmail.com>

>As far as I can tell there is no opportunity cost to casting a malicious
vote, no repercussions, and no collective action barrier that needs to be
overcome.

There is another interesting analysis on BMM and drivechains from /u/almkglor
on reddit
<https://www.reddit.com/r/Bitcoin/comments/6ztp3b/lets_discuss_something_techrelated_for_a_change/dn0rsdo/>.
I'm going to share here for visibility.

The problem with drivechains and blind merged mining is the disconnect
> between voting and "blind" merge mining. With BMM, a miner can do:
>
>    1. Not accept BMM, not vote.
>    2. Not accept BMM, operate their own sidechain node, mine sidecoin,
>    and vote correctly.
>    3. Not accept BMM, always upvote (i.e. allow theft).
>    4. Not accept BMM, always downvote (i.e. strangle).
>    5. Accept BMM, not vote.
>    6. Accept BMM, operate their own sidechain node, and vote correctly.
>    (not mine sidecoin directly: they get paid in maincoin by sidecoin-only
>    miners).
>    7. Accept BMM, always upvote (i.e. allow theft).
>    8. Accept BMM, always downvote (i.e. strangle).
>
> 3 and 7 will mean that non-verifying miners will be (inadvertently)
> complicit in theft. Drivechains have 1008-block cycles ostensibly to
> protect against theft, so that someone can "raise the alarm" and tell
> miners to downvote a particular theft withdrawal, but that sounds too much
> like centralized collusion to me.
>
> Strategy 8 will dominate over strategy 6, since the miner does not have to
> run a sidechain node (reduced cost) while still earning the same as
> strategy 6.
>
> Strategies 5->8 are all strictly superior to 1->4, so BMM does not really
> change anything: strategy 8 (equivalent to strategy 4 if BMM is not
> implemented) will still choke strategy 6 (equivalent to strategy 2 if BMM
> is not implemented)
>
> It seems Drivechain's security model is: miners always upvote by default.
> If a theft withdrawal is done on the mainchain, some sidechain nodes call
> up their miner friends (which makes me worry about miner centralization) to
> downvote it instead.
>
> The problem is: what if after a theft withdrawal is defeated, another
> theft withdrawal is done? And another, and another? This weakens the peg:
> while a theft withdrawal is on-going, a genuine withdrawal can't be posted
> (at least as I understand Sztorc's explanation). This chokes the sidechain
> withdrawal.
>
> The difference from maincoin is that attempts to choke the block are
> somewhat costly and a maincoin user can offer a higher transaction fee to
> beat the spam. If side->main is choked, no amount of sidecoin can be
> offered to beat the spammed theft transactions.
>
> I don't know, it seems like very weak security to me.
>
TLDR: a miner is most profitable if he always accepts BMM bribes, but
downvotes withdrawal transactions (WT). This obviously isn't ideal because
a withdrawal will never occur from the drivechain if enough miners employ
this strategy -- which seems to be the most profitable strategy.

-Chris


On Mon, Dec 4, 2017 at 1:36 PM, Chris Pacia via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

>
> I think you are missing a few things.
>
> First of all, I think the security model for sidechains is the same as
> that of every blockchain
>
> People will say things, like "but with sidechains 51% hashrate can steal
> your coins!", but as I have repeated many times, this is also true of
> mainchain btc-tx.  is something else?
>
>
> There are substantial opportunity costs as well as a collective action
> problem when it comes to re-writing the mainchain.
>
> Is there anything similar for drivechains? As far as I can tell there is
> no opportunity cost to casting a malicious vote, no repercussions, and no
> collective action barrier that needs to be overcome.
>
> Unless I'm missing something I wouldn't liken the security of a drivechain
> to that of the mainchain.
>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171204/dd24792f/attachment-0001.html>

From ajwest at gmail.com  Tue Dec  5 18:20:49 2017
From: ajwest at gmail.com (AJ West)
Date: Tue, 5 Dec 2017 13:20:49 -0500
Subject: [bitcoin-dev] Two Drivechain BIPs
In-Reply-To: <c898cc1c-d71c-de5c-aede-a2a4235656e0@gmail.com>
References: <d3497397-33c3-90c1-1be8-a733736eac0b@gmail.com>
	<1bb6cccd-3f6d-d62a-2825-4e6f46a4b525@mattcorallo.com>
	<dd2781a6-3e10-9f0c-6ee0-a2c070b7cf67@gmail.com>
	<CAB+qUq4wNv=-ZSibUvVCwYSE7Qw8xe8EH91KG6znUp1d7X=mdA@mail.gmail.com>
	<c898cc1c-d71c-de5c-aede-a2a4235656e0@gmail.com>
Message-ID: <CABXVU6asm_N94CUVm0_88zVOEr_m6Zm1_sR8i1r+UoKRji9X_Q@mail.gmail.com>

Hello,

I would like to refer to these BIPs in other contexts and conversations.
Regardless of the pitfalls or benefits, the discussion and technical review
happening in this thread (and the ones before) are well-formed ideas with
an active champion. The point of BIP numbers/conventions are so we're all
on the same page about what we're talking about.

Please assign these BIP numbers so discussion may continue in a controlled,
tagged, linear manner, instead of "the first BIP" and "the second BIP."

Thank you
AJ West

On Tue, Dec 5, 2017 at 1:05 PM, Paul Sztorc via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Hello Chris,
>
> 1. Marginal Cost
>
> There actually is a very small cost to casting a malicious vote, relative
> to an honest vote. This is because the software (when run as-is), will
> automatically vote correctly. But to vote fraudulently you must decide on
> what to do instead, and configure that! This might not be as easy as it
> seems (see collective action part, below).
>
> It is true that there is no *marginal* cost to creating a bad vote, in the
> fraudulent withdrawal case. But then again there is no marginal cost to
> creating a good vote either -- in fact there is no cost at all. In fact,
> there is no marginal cost to creating a bad block either, in the 51%
> hashrate reorganization case. Epistemologically, the protocol has no way of
> differentiating a "bad" block/vote from a good one. So one cannot "cost"
> more than the other, in a narrow sense.
>
> I suppose in the reorganization case there is the risk of lost mining
> effort on a chain that actually does *not* have 51% and therefore won't
> catch up. But this only encourages conformity to the longest chain,
> including fraudulent chains. For example, imagine that the reorganization
> is done via secretly mining a longer chain -- once that chain is published,
> it will be the longest. Then, according to your framework, there will be a
> "marginal cost" to doing the *right* thing (trying to preserve the honest,
> transparent chain). So I'm afraid I don't understand what you mean.
>
> 2. Repercussions
>
> As for there being no repercussions, that is incorrect. The miner's choice
> to engage in a fraudulent withdraw is one that has several negative
> consequences. They take a variety of forms and likelihoods, but they
> definitely exist and are very relevant.
>
> The first repercussion is the loss of victim-sidechain future tx-fees. A
> second is the loss of all future tx fees on all sidechains. A third is that
> the Bitcoin super-network is changed from being a "sidechain enabled"
> network to a "sidechain disabled" network.
>
> The impact of these repercussions is still unclear and open to
> interpretation. On one hand, the impact may be small and therefore not very
> persuasive (as in the case where a sidechain has few tx-fees, few
> sidechains are used, few are expected to be created/used, and so little is
> lost by attacking). On the other hand, a single fraudulent withdrawal might
> motivate the creation of a new spinoff network that is exactly the same as
> the old network, but with merely two changes: the fraudulent withdrawal
> surgically removed (as if it were never attempted) AND a new proof of work
> algorithm. Since the withdrawals are so slow, there would be plenty of time
> to organize such an option (and people who already want a pow-change would
> jump at this glaring opportunity). Will the repercussions be small or
> large? Even if there is only a *risk* of large repercussions, it can be
> very persuasive. (Just as the IRS is very persuasive to tax-paying
> Americans, even though only a tiny proportion of tax returns are audited.)
>
> 0. Useless Sidechain Fallacy
>
> Finally, you are joining the long list of people who are committing the
> "useless sidechain fallacy". You are saying that because you believe the
> sidechain is useless, therefore everyone must believe as you do, and
> therefore the option to use a sidechain must be one that has zero value.
> However, in the real world people are heterogeneous. They may decide that
> your interpretation contains errors, or else their circumstances might
> incline them towards a different risk-reward tradeoff. Finally, this
> fallacy obfuscates the main benefit of sidechains, which is that they are
> optional -- the sidechain-designer must convince users to deposit funds
> there.
>
> 3. Collective Action Problem
>
> There actually is a collective action problem inherent to fraudulent
> withdrawals.
>
> If miners wish to fraudulently withdraw from the sidechain, they need to
> choose the destination addresses (on mainchain Bitcoin Core) months in
> advance. Then they need to upvote/downvote this destination, despite that
> fact that --during this time-- new hashpower might be coming
> online/offline, and/or hashers might be joining/leaving specific pools. I
> bring this up to demonstrate that even the most straightforward attack (of
> "a 51% hashrate group attacks a sidechain and distributes the proceeds to
> the group proportional to hashpower") is actually one that contains a
> difficult (and potentially interminable) negotiation. The effort required
> to initiate the negotiation is the source of the collective action problem
> here.
>
> I think that this collective action problem is actually more burdensome
> than Bitcoin's -- for mainchain Bitcoin miners merely need to decide which
> block height they intend to reorganize from.
>
> You may wish to read Drivechain's security model to learn more:
> http://www.truthcoin.info/blog/drivechain/#drivechains-security
>
> In this case, I don't see a way to measure "security" cardinally or
> ordinally. Instead, I am only able to see it as either "secure enough" or
> "not secure enough". But perhaps someone can enlighten me as to the math
> they are using to produce these cardinal/ordinal rankings.
>
> --Paul
>
>
> On 12/4/2017 2:36 PM, Chris Pacia wrote:
>
>
> I think you are missing a few things.
>
> First of all, I think the security model for sidechains is the same as
> that of every blockchain
>
> People will say things, like "but with sidechains 51% hashrate can steal
> your coins!", but as I have repeated many times, this is also true of
> mainchain btc-tx.  is something else?
>
>
> There are substantial opportunity costs as well as a collective action
> problem when it comes to re-writing the mainchain.
>
> Is there anything similar for drivechains? As far as I can tell there is
> no opportunity cost to casting a malicious vote, no repercussions, and no
> collective action barrier that needs to be overcome.
>
> Unless I'm missing something I wouldn't liken the security of a drivechain
> to that of the mainchain.
>
>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171205/c6cc0277/attachment.html>

From willtech at live.com.au  Sun Dec  3 04:07:16 2017
From: willtech at live.com.au (Damian Williamson)
Date: Sun, 3 Dec 2017 04:07:16 +0000
Subject: [bitcoin-dev] BIP Proposal: UTWFOTIB - Use Transaction Weight For
 Ordering Transactions In Blocks
Message-ID: <PS2P216MB01791F54380CD03B3936399E9D3F0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>

# BIP Proposal: UTWFOTIB - Use Transaction Weight For Ordering Transactions In Blocks

I admit, with my limited experience in the operation of the protocol, the section entitled 'Solution operation' may not be entirely correct but you will get the idea. If I have it wrong, please correct it back to the list.


## The problem:


Everybody wants value. Miners want to maximize revenue from fees. Consumers want transaction reliability and, (we presume) low fees.

Current transaction bandwidth limit is a limiting factor for both.


## Solution summary:


Provide each transaction with a transaction weight, being a function of the fee paid (on a curve), and the time waiting in the transaction pool (also on a curve) out to n days (n=30 ?); the transaction weight serving as the likelihood of a transaction being included in the current block, and then use a target block size.

Protocol enforcement to prevent high or low blocksize cheating to be handled by having the protocol determine the target size for the current block using; current transaction pool size x ( 1 / (144 x n days ) ) = transactions to be included in the current block.

The curves used for the weight of transactions would have to be appropriate.


## Pros:

* Maximizes transaction reliability.
* Maximizes possibility for consumer and business uptake.
* Maximizes total fees paid per block without reducing reliability; because of reliability, confidence and uptake are greater; therefore, more transactions and more transactions total at priority fees.
* Market determines fee paid for transaction priority.

* Fee recommendations work all the way out to 30 days or greater.

* Provides additional block entropy and greater security since there is less probability of predicting the next block.


## Cons:

* ?
* Must be first be programmed.
* Anything else?


## Solution operation:


As I have said, my simplistic view of the operation. If I have this wrong, please correct it back to the list.

1. The protocol determines the target block size.

2. Assign each transaction in the pool a transaction weight based on fee and time waiting in the transaction pool.

3. Begin selecting transactions to include in the current block using transaction weight as the likelihood of inclusion until target block size is met.

4. Solve block.


Regards,

Damian Williamson
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171203/15371876/attachment-0001.html>

From luke at dashjr.org  Tue Dec  5 19:39:32 2017
From: luke at dashjr.org (Luke Dashjr)
Date: Tue, 5 Dec 2017 19:39:32 +0000
Subject: [bitcoin-dev] BIP-21 amendment proposal: -no125
In-Reply-To: <AE14915B-37DF-4D94-A0B1-E32A26903807@sprovoost.nl>
References: <AE14915B-37DF-4D94-A0B1-E32A26903807@sprovoost.nl>
Message-ID: <201712051939.33238.luke@dashjr.org>

On Tuesday 05 December 2017 7:24:04 PM Sjors Provoost wrote:
> I recently submitted a pull request that would turn on RBF by default,
> which triggered some discussion [2]. To ease the transition for merchants
> who are reluctant to see their customers use RBF, Matt Corallo suggested
> that wallets honor a no125=1 flag.
> 
> So a BIP-21 URI would look like this:
> bitcoin:175t...45W?amount=20.3&no125=1
> 
> When this flag is set, wallets should not use RBF, regardless of their
> default, unless the user explicitly overrides the merchant's preference.

This seems counterproductive. There is no reason to ever avoid the RBF flag. 
I'm not aware of any evidence it even reduces risk of, and it certainly 
doesn't prevent double spending. Plenty of miners allow RBF regardless of the 
flag, and malicious double spending doesn't benefit much from RBF in any case.

> P.S. I'd similarly suggest adding a bech32 param, but that's for another
> discussion

Bech32 addresses are just normal addresses. What need is there for a param?

Luke

From truthcoin at gmail.com  Tue Dec  5 19:55:33 2017
From: truthcoin at gmail.com (Paul Sztorc)
Date: Tue, 5 Dec 2017 14:55:33 -0500
Subject: [bitcoin-dev] Two Drivechain BIPs
In-Reply-To: <CAGL6+mF1YbjZ28MtvPxTye-HndEqmd6LkaFVr9BWvPiK-kfVTA@mail.gmail.com>
References: <d3497397-33c3-90c1-1be8-a733736eac0b@gmail.com>
	<1bb6cccd-3f6d-d62a-2825-4e6f46a4b525@mattcorallo.com>
	<dd2781a6-3e10-9f0c-6ee0-a2c070b7cf67@gmail.com>
	<CAB+qUq4wNv=-ZSibUvVCwYSE7Qw8xe8EH91KG6znUp1d7X=mdA@mail.gmail.com>
	<CAGL6+mF1YbjZ28MtvPxTye-HndEqmd6LkaFVr9BWvPiK-kfVTA@mail.gmail.com>
Message-ID: <b0c3f0f9-72f4-b73e-f5b1-e5590f9456aa@gmail.com>

Hi Other Chris,

Thanks for pointing this out. Here are my responses.

On 12/4/2017 3:11 PM, Chris Stewart wrote:
>There is another interesting analysis on BMM and drivechains from
/u/almkglor on reddit. I'm going to share here for visibility.
>> 3 and 7 will mean that non-verifying miners will be (inadvertently)
complicit in theft. Drivechains have 1008-block cycles ostensibly to
protect against theft, so that someone can "raise the alarm" and tell
miners to downvote a particular theft withdrawal, but that sounds too
much like centralized collusion to me.

Well, that is simply not what "centralized" means. "Centralized" means
that one person has special, irreplaceable influence. In contrast,
"decentralized" means that the process is not uniquely influenced by
what any *one* individual does or believes. Which is the case here: each
miner can independently make a decision about what to check, how to
check it, and what to do as a result. They could do undertake this
process, even if they ignored what everyone else was doing.

>> ...
>>
>> It seems Drivechain's security model is: miners always upvote by
default. If a theft withdrawal is done on the mainchain, some sidechain
nodes call up their miner friends (which makes me worry about miner
centralization) to downvote it instead.
>>
>> The problem is: what if after a theft withdrawal is defeated, another
theft withdrawal is done? And another, and another? This weakens the
peg: while a theft withdrawal is on-going, a genuine withdrawal can't be
posted (at least as I understand Sztorc's explanation). This chokes the
sidechain withdrawal.

This is a good question.

The answer is that there are mechanisms in place to address these
problems. Contrary to the reviewer's interpretation, multiple
withdrawal-attempts *are* allowed simultaneously. (This part of design
may have changed between now and Nov 2015, and I'm not sure if it was
ever documented anywhere until very recently). Second, only one
withdrawal can be upvoted at a time [ie, per sidechain per main:block].
Third, upvoting one withdrawal automatically downvotes all of the other
withdrawals (all in-progress withdrawals for that sidechain). Thus, we
have the asymmetry we desire. An "auditor class" can ignore all of the
withdrawals, until a significant amount of time has been invested in one
candidate. This makes the attempt more futile. Since they are unlikely
to be meaninglessly harassed, this opens the door to a "farmer class"
who can take it upon themselves to make sure the good withdrawals get
in, and get upvotes (especially early upvotes). Thus, the system can
tolerate a large "loafer class" who just lazily upvotes everything (or
nothing, or only the front-runner).

> TLDR: a miner is most profitable if he always accepts BMM bribes, but
downvotes withdrawal transactions (WT). This obviously isn't ideal
because a withdrawal will never occur from the drivechain if enough
miners employ this strategy -- which seems to be the most profitable
strategy.
>
>-Chris

I agree that miners should "always accept BMM bribes". In my recent
email to Matt Corallo, I described that this is basically the same as
saying that miners should "always mine on top of the heaviest chain".
(Of course, in mainchain Bitcoin miners are advised to mine atop the
heaviest *valid* chain, which is different from this case. It is
different because blind-merged-miners have no way of knowing if the
sidechain blocks they are mining are valid or not, which is kind of the
point. In practice I estimate that between 70% and 100% of today's
hashpower is already mining the mainchain "blind" -- through some
combination of pools, spv and spy mining.)

I don't agree with the conclusion (that the optimal policy is "always
downvoting", see above), but even if this analysis turns out to be
correct, it isn't a total disaster. The result (which is in the original
Nov 2015 specification) is that miners are the ones who perform the
atomic swaps. Then they walk the coins side-to-main (which, at this
point, are *their* coins). As long as there are a few large mining
groups, competition will drive the atomic swap fees down to negligible
levels. This slightly encourages mining to consolidate into two large
pools...but of course that is also true of the status quo!

Paul
?
>
> On Mon, Dec 4, 2017 at 1:36 PM, Chris Pacia via bitcoin-dev
> <bitcoin-dev at lists.linuxfoundation.org
> <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:
>
>
>         I think you are missing a few things.
>
>         First of all, I think the security model for sidechains is the
>         same as
>         that of every blockchain
>
>         People will say things, like "but with sidechains 51% hashrate
>         can steal
>         your coins!", but as I have repeated many times, this is also
>         true of
>         mainchain btc-tx. ?is something else?
>
>
>     There are substantial opportunity costs as well as a collective
>     action problem when it comes to re-writing the mainchain.?
>
>     Is there anything similar for drivechains? As far as I can tell
>     there is no opportunity cost to casting a malicious vote, no
>     repercussions, and no collective action barrier that needs to be
>     overcome.?
>
>     Unless I'm missing something I wouldn't liken the security of a
>     drivechain to that of the mainchain.
>
>     _______________________________________________
>     bitcoin-dev mailing list
>     bitcoin-dev at lists.linuxfoundation.org
>     <mailto:bitcoin-dev at lists.linuxfoundation.org>
>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>     <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171205/1ade3365/attachment.html>

From cryptaxe at gmail.com  Tue Dec  5 19:40:42 2017
From: cryptaxe at gmail.com (CryptAxe)
Date: Tue, 5 Dec 2017 11:40:42 -0800
Subject: [bitcoin-dev] BIP-21 amendment proposal: -no125
In-Reply-To: <AE14915B-37DF-4D94-A0B1-E32A26903807@sprovoost.nl>
References: <AE14915B-37DF-4D94-A0B1-E32A26903807@sprovoost.nl>
Message-ID: <CAF5CFkhwj5BHPndasvX5zYzmVwOF09XxzZo8hQO_f_1L3Vc+cg@mail.gmail.com>

Perhaps instead of a flag that can be used to disable a specific operation,
there should be a "-ignoredflags=x,y,z" section of the URI that can be used
to ignore whatever BIP this might also be useful for in the future?

On Dec 5, 2017 11:34 AM, "Sjors Provoost via bitcoin-dev" <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> One way to reduce fees is to encourage usage of Replace-By-Fee, BIP 125
> [0]. It allows wallets to recommend lower fees, because if a transaction
> gets stuck due to underestimation, the fee can easily be bumped.
>
> Bitcoin Core has had support for RBF for a while, and as of v0.15.0
> recommends lower fees [1] when the user chooses to use RBF.
>
> I recently submitted a pull request that would turn on RBF by default,
> which triggered some discussion [2]. To ease the transition for merchants
> who are reluctant to see their customers use RBF, Matt Corallo suggested
> that wallets honor a no125=1 flag.
>
> So a BIP-21 URI would look like this: bitcoin:175t...45W?amount=20.
> 3&no125=1
>
> When this flag is set, wallets should not use RBF, regardless of their
> default, unless the user explicitly overrides the merchant's preference.
>
> Afaik adding this flag won't break existing BIP-21 support. It doesn't use
> the req- prefix, because it's optional. I'm also not aware of any ad hoc
> standards that use no125 in BIP-21-ish URIs.
>
> - Sjors
>
> P.S. I'd similarly suggest adding a bech32 param, but that's for another
> discussion
>
> [0] https://github.com/bitcoin/bips/blob/master/bip-0125.mediawiki
> [1] https://bitcoincore.org/en/2017/09/01/release-0.15.0/#
> better-fee-estimates
> [2] https://github.com/bitcoin/bitcoin/pull/11605
> [3] https://github.com/bitcoin/bitcoin/issues/11828
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171205/923ac704/attachment-0001.html>

From sjors at sprovoost.nl  Tue Dec  5 20:00:01 2017
From: sjors at sprovoost.nl (Sjors Provoost)
Date: Tue, 5 Dec 2017 21:00:01 +0100
Subject: [bitcoin-dev] BIP-21 amendment proposal: -no125
In-Reply-To: <201712051939.33238.luke@dashjr.org>
References: <AE14915B-37DF-4D94-A0B1-E32A26903807@sprovoost.nl>
	<201712051939.33238.luke@dashjr.org>
Message-ID: <FD79573C-4771-464B-A570-E2868BBA0CA5@sprovoost.nl>

CryptAxe wrote:
> Perhaps instead of a flag that can be used to disable a specific operation, there should be a "-ignoredflags=x,y,z" section of the URI that can be used to ignore whatever BIP this might also be useful for in the future?

I don't think all BIPs lend themselves to this pattern. Can you think of another example? I also suspect each ignored flag requires carefully defined behavior, so it's probably better to spell that out in the BIP.

I also wouldn't be surprised if this BIP will get superseded in its entirety in the not too distant future; I believe there's some earlier discussion on this list about variations on BIP-71. So I don't think there will be many additional params in the future that warrant abstraction.


Luke Dashjr wrote:
>> P.S. I'd similarly suggest adding a bech32 param, but that's for another
>> discussion
> 
> Bech32 addresses are just normal addresses. What need is there for a param?
> 
> Luke

Most wallets consider bech32 addresses to be invalid. This would allow merchants to display a backwards compatible P2SH address and allow modern wallets to use bech32. In fact, this should be encouraged because it's slightly cheaper for the recipient to spend these funds (but not worth even a tiny increase in shopping cart abandonment).

Once the new format has sufficient adoption, merchants can simply drop support for old wallets and not use this parameter.

Sjors
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: Message signed with OpenPGP
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171205/6a2b0451/attachment.sig>

From cryptaxe at gmail.com  Tue Dec  5 20:06:31 2017
From: cryptaxe at gmail.com (CryptAxe)
Date: Tue, 5 Dec 2017 12:06:31 -0800
Subject: [bitcoin-dev] BIP-21 amendment proposal: -no125
In-Reply-To: <FD79573C-4771-464B-A570-E2868BBA0CA5@sprovoost.nl>
References: <AE14915B-37DF-4D94-A0B1-E32A26903807@sprovoost.nl>
	<201712051939.33238.luke@dashjr.org>
	<FD79573C-4771-464B-A570-E2868BBA0CA5@sprovoost.nl>
Message-ID: <CAF5CFkiVD6gUzmJbNGaJShMD3h5mq-RmUkBJEx61Eg6ie7=0MQ@mail.gmail.com>

On Dec 5, 2017 12:00 PM, "Sjors Provoost" <sjors at sprovoost.nl> wrote:

...

I don't think all BIPs lend themselves to this pattern. Can you think of
another example?


Not right now, just seemed like a good idea to consider making it useful
for more than one thing (maybe CT or something else could use it in the
future?).

I also suspect each ignored flag requires carefully defined behavior, so
it's probably better to spell that out in the BIP.

Sjors


Agreed, no reason they couldn't reuse the same section of the payment
request URI though. (And define that behavior in the BIP)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171205/f2230fff/attachment.html>

From ZmnSCPxj at protonmail.com  Wed Dec  6 04:49:12 2017
From: ZmnSCPxj at protonmail.com (ZmnSCPxj)
Date: Tue, 05 Dec 2017 23:49:12 -0500
Subject: [bitcoin-dev] Two Drivechain BIPs
In-Reply-To: <c898cc1c-d71c-de5c-aede-a2a4235656e0@gmail.com>
References: <d3497397-33c3-90c1-1be8-a733736eac0b@gmail.com>
	<1bb6cccd-3f6d-d62a-2825-4e6f46a4b525@mattcorallo.com>
	<dd2781a6-3e10-9f0c-6ee0-a2c070b7cf67@gmail.com>
	<CAB+qUq4wNv=-ZSibUvVCwYSE7Qw8xe8EH91KG6znUp1d7X=mdA@mail.gmail.com>
	<c898cc1c-d71c-de5c-aede-a2a4235656e0@gmail.com>
Message-ID: <XiOYlqnc-qXA7EdhRL5FyNeLDM6D5HissnTjnmuLlRrh8K2upymkEcnZb3drGUafY8CKkWjRbVQauYyUfA5cZrnIpNs5UAqWkcpahibEBpc=@protonmail.com>

Good morning Paul and Chris,

>3. Collective Action Problem
>
>There actually is a collective action problem inherent to fraudulent withdrawals.
>
>If miners wish to fraudulently withdraw from the sidechain, they need to choose the destination addresses (on mainchain Bitcoin Core) months in advance. Then they need to upvote/downvote this
>destination, despite that fact that --during this time-- new hashpower might be coming online/offline, and/or hashers might be joining/leaving specific pools. I bring this up to demonstrate that even the most
>straightforward attack (of "a 51% hashrate group attacks a sidechain and distributes the proceeds to the group proportional to hashpower") is actually one that contains a difficult (and potentially
>interminable) negotiation. The effort required to initiate the negotiation is the source of the collective action problem here.
>
>I think that this collective action problem is actually more burdensome than Bitcoin's -- for mainchain Bitcoin miners merely need to decide which block height they intend to reorganize from.

I actually devised a way to work around this collective action problem, and discussed it obliquely in a private e-mail with Chris, while I was preparing my article on sidechain weaknesses.  I removed it before publication of the sidechain weaknesses article, but perhaps I should not have.

Collective action can be ensured by contract.  In a world where some system can enforce certain actions programmatically, it is possible to ensure collective action via a program, i.e. a "smart contract".

The thief pays out to the destination address that is a P2SH of the below script:

OP_IF
  OP_HASH160 <hash> OP_EQUALVERIFY
  OP_DUP OP_HASH160 <thiefPubKeyHash> OP_EQUALVERIFY OP_CHECKSIG
OP_ELSE
  <withdrawTime+1week> OP_CHECKLOCKTIMEVERIFY OP_DROP
  OP_TRUE
OP_ENDIF

If the thief does not publish the preimage of the hash within 1 week of the withdrawal time, then it becomes possible for anyone to spend the above script; basically, some lucky miner who wins the first block past the specified time will get the entire winnings.  Let us call the above script, the Theft Contract.

The thief then recruits accomplices to the theft.  Note that the attack can be prepared and initiated before the accomplices are even recruited.

The thief locks some coins (the "cut" the accomplice gets), to the below script, for each accomplice it tries to entice:

OP_IF
  OP_HASH160 <hash> OP_EQUALVERIFY
  OP_DUP OP_HASH160 <accomplicePubKeyHash> OP_EQUALVERIFY OP_CHECKSIG
OP_ELSE
  <withdrawTime+2week> OP_CHECKLOCKTIMEVERIFY OP_DROP
  OP_DUP OP_HASH160 <thiefPubKeyHash> OP_EQUALVERIFY OP_CHECKSIG
OP_ENDIF

Let us call the above script, the Accomplice Contract.  If the accomplice accepts, he or she then starts to vote for the invalid withdrawal.

If the invalid withdrawal succeeds, the thief acquires the entire theft price from the Theft Contract by publishing the preimage to the <hash>.  (If he or she does not, then, some randomly-selected miner will acquire the money after the timeout, so the thief needs to publish the hash, before the timeout in the Theft Contract).

This publishes the preimage on the blockchain.  Each accomplice can then acquire their "cut" of the theft by copying the preimage and claiming from the Accomplice Contract.

If the theft never succeeds, then there is no reason for the thief to ever publish the preimage, and after the timeout on the Accomplice Contract, the thief can recover his or her offered funds at no loss (minus transaction fees),  This incentivizes accomplices to actually cooperate with the thief, as they will not get paid if the theft does not push through.

All that is necessary is for a single "mastermind" thief to begin this process.  Accomplices can be recruited later, with the "cut" they get negotiated according to how much hashpower they can bring to bear on theft.

Newly-created miners and mining pools can be enticed at the time they arise by offering an Accomplice Contract to them.  Thus, newly-created miners and mining pools can be brought into cooperation with the thief as soon as they make a presence on the blockchain.

Even if some mining pool makes a public statement that they will not assist in the theft, the thief may still commit an Accomplice Contract for them on-chain anyway, and publicize it, in order to put the integrity of that mining pool in question and drive out support from that mining pool.  True accomplices may pretend to initially be honest and then signal dishonestly later, in order to make it more plausible that a pool that "committed" to not support the theft is not trustable since they have an Accomplice Contract that will compensate them if they support the theft, creating further confusion and discord among honest miners.  The thief may also use the existence of such an Accomplice Contract while negotiating with more minor miners and mining pools, in order to entice those also to join, and thus gain additional buffer against the stochastic process of miner voting.

With the Theft Contract and the Accomplice Contract, negotiation can be done in parallel with the theft attempt, reducing the cost of organizing collective action, as we have all hoped "smart contracts" would do.

----

While it is true, that this requires that the thief have significant funds in reserve prior to theft (in order to fund the Accomplice Contracts he or she will have to offer to potential accomplices), we have always been assured that theft can be initiated by miners only, and that miners already have a significant amount of money they control.  So it will be no problem for a potential thief to reserve some funds for paying to Accomplice Contracts.

This vulnerability can be fixed if withdrawals are restricted to simple P2PKH or P2WPKH only, but in the presence of Scriptless Script and Bellare-Neven signatures, that may be sufficient to create the Theft Contract and the Accomplice Contract (but I know too little of Scriptless Script to be sure).

Regards,
ZmnSCPxj
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171205/7541418d/attachment-0001.html>

From ZmnSCPxj at protonmail.com  Wed Dec  6 05:46:45 2017
From: ZmnSCPxj at protonmail.com (ZmnSCPxj)
Date: Wed, 06 Dec 2017 00:46:45 -0500
Subject: [bitcoin-dev] BIP Proposal: UTWFOTIB - Use Transaction Weight
	For Ordering Transactions In Blocks
In-Reply-To: <PS2P216MB01791F54380CD03B3936399E9D3F0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
References: <PS2P216MB01791F54380CD03B3936399E9D3F0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
Message-ID: <TUV8ZuUkjBRWx-C9y-MOdLBBzWKRLd9TalfSPE1qN6oEvup6uAeGVUUlabCDDHKvWh1GZXTPgj6eOjPngN4ACLX2vIoXcjICy2s8tZfh7JQ=@protonmail.com>

Good morning Damian,

The primary problem in your proposal, as I understand it, is that the "transaction pool" is never committed to and is not part of consensus currently.  It is unlikely that the transaction pool will ever be part of consensus, as putting the transaction pool into consensus is effectively lifting the block size to include the entire transaction pool into each block.  The issue is that the transaction pool is transient and future fullnodes cannot find the contents of the transaction pool at the time blocks were made and cannot verify the correctness of historical blocks.  Also, fullnodes using -blocksonly mode have no transaction pool and cannot verify incoming blocks for these new rules.

Applying a patch that follows this policy into Bitcoin Core without enforcing it in all fullnodes will simply lead to miners removing the patch in software they run, making it an exercise in futility to write, review, and test this code in the first place.

In addition, you reuse the term "weight" for something different than its current use.  Current use, is that the "weight" of a transaction, is the computed weight from the SegWit weight equation, measured in virtual units called "sipa", using the equation (4sipa / non-witness byte + 1sipa/witness byte).

Regards,
ZmnSCPxj

Sent with [ProtonMail](https://protonmail.com) Secure Email.

> -------- Original Message --------
> Subject: [bitcoin-dev] BIP Proposal: UTWFOTIB - Use Transaction Weight For Ordering Transactions In Blocks
> Local Time: December 6, 2017 3:38 AM
> UTC Time: December 5, 2017 7:38 PM
> From: bitcoin-dev at lists.linuxfoundation.org
> To: bitcoin-dev at lists.linuxfoundation.org <bitcoin-dev at lists.linuxfoundation.org>
>
> # BIP Proposal: UTWFOTIB - Use Transaction Weight For Ordering Transactions In Blocks
>
> I admit, with my limited experience in the operation of the protocol, the section entitled 'Solution operation' may not be entirely correct but you will get the idea. If I have it wrong, please correct it back to the list.
>
> ## The problem:
>
> Everybody wants value. Miners want to maximize revenue from fees. Consumers want transaction reliability and, (we presume) low fees.
>
> Current transaction bandwidth limit is a limiting factor for both.
>
> ## Solution summary:
>
> Provide each transaction with a transaction weight, being a function of the fee paid (on a curve), and the time waiting in the transaction pool (also on a curve) out to n days (n=30 ?); the transaction weight serving as the likelihood of a transaction being included in the current block, and then use a target block size.
>
> Protocol enforcement to prevent high or low blocksize cheating to be handled by having the protocol determine the target size for the current block using; current transaction pool size x ( 1 / (144 x n days ) ) = transactions to be included in the current block.
>
> The curves used for the weight of transactions would have to be appropriate.
>
> ## Pros:
>
> * Maximizes transaction reliability.
> * Maximizes possibility for consumer and business uptake.
> * Maximizes total fees paid per block without reducing reliability; because of reliability, confidence and uptake are greater; therefore, more transactions and more transactions total at priority fees.
> * Market determines fee paid for transaction priority.
>
> * Fee recommendations work all the way out to 30 days or greater.
>
> * Provides additional block entropy and greater security since there is less probability of predicting the next block.
>
> ## Cons:
>
> * ?
> * Must be first be programmed.
> * Anything else?
>
> ## Solution operation:
>
> As I have said, my simplistic view of the operation. If I have this wrong, please correct it back to the list.
>
> 1. The protocol determines the target block size.
>
> 2. Assign each transaction in the pool a transaction weight based on fee and time waiting in the transaction pool.
>
> 3. Begin selecting transactions to include in the current block using transaction weight as the likelihood of inclusion until target block size is met.
>
> 4. Solve block.
>
> Regards,
>
> Damian Williamson
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171206/fe883569/attachment-0001.html>

From willtech at live.com.au  Wed Dec  6 09:27:30 2017
From: willtech at live.com.au (Damian Williamson)
Date: Wed, 6 Dec 2017 09:27:30 +0000
Subject: [bitcoin-dev] BIP Proposal: UTWFOTIB - Use Transaction Weight
 For Ordering Transactions In Blocks
In-Reply-To: <TUV8ZuUkjBRWx-C9y-MOdLBBzWKRLd9TalfSPE1qN6oEvup6uAeGVUUlabCDDHKvWh1GZXTPgj6eOjPngN4ACLX2vIoXcjICy2s8tZfh7JQ=@protonmail.com>
References: <PS2P216MB01791F54380CD03B3936399E9D3F0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>,
	<TUV8ZuUkjBRWx-C9y-MOdLBBzWKRLd9TalfSPE1qN6oEvup6uAeGVUUlabCDDHKvWh1GZXTPgj6eOjPngN4ACLX2vIoXcjICy2s8tZfh7JQ=@protonmail.com>
Message-ID: <PS2P216MB0179BC1CDE30F00D73DAA10F9D320@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>

Good afternoon ZmnSCPxj,


I have posted some discussion on the need for this proposal and, some refinements to the proposal explanation (not changes to the intended operation) to the bitcoin-discuss list. I didn't exactly mean to double post but thought it could use the discussion and, not to post it again, I will link to it when (if) it turns up, or will post it back here as an update on request. Currently, that post is awaiting moderator approval. I have also rewritten the solution operation section a bit in that post, not the idea that is being conveyed. I have added an additional step, reject blocks that do not meet the target block size for the current block.

I suggest it still should be added to the solution operation, to broadcast the next target block size with the current block when it is solved. Using that method may answer a part of your concern.

As I understand it, each node would be aware independently of x transactions waiting for confirmation, the transaction pool. Each node would no doubt have its own idea about how many waiting transactions there are and which particular transactions exist. I do not see why each node could not just work with the information at hand, it is my understanding that is what happens now, even with solved blocks vs the longest chain. I have not followed why you foresee from my proposal the need for fullnodes to back confirm the previous blocks in that manner.

If next blocksize is broadcast with the completed block it would be a simple matter to back confirm that. With transaction weight (transaction priority) I am suggesting that value gives the likelihood of a transaction being included, presuming an element of randomness as to whether any particular transaction is then included or not. Back confirmations on a transaction basis would be impossible anyway, all that could be confirmed is that a particular block has transactions that conform to a probability curve, if the variables are known, fee amount and time waiting in the pool, then the transaction priority can be recreated to establish that the probability of a particular block conforms. I certainly do not foresee including the full transaction pool in each block.

I am also presuming blocksize as a number of transactions rather than KB.

My suggestion, if adopted, is to directly make the operation of transaction priority a part of the operational standard - even without verification that it is being followed. The result of full transactional reliability is actually in the interests of miners as much as anyone.

The benefit of the proposal, not directly stated, is variable sized blocks (uncapped block size).

Yes, I have learned not to recycle terminology. My apologies, I had not been made aware that terminology already had use. Perhaps it would be simpler to call the proposal that I am putting forward here Transaction Priority.

Regards,
Damian Williamson


________________________________
From: ZmnSCPxj <ZmnSCPxj at protonmail.com>
Sent: Wednesday, 6 December 2017 4:46:45 PM
To: Damian Williamson
Cc: bitcoin-dev at lists.linuxfoundation.org
Subject: Re: [bitcoin-dev] BIP Proposal: UTWFOTIB - Use Transaction Weight For Ordering Transactions In Blocks

Good morning Damian,

The primary problem in your proposal, as I understand it, is that the "transaction pool" is never committed to and is not part of consensus currently.  It is unlikely that the transaction pool will ever be part of consensus, as putting the transaction pool into consensus is effectively lifting the block size to include the entire transaction pool into each block.  The issue is that the transaction pool is transient and future fullnodes cannot find the contents of the transaction pool at the time blocks were made and cannot verify the correctness of historical blocks.  Also, fullnodes using -blocksonly mode have no transaction pool and cannot verify incoming blocks for these new rules.

Applying a patch that follows this policy into Bitcoin Core without enforcing it in all fullnodes will simply lead to miners removing the patch in software they run, making it an exercise in futility to write, review, and test this code in the first place.

In addition, you reuse the term "weight" for something different than its current use.  Current use, is that the "weight" of a transaction, is the computed weight from the SegWit weight equation, measured in virtual units called "sipa", using the equation (4sipa / non-witness byte + 1sipa/witness byte).

Regards,
ZmnSCPxj




Sent with ProtonMail<https://protonmail.com> Secure Email.

-------- Original Message --------
Subject: [bitcoin-dev] BIP Proposal: UTWFOTIB - Use Transaction Weight For Ordering Transactions In Blocks
Local Time: December 6, 2017 3:38 AM
UTC Time: December 5, 2017 7:38 PM
From: bitcoin-dev at lists.linuxfoundation.org
To: bitcoin-dev at lists.linuxfoundation.org <bitcoin-dev at lists.linuxfoundation.org>



# BIP Proposal: UTWFOTIB - Use Transaction Weight For Ordering Transactions In Blocks

I admit, with my limited experience in the operation of the protocol, the section entitled 'Solution operation' may not be entirely correct but you will get the idea. If I have it wrong, please correct it back to the list.



## The problem:


Everybody wants value. Miners want to maximize revenue from fees. Consumers want transaction reliability and, (we presume) low fees.

Current transaction bandwidth limit is a limiting factor for both.



## Solution summary:


Provide each transaction with a transaction weight, being a function of the fee paid (on a curve), and the time waiting in the transaction pool (also on a curve) out to n days (n=30 ?); the transaction weight serving as the likelihood of a transaction being included in the current block, and then use a target block size.

Protocol enforcement to prevent high or low blocksize cheating to be handled by having the protocol determine the target size for the current block using; current transaction pool size x ( 1 / (144 x n days ) ) = transactions to be included in the current block.

The curves used for the weight of transactions would have to be appropriate.



## Pros:

* Maximizes transaction reliability.
* Maximizes possibility for consumer and business uptake.
* Maximizes total fees paid per block without reducing reliability; because of reliability, confidence and uptake are greater; therefore, more transactions and more transactions total at priority fees.
* Market determines fee paid for transaction priority.


* Fee recommendations work all the way out to 30 days or greater.

* Provides additional block entropy and greater security since there is less probability of predicting the next block.



## Cons:

* ?
* Must be first be programmed.
* Anything else?



## Solution operation:


As I have said, my simplistic view of the operation. If I have this wrong, please correct it back to the list.

1. The protocol determines the target block size.


2. Assign each transaction in the pool a transaction weight based on fee and time waiting in the transaction pool.

3. Begin selecting transactions to include in the current block using transaction weight as the likelihood of inclusion until target block size is met.

4. Solve block.



Regards,

Damian Williamson

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171206/462fabf4/attachment.html>

From jim.renkel at comcast.net  Wed Dec  6 05:18:11 2017
From: jim.renkel at comcast.net (Jim Renkel)
Date: Tue, 5 Dec 2017 23:18:11 -0600
Subject: [bitcoin-dev] BIP Proposal: UTWFOTIB - Use Transaction Weight
 For Ordering Transactions In Blocks
In-Reply-To: <PS2P216MB01791F54380CD03B3936399E9D3F0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
References: <PS2P216MB01791F54380CD03B3936399E9D3F0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
Message-ID: <52700305-585d-4239-134e-ac8c5b6c4165@comcast.net>

As i understand it, the transactions to be included in a block are 
entirely up to the miner of that block.


What prevents a miner from implementing the proposal on their own?


If this is adopted as some kind of "policy", what forces a miner to 
follow it?

Jim Renkel

On 12/2/2017 10:07 PM, Damian Williamson via bitcoin-dev wrote:
>
> # BIP Proposal: UTWFOTIB - Use Transaction Weight For Ordering 
> Transactions In Blocks
>
>
> I admit, with my limited experience in the operation of the protocol, 
> the section entitled 'Solution operation' may not be entirely correct 
> but you will get the idea. If I have it wrong, please correct it back 
> to the list.
>
> ## The problem:
>
>
> Everybody wants value. Miners want to maximize revenue from fees. 
> Consumers want transaction reliability and, (we presume) low fees.
>
>
> Current transaction bandwidth limit is a limiting factor for both.
>
> ## Solution summary:
>
>
> Provide each transaction with a transaction weight, being a function 
> of the fee paid (on a curve), and the time waiting in the transaction 
> pool (also on a curve) out to n days (n=30 ?); the transaction weight 
> serving as the likelihood of a transaction being included in the 
> current block, and then use a target block size.
>
>
> Protocol enforcement to prevent high or low blocksize cheating to be 
> handled by having the protocol determine the target size for the 
> current block using; current transaction pool size x ( 1 / (144 x n 
> days ) ) = transactions to be included in the current block.
>
> The curves used for the weight of transactions would have to be 
> appropriate.
>
> ## Pros:
>
>
> * Maximizes transaction reliability.
> * Maximizes possibility for consumer and business uptake.
> * Maximizes total fees paid per block without reducing reliability; 
> because of reliability, confidence and uptake are greater; therefore, 
> more transactions and more transactions total at priority fees.
> * Market determines fee paid for transaction priority.
>
> * Fee recommendations work all the way out to 30 days or greater.
>
> * Provides additional block entropy and greater security since there 
> is less probability of predicting the next block.
>
> ## Cons:
>
>
> * ?
> * Must be first be programmed.
> * Anything else?
>
> ## Solution operation:
>
>
> As I have said, my simplistic view of the operation. If I have this 
> wrong, please correct it back to the list.
>
>
> 1. The protocol determines the target block size.
>
> 2. Assign each transaction in the pool a transaction weight based on 
> fee and time waiting in the transaction pool.
>
> 3. Begin selecting transactions to include in the current block using 
> transaction weight as the likelihood of inclusion until target block 
> size is met.
>
> 4. Solve block.
>
> Regards,
>
> Damian Williamson
>
>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171205/c143a467/attachment-0001.html>

From ZmnSCPxj at protonmail.com  Thu Dec  7 06:46:08 2017
From: ZmnSCPxj at protonmail.com (ZmnSCPxj)
Date: Thu, 07 Dec 2017 01:46:08 -0500
Subject: [bitcoin-dev] BIP Proposal: UTWFOTIB - Use Transaction Weight
	For Ordering Transactions In Blocks
In-Reply-To: <PS2P216MB0179BC1CDE30F00D73DAA10F9D320@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
References: <PS2P216MB01791F54380CD03B3936399E9D3F0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<TUV8ZuUkjBRWx-C9y-MOdLBBzWKRLd9TalfSPE1qN6oEvup6uAeGVUUlabCDDHKvWh1GZXTPgj6eOjPngN4ACLX2vIoXcjICy2s8tZfh7JQ=@protonmail.com>
	<PS2P216MB0179BC1CDE30F00D73DAA10F9D320@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
Message-ID: <oVWjxK8fBoFl02giOtDPEQ7kAnp9TIRlAJKT14xJ6-VRRVJhT6-UsYLXqBARKUZi-fgRuKgymoTpHuQB5pluZRauX9dPOniJLAC5F6d0jo4=@protonmail.com>

Good morning Damian,

>As I understand it, each node would be aware independently of x transactions waiting for confirmation, the transaction pool.

Each long-running node would have a view that is roughly the same as the view of every other long-running node.

However, suppose a node, Sleeping Beauty, was temporarily stopped for a day (for various reasons) then is started again.  That node cannot verify what the "consensus" transaction pool was during the time it was stopped -- it has no view of that.  It can only trust that the longest chain is valid -- but that means it is SPV for this particular rule.

>If next blocksize is broadcast with the completed block it would be a simple matter to back confirm that.

It would not. Suppose Sleeping Beauty slept at block height 500,000.  On awakening, some node provides some purported block at height 500,001.  This block indicates some "next blocksize" for the block at height 500,002.  How does Sleeping Beauty know that the transaction pool at block 500,001 was of the correct size to provide the given "next blocksize"?  The only way, would be to look if there is some other chain with greater height that includes or does not include that block: that is, SPV confirmation.

How does Sleeping Beauty know it has caught up, and that its transaction pool is similar to that of its neighbors (who might be lying to it, for that matter), and that it should therefore stop using SPV confirmation and switch to strict fullnode rejection of blocks that indicate a "next blocksize" that is too large or too small according to your equation?  OR will it simply follow the longest chain always, in which case, it trusts miners to be honest about how loaded (or unloaded) the transaction pool is?

-------

As a general rule, consensus rules should restrict themselves to:

1.  The characteristics of the block.
2.  The characteristics of the transactions within the block.

The transaction pool is specifically those transaction that are NOT in any block, and thus, are not safe to depend on for any consensus rules.

Regards,
ZmnSCPxj
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171207/4e19d047/attachment.html>

From ZmnSCPxj at protonmail.com  Thu Dec  7 07:28:03 2017
From: ZmnSCPxj at protonmail.com (ZmnSCPxj)
Date: Thu, 07 Dec 2017 02:28:03 -0500
Subject: [bitcoin-dev] Two Drivechain BIPs
In-Reply-To: <b0c3f0f9-72f4-b73e-f5b1-e5590f9456aa@gmail.com>
References: <d3497397-33c3-90c1-1be8-a733736eac0b@gmail.com>
	<1bb6cccd-3f6d-d62a-2825-4e6f46a4b525@mattcorallo.com>
	<dd2781a6-3e10-9f0c-6ee0-a2c070b7cf67@gmail.com>
	<CAB+qUq4wNv=-ZSibUvVCwYSE7Qw8xe8EH91KG6znUp1d7X=mdA@mail.gmail.com>
	<CAGL6+mF1YbjZ28MtvPxTye-HndEqmd6LkaFVr9BWvPiK-kfVTA@mail.gmail.com>
	<b0c3f0f9-72f4-b73e-f5b1-e5590f9456aa@gmail.com>
Message-ID: <4iTYKa7LCe7_wN9neyumkheFrN7lPcmE8tbeD8if5SiobaBCeJUb3jpkwwrxi2-lL6q67TPLEAef43c7w-BRoFs21PUzUK8EOyTgaPCUZpA=@protonmail.com>

Good morning Paul and Chris,

>I don't agree with the conclusion (that the optimal policy is "always downvoting", see above), but even if this analysis turns out to be correct, it isn't a total disaster. The result (which is in the original Nov
>2015 specification) is that miners are the ones who perform the atomic swaps. Then they walk the coins side-to-main (which, at this point, are *their* coins). As long as there are a few large mining groups,
>competition will drive the atomic swap fees down to negligible levels.

Assuming there are three large mining groups who will ruthlessly want to undercut their competition, and with roughly 33% of total hashpower each (with the remaining 1% being some negligible hoi polloi), then one strategy to undercut your competitors would be to upvote only your own withdrawals and downvote that of your competitors.  A miner using this strategy hopes that the other miners will give up on withdrawing their own coin and trade their sidecoins at a discount to the undercutting miner.  That is, it is a hostage attempt of the sidecoin funds of the other miners.

In the case of three large mining pools that mistrust one another, then, no withdrawal would ever push through and drivechains stabilize to one-way pegs.

Now suppose that two of the mining pools collude.  They join their withdrawals into a single withdrawal proposal and upvote that, while downvoting the withdrawal of the third miner.  I observe that this is an opposite disaster: the 66% colluding miners can instead decide to simply outright make an invalid withdrawal of all funds, split up in half between themselves.

--

But three exactly equal mining pools is unnatural, for that matter

Suppose that there are three mining pools: A with 34%, B with 33%, C with 32%, and the hoi polloi making up the remaining 1%.  Those three pools cannot safely let the others withdraw funds.

Suppose A colludes with C to join their withdrawal proposals and their hashpower to withdraw.  This means that B can be pressured to sell its sidecoins for a discount to the joint coalition of A and C, since B cannot withdraw its own coins.  This lowers the profitability of B, causing grinders to leave them in favor of either A or C.  Since A is slightly larger than C, it is slightly more preferable, so it grows in size slightly more than C does.  Eventually B dies due to the coalition of A and C.  A and C are the only remaining pools, with A slightly larger than C.  In this case, A can break from the coalition and squeeze C of its sidecoins, since only A can withdraw (as it has more hashpower than C).  Again, grinders will leave C for A.  A rational C that is capable of considering this possible future path will thus never ally with A in a coalition to crush B, as it will then be next in line for being destroyed.

Similar analyses for coalitions of (B, C) and (A, B).

Knowing this, and knowing that they will end up sidecoin bagholders if they cannot withdraw coins, all miners decide to collude together and put all their withdrawals into a single withdrawal proposal.  But this removes any check-and-balance that the single withdrawal proposal is truthful to the sidechain: that is, the single coalition of A,B, and C can decide to just steal all sidechain funds and reassign them in proportion to their hashpower.  This might be stable at end-of-life for the sidechain where all ordinary users of the sidechain have exited it, but is otherwise a theft risk if the sidechain is operating normally.

Regards,
ZmnSCPxj
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171207/61cd76b3/attachment.html>

From cryptaxe at gmail.com  Wed Dec  6 20:51:43 2017
From: cryptaxe at gmail.com (CryptAxe)
Date: Wed, 6 Dec 2017 12:51:43 -0800
Subject: [bitcoin-dev] Two Drivechain BIPs
In-Reply-To: <XiOYlqnc-qXA7EdhRL5FyNeLDM6D5HissnTjnmuLlRrh8K2upymkEcnZb3drGUafY8CKkWjRbVQauYyUfA5cZrnIpNs5UAqWkcpahibEBpc=@protonmail.com>
References: <d3497397-33c3-90c1-1be8-a733736eac0b@gmail.com>
	<1bb6cccd-3f6d-d62a-2825-4e6f46a4b525@mattcorallo.com>
	<dd2781a6-3e10-9f0c-6ee0-a2c070b7cf67@gmail.com>
	<CAB+qUq4wNv=-ZSibUvVCwYSE7Qw8xe8EH91KG6znUp1d7X=mdA@mail.gmail.com>
	<c898cc1c-d71c-de5c-aede-a2a4235656e0@gmail.com>
	<XiOYlqnc-qXA7EdhRL5FyNeLDM6D5HissnTjnmuLlRrh8K2upymkEcnZb3drGUafY8CKkWjRbVQauYyUfA5cZrnIpNs5UAqWkcpahibEBpc=@protonmail.com>
Message-ID: <d293b884-5f28-d2db-d7b6-860ee7b17703@gmail.com>

On 12/05/2017 08:49 PM, ZmnSCPxj via bitcoin-dev wrote:

> ...
> This vulnerability can be fixed if withdrawals are restricted to
> simple P2PKH or P2WPKH only,

Limiting the withdrawal outputs to P2PKH and perhaps P2WPKH (would there
be any network benefit to supporting witness pubkeys for withdrawals?)
wouldn't be too much work for me. The downside is that people might want
to withdraw to multisig scripts, or any other legitimate P2SH. If it
prevents a huge issue, then it is probably worth it.


> but in the presence of Scriptless Script and Bellare-Neven signatures,
> that may be sufficient to create the Theft Contract and the Accomplice
> Contract (but I know too little of Scriptless Script to be sure).
>
> Regards,
> ZmnSCPxj
>

I'm curious if anyone on this list could help answer this.

Thanks!



From willtech at live.com.au  Thu Dec  7 06:34:39 2017
From: willtech at live.com.au (Damian Williamson)
Date: Thu, 7 Dec 2017 06:34:39 +0000
Subject: [bitcoin-dev] BIP Proposal: UTWFOTIB - Use Transaction Weight
 For Ordering Transactions In Blocks
In-Reply-To: <52700305-585d-4239-134e-ac8c5b6c4165@comcast.net>
References: <PS2P216MB01791F54380CD03B3936399E9D3F0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>,
	<52700305-585d-4239-134e-ac8c5b6c4165@comcast.net>
Message-ID: <PS2P216MB0179FC2174F0F9BFAA324F169D330@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>

Hello Jim,


The variable block sizes would not, as I understand it, be easily implemented by a solo miner.


You are right, there is presently nothing stopping a miner from ordering the transactions included by a priority that is not entirely based on the fee.


It may be possible to verify blocks conform to the proposal by showing that the probability for all transactions included in the block statistically conform to a probability distribution curve, if that is necessary and,  *if* the individual transaction priority can be recreated. I am not that deep into the mathematics, however, it may also be possible to use a similar method to do this just based on the fee, that statistically, the blocks conform to a fee distribution. Needs a clever mathematician.


It is certainly possible to verify that blocks conform to the expected size.


Honour is why people follow policy without enforcement. I may be in the wrong group. (sic)


Regards,

Damian Williamson

________________________________
From: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Jim Renkel via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>
Sent: Wednesday, 6 December 2017 4:18:11 PM
To: bitcoin-dev at lists.linuxfoundation.org
Subject: Re: [bitcoin-dev] BIP Proposal: UTWFOTIB - Use Transaction Weight For Ordering Transactions In Blocks


As i understand it, the transactions to be included in a block are entirely up to the miner of that block.


What prevents a miner from implementing the proposal on their own?


If this is adopted as some kind of "policy", what forces a miner to follow it?

Jim Renkel


On 12/2/2017 10:07 PM, Damian Williamson via bitcoin-dev wrote:

# BIP Proposal: UTWFOTIB - Use Transaction Weight For Ordering Transactions In Blocks

I admit, with my limited experience in the operation of the protocol, the section entitled 'Solution operation' may not be entirely correct but you will get the idea. If I have it wrong, please correct it back to the list.


## The problem:


Everybody wants value. Miners want to maximize revenue from fees. Consumers want transaction reliability and, (we presume) low fees.

Current transaction bandwidth limit is a limiting factor for both.


## Solution summary:


Provide each transaction with a transaction weight, being a function of the fee paid (on a curve), and the time waiting in the transaction pool (also on a curve) out to n days (n=30 ?); the transaction weight serving as the likelihood of a transaction being included in the current block, and then use a target block size.

Protocol enforcement to prevent high or low blocksize cheating to be handled by having the protocol determine the target size for the current block using; current transaction pool size x ( 1 / (144 x n days ) ) = transactions to be included in the current block.

The curves used for the weight of transactions would have to be appropriate.


## Pros:

* Maximizes transaction reliability.
* Maximizes possibility for consumer and business uptake.
* Maximizes total fees paid per block without reducing reliability; because of reliability, confidence and uptake are greater; therefore, more transactions and more transactions total at priority fees.
* Market determines fee paid for transaction priority.

* Fee recommendations work all the way out to 30 days or greater.

* Provides additional block entropy and greater security since there is less probability of predicting the next block.


## Cons:

* ?
* Must be first be programmed.
* Anything else?


## Solution operation:


As I have said, my simplistic view of the operation. If I have this wrong, please correct it back to the list.

1. The protocol determines the target block size.

2. Assign each transaction in the pool a transaction weight based on fee and time waiting in the transaction pool.

3. Begin selecting transactions to include in the current block using transaction weight as the likelihood of inclusion until target block size is met.

4. Solve block.


Regards,

Damian Williamson



_______________________________________________
bitcoin-dev mailing list
bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>
https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171207/312cb740/attachment-0001.html>

From willtech at live.com.au  Thu Dec  7 08:13:14 2017
From: willtech at live.com.au (Damian Williamson)
Date: Thu, 7 Dec 2017 08:13:14 +0000
Subject: [bitcoin-dev] BIP Proposal: UTWFOTIB - Use Transaction Weight
 For Ordering Transactions In Blocks
In-Reply-To: <oVWjxK8fBoFl02giOtDPEQ7kAnp9TIRlAJKT14xJ6-VRRVJhT6-UsYLXqBARKUZi-fgRuKgymoTpHuQB5pluZRauX9dPOniJLAC5F6d0jo4=@protonmail.com>
References: <PS2P216MB01791F54380CD03B3936399E9D3F0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<TUV8ZuUkjBRWx-C9y-MOdLBBzWKRLd9TalfSPE1qN6oEvup6uAeGVUUlabCDDHKvWh1GZXTPgj6eOjPngN4ACLX2vIoXcjICy2s8tZfh7JQ=@protonmail.com>
	<PS2P216MB0179BC1CDE30F00D73DAA10F9D320@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>,
	<oVWjxK8fBoFl02giOtDPEQ7kAnp9TIRlAJKT14xJ6-VRRVJhT6-UsYLXqBARKUZi-fgRuKgymoTpHuQB5pluZRauX9dPOniJLAC5F6d0jo4=@protonmail.com>
Message-ID: <PS2P216MB0179DD143E0558194295ADCC9D330@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>

Good morning ZmnSCPxj, it must be where you are,


I suppose that we are each missing each other's point some.


I understand that nodes would not be expected to agree on the transaction pool and do not propose validating that the correct transactions are included in a block. I speak of probability and likelihood of a transaction being included in a block, implying a random element. I do not propose rejecting blocks on the basis that the next block size is stated too large or too small for the transaction pool, only that the block received conforms to the next block size given on the previous block. Yes, it could be cheated. Also, various nodes may have at times wildly different amounts of transactions waiting in the transaction pool compared to each other and there could be a great disparity between them. It would not be possible in any case I can think of to validate the next block size is correct for the current transaction pool. Even as it is now, nodes may include transactions in a block that no other nodes have even heard of, nodes have no way to validate that either. If the block is built on sufficiently, it is the blockchain.


I will post back the revised proposal to the list. I have fleshed parts of it out more, given more explanation and, tried this time not to recycle terminology.


Regards,

Damian Williamson

________________________________
From: ZmnSCPxj <ZmnSCPxj at protonmail.com>
Sent: Thursday, 7 December 2017 5:46:08 PM
To: Damian Williamson
Cc: bitcoin-dev at lists.linuxfoundation.org
Subject: Re: [bitcoin-dev] BIP Proposal: UTWFOTIB - Use Transaction Weight For Ordering Transactions In Blocks

Good morning Damian,

>As I understand it, each node would be aware independently of x transactions waiting for confirmation, the transaction pool.

Each long-running node would have a view that is roughly the same as the view of every other long-running node.

However, suppose a node, Sleeping Beauty, was temporarily stopped for a day (for various reasons) then is started again.  That node cannot verify what the "consensus" transaction pool was during the time it was stopped -- it has no view of that.  It can only trust that the longest chain is valid -- but that means it is SPV for this particular rule.

>If next blocksize is broadcast with the completed block it would be a simple matter to back confirm that.

It would not. Suppose Sleeping Beauty slept at block height 500,000.  On awakening, some node provides some purported block at height 500,001.  This block indicates some "next blocksize" for the block at height 500,002.  How does Sleeping Beauty know that the transaction pool at block 500,001 was of the correct size to provide the given "next blocksize"?  The only way, would be to look if there is some other chain with greater height that includes or does not include that block: that is, SPV confirmation.

How does Sleeping Beauty know it has caught up, and that its transaction pool is similar to that of its neighbors (who might be lying to it, for that matter), and that it should therefore stop using SPV confirmation and switch to strict fullnode rejection of blocks that indicate a "next blocksize" that is too large or too small according to your equation?  OR will it simply follow the longest chain always, in which case, it trusts miners to be honest about how loaded (or unloaded) the transaction pool is?

-------

As a general rule, consensus rules should restrict themselves to:

1.  The characteristics of the block.
2.  The characteristics of the transactions within the block.

The transaction pool is specifically those transaction that are NOT in any block, and thus, are not safe to depend on for any consensus rules.

Regards,
ZmnSCPxj

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171207/91199698/attachment.html>

From willtech at live.com.au  Thu Dec  7 20:49:41 2017
From: willtech at live.com.au (Damian Williamson)
Date: Thu, 7 Dec 2017 20:49:41 +0000
Subject: [bitcoin-dev] BIP Proposal: UTWFOTIB - Use Transaction Weight
 For Ordering Transactions In Blocks
In-Reply-To: <PS2P216MB0179DD143E0558194295ADCC9D330@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
References: <PS2P216MB01791F54380CD03B3936399E9D3F0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<TUV8ZuUkjBRWx-C9y-MOdLBBzWKRLd9TalfSPE1qN6oEvup6uAeGVUUlabCDDHKvWh1GZXTPgj6eOjPngN4ACLX2vIoXcjICy2s8tZfh7JQ=@protonmail.com>
	<PS2P216MB0179BC1CDE30F00D73DAA10F9D320@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>,
	<oVWjxK8fBoFl02giOtDPEQ7kAnp9TIRlAJKT14xJ6-VRRVJhT6-UsYLXqBARKUZi-fgRuKgymoTpHuQB5pluZRauX9dPOniJLAC5F6d0jo4=@protonmail.com>,
	<PS2P216MB0179DD143E0558194295ADCC9D330@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
Message-ID: <PS2P216MB0179E4F0C7612263A59A20339D330@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>

Good morning ZmnSCPxj,


Actually, there is no incentive to cheat target block size by providing a next block size that is higher or lower than the proposal would give. Under the proposal the transaction pool can grow quite large. A low next block size just defers collecting transaction fees, while a high next block size shrinks the transaction pool and thereby lowers fees. It seems like a standoff. This is especially true if the curve for time waiting in the transaction pool is extended beyond n days, since it is a curve, after waiting longer than 60 days (if n = 60 days) a transaction would have a priority greater than one-hundred and would therfore be the first transaction included with no possibility of failing the likelihood, so, even low fee paying transactions would be included first if the pool size is growing through incorrectly providing the next block size.


As it is now, I presume, a miner could include exactly one transaction in a block and pad?


Regards,

Damian Williamson

________________________________
From: Damian Williamson <willtech at live.com.au>
Sent: Thursday, 7 December 2017 7:13:14 PM
To: ZmnSCPxj
Cc: bitcoin-dev at lists.linuxfoundation.org
Subject: Re: [bitcoin-dev] BIP Proposal: UTWFOTIB - Use Transaction Weight For Ordering Transactions In Blocks


Good morning ZmnSCPxj, it must be where you are,


I suppose that we are each missing each other's point some.


I understand that nodes would not be expected to agree on the transaction pool and do not propose validating that the correct transactions are included in a block. I speak of probability and likelihood of a transaction being included in a block, implying a random element. I do not propose rejecting blocks on the basis that the next block size is stated too large or too small for the transaction pool, only that the block received conforms to the next block size given on the previous block. Yes, it could be cheated. Also, various nodes may have at times wildly different amounts of transactions waiting in the transaction pool compared to each other and there could be a great disparity between them. It would not be possible in any case I can think of to validate the next block size is correct for the current transaction pool. Even as it is now, nodes may include transactions in a block that no other nodes have even heard of, nodes have no way to validate that either. If the block is built on sufficiently, it is the blockchain.


I will post back the revised proposal to the list. I have fleshed parts of it out more, given more explanation and, tried this time not to recycle terminology.


Regards,

Damian Williamson

________________________________
From: ZmnSCPxj <ZmnSCPxj at protonmail.com>
Sent: Thursday, 7 December 2017 5:46:08 PM
To: Damian Williamson
Cc: bitcoin-dev at lists.linuxfoundation.org
Subject: Re: [bitcoin-dev] BIP Proposal: UTWFOTIB - Use Transaction Weight For Ordering Transactions In Blocks

Good morning Damian,

>As I understand it, each node would be aware independently of x transactions waiting for confirmation, the transaction pool.

Each long-running node would have a view that is roughly the same as the view of every other long-running node.

However, suppose a node, Sleeping Beauty, was temporarily stopped for a day (for various reasons) then is started again.  That node cannot verify what the "consensus" transaction pool was during the time it was stopped -- it has no view of that.  It can only trust that the longest chain is valid -- but that means it is SPV for this particular rule.

>If next blocksize is broadcast with the completed block it would be a simple matter to back confirm that.

It would not. Suppose Sleeping Beauty slept at block height 500,000.  On awakening, some node provides some purported block at height 500,001.  This block indicates some "next blocksize" for the block at height 500,002.  How does Sleeping Beauty know that the transaction pool at block 500,001 was of the correct size to provide the given "next blocksize"?  The only way, would be to look if there is some other chain with greater height that includes or does not include that block: that is, SPV confirmation.

How does Sleeping Beauty know it has caught up, and that its transaction pool is similar to that of its neighbors (who might be lying to it, for that matter), and that it should therefore stop using SPV confirmation and switch to strict fullnode rejection of blocks that indicate a "next blocksize" that is too large or too small according to your equation?  OR will it simply follow the longest chain always, in which case, it trusts miners to be honest about how loaded (or unloaded) the transaction pool is?

-------

As a general rule, consensus rules should restrict themselves to:

1.  The characteristics of the block.
2.  The characteristics of the transactions within the block.

The transaction pool is specifically those transaction that are NOT in any block, and thus, are not safe to depend on for any consensus rules.

Regards,
ZmnSCPxj

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171207/2337b33a/attachment-0001.html>

From willtech at live.com.au  Thu Dec  7 21:01:43 2017
From: willtech at live.com.au (Damian Williamson)
Date: Thu, 7 Dec 2017 21:01:43 +0000
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction
 Priority For Ordering Transactions In Blocks
Message-ID: <PS2P216MB01794ABD544248B27BF0DFD99D330@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>

Good afternoon,

The need for this proposal:

We all must learn to admit that transaction bandwidth is still lurking as a serious issue for the operation, reliability, safety, consumer acceptance, uptake and, for the value of Bitcoin.

I recently sent a payment which was not urgent so; I chose three-day target confirmation from the fee recommendation. That transaction has still not confirmed after now more than six days - even waiting twice as long seems quite reasonable to me. That transaction is a valid transaction; it is not rubbish, junk or, spam. Under the current model with transaction bandwidth limitation, the longer a transaction waits, the less likely it is ever to confirm due to rising transaction numbers and being pushed back by transactions with rising fees.

I argue that no transactions are rubbish or junk, only some zero fee transactions might be spam. Having an ever-increasing number of valid transactions that do not confirm as more new transactions with higher fees are created is the opposite of operating a robust, reliable transaction system.

Business cannot operate with a model where transactions may or may not confirm. Even a business choosing a modest fee has no guarantee that their valid transaction will not be shuffled down by new transactions to the realm of never confirming after it is created. Consumers also will not accept this model as Bitcoin expands. If Bitcoin cannot be a reliable payment system for confirmed transactions then consumers, by and large, will simply not accept the model once they understand. Bitcoin will be a dirty payment system, and this will kill the value of Bitcoin.

Under the current system, a minority of transactions will eventually be the lucky few who have fees high enough to escape being pushed down the list.

Once there are more than x transactions (transaction bandwidth limit) every ten minutes, only those choosing twenty-minute confirmation (2 blocks) will have initially at most a fifty percent chance of ever having their payment confirm. Presently, not even using fee recommendations can ensure a sufficiently high fee is paid to ensure transaction confirmation.

I also argue that the current auction model for limited transaction bandwidth is wrong, is not suitable for a reliable transaction system and, is wrong for Bitcoin. All transactions must confirm in due time. Currently, Bitcoin is not a safe way to send payments.

I do not believe that consumers and business are against paying fees, even high fees. What is required is operational reliability.

This great issue needs to be resolved for the safety and reliability of Bitcoin. The time to resolve issues in commerce is before they become great big issues. The time to resolve this issue is now. We must have the foresight to identify and resolve problems before they trip us over.  Simply doubling block sizes every so often is reactionary and is not a reliable permanent solution. I have written a BIP proposal for a technical solution but, need your help to write it up to an acceptable standard to be a full BIP.

I have formatted the following with markdown which is human readable so, I hope nobody minds. I have done as much with this proposal as I feel that I am able so far but continue to take your feedback.

# BIP Proposal: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks

## The problem:
Everybody wants value. Miners want to maximize revenue from fees (and we presume, to minimize block size). Consumers need transaction reliability and, (we presume) want low fees.

The current transaction bandwidth limit is a limiting factor for both. As the operational safety of transactions is limited, so is consumer confidence as they realize the issue and, accordingly, uptake is limited. Fees are artificially inflated due to bandwidth limitations while failing to provide a full confirmation service for all transactions.

Current fee recommendations provide no satisfaction for transaction reliability and, as Bitcoin scales, this will worsen.

Bitcoin must be a fully scalable and reliable service, providing full transaction confirmation for every valid transaction.

The possibility to send a transaction with a fee lower than one that is acceptable to allow eventual transaction confirmation should be removed from the protocol and also from the user interface.

## Solution summary:
Provide each transaction with an individual transaction priority each time before choosing transactions to include in the current block, the priority being a function of the fee paid (on a curve), and the time waiting in the transaction pool (also on a curve) out to n days (n=60 ?). The transaction priority to serve as the likelihood of a transaction being included in the current block, and for determining the order in which transactions are tried to see if they will be included.

Use a target block size. Determine the target block size using; current transaction pool size x ( 1 / (144 x n days ) ) = number of transactions to be included in the current block. Broadcast the next target block size with the current block when it is solved so that nodes know the next target block size for the block that they are building on.

The curves used for the priority of transactions would have to be appropriate. Perhaps a mathematician with experience in probability can develop the right formulae. My thinking is a steep curve. I suppose that the probability of all transactions should probably account for a sufficient number of inclusions that the target block size is met although, it may not always be. As a suggestion, consider including some zero fee transactions to pad, highest BTC value first?

**Explanation of the operation of priority:**
> If transaction priority is, for example, a number between one (low) and one-hundred (high) it can be directly understood as the percentage chance in one-hundred of a transaction being included in the block. Using probability or likelihood infers that there is some function of random. If random (100) < transaction priority then the transaction is included.

>To break it down further, if both the fee on a curve value and the time waiting on a curve value are each a number between one and one-hundred, a rudimentary method may be to simply multiply those two numbers, to find the priority number. For example, a middle fee transaction waiting thirty days (if n = 60 days) may have a value of five for each part  (yes, just five, the values are on a curve). When multiplied that will give a priority value of twenty-five, or,  a twenty-five percent chance at that moment of being included in the block; it will likely be included in one of the next four blocks, getting more likely each chance. If it is still not included then the value of time waiting will be higher, making for more probability. A very low fee transaction would have a value for the fee of one. It would not be until near sixty-days that the particular low fee transaction has a high likelihood of being included in the block.

I am not concerned with low (or high) transaction fees, the primary reason for addressing the issue is to ensure transactional reliability and scalability while having each transaction confirm in due time.

## Pros:
* Maximizes transaction reliability.
* Fully scalable.
* Maximizes possibility for consumer and business uptake.
* Maximizes total fees paid per block without reducing reliability; because of reliability, in time confidence and overall uptake are greater; therefore, more transactions.
* Market determines fee paid for transaction priority.
* Fee recommendations work all the way out to 30 days or greater.
* Provides additional block entropy; greater security since there is less probability of predicting the next block.

## Cons:
* Could initially lower total transaction fees per block.
* Must be first be programmed.

## Solution operation:
This is a simplistic view of the operation. The actual operation will need to be determined in a spec for the programmer.

1. Determine the target block size for the current block.
2. Assign a transaction priority to each transaction in the pool.
3. Select transactions to include in the current block using probability in transaction priority order until the target block size is met.
5. Solve block.
6. Broadcast the next target block size with the current block when it is solved.
7. Block is received.
8. Block verification process.
9. Accept/reject block based on verification result.
10. Repeat.

## Closing comments:
It may be possible to verify blocks conform to the proposal by showing that the probability for all transactions included in the block statistically conforms to a probability distribution curve, *if* the individual transaction priority can be recreated. I am not that deep into the mathematics; however, it may also be possible to use a similar method to do this just based on the fee, that statistically, the blocks conform to a fee distribution. Any zero fee transactions would have to be ignored. This solution needs a clever mathematician.

I implore, at the very least, that we use some method that validates full transaction reliability and enables scalability of block sizes. If not this proposal, an alternative.

Regards,
Damian Williamson
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171207/79e32368/attachment.html>

From erik at q32.com  Thu Dec  7 21:39:56 2017
From: erik at q32.com (Erik Aronesty)
Date: Thu, 7 Dec 2017 16:39:56 -0500
Subject: [bitcoin-dev] BIP Proposal: UTWFOTIB - Use Transaction Weight
 For Ordering Transactions In Blocks
In-Reply-To: <PS2P216MB0179E4F0C7612263A59A20339D330@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
References: <PS2P216MB01791F54380CD03B3936399E9D3F0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<TUV8ZuUkjBRWx-C9y-MOdLBBzWKRLd9TalfSPE1qN6oEvup6uAeGVUUlabCDDHKvWh1GZXTPgj6eOjPngN4ACLX2vIoXcjICy2s8tZfh7JQ=@protonmail.com>
	<PS2P216MB0179BC1CDE30F00D73DAA10F9D320@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<oVWjxK8fBoFl02giOtDPEQ7kAnp9TIRlAJKT14xJ6-VRRVJhT6-UsYLXqBARKUZi-fgRuKgymoTpHuQB5pluZRauX9dPOniJLAC5F6d0jo4=@protonmail.com>
	<PS2P216MB0179DD143E0558194295ADCC9D330@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<PS2P216MB0179E4F0C7612263A59A20339D330@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CAJowKgKkao0dmfwNfxm4tNLsNRQ=TuHk3wTxgs5W1-NX5evfRw@mail.gmail.com>

You can feel free to write this version and try to get miners to use it.
 That's the nice thing about Bitcoin.

On Thu, Dec 7, 2017 at 3:49 PM, Damian Williamson via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Good morning ZmnSCPxj,
>
>
> Actually, there is no incentive to cheat target block size by providing a
> next block size that is higher or lower than the proposal would give. Under
> the proposal the transaction pool can grow quite large. A low next block
> size just defers collecting transaction fees, while a high next block size
> shrinks the transaction pool and thereby lowers fees. It seems like a
> standoff. This is especially true if the curve for time waiting in the
> transaction pool is extended beyond n days, since it is a curve, after
> waiting longer than 60 days (if n = 60 days) a transaction would have a
> priority greater than one-hundred and would therfore be the first
> transaction included with no possibility of failing the likelihood, so,
> even low fee paying transactions would be included first if the pool size
> is growing through incorrectly providing the next block size.
>
>
> As it is now, I presume, a miner could include exactly one transaction in
> a block and pad?
>
>
> Regards,
>
> Damian Williamson
> ------------------------------
> *From:* Damian Williamson <willtech at live.com.au>
> *Sent:* Thursday, 7 December 2017 7:13:14 PM
> *To:* ZmnSCPxj
>
> *Cc:* bitcoin-dev at lists.linuxfoundation.org
> *Subject:* Re: [bitcoin-dev] BIP Proposal: UTWFOTIB - Use Transaction
> Weight For Ordering Transactions In Blocks
>
>
> Good morning ZmnSCPxj, it must be where you are,
>
>
> I suppose that we are each missing each other's point some.
>
>
> I understand that nodes would not be expected to agree on the transaction
> pool and do not propose validating that the correct transactions are
> included in a block. I speak of probability and likelihood of a transaction
> being included in a block, implying a random element. I do not propose
> rejecting blocks on the basis that the next block size is stated too large
> or too small for the transaction pool, only that the block received
> conforms to the next block size given on the previous block. Yes, it could
> be cheated. Also, various nodes may have at times wildly different amounts
> of transactions waiting in the transaction pool compared to each other and
> there could be a great disparity between them. It would not be possible in
> any case I can think of to validate the next block size is correct for the
> current transaction pool. Even as it is now, nodes may include transactions
> in a block that no other nodes have even heard of, nodes have no way to
> validate that either. If the block is built on sufficiently, it is the
> blockchain.
>
>
> I will post back the revised proposal to the list. I have fleshed parts of
> it out more, given more explanation and, tried this time not to recycle
> terminology.
>
>
> Regards,
>
> Damian Williamson
> ------------------------------
> *From:* ZmnSCPxj <ZmnSCPxj at protonmail.com>
> *Sent:* Thursday, 7 December 2017 5:46:08 PM
> *To:* Damian Williamson
> *Cc:* bitcoin-dev at lists.linuxfoundation.org
> *Subject:* Re: [bitcoin-dev] BIP Proposal: UTWFOTIB - Use Transaction
> Weight For Ordering Transactions In Blocks
>
> Good morning Damian,
>
> >As I understand it, each node would be aware independently of x
> transactions waiting for confirmation, the transaction pool.
>
> Each long-running node would have a view that is roughly the same as the
> view of every other long-running node.
>
> However, suppose a node, Sleeping Beauty, was temporarily stopped for a
> day (for various reasons) then is started again.  That node cannot verify
> what the "consensus" transaction pool was during the time it was stopped --
> it has no view of that.  It can only trust that the longest chain is valid
> -- but that means it is SPV for this particular rule.
>
> >If next blocksize is broadcast with the completed block it would be a
> simple matter to back confirm that.
>
> It would not. Suppose Sleeping Beauty slept at block height 500,000.  On
> awakening, some node provides some purported block at height 500,001.  This
> block indicates some "next blocksize" for the block at height 500,002.  How
> does Sleeping Beauty know that the transaction pool at block 500,001 was of
> the correct size to provide the given "next blocksize"?  The only way,
> would be to look if there is some other chain with greater height that
> includes or does not include that block: that is, SPV confirmation.
>
> How does Sleeping Beauty know it has caught up, and that its transaction
> pool is similar to that of its neighbors (who might be lying to it, for
> that matter), and that it should therefore stop using SPV confirmation and
> switch to strict fullnode rejection of blocks that indicate a "next
> blocksize" that is too large or too small according to your equation?  OR
> will it simply follow the longest chain always, in which case, it trusts
> miners to be honest about how loaded (or unloaded) the transaction pool is?
>
> -------
>
> As a general rule, consensus rules should restrict themselves to:
>
> 1.  The characteristics of the block.
> 2.  The characteristics of the transactions within the block.
>
> The transaction pool is specifically those transaction that are NOT in any
> block, and thus, are not safe to depend on for any consensus rules.
>
> Regards,
> ZmnSCPxj
>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171207/846eb2b7/attachment-0001.html>

From ZmnSCPxj at protonmail.com  Fri Dec  8 15:40:11 2017
From: ZmnSCPxj at protonmail.com (ZmnSCPxj)
Date: Fri, 08 Dec 2017 10:40:11 -0500
Subject: [bitcoin-dev] Two Drivechain BIPs
In-Reply-To: <d293b884-5f28-d2db-d7b6-860ee7b17703@gmail.com>
References: <d3497397-33c3-90c1-1be8-a733736eac0b@gmail.com>
	<1bb6cccd-3f6d-d62a-2825-4e6f46a4b525@mattcorallo.com>
	<dd2781a6-3e10-9f0c-6ee0-a2c070b7cf67@gmail.com>
	<CAB+qUq4wNv=-ZSibUvVCwYSE7Qw8xe8EH91KG6znUp1d7X=mdA@mail.gmail.com>
	<c898cc1c-d71c-de5c-aede-a2a4235656e0@gmail.com>
	<XiOYlqnc-qXA7EdhRL5FyNeLDM6D5HissnTjnmuLlRrh8K2upymkEcnZb3drGUafY8CKkWjRbVQauYyUfA5cZrnIpNs5UAqWkcpahibEBpc=@protonmail.com>
	<d293b884-5f28-d2db-d7b6-860ee7b17703@gmail.com>
Message-ID: <gfGMVSmvpcb-lCCILymGhiCS0iI8szcxLyjDsPqfbsolY1u49TL2pcyojqk0DMWF_g_rvzqGn8eS2ROWqCoAed4UHLQE06x6GZxUNS5qywg=@protonmail.com>

Good morning CryptAxe,

I have come to realize that P2PKH is powerful enough to write a Theft Contract from which other Accomplice Contracts can derive.

The core of the Theft Contract and the Accomplice Contract is that they are both HTLCs.  The difference is that the Theft Contract, the timelock is anyone-can-spend after the time limit.  The Accomplice Contract is an ordinary HTLC.

However, P2PKH, plus an off-chain method, can be combined to form a HTLC with anyone-can-spend after the timelock.

P2PKH includes <pubKeyHash>.  Spending from a P2PKH reveals the preimage to <pubKeyHash>, the public key.  Thus, the Accomplice Contract can use the P2PKH <pubKeyHash> as the hash, and when the P2PKH is spent, acquire the public key to be used as the preimage of the hashlock.

The remaining ingredient is a timelock with anyone-can-spend after the time limit.  And I belatedly realized that I have in fact seen an offchain method of imposing a timelock on information: https://www.gwern.net/Self-decrypting-files  To create a timelock, the "mastermind" thief encrypts the private key to the P2PKH in such a timelocked-encryption scheme, and publishes it as part of the theft attempt to commit themselves to the timelock, together with a zero-knowledge proof that the timelock-encrypted private key is correctly the private key to the given public key hash (I am not mathematically gifted enough to know if such a proof if possible, however, and if this is impossible, then this entire scheme cannot work).  Thus, if the thief does not spend the P2PKH (which reveals the preimage to the hash, which unlocks the Accomplice Contracts and pays the accomplices), then someone else can grind the timelock-encryption and spend the P2PKH (and also incidentally unlocks the Accomplice Contracts anyway).

Of course, timelock-encryption is significantly less reliable as a time measure (different sequential processing speeds yield different timelocks from the same timelock-encrypted data), but that may be enough to have a reasonably trustless Thief-Accomplice coordination structure.

Another issue is that if the Accomplice does not cooperate and the theft fails, the Accomplices may still grind the timelock-encryption and acquire the private key, from which they can compute the public key, which is also the preimage to their hashlock.  So there may not actually be an incentive to coordinate with the Thief under this structure.  But perhaps this idea may trigger someone else to consider how to exploit the precise mathematics of P2PKH to create something similar to a HTLC.

Regards,
ZmnSCPxj

-------- Original Message --------
Subject: Re: [bitcoin-dev] Two Drivechain BIPs
Local Time: December 7, 2017 4:51 AM
UTC Time: December 6, 2017 8:51 PM
From: bitcoin-dev at lists.linuxfoundation.org
To: bitcoin-dev at lists.linuxfoundation.org

On 12/05/2017 08:49 PM, ZmnSCPxj via bitcoin-dev wrote:
...
This vulnerability can be fixed if withdrawals are restricted to
simple P2PKH or P2WPKH only,

Limiting the withdrawal outputs to P2PKH and perhaps P2WPKH (would there
be any network benefit to supporting witness pubkeys for withdrawals?)
wouldn't be too much work for me. The downside is that people might want
to withdraw to multisig scripts, or any other legitimate P2SH. If it
prevents a huge issue, then it is probably worth it.

but in the presence of Scriptless Script and Bellare-Neven signatures,
that may be sufficient to create the Theft Contract and the Accomplice
Contract (but I know too little of Scriptless Script to be sure).
Regards,
ZmnSCPxj

I'm curious if anyone on this list could help answer this.

Thanks!

bitcoin-dev mailing list
bitcoin-dev at lists.linuxfoundation.org
https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171208/63502b3f/attachment.html>

From dkbryant at gmail.com  Fri Dec  8 18:25:47 2017
From: dkbryant at gmail.com (Dan Bryant)
Date: Fri, 8 Dec 2017 12:25:47 -0600
Subject: [bitcoin-dev] Sign / Verify message against SegWit P2SH addresses.
Message-ID: <CAAUFj10gEPBS3nTZ6aJn4UazhcJKPni6_pYGWwOs+QNeDo9NaA@mail.gmail.com>

I know there are posts, and an issue opened against it, but is there anyone
writing a BIP for Sign / Verify message against a SegWit address?

I realize it is not a feature in wide use, but I think it still serves an
important purpose, such as when proof of assets are requested.

ref: https://github.com/bitcoin/bitcoin/issues/10542
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171208/3315b91a/attachment.html>

From sjors at sprovoost.nl  Sat Dec  9 12:57:52 2017
From: sjors at sprovoost.nl (Sjors Provoost)
Date: Sat, 9 Dec 2017 13:57:52 +0100
Subject: [bitcoin-dev] Sign / Verify message against SegWit P2SH
 addresses.
In-Reply-To: <CAAUFj10gEPBS3nTZ6aJn4UazhcJKPni6_pYGWwOs+QNeDo9NaA@mail.gmail.com>
References: <CAAUFj10gEPBS3nTZ6aJn4UazhcJKPni6_pYGWwOs+QNeDo9NaA@mail.gmail.com>
Message-ID: <69F75C75-6E51-4189-B3AE-032573B49A92@sprovoost.nl>

I would like to see this specifically for P2SH-PWPKH and/or native SegWit bech32 addresses.

Use cases I can think of are "I'm the whale in charge of these funds, listen to me" and some form of polling.

It's nice if funds aren't excluded from these type of functionalities just because they have a complicated redeem script. So something more generic like the Elements implementation / suggestion Greg Maxwell referred to in the Github thread would be nice too.

Is it also useful or possible to sign a message proving you are able to redeem some arbitrary branch in a MAST-like tree of scripts? What about being a minority part of a multisig?

All these features have privacy trade-offs, as well as perhaps security trade-offs, e.g. when you reveal a public key that was otherwise hidden behind a hash (i.e. if someone were to break secp256k1, they'd first organize a popular poll).

There's no BIP for the current message signing mechanism either afaik.

Sjors

> Op 8 dec. 2017, om 19:25 heeft Dan Bryant via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> het volgende geschreven:
> 
> I know there are posts, and an issue opened against it, but is there anyone writing a BIP for Sign / Verify message against a SegWit address?
> 
> I realize it is not a feature in wide use, but I think it still serves an important purpose, such as when proof of assets are requested.
> 
> ref: https://github.com/bitcoin/bitcoin/issues/10542 <https://github.com/bitcoin/bitcoin/issues/10542>
> 
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171209/621ffb05/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: Message signed with OpenPGP
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171209/621ffb05/attachment.sig>

From teweldemat at gmail.com  Mon Dec 11 17:30:37 2017
From: teweldemat at gmail.com (Teweldemedhin Aberra)
Date: Mon, 11 Dec 2017 20:30:37 +0300
Subject: [bitcoin-dev] BIP - Dead Man's Switch
Message-ID: <CAEA=K3QiDtuHJNBLbZxaw6eSGhYWC5++vKJEX2Shxs7vb9bZ-A@mail.gmail.com>

It is estimated that about 4 million of the about 16.4 Bitcoins ever mined
are lost forever because no one knows the private keys of some Bitcoin
addresses. This effectively mean there are actually only 14.4 million
Bitcoins in circulation even though 16.4 million are mined. There is no way
of eliminating the human errors that cause these losses of Bitcoin from
circulation, while the number of Bitcoin that will ever be mined is capped
at 21 million. This means the total number of Bitcoins that are in
circulation will eventually become zero, bringing the network to an end.

The solution this BIP proposes is to implementing a dead man's switch to
Bitcoin addresses. The dead man's switch causes the Bitcoins assigned to
dormant addresses to automatically expire. A Bitcoin address is deemed
dormant if it is not used in transactions for some fixed length of time,
say ten years.

The calculation of the miner's reward should take into account the Bitcoins
that has expired. This means there is a possibility that miner's reward can
increase if sufficient number of Bitcoins expire.

Ref:

http://fortune.com/2017/11/25/lost-bitcoins/


<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=icon>
Virus-free.
www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=link>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171211/b24d6834/attachment.html>

From joroark at vt.edu  Mon Dec 11 18:12:02 2017
From: joroark at vt.edu (Douglas Roark)
Date: Mon, 11 Dec 2017 10:12:02 -0800
Subject: [bitcoin-dev] BIP - Dead Man's Switch
In-Reply-To: <CAEA=K3QiDtuHJNBLbZxaw6eSGhYWC5++vKJEX2Shxs7vb9bZ-A@mail.gmail.com>
References: <CAEA=K3QiDtuHJNBLbZxaw6eSGhYWC5++vKJEX2Shxs7vb9bZ-A@mail.gmail.com>
Message-ID: <b1a6d74d-f268-e239-ef0e-6ce6facc21f8@vt.edu>

With all due respect, this isn't a BIP. It's idle speculation regarding
what one person considers to be a problem and others may not. Please
read https://github.com/bitcoin/bips/blob/master/bip-0001.mediawiki and
try again. Among other things:

- Convince us this is a real issue, and that your data is accurate.
Who's to say which coins are truly lost? Maybe the people controlling
the keys are just laying low, wish to use their coins in 2112, etc.
- Propose formulas for how the miners will take everything into account,
and explain why they're acceptable.
- Write code that implements your ideas.

Good luck!

-- 
---
Douglas Roark
Cryptocurrency, network security, travel, and art.
https://onename.com/droark
joroark at vt.edu
PGP key ID: 26623924

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 895 bytes
Desc: OpenPGP digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171211/de37c9f0/attachment.sig>

From pete at petertodd.org  Mon Dec 11 18:19:43 2017
From: pete at petertodd.org (Peter Todd)
Date: Mon, 11 Dec 2017 13:19:43 -0500
Subject: [bitcoin-dev] BIP-21 amendment proposal: -no125
In-Reply-To: <201712051939.33238.luke@dashjr.org>
References: <AE14915B-37DF-4D94-A0B1-E32A26903807@sprovoost.nl>
	<201712051939.33238.luke@dashjr.org>
Message-ID: <20171211181943.GA9855@savin.petertodd.org>

On Tue, Dec 05, 2017 at 07:39:32PM +0000, Luke Dashjr via bitcoin-dev wrote:
> On Tuesday 05 December 2017 7:24:04 PM Sjors Provoost wrote:
> > I recently submitted a pull request that would turn on RBF by default,
> > which triggered some discussion [2]. To ease the transition for merchants
> > who are reluctant to see their customers use RBF, Matt Corallo suggested
> > that wallets honor a no125=1 flag.
> > 
> > So a BIP-21 URI would look like this:
> > bitcoin:175t...45W?amount=20.3&no125=1
> > 
> > When this flag is set, wallets should not use RBF, regardless of their
> > default, unless the user explicitly overrides the merchant's preference.
> 
> This seems counterproductive. There is no reason to ever avoid the RBF flag. 
> I'm not aware of any evidence it even reduces risk of, and it certainly 
> doesn't prevent double spending. Plenty of miners allow RBF regardless of the 
> flag, and malicious double spending doesn't benefit much from RBF in any case.

I'll second the objection to a no-RBF flag.

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 455 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171211/160e761a/attachment.sig>

From nick at pudar.com  Mon Dec 11 18:12:05 2017
From: nick at pudar.com (Nick Pudar)
Date: Mon, 11 Dec 2017 18:12:05 +0000
Subject: [bitcoin-dev] BIP - Dead Man's Switch
In-Reply-To: <CAEA=K3QiDtuHJNBLbZxaw6eSGhYWC5++vKJEX2Shxs7vb9bZ-A@mail.gmail.com>
References: <CAEA=K3QiDtuHJNBLbZxaw6eSGhYWC5++vKJEX2Shxs7vb9bZ-A@mail.gmail.com>
Message-ID: <DM5PR12MB117879D6648A97D6393F401AC8370@DM5PR12MB1178.namprd12.prod.outlook.com>

This topic has come up several times in recent years. While it is well intentioned, it can have devastating outcomes for people that want to save long term. If such a system were implemented, it would force people to move funds around in order to not get nullified. In that process, it introduces multiple opportunities for errors. Cold storage should be able to stay cold. I personally would be apprehensive about implementing this kind of a system.

...via Android



From: Teweldemedhin Aberra via bitcoin-dev
Sent: Monday, December 11, 1:04 PM
Subject: [bitcoin-dev] BIP - Dead Man's Switch
To: bitcoin-dev at lists.linuxfoundation.org


It is estimated that about 4 million of the about 16.4 Bitcoins ever mined are lost forever because no one knows the private keys of some Bitcoin addresses. This effectively mean there are actually only 14.4 million Bitcoins in circulation even though 16.4 million are mined. There is no way of eliminating the human errors that cause these losses of Bitcoin from circulation, while the number of Bitcoin that will ever be mined is capped at 21 million. This means the total number of Bitcoins that are in circulation will eventually become zero, bringing the network to an end.
The solution this BIP proposes is to implementing a dead man's switch to Bitcoin addresses. The dead man's switch causes the Bitcoins assigned to dormant addresses to automatically expire. A Bitcoin address is deemed dormant if it is not used in transactions for some fixed length of time, say ten years.
The calculation of the miner's reward should take into account the Bitcoins that has expired. This means there is a possibility that miner's reward can increase if sufficient number of Bitcoins expire.

Ref:
http://fortune.com/2017/11/25/lost-bitcoins/


Virus-free.
        <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=link>
www.avast.com




-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171211/37a24fc9/attachment-0001.html>

From radoslaw.biernacki at gmail.com  Mon Dec 11 18:13:26 2017
From: radoslaw.biernacki at gmail.com (Radoslaw Biernacki)
Date: Mon, 11 Dec 2017 19:13:26 +0100
Subject: [bitcoin-dev] BIP - Dead Man's Switch
In-Reply-To: <CAEA=K3QiDtuHJNBLbZxaw6eSGhYWC5++vKJEX2Shxs7vb9bZ-A@mail.gmail.com>
References: <CAEA=K3QiDtuHJNBLbZxaw6eSGhYWC5++vKJEX2Shxs7vb9bZ-A@mail.gmail.com>
Message-ID: <CADp3C4vfL8yE4C8T5nU_qpOOLkDP+eMwM_pXmbdB0Nj0vbJHUg@mail.gmail.com>

Aside from that such change would require a hard fork it also violates one
of basic rules of bitcoin, which has long term consequences for miners and
for whole Bitcoin economy. In short, after altering the supply limit it
would not be "bitcoin" anymore.

On Mon, Dec 11, 2017 at 6:30 PM, Teweldemedhin Aberra via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> It is estimated that about 4 million of the about 16.4 Bitcoins ever mined
> are lost forever because no one knows the private keys of some Bitcoin
> addresses. This effectively mean there are actually only 14.4 million
> Bitcoins in circulation even though 16.4 million are mined. There is no way
> of eliminating the human errors that cause these losses of Bitcoin from
> circulation, while the number of Bitcoin that will ever be mined is capped
> at 21 million. This means the total number of Bitcoins that are in
> circulation will eventually become zero, bringing the network to an end.
>
> The solution this BIP proposes is to implementing a dead man's switch to
> Bitcoin addresses. The dead man's switch causes the Bitcoins assigned to
> dormant addresses to automatically expire. A Bitcoin address is deemed
> dormant if it is not used in transactions for some fixed length of time,
> say ten years.
>
> The calculation of the miner's reward should take into account the
> Bitcoins that has expired. This means there is a possibility that miner's
> reward can increase if sufficient number of Bitcoins expire.
>
> Ref:
>
> http://fortune.com/2017/11/25/lost-bitcoins/
>
>
>
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=icon> Virus-free.
> www.avast.com
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=link>
> <#m_-612306741899295358_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171211/82180950/attachment.html>

From pieter.wuille at gmail.com  Mon Dec 11 18:26:40 2017
From: pieter.wuille at gmail.com (Pieter Wuille)
Date: Mon, 11 Dec 2017 10:26:40 -0800
Subject: [bitcoin-dev] BIP - Dead Man's Switch
In-Reply-To: <DM5PR12MB117879D6648A97D6393F401AC8370@DM5PR12MB1178.namprd12.prod.outlook.com>
References: <CAEA=K3QiDtuHJNBLbZxaw6eSGhYWC5++vKJEX2Shxs7vb9bZ-A@mail.gmail.com>
	<DM5PR12MB117879D6648A97D6393F401AC8370@DM5PR12MB1178.namprd12.prod.outlook.com>
Message-ID: <CAPg+sBi9nYHCcN8ct=_iqWuxDFU1cPwBfbfF8WPX-w+kf6hzfQ@mail.gmail.com>

On Dec 11, 2017 10:23, "Nick Pudar via bitcoin-dev" <
bitcoin-dev at lists.linuxfoundation.org> wrote:

This topic has come up several times in recent years. While it is well
intentioned, it can have devastating outcomes for people that want to save
long term. If such a system were implemented, it would force people to move
funds around in order to not get nullified. In that process, it introduces
multiple opportunities for errors. Cold storage should be able to stay
cold. I personally would be apprehensive about implementing this kind of a
system.


Furthermore, if it rewards miners with funds that are expired, it creates
terrible incentives. Miners in their best interest could choose to censor
transactions that move funds close to their expiration time, to increase
their own future rewards.

Cheers,

-- 
Pieter
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171211/e43f4baa/attachment.html>

From criley at gmail.com  Mon Dec 11 18:28:03 2017
From: criley at gmail.com (Chris Riley)
Date: Mon, 11 Dec 2017 13:28:03 -0500
Subject: [bitcoin-dev] BIP - Dead Man's Switch
In-Reply-To: <CAEA=K3QiDtuHJNBLbZxaw6eSGhYWC5++vKJEX2Shxs7vb9bZ-A@mail.gmail.com>
References: <CAEA=K3QiDtuHJNBLbZxaw6eSGhYWC5++vKJEX2Shxs7vb9bZ-A@mail.gmail.com>
Message-ID: <CAL5BAw1ayaiD07PJ4MRqcKaXdet5KW131en69vbw5gebWTF8nA@mail.gmail.com>

Hi,
1. If there are 16.4 million mined and 4 million are lost, that results in
12.4 million in circulation vs 14.4 million.
2. Satoshi addressed this as have numerous other people (
https://bitcointalk.org/index.php?topic=198.msg1647#msg1647 ) - lost coins
decrease supply, increasing value of the remaining coins.
3. This assumes this is a problem.  Bitcoin is divisible, 100 million,
potentially more if necessary. (
https://en.bitcoin.it/wiki/Help:FAQ#How_divisible_are_bitcoins.3F)
4. Why is it okay to steal bitcoins from people who's bitcoins have been
"dormant" for a fixed period, 10 years in your example?
5. What happens to bitcoins that, say, Hal Finney still had (if any) and he
put in cold storage while he is in ultimate cold storage (
https://en.wikipedia.org/wiki/Hal_Finney_(computer_scientist)#Death) ?
Ditto for someone, say, in a coma for 11 years, in jail for 11 years or any
other similar event?  Or a 20 year old sets aside coins for retirement.
The following year, the system is changed, and when he looks again after
not paying attention for a decade or two, they are gone.
6. This encourages censorship by miners for people attempting to move coins.
7. This has been discussed many times before and everyone is welcome to
fork bitcoin code and the block chain and convince people to follow this
chain and code.  Then you can see if you can get many people to agree that
this is a good idea.








On Mon, Dec 11, 2017 at 12:30 PM, Teweldemedhin Aberra via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> It is estimated that about 4 million of the about 16.4 Bitcoins ever mined
> are lost forever because no one knows the private keys of some Bitcoin
> addresses. This effectively mean there are actually only 14.4 million
> Bitcoins in circulation even though 16.4 million are mined. There is no way
> of eliminating the human errors that cause these losses of Bitcoin from
> circulation, while the number of Bitcoin that will ever be mined is capped
> at 21 million. This means the total number of Bitcoins that are in
> circulation will eventually become zero, bringing the network to an end.
>
> The solution this BIP proposes is to implementing a dead man's switch to
> Bitcoin addresses. The dead man's switch causes the Bitcoins assigned to
> dormant addresses to automatically expire. A Bitcoin address is deemed
> dormant if it is not used in transactions for some fixed length of time,
> say ten years.
>
> The calculation of the miner's reward should take into account the
> Bitcoins that has expired. This means there is a possibility that miner's
> reward can increase if sufficient number of Bitcoins expire.
>
> Ref:
>
> http://fortune.com/2017/11/25/lost-bitcoins/
>
>
>
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=icon> Virus-free.
> www.avast.com
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=link>
> <#m_2495265241835744459_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171211/bae02d55/attachment-0001.html>

From luke at dashjr.org  Mon Dec 11 18:34:12 2017
From: luke at dashjr.org (Luke Dashjr)
Date: Mon, 11 Dec 2017 18:34:12 +0000
Subject: [bitcoin-dev] BIP - Dead Man's Switch
In-Reply-To: <CAEA=K3QiDtuHJNBLbZxaw6eSGhYWC5++vKJEX2Shxs7vb9bZ-A@mail.gmail.com>
References: <CAEA=K3QiDtuHJNBLbZxaw6eSGhYWC5++vKJEX2Shxs7vb9bZ-A@mail.gmail.com>
Message-ID: <201712111834.13672.luke@dashjr.org>

You can implement this already, but only for ~1 year expirations.

IF <normal script> ELSE <1 year> CHECKSEQUENCEVERIFY ENDIF

Perhaps it would make sense to propose a flag extending the range of relative 
lock-times so you can do several years?

Luke


On Monday 11 December 2017 5:30:37 PM Teweldemedhin Aberra via bitcoin-dev 
wrote:
> It is estimated that about 4 million of the about 16.4 Bitcoins ever mined
> are lost forever because no one knows the private keys of some Bitcoin
> addresses. This effectively mean there are actually only 14.4 million
> Bitcoins in circulation even though 16.4 million are mined. There is no way
> of eliminating the human errors that cause these losses of Bitcoin from
> circulation, while the number of Bitcoin that will ever be mined is capped
> at 21 million. This means the total number of Bitcoins that are in
> circulation will eventually become zero, bringing the network to an end.
> 
> The solution this BIP proposes is to implementing a dead man's switch to
> Bitcoin addresses. The dead man's switch causes the Bitcoins assigned to
> dormant addresses to automatically expire. A Bitcoin address is deemed
> dormant if it is not used in transactions for some fixed length of time,
> say ten years.
> 
> The calculation of the miner's reward should take into account the Bitcoins
> that has expired. This means there is a possibility that miner's reward can
> increase if sufficient number of Bitcoins expire.
> 
> Ref:
> 
> http://fortune.com/2017/11/25/lost-bitcoins/
> 
> 
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campa
> ign=sig-email&utm_content=webmail&utm_term=icon> Virus-free.
> www.avast.com
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campa
> ign=sig-email&utm_content=webmail&utm_term=link>
> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

From ilansky.sharkson at gmail.com  Mon Dec 11 18:37:06 2017
From: ilansky.sharkson at gmail.com (Ilan Oh)
Date: Mon, 11 Dec 2017 19:37:06 +0100
Subject: [bitcoin-dev] bitcoin-dev Digest, Vol 31, Issue 22
In-Reply-To: <CALTsm7jR=6gF+fYWAAtiK6M96oLp_KetyS9Zg9MzTxdc3U+_gw@mail.gmail.com>
References: <mailman.15635.1513017045.27509.bitcoin-dev@lists.linuxfoundation.org>
	<CALTsm7h_xHW_nne2_tGrbn3CwkKcNm0L7-h+e0uOG1jcOimauw@mail.gmail.com>
	<CALTsm7jR=6gF+fYWAAtiK6M96oLp_KetyS9Zg9MzTxdc3U+_gw@mail.gmail.com>
Message-ID: <CALTsm7iSkr7BSMT+svyh7t_bX6HNVtOdtJT_m2prWvTdGBPWig@mail.gmail.com>

Reply to dead man's switch,

Since this topic as gone un-technical,

People can already place a timer on transactions with the script to send
funds if not moved for a given period,

And people are responsible adults, trying to take ahead of every possible
future human error from the protocol perspective looks more like french
socialism than bitcoinism

Le 11 d?c. 2017 19:32, <bitcoin-dev-request at lists.linuxfoundation.org> a
?crit :

Send bitcoin-dev mailing list submissions to
        bitcoin-dev at lists.linuxfoundation.org

To subscribe or unsubscribe via the World Wide Web, visit
        https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
or, via email, send a message with subject or body 'help' to
        bitcoin-dev-request at lists.linuxfoundation.org

You can reach the person managing the list at
        bitcoin-dev-owner at lists.linuxfoundation.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of bitcoin-dev digest..."


Today's Topics:

   1. Re: BIP - Dead Man's Switch (Radoslaw Biernacki)
   2. Re: BIP - Dead Man's Switch (Pieter Wuille)
   3. Re: BIP - Dead Man's Switch (Chris Riley)


----------------------------------------------------------------------

Message: 1
Date: Mon, 11 Dec 2017 19:13:26 +0100
From: Radoslaw Biernacki <radoslaw.biernacki at gmail.com>
To: Teweldemedhin Aberra <teweldemat at gmail.com>,        Bitcoin Protocol
        Discussion <bitcoin-dev at lists.linuxfoundation.org>
Subject: Re: [bitcoin-dev] BIP - Dead Man's Switch
Message-ID:
        <CADp3C4vfL8yE4C8T5nU_qpOOLkDP+eMwM_pXmbdB0Nj0vbJHUg at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Aside from that such change would require a hard fork it also violates one
of basic rules of bitcoin, which has long term consequences for miners and
for whole Bitcoin economy. In short, after altering the supply limit it
would not be "bitcoin" anymore.

On Mon, Dec 11, 2017 at 6:30 PM, Teweldemedhin Aberra via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> It is estimated that about 4 million of the about 16.4 Bitcoins ever mined
> are lost forever because no one knows the private keys of some Bitcoin
> addresses. This effectively mean there are actually only 14.4 million
> Bitcoins in circulation even though 16.4 million are mined. There is no
way
> of eliminating the human errors that cause these losses of Bitcoin from
> circulation, while the number of Bitcoin that will ever be mined is capped
> at 21 million. This means the total number of Bitcoins that are in
> circulation will eventually become zero, bringing the network to an end.
>
> The solution this BIP proposes is to implementing a dead man's switch to
> Bitcoin addresses. The dead man's switch causes the Bitcoins assigned to
> dormant addresses to automatically expire. A Bitcoin address is deemed
> dormant if it is not used in transactions for some fixed length of time,
> say ten years.
>
> The calculation of the miner's reward should take into account the
> Bitcoins that has expired. This means there is a possibility that miner's
> reward can increase if sufficient number of Bitcoins expire.
>
> Ref:
>
> http://fortune.com/2017/11/25/lost-bitcoins/
>
>
>
> <https://www.avast.com/sig-email?utm_medium=email&utm_
source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=icon>
Virus-free.
> www.avast.com
> <https://www.avast.com/sig-email?utm_medium=email&utm_
source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=link>
> <#m_-612306741899295358_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/
attachments/20171211/82180950/attachment-0001.html>

------------------------------

Message: 2
Date: Mon, 11 Dec 2017 10:26:40 -0800
From: Pieter Wuille <pieter.wuille at gmail.com>
To: Nick Pudar <nick at pudar.com>,        Bitcoin Dev
        <bitcoin-dev at lists.linuxfoundation.org>
Subject: Re: [bitcoin-dev] BIP - Dead Man's Switch
Message-ID:
        <CAPg+sBi9nYHCcN8ct=_iqWuxDFU1cPwBfbfF8WPX-w+kf6hzfQ at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

On Dec 11, 2017 10:23, "Nick Pudar via bitcoin-dev" <
bitcoin-dev at lists.linuxfoundation.org> wrote:

This topic has come up several times in recent years. While it is well
intentioned, it can have devastating outcomes for people that want to save
long term. If such a system were implemented, it would force people to move
funds around in order to not get nullified. In that process, it introduces
multiple opportunities for errors. Cold storage should be able to stay
cold. I personally would be apprehensive about implementing this kind of a
system.


Furthermore, if it rewards miners with funds that are expired, it creates
terrible incentives. Miners in their best interest could choose to censor
transactions that move funds close to their expiration time, to increase
their own future rewards.

Cheers,

--
Pieter
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/
attachments/20171211/e43f4baa/attachment-0001.html>

------------------------------

Message: 3
Date: Mon, 11 Dec 2017 13:28:03 -0500
From: Chris Riley <criley at gmail.com>
To: Teweldemedhin Aberra <teweldemat at gmail.com>,        Bitcoin Protocol
        Discussion <bitcoin-dev at lists.linuxfoundation.org>
Subject: Re: [bitcoin-dev] BIP - Dead Man's Switch
Message-ID:
        <CAL5BAw1ayaiD07PJ4MRqcKaXdet5KW131en69vbw5gebWTF8nA at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hi,
1. If there are 16.4 million mined and 4 million are lost, that results in
12.4 million in circulation vs 14.4 million.
2. Satoshi addressed this as have numerous other people (
https://bitcointalk.org/index.php?topic=198.msg1647#msg1647 ) - lost coins
decrease supply, increasing value of the remaining coins.
3. This assumes this is a problem.  Bitcoin is divisible, 100 million,
potentially more if necessary. (
https://en.bitcoin.it/wiki/Help:FAQ#How_divisible_are_bitcoins.3F)
4. Why is it okay to steal bitcoins from people who's bitcoins have been
"dormant" for a fixed period, 10 years in your example?
5. What happens to bitcoins that, say, Hal Finney still had (if any) and he
put in cold storage while he is in ultimate cold storage (
https://en.wikipedia.org/wiki/Hal_Finney_(computer_scientist)#Death) ?
Ditto for someone, say, in a coma for 11 years, in jail for 11 years or any
other similar event?  Or a 20 year old sets aside coins for retirement.
The following year, the system is changed, and when he looks again after
not paying attention for a decade or two, they are gone.
6. This encourages censorship by miners for people attempting to move coins.
7. This has been discussed many times before and everyone is welcome to
fork bitcoin code and the block chain and convince people to follow this
chain and code.  Then you can see if you can get many people to agree that
this is a good idea.








On Mon, Dec 11, 2017 at 12:30 PM, Teweldemedhin Aberra via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> It is estimated that about 4 million of the about 16.4 Bitcoins ever mined
> are lost forever because no one knows the private keys of some Bitcoin
> addresses. This effectively mean there are actually only 14.4 million
> Bitcoins in circulation even though 16.4 million are mined. There is no
way
> of eliminating the human errors that cause these losses of Bitcoin from
> circulation, while the number of Bitcoin that will ever be mined is capped
> at 21 million. This means the total number of Bitcoins that are in
> circulation will eventually become zero, bringing the network to an end.
>
> The solution this BIP proposes is to implementing a dead man's switch to
> Bitcoin addresses. The dead man's switch causes the Bitcoins assigned to
> dormant addresses to automatically expire. A Bitcoin address is deemed
> dormant if it is not used in transactions for some fixed length of time,
> say ten years.
>
> The calculation of the miner's reward should take into account the
> Bitcoins that has expired. This means there is a possibility that miner's
> reward can increase if sufficient number of Bitcoins expire.
>
> Ref:
>
> http://fortune.com/2017/11/25/lost-bitcoins/
>
>
>
> <https://www.avast.com/sig-email?utm_medium=email&utm_
source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=icon>
Virus-free.
> www.avast.com
> <https://www.avast.com/sig-email?utm_medium=email&utm_
source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=link>
> <#m_2495265241835744459_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/
attachments/20171211/bae02d55/attachment.html>

------------------------------

_______________________________________________
bitcoin-dev mailing list
bitcoin-dev at lists.linuxfoundation.org
https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev


End of bitcoin-dev Digest, Vol 31, Issue 22
*******************************************
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171211/f7f49918/attachment-0001.html>

From jim.posen at gmail.com  Mon Dec 11 20:40:00 2017
From: jim.posen at gmail.com (Jim Posen)
Date: Mon, 11 Dec 2017 12:40:00 -0800
Subject: [bitcoin-dev] "Compressed" headers stream
Message-ID: <CADZtCShywq_s9ZK3oBBTUdCgjrTxbyeb-p7QrhJJ3mwRAECCMA@mail.gmail.com>

I want to resurrect this thread from August/September because it seems like
a significant improvement for light clients at very little cost. From the
mailing list, it seems like this got stalled in determining how many more
bytes could be save in addition to the prev_block.

The ideas I've gathered from Greg Maxwell's forwarded email are:

1. Omit nBits altogether and have the receiving node determine it from
chain context.
2. Include nBits only on headers with a height that is a multiple of 2016
since it does not change in between.
3. Compress nTime to two bytes by using the bounds on allowed values from
the consensus rules.

I propose just moving ahead with only the exclusion of the prev_block, as
IMO the other savings are not worth the added complexity.

Firstly, I don't like the idea of making the net header encoding dependent
on the specific header validation rules that Bitcoin uses (eg. the fact
that difficulty is only recalculated every 2016 blocks). This would be
coupling together the two layers, breaking net compatibility for some alts,
and possibly making consensus rule changes even more difficult for a
savings with insufficient benefit. So if you buy that argument, I'm not in
favor of #2 or #3.

Option 1 is still viable, though it has some downsides. The implementation
leaks into the validation code, whereas calculating prev_block can occur
just at the net layer (see implementation below). Also, nodes would now be
*required* to sync the header chain from the genesis block, whereas they
had the option of starting from some checkpoint before.

So switching gears, I'd like to ask what the best way to actually implement
this change is. Solutions I can think of are:

1. New headers command name like "cmpctheaders" or "headersv2".
2. Change serialization of existing headers message in a new protocol
version.
3. Change serialization of existing headers message with new service bit.

I wrote up some proof-of-concept implementations in Core a) just omitting
prev_block
<https://github.com/bitcoin/bitcoin/compare/master...jimpo:compact-headers>
and b) omitting nBits as well
<https://github.com/bitcoin/bitcoin/compare/master...jimpo:compact-headers-difficulty>.
If people think a) is reasonable, I'll write up a BIP.


> Hi everyone, the Bitcoin headers are probably the most condensed and
> important piece of data in the world, their demand is expected to grow.
> When sending a stream of continuous block headers, a common case in IBD and
> in disconnected clients, I think there is a possible optimization of the
> transmitted data: The headers after the first could avoid transmitting the
> previous hash cause the receiver could compute it by double hashing the
> previous header (an operation he needs to do anyway to verify PoW). In a
> long stream, for example 2016 headers, the savings in bandwidth are about
> 32/80 ~= 40% without compressed headers 2016*80=161280 bytes with
> compressed headers 80+2015*48=96800 bytes What do you think? In
> OpenTimestamps calendars we are going to use this compression to give
> lite-client a reasonable secure proofs (a full node give higher security
> but isn't feasible in all situations, for example for in-browser
> verification) To speed up sync of a new client Electrum starts with the
> download of a file <https://headers.electrum.org/blockchain_headers>
> ~36MB containing the first 477637 headers. For this kind of clients could
> be useful a common http API with fixed position chunks to leverage http
> caching. For example /headers/2016/0 returns the headers from the genesis
> to the 2015 header included while /headers/2016/1 gives the headers from
> the 2016th to the 4031. Other endpoints could have chunks of 20160 blocks
> or 201600 such that with about 10 http requests a client could fast sync
> the headers
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171211/86e7642f/attachment.html>

From greg at xiph.org  Mon Dec 11 21:04:01 2017
From: greg at xiph.org (Gregory Maxwell)
Date: Mon, 11 Dec 2017 21:04:01 +0000
Subject: [bitcoin-dev] "Compressed" headers stream
In-Reply-To: <CADZtCShywq_s9ZK3oBBTUdCgjrTxbyeb-p7QrhJJ3mwRAECCMA@mail.gmail.com>
References: <CADZtCShywq_s9ZK3oBBTUdCgjrTxbyeb-p7QrhJJ3mwRAECCMA@mail.gmail.com>
Message-ID: <CAAS2fgROykenGH43_FXun+q4u+=94tKqnRW=kQQ2AQFeXKdW=Q@mail.gmail.com>

On Mon, Dec 11, 2017 at 8:40 PM, Jim Posen via bitcoin-dev
<bitcoin-dev at lists.linuxfoundation.org> wrote:
> Firstly, I don't like the idea of making the net header encoding dependent
> on the specific header validation rules that Bitcoin uses (eg. the fact that
> difficulty is only recalculated every 2016 blocks). This would be coupling

In the last proposal I recall writing up, there was a one byte flag on
each header to indicate what was included.

Nbits _never_ needs to be sent even with other consensus rules because
its more or less necessarily a strict function of the prior headers.
This still holds in every clone of Bitcoin I'm aware of; sending it
with the first header in a group probably makes sense so it can be
checked independently.

> with insufficient benefit.

another >18% reduction in size beyond the removal of prev. is not
insubstantial by any means.  I don't think it should lightly be
ignored.

Prev omission itself is not, sadly, magically compatible:  I am quite
confident that if there is a bitcoin hardfork it would recover the
nbits/4-guarenteed always-zero bits of prev to use as extra nonce for
miners. This has been proposed many times, implemented at least once,
and the current requirement for mining infrastructure to reach inside
the coinbase txn to increment a nonce has been a reliable source of
failures.  So I think we'd want to have the encoding able to encode
leading prev bits.

Many altcoins also change the header structures. If the better thing
is altcoin incompatible, we should still do it. Doing otherwise would
competitively hobble Bitcoin especially considering the frequent
recklessly incompetent moves made by various altcoins and the near
total lack of useful novel development we've seen come out of the
clones.

Probably the most important change in a new header message wouldn't be
the encoding, but it would be changing the fetching mechanism so that
header sets could be pulled in parallel, etc.

I would rather not change the serialization of existing messages,
nodes are going to have to support speaking both messages for a long
time, and I think we already want a different protocol flow for
headers fetching in any case.

From jim.posen at gmail.com  Mon Dec 11 21:56:08 2017
From: jim.posen at gmail.com (Jim Posen)
Date: Mon, 11 Dec 2017 13:56:08 -0800
Subject: [bitcoin-dev] "Compressed" headers stream
In-Reply-To: <CAAS2fgROykenGH43_FXun+q4u+=94tKqnRW=kQQ2AQFeXKdW=Q@mail.gmail.com>
References: <CADZtCShywq_s9ZK3oBBTUdCgjrTxbyeb-p7QrhJJ3mwRAECCMA@mail.gmail.com>
	<CAAS2fgROykenGH43_FXun+q4u+=94tKqnRW=kQQ2AQFeXKdW=Q@mail.gmail.com>
Message-ID: <CADZtCSi1vimZ88kqG=HQHa3sHeLtvMjdJrZuqS2=iYr-=EHaLw@mail.gmail.com>

On Mon, Dec 11, 2017 at 1:04 PM, Gregory Maxwell <greg at xiph.org> wrote:

> On Mon, Dec 11, 2017 at 8:40 PM, Jim Posen via bitcoin-dev
> <bitcoin-dev at lists.linuxfoundation.org> wrote:
> > Firstly, I don't like the idea of making the net header encoding
> dependent
> > on the specific header validation rules that Bitcoin uses (eg. the fact
> that
> > difficulty is only recalculated every 2016 blocks). This would be
> coupling
>
> In the last proposal I recall writing up, there was a one byte flag on
> each header to indicate what was included.
>
>
Is there a link somewhere to that proposal? The only thing I could find was
your forwarded email
<https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-September/014904.html>
on
this thread.


> Nbits _never_ needs to be sent even with other consensus rules because
> its more or less necessarily a strict function of the prior headers.
> This still holds in every clone of Bitcoin I'm aware of; sending it
> with the first header in a group probably makes sense so it can be
> checked independently.
>
> > with insufficient benefit.
>
> another >18% reduction in size beyond the removal of prev. is not
> insubstantial by any means.  I don't think it should lightly be
> ignored.
>
>
Omitting nBits entirely seems reasonable, I wrote up a possible
implementation here
<https://github.com/bitcoin/bitcoin/compare/master...jimpo:compact-headers-difficulty>.
The downside is that it is more complex because it leaks into the
validation code. The extra 4 byte savings is certainly nice though.


> Prev omission itself is not, sadly, magically compatible:  I am quite
> confident that if there is a bitcoin hardfork it would recover the
> nbits/4-guarenteed always-zero bits of prev to use as extra nonce for
> miners. This has been proposed many times, implemented at least once,
> and the current requirement for mining infrastructure to reach inside
> the coinbase txn to increment a nonce has been a reliable source of
> failures.  So I think we'd want to have the encoding able to encode
> leading prev bits.
>
> Many altcoins also change the header structures. If the better thing
> is altcoin incompatible, we should still do it. Doing otherwise would
> competitively hobble Bitcoin especially considering the frequent
> recklessly incompetent moves made by various altcoins and the near
> total lack of useful novel development we've seen come out of the
> clones.
>
> Probably the most important change in a new header message wouldn't be
> the encoding, but it would be changing the fetching mechanism so that
> header sets could be pulled in parallel, etc.
>
> I would rather not change the serialization of existing messages,
> nodes are going to have to support speaking both messages for a long
> time, and I think we already want a different protocol flow for
> headers fetching in any case.
>

Can you elaborate on how parallel header fetching might work? getheaders
requests could probably already be pipelined, where the node requests the
next 2,000 headers before processing the current batch (though would make
sense to check that they are all above min difficulty first).

I'm open to more ideas on how to optimize the header download or design the
serialization format to be more flexible, but I'm concerned that we forgo a
40-45% bandwidth savings on the current protocol for a long time because
something better might be possible later on or there might be a hard fork
that at some point requires another upgrade. I do recognize that supporting
multiple serialization formats simultaneously adds code complexity, but in
this case the change seems simple enough to me that the tradeoff is worth
it.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171211/995788a9/attachment-0001.html>

From pulat at yunusov.org  Mon Dec 11 22:23:21 2017
From: pulat at yunusov.org (Pulat Yunusov)
Date: Mon, 11 Dec 2017 22:23:21 +0000
Subject: [bitcoin-dev] Scalable Semi-Trustless Asset Transfer via
 Single-Use-Seals and Proof-of-Publication
In-Reply-To: <20171205101551.GA10265@fedora-23-dvm>
References: <20171205101551.GA10265@fedora-23-dvm>
Message-ID: <CAC08FKvbbOsYWLieS+kgsdZByFiFXuQbBs1trvHuDAdG35HXkA@mail.gmail.com>

Thank you for your post, Peter. Why is it necessary to centralize the p-o-p
sidechain and have a maintainer? It seems the Bitcoin network will secure
the most critical element, which is the witness authenticity. Wouldn't a
second decentralized network be able to perform the functions of the
maintainer so the entire system is trustless?

On Tue, Dec 5, 2017 at 5:16 AM Peter Todd via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> I recently wrote this up for a client, and although the material has been
> covered elsewhere, I thought being a worked example it might be of
> interest,
> particularly while sidechains are being discussed again.
>
> As per (1) I've perhaps foolishly committed to making an even more fleshed
> out
> example, so peer review here before it gets to an even wider audience
> would be
> appreciated. :)
>
> 1) https://twitter.com/petertoddbtc/status/937401676042039296
>
>
> tl;dr: We can do trustless with respect to validity, trusted with respect
> to
> censorship resistance, indivisible asset transfer with less than
> 5MB/year/token
> of proof data, assuming token ownership is updated every two hours, at a
> rate
> of ~500,000 transfers per second. The scalability of this scheme is linear
> with
> respect to update interval, and logarithmic with respect to overall
> transfer
> rate.
>
>
> ## Single-Use-Seal Definition
>
> Analogous to the real-world, physical, single-use-seals used to secure
> shipping
> containers, a single-use-seal primitive is a unique object that can be
> closed
> over a message exactly once. In short, a single-use-seal is an abstract
> mechanism to prevent double-spends.
>
> A single-use-seal implementation supports two fundamental operations:
>
>     Close(l,m) -> w_l
>         Close seal l over message m, producing a witness w_l
>
>     Verify(l,w_l,m) -> bool
>         Verify that the seal l was closed over message m
>
> A single-use-seal implementation is secure if it is impossible for an
> attacker
> to cause the Verify function to return true for two distinct messages m_1,
> m_2,
> when applied to the same seal (it _is_ acceptable, although non-ideal, for
> there to exist multiple witnesses for the same seal/message pair).
>
> Practical single-use-seal implementations will also obviously require some
> way
> of generating new single-use-seals. Secondly, authentication is generally
> useful. Thus we have:
>
>     Gen(p) -> l
>         Generate a new seal bound to pubkey p
>
>     Close(l,m,s) -> w_l
>         Close seal l over message m, authenticated by signature s valid
> for pubkey p
>
> Obviously, in the above, pubkey can be replaced by any cryptographic
> identity
> scheme, such as a Bitcoin-style predicate script, zero-knowledge proof,
> etc.
>
> Finally, _some_ single-use-seal implementations may support the ability to
> prove that a seal is _open_, e.g. as of a given block height or point in
> time.
> This however is optional, and as it can be difficult to implement, it is
> suggested that seal-using protocols avoid depending on this functionality
> existing.
>
>
> ## Indivisible Token Transfer
>
> With a secure single-use-seal primitive we can build a indivisible token
> transfer system, allowing the secure transfer of a token from one party to
> another, with the seals preventing double-spends of that indivisible token.
>
> Each token is identified by its genesis seal l_0. To transfer a token, the
> most
> recent seal l_n is closed over a message committing to a new seal, l_{n+1},
> producing a witness w_{l_n} attesting to that transfer. This allows a
> recipient
> to securely verify that they have received the desired token as follows:
>
> 1. Generate a fresh, open, seal l_{n+1} that only they can close.
> 2. Ask the sender to close their seal, l_n, over the seal l_{n+1}
> 3. Verify that there exist a set of valid witnesses w_0 .. w_n, and seals
>    l_0 .. l_n, such that for each seal l_i in i = 0 .. n, Verify(l_i, w_i,
> l_{i+1})
>    returns true.
>
> Since a secure single-use-seal protocol prohibits the closure of a single
> seal
> over multiple messages, the above protocol ensures that the token can not
> be
> double-spent. Secondly, by ensuring that seal l_{n+1} can be closed by the
> recipient and only the recipient, the receipient of the token knows that
> they
> and they alone have the ability to send that token to the next owner.
>
>
> ## Divisible Asset Transfer
>
> In the case of a divisible asset, rather than transferring a single,
> unique,
> token we want to transfer a _quantity_ of an asset. We can accomplish this
> in a
> manner similar how Bitcoin's UTXO-based transactions, in which one or more
> inputs are combined in a single transaction, then split amongst zero or
> more
> outputs.
>
> We define the concept of an _output_. Each output x is associated with a
> seal l
> and value v. For each asset we define a set of _genesis outputs_, X_G,
> whose
> validity is assumed.
>
> To transfer divisible assets we further define the concepts of a _spend_
> and a
> _split_. A spend, D, is a commitment to a set of outputs x_i .. x_j; the
> value
> of a spend is simply the sum of the values of all outputs in the spend. A
> split
> commitments to a set of zero or seal/value, (l_i,v_i), tuples, with the sum
> value of the split being the sum of a values in the split.
>
> Spends and splits are used to define a _split output_. While a genesis
> output
> is simply assumed valid, a split output x is then the tuple (D,V,i),
> committing
> to a spend D, split V, and within that split, a particular output i.
>
> A split output is valid if:
>
> 1. Each output in the spend set D is a valid output.
> 2. The sum value of the spend set D is >= the sum value of the split V.
> 3. i corresponds to a valid output in the split.
> 4. There exists a set of witnesses w_i .. w_j, such that each seal in the
> spend
>    set closed over the message (D,V) (the spend and split).
>
> As with the indivisible asset transfer, a recipient can verify that an
> asset
> has been securely transferred to them by generating a fresh seal, asking
> the
> sender to create a new split output for that seal and requested output
> amount,
> and verifying that the newly created split output is in fact valid. As with
> Bitcoin transactions, in most transfers will also result in a change
> output.
>
> Note how an actual implementation can usefully use a merkle-sum-tree to
> commit
> to the split set, allowing outputs to be proven to the recipient by giving
> only
> a single branch of the tree, with other outputs pruned. This can have both
> efficiency and privacy advantages.
>
>
>
> ## Single-Use-Seal Implementation
>
> An obvious single-use-seal implementation is to simply have a trusted
> notary,
> with each seal committing to that notary's identity, and witnesses being
> cryptographic signatures produced by that notary. A further obvious
> refinement
> is to use disposable keys, with a unique private key being generated by the
> notary for each seal, and the private key being securely destroyed when the
> seal is closed.
>
> Secondly Bitcoin (or similar) transaction outputs can implement
> single-use-seals, with each seal being uniquely identified by outpoint
> (txid:n), and witnesses being transactions spending that outpoint in a
> specified way (e.g. the first output being an OP_RETURN committing to the
> message).
>
>
> ### Proof-of-Publication Ledger
>
> For a scalable, trust-minimized, single-use-seal implementation we can use
> a
> proof-of-publication ledger, where consensus over the state of the ledger
> is
> achieved with a second single-use-seal implementation (e.g. Bitcoin).
>
> Such a ledger is associated with a genesis seal, L_0, with each entry M_i
> in
> the ledger being committed by closing the most recent seal over that entry,
> producing W_i such that Verify(L_i, (L_{i+1}, M_i), W_i) returns true.
> Thus we achieve consensus over the state of the ledger as we can prove the
> contents of the ledger.
>
> Specifically, given starting point L_i we can prove that the subsequent
> ledger
> entries M_i .. M_j are valid with witnesses W_i .. W_j and seals L_{i+1}
> .. L_{j+1}.
>
> A proof-of-publication-based seal can then be constructed via the tuple
> (L_i,
> p), where L_i is one of the ledger's seals, and p is a pubkey (or
> similar). To
> close a proof-of-publication ledger seal a valid signature for that pubkey
> and
> message m is published in the ledger in entry M_j.
>
> Thus the seal witness is proof that:
>
> 1. Entry M_j contained a valid signature by pubkey p, for message m.
> 2. All prior entries M_i .. M_{j-1} (possibly an empty set) did _not_
> contain
>    valid signatures.
>
> Finally, for the purpose of scalability, instead of each ledger entry M_i
> consisting of a unstructured message, we can instead commit to a merkelized
> key:value tree, with each key being a pubkey p, and each value being an
> alleged signature (possibly invalid). Now the non-publication condition is
> proven by showing that either:
>
> 1. Tree M_i does not contain key p.
> 2. Tree M_i does contain key p, but alleged signature s is invalid.
>
> The publication condition is proven by showing that tree M_j does contain
> key
> p, and that key is associated with valid signature s.
>
> A merkelized key:value tree can prove both statements with a log2(n) sized
> proof, and thus we achieve log2(n) size scalability, with the constant
> factor
> growing by the age of the seals, the ledger update frequency, the rate at
> which
> seals are closed, and the maximum size allowed for signatures.
>
> Note how a number of simple optimizations are possible, such as preventing
> the
> creation of "spam" invalid signatures by blinding the actual pubkey with a
> nonce, ensuring only valid signatures are published, etc. Also note how it
> is
> _not_ necessary to validate all entries in the ledger form a chain: the
> single-use-seals guarantees that a particular range of ledger entries will
> be
> unique, regardless of whether all ledger history was unique.
>
> Proof-of-Publication ledgers are trustless with regard to false seal
> witnesses:
> the ledger maintainer(s) are unable to falsify a witness because they are
> unable to produce a valid signature. They are however trusted with regard
> to
> censorship: the ledger maintainer can prevent the publication of a
> signature
> and/or or withhold data necessary to prove the state of the seal.
>
>
> # Performance Figures
>
> Assume a indivisible token transfer via a PoP ledger using Bitcoin-based
> single-use-seals, with the ledger updated 12 times a day (every two hours).
> Assume each ledger update corresponds to 2^32, 4 billion, transfers.
>
> The data required to prove publication/non-publication for a given ledger
> update is less than:
>
>     lite-client BTC tx proof:                            = ~1KB
>     merkle path down k/v tree: 32 levels * 32bytes/level =  1KB
>     key/value: 32 bytes predicate hash + 1KB script sig  = ~1KB
>                                                    Total = ~3KB/ledger
> update
>
>         * 356 days/year * 12 updates/day = 13MB/year
>
> Now, those are *absolute worst case* numbers, and there's a number of ways
> that
> they can be substantially reduced such as only publishing valid
> signatures, or
> just assuming you're not being attacked constantly... Also, note how for a
> client with multiple tokens, much of the data can be shared amongst each
> token.
> But even then, being able to prove the ownership status of a token, in a
> trustless fashion, with just 13MB/year of data is an excellent result for
> many
> use-cases.
>
> With these optimizations, the marginal cost per token after the first one
> is
> just 1KB/ledger update, 4.4MB/year.
>
> --
> https://petertodd.org 'peter'[:-1]@petertodd.org
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171211/8d130370/attachment.html>

From tier.nolan at gmail.com  Mon Dec 11 22:41:50 2017
From: tier.nolan at gmail.com (Tier Nolan)
Date: Mon, 11 Dec 2017 22:41:50 +0000
Subject: [bitcoin-dev] "Compressed" headers stream
In-Reply-To: <CADZtCSi1vimZ88kqG=HQHa3sHeLtvMjdJrZuqS2=iYr-=EHaLw@mail.gmail.com>
References: <CADZtCShywq_s9ZK3oBBTUdCgjrTxbyeb-p7QrhJJ3mwRAECCMA@mail.gmail.com>
	<CAAS2fgROykenGH43_FXun+q4u+=94tKqnRW=kQQ2AQFeXKdW=Q@mail.gmail.com>
	<CADZtCSi1vimZ88kqG=HQHa3sHeLtvMjdJrZuqS2=iYr-=EHaLw@mail.gmail.com>
Message-ID: <CAE-z3OUetqa16Ub792dCXodpzafsgMyvO9QaVNWJ3bKZ59HWVQ@mail.gmail.com>

On Mon, Dec 11, 2017 at 9:56 PM, Jim Posen via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Omitting nBits entirely seems reasonable, I wrote up a possible
> implementation here
> <https://github.com/bitcoin/bitcoin/compare/master...jimpo:compact-headers-difficulty>.
> The downside is that it is more complex because it leaks into the
> validation code. The extra 4 byte savings is certainly nice though.
>

A compromise would be to have 1 byte indicating the difference since the
last header.

Since the exponent doesn't use the full range you could steal bits from
there to indicate mode.

- no change
- mantissa offset (for small changes)
- full difficulty

This would support any nBits rule and you say 3 of the 4 bytes.


> Can you elaborate on how parallel header fetching might work? getheaders
> requests could probably already be pipelined, where the node requests the
> next 2,000 headers before processing the current batch (though would make
> sense to check that they are all above min difficulty first).
>

I suggest adding a message where you can ask for the lowest N hashes
between 2 heights on the main chain.

The reply is an array of {height, header} pairs for the N headers with the
lowest hash in the specified range.

All peers should agree on which headers are in the array.  If there is
disagreement, then you can at least narrow down on which segment there is
disagreement.

It works kind of like a cut and choose.  You pick one segment of the ones
he gave you recursively.

You can ask a peer for proof for a segment between 2 headers of the form.

- first header + coinbase with merkle branch
- all headers in the segment

This proves the segment has the correct height and that all the headers
link up.

There is a method called "high hash highway" that allows compact proofs of
total POW.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171211/76d17ddf/attachment-0001.html>

From greg at xiph.org  Mon Dec 11 23:11:24 2017
From: greg at xiph.org (Gregory Maxwell)
Date: Mon, 11 Dec 2017 23:11:24 +0000
Subject: [bitcoin-dev] "Compressed" headers stream
In-Reply-To: <CAE-z3OUetqa16Ub792dCXodpzafsgMyvO9QaVNWJ3bKZ59HWVQ@mail.gmail.com>
References: <CADZtCShywq_s9ZK3oBBTUdCgjrTxbyeb-p7QrhJJ3mwRAECCMA@mail.gmail.com>
	<CAAS2fgROykenGH43_FXun+q4u+=94tKqnRW=kQQ2AQFeXKdW=Q@mail.gmail.com>
	<CADZtCSi1vimZ88kqG=HQHa3sHeLtvMjdJrZuqS2=iYr-=EHaLw@mail.gmail.com>
	<CAE-z3OUetqa16Ub792dCXodpzafsgMyvO9QaVNWJ3bKZ59HWVQ@mail.gmail.com>
Message-ID: <CAAS2fgRA7D5AsB6cbyiEe2BGReQ3QHOTeyH62bGbOtk_UHx4CQ@mail.gmail.com>

On Mon, Dec 11, 2017 at 10:41 PM, Tier Nolan via bitcoin-dev
<bitcoin-dev at lists.linuxfoundation.org> wrote:
> There is a method called "high hash highway" that allows compact proofs of
> total POW.

That provides no security without additional consensus enforced
commitments, so I think pretty off-topic for this discussion.

From pete at petertodd.org  Mon Dec 11 23:16:19 2017
From: pete at petertodd.org (Peter Todd)
Date: Mon, 11 Dec 2017 18:16:19 -0500
Subject: [bitcoin-dev] Scalable Semi-Trustless Asset Transfer via
 Single-Use-Seals and Proof-of-Publication
In-Reply-To: <CAC08FKvbbOsYWLieS+kgsdZByFiFXuQbBs1trvHuDAdG35HXkA@mail.gmail.com>
References: <20171205101551.GA10265@fedora-23-dvm>
	<CAC08FKvbbOsYWLieS+kgsdZByFiFXuQbBs1trvHuDAdG35HXkA@mail.gmail.com>
Message-ID: <20171211231619.GA22761@savin.petertodd.org>

On Mon, Dec 11, 2017 at 10:23:21PM +0000, Pulat Yunusov wrote:
> Thank you for your post, Peter. Why is it necessary to centralize the p-o-p
> sidechain and have a maintainer? It seems the Bitcoin network will secure
> the most critical element, which is the witness authenticity. Wouldn't a
> second decentralized network be able to perform the functions of the
> maintainer so the entire system is trustless?

It's centralized in that writeup basically because centralizing it is
*significantly* easier; it's not obvious how to maintain a proof-of-publication
ledger in a decentralized, scalable, way.

In the centralized version it's obvious how to scale process by which the
ledger is built via sharding: split the key range up as needed and assign each
range to a separate server (be it an actual server, or a fault-tolerate cluster
acting as a single server) that reports back to a master co-ordinator who
builds the tree from the per-range sub-tips reported back by the shards. If
required due to extreme scale, do this on multiple levels. Similarly, once the
tree is built, storage and distribution can obviously be done via sharding.

In short, no matter how much the transaction rate on a PoP ledger grows, it's
possible to meet demand by simply buying more hardware, and distributing the
key space over a larger number of smaller shards.

But that simple architecture only works with trust: the coordinator is trusting
the shards to build valid trees and distribute the results. Without trust, how
do you ensure that actually happens? How do you pick who is assigned to what
shard? How do you incentivise correct behavior?

That's not to say this is impossible - in fact my prior work on Treechains(1)
is an attempt to do just this - but it's an orders of magnitude more difficult
problem.

1) https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2014-March/004797.html,
   "[Bitcoin-development] Tree-chains preliminary summary", Mar 25th 2014,
   Peter Todd

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 455 bytes
Desc: Digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171211/9f7f9401/attachment.sig>

From teweldemat at gmail.com  Tue Dec 12 01:10:38 2017
From: teweldemat at gmail.com (Teweldemedhin Aberra)
Date: Tue, 12 Dec 2017 04:10:38 +0300
Subject: [bitcoin-dev] BIP - Dead Man's Switch
In-Reply-To: <201712111834.13672.luke@dashjr.org>
References: <CAEA=K3QiDtuHJNBLbZxaw6eSGhYWC5++vKJEX2Shxs7vb9bZ-A@mail.gmail.com>
	<201712111834.13672.luke@dashjr.org>
Message-ID: <CAEA=K3TTrMUgfFR0jjYxQS+BU5b+=7nNhT4wEUeUEtnOEP80Dw@mail.gmail.com>

Hi,
The only solution other than Dead Man's Switch to avoid gradual loss
Bitcoins in transaction is increasing the divisibiliy of Bitcoins. Then
Bitcoin values will need integer of more than 64 bits. Could that be done
with soft fork?

On Dec 11, 2017 9:42 PM, <bitcoin-dev-request at lists.linuxfoundation.org>
wrote:

> You can implement this already, but only for ~1 year expirations.
>
> IF <normal script> ELSE <1 year> CHECKSEQUENCEVERIFY ENDIF
>
> Perhaps it would make sense to propose a flag extending the range of
> relative
> lock-times so you can do several years?
>
> Luke
>
>
> On Monday 11 December 2017 5:30:37 PM Teweldemedhin Aberra via bitcoin-dev
> wrote:
> > It is estimated that about 4 million of the about 16.4 Bitcoins ever
> mined
> > are lost forever because no one knows the private keys of some Bitcoin
> > addresses. This effectively mean there are actually only 14.4 million
> > Bitcoins in circulation even though 16.4 million are mined. There is no
> way
> > of eliminating the human errors that cause these losses of Bitcoin from
> > circulation, while the number of Bitcoin that will ever be mined is
> capped
> > at 21 million. This means the total number of Bitcoins that are in
> > circulation will eventually become zero, bringing the network to an end.
> >
> > The solution this BIP proposes is to implementing a dead man's switch to
> > Bitcoin addresses. The dead man's switch causes the Bitcoins assigned to
> > dormant addresses to automatically expire. A Bitcoin address is deemed
> > dormant if it is not used in transactions for some fixed length of time,
> > say ten years.
> >
> > The calculation of the miner's reward should take into account the
> Bitcoins
> > that has expired. This means there is a possibility that miner's reward
> can
> > increase if sufficient number of Bitcoins expire.
> >
> > Ref:
> >
> > http://fortune.com/2017/11/25/lost-bitcoins/
> >
> >
> > <https://www.avast.com/sig-email?utm_medium=email&utm_
> source=link&utm_campa
> > ign=sig-email&utm_content=webmail&utm_term=icon> Virus-free.
> > www.avast.com
> > <https://www.avast.com/sig-email?utm_medium=email&utm_
> source=link&utm_campa
> > ign=sig-email&utm_content=webmail&utm_term=link>
> > <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171212/b54aa852/attachment.html>

From ricardojdfilipe at gmail.com  Tue Dec 12 14:02:12 2017
From: ricardojdfilipe at gmail.com (Ricardo Filipe)
Date: Tue, 12 Dec 2017 14:02:12 +0000
Subject: [bitcoin-dev] BIP - Dead Man's Switch
In-Reply-To: <5a2f9240.0abddf0a.0333.1139@mx.google.com>
References: <CAEA=K3QiDtuHJNBLbZxaw6eSGhYWC5++vKJEX2Shxs7vb9bZ-A@mail.gmail.com>
	<201712111834.13672.luke@dashjr.org>
	<CAEA=K3TTrMUgfFR0jjYxQS+BU5b+=7nNhT4wEUeUEtnOEP80Dw@mail.gmail.com>
	<CALC81COEqhkX04MyJ=hxGgapVTqSeSYXJJUgutxWp5GbZmSSmQ@mail.gmail.com>
	<5a2f9240.0abddf0a.0333.1139@mx.google.com>
Message-ID: <CALC81CO20c=PvCj9bk0YxSD2jKxErfyXqWtKwxdC8_qv8J9wSw@mail.gmail.com>

You can do it on 2nd layer solutions such as the lightning network,
with their own format.
On the base layer you cannot do it without a hard fork, or it would
undermine the invariants of bitcoin.

2017-12-12 8:24 GMT+00:00 Teweldemedhin Aberra <teweldemat at gmail.com>:
> How?
>
>
>
> From: Ricardo Filipe
> Sent: Tuesday, December 12, 2017 4:44 AM
> To: Teweldemedhin Aberra; Bitcoin Protocol Discussion
> Subject: Re: [bitcoin-dev] BIP - Dead Man's Switch
>
>
>
> yes
>
>
>
> 2017-12-12 1:10 GMT+00:00 Teweldemedhin Aberra via bitcoin-dev
>
> <bitcoin-dev at lists.linuxfoundation.org>:
>
>> Hi,
>
>> The only solution other than Dead Man's Switch to avoid gradual loss
>
>> Bitcoins in transaction is increasing the divisibiliy of Bitcoins. Then
>
>> Bitcoin values will need integer of more than 64 bits. Could that be done
>
>> with soft fork?
>
>>
>
>> On Dec 11, 2017 9:42 PM, <bitcoin-dev-request at lists.linuxfoundation.org>
>
>> wrote:
>
>>>
>
>>> You can implement this already, but only for ~1 year expirations.
>
>>>
>
>>> IF <normal script> ELSE <1 year> CHECKSEQUENCEVERIFY ENDIF
>
>>>
>
>>> Perhaps it would make sense to propose a flag extending the range of
>
>>> relative
>
>>> lock-times so you can do several years?
>
>>>
>
>>> Luke
>
>>>
>
>>>
>
>>> On Monday 11 December 2017 5:30:37 PM Teweldemedhin Aberra via
>>> bitcoin-dev
>
>>> wrote:
>
>>> > It is estimated that about 4 million of the about 16.4 Bitcoins ever
>
>>> > mined
>
>>> > are lost forever because no one knows the private keys of some Bitcoin
>
>>> > addresses. This effectively mean there are actually only 14.4 million
>
>>> > Bitcoins in circulation even though 16.4 million are mined. There is no
>
>>> > way
>
>>> > of eliminating the human errors that cause these losses of Bitcoin from
>
>>> > circulation, while the number of Bitcoin that will ever be mined is
>
>>> > capped
>
>>> > at 21 million. This means the total number of Bitcoins that are in
>
>>> > circulation will eventually become zero, bringing the network to an
>>> > end.
>
>>> >
>
>>> > The solution this BIP proposes is to implementing a dead man's switch
>>> > to
>
>>> > Bitcoin addresses. The dead man's switch causes the Bitcoins assigned
>>> > to
>
>>> > dormant addresses to automatically expire. A Bitcoin address is deemed
>
>>> > dormant if it is not used in transactions for some fixed length of
>>> > time,
>
>>> > say ten years.
>
>>> >
>
>>> > The calculation of the miner's reward should take into account the
>
>>> > Bitcoins
>
>>> > that has expired. This means there is a possibility that miner's reward
>
>>> > can
>
>>> > increase if sufficient number of Bitcoins expire.
>
>>> >
>
>>> > Ref:
>
>>> >
>
>>> > http://fortune.com/2017/11/25/lost-bitcoins/
>
>>> >
>
>>> >
>
>>> >
>
>>> >
>>> > <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campa
>
>>> > ign=sig-email&utm_content=webmail&utm_term=icon> Virus-free.
>
>>> > www.avast.com
>
>>> >
>
>>> >
>>> > <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campa
>
>>> > ign=sig-email&utm_content=webmail&utm_term=link>
>
>>> > <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
>>
>
>>
>
>> _______________________________________________
>
>> bitcoin-dev mailing list
>
>> bitcoin-dev at lists.linuxfoundation.org
>
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>>
>
>

From sdaftuar at gmail.com  Tue Dec 12 21:07:11 2017
From: sdaftuar at gmail.com (Suhas Daftuar)
Date: Tue, 12 Dec 2017 16:07:11 -0500
Subject: [bitcoin-dev] "Compressed" headers stream
In-Reply-To: <CAAS2fgROykenGH43_FXun+q4u+=94tKqnRW=kQQ2AQFeXKdW=Q@mail.gmail.com>
References: <CADZtCShywq_s9ZK3oBBTUdCgjrTxbyeb-p7QrhJJ3mwRAECCMA@mail.gmail.com>
	<CAAS2fgROykenGH43_FXun+q4u+=94tKqnRW=kQQ2AQFeXKdW=Q@mail.gmail.com>
Message-ID: <CAFp6fsHwdAbcYVdPzuDdD1OV7ibCN-ebMBi113m5-JOoJtccPQ@mail.gmail.com>

Hi,

First, thanks for resurrecting this, I agree this is worth pursuing.

On Mon, Dec 11, 2017 at 4:04 PM, Gregory Maxwell via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

>
> Nbits _never_ needs to be sent even with other consensus rules because
> its more or less necessarily a strict function of the prior headers.
> This still holds in every clone of Bitcoin I'm aware of; sending it
> with the first header in a group probably makes sense so it can be
> checked independently.
>

I think it would be nice, though, to not require the consensus-correct
calculation of nBits in order to process p2p messages.  For instance, I
think there's a use for nBits at the p2p layer for calculating the work on
a chain, which can be used as an anti-DoS measure, even without verifying
that the difficulty adjustments are following the consensus rules.

Moreover I think it's a bit messy if the p2p layer depends on intricate
consensus rules in order to reconstruct a message -- either we'd need to
interact with existing consensus logic in a potentially new way, or we'd
reimplement the same logic in the p2p layer, neither of which is very
desirable imo.

But I think we should be able to get nearly all the benefit just by
including nBits in any messages where the value is ambiguous; ie we include
it with the first header in a message, and whenever it changes from the
previous header's nBits.

I would rather not change the serialization of existing messages,
> nodes are going to have to support speaking both messages for a long
> time, and I think we already want a different protocol flow for
> headers fetching in any case.
>

I agree with this.  Specifically the way I envisioned this working is that
we could introduce a new 'cmpctheaders'/'getcmpcthdrs' message pair for
syncing using this new message type, while leaving the existing
'headers'/'getheaders' messages unchanged.  So when communicating with
upgraded peers, we'd never use 'getheaders' messages, and we'd only use
'headers' messages for potentially announcing new blocks.

Of course, we'll have to support the existing protocol for a long time.
But one downside I've discovered from deploying BIP 130, which introduced
block announcements via headers messages, is that overloading a 'headers'
message to be either a block announcement or a response to a 'getheaders'
message results in p2p-handling logic which is more complicated than it
needs to be.  So splitting off the headers chain-sync functionality to a
new message pair seems like a nice side-effect benefit, in the long run.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171212/4baa06b9/attachment.html>

From truthcoin at gmail.com  Tue Dec 12 22:16:47 2017
From: truthcoin at gmail.com (Paul Sztorc)
Date: Tue, 12 Dec 2017 17:16:47 -0500
Subject: [bitcoin-dev] Two Drivechain BIPs
In-Reply-To: <4iTYKa7LCe7_wN9neyumkheFrN7lPcmE8tbeD8if5SiobaBCeJUb3jpkwwrxi2-lL6q67TPLEAef43c7w-BRoFs21PUzUK8EOyTgaPCUZpA=@protonmail.com>
References: <d3497397-33c3-90c1-1be8-a733736eac0b@gmail.com>
	<1bb6cccd-3f6d-d62a-2825-4e6f46a4b525@mattcorallo.com>
	<dd2781a6-3e10-9f0c-6ee0-a2c070b7cf67@gmail.com>
	<CAB+qUq4wNv=-ZSibUvVCwYSE7Qw8xe8EH91KG6znUp1d7X=mdA@mail.gmail.com>
	<CAGL6+mF1YbjZ28MtvPxTye-HndEqmd6LkaFVr9BWvPiK-kfVTA@mail.gmail.com>
	<b0c3f0f9-72f4-b73e-f5b1-e5590f9456aa@gmail.com>
	<4iTYKa7LCe7_wN9neyumkheFrN7lPcmE8tbeD8if5SiobaBCeJUb3jpkwwrxi2-lL6q67TPLEAef43c7w-BRoFs21PUzUK8EOyTgaPCUZpA=@protonmail.com>
Message-ID: <3ed6b08f-b0c8-a469-9ef3-4edebce3c687@gmail.com>

Hello ZmnSCPxj,

Thanks for contributing your thoughts. I wish I were able to respond sooner!

1. I'm a little confused about the second half of your message, and its
emphasis on pools. As you know, pools can be created or destroyed an
unbounded number of times, costing only a small time lag. So I do not
see why anyone would care about pool-death (except for the administrator
of the pool of course -- and this exception is, itself, strong evidence
that pools will reflect the interests of their members). Pools are just
some naturally-occurring phenomenon that arise when many different
hashers all want similar things.

2. You have quoted a section where I suppose that miners are offering an
'atomic swaps' service. And you usually talk about that hypothetical
scenario I've outlined. But sometimes you talk in a way that leads me to
believe that you have departed from that hypothetical. For example you
talk about frozen withdrawals, invalid withdrawals, and miner-to-user
harm. But that isn't possible in my hypothetical, because users can
escape all of those things by using atomic swaps (which, recall are
instant and competitively priced, see #4). Moreover, miners can pretend
to be users (for the purpose of using these atomic swaps). If you want
to talk about a world where users aren't using these swaps, I would
appreciate it if you were more clear.

3. The question of miners harassing each other using strategy is a very
interesting one.

First, (as you seem to know) the withdrawals are designed to be
combine-able. This is in fact not only the default behavior but also the
most efficient behavior. (Assuming that n quantity of economic transfers
must go across, it is of course best to do them in one transaction.) So,
your complaint must immediately be limited to the case of "spiteful"
miners who care more about blocking opponent's transfers (for whatever
reason) than they care about upvoting their own transfers.

However, if any miner pursues a spiteful strategy, the victim(s) can
respond by orphaning. For example, if 33% are producing 'spiteful
blocks', the other 66% can easily orphan these. The central issues, as I
see it, is that to be *spiteful* is also to be *different* and
*noticeable*. Thus, different blocks can be orphaned.

Some may worry that this opens the door to endless vindictive arbitrary
orphaning (and that this is either the reason that such an alternative
will not work and therefore not be persuasive, or else that the outcome
of endless arbitrary orphaning would itself be a bad one). My view (and
observation) is that the threat of eventual orphaning is sufficient, and
that therefore there will be no actual orphaning. This is because the
antagonizing 33% group is now its own victim group, and they now have an
overwhelming incentive to either [a] stop being different (in this case,
spiteful), or else to [b] quickly obtain an additional 18% hashrate so
as to survive the orphaning. Should they add 18% to their 33%, "they"
will have 51%, and we might wonder if they will try orphaning of their
own. However, if they do, it merely restarts the above logic, with the
49% fighting to persuade a critical 2% to join.

So far, this logic may terminate with two 50% pools that each stubbornly
refuse to interact. But eventually chance will one of their blockchains
ahead of the other's, and the members of the disfavored group will feel
pressure to defect (or else they are likely to be left behind). It is no
different from traditional miner-bitterness over having not found the
most-recent block.

Users who move side-to-main via atomic swaps will have no reason to care
about any of this.?

4. As I point out in the Nov 2015 specification and security model, and
as you have suggested, the atomic swaps will only be ultra-cheap and
ultra-available if there exists *some other way* of *eventually* moving
side-to-main with *certainty*. The goal is to have a side-to-main method
that definitely will work, even if it takes a very long time to work.
Then the atomic swap is paying a premium for speed only, relative to
this method. This is why the security model of drivechain relies
(partially) on investor disappointment that sidechains are no longer
going to be supported. And it is why the slow (non-AtomicSwap)
withdrawal process is so slow and delay-able in the first place -- to
increase its security. If it is secure enough to withstand any attack,
then attackers will eventually give up (or else, they will never attack
in the first place). This satisfies the criterion of an alternative
withdrawal process that is certain and eventual.

Paul


On 12/7/2017 2:28 AM, ZmnSCPxj wrote:
> Good morning Paul and Chris,
>
> >I don't agree with the conclusion (that the optimal policy is "always
> downvoting", see above), but even if this analysis turns out to be
> correct, it isn't a total disaster. The result (which is in the
> original Nov
> >2015 specification) is that miners are the ones who perform the
> atomic swaps. Then they walk the coins side-to-main (which, at this
> point, are *their* coins). As long as there are a few large mining
> groups,
> >competition will drive the atomic swap fees down to negligible levels.
>
> Assuming there are three large mining groups who will ruthlessly want
> to undercut their competition, and with roughly 33% of total hashpower
> each (with the remaining 1% being some negligible hoi polloi), then
> one strategy to undercut your competitors would be to upvote only your
> own withdrawals and downvote that of your competitors.? A miner using
> this strategy hopes that the other miners will give up on withdrawing
> their own coin and trade their sidecoins at a discount to the
> undercutting miner.? That is, it is a hostage attempt of the sidecoin
> funds of the other miners.
>
> In the case of three large mining pools that mistrust one another,
> then, no withdrawal would ever push through and drivechains stabilize
> to one-way pegs.
>
> Now suppose that two of the mining pools collude.? They join their
> withdrawals into a single withdrawal proposal and upvote that, while
> downvoting the withdrawal of the third miner.? I observe that this is
> an opposite disaster: the 66% colluding miners can instead decide to
> simply outright make an invalid withdrawal of all funds, split up in
> half between themselves.
>
> --
>
> But three exactly equal mining pools is unnatural, for that matter
>
> Suppose that there are three mining pools: A with 34%, B with 33%, C
> with 32%, and the hoi polloi making up the remaining 1%.? Those three
> pools cannot safely let the others withdraw funds.
>
> Suppose A colludes with C to join their withdrawal proposals and their
> hashpower to withdraw.? This means that B can be pressured to sell its
> sidecoins for a discount to the joint coalition of A and C, since B
> cannot withdraw its own coins.? This lowers the profitability of B,
> causing grinders to leave them in favor of either A or C.? Since A is
> slightly larger than C, it is slightly more preferable, so it grows in
> size slightly more than C does.? Eventually B dies due to the
> coalition of A and C.? A and C are the only remaining pools, with A
> slightly larger than C.? In this case, A can break from the coalition
> and squeeze C of its sidecoins, since only A can withdraw (as it has
> more hashpower than C).? Again, grinders will leave C for A.? A
> rational C that is capable of considering this possible future path
> will thus never ally with A in a coalition to crush B, as it will then
> be next in line for being destroyed.
>
> Similar analyses for coalitions of (B, C) and (A, B).
>
> Knowing this, and knowing that they will end up sidecoin bagholders if
> they cannot withdraw coins, all miners decide to collude together and
> put all their withdrawals into a single withdrawal proposal.? But this
> removes any check-and-balance that the single withdrawal proposal is
> truthful to the sidechain: that is, the single coalition of A,B, and C
> can decide to just steal all sidechain funds and reassign them in
> proportion to their hashpower.? This might be stable at end-of-life
> for the sidechain where all ordinary users of the sidechain have
> exited it, but is otherwise a theft risk if the sidechain is operating
> normally.
>
> Regards,
> ZmnSCPxj




From truthcoin at gmail.com  Tue Dec 12 22:29:39 2017
From: truthcoin at gmail.com (Paul Sztorc)
Date: Tue, 12 Dec 2017 17:29:39 -0500
Subject: [bitcoin-dev] Two Drivechain BIPs
In-Reply-To: <XiOYlqnc-qXA7EdhRL5FyNeLDM6D5HissnTjnmuLlRrh8K2upymkEcnZb3drGUafY8CKkWjRbVQauYyUfA5cZrnIpNs5UAqWkcpahibEBpc=@protonmail.com>
References: <d3497397-33c3-90c1-1be8-a733736eac0b@gmail.com>
	<1bb6cccd-3f6d-d62a-2825-4e6f46a4b525@mattcorallo.com>
	<dd2781a6-3e10-9f0c-6ee0-a2c070b7cf67@gmail.com>
	<CAB+qUq4wNv=-ZSibUvVCwYSE7Qw8xe8EH91KG6znUp1d7X=mdA@mail.gmail.com>
	<c898cc1c-d71c-de5c-aede-a2a4235656e0@gmail.com>
	<XiOYlqnc-qXA7EdhRL5FyNeLDM6D5HissnTjnmuLlRrh8K2upymkEcnZb3drGUafY8CKkWjRbVQauYyUfA5cZrnIpNs5UAqWkcpahibEBpc=@protonmail.com>
Message-ID: <a29e72dd-f401-387b-6f54-473adf065166@gmail.com>

Hi Zmn,

I'm actually not sure that the existence of these tools makes the
attacker's collective action problem that much easier to solve.

As I said: "...even the most straightforward attack (of "a 51% hashrate
group attacks a sidechain and distributes the proceeds to the group
proportional to hashpower") is actually one that contains a difficult
(and potentially interminable) negotiation."

But even under your scheme, there is someone who has to seek out the
Accomplices, and has to try to figure out what is acceptable to pay
them. This sparks a tiresome negotiation that drains both parties of
time and effort and might potentially last forever. Problematically,
there is a Market for Lemons problem with respect to how many blocks an
Accomplice "will" mine. If many people try to be Thieves at once, then
each individual Thief has less of an incentive to bother trying to steal
in the first place.

And so, even if your scheme does work, the improvement seems small. And
even if the improvement is very great, the remaining collective action
problem is still more difficult than the one in the comparative "reorg
case" (in which the problem is just to "pick the block number from which
to start the reorg").

Paul



On 12/5/2017 11:49 PM, ZmnSCPxj wrote:
> Good morning Paul and Chris,
>
> >3. Collective Action Problem
> >
> >There actually is a collective action problem inherent to fraudulent
> withdrawals.
> >
> >If miners wish to fraudulently withdraw from the sidechain, they need
> to choose the destination addresses (on mainchain Bitcoin Core) months
> in advance. Then they need to upvote/downvote this
> >destination, despite that fact that --during this time-- new
> hashpower might be coming online/offline, and/or hashers might be
> joining/leaving specific pools. I bring this up to demonstrate that
> even the most
> >straightforward attack (of "a 51% hashrate group attacks a sidechain
> and distributes the proceeds to the group proportional to hashpower")
> is actually one that contains a difficult (and potentially
> >interminable) negotiation. The effort required to initiate the
> negotiation is the source of the collective action problem here.
> >
> >I think that this collective action problem is actually more
> burdensome than Bitcoin's -- for mainchain Bitcoin miners merely need
> to decide which block height they intend to reorganize from.
>
> I actually devised a way to work around this collective action
> problem, and discussed it obliquely in a private e-mail with Chris,
> while I was preparing my article on sidechain weaknesses.? I removed
> it before publication of the sidechain weaknesses article, but perhaps
> I should not have.
>
> Collective action can be ensured by contract.? In a world where some
> system can enforce certain actions programmatically, it is possible to
> ensure collective action via a program, i.e. a "smart contract".
>
> The thief pays out to the destination address that is a P2SH of the
> below script:
>
> OP_IF
> ? OP_HASH160 <hash> OP_EQUALVERIFY
> ? OP_DUP OP_HASH160 <thiefPubKeyHash> OP_EQUALVERIFY OP_CHECKSIG
> OP_ELSE
> ? <withdrawTime+1week> OP_CHECKLOCKTIMEVERIFY OP_DROP
> ? OP_TRUE
> OP_ENDIF
>
> If the thief does not publish the preimage of the hash within 1 week
> of the withdrawal time, then it becomes possible for anyone to spend
> the above script; basically, some lucky miner who wins the first block
> past the specified time will get the entire winnings.? Let us call the
> above script, the Theft Contract.
>
> The thief then recruits accomplices to the theft.? Note that the
> attack can be prepared and initiated before the accomplices are even
> recruited.
>
> The thief locks some coins (the "cut" the accomplice gets), to the
> below script, for each accomplice it tries to entice:
>
> OP_IF
> ? OP_HASH160 <hash> OP_EQUALVERIFY
> ? OP_DUP OP_HASH160 <accomplicePubKeyHash> OP_EQUALVERIFY OP_CHECKSIG
> OP_ELSE
> ? <withdrawTime+2week> OP_CHECKLOCKTIMEVERIFY OP_DROP
> ? OP_DUP OP_HASH160 <thiefPubKeyHash> OP_EQUALVERIFY OP_CHECKSIG
> OP_ENDIF
>
> Let us call the above script, the Accomplice Contract.? If the
> accomplice accepts, he or she then starts to vote for the invalid
> withdrawal.
>
> If the invalid withdrawal succeeds, the thief acquires the entire
> theft price from the Theft Contract by publishing the preimage to the
> <hash>.? (If he or she does not, then, some randomly-selected miner
> will acquire the money after the timeout, so the thief needs to
> publish the hash, before the timeout in the Theft Contract).
>
> This publishes the preimage on the blockchain.? Each accomplice can
> then acquire their "cut" of the theft by copying the preimage and
> claiming from the Accomplice Contract.
>
> If the theft never succeeds, then there is no reason for the thief to
> ever publish the preimage, and after the timeout on the Accomplice
> Contract, the thief can recover his or her offered funds at no loss
> (minus transaction fees),? This incentivizes accomplices to actually
> cooperate with the thief, as they will not get paid if the theft does
> not push through.
>
> All that is necessary is for a single "mastermind" thief to begin this
> process.? Accomplices can be recruited later, with the "cut" they get
> negotiated according to how much hashpower they can bring to bear on
> theft.
>
> Newly-created miners and mining pools can be enticed at the time they
> arise by offering an Accomplice Contract to them.? Thus, newly-created
> miners and mining pools can be brought into cooperation with the thief
> as soon as they make a presence on the blockchain.
>
> Even if some mining pool makes a public statement that they will not
> assist in the theft, the thief may still commit an Accomplice Contract
> for them on-chain anyway, and publicize it, in order to put the
> integrity of that mining pool in question and drive out support from
> that mining pool.? True accomplices may pretend to initially be honest
> and then signal dishonestly later, in order to make it more plausible
> that a pool that "committed" to not support the theft is not trustable
> since they have an Accomplice Contract that will compensate them if
> they support the theft, creating further confusion and discord among
> honest miners.? The thief may also use the existence of such an
> Accomplice Contract while negotiating with more minor miners and
> mining pools, in order to entice those also to join, and thus gain
> additional buffer against the stochastic process of miner voting.
>
> With the Theft Contract and the Accomplice Contract, negotiation can
> be done in parallel with the theft attempt, reducing the cost of
> organizing collective action, as we have all hoped "smart contracts"
> would do.
>
> ----
>
> While it is true, that this requires that the thief have significant
> funds in reserve prior to theft (in order to fund the Accomplice
> Contracts he or she will have to offer to potential accomplices), we
> have always been assured that theft can be initiated by miners only,
> and that miners already have a significant amount of money they
> control.? So it will be no problem for a potential thief to reserve
> some funds for paying to Accomplice Contracts.
>
> This vulnerability can be fixed if withdrawals are restricted to
> simple P2PKH or P2WPKH only, but in the presence of Scriptless Script
> and Bellare-Neven signatures, that may be sufficient to create the
> Theft Contract and the Accomplice Contract (but I know too little of
> Scriptless Script to be sure).
>
> Regards,
> ZmnSCPxj




From greg at xiph.org  Wed Dec 13 00:01:32 2017
From: greg at xiph.org (Gregory Maxwell)
Date: Wed, 13 Dec 2017 00:01:32 +0000
Subject: [bitcoin-dev] "Compressed" headers stream
In-Reply-To: <CAFp6fsHwdAbcYVdPzuDdD1OV7ibCN-ebMBi113m5-JOoJtccPQ@mail.gmail.com>
References: <CADZtCShywq_s9ZK3oBBTUdCgjrTxbyeb-p7QrhJJ3mwRAECCMA@mail.gmail.com>
	<CAAS2fgROykenGH43_FXun+q4u+=94tKqnRW=kQQ2AQFeXKdW=Q@mail.gmail.com>
	<CAFp6fsHwdAbcYVdPzuDdD1OV7ibCN-ebMBi113m5-JOoJtccPQ@mail.gmail.com>
Message-ID: <CAAS2fgRLC7GZ6pr+o59e8SycxfuBniLObFEz5yCz_fpvN8i+_Q@mail.gmail.com>

On Tue, Dec 12, 2017 at 9:07 PM, Suhas Daftuar <sdaftuar at gmail.com> wrote:
> But I think we should be able to get nearly all the benefit just by
> including nBits in any messages where the value is ambiguous; ie we include
> it with the first header in a message, and whenever it changes from the
> previous header's nBits.

Yes, that is what I was thinking last time we discussed it, just with
each header include a one byte flag that lets you express:

bit: meaning
(0) if nbits is the same as last,
(1) if timestamp is a full field or a small offset, (e.g. two bytes
defined as unsigned offset between the last time - 7200 and the new
time).
(2,3,4) if version is the same as the last distinct value .. 7th last,
or a new 32bit distinct value;
(5,6) if prev is entirely there, entirely gone, first 4 bytes
provided, or first 8 bytes provided. (if provided they override the
computed values).

That would be 7 bits in total; the 8th could be reserved or use to
signal "more headers follow" to make the encoding self-delimiting.

The downside with nbits the same as last as the optimization is that
if we ever change consensus rules to ones where difficulty management
works differently it may be the case that nbits changes every block.

Alternatively, nbits could get a differential encoding that could be
opted into for small differences-- though I haven't thought much about
it to see if a one byte difference would be that useful (e.g. can bch
differences usually be expressed with one byte?)

I'm kind of dubious of the consensus layer anti-dos separation:  nbits
minimum is so low compared to the speed of a mining device, virtually
any attack that you might do with invalid headers could still be done
with headers at the minimum difficulty. But I'm fully willing to
accept that simpler is better...



>> I would rather not change the serialization of existing messages,
>> nodes are going to have to support speaking both messages for a long
>> time, and I think we already want a different protocol flow for
>> headers fetching in any case.
>
>
> I agree with this.  Specifically the way I envisioned this working is that
> we could introduce a new 'cmpctheaders'/'getcmpcthdrs' message pair for
> syncing using this new message type, while leaving the existing
> 'headers'/'getheaders' messages unchanged.  So when communicating with
> upgraded peers, we'd never use 'getheaders' messages, and we'd only use
> 'headers' messages for potentially announcing new blocks.
>
> Of course, we'll have to support the existing protocol for a long time.  But
> one downside I've discovered from deploying BIP 130, which introduced block
> announcements via headers messages, is that overloading a 'headers' message
> to be either a block announcement or a response to a 'getheaders' message
> results in p2p-handling logic which is more complicated than it needs to be.
> So splitting off the headers chain-sync functionality to a new message pair
> seems like a nice side-effect benefit, in the long run.
>

From greg at xiph.org  Wed Dec 13 00:12:45 2017
From: greg at xiph.org (Gregory Maxwell)
Date: Wed, 13 Dec 2017 00:12:45 +0000
Subject: [bitcoin-dev] "Compressed" headers stream
In-Reply-To: <CAFp6fsHwdAbcYVdPzuDdD1OV7ibCN-ebMBi113m5-JOoJtccPQ@mail.gmail.com>
References: <CADZtCShywq_s9ZK3oBBTUdCgjrTxbyeb-p7QrhJJ3mwRAECCMA@mail.gmail.com>
	<CAAS2fgROykenGH43_FXun+q4u+=94tKqnRW=kQQ2AQFeXKdW=Q@mail.gmail.com>
	<CAFp6fsHwdAbcYVdPzuDdD1OV7ibCN-ebMBi113m5-JOoJtccPQ@mail.gmail.com>
Message-ID: <CAAS2fgQiicyUO31qJP7_xxAwRvp3rx8fHN+W+0jwq1Py=7+sFg@mail.gmail.com>

On Tue, Dec 12, 2017 at 9:07 PM, Suhas Daftuar <sdaftuar at gmail.com> wrote:
> I agree with this.  Specifically the way I envisioned this working is that
> we could introduce a new 'cmpctheaders'/'getcmpcthdrs' message pair for
> syncing using this new message type, while leaving the existing
> 'headers'/'getheaders' messages unchanged.  So when communicating with
> upgraded peers, we'd never use 'getheaders' messages, and we'd only use
> 'headers' messages for potentially announcing new blocks.

The question becomes there-- how should it work.

In an ideal world, we'd decide what peers to fetch headers from based
on a compact proof of the total work in their chains... but we cannot
construct such proofs in Bitcoin today.

I think that instead of that a weak heuristic is to fetch first from
the peers with the tip at the highest difficulty. Then work backwards.

See: https://en.bitcoin.it/wiki/User:Gmaxwell/Reverse_header-fetching_sync

Which is the inspiration for the current headers first sync, but
without the reverse part because the protocol didn't permit it: you
can't request a linear wad of headers that come before a header. This
is the thing I was mostly thinking of when I mentioned that we may
want to change the interface.

From jaejoon at gmail.com  Wed Dec 13 19:46:09 2017
From: jaejoon at gmail.com (Jimmy Song)
Date: Wed, 13 Dec 2017 13:46:09 -0600
Subject: [bitcoin-dev] BIP Proposal: Utilization of bits denomination
Message-ID: <CAJR7vkqcBo+o9BL8sK1TBqqNUNSMWdut_aL_YMXse8rDC2ju9A@mail.gmail.com>

Hey all,

I am proposing an informational BIP to standardize the term "bits". The
term has been around a while, but having some formal informational standard
helps give structure to how the term is used.

https://github.com/jimmysong/bips/blob/unit-bias/bip-unit-bias.mediawiki

Entire BIP included below (mediawiki format) for convenience.

Best,

Jimmy

----------

<pre>
    BIP: ????
    Title: Utilization of bits denomination
    Author: Jimmy Song <jaejoon at gmail.com>
    Comments-URI:  https://github.com/bitcoin/bips/wiki/Comments:BIP-????
    Status: Draft
    Type: Informational
    Created: 2017-12-12
    License: BSD-2-Clause
    License-Code: BSD-2
</pre>

== Abstract ==
Bits is presented here as the standard term for 100 (one hundred) satoshis
or 1/1,000,000 (one one-millionth) of a bitcoin.

== Motivation ==
The bitcoin price has grown over the years and once the price is past
$10,000 USD or so, bitcoin amounts under $10 USD start having enough
decimal places that it's difficult to tell whether the user is off by a
factor of 10 or not. Switching the denomination to "bits" makes
comprehension easier. For example, when BTC is $15,000 USD, $10.50 is a
somewhat confusing 0.00067 BTC, versus 670 bits, which is a lot clearer.

Additonally, reverse comparisons are easier as 67 bits being $1 is easier
to comprehend for most people than 0.000067 BTC being $1. Similar
comparisons can be made to other currencies: 1 yen being 0.8 bits, 1 won
being 0.07 bits and so on.

Potential benefits of utilizing "bits" include:

# Reduce user error on small bitcoin amounts.
# Reduce unit bias for users that want a "whole" bitcoin.
# Allow easier comparisons of prices for most users.
# Allow easier bi-directional comparisons to fiat currencies.
# Allows all UTXO amounts to need at most 2 decimal places, which can be
easier to handle.

== Specification ==
Definition: 1 bit = 1/1,000,000 bitcoin.
Plural of "bit" is "bits". The terms "bit" and "bits" are not proper nouns
and thus should not be capitalized unless used at the start of a sentence,
etc.

All Bitcoin-denominated items are encouraged to also show the denomination
in bits, either as the default or as an option.

== Rationale ==
As bitcoin grows in price versus fiat currencies, it's important to give
users the ability to quickly and accurately calculate prices for
transactions, savings and other economic activities. "Bits" have been used
as a denomination within the Bitcoin ecosystem for some time. The idea of
this BIP is to formalize this name. Additionally, "bits" is likely the only
other denomination that will be needed for Bitcoin as 0.01 bit = 1 satoshi,
meaning that two decimal places will be sufficient to describe any current
utxo.

Existing terms used in bitcoin such as satoshi, milli-bitcoin (mBTC) and
bitcoin (BTC) do not conflict as they operate at different orders of
magnitude.

The term micro-bitcoin (?BTC) can continue to exist in tandem with the term
"bits".

== Backwards Compatibility ==
Software such as the Bitcoin Core GUI currently use the ?BTC denomination
and can continue to do so. There is no obligation to switch to "bits".

== Copyright ==
This BIP is licensed under the BSD 2-clause license.

== Credit ==
It's hard to ascertain exactly who invented the term "bits", but the term
has been around for a while and the author of this BIP does not take any
credit for inventing the term.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171213/83d9a519/attachment.html>

From dave at dtrt.org  Wed Dec 13 21:36:07 2017
From: dave at dtrt.org (David A. Harding)
Date: Wed, 13 Dec 2017 16:36:07 -0500
Subject: [bitcoin-dev] BIP Proposal: Utilization of bits denomination
In-Reply-To: <CAJR7vkqcBo+o9BL8sK1TBqqNUNSMWdut_aL_YMXse8rDC2ju9A@mail.gmail.com>
References: <CAJR7vkqcBo+o9BL8sK1TBqqNUNSMWdut_aL_YMXse8rDC2ju9A@mail.gmail.com>
Message-ID: <20171213213607.ijlvqwpdaokucgi6@fedora-23-dvm>

On Wed, Dec 13, 2017 at 01:46:09PM -0600, Jimmy Song via bitcoin-dev wrote:
> Hey all,
> 
> I am proposing an informational BIP to standardize the term "bits". The
> term has been around a while, but having some formal informational standard
> helps give structure to how the term is used.
> 
> https://github.com/jimmysong/bips/blob/unit-bias/bip-unit-bias.mediawiki

Wallets and other software is already using this term, so I think it's a
good idea to ensure its usage is normalized.

That said, I think the term is unnecessary and confusing given that
microbitcoins provides all of the same advantages and at least two
additional advantages:

- Microbitcoins is not a homonym for any other word in English (and
  probably not in any other language), whereas "bit" and "bits" have
  more than a dozen homonyms in English---some of which are quite common
  in general currency usage, Bitcoin currency usage, or Bitcoin
  technical usage.

- Microbitcoins trains users to understand SI prefixes, allowing them to
  easily migrate from one prefix to the next.  This will be important
  when bitcoin prices rise to $10M USD[1] and the bits denomination has
  the same problems the millibitcoin denomination has now, but it's also
  useful in the short term when interacting with users who make very
  large payments (bitcoin-scale) or very small payments
  (nanobitcoin-scale).[2]  Maybe a table of scale can emphasize this
  point:

      Wrong (IMO):        Right (IMO):
      ---------------     --------------
      BTC                 BTC
      mBTC                mBTC
      bits                ?BTC
      nBTC                nBTC
  
[1] A rise in price to $10M doesn't require huge levels of growth---it
only requires time under the assumption that a percentage of bitcoins will
be lost every year due to wallet mishaps, failure to inherit bitcoins,
and other issues that remove bitcoins from circulation.  In other words,
it's important to remember that Bitcoin is expected to become a
deflationary currency and plan accordingly.

[2] Although Bitcoin does not currently support committed
nanobitcoin-scale payments in the block chain, it can be supported in a
variety of ways by offchain systems---including (it is hypothesized)
trustless systems based on probabilistic payments.

Thanks,

-Dave
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 819 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171213/7d7cdfb6/attachment.sig>

From nathan.f77 at gmail.com  Wed Dec 13 22:08:05 2017
From: nathan.f77 at gmail.com (Nathan Broadbent)
Date: Thu, 14 Dec 2017 05:08:05 +0700
Subject: [bitcoin-dev] BIP Proposal: Bitcoin nodes could be used as a
 trusted third party that broadcasts encrypted transactions
Message-ID: <CAPXHQbOpwmL2LxbwDByJ++CGBd+Mnv6mmJbnPVifVDP7fJAU=Q@mail.gmail.com>

Hello,

I would like propose a way for full Bitcoin nodes to be used as simple
trusted third parties (TTPs) [1]. The idea is that parties would work
together to randomly select a Bitcoin node. The parties would then perform
a secure multi-party computation (MPC) [2], where every party has a secret
value that they don't want to share with anyone else. The result of this
computation would be a Bitcoin transaction that was encrypted by the random
node's public key. Any of the parties could then send the encrypted
transaction to this node. The node would decrypt the transaction and
broadcast it to its peers. Nodes would receive a small fee for providing
this service.


*Mental Poker*

Mental Poker [3] is where you play a fair game of poker without the need
for a trusted third party who moderates the game. A paper titled "A Toolbox
for Mental Card Games" [4] describes how you can use MPC to
play decentralized poker.

This works great when you're just playing for fun, but everything falls
apart when you're playing for Bitcoin. The problem is that MPC is not fair,
because one party will always learn the outcome of a computation before
anyone else. If they find out that they lost the round, they can abort the
computation and prevent anyone else from gaining that information. The
other players will know what happened, but they can't force the cheater to
broadcast the Bitcoin transaction. The game would just be stalled, and
people would use their timelock transactions to get their money back.

In a paper titled "How to Use Bitcoin to Play Decentralized Poker" [5], the
authors describe how penalties could be used to force players into
revealing the outcome. If one player aborts the computation after learning
that they lost, they would automatically pay a penalty to the other players.

There's one big problem with this penalty system: A group of dishonest
players can simply ignore that player and force them to pay the penalty.
The outcome of the round doesn't even matter. It would be easy to set up an
army of bots that never finishes a round and just collects penalties.


*Mental Poker With Random Bitcoin Nodes as TTPs*

The fairness problem might be solved if a randomly selected Bitcoin node
served as a simple TTP. The node could provide a public key, and result of
the MPC would then be an *encrypted* Bitcoin transaction that could only be
decrypted and broadcast by that randomly selected node. No players would
gain any information about the outcome until they saw the unconfirmed
transaction in the mempool.

The following example is very long and detailed (as is this whole email!),
but it demonstrates all of the functions that a node would need to perform.


*Example Protocol*

Alice and Bob choose a random full Bitcoin node that supports this new
protocol. (Alice might shuffle all of the IP addresses and send Bob the
Merkle tree root hash. Bob then picks one index at random, and Alice sends
Bob the full Merkle tree. Now they've both committed to a random node.)

Alice sends the request to the randomly selected node. The node generates a
one-time-use key pair, and encrypts the one-time private key using its
static public key. It also signs "<one-time-use public key><encrypted
one-time-use private key>" using its static private key.

*Note: This one-time-use key pair is generated so that Alice and Bob can
encrypt up to 32 bytes of metadata and send this with the one-time key
and their encrypted transaction. The node would broadcast the transaction
and return their decrypted data. Also note that the node would use the same
static key pair as P2P encryption. (BIP151) [6]*

The node sends Alice the fee amount (maybe 20 Satoshis), an address where
she should send the fee, the node's static public key, and the one-time
public key / encrypted private key / signature.

Alice sends this data to Bob. Bob connects to the node himself, and fetches
the fee and static public key. Bob uses the public key and signature to
verify that the one-time key pair was generated and signed by this node.

Alice and Bob now play a round of decentralized poker. At the end of the
round, they use MPC to create an encrypted Bitcoin transaction that sends
the money to the winner. The MPC also has an output for the encrypted
showdown (the cards that are revealed at the end of the round.)

Either Bob or Alice (or both) now send this encrypted transaction to the
node, plus the encrypted showdown, the one-time key data.

The node then decrypts and verifies the Bitcoin transaction. If it's valid
and it contains the correct fee output, it broadcasts the transaction to
its peers. The node also decrypts the one-time private key, and uses the
decrypted private key to decrypt the metadata that was sent. The node
returns the decrypted metadata to the sender, who now knows the other
player's cards.

Note that one player can still abort the computation and send the encrypted
transaction as soon as they have it, which prevents the other player from
learning about the cards. A solution could be that the node keeps the
decrypted metadata in memory for a short time, and the other player can
access that data by sending the one-time-use public key.


*Example Protocol Notes:*

This example only uses a single TTP node. It would be far more secure if
the parties randomly select a large number of nodes. The encrypted
transaction would contain fee outputs for every node.

Shamir's Secret Sharing could be used so that *n* of *t* nodes are needed
to decrypt the transaction. The MPC could encrypt the individual key parts
using each node's public key. The node would either broadcast a fully
decrypted transaction, or return a partially decrypted transaction to the
sender.

People might be tempted to use the seed nodes more often, because they're
hard-coded in the Bitcoin source code. Don't do that. For important
transactions, you should just use a large number of TTP nodes (e.g. require
decryption by 20 out of 50 randomly selected nodes.)


*Real-World Applications*

People could anonymously vote on the distribution of funds without
revealing their vote to anyone. No-one would know the outcome of the vote
until the transaction was broadcast.

It would also be possible to create a fully decentralized Bitcoin lottery.



Sorry for the incredibly long email. I hope you found this interesting!
I've probably made a few mistakes, but I hope I've explained things
clearly, and I look forward to reading your feedback.


Best Regards,
Nathan Broadbent



*References:*

[1] https://en.wikipedia.org/wiki/Trusted_third_party
[2] https://en.wikipedia.org/wiki/Secure_multi-party_computation
[3] https://en.wikipedia.org/wiki/Mental_poker
[4]
http://www.cs.miami.edu/home/burt/projects/smpc/doc/schindelhauer98toolbox.pdf
[5] http://people.csail.mit.edu/ranjit/papers/poker.pdf
[6] https://github.com/bitcoin/bips/blob/master/bip-0151.mediawiki
?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171214/c6fe52e8/attachment-0001.html>

From ZmnSCPxj at protonmail.com  Thu Dec 14 03:24:07 2017
From: ZmnSCPxj at protonmail.com (ZmnSCPxj)
Date: Wed, 13 Dec 2017 22:24:07 -0500
Subject: [bitcoin-dev] Two Drivechain BIPs
In-Reply-To: <a29e72dd-f401-387b-6f54-473adf065166@gmail.com>
References: <d3497397-33c3-90c1-1be8-a733736eac0b@gmail.com>
	<1bb6cccd-3f6d-d62a-2825-4e6f46a4b525@mattcorallo.com>
	<dd2781a6-3e10-9f0c-6ee0-a2c070b7cf67@gmail.com>
	<CAB+qUq4wNv=-ZSibUvVCwYSE7Qw8xe8EH91KG6znUp1d7X=mdA@mail.gmail.com>
	<c898cc1c-d71c-de5c-aede-a2a4235656e0@gmail.com>
	<XiOYlqnc-qXA7EdhRL5FyNeLDM6D5HissnTjnmuLlRrh8K2upymkEcnZb3drGUafY8CKkWjRbVQauYyUfA5cZrnIpNs5UAqWkcpahibEBpc=@protonmail.com>
	<a29e72dd-f401-387b-6f54-473adf065166@gmail.com>
Message-ID: <M4jjdDZcFz1m6s-UKP323jDzdu-15r8uwFjxDsKHzAcizXleLEjJ5pZ9O2gghUj7w9AXWXDgD7eKpt3luNcYVEGajFaYPGR2LRIODmOdtgE=@protonmail.com>

Good morning Paul,

It seems many blocks have a coinbase that pays out to a P2PKH.

The public key hash of a potential Accomplice is then readily visible on-chain on the P2PKH of the coinbase.

What is more, the potential Accomplice's hashpower can be judged on-chain also: the more blocks pay out to their P2PKH, the greater their hashpower.

From this, the motivating Thief can blindly and automatically create HTLCs paying out to the public key hash of potential Accomplices, weighed according to how many blocks were mined by those.

Then the motivating Thief can broadcast (perhaps on some website they control, via social media, and so on) the fact of the HTLCs existing, without negotiating with the Accomplices.  It is a simple "take it or leave it": if the theft succeeds (whether the Accomplice assisted in the theft or not) the Accompilce can get paid.  Thus, communication overhead is reduced to a single broadcast message (the Thief might batch a number of different possible Accomplices, and in addition, might want to play on the psychological effect of the broadcast), and the Accomplice is simply faced with the choice: either participate in the theft (and increase the chance they earn money from it) or protect against the theft (and reduce the chance they earn money from it).

Regards,
ZmnSCPxj

Sent with [ProtonMail](https://protonmail.com) Secure Email.

> -------- Original Message --------
> Subject: Re: [bitcoin-dev] Two Drivechain BIPs
> Local Time: December 13, 2017 6:29 AM
> UTC Time: December 12, 2017 10:29 PM
> From: truthcoin at gmail.com
> To: ZmnSCPxj <ZmnSCPxj at protonmail.com>, Chris Stewart <chris at suredbits.com>
> Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>
>
> Hi Zmn,
>
> I'm actually not sure that the existence of these tools makes the
> attacker's collective action problem that much easier to solve.
>
> As I said: "...even the most straightforward attack (of "a 51% hashrate
> group attacks a sidechain and distributes the proceeds to the group
> proportional to hashpower") is actually one that contains a difficult
> (and potentially interminable) negotiation."
>
> But even under your scheme, there is someone who has to seek out the
> Accomplices, and has to try to figure out what is acceptable to pay
> them. This sparks a tiresome negotiation that drains both parties of
> time and effort and might potentially last forever. Problematically,
> there is a Market for Lemons problem with respect to how many blocks an
> Accomplice "will" mine. If many people try to be Thieves at once, then
> each individual Thief has less of an incentive to bother trying to steal
> in the first place.
>
> And so, even if your scheme does work, the improvement seems small. And
> even if the improvement is very great, the remaining collective action
> problem is still more difficult than the one in the comparative "reorg
> case" (in which the problem is just to "pick the block number from which
> to start the reorg").
>
> Paul
>
> On 12/5/2017 11:49 PM, ZmnSCPxj wrote:
>
>> Good morning Paul and Chris,
>>
>>> - Collective Action Problem
>>>
>>> There actually is a collective action problem inherent to fraudulent
>>> withdrawals.
>>> If miners wish to fraudulently withdraw from the sidechain, they need
>>> to choose the destination addresses (on mainchain Bitcoin Core) months
>>> in advance. Then they need to upvote/downvote this
>>> destination, despite that fact that --during this time-- new
>>> hashpower might be coming online/offline, and/or hashers might be
>>> joining/leaving specific pools. I bring this up to demonstrate that
>>> even the most
>>> straightforward attack (of "a 51% hashrate group attacks a sidechain
>>> and distributes the proceeds to the group proportional to hashpower")
>>> is actually one that contains a difficult (and potentially
>>> interminable) negotiation. The effort required to initiate the
>>> negotiation is the source of the collective action problem here.
>>> I think that this collective action problem is actually more
>>> burdensome than Bitcoin's -- for mainchain Bitcoin miners merely need
>>> to decide which block height they intend to reorganize from.
>>
>> I actually devised a way to work around this collective action
>> problem, and discussed it obliquely in a private e-mail with Chris,
>> while I was preparing my article on sidechain weaknesses.  I removed
>> it before publication of the sidechain weaknesses article, but perhaps
>> I should not have.
>> Collective action can be ensured by contract.  In a world where some
>> system can enforce certain actions programmatically, it is possible to
>> ensure collective action via a program, i.e. a "smart contract".
>> The thief pays out to the destination address that is a P2SH of the
>> below script:
>> OP_IF
>>   OP_HASH160 <hash> OP_EQUALVERIFY
>>   OP_DUP OP_HASH160 <thiefPubKeyHash> OP_EQUALVERIFY OP_CHECKSIG
>> OP_ELSE
>>   <withdrawTime+1week> OP_CHECKLOCKTIMEVERIFY OP_DROP
>>   OP_TRUE
>> OP_ENDIF
>> If the thief does not publish the preimage of the hash within 1 week
>> of the withdrawal time, then it becomes possible for anyone to spend
>> the above script; basically, some lucky miner who wins the first block
>> past the specified time will get the entire winnings.  Let us call the
>> above script, the Theft Contract.
>> The thief then recruits accomplices to the theft.  Note that the
>> attack can be prepared and initiated before the accomplices are even
>> recruited.
>> The thief locks some coins (the "cut" the accomplice gets), to the
>> below script, for each accomplice it tries to entice:
>> OP_IF
>>   OP_HASH160 <hash> OP_EQUALVERIFY
>>   OP_DUP OP_HASH160 <accomplicePubKeyHash> OP_EQUALVERIFY OP_CHECKSIG
>> OP_ELSE
>>   <withdrawTime+2week> OP_CHECKLOCKTIMEVERIFY OP_DROP
>>   OP_DUP OP_HASH160 <thiefPubKeyHash> OP_EQUALVERIFY OP_CHECKSIG
>> OP_ENDIF
>> Let us call the above script, the Accomplice Contract.  If the
>> accomplice accepts, he or she then starts to vote for the invalid
>> withdrawal.
>> If the invalid withdrawal succeeds, the thief acquires the entire
>> theft price from the Theft Contract by publishing the preimage to the
>> <hash>.  (If he or she does not, then, some randomly-selected miner
>> will acquire the money after the timeout, so the thief needs to
>> publish the hash, before the timeout in the Theft Contract).
>> This publishes the preimage on the blockchain.  Each accomplice can
>> then acquire their "cut" of the theft by copying the preimage and
>> claiming from the Accomplice Contract.
>> If the theft never succeeds, then there is no reason for the thief to
>> ever publish the preimage, and after the timeout on the Accomplice
>> Contract, the thief can recover his or her offered funds at no loss
>> (minus transaction fees),  This incentivizes accomplices to actually
>> cooperate with the thief, as they will not get paid if the theft does
>> not push through.
>> All that is necessary is for a single "mastermind" thief to begin this
>> process.  Accomplices can be recruited later, with the "cut" they get
>> negotiated according to how much hashpower they can bring to bear on
>> theft.
>> Newly-created miners and mining pools can be enticed at the time they
>> arise by offering an Accomplice Contract to them.  Thus, newly-created
>> miners and mining pools can be brought into cooperation with the thief
>> as soon as they make a presence on the blockchain.
>> Even if some mining pool makes a public statement that they will not
>> assist in the theft, the thief may still commit an Accomplice Contract
>> for them on-chain anyway, and publicize it, in order to put the
>> integrity of that mining pool in question and drive out support from
>> that mining pool.  True accomplices may pretend to initially be honest
>> and then signal dishonestly later, in order to make it more plausible
>> that a pool that "committed" to not support the theft is not trustable
>> since they have an Accomplice Contract that will compensate them if
>> they support the theft, creating further confusion and discord among
>> honest miners.  The thief may also use the existence of such an
>> Accomplice Contract while negotiating with more minor miners and
>> mining pools, in order to entice those also to join, and thus gain
>> additional buffer against the stochastic process of miner voting.
>> With the Theft Contract and the Accomplice Contract, negotiation can
>> be done in parallel with the theft attempt, reducing the cost of
>> organizing collective action, as we have all hoped "smart contracts"
>> would do.
>> ---------------------------------------------------------------
>>
>> While it is true, that this requires that the thief have significant
>> funds in reserve prior to theft (in order to fund the Accomplice
>> Contracts he or she will have to offer to potential accomplices), we
>> have always been assured that theft can be initiated by miners only,
>> and that miners already have a significant amount of money they
>> control.  So it will be no problem for a potential thief to reserve
>> some funds for paying to Accomplice Contracts.
>> This vulnerability can be fixed if withdrawals are restricted to
>> simple P2PKH or P2WPKH only, but in the presence of Scriptless Script
>> and Bellare-Neven signatures, that may be sufficient to create the
>> Theft Contract and the Accomplice Contract (but I know too little of
>> Scriptless Script to be sure).
>> Regards,
>> ZmnSCPxj
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171213/f53d60bf/attachment-0001.html>

From therealsangaman at gmail.com  Wed Dec 13 23:00:02 2017
From: therealsangaman at gmail.com (Daniel McNally)
Date: Wed, 13 Dec 2017 18:00:02 -0500
Subject: [bitcoin-dev] BIP Proposal: Utilization of bits denomination
In-Reply-To: <CADPKye0Kt87cHbuOqphMOPY3TPmO1awH46k17rEoVZ4kAejkxw@mail.gmail.com>
References: <CADPKye1m2_5PaqedMU9nPsmvpW-3S+LSoqt0LnQLXXk=MjDJew@mail.gmail.com>
	<CADPKye39X_QFi_G0we39ZWXAQme=veC1hCfc_fFFwjs15Op=Lw@mail.gmail.com>
	<CADPKye1FjsjG9gO7oWngx2LDnVqRQT_ia4Ke-wPfCRbXjnfZCg@mail.gmail.com>
	<CADPKye03UUnJ5T94m8OdBNC5k8wnXGVB-xpbqf363gzTtfN_6A@mail.gmail.com>
	<CADPKye2H66iZt=uOz765zrVtv_toeAzfoJXaqQvJaUtadqjDwg@mail.gmail.com>
	<CADPKye35ZxJDcfM2e+pvw+z6eZEyzj1-6VDcpHP6Z5FtX-=GOQ@mail.gmail.com>
	<CADPKye0JD5kfmsGb-AzO6EfPubOGUXtxaEqizLQUQ3QJmCMLJQ@mail.gmail.com>
	<CADPKye0_eozpfG35qCmPKX-MX+qYZBLt5peU0_jBOCfVoZfefQ@mail.gmail.com>
	<CADPKye0PSwH_bMYa9DzRos9SgL4e2Vid1gEKnNtcUKQB-op5UQ@mail.gmail.com>
	<CADPKye04MRZkWtZm1mWnjmSe97v0-iZwAdYH6pSrFjpHfzuQ-w@mail.gmail.com>
	<CADPKye2Ozj6rqApztKyoeJvekofdaiP1=jbd6buxFTebEantMA@mail.gmail.com>
	<CADPKye3hyOH4Z+y_JgJUfEspSt8jL+ZGaU05v_fX3Wiwr2-N9g@mail.gmail.com>
	<CADPKye11prrk663bWAatFCkjktJNgemg-ECdZdP07RECWcE6nQ@mail.gmail.com>
	<CADPKye1+z2aUBXc3UECvmoNSGO23hXGzGXekFOTPy-rdHFG_Nw@mail.gmail.com>
	<CADPKye0i0LaGgS4Hmp086LLCnPEHNYqJ+VbZ2h2DxycTwY2srQ@mail.gmail.com>
	<CADPKye0dj5z=hDbooUOY-vhP0N+L=VzhOGn3Wue4tPgY3vnHwA@mail.gmail.com>
	<CADPKye3Z8PDe_5D28hcELDurtpr=5wgzazw3RT=Fc3gUDvhcng@mail.gmail.com>
	<CADPKye0-JwfDJruc00XXd55Gm0Ho4c5EKGxqcCqyuFcTY=omYQ@mail.gmail.com>
	<CADPKye27FpEYtO31XjX6KcG59HjfZzaGGW0gayO-xZVbdb7jtg@mail.gmail.com>
	<CADPKye0Kt87cHbuOqphMOPY3TPmO1awH46k17rEoVZ4kAejkxw@mail.gmail.com>
Message-ID: <CADPKye3r+ZRGFqdF2ihyuJomzQNemUU+4+TprouPhZu_OGu89Q@mail.gmail.com>

I think standardization of this term is a great idea. I second all of
Jimmy's points. I think the analogy of dollars & cents to bits and satoshis
is easy to grasp, particularly given that satoshis and cents are the
smallest tangible units of their respective currencies. It's a concept
that's common across cultures and countries as it also applies to pounds
and pence, pesos and centavos, etc...

To David's points, I agree that it's not ideal that bit is a homonym for
other words, but I don't think it's a terrible flaw as context will usually
make the meaning clear. I'm actually not in love with the term "bit," but
rather the idea of a non-SI term for a millionth of a bitcoin. But bit has
already caught on to some extent and I can't think of anything better.


> - Microbitcoins trains users to understand SI prefixes, allowing them to easily
> migrate from one prefix to the next.  This will be important when bitcoin
> prices rise to $10M USD[1] and the bits denomination has the same
> problems the millibitcoin denomination has now, but it's also useful in
> the short term when interacting with users who make very large payments
> (bitcoin-scale) or very small payments (nanobitcoin-scale).[2]


I find the SI prefixes to be very user unfriendly. I have plenty of smart
friends and family who constantly confuse mega, giga, micro, nano, and so
on. Rather than try to train users, I think we should choose terms that
will be easy for them to grasp right away. Even for people fluent in SI
terms, I think some of the problems regarding unit bias still exist. 500
microbitcoins sounds diminutive and uttering it is a reminder that it's a
very small fraction of a larger unit. 500 bits sounds like you have 500 of
something, neat!

I consider "bits" to be a term that's quite future proofed. While I won't
dismiss the possibility of $10M or $100M bitcoins in the not-too-distant
future, there would still be plenty of time for a bit to be a useful
day-to-day unit. Even at the $10M point, small ticket items like coffee
could still be priced at 0.30 bits for example, not bad I'd say.

Should bitcoin ever soar past the $100M mark, it might be time for a new
term akin to bits and maybe a hard fork to allow for more decimal places on
chain. A nanobitcoin could not be transacted with today anyhow. These would
all be good problems to have.

Thanks for reading and thanks to Jimmy for taking the initiative with this
BIP.

Daniel
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171213/c6e2f0e0/attachment.html>

From sjors at sprovoost.nl  Thu Dec 14 15:52:24 2017
From: sjors at sprovoost.nl (Sjors Provoost)
Date: Thu, 14 Dec 2017 16:52:24 +0100
Subject: [bitcoin-dev] BIP Proposal: Utilization of bits denomination
In-Reply-To: <20171213213607.ijlvqwpdaokucgi6@fedora-23-dvm>
References: <CAJR7vkqcBo+o9BL8sK1TBqqNUNSMWdut_aL_YMXse8rDC2ju9A@mail.gmail.com>
	<20171213213607.ijlvqwpdaokucgi6@fedora-23-dvm>
Message-ID: <B8087CB6-CBF7-43C6-8368-9E98523FB68B@sprovoost.nl>

As much as I love SI standards, "trains users to understand SI prefixes, allowing them to
easily migrate from one prefix to the next" seems unrealistic. The metric system is about to
have its 220th birthday and people in the US still don't use it.

It makes sense to embrace terms that stick. "bits" as a formal-yet-informal alias for ?BTC makes sense to me, unless someone can point to another term that's already commonly used.

I'm not too worried about the word bit having other meanings in common language. The word "bit coin" was introduced in the English language without a problem. A "bit" being 1 millionth of a "bit coin" doesn't seem too difficult. It will give a while new meaning to the expression "a bit expensive" :-)

Rather than nano-bitcoin, I would suggest milli bits.


It's rather unfortunate that 1 satoshi was defined as 10^-8 BTC instead of 10^-9. We could redefine satoshi to 10^-9 BTC. Then we can use kilo-satoshi instead of bits. Then the next step can be satoshi, followed by millisatoshi (you never know).

The smallest amount that can be handled by bitcoin software under this redefinition would be 10 satoshi rather than 1; mostly a matter of changing some source code comments.

The only place where I've seen the unit "satoshi" used is fee estimators. I think it's still early enough that people aren't terribly attached to the numbers shown on those sites (most people express fees in fiat terms, especially when complaining). We could switch from vbytes to weight units at the same time.

Sjors

> Op 13 dec. 2017, om 22:36 heeft David A. Harding via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> het volgende geschreven:
> 
> On Wed, Dec 13, 2017 at 01:46:09PM -0600, Jimmy Song via bitcoin-dev wrote:
>> Hey all,
>> 
>> I am proposing an informational BIP to standardize the term "bits". The
>> term has been around a while, but having some formal informational standard
>> helps give structure to how the term is used.
>> 
>> https://github.com/jimmysong/bips/blob/unit-bias/bip-unit-bias.mediawiki
> 
> Wallets and other software is already using this term, so I think it's a
> good idea to ensure its usage is normalized.
> 
> That said, I think the term is unnecessary and confusing given that
> microbitcoins provides all of the same advantages and at least two
> additional advantages:
> 
> - Microbitcoins is not a homonym for any other word in English (and
>  probably not in any other language), whereas "bit" and "bits" have
>  more than a dozen homonyms in English---some of which are quite common
>  in general currency usage, Bitcoin currency usage, or Bitcoin
>  technical usage.
> 
> - Microbitcoins trains users to understand SI prefixes, allowing them to
>  easily migrate from one prefix to the next.  This will be important
>  when bitcoin prices rise to $10M USD[1] and the bits denomination has
>  the same problems the millibitcoin denomination has now, but it's also
>  useful in the short term when interacting with users who make very
>  large payments (bitcoin-scale) or very small payments
>  (nanobitcoin-scale).[2]  Maybe a table of scale can emphasize this
>  point:
> 
>      Wrong (IMO):        Right (IMO):
>      ---------------     --------------
>      BTC                 BTC
>      mBTC                mBTC
>      bits                ?BTC
>      nBTC                nBTC
> 
> [1] A rise in price to $10M doesn't require huge levels of growth---it
> only requires time under the assumption that a percentage of bitcoins will
> be lost every year due to wallet mishaps, failure to inherit bitcoins,
> and other issues that remove bitcoins from circulation.  In other words,
> it's important to remember that Bitcoin is expected to become a
> deflationary currency and plan accordingly.
> 
> [2] Although Bitcoin does not currently support committed
> nanobitcoin-scale payments in the block chain, it can be supported in a
> variety of ways by offchain systems---including (it is hypothesized)
> trustless systems based on probabilistic payments.
> 
> Thanks,
> 
> -Dave
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: Message signed with OpenPGP
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171214/b27a9030/attachment.sig>

From marcel at jamin.net  Thu Dec 14 08:02:44 2017
From: marcel at jamin.net (Marcel Jamin)
Date: Thu, 14 Dec 2017 09:02:44 +0100
Subject: [bitcoin-dev] BIP Proposal: Utilization of bits denomination
In-Reply-To: <20171213213607.ijlvqwpdaokucgi6@fedora-23-dvm>
References: <CAJR7vkqcBo+o9BL8sK1TBqqNUNSMWdut_aL_YMXse8rDC2ju9A@mail.gmail.com>
	<20171213213607.ijlvqwpdaokucgi6@fedora-23-dvm>
Message-ID: <CAAUq485pTYs++FY9GkAt64gvba_Mngzpui7TWXdQM-x9GyAQdg@mail.gmail.com>

On 13 December 2017 at 22:36, David A. Harding via bitcoin-dev
<bitcoin-dev at lists.linuxfoundation.org> wrote:
> - Microbitcoins is not a homonym for any other word in English (and
>   probably not in any other language), whereas "bit" and "bits" have
>   more than a dozen homonyms in English---some of which are quite common
>   in general currency usage, Bitcoin currency usage, or Bitcoin
>   technical usage.

Reposting /u/BashCo's post on reddit here, for visibility:

---8<---------------------------------------------------------------

> Before anyone says 'bits' are too confusing because it's a computer science term, here's a list of homonyms [https://en.wikipedia.org/wiki/List_of_true_homonyms] that you use every day. Homonyms are fine because our brains are able to interpret language based on context, so it's a non-argument. Also, the term 'bits' was used in reference to money long before 'bits and bytes' came along, and even before the metric system itself.

> https://en.wikipedia.org/wiki/Bit_(money)

> https://en.wikipedia.org/wiki/Spanish_colonial_real

> 'Bits' are superior to mBTC partly because we'll need to transition to bits eventually anyways (one transition is easier than two), but more importantly, bits have two decimal places, matching the format of dozens of other major currencies.

> No other currency has 8 decimal places, or even 4 decimal places. Most of them have 2. Dollars and cents, Bits and satoshis.

> If people actually want this to happen, then they need to train their own brains by switching their wallets and exchange settings to bits. The shift will probably happen eventually, although the major Bitcoin denomination probably isn't going anywhere any time soon, even if the majority of people use 'bits' as a matter of habit.

> 99.99 bits is currently equal to $1.63 USD.

---8<---------------------------------------------------------------

>
> - Microbitcoins trains users to understand SI prefixes, allowing them to
>   easily migrate from one prefix to the next.  This will be important
>   when bitcoin prices rise to $10M USD[1] and the bits denomination has
>   the same problems the millibitcoin denomination has now, but it's also
>   useful in the short term when interacting with users who make very
>   large payments (bitcoin-scale) or very small payments
>   (nanobitcoin-scale).[2]  Maybe a table of scale can emphasize this
>   point:
>
>       Wrong (IMO):        Right (IMO):
>       ---------------     --------------
>       BTC                 BTC
>       mBTC                mBTC
>       bits                ?BTC
>       nBTC                nBTC
>

I wouldn't expect people to type out ?BTC. I think the best you can
hope for here is uBTC. As for saying "microbitcoins", I can virtually
guarantee that this will be abbreviated to "microbits" and/or
eventually "bits" anyway. Bits and sats.

> [1] A rise in price to $10M doesn't require huge levels of growth---it
> only requires time under the assumption that a percentage of bitcoins will
> be lost every year due to wallet mishaps, failure to inherit bitcoins,
> and other issues that remove bitcoins from circulation.  In other words,
> it's important to remember that Bitcoin is expected to become a
> deflationary currency and plan accordingly.
>
> [2] Although Bitcoin does not currently support committed
> nanobitcoin-scale payments in the block chain, it can be supported in a
> variety of ways by offchain systems---including (it is hypothesized)
> trustless systems based on probabilistic payments.
>
> Thanks,
>
> -Dave
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>

From natanael.l at gmail.com  Thu Dec 14 22:01:09 2017
From: natanael.l at gmail.com (Natanael)
Date: Thu, 14 Dec 2017 23:01:09 +0100
Subject: [bitcoin-dev] BIP Proposal: Utilization of bits denomination
In-Reply-To: <CAAUq485pTYs++FY9GkAt64gvba_Mngzpui7TWXdQM-x9GyAQdg@mail.gmail.com>
References: <CAJR7vkqcBo+o9BL8sK1TBqqNUNSMWdut_aL_YMXse8rDC2ju9A@mail.gmail.com>
	<20171213213607.ijlvqwpdaokucgi6@fedora-23-dvm>
	<CAAUq485pTYs++FY9GkAt64gvba_Mngzpui7TWXdQM-x9GyAQdg@mail.gmail.com>
Message-ID: <CAAt2M19ZrbvrKc+mz1LEKrM2AuGH01gN+i9w8zSvdmazommMxg@mail.gmail.com>

Reposting /u/BashCo's post on reddit here, for visibility:

---8<---------------------------------------------------------------

> Before anyone says 'bits' are too confusing because it's a computer
science term, here's a list of homonyms [https://en.wikipedia.org/
wiki/List_of_true_homonyms] that you use every day. Homonyms are fine
because our brains are able to interpret language based on context, so it's
a non-argument.


This ignores the fact that there exists multiple meanings of bits *within
the same context*, and that beginners likely can't tell them apart.

Feel free to try it yourself - talk about Bitcoin "bits" of a particular
value with somebody who  doesn't understand Bitcoin. Then explain that the
cryptography uses 256 bit keys. I would be surprised if you could find
somebody who would not be confused by that.

Let's say a website says a song is 24 bits. Was that 24 bit audio
resolution or 24 bit price? Somebody writes about 256 bit keys, are that
their size or value?

You guys here can probably tell the difference. Can everybody...? Bits will
cause confusion, because plenty of people will not be able to tell these
apart. They will not know WHEN to apply one definition or the other.

https://www.reddit.com/r/bitcoin/comments/24m3nb/_/ch8gua7
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171214/75a7967d/attachment.html>

From clark at clarkmoody.com  Thu Dec 14 23:11:17 2017
From: clark at clarkmoody.com (Clark Moody)
Date: Thu, 14 Dec 2017 17:11:17 -0600
Subject: [bitcoin-dev] BIP Proposal: Utilization of bits denomination
In-Reply-To: <CAAt2M19ZrbvrKc+mz1LEKrM2AuGH01gN+i9w8zSvdmazommMxg@mail.gmail.com>
References: <CAJR7vkqcBo+o9BL8sK1TBqqNUNSMWdut_aL_YMXse8rDC2ju9A@mail.gmail.com>
	<20171213213607.ijlvqwpdaokucgi6@fedora-23-dvm>
	<CAAUq485pTYs++FY9GkAt64gvba_Mngzpui7TWXdQM-x9GyAQdg@mail.gmail.com>
	<CAAt2M19ZrbvrKc+mz1LEKrM2AuGH01gN+i9w8zSvdmazommMxg@mail.gmail.com>
Message-ID: <CAHGSxGsTP8DeFnyWZRQStT4rvEv9k3QLd30JQ=f0EdEaui--NA@mail.gmail.com>

An alternative to "training" users to understand SI prefixes could be to
make 100 satoshi = 1 mu, spelling out the Greek letter.

Although the Units <https://en.bitcoin.it/wiki/Units> page on the wiki has
been brought up to argue against naming 10,000 satoshi = 1 finney, I would
like to support this designation. It seems to be gaining some popular
support on Twitter & podcasts. So at $10,000 BTC/USD, 1 finney = $1.00. The
smallest unit of value would be 0.0001 finney = 1 satoshi. Finney has a
natural abbreviation as fin, and 100 mu = 1 finney.

The Units page also refers to "bitcent" as 0.01 BTC, but if a "bit" is 100
satoshi, then what is a "bitcent" in that context?

/bikeshed

@Natanael you're exactly right. There are already multiple uses of "bits"
within bitcoin itself.

@Sjors I don't think a redefinition of 'satoshi' is going to happen ;-)



-Clark

On Thu, Dec 14, 2017 at 4:01 PM, Natanael via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

>
> Reposting /u/BashCo's post on reddit here, for visibility:
>
> ---8<---------------------------------------------------------------
>
> > Before anyone says 'bits' are too confusing because it's a computer
> science term, here's a list of homonyms [https://en.wikipedia.org/wiki
> /List_of_true_homonyms] that you use every day. Homonyms are fine because
> our brains are able to interpret language based on context, so it's a
> non-argument.
>
>
> This ignores the fact that there exists multiple meanings of bits *within
> the same context*, and that beginners likely can't tell them apart.
>
> Feel free to try it yourself - talk about Bitcoin "bits" of a particular
> value with somebody who  doesn't understand Bitcoin. Then explain that the
> cryptography uses 256 bit keys. I would be surprised if you could find
> somebody who would not be confused by that.
>
> Let's say a website says a song is 24 bits. Was that 24 bit audio
> resolution or 24 bit price? Somebody writes about 256 bit keys, are that
> their size or value?
>
> You guys here can probably tell the difference. Can everybody...? Bits
> will cause confusion, because plenty of people will not be able to tell
> these apart. They will not know WHEN to apply one definition or the other.
>
> https://www.reddit.com/r/bitcoin/comments/24m3nb/_/ch8gua7
>
>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171214/73f8b8ef/attachment-0001.html>

From marcel at jamin.net  Fri Dec 15 06:27:10 2017
From: marcel at jamin.net (Marcel Jamin)
Date: Fri, 15 Dec 2017 07:27:10 +0100
Subject: [bitcoin-dev] BIP Proposal: Utilization of bits denomination
In-Reply-To: <CAAt2M19ZrbvrKc+mz1LEKrM2AuGH01gN+i9w8zSvdmazommMxg@mail.gmail.com>
References: <CAJR7vkqcBo+o9BL8sK1TBqqNUNSMWdut_aL_YMXse8rDC2ju9A@mail.gmail.com>
	<20171213213607.ijlvqwpdaokucgi6@fedora-23-dvm>
	<CAAUq485pTYs++FY9GkAt64gvba_Mngzpui7TWXdQM-x9GyAQdg@mail.gmail.com>
	<CAAt2M19ZrbvrKc+mz1LEKrM2AuGH01gN+i9w8zSvdmazommMxg@mail.gmail.com>
Message-ID: <CAAUq487ijoaWV46YHSS_tRak8gigT7jvfUBQ=mRntkfz9KV57Q@mail.gmail.com>

I think one could make the argument that the only people who talk
about and understand 24 bit audio or 256 bit cryptography are the ones
who can tell the difference very easily.

To me, your example seems to try hard to make the case for a problem
that won't exist in reality.

Bitcoin (BTC), Millibitcoin (mBTC) and Microbitcoin (?BTC) is the
>correct< approach. It's tidy, systematic and precise. But that won't
stop people from using something that's easier to deal with as I just
had to google the ? character again.

Let's also keep in mind that Coinbase has been using "bits" as the
default for over 2 years now:
https://blog.coinbase.com/bits-is-the-new-default-and-all-new-users-get-100-bits-for-free-9165f757594b

Just from a linguistic standpoint, chances are we'll end up with bits
anyway. Why fight it? We don't have a SI prefix educational mandate.

Marcel

On 14 December 2017 at 23:01, Natanael <natanael.l at gmail.com> wrote:
>
> Reposting /u/BashCo's post on reddit here, for visibility:
>
> ---8<---------------------------------------------------------------
>
>> Before anyone says 'bits' are too confusing because it's a computer
>> science term, here's a list of homonyms
>> [https://en.wikipedia.org/wiki/List_of_true_homonyms] that you use every
>> day. Homonyms are fine because our brains are able to interpret language
>> based on context, so it's a non-argument.
>
>
> This ignores the fact that there exists multiple meanings of bits *within
> the same context*, and that beginners likely can't tell them apart.
>
> Feel free to try it yourself - talk about Bitcoin "bits" of a particular
> value with somebody who  doesn't understand Bitcoin. Then explain that the
> cryptography uses 256 bit keys. I would be surprised if you could find
> somebody who would not be confused by that.
>
> Let's say a website says a song is 24 bits. Was that 24 bit audio resolution
> or 24 bit price? Somebody writes about 256 bit keys, are that their size or
> value?
>
> You guys here can probably tell the difference. Can everybody...? Bits will
> cause confusion, because plenty of people will not be able to tell these
> apart. They will not know WHEN to apply one definition or the other.
>
> https://www.reddit.com/r/bitcoin/comments/24m3nb/_/ch8gua7
>
>

From willtech at live.com.au  Fri Dec 15 09:42:42 2017
From: willtech at live.com.au (Damian Williamson)
Date: Fri, 15 Dec 2017 09:42:42 +0000
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction
 Priority For Ordering Transactions In Blocks
In-Reply-To: <PS2P216MB01794ABD544248B27BF0DFD99D330@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
References: <PS2P216MB01794ABD544248B27BF0DFD99D330@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
Message-ID: <PS2P216MB01795BFC05612E021CCEDD7C9D0B0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>

I should not take it that the lack of critical feedback to this revised proposal is a glowing endorsement. I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?

I suppose that it if is difficult to determine how long a transaction has been waiting in the pool then, each node could simply keep track of when a transaction was first seen. This may have implications for a verify routine, however, for example, if a node was offline, how should it differentiate how long each transaction was waiting in that case? If a node was restarted daily would it always think that all transactions had been waiting in the pool less than one day If each node keeps the current transaction pool in a file and updates it, as transactions are included in blocks and, as new transactions appear in the pool, then that would go some way to alleviate the issue, apart from entirely new nodes. There should be no reason the contents of a transaction pool files cannot be shared without agreement as to the transaction pool between nodes, just as nodes transmit new transactions freely.

It has been questioned why miners could not cheat. For the question of how many transactions to include in a block, I say it is a standoff and miners will conform to the proposal, not wanting to leave transactions with valid fees standing, and, not wanting to shrink the transaction pool. In any case, if miners shrink the transaction pool then I am not immediately concerned since it provides a more efficient service. For the question of including transactions according to the proposal, I say if it is possible to keep track of how long transactions are waiting in the pool so that they can be included on a probability curve then it is possible to verify that blocks conform to the proposal, since the input is a probability, the output should conform to a probability curve.


If someone has the necessary skill, would anyone be willing to develop the math necessary for the proposal?

Regards,
Damian Williamson

________________________________
From: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>
Sent: Friday, 8 December 2017 8:01 AM
To: bitcoin-dev at lists.linuxfoundation.org
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks


Good afternoon,

The need for this proposal:

We all must learn to admit that transaction bandwidth is still lurking as a serious issue for the operation, reliability, safety, consumer acceptance, uptake and, for the value of Bitcoin.

I recently sent a payment which was not urgent so; I chose three-day target confirmation from the fee recommendation. That transaction has still not confirmed after now more than six days - even waiting twice as long seems quite reasonable to me. That transaction is a valid transaction; it is not rubbish, junk or, spam. Under the current model with transaction bandwidth limitation, the longer a transaction waits, the less likely it is ever to confirm due to rising transaction numbers and being pushed back by transactions with rising fees.

I argue that no transactions are rubbish or junk, only some zero fee transactions might be spam. Having an ever-increasing number of valid transactions that do not confirm as more new transactions with higher fees are created is the opposite of operating a robust, reliable transaction system.

Business cannot operate with a model where transactions may or may not confirm. Even a business choosing a modest fee has no guarantee that their valid transaction will not be shuffled down by new transactions to the realm of never confirming after it is created. Consumers also will not accept this model as Bitcoin expands. If Bitcoin cannot be a reliable payment system for confirmed transactions then consumers, by and large, will simply not accept the model once they understand. Bitcoin will be a dirty payment system, and this will kill the value of Bitcoin.

Under the current system, a minority of transactions will eventually be the lucky few who have fees high enough to escape being pushed down the list.

Once there are more than x transactions (transaction bandwidth limit) every ten minutes, only those choosing twenty-minute confirmation (2 blocks) will have initially at most a fifty percent chance of ever having their payment confirm. Presently, not even using fee recommendations can ensure a sufficiently high fee is paid to ensure transaction confirmation.

I also argue that the current auction model for limited transaction bandwidth is wrong, is not suitable for a reliable transaction system and, is wrong for Bitcoin. All transactions must confirm in due time. Currently, Bitcoin is not a safe way to send payments.

I do not believe that consumers and business are against paying fees, even high fees. What is required is operational reliability.

This great issue needs to be resolved for the safety and reliability of Bitcoin. The time to resolve issues in commerce is before they become great big issues. The time to resolve this issue is now. We must have the foresight to identify and resolve problems before they trip us over.  Simply doubling block sizes every so often is reactionary and is not a reliable permanent solution. I have written a BIP proposal for a technical solution but, need your help to write it up to an acceptable standard to be a full BIP.

I have formatted the following with markdown which is human readable so, I hope nobody minds. I have done as much with this proposal as I feel that I am able so far but continue to take your feedback.

# BIP Proposal: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks

## The problem:
Everybody wants value. Miners want to maximize revenue from fees (and we presume, to minimize block size). Consumers need transaction reliability and, (we presume) want low fees.

The current transaction bandwidth limit is a limiting factor for both. As the operational safety of transactions is limited, so is consumer confidence as they realize the issue and, accordingly, uptake is limited. Fees are artificially inflated due to bandwidth limitations while failing to provide a full confirmation service for all transactions.

Current fee recommendations provide no satisfaction for transaction reliability and, as Bitcoin scales, this will worsen.

Bitcoin must be a fully scalable and reliable service, providing full transaction confirmation for every valid transaction.

The possibility to send a transaction with a fee lower than one that is acceptable to allow eventual transaction confirmation should be removed from the protocol and also from the user interface.

## Solution summary:
Provide each transaction with an individual transaction priority each time before choosing transactions to include in the current block, the priority being a function of the fee paid (on a curve), and the time waiting in the transaction pool (also on a curve) out to n days (n=60 ?). The transaction priority to serve as the likelihood of a transaction being included in the current block, and for determining the order in which transactions are tried to see if they will be included.

Use a target block size. Determine the target block size using; current transaction pool size x ( 1 / (144 x n days ) ) = number of transactions to be included in the current block. Broadcast the next target block size with the current block when it is solved so that nodes know the next target block size for the block that they are building on.

The curves used for the priority of transactions would have to be appropriate. Perhaps a mathematician with experience in probability can develop the right formulae. My thinking is a steep curve. I suppose that the probability of all transactions should probably account for a sufficient number of inclusions that the target block size is met although, it may not always be. As a suggestion, consider including some zero fee transactions to pad, highest BTC value first?

**Explanation of the operation of priority:**
> If transaction priority is, for example, a number between one (low) and one-hundred (high) it can be directly understood as the percentage chance in one-hundred of a transaction being included in the block. Using probability or likelihood infers that there is some function of random. If random (100) < transaction priority then the transaction is included.

>To break it down further, if both the fee on a curve value and the time waiting on a curve value are each a number between one and one-hundred, a rudimentary method may be to simply multiply those two numbers, to find the priority number. For example, a middle fee transaction waiting thirty days (if n = 60 days) may have a value of five for each part  (yes, just five, the values are on a curve). When multiplied that will give a priority value of twenty-five, or,  a twenty-five percent chance at that moment of being included in the block; it will likely be included in one of the next four blocks, getting more likely each chance. If it is still not included then the value of time waiting will be higher, making for more probability. A very low fee transaction would have a value for the fee of one. It would not be until near sixty-days that the particular low fee transaction has a high likelihood of being included in the block.

I am not concerned with low (or high) transaction fees, the primary reason for addressing the issue is to ensure transactional reliability and scalability while having each transaction confirm in due time.

## Pros:
* Maximizes transaction reliability.
* Fully scalable.
* Maximizes possibility for consumer and business uptake.
* Maximizes total fees paid per block without reducing reliability; because of reliability, in time confidence and overall uptake are greater; therefore, more transactions.
* Market determines fee paid for transaction priority.
* Fee recommendations work all the way out to 30 days or greater.
* Provides additional block entropy; greater security since there is less probability of predicting the next block.

## Cons:
* Could initially lower total transaction fees per block.
* Must be first be programmed.

## Solution operation:
This is a simplistic view of the operation. The actual operation will need to be determined in a spec for the programmer.

1. Determine the target block size for the current block.
2. Assign a transaction priority to each transaction in the pool.
3. Select transactions to include in the current block using probability in transaction priority order until the target block size is met.
5. Solve block.
6. Broadcast the next target block size with the current block when it is solved.
7. Block is received.
8. Block verification process.
9. Accept/reject block based on verification result.
10. Repeat.

## Closing comments:
It may be possible to verify blocks conform to the proposal by showing that the probability for all transactions included in the block statistically conforms to a probability distribution curve, *if* the individual transaction priority can be recreated. I am not that deep into the mathematics; however, it may also be possible to use a similar method to do this just based on the fee, that statistically, the blocks conform to a fee distribution. Any zero fee transactions would have to be ignored. This solution needs a clever mathematician.

I implore, at the very least, that we use some method that validates full transaction reliability and enables scalability of block sizes. If not this proposal, an alternative.

Regards,
Damian Williamson
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171215/dc268c35/attachment-0001.html>

From ethan.scruples at gmail.com  Fri Dec 15 18:20:34 2017
From: ethan.scruples at gmail.com (Moral Agent)
Date: Fri, 15 Dec 2017 13:20:34 -0500
Subject: [bitcoin-dev] BIP Proposal: Utilization of bits denomination
In-Reply-To: <CAAUq487ijoaWV46YHSS_tRak8gigT7jvfUBQ=mRntkfz9KV57Q@mail.gmail.com>
References: <CAJR7vkqcBo+o9BL8sK1TBqqNUNSMWdut_aL_YMXse8rDC2ju9A@mail.gmail.com>
	<20171213213607.ijlvqwpdaokucgi6@fedora-23-dvm>
	<CAAUq485pTYs++FY9GkAt64gvba_Mngzpui7TWXdQM-x9GyAQdg@mail.gmail.com>
	<CAAt2M19ZrbvrKc+mz1LEKrM2AuGH01gN+i9w8zSvdmazommMxg@mail.gmail.com>
	<CAAUq487ijoaWV46YHSS_tRak8gigT7jvfUBQ=mRntkfz9KV57Q@mail.gmail.com>
Message-ID: <CACiOHGwwgQJOPwaH8EKZbzx2QpnujnDe9XV1M72Tz46_u+mcgg@mail.gmail.com>

>Bitcoin (BTC), Millibitcoin (mBTC) and Microbitcoin (?BTC) is the >correct<
approach. It's tidy, systematic and precise.

The SI system is great, but it's nice if you pick a base unit that is easy
for intuition to comprehend.

It is a fact that I weigh approximately .000,000,000,000,000,000,000,014
Earth masses. If we arrived at rough consensus that this was a cumbersome
way to express the mass of a human, we might then find a group of people
making the superficially sensible proposal that we use SI prefixes and say
I weigh 14 yoctoearths. This would be tidy, systematic and precise, but
that might not be enough to make it the best option. It might be even
better to choose a base unit that human intuition can make sense of, and
THEN add prefixes as needed.

I dislike the name "bits" but I think 100 satoshis does make a nice base
unit. If we cannot crowdsource a more inspiring label we may be stuck with
bits just due to linguistic network effects.

-Ethan



On Fri, Dec 15, 2017 at 1:27 AM, Marcel Jamin via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> I think one could make the argument that the only people who talk
> about and understand 24 bit audio or 256 bit cryptography are the ones
> who can tell the difference very easily.
>
> To me, your example seems to try hard to make the case for a problem
> that won't exist in reality.
>
> Bitcoin (BTC), Millibitcoin (mBTC) and Microbitcoin (?BTC) is the
> >correct< approach. It's tidy, systematic and precise. But that won't
> stop people from using something that's easier to deal with as I just
> had to google the ? character again.
>
> Let's also keep in mind that Coinbase has been using "bits" as the
> default for over 2 years now:
> https://blog.coinbase.com/bits-is-the-new-default-and-
> all-new-users-get-100-bits-for-free-9165f757594b
>
> Just from a linguistic standpoint, chances are we'll end up with bits
> anyway. Why fight it? We don't have a SI prefix educational mandate.
>
> Marcel
>
> On 14 December 2017 at 23:01, Natanael <natanael.l at gmail.com> wrote:
> >
> > Reposting /u/BashCo's post on reddit here, for visibility:
> >
> > ---8<---------------------------------------------------------------
> >
> >> Before anyone says 'bits' are too confusing because it's a computer
> >> science term, here's a list of homonyms
> >> [https://en.wikipedia.org/wiki/List_of_true_homonyms] that you use
> every
> >> day. Homonyms are fine because our brains are able to interpret language
> >> based on context, so it's a non-argument.
> >
> >
> > This ignores the fact that there exists multiple meanings of bits *within
> > the same context*, and that beginners likely can't tell them apart.
> >
> > Feel free to try it yourself - talk about Bitcoin "bits" of a particular
> > value with somebody who  doesn't understand Bitcoin. Then explain that
> the
> > cryptography uses 256 bit keys. I would be surprised if you could find
> > somebody who would not be confused by that.
> >
> > Let's say a website says a song is 24 bits. Was that 24 bit audio
> resolution
> > or 24 bit price? Somebody writes about 256 bit keys, are that their size
> or
> > value?
> >
> > You guys here can probably tell the difference. Can everybody...? Bits
> will
> > cause confusion, because plenty of people will not be able to tell these
> > apart. They will not know WHEN to apply one definition or the other.
> >
> > https://www.reddit.com/r/bitcoin/comments/24m3nb/_/ch8gua7
> >
> >
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171215/491a9809/attachment.html>

From rhavar at protonmail.com  Fri Dec 15 16:38:46 2017
From: rhavar at protonmail.com (Rhavar)
Date: Fri, 15 Dec 2017 11:38:46 -0500
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction
	Priority For Ordering Transactions In Blocks
In-Reply-To: <PS2P216MB01795BFC05612E021CCEDD7C9D0B0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
References: <PS2P216MB01794ABD544248B27BF0DFD99D330@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<PS2P216MB01795BFC05612E021CCEDD7C9D0B0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
Message-ID: <5upGmF0IhXUWhcikhdV-e9Pqg-kXfUuXe0kOpGxumie_TO2jLvCgTZ5c6vgBRtaqkL6DmOJb1YftK0osufB5RkhW7YhAhhCI0zBTH3YcORY=@protonmail.com>

> I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?

Unfortunately your proposal is really fundamentally broken, on a few levels. I think you might need to do a bit more research into how bitcoin works before coming up with such improvements =)

But just some quick notes:

* Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.

* Increasing the entropy in a block to make it more unpredictable doesn't really make sense.

* Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by "priority".  What are you going to do if a "malicious" miner decides to go after their profits and order by what makes them the most money. Add "ordered by priority" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.

If you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.

-Ryan

> -------- Original Message --------
> Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks
> Local Time: December 15, 2017 3:42 AM
> UTC Time: December 15, 2017 9:42 AM
> From: bitcoin-dev at lists.linuxfoundation.org
> To: Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>
>
> I should not take it that the lack of critical feedback to this revised proposal is a glowing endorsement. I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?
>
> I suppose that it if is difficult to determine how long a transaction has been waiting in the pool then, each node could simply keep track of when a transaction was first seen. This may have implications for a verify routine, however, for example, if a node was offline, how should it differentiate how long each transaction was waiting in that case? If a node was restarted daily would it always think that all transactions had been waiting in the pool less than one day If each node keeps the current transaction pool in a file and updates it, as transactions are included in blocks and, as new transactions appear in the pool, then that would go some way to alleviate the issue, apart from entirely new nodes. There should be no reason the contents of a transaction pool files cannot be shared without agreement as to the transaction pool between nodes, just as nodes transmit new transactions freely.
>
> It has been questioned why miners could not cheat. For the question of how many transactions to include in a block, I say it is a standoff and miners will conform to the proposal, not wanting to leave transactions with valid fees standing, and, not wanting to shrink the transaction pool. In any case, if miners shrink the transaction pool then I am not immediately concerned since it provides a more efficient service. For the question of including transactions according to the proposal, I say if it is possible to keep track of how long transactions are waiting in the pool so that they can be included on a probability curve then it is possible to verify that blocks conform to the proposal, since the input is a probability, the output should conform to a probability curve.
>
> If someone has the necessary skill, would anyone be willing to develop the math necessary for the proposal?
>
> Regards,
> Damian Williamson
>
> ---------------------------------------------------------------
>
> From: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>
> Sent: Friday, 8 December 2017 8:01 AM
> To: bitcoin-dev at lists.linuxfoundation.org
> Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks
>
> Good afternoon,
>
> The need for this proposal:
>
> We all must learn to admit that transaction bandwidth is still lurking as a serious issue for the operation, reliability, safety, consumer acceptance, uptake and, for the value of Bitcoin.
>
> I recently sent a payment which was not urgent so; I chose three-day target confirmation from the fee recommendation. That transaction has still not confirmed after now more than six days - even waiting twice as long seems quite reasonable to me. That transaction is a valid transaction; it is not rubbish, junk or, spam. Under the current model with transaction bandwidth limitation, the longer a transaction waits, the less likely it is ever to confirm due to rising transaction numbers and being pushed back by transactions with rising fees.
>
> I argue that no transactions are rubbish or junk, only some zero fee transactions might be spam. Having an ever-increasing number of valid transactions that do not confirm as more new transactions with higher fees are created is the opposite of operating a robust, reliable transaction system.
>
> Business cannot operate with a model where transactions may or may not confirm. Even a business choosing a modest fee has no guarantee that their valid transaction will not be shuffled down by new transactions to the realm of never confirming after it is created. Consumers also will not accept this model as Bitcoin expands. If Bitcoin cannot be a reliable payment system for confirmed transactions then consumers, by and large, will simply not accept the model once they understand. Bitcoin will be a dirty payment system, and this will kill the value of Bitcoin.
>
> Under the current system, a minority of transactions will eventually be the lucky few who have fees high enough to escape being pushed down the list.
>
> Once there are more than x transactions (transaction bandwidth limit) every ten minutes, only those choosing twenty-minute confirmation (2 blocks) will have initially at most a fifty percent chance of ever having their payment confirm. Presently, not even using fee recommendations can ensure a sufficiently high fee is paid to ensure transaction confirmation.
>
> I also argue that the current auction model for limited transaction bandwidth is wrong, is not suitable for a reliable transaction system and, is wrong for Bitcoin. All transactions must confirm in due time. Currently, Bitcoin is not a safe way to send payments.
>
> I do not believe that consumers and business are against paying fees, even high fees. What is required is operational reliability.
>
> This great issue needs to be resolved for the safety and reliability of Bitcoin. The time to resolve issues in commerce is before they become great big issues. The time to resolve this issue is now. We must have the foresight to identify and resolve problems before they trip us over.  Simply doubling block sizes every so often is reactionary and is not a reliable permanent solution. I have written a BIP proposal for a technical solution but, need your help to write it up to an acceptable standard to be a full BIP.
>
> I have formatted the following with markdown which is human readable so, I hope nobody minds. I have done as much with this proposal as I feel that I am able so far but continue to take your feedback.
>
> # BIP Proposal: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks
>
> ## The problem:
> Everybody wants value. Miners want to maximize revenue from fees (and we presume, to minimize block size). Consumers need transaction reliability and, (we presume) want low fees.
>
> The current transaction bandwidth limit is a limiting factor for both. As the operational safety of transactions is limited, so is consumer confidence as they realize the issue and, accordingly, uptake is limited. Fees are artificially inflated due to bandwidth limitations while failing to provide a full confirmation service for all transactions.
>
> Current fee recommendations provide no satisfaction for transaction reliability and, as Bitcoin scales, this will worsen.
>
> Bitcoin must be a fully scalable and reliable service, providing full transaction confirmation for every valid transaction.
>
> The possibility to send a transaction with a fee lower than one that is acceptable to allow eventual transaction confirmation should be removed from the protocol and also from the user interface.
>
> ## Solution summary:
> Provide each transaction with an individual transaction priority each time before choosing transactions to include in the current block, the priority being a function of the fee paid (on a curve), and the time waiting in the transaction pool (also on a curve) out to n days (n=60 ?). The transaction priority to serve as the likelihood of a transaction being included in the current block, and for determining the order in which transactions are tried to see if they will be included.
>
> Use a target block size. Determine the target block size using; current transaction pool size x ( 1 / (144 x n days ) ) = number of transactions to be included in the current block. Broadcast the next target block size with the current block when it is solved so that nodes know the next target block size for the block that they are building on.
>
> The curves used for the priority of transactions would have to be appropriate. Perhaps a mathematician with experience in probability can develop the right formulae. My thinking is a steep curve. I suppose that the probability of all transactions should probably account for a sufficient number of inclusions that the target block size is met although, it may not always be. As a suggestion, consider including some zero fee transactions to pad, highest BTC value first?
>
> **Explanation of the operation of priority:**
>> If transaction priority is, for example, a number between one (low) and one-hundred (high) it can be directly understood as the percentage chance in one-hundred of a transaction being included in the block. Using probability or likelihood infers that there is some function of random. If random (100) < transaction priority then the transaction is included.
>
>>To break it down further, if both the fee on a curve value and the time waiting on a curve value are each a number between one and one-hundred, a rudimentary method may be to simply multiply those two numbers, to find the priority number. For example, a middle fee transaction waiting thirty days (if n = 60 days) may have a value of five for each part  (yes, just five, the values are on a curve). When multiplied that will give a priority value of twenty-five, or,  a twenty-five percent chance at that moment of being included in the block; it will likely be included in one of the next four blocks, getting more likely each chance. If it is still not included then the value of time waiting will be higher, making for more probability. A very low fee transaction would have a value for the fee of one. It would not be until near sixty-days that the particular low fee transaction has a high likelihood of being included in the block.
>
> I am not concerned with low (or high) transaction fees, the primary reason for addressing the issue is to ensure transactional reliability and scalability while having each transaction confirm in due time.
>
> ## Pros:
> * Maximizes transaction reliability.
> * Fully scalable.
> * Maximizes possibility for consumer and business uptake.
> * Maximizes total fees paid per block without reducing reliability; because of reliability, in time confidence and overall uptake are greater; therefore, more transactions.
> * Market determines fee paid for transaction priority.
> * Fee recommendations work all the way out to 30 days or greater.
> * Provides additional block entropy; greater security since there is less probability of predicting the next block.
>
> ## Cons:
> * Could initially lower total transaction fees per block.
> * Must be first be programmed.
>
> ## Solution operation:
> This is a simplistic view of the operation. The actual operation will need to be determined in a spec for the programmer.
>
> 1. Determine the target block size for the current block.
> 2. Assign a transaction priority to each transaction in the pool.
> 3. Select transactions to include in the current block using probability in transaction priority order until the target block size is met.
> 5. Solve block.
> 6. Broadcast the next target block size with the current block when it is solved.
> 7. Block is received.
> 8. Block verification process.
> 9. Accept/reject block based on verification result.
> 10. Repeat.
>
> ## Closing comments:
> It may be possible to verify blocks conform to the proposal by showing that the probability for all transactions included in the block statistically conforms to a probability distribution curve, *if* the individual transaction priority can be recreated. I am not that deep into the mathematics; however, it may also be possible to use a similar method to do this just based on the fee, that statistically, the blocks conform to a fee distribution. Any zero fee transactions would have to be ignored. This solution needs a clever mathematician.
>
> I implore, at the very least, that we use some method that validates full transaction reliability and enables scalability of block sizes. If not this proposal, an alternative.
>
> Regards,
> Damian Williamson
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171215/4158a992/attachment-0001.html>

From rhavar at protonmail.com  Fri Dec 15 18:46:45 2017
From: rhavar at protonmail.com (Rhavar)
Date: Fri, 15 Dec 2017 13:46:45 -0500
Subject: [bitcoin-dev] BIP Proposal: Utilization of bits denomination
In-Reply-To: <CACiOHGwwgQJOPwaH8EKZbzx2QpnujnDe9XV1M72Tz46_u+mcgg@mail.gmail.com>
References: <CAJR7vkqcBo+o9BL8sK1TBqqNUNSMWdut_aL_YMXse8rDC2ju9A@mail.gmail.com>
	<20171213213607.ijlvqwpdaokucgi6@fedora-23-dvm>
	<CAAUq485pTYs++FY9GkAt64gvba_Mngzpui7TWXdQM-x9GyAQdg@mail.gmail.com>
	<CAAt2M19ZrbvrKc+mz1LEKrM2AuGH01gN+i9w8zSvdmazommMxg@mail.gmail.com>
	<CAAUq487ijoaWV46YHSS_tRak8gigT7jvfUBQ=mRntkfz9KV57Q@mail.gmail.com>
	<CACiOHGwwgQJOPwaH8EKZbzx2QpnujnDe9XV1M72Tz46_u+mcgg@mail.gmail.com>
Message-ID: <vccoLzOawXMLVXWO7cHkpI92LU1akgsBpB3RjpG3z6hYWeMragOrlW-DQhWvlJLommiipBJoyj5QJ1NP55OPpRwynGINcP0uM3nSMgV1CV0=@protonmail.com>

I don't have anything interesting to add, except that I have been using 'bits' on my site for over 3 years. It's a great unit that people quickly adapt to, and it's far more convenient. When dealing with large amounts of money, people have no problem naturally thinking in "thousand bits" or "million bits" (a bitcoin).

I would highly encourage it to be a default everywhere. Consistency is really important.

Also slightly unrelated, but the whole "sat/B" thing for fees is such a clusterfuck. Half the time it's used as "vbyte" and half the time actual bytes. Users are constantly confused because of explorers and wallet and stuff all showing it inconsistently. I would suggest there that there is a "standard" of "bits per kiloweight" (i.e. how many bits of fees to pay for a transaction that is 1000 weight)

-Ryan

> -------- Original Message --------
> Subject: Re: [bitcoin-dev] BIP Proposal: Utilization of bits denomination
> Local Time: December 15, 2017 12:20 PM
> UTC Time: December 15, 2017 6:20 PM
> From: bitcoin-dev at lists.linuxfoundation.org
> To: Marcel Jamin <marcel at jamin.net>, Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>
>
>>Bitcoin (BTC), Millibitcoin (mBTC) and Microbitcoin (?BTC) is the >correct< approach. It's tidy, systematic and precise.
>
> The SI system is great, but it's nice if you pick a base unit that is easy for intuition to comprehend.
>
> It is a fact that I weigh approximately .000,000,000,000,000,000,000,014 Earth masses. If we arrived at rough consensus that this was a cumbersome way to express the mass of a human, we might then find a group of people making the superficially sensible proposal that we use SI prefixes and say I weigh 14 yoctoearths. This would be tidy, systematic and precise, but that might not be enough to make it the best option. It might be even better to choose a base unit that human intuition can make sense of, and THEN add prefixes as needed.
>
> I dislike the name "bits" but I think 100 satoshis does make a nice base unit. If we cannot crowdsource a more inspiring label we may be stuck with bits just due to linguistic network effects.
>
> -Ethan
>
> On Fri, Dec 15, 2017 at 1:27 AM, Marcel Jamin via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>> I think one could make the argument that the only people who talk
>> about and understand 24 bit audio or 256 bit cryptography are the ones
>> who can tell the difference very easily.
>>
>> To me, your example seems to try hard to make the case for a problem
>> that won't exist in reality.
>>
>> Bitcoin (BTC), Millibitcoin (mBTC) and Microbitcoin (?BTC) is the
>>>correct< approach. It's tidy, systematic and precise. But that won't
>> stop people from using something that's easier to deal with as I just
>> had to google the ? character again.
>>
>> Let's also keep in mind that Coinbase has been using "bits" as the
>> default for over 2 years now:
>> https://blog.coinbase.com/bits-is-the-new-default-and-all-new-users-get-100-bits-for-free-9165f757594b
>>
>> Just from a linguistic standpoint, chances are we'll end up with bits
>> anyway. Why fight it? We don't have a SI prefix educational mandate.
>>
>> Marcel
>>
>> On 14 December 2017 at 23:01, Natanael <natanael.l at gmail.com> wrote:
>>>
>>> Reposting /u/BashCo's post on reddit here, for visibility:
>>>
>>> ---8<---------------------------------------------------------------
>>>
>>>> Before anyone says 'bits' are too confusing because it's a computer
>>>> science term, here's a list of homonyms
>>>> [https://en.wikipedia.org/wiki/List_of_true_homonyms] that you use every
>>>> day. Homonyms are fine because our brains are able to interpret language
>>>> based on context, so it's a non-argument.
>>>
>>>
>>> This ignores the fact that there exists multiple meanings of bits *within
>>> the same context*, and that beginners likely can't tell them apart.
>>>
>>> Feel free to try it yourself - talk about Bitcoin "bits" of a particular
>>> value with somebody who  doesn't understand Bitcoin. Then explain that the
>>> cryptography uses 256 bit keys. I would be surprised if you could find
>>> somebody who would not be confused by that.
>>>
>>> Let's say a website says a song is 24 bits. Was that 24 bit audio resolution
>>> or 24 bit price? Somebody writes about 256 bit keys, are that their size or
>>> value?
>>>
>>> You guys here can probably tell the difference. Can everybody...? Bits will
>>> cause confusion, because plenty of people will not be able to tell these
>>> apart. They will not know WHEN to apply one definition or the other.
>>>
>>> https://www.reddit.com/r/bitcoin/comments/24m3nb/_/ch8gua7
>>>
>>>
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171215/375ec903/attachment.html>

From jim.posen at gmail.com  Fri Dec 15 23:55:16 2017
From: jim.posen at gmail.com (Jim Posen)
Date: Fri, 15 Dec 2017 15:55:16 -0800
Subject: [bitcoin-dev] Parallel header download during sync
Message-ID: <CADZtCSjR8Cd30Ag__+Rr2FV8rdbYY4_bUgGKeEgpoyTjxzM=dw@mail.gmail.com>

One of the ideas that Greg Maxwell brought up in the "'Compressed' headers
stream" thread is the possibility of a header sync mechanism that allowed
parallel download from multiple peers. With the current getheaders/headers
semantics, headers must be downloaded sequentially from genesis. In my
testing, I saw that syncing headers directly from a colocated node took <5s
whereas syncing normally from network peers takes ~5 min for me, which goes
to show that 5s is an upper bound on the time to process all headers if
they are locally available. So if we can introduce new p2p messages for
header sync, what would they look like? Here's one idea.

A new getheadersv2 request would include a start height for the range of
headers requested and a commitment to the last block in the chain that you
want to download. Then you find N peers that are all on the same chain,
partition the range of headers from 0 to the chain height minus some
reasonable reorg safety buffer (~6 blocks), and send download requests in
parallel. So how do we know that the peers are on the same chain and that
their headers served connect into this chain?

When you connect to outbound peers and are in IBD, you will query them for
a Merkle Mountain Range commitment to all headers up to a height X (which
is 6ish blocks before their start height from the version message). Then
you choose the commitment that the majority of the queried peers sent (or
some other heuristic), and these become your download peers. Every
getheadersv2 request includes the start height, X, and the chain
commitment. The headersv2 response messages include all of the headers
followed by a merkle branch linking the last header into the chain
commitment. Headers are processed in order as they arrive and if any of the
headers are invalid, you can ban/disconnect all peers that committed to it,
drop the buffer of later headers and start over.

That's the basic idea. Here are other details:

- This would require an additional 32-byte MMR commitment for each header
in memory.
- When a node receives a headersv2 request and constructs a merkle proof
for the last header, it checks against the sent commitment. In the case of
a really deep reorg, that check would fail, and the node can instead
respond with an updated commitment hash for that height.
- Another packet is needed, getheaderchain or something, that a syncing
peer first sends along with a header locator and an end height. The peer
responds with headerchain, which includes the last common header from the
locator along with the chain commitment at that height and a merkle branch
proving inclusion of that header in the chain.
- Nodes would cache chain commitments for the last ~20 blocks (somewhat
arbitrary), and refuse to serve chain commitments for heights before that.

Thoughts? This is a pretty recycled idea, so please point me at prior
proposals that are similar as well.

-jimpo
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171215/267e7064/attachment-0001.html>

From sjors at sprovoost.nl  Mon Dec 18 11:26:19 2017
From: sjors at sprovoost.nl (Sjors Provoost)
Date: Mon, 18 Dec 2017 12:26:19 +0100
Subject: [bitcoin-dev] A DNS-like decentralized mapping for wallet
 addresses?
In-Reply-To: <c889543b-8dbe-b88c-5f47-7aee1db697aa@vt.edu>
References: <CAHneDF3qH9OUxqLthY6hEzzFr21QJFLV5wOP8jw+p5eOtpb2oQ@mail.gmail.com>
	<c889543b-8dbe-b88c-5f47-7aee1db697aa@vt.edu>
Message-ID: <1085B203-DB5E-42AB-A9F3-467D09246314@sprovoost.nl>

Have you thought about combining this with BIP-47? You could associate payment codes with email via DNS.

It would be nice if there was a way to get rid of the announcement transaction in BIP-47 and establish a shared secret out of bound. That would simplify things, at the cost of an additional burden of storing more than an HD seed to recover a wallet that received funds this way.

Perhaps the sender can email to the recipient the information they need to retrieve the funds. The (first) transaction could have a time locked refund in it, in case the payment code is stale.

Sjors

> Op 1 dec. 2017, om 04:08 heeft Douglas Roark via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> het volgende geschreven:
> 
> On 2017/11/30 14:20, mandar mulherkar via bitcoin-dev wrote:
>> I was wondering in terms of mass adoption, instead of long wallet
>> addresses, maybe there should be a DNS-like decentralized mapping
>> service to provide a user at crypto address?
> 
> A few years ago, I was part of an effort with Armory and Verisign to
> make something similar to what you're describing.
> https://tools.ietf.org/html/draft-wiley-paymentassoc-00 is where you can
> find the one and only official draft. I worked on a follow-up with some
> changes and some nice appendices, explaining some nice tricks one could
> use to make payment management flexible. For various reasons, it never
> got published. I think it's an interesting draft that could be turned
> into something useful. Among other things, it was able to leverage BIP32
> and allow payment requests to be generated that automatically pointed
> payees to the correct branch. DNSSEC may have some issues but, AFAIK,
> it's as the easiest way to bootstrap identity to a common, reasonably
> secure standard.
> 
> --
> ---
> Douglas Roark
> Cryptocurrency, network security, travel, and art.
> https://onename.com/droark
> joroark at vt.edu
> PGP key ID: 26623924
> 
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: Message signed with OpenPGP
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171218/376f96f6/attachment.sig>

From kalle at rosenbaum.se  Mon Dec 18 08:32:23 2017
From: kalle at rosenbaum.se (Kalle Rosenbaum)
Date: Mon, 18 Dec 2017 09:32:23 +0100
Subject: [bitcoin-dev] Why not witnessless nodes?
Message-ID: <CAPswA9ycPdTtm9PeD5a2R36cZ46HwnkwJu06FXuoE-F5Dx+eZQ@mail.gmail.com>

Dear list,

I find it hard to understand why a full node that does initial block
download also must download witnesses if they are going to skip
verification anyway. If my full node skips signature verification for
blocks earlier than X, it seems the reasons for downloading the
witnesses for those blocks are:

* to be able to send witnesses to other nodes.

* to verify the witness root hash of the blocks

I suppose that it's important to verify the witness root hash because
a bad peer may send me invalid witnesses during initial block
download, and if I don't verify that the witness root hash actually
commits to them, I will get banned by peers requesting the blocks from
me because I send them garbage.

So both the reasons above (there may be more that I don't know about)
are actually the same reason: To be able to send witnesses to others
without getting banned.

What if a node could chose not to download witnesses and thus chose to
send only witnessless blocks to peers. Let's call these nodes
witnessless nodes. Note that witnessless nodes are only witnessless
for blocks up to X. Everything after X is fully verified.

Witnessless nodes would be able to sync faster because it needs to
download less data to calculate their UTXO set. They would therefore
more quickly be able to provide full service to SPV wallets and its
local wallets as well as serving blocks to other witnessless nodes
with same or higher assumevalid block. For witnessless nodes with
lower assumevalid they can serve at least some blocks. It could also
serve blocks to non-segwit nodes.

Do witnessless nodes risk dividing the network in two parts, one
witnessless and one with full nodes, with few connections between the
parts?

So basically, what are the reasons not to implement witnessless
nodes?

Thank you,
/Kalle
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171218/34624abd/attachment.html>

From willtech at live.com.au  Fri Dec 15 20:59:51 2017
From: willtech at live.com.au (Damian Williamson)
Date: Fri, 15 Dec 2017 20:59:51 +0000
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction
 Priority For Ordering Transactions In Blocks
In-Reply-To: <5upGmF0IhXUWhcikhdV-e9Pqg-kXfUuXe0kOpGxumie_TO2jLvCgTZ5c6vgBRtaqkL6DmOJb1YftK0osufB5RkhW7YhAhhCI0zBTH3YcORY=@protonmail.com>
References: <PS2P216MB01794ABD544248B27BF0DFD99D330@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<PS2P216MB01795BFC05612E021CCEDD7C9D0B0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>,
	<5upGmF0IhXUWhcikhdV-e9Pqg-kXfUuXe0kOpGxumie_TO2jLvCgTZ5c6vgBRtaqkL6DmOJb1YftK0osufB5RkhW7YhAhhCI0zBTH3YcORY=@protonmail.com>
Message-ID: <PS2P216MB0179544A6503C2992190CEB69D0B0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>

There are really two separate problems to solve.


  1.  How does Bitcoin scale with fixed block size?
  2.  How do we ensure that all valid transactions are eventually included in the blockchain?


Those are the two issues that the proposal attempts to address. It makes sense to resolve these two problems together. Using the proposed system for variable block sizes would solve the first problem but there would still be a whole bunch of never confirming transactions. I am not sure how to reliably solve the second problem at scale without first solving the first.


>* Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.

I do not suggest a consensus. Depending on which node solves a block the value for next block size will be different. The consensus would be that blocks will adhere to the next block size value transmitted with the current block. It is easy to verify that the consensus is being adhered to once in place.

>* Increasing the entropy in a block to make it more unpredictable doesn't really make sense.

Not a necessary function, just an effect of using a probability-based distribution.

>* Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by "priority".  What are you going to do if a "malicious" miner decides to go after their profits and order by what makes them the most money. Add "ordered by priority" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.

I entirely agree with your sentiment that Bitcoin must be incentive compatible. It is necessary.

It is in only miners immediate interest to make the most profitable block from the available transaction pool. As with so many other things, it is necessary to partially ignore short-term gain for long-term benefit. It is in miners and everybody's long-term interest to have a reliable transaction service. A busy transaction service that confirms lots of transactions per hour will become more profitable as demand increases and more users are prepared to pay for priority. As it is there is currently no way to fully scale because of the transaction bandwidth limit and that is problematic. If all valid transactions must eventually confirm then there must be a way to resolve that problem.

Bitcoin deliberately removes traditional scale by ensuring blocks take ten minutes on average to solve, an ingenious idea and, incentive compatible but, fixed block sizes leaves us with a problem to solve when we want to scale.

>If you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.

I am confident that the math to verify blocks based on the proposal can be developed (and I think it will not be too complex for a mathematician with the relevant experience), however, I am nowhere near experienced enough with probability and statistical analysis to do it. Yes, if Bitcoin doesn't then it might make another great opportunity for an altcoin but I am not even nearly interested in promoting any altcoins.


If not the proposal that I have put forward, then, hopefully, someone can come up with a better solution. The important thing is that the issues are resolved.


Regards,

Damian Williamson


________________________________
From: Rhavar <rhavar at protonmail.com>
Sent: Saturday, 16 December 2017 3:38 AM
To: Damian Williamson
Cc: Bitcoin Protocol Discussion
Subject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks

> I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?

Unfortunately your proposal is really fundamentally broken, on a few levels. I think you might need to do a bit more research into how bitcoin works before coming up with such improvements =)

But just some quick notes:

* Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.

* Increasing the entropy in a block to make it more unpredictable doesn't really make sense.

* Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by "priority".  What are you going to do if a "malicious" miner decides to go after their profits and order by what makes them the most money. Add "ordered by priority" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.

If you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.




-Ryan


-------- Original Message --------
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks
Local Time: December 15, 2017 3:42 AM
UTC Time: December 15, 2017 9:42 AM
From: bitcoin-dev at lists.linuxfoundation.org
To: Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>




I should not take it that the lack of critical feedback to this revised proposal is a glowing endorsement. I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?

I suppose that it if is difficult to determine how long a transaction has been waiting in the pool then, each node could simply keep track of when a transaction was first seen. This may have implications for a verify routine, however, for example, if a node was offline, how should it differentiate how long each transaction was waiting in that case? If a node was restarted daily would it always think that all transactions had been waiting in the pool less than one day If each node keeps the current transaction pool in a file and updates it, as transactions are included in blocks and, as new transactions appear in the pool, then that would go some way to alleviate the issue, apart from entirely new nodes. There should be no reason the contents of a transaction pool files cannot be shared without agreement as to the transaction pool between nodes, just as nodes transmit new transactions freely.

It has been questioned why miners could not cheat. For the question of how many transactions to include in a block, I say it is a standoff and miners will conform to the proposal, not wanting to leave transactions with valid fees standing, and, not wanting to shrink the transaction pool. In any case, if miners shrink the transaction pool then I am not immediately concerned since it provides a more efficient service. For the question of including transactions according to the proposal, I say if it is possible to keep track of how long transactions are waiting in the pool so that they can be included on a probability curve then it is possible to verify that blocks conform to the proposal, since the input is a probability, the output should conform to a probability curve.



If someone has the necessary skill, would anyone be willing to develop the math necessary for the proposal?

Regards,
Damian Williamson


________________________________

From: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>
Sent: Friday, 8 December 2017 8:01 AM
To: bitcoin-dev at lists.linuxfoundation.org
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks



Good afternoon,

The need for this proposal:

We all must learn to admit that transaction bandwidth is still lurking as a serious issue for the operation, reliability, safety, consumer acceptance, uptake and, for the value of Bitcoin.

I recently sent a payment which was not urgent so; I chose three-day target confirmation from the fee recommendation. That transaction has still not confirmed after now more than six days - even waiting twice as long seems quite reasonable to me. That transaction is a valid transaction; it is not rubbish, junk or, spam. Under the current model with transaction bandwidth limitation, the longer a transaction waits, the less likely it is ever to confirm due to rising transaction numbers and being pushed back by transactions with rising fees.

I argue that no transactions are rubbish or junk, only some zero fee transactions might be spam. Having an ever-increasing number of valid transactions that do not confirm as more new transactions with higher fees are created is the opposite of operating a robust, reliable transaction system.

Business cannot operate with a model where transactions may or may not confirm. Even a business choosing a modest fee has no guarantee that their valid transaction will not be shuffled down by new transactions to the realm of never confirming after it is created. Consumers also will not accept this model as Bitcoin expands. If Bitcoin cannot be a reliable payment system for confirmed transactions then consumers, by and large, will simply not accept the model once they understand. Bitcoin will be a dirty payment system, and this will kill the value of Bitcoin.

Under the current system, a minority of transactions will eventually be the lucky few who have fees high enough to escape being pushed down the list.

Once there are more than x transactions (transaction bandwidth limit) every ten minutes, only those choosing twenty-minute confirmation (2 blocks) will have initially at most a fifty percent chance of ever having their payment confirm. Presently, not even using fee recommendations can ensure a sufficiently high fee is paid to ensure transaction confirmation.

I also argue that the current auction model for limited transaction bandwidth is wrong, is not suitable for a reliable transaction system and, is wrong for Bitcoin. All transactions must confirm in due time. Currently, Bitcoin is not a safe way to send payments.

I do not believe that consumers and business are against paying fees, even high fees. What is required is operational reliability.

This great issue needs to be resolved for the safety and reliability of Bitcoin. The time to resolve issues in commerce is before they become great big issues. The time to resolve this issue is now. We must have the foresight to identify and resolve problems before they trip us over.  Simply doubling block sizes every so often is reactionary and is not a reliable permanent solution. I have written a BIP proposal for a technical solution but, need your help to write it up to an acceptable standard to be a full BIP.

I have formatted the following with markdown which is human readable so, I hope nobody minds. I have done as much with this proposal as I feel that I am able so far but continue to take your feedback.

# BIP Proposal: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks

## The problem:
Everybody wants value. Miners want to maximize revenue from fees (and we presume, to minimize block size). Consumers need transaction reliability and, (we presume) want low fees.

The current transaction bandwidth limit is a limiting factor for both. As the operational safety of transactions is limited, so is consumer confidence as they realize the issue and, accordingly, uptake is limited. Fees are artificially inflated due to bandwidth limitations while failing to provide a full confirmation service for all transactions.

Current fee recommendations provide no satisfaction for transaction reliability and, as Bitcoin scales, this will worsen.

Bitcoin must be a fully scalable and reliable service, providing full transaction confirmation for every valid transaction.

The possibility to send a transaction with a fee lower than one that is acceptable to allow eventual transaction confirmation should be removed from the protocol and also from the user interface.

## Solution summary:
Provide each transaction with an individual transaction priority each time before choosing transactions to include in the current block, the priority being a function of the fee paid (on a curve), and the time waiting in the transaction pool (also on a curve) out to n days (n=60 ?). The transaction priority to serve as the likelihood of a transaction being included in the current block, and for determining the order in which transactions are tried to see if they will be included.

Use a target block size. Determine the target block size using; current transaction pool size x ( 1 / (144 x n days ) ) = number of transactions to be included in the current block. Broadcast the next target block size with the current block when it is solved so that nodes know the next target block size for the block that they are building on.

The curves used for the priority of transactions would have to be appropriate. Perhaps a mathematician with experience in probability can develop the right formulae. My thinking is a steep curve. I suppose that the probability of all transactions should probably account for a sufficient number of inclusions that the target block size is met although, it may not always be. As a suggestion, consider including some zero fee transactions to pad, highest BTC value first?

**Explanation of the operation of priority:**
> If transaction priority is, for example, a number between one (low) and one-hundred (high) it can be directly understood as the percentage chance in one-hundred of a transaction being included in the block. Using probability or likelihood infers that there is some function of random. If random (100) < transaction priority then the transaction is included.

>To break it down further, if both the fee on a curve value and the time waiting on a curve value are each a number between one and one-hundred, a rudimentary method may be to simply multiply those two numbers, to find the priority number. For example, a middle fee transaction waiting thirty days (if n = 60 days) may have a value of five for each part  (yes, just five, the values are on a curve). When multiplied that will give a priority value of twenty-five, or,  a twenty-five percent chance at that moment of being included in the block; it will likely be included in one of the next four blocks, getting more likely each chance. If it is still not included then the value of time waiting will be higher, making for more probability. A very low fee transaction would have a value for the fee of one. It would not be until near sixty-days that the particular low fee transaction has a high likelihood of being included in the block.

I am not concerned with low (or high) transaction fees, the primary reason for addressing the issue is to ensure transactional reliability and scalability while having each transaction confirm in due time.

## Pros:
* Maximizes transaction reliability.
* Fully scalable.
* Maximizes possibility for consumer and business uptake.
* Maximizes total fees paid per block without reducing reliability; because of reliability, in time confidence and overall uptake are greater; therefore, more transactions.
* Market determines fee paid for transaction priority.
* Fee recommendations work all the way out to 30 days or greater.
* Provides additional block entropy; greater security since there is less probability of predicting the next block.

## Cons:
* Could initially lower total transaction fees per block.
* Must be first be programmed.

## Solution operation:
This is a simplistic view of the operation. The actual operation will need to be determined in a spec for the programmer.

1. Determine the target block size for the current block.
2. Assign a transaction priority to each transaction in the pool.
3. Select transactions to include in the current block using probability in transaction priority order until the target block size is met.
5. Solve block.
6. Broadcast the next target block size with the current block when it is solved.
7. Block is received.
8. Block verification process.
9. Accept/reject block based on verification result.
10. Repeat.

## Closing comments:
It may be possible to verify blocks conform to the proposal by showing that the probability for all transactions included in the block statistically conforms to a probability distribution curve, *if* the individual transaction priority can be recreated. I am not that deep into the mathematics; however, it may also be possible to use a similar method to do this just based on the fee, that statistically, the blocks conform to a fee distribution. Any zero fee transactions would have to be ignored. This solution needs a clever mathematician.

I implore, at the very least, that we use some method that validates full transaction reliability and enables scalability of block sizes. If not this proposal, an alternative.

Regards,
Damian Williamson


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171215/b36462c3/attachment-0001.html>

From willtech at live.com.au  Sun Dec 17 04:14:39 2017
From: willtech at live.com.au (Damian Williamson)
Date: Sun, 17 Dec 2017 04:14:39 +0000
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction
 Priority For Ordering Transactions In Blocks
In-Reply-To: <PS2P216MB0179544A6503C2992190CEB69D0B0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
References: <PS2P216MB01794ABD544248B27BF0DFD99D330@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<PS2P216MB01795BFC05612E021CCEDD7C9D0B0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>,
	<5upGmF0IhXUWhcikhdV-e9Pqg-kXfUuXe0kOpGxumie_TO2jLvCgTZ5c6vgBRtaqkL6DmOJb1YftK0osufB5RkhW7YhAhhCI0zBTH3YcORY=@protonmail.com>,
	<PS2P216MB0179544A6503C2992190CEB69D0B0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
Message-ID: <PS2P216MB0179D6A5965D0CFFEFB2880A9D090@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>

I do not know why people make the leap that the proposal requires a consensus on the transaction pool. It does not.


It may be helpful to have the discussion from the previous thread linked here.

https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/015370.html


Where I speak of validating that a block conforms to the broadcast next block size, I do not propose validating the number broadcast for the next block size itself, only that the next generated block is that size.


Regards,

Damian Williamson


________________________________
From: Damian Williamson <willtech at live.com.au>
Sent: Saturday, 16 December 2017 7:59 AM
To: Rhavar
Cc: Bitcoin Protocol Discussion
Subject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks


There are really two separate problems to solve.


  1.  How does Bitcoin scale with fixed block size?
  2.  How do we ensure that all valid transactions are eventually included in the blockchain?


Those are the two issues that the proposal attempts to address. It makes sense to resolve these two problems together. Using the proposed system for variable block sizes would solve the first problem but there would still be a whole bunch of never confirming transactions. I am not sure how to reliably solve the second problem at scale without first solving the first.


>* Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.

I do not suggest a consensus. Depending on which node solves a block the value for next block size will be different. The consensus would be that blocks will adhere to the next block size value transmitted with the current block. It is easy to verify that the consensus is being adhered to once in place.

>* Increasing the entropy in a block to make it more unpredictable doesn't really make sense.

Not a necessary function, just an effect of using a probability-based distribution.

>* Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by "priority".  What are you going to do if a "malicious" miner decides to go after their profits and order by what makes them the most money. Add "ordered by priority" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.

I entirely agree with your sentiment that Bitcoin must be incentive compatible. It is necessary.

It is in only miners immediate interest to make the most profitable block from the available transaction pool. As with so many other things, it is necessary to partially ignore short-term gain for long-term benefit. It is in miners and everybody's long-term interest to have a reliable transaction service. A busy transaction service that confirms lots of transactions per hour will become more profitable as demand increases and more users are prepared to pay for priority. As it is there is currently no way to fully scale because of the transaction bandwidth limit and that is problematic. If all valid transactions must eventually confirm then there must be a way to resolve that problem.

Bitcoin deliberately removes traditional scale by ensuring blocks take ten minutes on average to solve, an ingenious idea and, incentive compatible but, fixed block sizes leaves us with a problem to solve when we want to scale.

>If you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.

I am confident that the math to verify blocks based on the proposal can be developed (and I think it will not be too complex for a mathematician with the relevant experience), however, I am nowhere near experienced enough with probability and statistical analysis to do it. Yes, if Bitcoin doesn't then it might make another great opportunity for an altcoin but I am not even nearly interested in promoting any altcoins.


If not the proposal that I have put forward, then, hopefully, someone can come up with a better solution. The important thing is that the issues are resolved.


Regards,

Damian Williamson


________________________________
From: Rhavar <rhavar at protonmail.com>
Sent: Saturday, 16 December 2017 3:38 AM
To: Damian Williamson
Cc: Bitcoin Protocol Discussion
Subject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks

> I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?

Unfortunately your proposal is really fundamentally broken, on a few levels. I think you might need to do a bit more research into how bitcoin works before coming up with such improvements =)

But just some quick notes:

* Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.

* Increasing the entropy in a block to make it more unpredictable doesn't really make sense.

* Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by "priority".  What are you going to do if a "malicious" miner decides to go after their profits and order by what makes them the most money. Add "ordered by priority" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.

If you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.




-Ryan


-------- Original Message --------
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks
Local Time: December 15, 2017 3:42 AM
UTC Time: December 15, 2017 9:42 AM
From: bitcoin-dev at lists.linuxfoundation.org
To: Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>




I should not take it that the lack of critical feedback to this revised proposal is a glowing endorsement. I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?

I suppose that it if is difficult to determine how long a transaction has been waiting in the pool then, each node could simply keep track of when a transaction was first seen. This may have implications for a verify routine, however, for example, if a node was offline, how should it differentiate how long each transaction was waiting in that case? If a node was restarted daily would it always think that all transactions had been waiting in the pool less than one day If each node keeps the current transaction pool in a file and updates it, as transactions are included in blocks and, as new transactions appear in the pool, then that would go some way to alleviate the issue, apart from entirely new nodes. There should be no reason the contents of a transaction pool files cannot be shared without agreement as to the transaction pool between nodes, just as nodes transmit new transactions freely.

It has been questioned why miners could not cheat. For the question of how many transactions to include in a block, I say it is a standoff and miners will conform to the proposal, not wanting to leave transactions with valid fees standing, and, not wanting to shrink the transaction pool. In any case, if miners shrink the transaction pool then I am not immediately concerned since it provides a more efficient service. For the question of including transactions according to the proposal, I say if it is possible to keep track of how long transactions are waiting in the pool so that they can be included on a probability curve then it is possible to verify that blocks conform to the proposal, since the input is a probability, the output should conform to a probability curve.



If someone has the necessary skill, would anyone be willing to develop the math necessary for the proposal?

Regards,
Damian Williamson


________________________________

From: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>
Sent: Friday, 8 December 2017 8:01 AM
To: bitcoin-dev at lists.linuxfoundation.org
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks



Good afternoon,

The need for this proposal:

We all must learn to admit that transaction bandwidth is still lurking as a serious issue for the operation, reliability, safety, consumer acceptance, uptake and, for the value of Bitcoin.

I recently sent a payment which was not urgent so; I chose three-day target confirmation from the fee recommendation. That transaction has still not confirmed after now more than six days - even waiting twice as long seems quite reasonable to me. That transaction is a valid transaction; it is not rubbish, junk or, spam. Under the current model with transaction bandwidth limitation, the longer a transaction waits, the less likely it is ever to confirm due to rising transaction numbers and being pushed back by transactions with rising fees.

I argue that no transactions are rubbish or junk, only some zero fee transactions might be spam. Having an ever-increasing number of valid transactions that do not confirm as more new transactions with higher fees are created is the opposite of operating a robust, reliable transaction system.

Business cannot operate with a model where transactions may or may not confirm. Even a business choosing a modest fee has no guarantee that their valid transaction will not be shuffled down by new transactions to the realm of never confirming after it is created. Consumers also will not accept this model as Bitcoin expands. If Bitcoin cannot be a reliable payment system for confirmed transactions then consumers, by and large, will simply not accept the model once they understand. Bitcoin will be a dirty payment system, and this will kill the value of Bitcoin.

Under the current system, a minority of transactions will eventually be the lucky few who have fees high enough to escape being pushed down the list.

Once there are more than x transactions (transaction bandwidth limit) every ten minutes, only those choosing twenty-minute confirmation (2 blocks) will have initially at most a fifty percent chance of ever having their payment confirm. Presently, not even using fee recommendations can ensure a sufficiently high fee is paid to ensure transaction confirmation.

I also argue that the current auction model for limited transaction bandwidth is wrong, is not suitable for a reliable transaction system and, is wrong for Bitcoin. All transactions must confirm in due time. Currently, Bitcoin is not a safe way to send payments.

I do not believe that consumers and business are against paying fees, even high fees. What is required is operational reliability.

This great issue needs to be resolved for the safety and reliability of Bitcoin. The time to resolve issues in commerce is before they become great big issues. The time to resolve this issue is now. We must have the foresight to identify and resolve problems before they trip us over.  Simply doubling block sizes every so often is reactionary and is not a reliable permanent solution. I have written a BIP proposal for a technical solution but, need your help to write it up to an acceptable standard to be a full BIP.

I have formatted the following with markdown which is human readable so, I hope nobody minds. I have done as much with this proposal as I feel that I am able so far but continue to take your feedback.

# BIP Proposal: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks

## The problem:
Everybody wants value. Miners want to maximize revenue from fees (and we presume, to minimize block size). Consumers need transaction reliability and, (we presume) want low fees.

The current transaction bandwidth limit is a limiting factor for both. As the operational safety of transactions is limited, so is consumer confidence as they realize the issue and, accordingly, uptake is limited. Fees are artificially inflated due to bandwidth limitations while failing to provide a full confirmation service for all transactions.

Current fee recommendations provide no satisfaction for transaction reliability and, as Bitcoin scales, this will worsen.

Bitcoin must be a fully scalable and reliable service, providing full transaction confirmation for every valid transaction.

The possibility to send a transaction with a fee lower than one that is acceptable to allow eventual transaction confirmation should be removed from the protocol and also from the user interface.

## Solution summary:
Provide each transaction with an individual transaction priority each time before choosing transactions to include in the current block, the priority being a function of the fee paid (on a curve), and the time waiting in the transaction pool (also on a curve) out to n days (n=60 ?). The transaction priority to serve as the likelihood of a transaction being included in the current block, and for determining the order in which transactions are tried to see if they will be included.

Use a target block size. Determine the target block size using; current transaction pool size x ( 1 / (144 x n days ) ) = number of transactions to be included in the current block. Broadcast the next target block size with the current block when it is solved so that nodes know the next target block size for the block that they are building on.

The curves used for the priority of transactions would have to be appropriate. Perhaps a mathematician with experience in probability can develop the right formulae. My thinking is a steep curve. I suppose that the probability of all transactions should probably account for a sufficient number of inclusions that the target block size is met although, it may not always be. As a suggestion, consider including some zero fee transactions to pad, highest BTC value first?

**Explanation of the operation of priority:**
> If transaction priority is, for example, a number between one (low) and one-hundred (high) it can be directly understood as the percentage chance in one-hundred of a transaction being included in the block. Using probability or likelihood infers that there is some function of random. If random (100) < transaction priority then the transaction is included.

>To break it down further, if both the fee on a curve value and the time waiting on a curve value are each a number between one and one-hundred, a rudimentary method may be to simply multiply those two numbers, to find the priority number. For example, a middle fee transaction waiting thirty days (if n = 60 days) may have a value of five for each part  (yes, just five, the values are on a curve). When multiplied that will give a priority value of twenty-five, or,  a twenty-five percent chance at that moment of being included in the block; it will likely be included in one of the next four blocks, getting more likely each chance. If it is still not included then the value of time waiting will be higher, making for more probability. A very low fee transaction would have a value for the fee of one. It would not be until near sixty-days that the particular low fee transaction has a high likelihood of being included in the block.

I am not concerned with low (or high) transaction fees, the primary reason for addressing the issue is to ensure transactional reliability and scalability while having each transaction confirm in due time.

## Pros:
* Maximizes transaction reliability.
* Fully scalable.
* Maximizes possibility for consumer and business uptake.
* Maximizes total fees paid per block without reducing reliability; because of reliability, in time confidence and overall uptake are greater; therefore, more transactions.
* Market determines fee paid for transaction priority.
* Fee recommendations work all the way out to 30 days or greater.
* Provides additional block entropy; greater security since there is less probability of predicting the next block.

## Cons:
* Could initially lower total transaction fees per block.
* Must be first be programmed.

## Solution operation:
This is a simplistic view of the operation. The actual operation will need to be determined in a spec for the programmer.

1. Determine the target block size for the current block.
2. Assign a transaction priority to each transaction in the pool.
3. Select transactions to include in the current block using probability in transaction priority order until the target block size is met.
5. Solve block.
6. Broadcast the next target block size with the current block when it is solved.
7. Block is received.
8. Block verification process.
9. Accept/reject block based on verification result.
10. Repeat.

## Closing comments:
It may be possible to verify blocks conform to the proposal by showing that the probability for all transactions included in the block statistically conforms to a probability distribution curve, *if* the individual transaction priority can be recreated. I am not that deep into the mathematics; however, it may also be possible to use a similar method to do this just based on the fee, that statistically, the blocks conform to a fee distribution. Any zero fee transactions would have to be ignored. This solution needs a clever mathematician.

I implore, at the very least, that we use some method that validates full transaction reliability and enables scalability of block sizes. If not this proposal, an alternative.

Regards,
Damian Williamson


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171217/371a19f8/attachment-0001.html>

From criley at gmail.com  Mon Dec 18 12:09:34 2017
From: criley at gmail.com (Chris Riley)
Date: Mon, 18 Dec 2017 07:09:34 -0500
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction
 Priority For Ordering Transactions In Blocks
In-Reply-To: <PS2P216MB0179544A6503C2992190CEB69D0B0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
References: <PS2P216MB01794ABD544248B27BF0DFD99D330@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<PS2P216MB01795BFC05612E021CCEDD7C9D0B0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<5upGmF0IhXUWhcikhdV-e9Pqg-kXfUuXe0kOpGxumie_TO2jLvCgTZ5c6vgBRtaqkL6DmOJb1YftK0osufB5RkhW7YhAhhCI0zBTH3YcORY=@protonmail.com>
	<PS2P216MB0179544A6503C2992190CEB69D0B0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CAL5BAw0pQJg8MjopRH5ReBVHmJR0bYud=E6fkFuY=-3hMAumEw@mail.gmail.com>

Regarding "problem" #2 where you say "How do we ensure that all valid
transactions are eventually included in the blockchain?":  I do not believe
that all people would (a) agree this is a problem or (b) that we do want to
*ENSURE* that *ALL* valid transactions are eventually included in the
blockchain.  There are many *valid* transactions that oftentimes miners do
not (and should not) wish to require be confirmed and included in the
blockchain.  Spam transactions for example can be valid, but used to attack
bitcoin by using no or low fee.  Any valid transaction MAY be included by a
miner, but requiring it in some fashion at this point would open the
network to other attack vectors.  Perhaps you meant it a different way.


On Fri, Dec 15, 2017 at 3:59 PM, Damian Williamson via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:
>
> There are really two separate problems to solve.
>
>
> How does Bitcoin scale with fixed block size?
> How do we ensure that all valid transactions are eventually included in
the blockchain?
>
>
> Those are the two issues that the proposal attempts to address. It makes
sense to resolve these two problems together. Using the proposed system for
variable block sizes would solve the first problem but there would still be
a whole bunch of never confirming transactions. I am not sure how to
reliably solve the second problem at scale without first solving the first.
>
>
> >* Every node has a (potentially) different mempool, you can't use it to
decide consensus values like the max block size.
>
>
> I do not suggest a consensus. Depending on which node solves a block the
value for next block size will be different. The consensus would be that
blocks will adhere to the next block size value transmitted with the
current block. It is easy to verify that the consensus is being adhered to
once in place.
>
> >* Increasing the entropy in a block to make it more unpredictable
doesn't really make sense.
>
> Not a necessary function, just an effect of using a probability-based
distribution.
>
> >* Bitcoin should be roughly incentive compatible. Your proposal
explicits asks miners to ignore their best interests, and confirm
transactions by "priority".  What are you going to do if a "malicious"
miner decides to go after their profits and order by what makes them the
most money. Add "ordered by priority" as a consensus requirement? And even
if you miners can still sort their mempool by fee, and then order the top
1MB by priority.
>
> I entirely agree with your sentiment that Bitcoin must be incentive
compatible. It is necessary.
>
> It is in only miners immediate interest to make the most profitable block
from the available transaction pool. As with so many other things, it is
necessary to partially ignore short-term gain for long-term benefit. It is
in miners and everybody's long-term interest to have a reliable transaction
service. A busy transaction service that confirms lots of transactions per
hour will become more profitable as demand increases and more users are
prepared to pay for priority. As it is there is currently no way to fully
scale because of the transaction bandwidth limit and that is problematic.
If all valid transactions must eventually confirm then there must be a way
to resolve that problem.
>
> Bitcoin deliberately removes traditional scale by ensuring blocks take
ten minutes on average to solve, an ingenious idea and, incentive
compatible but, fixed block sizes leaves us with a problem to solve when we
want to scale.
>
> >If you could find a good solution that would allow you to know if miners
were following your rule or not (and thus ignore it if it doesn't) then you
wouldn't even need bitcoin in the first place.
>
> I am confident that the math to verify blocks based on the proposal can
be developed (and I think it will not be too complex for a mathematician
with the relevant experience), however, I am nowhere near experienced
enough with probability and statistical analysis to do it. Yes, if Bitcoin
doesn't then it might make another great opportunity for an altcoin but I
am not even nearly interested in promoting any altcoins.
>
>
> If not the proposal that I have put forward, then, hopefully, someone can
come up with a better solution. The important thing is that the issues are
resolved.
>
>
> Regards,
>
> Damian Williamson
>
>
>
> ________________________________
> From: Rhavar <rhavar at protonmail.com>
> Sent: Saturday, 16 December 2017 3:38 AM
> To: Damian Williamson
> Cc: Bitcoin Protocol Discussion
> Subject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use
Transaction Priority For Ordering Transactions In Blocks
>
> > I understand that there would be technical issues to resolve in
implementation, but, are there no fundamental errors?
>
> Unfortunately your proposal is really fundamentally broken, on a few
levels. I think you might need to do a bit more research into how bitcoin
works before coming up with such improvements =)
>
> But just some quick notes:
>
> * Every node has a (potentially) different mempool, you can't use it to
decide consensus values like the max block size.
>
> * Increasing the entropy in a block to make it more unpredictable doesn't
really make sense.
>
> * Bitcoin should be roughly incentive compatible. Your proposal explicits
asks miners to ignore their best interests, and confirm transactions by
"priority".  What are you going to do if a "malicious" miner decides to go
after their profits and order by what makes them the most money. Add
"ordered by priority" as a consensus requirement? And even if you miners
can still sort their mempool by fee, and then order the top 1MB by priority.
>
> If you could find a good solution that would allow you to know if miners
were following your rule or not (and thus ignore it if it doesn't) then you
wouldn't even need bitcoin in the first place.
>
>
>
>
> -Ryan
>
>
> -------- Original Message --------
> Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction
Priority For Ordering Transactions In Blocks
> Local Time: December 15, 2017 3:42 AM
> UTC Time: December 15, 2017 9:42 AM
> From: bitcoin-dev at lists.linuxfoundation.org
> To: Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>
>
>
>
> I should not take it that the lack of critical feedback to this revised
proposal is a glowing endorsement. I understand that there would be
technical issues to resolve in implementation, but, are there no
fundamental errors?
>
> I suppose that it if is difficult to determine how long a transaction has
been waiting in the pool then, each node could simply keep track of when a
transaction was first seen. This may have implications for a verify
routine, however, for example, if a node was offline, how should it
differentiate how long each transaction was waiting in that case? If a node
was restarted daily would it always think that all transactions had been
waiting in the pool less than one day If each node keeps the current
transaction pool in a file and updates it, as transactions are included in
blocks and, as new transactions appear in the pool, then that would go some
way to alleviate the issue, apart from entirely new nodes. There should be
no reason the contents of a transaction pool files cannot be shared without
agreement as to the transaction pool between nodes, just as nodes transmit
new transactions freely.
>
> It has been questioned why miners could not cheat. For the question of
how many transactions to include in a block, I say it is a standoff and
miners will conform to the proposal, not wanting to leave transactions with
valid fees standing, and, not wanting to shrink the transaction pool. In
any case, if miners shrink the transaction pool then I am not immediately
concerned since it provides a more efficient service. For the question of
including transactions according to the proposal, I say if it is possible
to keep track of how long transactions are waiting in the pool so that they
can be included on a probability curve then it is possible to verify that
blocks conform to the proposal, since the input is a probability, the
output should conform to a probability curve.
>
>
> If someone has the necessary skill, would anyone be willing to develop
the math necessary for the proposal?
>
> Regards,
> Damian Williamson
>
>
> ________________________________
>
> From: bitcoin-dev-bounces at lists.linuxfoundation.org <
bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Damian
Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>
> Sent: Friday, 8 December 2017 8:01 AM
> To: bitcoin-dev at lists.linuxfoundation.org
> Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction
Priority For Ordering Transactions In Blocks
>
>
>
> Good afternoon,
>
> The need for this proposal:
>
> We all must learn to admit that transaction bandwidth is still lurking as
a serious issue for the operation, reliability, safety, consumer
acceptance, uptake and, for the value of Bitcoin.
>
> I recently sent a payment which was not urgent so; I chose three-day
target confirmation from the fee recommendation. That transaction has still
not confirmed after now more than six days - even waiting twice as long
seems quite reasonable to me. That transaction is a valid transaction; it
is not rubbish, junk or, spam. Under the current model with transaction
bandwidth limitation, the longer a transaction waits, the less likely it is
ever to confirm due to rising transaction numbers and being pushed back by
transactions with rising fees.
>
> I argue that no transactions are rubbish or junk, only some zero fee
transactions might be spam. Having an ever-increasing number of valid
transactions that do not confirm as more new transactions with higher fees
are created is the opposite of operating a robust, reliable transaction
system.
>
> Business cannot operate with a model where transactions may or may not
confirm. Even a business choosing a modest fee has no guarantee that their
valid transaction will not be shuffled down by new transactions to the
realm of never confirming after it is created. Consumers also will not
accept this model as Bitcoin expands. If Bitcoin cannot be a reliable
payment system for confirmed transactions then consumers, by and large,
will simply not accept the model once they understand. Bitcoin will be a
dirty payment system, and this will kill the value of Bitcoin.
>
> Under the current system, a minority of transactions will eventually be
the lucky few who have fees high enough to escape being pushed down the
list.
>
> Once there are more than x transactions (transaction bandwidth limit)
every ten minutes, only those choosing twenty-minute confirmation (2
blocks) will have initially at most a fifty percent chance of ever having
their payment confirm. Presently, not even using fee recommendations can
ensure a sufficiently high fee is paid to ensure transaction confirmation.
>
> I also argue that the current auction model for limited transaction
bandwidth is wrong, is not suitable for a reliable transaction system and,
is wrong for Bitcoin. All transactions must confirm in due time. Currently,
Bitcoin is not a safe way to send payments.
>
> I do not believe that consumers and business are against paying fees,
even high fees. What is required is operational reliability.
>
> This great issue needs to be resolved for the safety and reliability of
Bitcoin. The time to resolve issues in commerce is before they become great
big issues. The time to resolve this issue is now. We must have the
foresight to identify and resolve problems before they trip us over.
Simply doubling block sizes every so often is reactionary and is not a
reliable permanent solution. I have written a BIP proposal for a technical
solution but, need your help to write it up to an acceptable standard to be
a full BIP.
>
> I have formatted the following with markdown which is human readable so,
I hope nobody minds. I have done as much with this proposal as I feel that
I am able so far but continue to take your feedback.
>
> # BIP Proposal: UTPFOTIB - Use Transaction Priority For Ordering
Transactions In Blocks
>
> ## The problem:
> Everybody wants value. Miners want to maximize revenue from fees (and we
presume, to minimize block size). Consumers need transaction reliability
and, (we presume) want low fees.
>
> The current transaction bandwidth limit is a limiting factor for both. As
the operational safety of transactions is limited, so is consumer
confidence as they realize the issue and, accordingly, uptake is limited.
Fees are artificially inflated due to bandwidth limitations while failing
to provide a full confirmation service for all transactions.
>
> Current fee recommendations provide no satisfaction for transaction
reliability and, as Bitcoin scales, this will worsen.
>
> Bitcoin must be a fully scalable and reliable service, providing full
transaction confirmation for every valid transaction.
>
> The possibility to send a transaction with a fee lower than one that is
acceptable to allow eventual transaction confirmation should be removed
from the protocol and also from the user interface.
>
> ## Solution summary:
> Provide each transaction with an individual transaction priority each
time before choosing transactions to include in the current block, the
priority being a function of the fee paid (on a curve), and the time
waiting in the transaction pool (also on a curve) out to n days (n=60 ?).
The transaction priority to serve as the likelihood of a transaction being
included in the current block, and for determining the order in which
transactions are tried to see if they will be included.
>
> Use a target block size. Determine the target block size using; current
transaction pool size x ( 1 / (144 x n days ) ) = number of transactions to
be included in the current block. Broadcast the next target block size with
the current block when it is solved so that nodes know the next target
block size for the block that they are building on.
>
> The curves used for the priority of transactions would have to be
appropriate. Perhaps a mathematician with experience in probability can
develop the right formulae. My thinking is a steep curve. I suppose that
the probability of all transactions should probably account for a
sufficient number of inclusions that the target block size is met although,
it may not always be. As a suggestion, consider including some zero fee
transactions to pad, highest BTC value first?
>
> **Explanation of the operation of priority:**
> > If transaction priority is, for example, a number between one (low) and
one-hundred (high) it can be directly understood as the percentage chance
in one-hundred of a transaction being included in the block. Using
probability or likelihood infers that there is some function of random. If
random (100) < transaction priority then the transaction is included.
>
> >To break it down further, if both the fee on a curve value and the time
waiting on a curve value are each a number between one and one-hundred, a
rudimentary method may be to simply multiply those two numbers, to find the
priority number. For example, a middle fee transaction waiting thirty days
(if n = 60 days) may have a value of five for each part  (yes, just five,
the values are on a curve). When multiplied that will give a priority value
of twenty-five, or,  a twenty-five percent chance at that moment of being
included in the block; it will likely be included in one of the next four
blocks, getting more likely each chance. If it is still not included then
the value of time waiting will be higher, making for more probability. A
very low fee transaction would have a value for the fee of one. It would
not be until near sixty-days that the particular low fee transaction has a
high likelihood of being included in the block.
>
> I am not concerned with low (or high) transaction fees, the primary
reason for addressing the issue is to ensure transactional reliability and
scalability while having each transaction confirm in due time.
>
> ## Pros:
> * Maximizes transaction reliability.
> * Fully scalable.
> * Maximizes possibility for consumer and business uptake.
> * Maximizes total fees paid per block without reducing reliability;
because of reliability, in time confidence and overall uptake are greater;
therefore, more transactions.
> * Market determines fee paid for transaction priority.
> * Fee recommendations work all the way out to 30 days or greater.
> * Provides additional block entropy; greater security since there is less
probability of predicting the next block.
>
> ## Cons:
> * Could initially lower total transaction fees per block.
> * Must be first be programmed.
>
> ## Solution operation:
> This is a simplistic view of the operation. The actual operation will
need to be determined in a spec for the programmer.
>
> 1. Determine the target block size for the current block.
> 2. Assign a transaction priority to each transaction in the pool.
> 3. Select transactions to include in the current block using probability
in transaction priority order until the target block size is met.
> 5. Solve block.
> 6. Broadcast the next target block size with the current block when it is
solved.
> 7. Block is received.
> 8. Block verification process.
> 9. Accept/reject block based on verification result.
> 10. Repeat.
>
> ## Closing comments:
> It may be possible to verify blocks conform to the proposal by showing
that the probability for all transactions included in the block
statistically conforms to a probability distribution curve, *if* the
individual transaction priority can be recreated. I am not that deep into
the mathematics; however, it may also be possible to use a similar method
to do this just based on the fee, that statistically, the blocks conform to
a fee distribution. Any zero fee transactions would have to be ignored.
This solution needs a clever mathematician.
>
> I implore, at the very least, that we use some method that validates full
transaction reliability and enables scalability of block sizes. If not this
proposal, an alternative.
>
> Regards,
> Damian Williamson
>
>
>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171218/50d68c11/attachment-0001.html>

From o at zgur.org  Mon Dec 18 12:11:10 2017
From: o at zgur.org (Ozgur)
Date: Mon, 18 Dec 2017 15:11:10 +0300
Subject: [bitcoin-dev] Why not witnessless nodes?
In-Reply-To: <CAPswA9ycPdTtm9PeD5a2R36cZ46HwnkwJu06FXuoE-F5Dx+eZQ@mail.gmail.com>
References: <CAPswA9ycPdTtm9PeD5a2R36cZ46HwnkwJu06FXuoE-F5Dx+eZQ@mail.gmail.com>
Message-ID: <536491513599070@web22o.yandex.ru>

An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171218/7c075b9b/attachment.html>

From eric at voskuil.org  Mon Dec 18 12:43:58 2017
From: eric at voskuil.org (Eric Voskuil)
Date: Mon, 18 Dec 2017 07:43:58 -0500
Subject: [bitcoin-dev] Why not witnessless nodes?
In-Reply-To: <CAPswA9ycPdTtm9PeD5a2R36cZ46HwnkwJu06FXuoE-F5Dx+eZQ@mail.gmail.com>
References: <CAPswA9ycPdTtm9PeD5a2R36cZ46HwnkwJu06FXuoE-F5Dx+eZQ@mail.gmail.com>
Message-ID: <CD7FBCF6-5386-4E9E-A3B9-D5B3DBAF312C@voskuil.org>


> On Dec 18, 2017, at 03:32, Kalle Rosenbaum via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
> 
> Dear list,
> 
> I find it hard to understand why a full node that does initial block
> download also must download witnesses if they are going to skip verification anyway.

Why run a full node if you are not going to verify the chain?

> If my full node skips signature verification for
> blocks earlier than X, it seems the reasons for downloading the
> witnesses for those blocks are:
> 
> * to be able to send witnesses to other nodes.
> 
> * to verify the witness root hash of the blocks
> 
> I suppose that it's important to verify the witness root hash because
> a bad peer may send me invalid witnesses during initial block
> download, and if I don't verify that the witness root hash actually
> commits to them, I will get banned by peers requesting the blocks from
> me because I send them garbage.
> So both the reasons above (there may be more that I don't know about)
> are actually the same reason: To be able to send witnesses to others
> without getting banned.
> 
> What if a node could chose not to download witnesses and thus chose to
> send only witnessless blocks to peers. Let's call these nodes
> witnessless nodes. Note that witnessless nodes are only witnessless
> for blocks up to X. Everything after X is fully verified.
> 
> Witnessless nodes would be able to sync faster because it needs to
> download less data to calculate their UTXO set. They would therefore
> more quickly be able to provide full service to SPV wallets and its
> local wallets as well as serving blocks to other witnessless nodes
> with same or higher assumevalid block. For witnessless nodes with
> lower assumevalid they can serve at least some blocks. It could also
> serve blocks to non-segwit nodes.
> 
> Do witnessless nodes risk dividing the network in two parts, one
> witnessless and one with full nodes, with few connections between the
> parts?
> 
> So basically, what are the reasons not to implement witnessless
> nodes?
> 
> Thank you,
> /Kalle
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

From kalle at rosenbaum.se  Mon Dec 18 13:35:44 2017
From: kalle at rosenbaum.se (Kalle Rosenbaum)
Date: Mon, 18 Dec 2017 14:35:44 +0100
Subject: [bitcoin-dev] Why not witnessless nodes?
In-Reply-To: <CD7FBCF6-5386-4E9E-A3B9-D5B3DBAF312C@voskuil.org>
References: <CAPswA9ycPdTtm9PeD5a2R36cZ46HwnkwJu06FXuoE-F5Dx+eZQ@mail.gmail.com>
	<CD7FBCF6-5386-4E9E-A3B9-D5B3DBAF312C@voskuil.org>
Message-ID: <CAPswA9zo1dLYHP9A+xrYLsrFO5GVYFqVLQC-A9uHQSCie7xeYg@mail.gmail.com>

2017-12-18 13:43 GMT+01:00 Eric Voskuil <eric at voskuil.org>:

>
> > On Dec 18, 2017, at 03:32, Kalle Rosenbaum via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
> >
> > Dear list,
> >
> > I find it hard to understand why a full node that does initial block
> > download also must download witnesses if they are going to skip
> verification anyway.
>
> Why run a full node if you are not going to verify the chain?
>

I meant to say "I find it hard to understand why a full node that does
initial block
download also must download witnesses when it is going to skip verification
of the witnesses anyway."

I'm referring to the "assumevalid" feature of Bitcoin Core that skips
signature verification up to block X. Or have I misunderstood assumevalid?

/Kalle


>
> > If my full node skips signature verification for
> > blocks earlier than X, it seems the reasons for downloading the
> > witnesses for those blocks are:
> >
> > * to be able to send witnesses to other nodes.
> >
> > * to verify the witness root hash of the blocks
> >
> > I suppose that it's important to verify the witness root hash because
> > a bad peer may send me invalid witnesses during initial block
> > download, and if I don't verify that the witness root hash actually
> > commits to them, I will get banned by peers requesting the blocks from
> > me because I send them garbage.
> > So both the reasons above (there may be more that I don't know about)
> > are actually the same reason: To be able to send witnesses to others
> > without getting banned.
> >
> > What if a node could chose not to download witnesses and thus chose to
> > send only witnessless blocks to peers. Let's call these nodes
> > witnessless nodes. Note that witnessless nodes are only witnessless
> > for blocks up to X. Everything after X is fully verified.
> >
> > Witnessless nodes would be able to sync faster because it needs to
> > download less data to calculate their UTXO set. They would therefore
> > more quickly be able to provide full service to SPV wallets and its
> > local wallets as well as serving blocks to other witnessless nodes
> > with same or higher assumevalid block. For witnessless nodes with
> > lower assumevalid they can serve at least some blocks. It could also
> > serve blocks to non-segwit nodes.
> >
> > Do witnessless nodes risk dividing the network in two parts, one
> > witnessless and one with full nodes, with few connections between the
> > parts?
> >
> > So basically, what are the reasons not to implement witnessless
> > nodes?
> >
> > Thank you,
> > /Kalle
> > _______________________________________________
> > bitcoin-dev mailing list
> > bitcoin-dev at lists.linuxfoundation.org
> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171218/f5dc0e16/attachment.html>

From eric at voskuil.org  Mon Dec 18 16:19:34 2017
From: eric at voskuil.org (Eric Voskuil)
Date: Mon, 18 Dec 2017 11:19:34 -0500
Subject: [bitcoin-dev] Why not witnessless nodes?
In-Reply-To: <CAPswA9zo1dLYHP9A+xrYLsrFO5GVYFqVLQC-A9uHQSCie7xeYg@mail.gmail.com>
References: <CAPswA9ycPdTtm9PeD5a2R36cZ46HwnkwJu06FXuoE-F5Dx+eZQ@mail.gmail.com>
	<CD7FBCF6-5386-4E9E-A3B9-D5B3DBAF312C@voskuil.org>
	<CAPswA9zo1dLYHP9A+xrYLsrFO5GVYFqVLQC-A9uHQSCie7xeYg@mail.gmail.com>
Message-ID: <A2B6418E-069F-476A-86EE-638C6D9E826A@voskuil.org>

You can't know (assume) a block is valid unless you have previously validated the block yourself. But in the case where you have, and then intend to rely on it in a future sync, there is no need for witness data for blocks you are not going to validate. So you can just not request it. 

However you will not be able to provide those blocks to nodes that *are* validating; the client is pruned and therefore not a peer (cannot reciprocate). (An SPV client is similarly not a peer; it is a more deeply pruned client than the witnessless client.)

There is no other reason that a node requires witness data. SPV clients don't need it as it is neither require it to verify header commitment to transactions nor to extract payment addresses from them.

The harm to the network by pruning is that eventually it can become harder and even impossible for anyone to validate the chain. But because you are fully validating you individually remain secure, so there is no individual incentive working against this system harm.

e

> On Dec 18, 2017, at 08:35, Kalle Rosenbaum <kalle at rosenbaum.se> wrote:
> 
> 2017-12-18 13:43 GMT+01:00 Eric Voskuil <eric at voskuil.org>:
>> 
>> > On Dec 18, 2017, at 03:32, Kalle Rosenbaum via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
>> >
>> > Dear list,
>> >
>> > I find it hard to understand why a full node that does initial block
>> > download also must download witnesses if they are going to skip verification anyway.
>> 
>> Why run a full node if you are not going to verify the chain?
> 
> I meant to say "I find it hard to understand why a full node that does initial block
> download also must download witnesses when it is going to skip verification of the witnesses anyway."
> 
> I'm referring to the "assumevalid" feature of Bitcoin Core that skips signature verification up to block X. Or have I misunderstood assumevalid?
> 
> /Kalle
>  
>> 
>> > If my full node skips signature verification for
>> > blocks earlier than X, it seems the reasons for downloading the
>> > witnesses for those blocks are:
>> >
>> > * to be able to send witnesses to other nodes.
>> >
>> > * to verify the witness root hash of the blocks
>> >
>> > I suppose that it's important to verify the witness root hash because
>> > a bad peer may send me invalid witnesses during initial block
>> > download, and if I don't verify that the witness root hash actually
>> > commits to them, I will get banned by peers requesting the blocks from
>> > me because I send them garbage.
>> > So both the reasons above (there may be more that I don't know about)
>> > are actually the same reason: To be able to send witnesses to others
>> > without getting banned.
>> >
>> > What if a node could chose not to download witnesses and thus chose to
>> > send only witnessless blocks to peers. Let's call these nodes
>> > witnessless nodes. Note that witnessless nodes are only witnessless
>> > for blocks up to X. Everything after X is fully verified.
>> >
>> > Witnessless nodes would be able to sync faster because it needs to
>> > download less data to calculate their UTXO set. They would therefore
>> > more quickly be able to provide full service to SPV wallets and its
>> > local wallets as well as serving blocks to other witnessless nodes
>> > with same or higher assumevalid block. For witnessless nodes with
>> > lower assumevalid they can serve at least some blocks. It could also
>> > serve blocks to non-segwit nodes.
>> >
>> > Do witnessless nodes risk dividing the network in two parts, one
>> > witnessless and one with full nodes, with few connections between the
>> > parts?
>> >
>> > So basically, what are the reasons not to implement witnessless
>> > nodes?
>> >
>> > Thank you,
>> > /Kalle
>> > _______________________________________________
>> > bitcoin-dev mailing list
>> > bitcoin-dev at lists.linuxfoundation.org
>> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171218/9a59ee24/attachment-0001.html>

From mail at albertodeluigi.com  Mon Dec 18 16:40:08 2017
From: mail at albertodeluigi.com (Alberto De Luigi)
Date: Mon, 18 Dec 2017 17:40:08 +0100
Subject: [bitcoin-dev] Clarification about SegWit transaction size and bech32
Message-ID: <003c01d3781e$dda115f0$98e341d0$@albertodeluigi.com>

Hello guys,

I have a few questions about the SegWit tx size, I'd like to have
confirmation about the following statements. Can you correct mistakes or
inaccuracies? Thank you in advance.

 

In general, SegWit tx costs more than legacy tx (source
https://bitcoincore.org/en/2016/10/28/segwit-costs/):

 

*	Compared to P2PKH, P2WPKH uses 3 fewer bytes (-1%) in the
scriptPubKey, and the same number of witness bytes as P2PKH scriptSig.
*	Compared to P2SH, P2WSH uses 11 additional bytes (6%) in the
scriptPubKey, and the same number of witness bytes as P2SH scriptSig.
*	Compared to P2PKH, P2WPKH/P2SH uses 21 additional bytes (11%), due
to using 24 bytes in scriptPubKey, 3 fewer bytes in scriptSig than in P2PKH
scriptPubKey, and the same number of witness bytes as P2PKH scriptSig.
*	Compared to P2SH, P2WSH/P2SH uses 35 additional bytes (19%), due to
using 24 bytes in scriptPubKey, 11 additional bytes in scriptSig compared to
P2SH scriptPubKey, and the same number of witness bytes as P2SH scriptSig.

 

But still it is convenient to adopt segwit because you move the bytes to the
blockweight part, paying smaller fee. In general, a tx with 1 input and 1
output is about 190kb. If it's a Segwit tx, 82kb in the non-witness part
(blocksize), 108 in the witness part (blockweight).

See source:

4 bytes version

1 byte input count

Input

36 bytes outpoint

1 byte scriptSigLen (0x00)

0 bytes scriptSig

4 bytes sequence

1 byte output count

8 bytes value

1 byte scriptPubKeyLen

22 bytes scriptPubKey (0x0014{20-byte keyhash})

4 bytes locktime

https://bitcoin.stackexchange.com/questions/59408/with-100-segwit-transactio
ns-what-would-be-the-max-number-of-transaction-confi

 

Which means, if you fill a block entirely with this kind of tx, you can
approximately double the capacity of the blockchain (blocksize capped to
1mb, blockweight a little bit more than 2mb)

 

My concern is about segwit adoption by the exchanges. 

SegWit transactions cost 10bytes more than legacy transactions for each
output (vout is 256 bits instead of 160). Exchanges aggregate tx adding many
outputs, which is of course something good for bitcoin scalability, since
this way we save space and pay less fees.

But when a tx has at least 10 outputs, using segwit you don't save space,
instead:

- the total blockweight is at least 100bytes higher (10bytes x 10 outputs),
so the blockchain is heavier 

- you don't save space inside the blocksize, so you cannot validate more
transactions of this kind (with many outputs), nor get cheaper fee

- without cheaper fees exchanges have no incentives for segwit adoption
before they decide to adopt LN

 

In general we can say that using SegWit:

- you decrease the fee only for some specific kind of transactions, and just
because you move some bytes to the blockweight

- you don't save space in the blockchain, on the contrary the total weight
of the blockchain increases (so it's clear to me why some time ago Luke
tweeted to not use SegWit unless really necessary... but then it's not clear
why so much haste in promoting BIP148 the 1st august risking a split)

 

If it's all correct, does something change with bech32? I'm reading bech32
allows to save about 22% of the space. Is this true for whatever kind of tx?
Immediate benefits of segwit for scalability are only with bech32?

 

Bech32 is non-compatible with the entire ecosystem (you cannot receive coins
from the quasi-totality of wallets in circulation), I would say it is a hard
fork. But the bare segwit is really so different? the soft fork is "soft"
for the reference client Bitcoin Core, but outside you cannot know what
happens, there are plenty of implementations (especially frontend
customization) which don't work with segwit and need to upgrade. To upgrade
takes a lot of time, especially when services are so crowded and so many new
people want to step in. At this point, if bech32 brings only efficiency (but
correct me if it's not so) and it is well planned, it could be a consensual
upgrade, maybe together with a 2x blocksize? Is there a specific plan for
some upgrade in 2018? I personally think it is far easier to reach consensus
on a blocksize increase una tantum rather than a dynamic increase. You
cannot predict the technology growth: will it be linear, exponential, or
suddenly stop for a while, maybe right before a huge innovation? I think a
hard fork bech32 upgrade + 2x could help a lot in scalability while we test
LN, and it might be the only way to effectively promote (or should I say
enforce?) SegWit adoption.

 

thank you,

Alberto De Luigi

(.com)

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171218/c095de60/attachment.html>

From mark at friedenbach.org  Mon Dec 18 17:30:17 2017
From: mark at friedenbach.org (Mark Friedenbach)
Date: Mon, 18 Dec 2017 09:30:17 -0800
Subject: [bitcoin-dev] Why not witnessless nodes?
In-Reply-To: <A2B6418E-069F-476A-86EE-638C6D9E826A@voskuil.org>
References: <CAPswA9ycPdTtm9PeD5a2R36cZ46HwnkwJu06FXuoE-F5Dx+eZQ@mail.gmail.com>
	<CD7FBCF6-5386-4E9E-A3B9-D5B3DBAF312C@voskuil.org>
	<CAPswA9zo1dLYHP9A+xrYLsrFO5GVYFqVLQC-A9uHQSCie7xeYg@mail.gmail.com>
	<A2B6418E-069F-476A-86EE-638C6D9E826A@voskuil.org>
Message-ID: <61B0AEC9-3B1D-416F-8883-A030E5109538@friedenbach.org>

Sign-to-contract enables some interesting protocols, none of which are in wide use as far as I?m aware. But if they were (and arguably this is an area that should be more developed), then SPV nodes validating these protocols will need access to witness data. If a node is performing IBD with assumevalid set to true, and is also intending to prune history, then there?s no reason to fetch those witnesses as far as I?m aware. But it would be a great disservice to the network for nodes intending to serve SPV clients to prune this portion of the block history. 

> On Dec 18, 2017, at 8:19 AM, Eric Voskuil via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
> 
> You can't know (assume) a block is valid unless you have previously validated the block yourself. But in the case where you have, and then intend to rely on it in a future sync, there is no need for witness data for blocks you are not going to validate. So you can just not request it. 
> 
> However you will not be able to provide those blocks to nodes that *are* validating; the client is pruned and therefore not a peer (cannot reciprocate). (An SPV client is similarly not a peer; it is a more deeply pruned client than the witnessless client.)
> 
> There is no other reason that a node requires witness data. SPV clients don't need it as it is neither require it to verify header commitment to transactions nor to extract payment addresses from them.
> 
> The harm to the network by pruning is that eventually it can become harder and even impossible for anyone to validate the chain. But because you are fully validating you individually remain secure, so there is no individual incentive working against this system harm.
> 
> e
> 
> On Dec 18, 2017, at 08:35, Kalle Rosenbaum <kalle at rosenbaum.se <mailto:kalle at rosenbaum.se>> wrote:
> 
>> 2017-12-18 13:43 GMT+01:00 Eric Voskuil <eric at voskuil.org <mailto:eric at voskuil.org>>:
>> 
>> > On Dec 18, 2017, at 03:32, Kalle Rosenbaum via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:
>> >
>> > Dear list,
>> >
>> > I find it hard to understand why a full node that does initial block
>> > download also must download witnesses if they are going to skip verification anyway.
>> 
>> Why run a full node if you are not going to verify the chain?
>> 
>> I meant to say "I find it hard to understand why a full node that does initial block
>> download also must download witnesses when it is going to skip verification of the witnesses anyway."
>> 
>> I'm referring to the "assumevalid" feature of Bitcoin Core that skips signature verification up to block X. Or have I misunderstood assumevalid?
>> 
>> /Kalle
>>  
>> 
>> > If my full node skips signature verification for
>> > blocks earlier than X, it seems the reasons for downloading the
>> > witnesses for those blocks are:
>> >
>> > * to be able to send witnesses to other nodes.
>> >
>> > * to verify the witness root hash of the blocks
>> >
>> > I suppose that it's important to verify the witness root hash because
>> > a bad peer may send me invalid witnesses during initial block
>> > download, and if I don't verify that the witness root hash actually
>> > commits to them, I will get banned by peers requesting the blocks from
>> > me because I send them garbage.
>> > So both the reasons above (there may be more that I don't know about)
>> > are actually the same reason: To be able to send witnesses to others
>> > without getting banned.
>> >
>> > What if a node could chose not to download witnesses and thus chose to
>> > send only witnessless blocks to peers. Let's call these nodes
>> > witnessless nodes. Note that witnessless nodes are only witnessless
>> > for blocks up to X. Everything after X is fully verified.
>> >
>> > Witnessless nodes would be able to sync faster because it needs to
>> > download less data to calculate their UTXO set. They would therefore
>> > more quickly be able to provide full service to SPV wallets and its
>> > local wallets as well as serving blocks to other witnessless nodes
>> > with same or higher assumevalid block. For witnessless nodes with
>> > lower assumevalid they can serve at least some blocks. It could also
>> > serve blocks to non-segwit nodes.
>> >
>> > Do witnessless nodes risk dividing the network in two parts, one
>> > witnessless and one with full nodes, with few connections between the
>> > parts?
>> >
>> > So basically, what are the reasons not to implement witnessless
>> > nodes?
>> >
>> > Thank you,
>> > /Kalle
>> > _______________________________________________
>> > bitcoin-dev mailing list
>> > bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>
>> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>
>> 
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171218/635995bc/attachment-0001.html>

From mark at friedenbach.org  Mon Dec 18 17:38:01 2017
From: mark at friedenbach.org (Mark Friedenbach)
Date: Mon, 18 Dec 2017 09:38:01 -0800
Subject: [bitcoin-dev] Clarification about SegWit transaction size and
 bech32
In-Reply-To: <003c01d3781e$dda115f0$98e341d0$@albertodeluigi.com>
References: <003c01d3781e$dda115f0$98e341d0$@albertodeluigi.com>
Message-ID: <B0012211-15E8-45F8-881C-D4C120288CA4@friedenbach.org>

Addresses are entirely a user-interface issue. They don?t factor into the bitcoin protocol at all.

The bitcoin protocol doesn?t have addresses. It has a generic programmable signature framework called script. Addresses are merely a UI convention for representing common script templates. 1.. addresses and 3? addresses have script templates that are not as optimal as could be constructed with post-segwit assumptions. The newer bech32 address just uses a different underlying template that achieves better security guarantees (for pay-to-script) or lower fees (for pay-to-pubkey-hash). But this is really a UI/UX issue.

A ?fork? in bitcoin-like consensus systems has a very specific meaning. Changing address formats is not a fork, soft or hard.

There are many benefits to segregated witness. You may find this page helpful:

https://bitcoincore.org/en/2016/01/26/segwit-benefits/ <https://bitcoincore.org/en/2016/01/26/segwit-benefits/>

> On Dec 18, 2017, at 8:40 AM, Alberto De Luigi via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
> 
> Hello guys,
> I have a few questions about the SegWit tx size, I'd like to have confirmation about the following statements. Can you correct mistakes or inaccuracies? Thank you in advance.
>  
> In general, SegWit tx costs more than legacy tx (source https://bitcoincore.org/en/2016/10/28/segwit-costs/ <https://bitcoincore.org/en/2016/10/28/segwit-costs/>):
>  
> Compared to P2PKH, P2WPKH uses 3 fewer bytes (-1%) in the scriptPubKey, and the same number of witness bytes as P2PKH scriptSig.
> Compared to P2SH, P2WSH uses 11 additional bytes (6%) in the scriptPubKey, and the same number of witness bytes as P2SH scriptSig.
> Compared to P2PKH, P2WPKH/P2SH uses 21 additional bytes (11%), due to using 24 bytes in scriptPubKey, 3 fewer bytes in scriptSig than in P2PKH scriptPubKey, and the same number of witness bytes as P2PKH scriptSig.
> Compared to P2SH, P2WSH/P2SH uses 35 additional bytes (19%), due to using 24 bytes in scriptPubKey, 11 additional bytes in scriptSig compared to P2SH scriptPubKey, and the same number of witness bytes as P2SH scriptSig.
>  
> But still it is convenient to adopt segwit because you move the bytes to the blockweight part, paying smaller fee. In general, a tx with 1 input and 1 output is about 190kb. If it's a Segwit tx, 82kb in the non-witness part (blocksize), 108 in the witness part (blockweight).
> See source:
> 4 bytes version
> 1 byte input count
> Input
> 36 bytes outpoint
> 1 byte scriptSigLen (0x00)
> 0 bytes scriptSig
> 4 bytes sequence
> 1 byte output count
> 8 bytes value
> 1 byte scriptPubKeyLen
> 22 bytes scriptPubKey (0x0014{20-byte keyhash})
> 4 bytes locktime
> https://bitcoin.stackexchange.com/questions/59408/with-100-segwit-transactions-what-would-be-the-max-number-of-transaction-confi <https://bitcoin.stackexchange.com/questions/59408/with-100-segwit-transactions-what-would-be-the-max-number-of-transaction-confi>
>  
> Which means, if you fill a block entirely with this kind of tx, you can approximately double the capacity of the blockchain (blocksize capped to 1mb, blockweight a little bit more than 2mb)
>  
> My concern is about segwit adoption by the exchanges. 
> SegWit transactions cost 10bytes more than legacy transactions for each output (vout is 256 bits instead of 160). Exchanges aggregate tx adding many outputs, which is of course something good for bitcoin scalability, since this way we save space and pay less fees.
> But when a tx has at least 10 outputs, using segwit you don't save space, instead:
> - the total blockweight is at least 100bytes higher (10bytes x 10 outputs), so the blockchain is heavier 
> - you don't save space inside the blocksize, so you cannot validate more transactions of this kind (with many outputs), nor get cheaper fee
> - without cheaper fees exchanges have no incentives for segwit adoption before they decide to adopt LN
>  
> In general we can say that using SegWit:
> - you decrease the fee only for some specific kind of transactions, and just because you move some bytes to the blockweight
> - you don?t save space in the blockchain, on the contrary the total weight of the blockchain increases (so it's clear to me why some time ago Luke tweeted to not use SegWit unless really necessary... but then it's not clear why so much haste in promoting BIP148 the 1st august risking a split)
>  
> If it's all correct, does something change with bech32? I'm reading bech32 allows to save about 22% of the space. Is this true for whatever kind of tx? Immediate benefits of segwit for scalability are only with bech32?
>  
> Bech32 is non-compatible with the entire ecosystem (you cannot receive coins from the quasi-totality of wallets in circulation), I would say it is a hard fork. But the bare segwit is really so different? the soft fork is "soft" for the reference client Bitcoin Core, but outside you cannot know what happens, there are plenty of implementations (especially frontend customization) which don?t work with segwit and need to upgrade. To upgrade takes a lot of time, especially when services are so crowded and so many new people want to step in. At this point, if bech32 brings only efficiency (but correct me if it?s not so) and it is well planned, it could be a consensual upgrade, maybe together with a 2x blocksize? Is there a specific plan for some upgrade in 2018? I personally think it is far easier to reach consensus on a blocksize increase una tantum rather than a dynamic increase. You cannot predict the technology growth: will it be linear, exponential, or suddenly stop for a while, maybe right before a huge innovation? I think a hard fork bech32 upgrade + 2x could help a lot in scalability while we test LN, and it might be the only way to effectively promote (or should I say enforce?) SegWit adoption.
>  
> thank you,
> Alberto De Luigi
> (.com)
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171218/d9694d67/attachment.html>

From danrobinson010 at gmail.com  Mon Dec 18 20:32:17 2017
From: danrobinson010 at gmail.com (Daniel Robinson)
Date: Mon, 18 Dec 2017 20:32:17 +0000
Subject: [bitcoin-dev] Ivy: a higher-level language targeting Bitcoin Script
Message-ID: <CAD438HvzYAMVTU8A0OiNnj2nvYgMApdS8NNfzE86Ae_OsTfuaA@mail.gmail.com>

Today, we?re releasing Ivy, a prototype higher-level language and
development environment for creating custom Bitcoin Script programs. You
can see the full announcement here
<https://blog.chain.com/ivy-for-bitcoin-a-smart-contract-language-that-compiles-to-bitcoin-script-bec06377141a>,
or check out the docs <https://docs.ivy-lang.org/bitcoin/> and source code
<https://github.com/ivy-lang/ivy-bitcoin>.

Ivy is a simple smart contract language that can compile to Bitcoin Script.
It aims to improve on the useability of Bitcoin Script by adding
affordances like named variables and clauses, static (and domain-specific)
types, and familiar syntax for function calls.

To try out Ivy, you can use the Ivy Playground for Bitcoin
<https://ivy-lang.org/bitcoin/>, which allows you to create and test
simulated contracts in a sandboxed environment.

This is prototype software intended for educational and research purposes
only. Please don't try to use Ivy to control real or testnet Bitcoins.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171218/88572040/attachment-0001.html>

From kalle at rosenbaum.se  Mon Dec 18 20:34:30 2017
From: kalle at rosenbaum.se (Kalle Rosenbaum)
Date: Mon, 18 Dec 2017 21:34:30 +0100
Subject: [bitcoin-dev] Why not witnessless nodes?
In-Reply-To: <A2B6418E-069F-476A-86EE-638C6D9E826A@voskuil.org>
References: <CAPswA9ycPdTtm9PeD5a2R36cZ46HwnkwJu06FXuoE-F5Dx+eZQ@mail.gmail.com>
	<CD7FBCF6-5386-4E9E-A3B9-D5B3DBAF312C@voskuil.org>
	<CAPswA9zo1dLYHP9A+xrYLsrFO5GVYFqVLQC-A9uHQSCie7xeYg@mail.gmail.com>
	<A2B6418E-069F-476A-86EE-638C6D9E826A@voskuil.org>
Message-ID: <CAPswA9z2+kf7LrCQpsPftPC7SdcUT0fi6GqeyxMtwxAop00xFA@mail.gmail.com>

Thanks Eric.

It would be a pity if early witnesses got lost due to nodes abandoning them
by running witnessless. But as long as there's at least one accessible
source for them left we're OKish. Let's hope we don't get to that point in
the near future. As long as Bitcoin Core doesn't implement witnessless
mode, there's little risk.

What do people here think about the benefits and risks with running
witnessless?

/Kalle

Sent from my Sinclair ZX81

Den 18 dec. 2017 17:19 skrev "Eric Voskuil" <eric at voskuil.org>:

> You can't know (assume) a block is valid unless you have previously
> validated the block yourself. But in the case where you have, and then
> intend to rely on it in a future sync, there is no need for witness data
> for blocks you are not going to validate. So you can just not request it.
>
> However you will not be able to provide those blocks to nodes that *are*
> validating; the client is pruned and therefore not a peer (cannot
> reciprocate). (An SPV client is similarly not a peer; it is a more deeply
> pruned client than the witnessless client.)
>
> There is no other reason that a node requires witness data. SPV clients
> don't need it as it is neither require it to verify header commitment to
> transactions nor to extract payment addresses from them.
>
> The harm to the network by pruning is that eventually it can become harder
> and even impossible for anyone to validate the chain. But because you are
> fully validating you individually remain secure, so there is no individual
> incentive working against this system harm.
>
> e
>
> On Dec 18, 2017, at 08:35, Kalle Rosenbaum <kalle at rosenbaum.se> wrote:
>
> 2017-12-18 13:43 GMT+01:00 Eric Voskuil <eric at voskuil.org>:
>
>>
>> > On Dec 18, 2017, at 03:32, Kalle Rosenbaum via bitcoin-dev <
>> bitcoin-dev at lists.linuxfoundation.org> wrote:
>> >
>> > Dear list,
>> >
>> > I find it hard to understand why a full node that does initial block
>> > download also must download witnesses if they are going to skip
>> verification anyway.
>>
>> Why run a full node if you are not going to verify the chain?
>>
>
> I meant to say "I find it hard to understand why a full node that does
> initial block
> download also must download witnesses when it is going to skip
> verification of the witnesses anyway."
>
> I'm referring to the "assumevalid" feature of Bitcoin Core that skips
> signature verification up to block X. Or have I misunderstood assumevalid?
>
> /Kalle
>
>
>>
>> > If my full node skips signature verification for
>> > blocks earlier than X, it seems the reasons for downloading the
>> > witnesses for those blocks are:
>> >
>> > * to be able to send witnesses to other nodes.
>> >
>> > * to verify the witness root hash of the blocks
>> >
>> > I suppose that it's important to verify the witness root hash because
>> > a bad peer may send me invalid witnesses during initial block
>> > download, and if I don't verify that the witness root hash actually
>> > commits to them, I will get banned by peers requesting the blocks from
>> > me because I send them garbage.
>> > So both the reasons above (there may be more that I don't know about)
>> > are actually the same reason: To be able to send witnesses to others
>> > without getting banned.
>> >
>> > What if a node could chose not to download witnesses and thus chose to
>> > send only witnessless blocks to peers. Let's call these nodes
>> > witnessless nodes. Note that witnessless nodes are only witnessless
>> > for blocks up to X. Everything after X is fully verified.
>> >
>> > Witnessless nodes would be able to sync faster because it needs to
>> > download less data to calculate their UTXO set. They would therefore
>> > more quickly be able to provide full service to SPV wallets and its
>> > local wallets as well as serving blocks to other witnessless nodes
>> > with same or higher assumevalid block. For witnessless nodes with
>> > lower assumevalid they can serve at least some blocks. It could also
>> > serve blocks to non-segwit nodes.
>> >
>> > Do witnessless nodes risk dividing the network in two parts, one
>> > witnessless and one with full nodes, with few connections between the
>> > parts?
>> >
>> > So basically, what are the reasons not to implement witnessless
>> > nodes?
>> >
>> > Thank you,
>> > /Kalle
>> > _______________________________________________
>> > bitcoin-dev mailing list
>> > bitcoin-dev at lists.linuxfoundation.org
>> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171218/23ed9807/attachment.html>

From greg at xiph.org  Mon Dec 18 20:42:34 2017
From: greg at xiph.org (Gregory Maxwell)
Date: Mon, 18 Dec 2017 20:42:34 +0000
Subject: [bitcoin-dev] Why not witnessless nodes?
In-Reply-To: <CAPswA9ycPdTtm9PeD5a2R36cZ46HwnkwJu06FXuoE-F5Dx+eZQ@mail.gmail.com>
References: <CAPswA9ycPdTtm9PeD5a2R36cZ46HwnkwJu06FXuoE-F5Dx+eZQ@mail.gmail.com>
Message-ID: <CAAS2fgRuLWbQLw=2EQEODGHOp0=OrLkGguw=jJSCpQXEC_P+hQ@mail.gmail.com>

Because it would make no meaningful difference now, and if you are not
going to check the history there are much more efficient things to
do-- like not transfer it at all.

On Mon, Dec 18, 2017 at 8:32 AM, Kalle Rosenbaum via bitcoin-dev
<bitcoin-dev at lists.linuxfoundation.org> wrote:
> Dear list,
>
> I find it hard to understand why a full node that does initial block
> download also must download witnesses if they are going to skip
> verification anyway. If my full node skips signature verification for
> blocks earlier than X, it seems the reasons for downloading the
> witnesses for those blocks are:
>
> * to be able to send witnesses to other nodes.
>
> * to verify the witness root hash of the blocks
>
> I suppose that it's important to verify the witness root hash because
> a bad peer may send me invalid witnesses during initial block
> download, and if I don't verify that the witness root hash actually
> commits to them, I will get banned by peers requesting the blocks from
> me because I send them garbage.
>
> So both the reasons above (there may be more that I don't know about)
> are actually the same reason: To be able to send witnesses to others
> without getting banned.
>
> What if a node could chose not to download witnesses and thus chose to
> send only witnessless blocks to peers. Let's call these nodes
> witnessless nodes. Note that witnessless nodes are only witnessless
> for blocks up to X. Everything after X is fully verified.
>
> Witnessless nodes would be able to sync faster because it needs to
> download less data to calculate their UTXO set. They would therefore
> more quickly be able to provide full service to SPV wallets and its
> local wallets as well as serving blocks to other witnessless nodes
> with same or higher assumevalid block. For witnessless nodes with
> lower assumevalid they can serve at least some blocks. It could also
> serve blocks to non-segwit nodes.
>
> Do witnessless nodes risk dividing the network in two parts, one
> witnessless and one with full nodes, with few connections between the
> parts?
>
> So basically, what are the reasons not to implement witnessless
> nodes?
>
> Thank you,
> /Kalle
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>

From kalle at rosenbaum.se  Mon Dec 18 21:27:14 2017
From: kalle at rosenbaum.se (Kalle Rosenbaum)
Date: Mon, 18 Dec 2017 22:27:14 +0100
Subject: [bitcoin-dev] Why not witnessless nodes?
In-Reply-To: <61B0AEC9-3B1D-416F-8883-A030E5109538@friedenbach.org>
References: <CAPswA9ycPdTtm9PeD5a2R36cZ46HwnkwJu06FXuoE-F5Dx+eZQ@mail.gmail.com>
	<CD7FBCF6-5386-4E9E-A3B9-D5B3DBAF312C@voskuil.org>
	<CAPswA9zo1dLYHP9A+xrYLsrFO5GVYFqVLQC-A9uHQSCie7xeYg@mail.gmail.com>
	<A2B6418E-069F-476A-86EE-638C6D9E826A@voskuil.org>
	<61B0AEC9-3B1D-416F-8883-A030E5109538@friedenbach.org>
Message-ID: <CAPswA9xEf9+vtW5LwdzJ5BofN4zJLoiPUy9i=mH=UQrcyUifLw@mail.gmail.com>

Hi Mark

Yes, it seems like sign-to-contract protocols, which I just now briefly
read about [1][2], may need to use historic witnesses. That raises the
question, what are Bitcoin witnesses for?

To me it seems witnesses should be regarded as temporary. But it seems both
respondents to this thread, Eric and Mark, mean that witnesses are forever.
I regard witnesses as a way to authenticate updates to the UTXO set, and
once buried deep enough in the blockchain, the witness is no longer needed,
because consensus has formed around the UTXO set update.

Suppose a transaction with an invalid witness happens to enter the
blockchain and gets buried 100000 blocks down with the witness still
available. Is the blockchain above it valid? I'd say the blockchain is
valid and that it was a bug that the transaction made it into the
blockchain. We will have to live with such bugs.

Another way to put it: Suppose that all witnesses from 2017 dissappears
from all nodes in 2020. Is the blockchain still valid? I think so. I would
continue using it without looking back.

With that approach, I think sign-to-contract protocols has to find ways to
work in a witnessless environment. For example, users of such protocols can
setup their own archival nodes.

I'd love to hear alternative views on this.

Thanks,
/Kalle

[1]
https://download.wpsoftware.net/bitcoin/wizardry/mw-slides/2017-03-mit-bitcoin-expo/slides.pdf
[2] https://bitcointalk.org/index.php?topic=893898.msg9861102#msg9861102

2017-12-18 18:30 GMT+01:00 Mark Friedenbach via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org>:

> Sign-to-contract enables some interesting protocols, none of which are in
> wide use as far as I?m aware. But if they were (and arguably this is an
> area that should be more developed), then SPV nodes validating these
> protocols will need access to witness data. If a node is performing IBD
> with assumevalid set to true, and is also intending to prune history, then
> there?s no reason to fetch those witnesses as far as I?m aware. But it
> would be a great disservice to the network for nodes intending to serve SPV
> clients to prune this portion of the block history.
>
>
> On Dec 18, 2017, at 8:19 AM, Eric Voskuil via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
> You can't know (assume) a block is valid unless you have previously
> validated the block yourself. But in the case where you have, and then
> intend to rely on it in a future sync, there is no need for witness data
> for blocks you are not going to validate. So you can just not request it.
>
> However you will not be able to provide those blocks to nodes that *are*
> validating; the client is pruned and therefore not a peer (cannot
> reciprocate). (An SPV client is similarly not a peer; it is a more deeply
> pruned client than the witnessless client.)
>
> There is no other reason that a node requires witness data. SPV clients
> don't need it as it is neither require it to verify header commitment to
> transactions nor to extract payment addresses from them.
>
> The harm to the network by pruning is that eventually it can become harder
> and even impossible for anyone to validate the chain. But because you are
> fully validating you individually remain secure, so there is no individual
> incentive working against this system harm.
>
> e
>
> On Dec 18, 2017, at 08:35, Kalle Rosenbaum <kalle at rosenbaum.se> wrote:
>
> 2017-12-18 13:43 GMT+01:00 Eric Voskuil <eric at voskuil.org>:
>
>>
>> > On Dec 18, 2017, at 03:32, Kalle Rosenbaum via bitcoin-dev <
>> bitcoin-dev at lists.linuxfoundation.org> wrote:
>> >
>> > Dear list,
>> >
>> > I find it hard to understand why a full node that does initial block
>> > download also must download witnesses if they are going to skip
>> verification anyway.
>>
>> Why run a full node if you are not going to verify the chain?
>>
>
> I meant to say "I find it hard to understand why a full node that does
> initial block
> download also must download witnesses when it is going to skip
> verification of the witnesses anyway."
>
> I'm referring to the "assumevalid" feature of Bitcoin Core that skips
> signature verification up to block X. Or have I misunderstood assumevalid?
>
> /Kalle
>
>
>>
>> > If my full node skips signature verification for
>> > blocks earlier than X, it seems the reasons for downloading the
>> > witnesses for those blocks are:
>> >
>> > * to be able to send witnesses to other nodes.
>> >
>> > * to verify the witness root hash of the blocks
>> >
>> > I suppose that it's important to verify the witness root hash because
>> > a bad peer may send me invalid witnesses during initial block
>> > download, and if I don't verify that the witness root hash actually
>> > commits to them, I will get banned by peers requesting the blocks from
>> > me because I send them garbage.
>> > So both the reasons above (there may be more that I don't know about)
>> > are actually the same reason: To be able to send witnesses to others
>> > without getting banned.
>> >
>> > What if a node could chose not to download witnesses and thus chose to
>> > send only witnessless blocks to peers. Let's call these nodes
>> > witnessless nodes. Note that witnessless nodes are only witnessless
>> > for blocks up to X. Everything after X is fully verified.
>> >
>> > Witnessless nodes would be able to sync faster because it needs to
>> > download less data to calculate their UTXO set. They would therefore
>> > more quickly be able to provide full service to SPV wallets and its
>> > local wallets as well as serving blocks to other witnessless nodes
>> > with same or higher assumevalid block. For witnessless nodes with
>> > lower assumevalid they can serve at least some blocks. It could also
>> > serve blocks to non-segwit nodes.
>> >
>> > Do witnessless nodes risk dividing the network in two parts, one
>> > witnessless and one with full nodes, with few connections between the
>> > parts?
>> >
>> > So basically, what are the reasons not to implement witnessless
>> > nodes?
>> >
>> > Thank you,
>> > /Kalle
>> > _______________________________________________
>> > bitcoin-dev mailing list
>> > bitcoin-dev at lists.linuxfoundation.org
>> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171218/966989da/attachment-0001.html>

From mark at friedenbach.org  Mon Dec 18 22:03:44 2017
From: mark at friedenbach.org (Mark Friedenbach)
Date: Mon, 18 Dec 2017 14:03:44 -0800
Subject: [bitcoin-dev] Clarification about SegWit transaction size and
	bech32
In-Reply-To: <cdc58f64d235e77031d59dc316c85a86@albertodeluigi.com>
References: <003c01d3781e$dda115f0$98e341d0$@albertodeluigi.com>
	<B0012211-15E8-45F8-881C-D4C120288CA4@friedenbach.org>
	<cdc58f64d235e77031d59dc316c85a86@albertodeluigi.com>
Message-ID: <31B7FC33-8C4A-4F73-A126-70D6C830BFBB@friedenbach.org>

Why would I send you coins to anything other than the address you provided to me? If you send me a bech32 address I use the native segwit scripts. If you send me an old address, I do what it specifies instead. The recipient has control over what type of script the payment is sent to, without any ambiguity.

> On Dec 18, 2017, at 1:41 PM, mail at albertodeluigi.com wrote:
> 
> Hi Mark,
> thank you. I understand your point, but despite what we define as a fork, when a software uses a particular address, it becomes part of the rules of that software. If another software doesn't recognize that address as a bitcoin address, then the rules it enforces aren't compatible with the behaviour of the first software. If you send me your bitcoins, I can't receive it, exactly like if it was in another chain. This happens even if there isn't such a situation where miners verify that transaction on a chain, while other miners reject it.
> 
> If we want to change the addresses, we need consensus and the coordinate upgrade of the entire network. In case we haven't consensus, most of the clients cannot send and receive bitcoins, which is a huge problem.
> For this reason I think it is something we should discuss in order to make a coordinated upgrade, exactly like what we do when we propose a fork. And it would be better to do it precisely as a part of a fork, like a 2x (or whatever other upgrade gaining enough consensus)
> 
> Apart from the proposal of an upgrade to bench32, do you agree with the rest of my points? I know segwit is valuable because it fixes tx malleability and so on... thank you for your link, but that wasn't the point I wanted to highlight!
> 
> Thank you,
> Alberto
> 
> 
> 
> 
> Il 2017-12-18 18:38 Mark Friedenbach ha scritto:
>> Addresses are entirely a user-interface issue. They don?t factor
>> into the bitcoin protocol at all.
>> The bitcoin protocol doesn?t have addresses. It has a generic
>> programmable signature framework called script. Addresses are merely a
>> UI convention for representing common script templates. 1.. addresses
>> and 3? addresses have script templates that are not as optimal as
>> could be constructed with post-segwit assumptions. The newer bech32
>> address just uses a different underlying template that achieves better
>> security guarantees (for pay-to-script) or lower fees (for
>> pay-to-pubkey-hash). But this is really a UI/UX issue.
>> A ?fork? in bitcoin-like consensus systems has a very specific
>> meaning. Changing address formats is not a fork, soft or hard.
>> There are many benefits to segregated witness. You may find this page
>> helpful:
>> https://bitcoincore.org/en/2016/01/26/segwit-benefits/ [4]
>>> On Dec 18, 2017, at 8:40 AM, Alberto De Luigi via bitcoin-dev
>>> <bitcoin-dev at lists.linuxfoundation.org> wrote:
>>> Hello guys,
>>> I have a few questions about the SegWit tx size, I'd like to have
>>> confirmation about the following statements. Can you correct
>>> mistakes or inaccuracies? Thank you in advance.
>>> In general, SegWit tx costs more than legacy tx (source
>>> https://bitcoincore.org/en/2016/10/28/segwit-costs/ [1]):
>>> * Compared to P2PKH, P2WPKH uses 3 fewer bytes (-1%) in the
>>> scriptPubKey, and the same number of witness bytes as P2PKH
>>> scriptSig.
>>> * Compared to P2SH, P2WSH uses 11 additional bytes (6%) in the
>>> scriptPubKey, and the same number of witness bytes as P2SH
>>> scriptSig.
>>> * Compared to P2PKH, P2WPKH/P2SH uses 21 additional bytes (11%),
>>> due to using 24 bytes in scriptPubKey, 3 fewer bytes in scriptSig
>>> than in P2PKH scriptPubKey, and the same number of witness bytes as
>>> P2PKH scriptSig.
>>> * Compared to P2SH, P2WSH/P2SH uses 35 additional bytes (19%), due
>>> to using 24 bytes in scriptPubKey, 11 additional bytes in scriptSig
>>> compared to P2SH scriptPubKey, and the same number of witness bytes
>>> as P2SH scriptSig.
>>> But still it is convenient to adopt segwit because you move the
>>> bytes to the blockweight part, paying smaller fee. In general, a tx
>>> with 1 input and 1 output is about 190kb. If it's a Segwit tx, 82kb
>>> in the non-witness part (blocksize), 108 in the witness part
>>> (blockweight).
>>> See source:
>>> 4 bytes version
>>> 1 byte input count
>>> Input
>>> 36 bytes outpoint
>>> 1 byte scriptSigLen (0x00)
>>> 0 bytes scriptSig
>>> 4 bytes sequence
>>> 1 byte output count
>>> 8 bytes value
>>> 1 byte scriptPubKeyLen
>>> 22 bytes scriptPubKey (0x0014{20-byte keyhash})
>>> 4 bytes locktime
>> https://bitcoin.stackexchange.com/questions/59408/with-100-segwit-transactions-what-would-be-the-max-number-of-transaction-confi
>>> [2]
>>> Which means, if you fill a block entirely with this kind of tx, you
>>> can approximately double the capacity of the blockchain (blocksize
>>> capped to 1mb, blockweight a little bit more than 2mb)
>>> My concern is about segwit adoption by the exchanges.
>>> SegWit transactions cost 10bytes more than legacy transactions for
>>> each output (vout is 256 bits instead of 160). Exchanges aggregate
>>> tx adding many outputs, which is of course something good for
>>> bitcoin scalability, since this way we save space and pay less fees.
>>> But when a tx has at least 10 outputs, using segwit you don't save
>>> space, instead:
>>> - the total blockweight is at least 100bytes higher (10bytes x 10
>>> outputs), so the blockchain is heavier
>>> - you don't save space inside the blocksize, so you cannot validate
>>> more transactions of this kind (with many outputs), nor get cheaper
>>> fee
>>> - without cheaper fees exchanges have no incentives for segwit
>>> adoption before they decide to adopt LN
>>> In general we can say that using SegWit:
>>> - you decrease the fee only for some specific kind of transactions,
>>> and just because you move some bytes to the blockweight
>>> - you don?t save space in the blockchain, on the contrary the
>>> total weight of the blockchain increases (so it's clear to me why
>>> some time ago Luke tweeted to not use SegWit unless really
>>> necessary... but then it's not clear why so much haste in promoting
>>> BIP148 the 1st august risking a split)
>>> If it's all correct, does something change with bech32? I'm reading
>>> bech32 allows to save about 22% of the space. Is this true for
>>> whatever kind of tx? Immediate benefits of segwit for scalability
>>> are only with bech32?
>>> Bech32 is non-compatible with the entire ecosystem (you cannot
>>> receive coins from the quasi-totality of wallets in circulation), I
>>> would say it is a hard fork. But the bare segwit is really so
>>> different? the soft fork is "soft" for the reference client Bitcoin
>>> Core, but outside you cannot know what happens, there are plenty of
>>> implementations (especially frontend customization) which don?t
>>> work with segwit and need to upgrade. To upgrade takes a lot of
>>> time, especially when services are so crowded and so many new people
>>> want to step in. At this point, if bech32 brings only efficiency
>>> (but correct me if it?s not so) and it is well planned, it could
>>> be a consensual upgrade, maybe together with a 2x blocksize? Is
>>> there a specific plan for some upgrade in 2018? I personally think
>>> it is far easier to reach consensus on a blocksize increase una
>>> tantum rather than a dynamic increase. You cannot predict the
>>> technology growth: will it be linear, exponential, or suddenly stop
>>> for a while, maybe right before a huge innovation? I think a hard
>>> fork bech32 upgrade + 2x could help a lot in scalability while we
>>> test LN, and it might be the only way to effectively promote (or
>>> should I say enforce?) SegWit adoption.
>>> thank you,
>>> Alberto De Luigi
>>> (.com)_______________________________________________
>>> bitcoin-dev mailing list
>>> bitcoin-dev at lists.linuxfoundation.org
>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev [3]
>> Links:
>> ------
>> [1] https://bitcoincore.org/en/2016/10/28/segwit-costs/
>> [2]
>> https://bitcoin.stackexchange.com/questions/59408/with-100-segwit-transactions-what-would-be-the-max-number-of-transaction-confi
>> [3] https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>> [4] https://bitcoincore.org/en/2016/01/26/segwit-benefits/
> 
> 

From kalle at rosenbaum.se  Mon Dec 18 21:51:40 2017
From: kalle at rosenbaum.se (Kalle Rosenbaum)
Date: Mon, 18 Dec 2017 22:51:40 +0100
Subject: [bitcoin-dev] Why not witnessless nodes?
In-Reply-To: <CAAS2fgRuLWbQLw=2EQEODGHOp0=OrLkGguw=jJSCpQXEC_P+hQ@mail.gmail.com>
References: <CAPswA9ycPdTtm9PeD5a2R36cZ46HwnkwJu06FXuoE-F5Dx+eZQ@mail.gmail.com>
	<CAAS2fgRuLWbQLw=2EQEODGHOp0=OrLkGguw=jJSCpQXEC_P+hQ@mail.gmail.com>
Message-ID: <CAPswA9xurB=RJq4z1pJxkLN+ojSccf+T5nK4YJh2eAwwpb7r9A@mail.gmail.com>

Hi Greg,

2017-12-18 21:42 GMT+01:00 Gregory Maxwell <greg at xiph.org>:

> Because it would make no meaningful difference now,


Sure.


> and if you are not
> going to check the history


I'm not going to do any less checks than a node running with assumevalid.
Well not exactly true, because a node running today with assumevalid will
verify the witness root hash, right?


> there are much more efficient things to
> do-- like not transfer it at all.
>

I'm not sure what you are referring to.

Thank you
/Kalle


>
> On Mon, Dec 18, 2017 at 8:32 AM, Kalle Rosenbaum via bitcoin-dev
> <bitcoin-dev at lists.linuxfoundation.org> wrote:
> > Dear list,
> >
> > I find it hard to understand why a full node that does initial block
> > download also must download witnesses if they are going to skip
> > verification anyway. If my full node skips signature verification for
> > blocks earlier than X, it seems the reasons for downloading the
> > witnesses for those blocks are:
> >
> > * to be able to send witnesses to other nodes.
> >
> > * to verify the witness root hash of the blocks
> >
> > I suppose that it's important to verify the witness root hash because
> > a bad peer may send me invalid witnesses during initial block
> > download, and if I don't verify that the witness root hash actually
> > commits to them, I will get banned by peers requesting the blocks from
> > me because I send them garbage.
> >
> > So both the reasons above (there may be more that I don't know about)
> > are actually the same reason: To be able to send witnesses to others
> > without getting banned.
> >
> > What if a node could chose not to download witnesses and thus chose to
> > send only witnessless blocks to peers. Let's call these nodes
> > witnessless nodes. Note that witnessless nodes are only witnessless
> > for blocks up to X. Everything after X is fully verified.
> >
> > Witnessless nodes would be able to sync faster because it needs to
> > download less data to calculate their UTXO set. They would therefore
> > more quickly be able to provide full service to SPV wallets and its
> > local wallets as well as serving blocks to other witnessless nodes
> > with same or higher assumevalid block. For witnessless nodes with
> > lower assumevalid they can serve at least some blocks. It could also
> > serve blocks to non-segwit nodes.
> >
> > Do witnessless nodes risk dividing the network in two parts, one
> > witnessless and one with full nodes, with few connections between the
> > parts?
> >
> > So basically, what are the reasons not to implement witnessless
> > nodes?
> >
> > Thank you,
> > /Kalle
> >
> > _______________________________________________
> > bitcoin-dev mailing list
> > bitcoin-dev at lists.linuxfoundation.org
> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> >
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171218/f5af3a69/attachment-0001.html>

From eric at voskuil.org  Mon Dec 18 21:58:58 2017
From: eric at voskuil.org (Eric Voskuil)
Date: Mon, 18 Dec 2017 16:58:58 -0500
Subject: [bitcoin-dev] Why not witnessless nodes?
In-Reply-To: <CAPswA9xEf9+vtW5LwdzJ5BofN4zJLoiPUy9i=mH=UQrcyUifLw@mail.gmail.com>
References: <CAPswA9ycPdTtm9PeD5a2R36cZ46HwnkwJu06FXuoE-F5Dx+eZQ@mail.gmail.com>
	<CD7FBCF6-5386-4E9E-A3B9-D5B3DBAF312C@voskuil.org>
	<CAPswA9zo1dLYHP9A+xrYLsrFO5GVYFqVLQC-A9uHQSCie7xeYg@mail.gmail.com>
	<A2B6418E-069F-476A-86EE-638C6D9E826A@voskuil.org>
	<61B0AEC9-3B1D-416F-8883-A030E5109538@friedenbach.org>
	<CAPswA9xEf9+vtW5LwdzJ5BofN4zJLoiPUy9i=mH=UQrcyUifLw@mail.gmail.com>
Message-ID: <F000E66A-DC3A-4A40-A74C-E6259A9D747B@voskuil.org>

How does one know what consensus has formed (around a UTXO set)?

e

> On Dec 18, 2017, at 16:27, Kalle Rosenbaum via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
> 
> Hi Mark
> 
> Yes, it seems like sign-to-contract protocols, which I just now briefly read about [1][2], may need to use historic witnesses. That raises the question, what are Bitcoin witnesses for?
> 
> To me it seems witnesses should be regarded as temporary. But it seems both respondents to this thread, Eric and Mark, mean that witnesses are forever. I regard witnesses as a way to authenticate updates to the UTXO set, and once buried deep enough in the blockchain, the witness is no longer needed, because consensus has formed around the UTXO set update.
> 
> Suppose a transaction with an invalid witness happens to enter the blockchain and gets buried 100000 blocks down with the witness still available. Is the blockchain above it valid? I'd say the blockchain is valid and that it was a bug that the transaction made it into the blockchain. We will have to live with such bugs.
> 
> Another way to put it: Suppose that all witnesses from 2017 dissappears from all nodes in 2020. Is the blockchain still valid? I think so. I would continue using it without looking back.
> 
> With that approach, I think sign-to-contract protocols has to find ways to work in a witnessless environment. For example, users of such protocols can setup their own archival nodes.
> 
> I'd love to hear alternative views on this.
> 
> Thanks,
> /Kalle
> 
> [1] https://download.wpsoftware.net/bitcoin/wizardry/mw-slides/2017-03-mit-bitcoin-expo/slides.pdf
> [2] https://bitcointalk.org/index.php?topic=893898.msg9861102#msg9861102
> 
> 2017-12-18 18:30 GMT+01:00 Mark Friedenbach via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>:
>> Sign-to-contract enables some interesting protocols, none of which are in wide use as far as I?m aware. But if they were (and arguably this is an area that should be more developed), then SPV nodes validating these protocols will need access to witness data. If a node is performing IBD with assumevalid set to true, and is also intending to prune history, then there?s no reason to fetch those witnesses as far as I?m aware. But it would be a great disservice to the network for nodes intending to serve SPV clients to prune this portion of the block history. 
>> 
>> 
>>> On Dec 18, 2017, at 8:19 AM, Eric Voskuil via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
>>> 
>>> You can't know (assume) a block is valid unless you have previously validated the block yourself. But in the case where you have, and then intend to rely on it in a future sync, there is no need for witness data for blocks you are not going to validate. So you can just not request it. 
>>> 
>>> However you will not be able to provide those blocks to nodes that *are* validating; the client is pruned and therefore not a peer (cannot reciprocate). (An SPV client is similarly not a peer; it is a more deeply pruned client than the witnessless client.)
>>> 
>>> There is no other reason that a node requires witness data. SPV clients don't need it as it is neither require it to verify header commitment to transactions nor to extract payment addresses from them.
>>> 
>>> The harm to the network by pruning is that eventually it can become harder and even impossible for anyone to validate the chain. But because you are fully validating you individually remain secure, so there is no individual incentive working against this system harm.
>>> 
>>> e
>>> 
>>>> On Dec 18, 2017, at 08:35, Kalle Rosenbaum <kalle at rosenbaum.se> wrote:
>>>> 
>>>> 2017-12-18 13:43 GMT+01:00 Eric Voskuil <eric at voskuil.org>:
>>>>> 
>>>>> > On Dec 18, 2017, at 03:32, Kalle Rosenbaum via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
>>>>> >
>>>>> > Dear list,
>>>>> >
>>>>> > I find it hard to understand why a full node that does initial block
>>>>> > download also must download witnesses if they are going to skip verification anyway.
>>>>> 
>>>>> Why run a full node if you are not going to verify the chain?
>>>> 
>>>> I meant to say "I find it hard to understand why a full node that does initial block
>>>> download also must download witnesses when it is going to skip verification of the witnesses anyway."
>>>> 
>>>> I'm referring to the "assumevalid" feature of Bitcoin Core that skips signature verification up to block X. Or have I misunderstood assumevalid?
>>>> 
>>>> /Kalle
>>>>  
>>>>> 
>>>>> > If my full node skips signature verification for
>>>>> > blocks earlier than X, it seems the reasons for downloading the
>>>>> > witnesses for those blocks are:
>>>>> >
>>>>> > * to be able to send witnesses to other nodes.
>>>>> >
>>>>> > * to verify the witness root hash of the blocks
>>>>> >
>>>>> > I suppose that it's important to verify the witness root hash because
>>>>> > a bad peer may send me invalid witnesses during initial block
>>>>> > download, and if I don't verify that the witness root hash actually
>>>>> > commits to them, I will get banned by peers requesting the blocks from
>>>>> > me because I send them garbage.
>>>>> > So both the reasons above (there may be more that I don't know about)
>>>>> > are actually the same reason: To be able to send witnesses to others
>>>>> > without getting banned.
>>>>> >
>>>>> > What if a node could chose not to download witnesses and thus chose to
>>>>> > send only witnessless blocks to peers. Let's call these nodes
>>>>> > witnessless nodes. Note that witnessless nodes are only witnessless
>>>>> > for blocks up to X. Everything after X is fully verified.
>>>>> >
>>>>> > Witnessless nodes would be able to sync faster because it needs to
>>>>> > download less data to calculate their UTXO set. They would therefore
>>>>> > more quickly be able to provide full service to SPV wallets and its
>>>>> > local wallets as well as serving blocks to other witnessless nodes
>>>>> > with same or higher assumevalid block. For witnessless nodes with
>>>>> > lower assumevalid they can serve at least some blocks. It could also
>>>>> > serve blocks to non-segwit nodes.
>>>>> >
>>>>> > Do witnessless nodes risk dividing the network in two parts, one
>>>>> > witnessless and one with full nodes, with few connections between the
>>>>> > parts?
>>>>> >
>>>>> > So basically, what are the reasons not to implement witnessless
>>>>> > nodes?
>>>>> >
>>>>> > Thank you,
>>>>> > /Kalle
>>>>> > _______________________________________________
>>>>> > bitcoin-dev mailing list
>>>>> > bitcoin-dev at lists.linuxfoundation.org
>>>>> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>> 
>>> _______________________________________________
>>> bitcoin-dev mailing list
>>> bitcoin-dev at lists.linuxfoundation.org
>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>> 
>> 
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>> 
> 
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171218/f9f579ba/attachment-0001.html>

From mail at albertodeluigi.com  Mon Dec 18 21:41:18 2017
From: mail at albertodeluigi.com (mail at albertodeluigi.com)
Date: Mon, 18 Dec 2017 22:41:18 +0100
Subject: [bitcoin-dev] Clarification about SegWit transaction size and bech32
In-Reply-To: <B0012211-15E8-45F8-881C-D4C120288CA4@friedenbach.org>
References: <003c01d3781e$dda115f0$98e341d0$@albertodeluigi.com>
	<B0012211-15E8-45F8-881C-D4C120288CA4@friedenbach.org>
Message-ID: <cdc58f64d235e77031d59dc316c85a86@albertodeluigi.com>

Hi Mark,
thank you. I understand your point, but despite what we define as a 
fork, when a software uses a particular address, it becomes part of the 
rules of that software. If another software doesn't recognize that 
address as a bitcoin address, then the rules it enforces aren't 
compatible with the behaviour of the first software. If you send me your 
bitcoins, I can't receive it, exactly like if it was in another chain. 
This happens even if there isn't such a situation where miners verify 
that transaction on a chain, while other miners reject it.

If we want to change the addresses, we need consensus and the coordinate 
upgrade of the entire network. In case we haven't consensus, most of the 
clients cannot send and receive bitcoins, which is a huge problem.
For this reason I think it is something we should discuss in order to 
make a coordinated upgrade, exactly like what we do when we propose a 
fork. And it would be better to do it precisely as a part of a fork, 
like a 2x (or whatever other upgrade gaining enough consensus)

Apart from the proposal of an upgrade to bench32, do you agree with the 
rest of my points? I know segwit is valuable because it fixes tx 
malleability and so on... thank you for your link, but that wasn't the 
point I wanted to highlight!

Thank you,
Alberto




Il 2017-12-18 18:38 Mark Friedenbach ha scritto:
> Addresses are entirely a user-interface issue. They don?t factor
> into the bitcoin protocol at all.
> 
> The bitcoin protocol doesn?t have addresses. It has a generic
> programmable signature framework called script. Addresses are merely a
> UI convention for representing common script templates. 1.. addresses
> and 3? addresses have script templates that are not as optimal as
> could be constructed with post-segwit assumptions. The newer bech32
> address just uses a different underlying template that achieves better
> security guarantees (for pay-to-script) or lower fees (for
> pay-to-pubkey-hash). But this is really a UI/UX issue.
> 
> A ?fork? in bitcoin-like consensus systems has a very specific
> meaning. Changing address formats is not a fork, soft or hard.
> 
> There are many benefits to segregated witness. You may find this page
> helpful:
> 
> https://bitcoincore.org/en/2016/01/26/segwit-benefits/ [4]
> 
>> On Dec 18, 2017, at 8:40 AM, Alberto De Luigi via bitcoin-dev
>> <bitcoin-dev at lists.linuxfoundation.org> wrote:
>> 
>> Hello guys,
>> I have a few questions about the SegWit tx size, I'd like to have
>> confirmation about the following statements. Can you correct
>> mistakes or inaccuracies? Thank you in advance.
>> 
>> In general, SegWit tx costs more than legacy tx (source
>> https://bitcoincore.org/en/2016/10/28/segwit-costs/ [1]):
>> 
>> * Compared to P2PKH, P2WPKH uses 3 fewer bytes (-1%) in the
>> scriptPubKey, and the same number of witness bytes as P2PKH
>> scriptSig.
>> * Compared to P2SH, P2WSH uses 11 additional bytes (6%) in the
>> scriptPubKey, and the same number of witness bytes as P2SH
>> scriptSig.
>> * Compared to P2PKH, P2WPKH/P2SH uses 21 additional bytes (11%),
>> due to using 24 bytes in scriptPubKey, 3 fewer bytes in scriptSig
>> than in P2PKH scriptPubKey, and the same number of witness bytes as
>> P2PKH scriptSig.
>> * Compared to P2SH, P2WSH/P2SH uses 35 additional bytes (19%), due
>> to using 24 bytes in scriptPubKey, 11 additional bytes in scriptSig
>> compared to P2SH scriptPubKey, and the same number of witness bytes
>> as P2SH scriptSig.
>> 
>> But still it is convenient to adopt segwit because you move the
>> bytes to the blockweight part, paying smaller fee. In general, a tx
>> with 1 input and 1 output is about 190kb. If it's a Segwit tx, 82kb
>> in the non-witness part (blocksize), 108 in the witness part
>> (blockweight).
>> See source:
>> 4 bytes version
>> 1 byte input count
>> Input
>> 36 bytes outpoint
>> 1 byte scriptSigLen (0x00)
>> 0 bytes scriptSig
>> 4 bytes sequence
>> 1 byte output count
>> 8 bytes value
>> 1 byte scriptPubKeyLen
>> 22 bytes scriptPubKey (0x0014{20-byte keyhash})
>> 4 bytes locktime
>> 
> https://bitcoin.stackexchange.com/questions/59408/with-100-segwit-transactions-what-would-be-the-max-number-of-transaction-confi
>> [2]
>> 
>> Which means, if you fill a block entirely with this kind of tx, you
>> can approximately double the capacity of the blockchain (blocksize
>> capped to 1mb, blockweight a little bit more than 2mb)
>> 
>> My concern is about segwit adoption by the exchanges.
>> SegWit transactions cost 10bytes more than legacy transactions for
>> each output (vout is 256 bits instead of 160). Exchanges aggregate
>> tx adding many outputs, which is of course something good for
>> bitcoin scalability, since this way we save space and pay less fees.
>> But when a tx has at least 10 outputs, using segwit you don't save
>> space, instead:
>> 
>> - the total blockweight is at least 100bytes higher (10bytes x 10
>> outputs), so the blockchain is heavier
>> - you don't save space inside the blocksize, so you cannot validate
>> more transactions of this kind (with many outputs), nor get cheaper
>> fee
>> - without cheaper fees exchanges have no incentives for segwit
>> adoption before they decide to adopt LN
>> 
>> In general we can say that using SegWit:
>> - you decrease the fee only for some specific kind of transactions,
>> and just because you move some bytes to the blockweight
>> - you don?t save space in the blockchain, on the contrary the
>> total weight of the blockchain increases (so it's clear to me why
>> some time ago Luke tweeted to not use SegWit unless really
>> necessary... but then it's not clear why so much haste in promoting
>> BIP148 the 1st august risking a split)
>> 
>> If it's all correct, does something change with bech32? I'm reading
>> bech32 allows to save about 22% of the space. Is this true for
>> whatever kind of tx? Immediate benefits of segwit for scalability
>> are only with bech32?
>> 
>> Bech32 is non-compatible with the entire ecosystem (you cannot
>> receive coins from the quasi-totality of wallets in circulation), I
>> would say it is a hard fork. But the bare segwit is really so
>> different? the soft fork is "soft" for the reference client Bitcoin
>> Core, but outside you cannot know what happens, there are plenty of
>> implementations (especially frontend customization) which don?t
>> work with segwit and need to upgrade. To upgrade takes a lot of
>> time, especially when services are so crowded and so many new people
>> want to step in. At this point, if bech32 brings only efficiency
>> (but correct me if it?s not so) and it is well planned, it could
>> be a consensual upgrade, maybe together with a 2x blocksize? Is
>> there a specific plan for some upgrade in 2018? I personally think
>> it is far easier to reach consensus on a blocksize increase una
>> tantum rather than a dynamic increase. You cannot predict the
>> technology growth: will it be linear, exponential, or suddenly stop
>> for a while, maybe right before a huge innovation? I think a hard
>> fork bech32 upgrade + 2x could help a lot in scalability while we
>> test LN, and it might be the only way to effectively promote (or
>> should I say enforce?) SegWit adoption.
>> 
>> thank you,
>> Alberto De Luigi
>> (.com)_______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev [3]
> 
> 
> 
> Links:
> ------
> [1] https://bitcoincore.org/en/2016/10/28/segwit-costs/
> [2]
> https://bitcoin.stackexchange.com/questions/59408/with-100-segwit-transactions-what-would-be-the-max-number-of-transaction-confi
> [3] https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> [4] https://bitcoincore.org/en/2016/01/26/segwit-benefits/



From mail at albertodeluigi.com  Mon Dec 18 22:19:34 2017
From: mail at albertodeluigi.com (mail at albertodeluigi.com)
Date: Mon, 18 Dec 2017 23:19:34 +0100
Subject: [bitcoin-dev] Clarification about SegWit transaction size and bech32
In-Reply-To: <31B7FC33-8C4A-4F73-A126-70D6C830BFBB@friedenbach.org>
References: <003c01d3781e$dda115f0$98e341d0$@albertodeluigi.com>
	<B0012211-15E8-45F8-881C-D4C120288CA4@friedenbach.org>
	<cdc58f64d235e77031d59dc316c85a86@albertodeluigi.com>
	<31B7FC33-8C4A-4F73-A126-70D6C830BFBB@friedenbach.org>
Message-ID: <cc605af6ccaf752d26dd85aaf122b8d0@albertodeluigi.com>

Mark,
suppose I am an average user. Give me a bech32 address and ask me to 
send a few coins there. I am 100% sure you will never receive my coins. 
I will call you back saying: "Mark, sorry, I tried with three different 
wallets, but it seems what you gave me is not a bitcoin address!"

My point is: we want SegWit is used and implemented more and more by the 
community. But if besides malleability fix, the main effect of sw 
adoption is this:

1) The blockahin is heavier (transactions require more space)
2) the fee is smaller only for some kind of tx
3) the transactions of the exchanges, which aggregate outputs, would be 
heavier and pay a higher fee using segwit!

then how can we expect people, exchanges and services to adopt segwit?

Thank you,
Alberto De Luigi



Il 2017-12-18 23:03 Mark Friedenbach ha scritto:
> Why would I send you coins to anything other than the address you
> provided to me? If you send me a bech32 address I use the native
> segwit scripts. If you send me an old address, I do what it specifies
> instead. The recipient has control over what type of script the
> payment is sent to, without any ambiguity.
> 
>> On Dec 18, 2017, at 1:41 PM, mail at albertodeluigi.com wrote:
>> 
>> Hi Mark,
>> thank you. I understand your point, but despite what we define as a 
>> fork, when a software uses a particular address, it becomes part of 
>> the rules of that software. If another software doesn't recognize that 
>> address as a bitcoin address, then the rules it enforces aren't 
>> compatible with the behaviour of the first software. If you send me 
>> your bitcoins, I can't receive it, exactly like if it was in another 
>> chain. This happens even if there isn't such a situation where miners 
>> verify that transaction on a chain, while other miners reject it.
>> 
>> If we want to change the addresses, we need consensus and the 
>> coordinate upgrade of the entire network. In case we haven't 
>> consensus, most of the clients cannot send and receive bitcoins, which 
>> is a huge problem.
>> For this reason I think it is something we should discuss in order to 
>> make a coordinated upgrade, exactly like what we do when we propose a 
>> fork. And it would be better to do it precisely as a part of a fork, 
>> like a 2x (or whatever other upgrade gaining enough consensus)
>> 
>> Apart from the proposal of an upgrade to bench32, do you agree with 
>> the rest of my points? I know segwit is valuable because it fixes tx 
>> malleability and so on... thank you for your link, but that wasn't the 
>> point I wanted to highlight!
>> 
>> Thank you,
>> Alberto
>> 
>> 
>> 
>> 
>> Il 2017-12-18 18:38 Mark Friedenbach ha scritto:
>>> Addresses are entirely a user-interface issue. They don?t factor
>>> into the bitcoin protocol at all.
>>> The bitcoin protocol doesn?t have addresses. It has a generic
>>> programmable signature framework called script. Addresses are merely 
>>> a
>>> UI convention for representing common script templates. 1.. addresses
>>> and 3? addresses have script templates that are not as optimal as
>>> could be constructed with post-segwit assumptions. The newer bech32
>>> address just uses a different underlying template that achieves 
>>> better
>>> security guarantees (for pay-to-script) or lower fees (for
>>> pay-to-pubkey-hash). But this is really a UI/UX issue.
>>> A ?fork? in bitcoin-like consensus systems has a very specific
>>> meaning. Changing address formats is not a fork, soft or hard.
>>> There are many benefits to segregated witness. You may find this page
>>> helpful:
>>> https://bitcoincore.org/en/2016/01/26/segwit-benefits/ [4]
>>>> On Dec 18, 2017, at 8:40 AM, Alberto De Luigi via bitcoin-dev
>>>> <bitcoin-dev at lists.linuxfoundation.org> wrote:
>>>> Hello guys,
>>>> I have a few questions about the SegWit tx size, I'd like to have
>>>> confirmation about the following statements. Can you correct
>>>> mistakes or inaccuracies? Thank you in advance.
>>>> In general, SegWit tx costs more than legacy tx (source
>>>> https://bitcoincore.org/en/2016/10/28/segwit-costs/ [1]):
>>>> * Compared to P2PKH, P2WPKH uses 3 fewer bytes (-1%) in the
>>>> scriptPubKey, and the same number of witness bytes as P2PKH
>>>> scriptSig.
>>>> * Compared to P2SH, P2WSH uses 11 additional bytes (6%) in the
>>>> scriptPubKey, and the same number of witness bytes as P2SH
>>>> scriptSig.
>>>> * Compared to P2PKH, P2WPKH/P2SH uses 21 additional bytes (11%),
>>>> due to using 24 bytes in scriptPubKey, 3 fewer bytes in scriptSig
>>>> than in P2PKH scriptPubKey, and the same number of witness bytes as
>>>> P2PKH scriptSig.
>>>> * Compared to P2SH, P2WSH/P2SH uses 35 additional bytes (19%), due
>>>> to using 24 bytes in scriptPubKey, 11 additional bytes in scriptSig
>>>> compared to P2SH scriptPubKey, and the same number of witness bytes
>>>> as P2SH scriptSig.
>>>> But still it is convenient to adopt segwit because you move the
>>>> bytes to the blockweight part, paying smaller fee. In general, a tx
>>>> with 1 input and 1 output is about 190kb. If it's a Segwit tx, 82kb
>>>> in the non-witness part (blocksize), 108 in the witness part
>>>> (blockweight).
>>>> See source:
>>>> 4 bytes version
>>>> 1 byte input count
>>>> Input
>>>> 36 bytes outpoint
>>>> 1 byte scriptSigLen (0x00)
>>>> 0 bytes scriptSig
>>>> 4 bytes sequence
>>>> 1 byte output count
>>>> 8 bytes value
>>>> 1 byte scriptPubKeyLen
>>>> 22 bytes scriptPubKey (0x0014{20-byte keyhash})
>>>> 4 bytes locktime
>>> https://bitcoin.stackexchange.com/questions/59408/with-100-segwit-transactions-what-would-be-the-max-number-of-transaction-confi
>>>> [2]
>>>> Which means, if you fill a block entirely with this kind of tx, you
>>>> can approximately double the capacity of the blockchain (blocksize
>>>> capped to 1mb, blockweight a little bit more than 2mb)
>>>> My concern is about segwit adoption by the exchanges.
>>>> SegWit transactions cost 10bytes more than legacy transactions for
>>>> each output (vout is 256 bits instead of 160). Exchanges aggregate
>>>> tx adding many outputs, which is of course something good for
>>>> bitcoin scalability, since this way we save space and pay less fees.
>>>> But when a tx has at least 10 outputs, using segwit you don't save
>>>> space, instead:
>>>> - the total blockweight is at least 100bytes higher (10bytes x 10
>>>> outputs), so the blockchain is heavier
>>>> - you don't save space inside the blocksize, so you cannot validate
>>>> more transactions of this kind (with many outputs), nor get cheaper
>>>> fee
>>>> - without cheaper fees exchanges have no incentives for segwit
>>>> adoption before they decide to adopt LN
>>>> In general we can say that using SegWit:
>>>> - you decrease the fee only for some specific kind of transactions,
>>>> and just because you move some bytes to the blockweight
>>>> - you don?t save space in the blockchain, on the contrary the
>>>> total weight of the blockchain increases (so it's clear to me why
>>>> some time ago Luke tweeted to not use SegWit unless really
>>>> necessary... but then it's not clear why so much haste in promoting
>>>> BIP148 the 1st august risking a split)
>>>> If it's all correct, does something change with bech32? I'm reading
>>>> bech32 allows to save about 22% of the space. Is this true for
>>>> whatever kind of tx? Immediate benefits of segwit for scalability
>>>> are only with bech32?
>>>> Bech32 is non-compatible with the entire ecosystem (you cannot
>>>> receive coins from the quasi-totality of wallets in circulation), I
>>>> would say it is a hard fork. But the bare segwit is really so
>>>> different? the soft fork is "soft" for the reference client Bitcoin
>>>> Core, but outside you cannot know what happens, there are plenty of
>>>> implementations (especially frontend customization) which don?t
>>>> work with segwit and need to upgrade. To upgrade takes a lot of
>>>> time, especially when services are so crowded and so many new people
>>>> want to step in. At this point, if bech32 brings only efficiency
>>>> (but correct me if it?s not so) and it is well planned, it could
>>>> be a consensual upgrade, maybe together with a 2x blocksize? Is
>>>> there a specific plan for some upgrade in 2018? I personally think
>>>> it is far easier to reach consensus on a blocksize increase una
>>>> tantum rather than a dynamic increase. You cannot predict the
>>>> technology growth: will it be linear, exponential, or suddenly stop
>>>> for a while, maybe right before a huge innovation? I think a hard
>>>> fork bech32 upgrade + 2x could help a lot in scalability while we
>>>> test LN, and it might be the only way to effectively promote (or
>>>> should I say enforce?) SegWit adoption.
>>>> thank you,
>>>> Alberto De Luigi
>>>> (.com)_______________________________________________
>>>> bitcoin-dev mailing list
>>>> bitcoin-dev at lists.linuxfoundation.org
>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev [3]
>>> Links:
>>> ------
>>> [1] https://bitcoincore.org/en/2016/10/28/segwit-costs/
>>> [2]
>>> https://bitcoin.stackexchange.com/questions/59408/with-100-segwit-transactions-what-would-be-the-max-number-of-transaction-confi
>>> [3] https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>> [4] https://bitcoincore.org/en/2016/01/26/segwit-benefits/
>> 
>> 



From willtech at live.com.au  Tue Dec 19 07:48:37 2017
From: willtech at live.com.au (Damian Williamson)
Date: Tue, 19 Dec 2017 07:48:37 +0000
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction
 Priority For Ordering Transactions In Blocks
In-Reply-To: <CAL5BAw0pQJg8MjopRH5ReBVHmJR0bYud=E6fkFuY=-3hMAumEw@mail.gmail.com>
References: <PS2P216MB01794ABD544248B27BF0DFD99D330@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<PS2P216MB01795BFC05612E021CCEDD7C9D0B0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<5upGmF0IhXUWhcikhdV-e9Pqg-kXfUuXe0kOpGxumie_TO2jLvCgTZ5c6vgBRtaqkL6DmOJb1YftK0osufB5RkhW7YhAhhCI0zBTH3YcORY=@protonmail.com>
	<PS2P216MB0179544A6503C2992190CEB69D0B0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>,
	<CAL5BAw0pQJg8MjopRH5ReBVHmJR0bYud=E6fkFuY=-3hMAumEw@mail.gmail.com>
Message-ID: <PS2P216MB01798757147723AF5B7B7CA49D0F0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>

Thank you for your constructive feedback. I now see that the proposal introduces a potential issue.


It is difficult to define then, what is a valid transaction? Clearly, my definition was insufficient.


Regards,

Damian Williamson


________________________________
From: Chris Riley <criley at gmail.com>
Sent: Monday, 18 December 2017 11:09 PM
To: Damian Williamson; Bitcoin Protocol Discussion
Subject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks

Regarding "problem" #2 where you say "How do we ensure that all valid transactions are eventually included in the blockchain?":  I do not believe that all people would (a) agree this is a problem or (b) that we do want to *ENSURE* that *ALL* valid transactions are eventually included in the blockchain.  There are many *valid* transactions that oftentimes miners do not (and should not) wish to require be confirmed and included in the blockchain.  Spam transactions for example can be valid, but used to attack bitcoin by using no or low fee.  Any valid transaction MAY be included by a miner, but requiring it in some fashion at this point would open the network to other attack vectors.  Perhaps you meant it a different way.


On Fri, Dec 15, 2017 at 3:59 PM, Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:
>
> There are really two separate problems to solve.
>
>
> How does Bitcoin scale with fixed block size?
> How do we ensure that all valid transactions are eventually included in the blockchain?
>
>
> Those are the two issues that the proposal attempts to address. It makes sense to resolve these two problems together. Using the proposed system for variable block sizes would solve the first problem but there would still be a whole bunch of never confirming transactions. I am not sure how to reliably solve the second problem at scale without first solving the first.
>
>
> >* Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.
>
>
> I do not suggest a consensus. Depending on which node solves a block the value for next block size will be different. The consensus would be that blocks will adhere to the next block size value transmitted with the current block. It is easy to verify that the consensus is being adhered to once in place.
>
> >* Increasing the entropy in a block to make it more unpredictable doesn't really make sense.
>
> Not a necessary function, just an effect of using a probability-based distribution.
>
> >* Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by "priority".  What are you going to do if a "malicious" miner decides to go after their profits and order by what makes them the most money. Add "ordered by priority" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.
>
> I entirely agree with your sentiment that Bitcoin must be incentive compatible. It is necessary.
>
> It is in only miners immediate interest to make the most profitable block from the available transaction pool. As with so many other things, it is necessary to partially ignore short-term gain for long-term benefit. It is in miners and everybody's long-term interest to have a reliable transaction service. A busy transaction service that confirms lots of transactions per hour will become more profitable as demand increases and more users are prepared to pay for priority. As it is there is currently no way to fully scale because of the transaction bandwidth limit and that is problematic. If all valid transactions must eventually confirm then there must be a way to resolve that problem.
>
> Bitcoin deliberately removes traditional scale by ensuring blocks take ten minutes on average to solve, an ingenious idea and, incentive compatible but, fixed block sizes leaves us with a problem to solve when we want to scale.
>
> >If you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.
>
> I am confident that the math to verify blocks based on the proposal can be developed (and I think it will not be too complex for a mathematician with the relevant experience), however, I am nowhere near experienced enough with probability and statistical analysis to do it. Yes, if Bitcoin doesn't then it might make another great opportunity for an altcoin but I am not even nearly interested in promoting any altcoins.
>
>
> If not the proposal that I have put forward, then, hopefully, someone can come up with a better solution. The important thing is that the issues are resolved.
>
>
> Regards,
>
> Damian Williamson
>
>
>
> ________________________________
> From: Rhavar <rhavar at protonmail.com<mailto:rhavar at protonmail.com>>
> Sent: Saturday, 16 December 2017 3:38 AM
> To: Damian Williamson
> Cc: Bitcoin Protocol Discussion
> Subject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks
>
> > I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?
>
> Unfortunately your proposal is really fundamentally broken, on a few levels. I think you might need to do a bit more research into how bitcoin works before coming up with such improvements =)
>
> But just some quick notes:
>
> * Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.
>
> * Increasing the entropy in a block to make it more unpredictable doesn't really make sense.
>
> * Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by "priority".  What are you going to do if a "malicious" miner decides to go after their profits and order by what makes them the most money. Add "ordered by priority" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.
>
> If you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.
>
>
>
>
> -Ryan
>
>
> -------- Original Message --------
> Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks
> Local Time: December 15, 2017 3:42 AM
> UTC Time: December 15, 2017 9:42 AM
> From: bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>
> To: Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>>
>
>
>
> I should not take it that the lack of critical feedback to this revised proposal is a glowing endorsement. I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?
>
> I suppose that it if is difficult to determine how long a transaction has been waiting in the pool then, each node could simply keep track of when a transaction was first seen. This may have implications for a verify routine, however, for example, if a node was offline, how should it differentiate how long each transaction was waiting in that case? If a node was restarted daily would it always think that all transactions had been waiting in the pool less than one day If each node keeps the current transaction pool in a file and updates it, as transactions are included in blocks and, as new transactions appear in the pool, then that would go some way to alleviate the issue, apart from entirely new nodes. There should be no reason the contents of a transaction pool files cannot be shared without agreement as to the transaction pool between nodes, just as nodes transmit new transactions freely.
>
> It has been questioned why miners could not cheat. For the question of how many transactions to include in a block, I say it is a standoff and miners will conform to the proposal, not wanting to leave transactions with valid fees standing, and, not wanting to shrink the transaction pool. In any case, if miners shrink the transaction pool then I am not immediately concerned since it provides a more efficient service. For the question of including transactions according to the proposal, I say if it is possible to keep track of how long transactions are waiting in the pool so that they can be included on a probability curve then it is possible to verify that blocks conform to the proposal, since the input is a probability, the output should conform to a probability curve.
>
>
> If someone has the necessary skill, would anyone be willing to develop the math necessary for the proposal?
>
> Regards,
> Damian Williamson
>
>
> ________________________________
>
> From: bitcoin-dev-bounces at lists.linuxfoundation.org<mailto:bitcoin-dev-bounces at lists.linuxfoundation.org> <bitcoin-dev-bounces at lists.linuxfoundation.org<mailto:bitcoin-dev-bounces at lists.linuxfoundation.org>> on behalf of Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>>
> Sent: Friday, 8 December 2017 8:01 AM
> To: bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>
> Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks
>
>
>
> Good afternoon,
>
> The need for this proposal:
>
> We all must learn to admit that transaction bandwidth is still lurking as a serious issue for the operation, reliability, safety, consumer acceptance, uptake and, for the value of Bitcoin.
>
> I recently sent a payment which was not urgent so; I chose three-day target confirmation from the fee recommendation. That transaction has still not confirmed after now more than six days - even waiting twice as long seems quite reasonable to me. That transaction is a valid transaction; it is not rubbish, junk or, spam. Under the current model with transaction bandwidth limitation, the longer a transaction waits, the less likely it is ever to confirm due to rising transaction numbers and being pushed back by transactions with rising fees.
>
> I argue that no transactions are rubbish or junk, only some zero fee transactions might be spam. Having an ever-increasing number of valid transactions that do not confirm as more new transactions with higher fees are created is the opposite of operating a robust, reliable transaction system.
>
> Business cannot operate with a model where transactions may or may not confirm. Even a business choosing a modest fee has no guarantee that their valid transaction will not be shuffled down by new transactions to the realm of never confirming after it is created. Consumers also will not accept this model as Bitcoin expands. If Bitcoin cannot be a reliable payment system for confirmed transactions then consumers, by and large, will simply not accept the model once they understand. Bitcoin will be a dirty payment system, and this will kill the value of Bitcoin.
>
> Under the current system, a minority of transactions will eventually be the lucky few who have fees high enough to escape being pushed down the list.
>
> Once there are more than x transactions (transaction bandwidth limit) every ten minutes, only those choosing twenty-minute confirmation (2 blocks) will have initially at most a fifty percent chance of ever having their payment confirm. Presently, not even using fee recommendations can ensure a sufficiently high fee is paid to ensure transaction confirmation.
>
> I also argue that the current auction model for limited transaction bandwidth is wrong, is not suitable for a reliable transaction system and, is wrong for Bitcoin. All transactions must confirm in due time. Currently, Bitcoin is not a safe way to send payments.
>
> I do not believe that consumers and business are against paying fees, even high fees. What is required is operational reliability.
>
> This great issue needs to be resolved for the safety and reliability of Bitcoin. The time to resolve issues in commerce is before they become great big issues. The time to resolve this issue is now. We must have the foresight to identify and resolve problems before they trip us over.  Simply doubling block sizes every so often is reactionary and is not a reliable permanent solution. I have written a BIP proposal for a technical solution but, need your help to write it up to an acceptable standard to be a full BIP.
>
> I have formatted the following with markdown which is human readable so, I hope nobody minds. I have done as much with this proposal as I feel that I am able so far but continue to take your feedback.
>
> # BIP Proposal: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks
>
> ## The problem:
> Everybody wants value. Miners want to maximize revenue from fees (and we presume, to minimize block size). Consumers need transaction reliability and, (we presume) want low fees.
>
> The current transaction bandwidth limit is a limiting factor for both. As the operational safety of transactions is limited, so is consumer confidence as they realize the issue and, accordingly, uptake is limited. Fees are artificially inflated due to bandwidth limitations while failing to provide a full confirmation service for all transactions.
>
> Current fee recommendations provide no satisfaction for transaction reliability and, as Bitcoin scales, this will worsen.
>
> Bitcoin must be a fully scalable and reliable service, providing full transaction confirmation for every valid transaction.
>
> The possibility to send a transaction with a fee lower than one that is acceptable to allow eventual transaction confirmation should be removed from the protocol and also from the user interface.
>
> ## Solution summary:
> Provide each transaction with an individual transaction priority each time before choosing transactions to include in the current block, the priority being a function of the fee paid (on a curve), and the time waiting in the transaction pool (also on a curve) out to n days (n=60 ?). The transaction priority to serve as the likelihood of a transaction being included in the current block, and for determining the order in which transactions are tried to see if they will be included.
>
> Use a target block size. Determine the target block size using; current transaction pool size x ( 1 / (144 x n days ) ) = number of transactions to be included in the current block. Broadcast the next target block size with the current block when it is solved so that nodes know the next target block size for the block that they are building on.
>
> The curves used for the priority of transactions would have to be appropriate. Perhaps a mathematician with experience in probability can develop the right formulae. My thinking is a steep curve. I suppose that the probability of all transactions should probably account for a sufficient number of inclusions that the target block size is met although, it may not always be. As a suggestion, consider including some zero fee transactions to pad, highest BTC value first?
>
> **Explanation of the operation of priority:**
> > If transaction priority is, for example, a number between one (low) and one-hundred (high) it can be directly understood as the percentage chance in one-hundred of a transaction being included in the block. Using probability or likelihood infers that there is some function of random. If random (100) < transaction priority then the transaction is included.
>
> >To break it down further, if both the fee on a curve value and the time waiting on a curve value are each a number between one and one-hundred, a rudimentary method may be to simply multiply those two numbers, to find the priority number. For example, a middle fee transaction waiting thirty days (if n = 60 days) may have a value of five for each part  (yes, just five, the values are on a curve). When multiplied that will give a priority value of twenty-five, or,  a twenty-five percent chance at that moment of being included in the block; it will likely be included in one of the next four blocks, getting more likely each chance. If it is still not included then the value of time waiting will be higher, making for more probability. A very low fee transaction would have a value for the fee of one. It would not be until near sixty-days that the particular low fee transaction has a high likelihood of being included in the block.
>
> I am not concerned with low (or high) transaction fees, the primary reason for addressing the issue is to ensure transactional reliability and scalability while having each transaction confirm in due time.
>
> ## Pros:
> * Maximizes transaction reliability.
> * Fully scalable.
> * Maximizes possibility for consumer and business uptake.
> * Maximizes total fees paid per block without reducing reliability; because of reliability, in time confidence and overall uptake are greater; therefore, more transactions.
> * Market determines fee paid for transaction priority.
> * Fee recommendations work all the way out to 30 days or greater.
> * Provides additional block entropy; greater security since there is less probability of predicting the next block.
>
> ## Cons:
> * Could initially lower total transaction fees per block.
> * Must be first be programmed.
>
> ## Solution operation:
> This is a simplistic view of the operation. The actual operation will need to be determined in a spec for the programmer.
>
> 1. Determine the target block size for the current block.
> 2. Assign a transaction priority to each transaction in the pool.
> 3. Select transactions to include in the current block using probability in transaction priority order until the target block size is met.
> 5. Solve block.
> 6. Broadcast the next target block size with the current block when it is solved.
> 7. Block is received.
> 8. Block verification process.
> 9. Accept/reject block based on verification result.
> 10. Repeat.
>
> ## Closing comments:
> It may be possible to verify blocks conform to the proposal by showing that the probability for all transactions included in the block statistically conforms to a probability distribution curve, *if* the individual transaction priority can be recreated. I am not that deep into the mathematics; however, it may also be possible to use a similar method to do this just based on the fee, that statistically, the blocks conform to a fee distribution. Any zero fee transactions would have to be ignored. This solution needs a clever mathematician.
>
> I implore, at the very least, that we use some method that validates full transaction reliability and enables scalability of block sizes. If not this proposal, an alternative.
>
> Regards,
> Damian Williamson
>
>
>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171219/9ab11dee/attachment-0001.html>

From willtech at live.com.au  Tue Dec 19 07:51:39 2017
From: willtech at live.com.au (Damian Williamson)
Date: Tue, 19 Dec 2017 07:51:39 +0000
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction
 Priority For Ordering Transactions In Blocks
In-Reply-To: <AB6BF756-29F1-4442-85A9-B81228E829EC@friedenbach.org>
References: <PS2P216MB01794ABD544248B27BF0DFD99D330@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<PS2P216MB01795BFC05612E021CCEDD7C9D0B0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<5upGmF0IhXUWhcikhdV-e9Pqg-kXfUuXe0kOpGxumie_TO2jLvCgTZ5c6vgBRtaqkL6DmOJb1YftK0osufB5RkhW7YhAhhCI0zBTH3YcORY=@protonmail.com>
	<PS2P216MB0179544A6503C2992190CEB69D0B0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<PS2P216MB0179D6A5965D0CFFEFB2880A9D090@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>,
	<AB6BF756-29F1-4442-85A9-B81228E829EC@friedenbach.org>
Message-ID: <PS2P216MB017991D78147E2B1EC14C3059D0F0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>

Thank you for your constructive feedback. I now see that the proposal introduces a potential issue.


>Finally in terms of the broad goal, having block size based on the number of transactions is NOT something desirable in the first place, even if it did work. That?s effectively the same as an infinite block size since anyone anywhere can create transactions in the mempool at no cost.


Do you have any critical suggestion as to how transaction bandwidth limit could be addressed, it will eventually become an issue if nothing is changed regardless of how high fees go?


Regards,

Damian Williamson



________________________________
From: Mark Friedenbach <mark at friedenbach.org>
Sent: Tuesday, 19 December 2017 3:08 AM
To: Damian Williamson
Subject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks

Damian, you seem to be misunderstanding that either

(1) the strong form of your proposal requires validating the commitment to the mempool properties, in which case the mempool becomes consensus critical (an impossible requirement); or

(2) in the weak form where the current block is dependent on the commitment in the last block only it is becomes a miner-selected field they can freely parameterize with no repercussions for setting values totally independent of the actual mempool.

If you want to make the block size dependent on the properties of the mempool in a consensus critical way, flex cap achieves this. If you want to make the contents or properties of the mempool known to well-connected nodes, weak blocks achieves that. But you can?t stick the mempool in consensus because it fundamentally is not something the nodes have consensus over. That?s a chicken-and-the-egg assumption.

Finally in terms of the broad goal, having block size based on the number of transactions is NOT something desirable in the first place, even if it did work. That?s effectively the same as an infinite block size since anyone anywhere can create transactions in the mempool at no cost.

On Dec 16, 2017, at 8:14 PM, Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:

I do not know why people make the leap that the proposal requires a consensus on the transaction pool. It does not.

It may be helpful to have the discussion from the previous thread linked here.
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/015370.html

Where I speak of validating that a block conforms to the broadcast next block size, I do not propose validating the number broadcast for the next block size itself, only that the next generated block is that size.

Regards,
Damian Williamson


________________________________
From: Damian Williamson <willtech at live.com.au<mailto:willtech at live.com.au>>
Sent: Saturday, 16 December 2017 7:59 AM
To: Rhavar
Cc: Bitcoin Protocol Discussion
Subject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks

There are really two separate problems to solve.


  1.  How does Bitcoin scale with fixed block size?
  2.  How do we ensure that all valid transactions are eventually included in the blockchain?

Those are the two issues that the proposal attempts to address. It makes sense to resolve these two problems together. Using the proposed system for variable block sizes would solve the first problem but there would still be a whole bunch of never confirming transactions. I am not sure how to reliably solve the second problem at scale without first solving the first.

>* Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.

I do not suggest a consensus. Depending on which node solves a block the value for next block size will be different. The consensus would be that blocks will adhere to the next block size value transmitted with the current block. It is easy to verify that the consensus is being adhered to once in place.

>* Increasing the entropy in a block to make it more unpredictable doesn't really make sense.

Not a necessary function, just an effect of using a probability-based distribution.

>* Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by "priority".  What are you going to do if a "malicious" miner decides to go after their profits and order by what makes them the most money. Add "ordered by priority" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.

I entirely agree with your sentiment that Bitcoin must be incentive compatible. It is necessary.

It is in only miners immediate interest to make the most profitable block from the available transaction pool. As with so many other things, it is necessary to partially ignore short-term gain for long-term benefit. It is in miners and everybody's long-term interest to have a reliable transaction service. A busy transaction service that confirms lots of transactions per hour will become more profitable as demand increases and more users are prepared to pay for priority. As it is there is currently no way to fully scale because of the transaction bandwidth limit and that is problematic. If all valid transactions must eventually confirm then there must be a way to resolve that problem.

Bitcoin deliberately removes traditional scale by ensuring blocks take ten minutes on average to solve, an ingenious idea and, incentive compatible but, fixed block sizes leaves us with a problem to solve when we want to scale.

>If you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.

I am confident that the math to verify blocks based on the proposal can be developed (and I think it will not be too complex for a mathematician with the relevant experience), however, I am nowhere near experienced enough with probability and statistical analysis to do it. Yes, if Bitcoin doesn't then it might make another great opportunity for an altcoin but I am not even nearly interested in promoting any altcoins.

If not the proposal that I have put forward, then, hopefully, someone can come up with a better solution. The important thing is that the issues are resolved.

Regards,
Damian Williamson


________________________________
From: Rhavar <rhavar at protonmail.com<mailto:rhavar at protonmail.com>>
Sent: Saturday, 16 December 2017 3:38 AM
To: Damian Williamson
Cc: Bitcoin Protocol Discussion
Subject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks

> I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?

Unfortunately your proposal is really fundamentally broken, on a few levels. I think you might need to do a bit more research into how bitcoin works before coming up with such improvements =)

But just some quick notes:

* Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.

* Increasing the entropy in a block to make it more unpredictable doesn't really make sense.

* Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by "priority".  What are you going to do if a "malicious" miner decides to go after their profits and order by what makes them the most money. Add "ordered by priority" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.

If you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.




-Ryan


-------- Original Message --------
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks
Local Time: December 15, 2017 3:42 AM
UTC Time: December 15, 2017 9:42 AM
From: bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>
To: Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>>



I should not take it that the lack of critical feedback to this revised proposal is a glowing endorsement. I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?

I suppose that it if is difficult to determine how long a transaction has been waiting in the pool then, each node could simply keep track of when a transaction was first seen. This may have implications for a verify routine, however, for example, if a node was offline, how should it differentiate how long each transaction was waiting in that case? If a node was restarted daily would it always think that all transactions had been waiting in the pool less than one day If each node keeps the current transaction pool in a file and updates it, as transactions are included in blocks and, as new transactions appear in the pool, then that would go some way to alleviate the issue, apart from entirely new nodes. There should be no reason the contents of a transaction pool files cannot be shared without agreement as to the transaction pool between nodes, just as nodes transmit new transactions freely.

It has been questioned why miners could not cheat. For the question of how many transactions to include in a block, I say it is a standoff and miners will conform to the proposal, not wanting to leave transactions with valid fees standing, and, not wanting to shrink the transaction pool. In any case, if miners shrink the transaction pool then I am not immediately concerned since it provides a more efficient service. For the question of including transactions according to the proposal, I say if it is possible to keep track of how long transactions are waiting in the pool so that they can be included on a probability curve then it is possible to verify that blocks conform to the proposal, since the input is a probability, the output should conform to a probability curve.


If someone has the necessary skill, would anyone be willing to develop the math necessary for the proposal?

Regards,
Damian Williamson


________________________________

From: bitcoin-dev-bounces at lists.linuxfoundation.org<mailto:bitcoin-dev-bounces at lists.linuxfoundation.org> <bitcoin-dev-bounces at lists.linuxfoundation.org<mailto:bitcoin-dev-bounces at lists.linuxfoundation.org>> on behalf of Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>>
Sent: Friday, 8 December 2017 8:01 AM
To: bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks


Good afternoon,

The need for this proposal:

We all must learn to admit that transaction bandwidth is still lurking as a serious issue for the operation, reliability, safety, consumer acceptance, uptake and, for the value of Bitcoin.

I recently sent a payment which was not urgent so; I chose three-day target confirmation from the fee recommendation. That transaction has still not confirmed after now more than six days - even waiting twice as long seems quite reasonable to me. That transaction is a valid transaction; it is not rubbish, junk or, spam. Under the current model with transaction bandwidth limitation, the longer a transaction waits, the less likely it is ever to confirm due to rising transaction numbers and being pushed back by transactions with rising fees.

I argue that no transactions are rubbish or junk, only some zero fee transactions might be spam. Having an ever-increasing number of valid transactions that do not confirm as more new transactions with higher fees are created is the opposite of operating a robust, reliable transaction system.

Business cannot operate with a model where transactions may or may not confirm. Even a business choosing a modest fee has no guarantee that their valid transaction will not be shuffled down by new transactions to the realm of never confirming after it is created. Consumers also will not accept this model as Bitcoin expands. If Bitcoin cannot be a reliable payment system for confirmed transactions then consumers, by and large, will simply not accept the model once they understand. Bitcoin will be a dirty payment system, and this will kill the value of Bitcoin.

Under the current system, a minority of transactions will eventually be the lucky few who have fees high enough to escape being pushed down the list.

Once there are more than x transactions (transaction bandwidth limit) every ten minutes, only those choosing twenty-minute confirmation (2 blocks) will have initially at most a fifty percent chance of ever having their payment confirm. Presently, not even using fee recommendations can ensure a sufficiently high fee is paid to ensure transaction confirmation.

I also argue that the current auction model for limited transaction bandwidth is wrong, is not suitable for a reliable transaction system and, is wrong for Bitcoin. All transactions must confirm in due time. Currently, Bitcoin is not a safe way to send payments.

I do not believe that consumers and business are against paying fees, even high fees. What is required is operational reliability.

This great issue needs to be resolved for the safety and reliability of Bitcoin. The time to resolve issues in commerce is before they become great big issues. The time to resolve this issue is now. We must have the foresight to identify and resolve problems before they trip us over.  Simply doubling block sizes every so often is reactionary and is not a reliable permanent solution. I have written a BIP proposal for a technical solution but, need your help to write it up to an acceptable standard to be a full BIP.

I have formatted the following with markdown which is human readable so, I hope nobody minds. I have done as much with this proposal as I feel that I am able so far but continue to take your feedback.

# BIP Proposal: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks

## The problem:
Everybody wants value. Miners want to maximize revenue from fees (and we presume, to minimize block size). Consumers need transaction reliability and, (we presume) want low fees.

The current transaction bandwidth limit is a limiting factor for both. As the operational safety of transactions is limited, so is consumer confidence as they realize the issue and, accordingly, uptake is limited. Fees are artificially inflated due to bandwidth limitations while failing to provide a full confirmation service for all transactions.

Current fee recommendations provide no satisfaction for transaction reliability and, as Bitcoin scales, this will worsen.

Bitcoin must be a fully scalable and reliable service, providing full transaction confirmation for every valid transaction.

The possibility to send a transaction with a fee lower than one that is acceptable to allow eventual transaction confirmation should be removed from the protocol and also from the user interface.

## Solution summary:
Provide each transaction with an individual transaction priority each time before choosing transactions to include in the current block, the priority being a function of the fee paid (on a curve), and the time waiting in the transaction pool (also on a curve) out to n days (n=60 ?). The transaction priority to serve as the likelihood of a transaction being included in the current block, and for determining the order in which transactions are tried to see if they will be included.

Use a target block size. Determine the target block size using; current transaction pool size x ( 1 / (144 x n days ) ) = number of transactions to be included in the current block. Broadcast the next target block size with the current block when it is solved so that nodes know the next target block size for the block that they are building on.

The curves used for the priority of transactions would have to be appropriate. Perhaps a mathematician with experience in probability can develop the right formulae. My thinking is a steep curve. I suppose that the probability of all transactions should probably account for a sufficient number of inclusions that the target block size is met although, it may not always be. As a suggestion, consider including some zero fee transactions to pad, highest BTC value first?

**Explanation of the operation of priority:**
> If transaction priority is, for example, a number between one (low) and one-hundred (high) it can be directly understood as the percentage chance in one-hundred of a transaction being included in the block. Using probability or likelihood infers that there is some function of random. If random (100) < transaction priority then the transaction is included.

>To break it down further, if both the fee on a curve value and the time waiting on a curve value are each a number between one and one-hundred, a rudimentary method may be to simply multiply those two numbers, to find the priority number. For example, a middle fee transaction waiting thirty days (if n = 60 days) may have a value of five for each part  (yes, just five, the values are on a curve). When multiplied that will give a priority value of twenty-five, or,  a twenty-five percent chance at that moment of being included in the block; it will likely be included in one of the next four blocks, getting more likely each chance. If it is still not included then the value of time waiting will be higher, making for more probability. A very low fee transaction would have a value for the fee of one. It would not be until near sixty-days that the particular low fee transaction has a high likelihood of being included in the block.

I am not concerned with low (or high) transaction fees, the primary reason for addressing the issue is to ensure transactional reliability and scalability while having each transaction confirm in due time.

## Pros:
* Maximizes transaction reliability.
* Fully scalable.
* Maximizes possibility for consumer and business uptake.
* Maximizes total fees paid per block without reducing reliability; because of reliability, in time confidence and overall uptake are greater; therefore, more transactions.
* Market determines fee paid for transaction priority.
* Fee recommendations work all the way out to 30 days or greater.
* Provides additional block entropy; greater security since there is less probability of predicting the next block.

## Cons:
* Could initially lower total transaction fees per block.
* Must be first be programmed.

## Solution operation:
This is a simplistic view of the operation. The actual operation will need to be determined in a spec for the programmer.

1. Determine the target block size for the current block.
2. Assign a transaction priority to each transaction in the pool.
3. Select transactions to include in the current block using probability in transaction priority order until the target block size is met.
5. Solve block.
6. Broadcast the next target block size with the current block when it is solved.
7. Block is received.
8. Block verification process.
9. Accept/reject block based on verification result.
10. Repeat.

## Closing comments:
It may be possible to verify blocks conform to the proposal by showing that the probability for all transactions included in the block statistically conforms to a probability distribution curve, *if* the individual transaction priority can be recreated. I am not that deep into the mathematics; however, it may also be possible to use a similar method to do this just based on the fee, that statistically, the blocks conform to a fee distribution. Any zero fee transactions would have to be ignored. This solution needs a clever mathematician.

I implore, at the very least, that we use some method that validates full transaction reliability and enables scalability of block sizes. If not this proposal, an alternative.

Regards,
Damian Williamson


_______________________________________________
bitcoin-dev mailing list
bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>
https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171219/f24be6fb/attachment-0001.html>

From willtech at live.com.au  Tue Dec 19 09:05:34 2017
From: willtech at live.com.au (Damian Williamson)
Date: Tue, 19 Dec 2017 09:05:34 +0000
Subject: [bitcoin-dev] A DNS-like decentralized mapping for wallet addresses?
In-Reply-To: <1085B203-DB5E-42AB-A9F3-467D09246314@sprovoost.nl>
References: <CAHneDF3qH9OUxqLthY6hEzzFr21QJFLV5wOP8jw+p5eOtpb2oQ@mail.gmail.com>
	<c889543b-8dbe-b88c-5f47-7aee1db697aa@vt.edu>,
	<1085B203-DB5E-42AB-A9F3-467D09246314@sprovoost.nl>
Message-ID: <PS2P216MB01790A2EC251507D2739360E9D0F0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>

There is no reason it should not be easily possible to develop a Bitcoin wallet that has an integrated name to address mapping feature. It might be a good idea for a software product, it could even be based on Bitcoin Core. There is no specific reason that people wanting that sort of feature could not use it. In fact, you could map names, strings, email addresses, it could be very flexible.


Relying on an additional service like DNS which is flexible enough to handle the job, does introduce an additional availability risk. There is no additional privacy risk provided each mapped name or address is only used once to send/receive one payment unless you directly use something personally identifiable like an email address which could be used to map bitcoin addresses to an individual. Personally, I am not concerned about privacy so much but can understand that some highly value their privacy.


If you get it right it will be a service better than namecoin transacting in Bitcoin. If you think that is valuable, go for it.


Regards,

Damian Williamson


________________________________
From: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Sjors Provoost via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>
Sent: Monday, 18 December 2017 10:26 PM
To: Douglas Roark; Bitcoin Protocol Discussion
Subject: Re: [bitcoin-dev] A DNS-like decentralized mapping for wallet addresses?

Have you thought about combining this with BIP-47? You could associate payment codes with email via DNS.

It would be nice if there was a way to get rid of the announcement transaction in BIP-47 and establish a shared secret out of bound. That would simplify things, at the cost of an additional burden of storing more than an HD seed to recover a wallet that received funds this way.

Perhaps the sender can email to the recipient the information they need to retrieve the funds. The (first) transaction could have a time locked refund in it, in case the payment code is stale.

Sjors

> Op 1 dec. 2017, om 04:08 heeft Douglas Roark via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> het volgende geschreven:
>
> On 2017/11/30 14:20, mandar mulherkar via bitcoin-dev wrote:
>> I was wondering in terms of mass adoption, instead of long wallet
>> addresses, maybe there should be a DNS-like decentralized mapping
>> service to provide a user at crypto address?
>
> A few years ago, I was part of an effort with Armory and Verisign to
> make something similar to what you're describing.
> https://tools.ietf.org/html/draft-wiley-paymentassoc-00 is where you can
> find the one and only official draft. I worked on a follow-up with some
> changes and some nice appendices, explaining some nice tricks one could
> use to make payment management flexible. For various reasons, it never
> got published. I think it's an interesting draft that could be turned
> into something useful. Among other things, it was able to leverage BIP32
> and allow payment requests to be generated that automatically pointed
> payees to the correct branch. DNSSEC may have some issues but, AFAIK,
> it's as the easiest way to bootstrap identity to a common, reasonably
> secure standard.
>
> --
> ---
> Douglas Roark
> Cryptocurrency, network security, travel, and art.
> https://onename.com/droark
> joroark at vt.edu
> PGP key ID: 26623924
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171219/60b0253d/attachment.html>

From hampus.sjoberg at gmail.com  Tue Dec 19 13:11:24 2017
From: hampus.sjoberg at gmail.com (=?UTF-8?Q?Hampus_Sj=C3=B6berg?=)
Date: Tue, 19 Dec 2017 14:11:24 +0100
Subject: [bitcoin-dev] A DNS-like decentralized mapping for wallet
	addresses?
In-Reply-To: <PS2P216MB01790A2EC251507D2739360E9D0F0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
References: <CAHneDF3qH9OUxqLthY6hEzzFr21QJFLV5wOP8jw+p5eOtpb2oQ@mail.gmail.com>
	<c889543b-8dbe-b88c-5f47-7aee1db697aa@vt.edu>
	<1085B203-DB5E-42AB-A9F3-467D09246314@sprovoost.nl>
	<PS2P216MB01790A2EC251507D2739360E9D0F0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CAFMkqK_e6PtDpHUq6HS+ActW2QFvF=_t7wOO0CDCcbO=KS3beg@mail.gmail.com>

Most solutions only work with a single Bitcoin address (terrible for
privacy, and also potentially a security risk) or xpubkey (also terrible
for privacy).

I think the best solution here is some kind of store-and-forward server,
where you trade a little bit of privacy (to the server, that is), but get
the convenience of using (for example) an email address as the account.
I like for example BIP75 for this, and I hope the community can work
towards a solution like this. This could potentially work good with LN as
well. https://github.com/bitcoin/bips/blob/master/bip-0075.mediawiki

Hampus

2017-12-19 10:05 GMT+01:00 Damian Williamson via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org>:

> There is no reason it should not be easily possible to develop a Bitcoin
> wallet that has an integrated name to address mapping feature. It might be
> a good idea for a software product, it could even be based on Bitcoin Core.
> There is no specific reason that people wanting that sort of feature could
> not use it. In fact, you could map names, strings, email addresses, it
> could be very flexible.
>
>
> Relying on an additional service like DNS which is flexible enough to
> handle the job, does introduce an additional availability risk. There is no
> additional privacy risk provided each mapped name or address is only used
> once to send/receive one payment unless you directly use something
> personally identifiable like an email address which could be used to map
> bitcoin addresses to an individual. Personally, I am not concerned about
> privacy so much but can understand that some highly value their privacy.
>
>
> If you get it right it will be a service better than namecoin transacting
> in Bitcoin. If you think that is valuable, go for it.
>
>
> Regards,
>
> Damian Williamson
>
>
> ------------------------------
> *From:* bitcoin-dev-bounces at lists.linuxfoundation.org <
> bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Sjors
> Provoost via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>
> *Sent:* Monday, 18 December 2017 10:26 PM
> *To:* Douglas Roark; Bitcoin Protocol Discussion
> *Subject:* Re: [bitcoin-dev] A DNS-like decentralized mapping for wallet
> addresses?
>
> Have you thought about combining this with BIP-47? You could associate
> payment codes with email via DNS.
>
> It would be nice if there was a way to get rid of the announcement
> transaction in BIP-47 and establish a shared secret out of bound. That
> would simplify things, at the cost of an additional burden of storing more
> than an HD seed to recover a wallet that received funds this way.
>
> Perhaps the sender can email to the recipient the information they need to
> retrieve the funds. The (first) transaction could have a time locked refund
> in it, in case the payment code is stale.
>
> Sjors
>
> > Op 1 dec. 2017, om 04:08 heeft Douglas Roark via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> het volgende geschreven:
> >
> > On 2017/11/30 14:20, mandar mulherkar via bitcoin-dev wrote:
> >> I was wondering in terms of mass adoption, instead of long wallet
> >> addresses, maybe there should be a DNS-like decentralized mapping
> >> service to provide a user at crypto address?
> >
> > A few years ago, I was part of an effort with Armory and Verisign to
> > make something similar to what you're describing.
> > https://tools.ietf.org/html/draft-wiley-paymentassoc-00 is where you can
> > find the one and only official draft. I worked on a follow-up with some
> > changes and some nice appendices, explaining some nice tricks one could
> > use to make payment management flexible. For various reasons, it never
> > got published. I think it's an interesting draft that could be turned
> > into something useful. Among other things, it was able to leverage BIP32
> > and allow payment requests to be generated that automatically pointed
> > payees to the correct branch. DNSSEC may have some issues but, AFAIK,
> > it's as the easiest way to bootstrap identity to a common, reasonably
> > secure standard.
> >
> > --
> > ---
> > Douglas Roark
> > Cryptocurrency, network security, travel, and art.
> > https://onename.com/droark
> > joroark at vt.edu
> > PGP key ID: 26623924
> >
> > _______________________________________________
> > bitcoin-dev mailing list
> > bitcoin-dev at lists.linuxfoundation.org
> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171219/cbaee39b/attachment-0001.html>

From mail at albertodeluigi.com  Tue Dec 19 13:45:09 2017
From: mail at albertodeluigi.com (Alberto De Luigi)
Date: Tue, 19 Dec 2017 14:45:09 +0100
Subject: [bitcoin-dev] Clarification about SegWit transaction size and bech32
Message-ID: <001701d378cf$961e5510$c25aff30$@albertodeluigi.com>

Thank you Gregory,
so SegWit P2PHK have strictly less weight than P2WPKH, 3 fewer bytes (-1%) no matter the n. of outputs.
Instead, Segwit P2WPKH/P2SH cost 11% more than P2PHK, while compared to P2SH, SegWit transaction P2WSH and P2WSH/P2SH cost respectively 6% and 19% more space. And it can be much more if outputs are, as you say, an absurd number, which is the case of tx made by an exchange.

I understand there is a rationale for the overhead size. It's transparent from here: https://bitcoincore.org/en/2016/01/26/segwit-benefits
I don't understand your two points, which are new to me, maybe I lack of some technical details?
1) outputs were previously undercosted
2) a great many TXOUTs are putting a serious long term cost on the network

But independently from that, my point is: does an exchange have economic incentives in adopting SegWit? I think the answer is no.
Does SegWit help making bitcoin more scalable? Not until Lightning Network, since transactions just take up more space. 

Instead, if bech32 really makes possible to save up to 22% of space (I still need confirmation), it would help a lot in scaling bitcoin. We just need to coordinate the network to bring it on most of the wallets. Since using bech32 everybody will benefit and pay smaller fees there are economic incentives in implementing it. For this reason I think an agreement about a transition to bech32 as default address for every wallet is a highly realistic scenario, while widespread SegWit adoption without bech32 is not, in my opinion, because poor or negative economic incentives (including also the costs companies sustain for development).

I know an agreement is a political matter, should it be discussed elsewhere?
I think a network upgrade to bech32 addresses requires the same coordination of a hard fork, but.. just a hint: bech32 helps saving space, in the meanwhile we reach widespread segwit adoption. If transition is achieved, we would have blocks of 2mb fulfilled with transactions using bech32, which have a 20% discount. Compared to the current situation of 1.05mb average blocks and 400k tx daily, we could have about 2mb blocks and 960k tx daily...

Thank you,
Alberto De Luigi
(.com)



-----Original Message-----
From: Gregory Maxwell [mailto:gmaxwell at gmail.com]
Sent: marted? 19 dicembre 2017 09:06
To: mail at albertodeluigi.com; Bitcoin Protocol Discussion
<bitcoin-dev at lists.linuxfoundation.org>
Cc: Mark Friedenbach <mark at friedenbach.org>
Subject: Re: [bitcoin-dev] Clarification about SegWit transaction size and
bech32

Alberto,

You are confused about the impact.  Ordinary P2WPKH have strictly less
weight no matter how many outputs you have.  P2WSH in very output heavy
transactions can be more, but this is inherent in the upgrade from
inadequate 80-bit security to 128-bit security, an intentional
change: because outputs were previously _radically_ undercosted in the
system and any party making a great many new TXOUTs are putting a serious
long term cost on the network,  and in any case it's except for transactions
that make an absurd number of P2WSH outputs at once the difference is pretty
small.

On Mon, Dec 18, 2017 at 10:19 PM, Alberto De Luigi via bitcoin-dev
<bitcoin-dev at lists.linuxfoundation.org> wrote:
> Mark,
> suppose I am an average user. Give me a bech32 address and ask me to
> send a few coins there. I am 100% sure you will never receive my
> coins. I will call you back saying: "Mark, sorry, I tried with three
> different wallets, but it seems what you gave me is not a bitcoin
> address!"
>
> My point is: we want SegWit is used and implemented more and more by
> the community. But if besides malleability fix, the main effect of sw
> adoption is this:
>
> 1) The blockahin is heavier (transactions require more space)
> 2) the fee is smaller only for some kind of tx
> 3) the transactions of the exchanges, which aggregate outputs, would
> be heavier and pay a higher fee using segwit!
>
> then how can we expect people, exchanges and services to adopt segwit?
>
> Thank you,
> Alberto De Luigi
>
>
>
>
> Il 2017-12-18 23:03 Mark Friedenbach ha scritto:
>>
>> Why would I send you coins to anything other than the address you
>> provided to me? If you send me a bech32 address I use the native
>> segwit scripts. If you send me an old address, I do what it specifies
>> instead. The recipient has control over what type of script the
>> payment is sent to, without any ambiguity.
>>
>>> On Dec 18, 2017, at 1:41 PM, mail at albertodeluigi.com wrote:
>>>
>>> Hi Mark,
>>> thank you. I understand your point, but despite what we define as a
>>> fork, when a software uses a particular address, it becomes part of
>>> the rules of that software. If another software doesn't recognize
>>> that address as a bitcoin address, then the rules it enforces aren't
>>> compatible with the behaviour of the first software. If you send me
>>> your bitcoins, I can't receive it, exactly like if it was in another
>>> chain. This happens even if there isn't such a situation where
>>> miners verify that transaction on a chain, while other miners reject it.
>>>
>>> If we want to change the addresses, we need consensus and the
>>> coordinate upgrade of the entire network. In case we haven't
>>> consensus, most of the clients cannot send and receive bitcoins, which
>>> is a huge problem.
>>> For this reason I think it is something we should discuss in order
>>> to make a coordinated upgrade, exactly like what we do when we propose a
>>> fork.
>>> And it would be better to do it precisely as a part of a fork, like
>>> a 2x (or whatever other upgrade gaining enough consensus)
>>>
>>> Apart from the proposal of an upgrade to bench32, do you agree with
>>> the rest of my points? I know segwit is valuable because it fixes tx
>>> malleability and so on... thank you for your link, but that wasn't
>>> the point I wanted to highlight!
>>>
>>> Thank you,
>>> Alberto
>>>
>>>
>>>
>>>
>>> Il 2017-12-18 18:38 Mark Friedenbach ha scritto:
>>>>
>>>> Addresses are entirely a user-interface issue. They don?t factor
>>>> into the bitcoin protocol at all.
>>>> The bitcoin protocol doesn?t have addresses. It has a generic
>>>> programmable signature framework called script. Addresses are
>>>> merely a UI convention for representing common script templates.
>>>> 1.. addresses and 3? addresses have script templates that are not
>>>> as optimal as could be constructed with post-segwit assumptions.
>>>> The newer bech32 address just uses a different underlying template
>>>> that achieves better security guarantees (for pay-to-script) or
>>>> lower fees (for pay-to-pubkey-hash). But this is really a UI/UX issue.
>>>> A ?fork? in bitcoin-like consensus systems has a very specific
>>>> meaning. Changing address formats is not a fork, soft or hard.
>>>> There are many benefits to segregated witness. You may find this
>>>> page
>>>> helpful:
>>>> https://bitcoincore.org/en/2016/01/26/segwit-benefits/ [4]
>>>>>
>>>>> On Dec 18, 2017, at 8:40 AM, Alberto De Luigi via bitcoin-dev
>>>>> <bitcoin-dev at lists.linuxfoundation.org> wrote:
>>>>> Hello guys,
>>>>> I have a few questions about the SegWit tx size, I'd like to have
>>>>> confirmation about the following statements. Can you correct
>>>>> mistakes or inaccuracies? Thank you in advance.
>>>>> In general, SegWit tx costs more than legacy tx (source
>>>>> https://bitcoincore.org/en/2016/10/28/segwit-costs/ [1]):
>>>>> * Compared to P2PKH, P2WPKH uses 3 fewer bytes (-1%) in the
>>>>> scriptPubKey, and the same number of witness bytes as P2PKH
>>>>> scriptSig.
>>>>> * Compared to P2SH, P2WSH uses 11 additional bytes (6%) in the
>>>>> scriptPubKey, and the same number of witness bytes as P2SH
>>>>> scriptSig.
>>>>> * Compared to P2PKH, P2WPKH/P2SH uses 21 additional bytes (11%),
>>>>> due to using 24 bytes in scriptPubKey, 3 fewer bytes in scriptSig
>>>>> than in P2PKH scriptPubKey, and the same number of witness bytes
>>>>> as P2PKH scriptSig.
>>>>> * Compared to P2SH, P2WSH/P2SH uses 35 additional bytes (19%), due
>>>>> to using 24 bytes in scriptPubKey, 11 additional bytes in
>>>>> scriptSig compared to P2SH scriptPubKey, and the same number of
>>>>> witness bytes as P2SH scriptSig.
>>>>> But still it is convenient to adopt segwit because you move the
>>>>> bytes to the blockweight part, paying smaller fee. In general, a
>>>>> tx with 1 input and 1 output is about 190kb. If it's a Segwit tx,
>>>>> 82kb in the non-witness part (blocksize), 108 in the witness part
>>>>> (blockweight).
>>>>> See source:
>>>>> 4 bytes version
>>>>> 1 byte input count
>>>>> Input
>>>>> 36 bytes outpoint
>>>>> 1 byte scriptSigLen (0x00)
>>>>> 0 bytes scriptSig
>>>>> 4 bytes sequence
>>>>> 1 byte output count
>>>>> 8 bytes value
>>>>> 1 byte scriptPubKeyLen
>>>>> 22 bytes scriptPubKey (0x0014{20-byte keyhash})
>>>>> 4 bytes locktime
>>>>
>>>>
>>>> https://bitcoin.stackexchange.com/questions/59408/with-100-segwit-t
>>>> ransactions-what-would-be-the-max-number-of-transaction-confi
>>>>>
>>>>> [2]
>>>>> Which means, if you fill a block entirely with this kind of tx,
>>>>> you can approximately double the capacity of the blockchain
>>>>> (blocksize capped to 1mb, blockweight a little bit more than 2mb)
>>>>> My concern is about segwit adoption by the exchanges.
>>>>> SegWit transactions cost 10bytes more than legacy transactions for
>>>>> each output (vout is 256 bits instead of 160). Exchanges aggregate
>>>>> tx adding many outputs, which is of course something good for
>>>>> bitcoin scalability, since this way we save space and pay less fees.
>>>>> But when a tx has at least 10 outputs, using segwit you don't save
>>>>> space, instead:
>>>>> - the total blockweight is at least 100bytes higher (10bytes x 10
>>>>> outputs), so the blockchain is heavier
>>>>> - you don't save space inside the blocksize, so you cannot
>>>>> validate more transactions of this kind (with many outputs), nor
>>>>> get cheaper fee
>>>>> - without cheaper fees exchanges have no incentives for segwit
>>>>> adoption before they decide to adopt LN In general we can say that
>>>>> using SegWit:
>>>>> - you decrease the fee only for some specific kind of
>>>>> transactions, and just because you move some bytes to the
>>>>> blockweight
>>>>> - you don?t save space in the blockchain, on the contrary the
>>>>> total weight of the blockchain increases (so it's clear to me why
>>>>> some time ago Luke tweeted to not use SegWit unless really
>>>>> necessary... but then it's not clear why so much haste in
>>>>> promoting
>>>>> BIP148 the 1st august risking a split) If it's all correct, does
>>>>> something change with bech32? I'm reading
>>>>> bech32 allows to save about 22% of the space. Is this true for
>>>>> whatever kind of tx? Immediate benefits of segwit for scalability
>>>>> are only with bech32?
>>>>> Bech32 is non-compatible with the entire ecosystem (you cannot
>>>>> receive coins from the quasi-totality of wallets in circulation),
>>>>> I would say it is a hard fork. But the bare segwit is really so
>>>>> different? the soft fork is "soft" for the reference client
>>>>> Bitcoin Core, but outside you cannot know what happens, there are
>>>>> plenty of implementations (especially frontend customization)
>>>>> which don?t work with segwit and need to upgrade. To upgrade takes
>>>>> a lot of time, especially when services are so crowded and so many
>>>>> new people want to step in. At this point, if bech32 brings only
>>>>> efficiency (but correct me if it?s not so) and it is well planned,
>>>>> it could be a consensual upgrade, maybe together with a 2x
>>>>> blocksize? Is there a specific plan for some upgrade in 2018? I
>>>>> personally think it is far easier to reach consensus on a
>>>>> blocksize increase una tantum rather than a dynamic increase. You
>>>>> cannot predict the technology growth: will it be linear,
>>>>> exponential, or suddenly stop for a while, maybe right before a
>>>>> huge innovation? I think a hard fork bech32 upgrade + 2x could
>>>>> help a lot in scalability while we test LN, and it might be the
>>>>> only way to effectively promote (or should I say enforce?) SegWit
>>>>> adoption.
>>>>> thank you,
>>>>> Alberto De Luigi
>>>>> (.com)_______________________________________________
>>>>> bitcoin-dev mailing list
>>>>> bitcoin-dev at lists.linuxfoundation.org
>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev [3]
>>>>
>>>> Links:
>>>> ------
>>>> [1] https://bitcoincore.org/en/2016/10/28/segwit-costs/
>>>> [2]
>>>>
>>>> https://bitcoin.stackexchange.com/questions/59408/with-100-segwit-t
>>>> ransactions-what-would-be-the-max-number-of-transaction-confi
>>>> [3] https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>> [4] https://bitcoincore.org/en/2016/01/26/segwit-benefits/
>>>
>>>
>>>
>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev





From stick at satoshilabs.com  Tue Dec 19 21:36:45 2017
From: stick at satoshilabs.com (Pavol Rusnak)
Date: Tue, 19 Dec 2017 22:36:45 +0100
Subject: [bitcoin-dev] Sign / Verify message against SegWit P2SH
 addresses.
In-Reply-To: <CAAUFj10gEPBS3nTZ6aJn4UazhcJKPni6_pYGWwOs+QNeDo9NaA@mail.gmail.com>
References: <CAAUFj10gEPBS3nTZ6aJn4UazhcJKPni6_pYGWwOs+QNeDo9NaA@mail.gmail.com>
Message-ID: <52b65bab-ff84-7e21-e35a-f6ebd8106767@satoshilabs.com>

On 08/12/17 19:25, Dan Bryant via bitcoin-dev wrote:
> I know there are posts, and an issue opened against it, but is there
> anyone writing a BIP for Sign / Verify message against a SegWit address?

Dan, are you still planning to write this BIP?

-- 
Best Regards / S pozdravom,

Pavol "stick" Rusnak
CTO, SatoshiLabs

From mark at friedenbach.org  Tue Dec 19 21:58:40 2017
From: mark at friedenbach.org (Mark Friedenbach)
Date: Tue, 19 Dec 2017 13:58:40 -0800
Subject: [bitcoin-dev] Sign / Verify message against SegWit P2SH
 addresses.
In-Reply-To: <52b65bab-ff84-7e21-e35a-f6ebd8106767@satoshilabs.com>
References: <CAAUFj10gEPBS3nTZ6aJn4UazhcJKPni6_pYGWwOs+QNeDo9NaA@mail.gmail.com>
	<52b65bab-ff84-7e21-e35a-f6ebd8106767@satoshilabs.com>
Message-ID: <725C679B-60E2-4E21-9F7D-10F67118D58D@friedenbach.org>

For what it?s worth, I think it would be quite easy to do better than the implied solution of rejiggering the message signing system to support non-P2PKH scripts. Instead, have the signature be an actual bitcoin transaction with inputs that have the script being signed. Use the salted hash of the message being signed as the FORKID as if this were a spin-off with replay protection. This accomplishes three things:

(1) This enables signing by any infrastructure out there ? including hardware wallets and 2FA signing services ? that have enabled support for FORKID signing, which is a wide swath of the ecosystem because of Bitcoin Cash and Bitcoin Gold.

(2) It generalizes the message signing to allow multi-party signing setups as complicated (via sighash, etc.) as those bitcoin transactions allow, using existing and future tools based on Partially Signed Bitcoin Transactions; and

(3) It unifies a single approach for message signing, proof of reserve (where the inputs are actual UTXOs), and off-chain colored coins.

There?s the issue of size efficiency, but for the single-party message signing application that can be handled by a BIP that specifies a template for constructing the pseudo-transaction and its inputs from a raw script.

Mark

> On Dec 19, 2017, at 1:36 PM, Pavol Rusnak via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
> 
> On 08/12/17 19:25, Dan Bryant via bitcoin-dev wrote:
>> I know there are posts, and an issue opened against it, but is there
>> anyone writing a BIP for Sign / Verify message against a SegWit address?
> 
> Dan, are you still planning to write this BIP?
> 
> -- 
> Best Regards / S pozdravom,
> 
> Pavol "stick" Rusnak
> CTO, SatoshiLabs
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev


From nicolas.dorier at gmail.com  Wed Dec 20 06:28:07 2017
From: nicolas.dorier at gmail.com (Nicolas Dorier)
Date: Wed, 20 Dec 2017 15:28:07 +0900
Subject: [bitcoin-dev] BIP Proposal: Crypto Open Exchange Protocol (COX)
Message-ID: <CA+1nnr=-6UkJT=TWjDHhZtXsic8p0fzQ=Yk1tSqkhL+NuvqCQw@mail.gmail.com>

Hi everyone,

As some of you know, I am working on a complete open source replacement of
Bitpay for allowing merchant to accept cryptocurrency payments while having
a way to sell automatically.

A crucial, missing part, is fiat conversion. And I figured out a simple
protocol that exchanges (or adapters) can implement to allow any merchant
to cash out BTC in fiat while giving them the freedom to choose their own
payment processor solution.

This also have positive impact on scalability: Before, a merchant would
receive the bitcoin from the customer then would send to the exchange,
resulting in two transactions.
With this specification, it would be one transaction.

Special thanks to anditto and kallewoof for reviewing. I am waiting for
your feedback:

Github link:
https://github.com/NicolasDorier/bips/blob/master/bip-xxx.mediawiki

<pre>
  BIP: XXX
  Layer: Applications
  Title: Crypto Open Exchange Protocol (COX)
  Author: Nicolas Dorier <nicolas.dorier at gmail.com>
  Comments-Summary: No comments yet.
  Comments-URI: https://github.com/bitcoin/bips/wiki/Comments:BIP-XXX
  Status: Draft
  Type: Standards Track
  Created: 2017-12-20
  License: BSD-3-Clause
           CC0-1.0
</pre>

==Abstract==

A simple protocol for decoupling payment processor solutions from exchanges.

==Motivation==

Cryptocurrency merchant adoption is mainly driven by availability, ease of
use and means of acceptance.
We call such solutions `Payment Processors`.

Until now, payment processing solutions fall into one of the two following
categories:

# Self-hosted with the customer paying in cryptocurrency and the merchant
receiving it directly.
# Centralized, coupled with an exchange feature, with the customer paying
in cryptocurrency to the merchant, and receiving fiat or cryptocurrency on
his exchange account.

The self-hosted solution has two issues:

# The merchant becomes vulnerable to the wild volatility of
cryptocurrencies.
# It is wasteful of blockchain space, if the merchant does not pay
suppliers in crypto, as they need a second transaction to change to his
exchange,

The centralized solution has two issues:

# It locks-in the merchant to a particular payment processor whose
intentions might not be aligned (e.g. Bitpay who tried to redefine Bitcoin
as being a different chain, without merchant approval)
# It has to deal with local regulations (e.g. Bitpay does not provide fiat
CAD to canadian merchants)

The goal of this BIP is to specify a simple protocol which makes possible
decoupling of payment processors from exchanges.

We believe this BIP will gather a lot of interest among local exchanges
which do not have the resources to develop their own payment solutions.

Their customers can decide which payment processor solution they prefer,
while the exchanges give them a way to protect against cryptocurrency
volatility.

==Summary==

The merchant log in to its exchange website, go into "Address sources"
section of it, an click on "Create a new address source".

The address source creation wizard asks him questions about what to do when
crypto currency is sent to this the address source. (Cryptocurrency, Market
sell order, limit order of past day average etc...)

The merchant receives an "address source URI" which they can input inside
the payment processor.

An exchange compatible with the Crypto Open Exchange Protocol would reply
to any HTTP POST request to this  "address source URI" returning the
following information (more details in the Specification part)

# A deposit address for accepting a payment
# The current rate
# Optional: If the exchange is willing to take the risk of rate
fluctuation, until when this rate is guaranteed and under which conditions.

<img src="bip-xxx/overview.png"></img>

===Interaction===

* Manny (the "merchant") wants to accept Bitcoin payments on his e-commerce
website.
* Manny chooses the payment processor "PROCCO" which has a powerful plugin
for his e-commerce website.
* Manny is based in Canada and already has an account on the exchange
"MYCOIN" which supports the Crypto Open Exchange Protocol.
* Manny connects to the exchange website, and creates a new address source.
* In the configuration screen of the address source, for each payment sent
to this address source, Manny decides to keep 30% in Bitcoin and place a
market sell order for the remaining 70% of the amount.
* "MYCOIN" creates the address source, and gives the "address source URI"
to the merchant. (e.g. https://example.com/addresssources/abd29ddn92)
* Manny copies the address source URI and goes inside "PROCCO" settings,
and configures his store to use this address source URI.

Now a customer, Carol, wants to order a brand new phone for 0.01 BTC on
Manny's store and decides to pay in Bitcoin.

* The E-Commerce website plugin requests the creation of an invoice from
PROCCO.
* PROCCO queries the "address source URI" and retrieves the rate, the
expiration of this rate and conditions.
* PROCCO can now show the Bitcoin Payment Checkout page.
* Carla pays.
* PROCCO marks the payment as paid and redirects to the e-commerce website.
* MYCOIN, under its own policy (typically after 6 confirmations), credits
Manny's account of 0.01 BTC and simultaneously creates a market sell order
of 0.007 BTC on behalf of Manny.

==Specification==

The payment processor sends a POST request to the "address source URI", the
response from a Crypto Open Exchange Protocol exchange would be:

If the exchange does not guarantee the rate:

    {
        "depositAddress" : "13....abd",
        "currencyCode" : "CAD",
        "cryptoCurrencyCode" : "BTC",
        "rate" : "15600",
        # When the merchant account get credited on the exchange
        "requiredConfirmations" : blockcount
    }


If the exchange guarantee the rate:

    {
        "depositAddress" : "13....abd",
        "currencyCode" : "CAD",
        "cryptoCurrencyCode" : "BTC",
        "rate" : "15600",
        "requiredConfirmations" : blockcount
        "conditions" :
        {
            # When the transaction should be seen on the blockchain to
guarantee the rate
            "receivedBefore" : timestamp,
            # When the transaction should be confirmed on the blockchain to
guarantee the rate
            "confirmedBefore" : timestamp
        }
    }


The payment processor is responsible for giving feedback to the customer if
the fees of the received transaction are not enough to guarantee the rate.

==Note on adoption==

While local exchanges have incentives to implement this simple protocol, it
is not strictly needed.

An alternative is to develop an adapter server which expose Crypto Open
Exchange Protocol endpoint and connect to underlying exchange's API.

The only downside is that the rate can't be guaranteed.

==Copyright==

This document is dual licensed as BSD 3-clause, and Creative Commons CC0
1.0 Universal.


Nicolas,
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171220/d0b0422b/attachment-0001.html>

From dan at osc.co.cr  Wed Dec 20 06:50:42 2017
From: dan at osc.co.cr (Dan Libby)
Date: Wed, 20 Dec 2017 14:50:42 +0800
Subject: [bitcoin-dev] BIP Proposal: Crypto Open Exchange Protocol (COX)
In-Reply-To: <CA+1nnr=-6UkJT=TWjDHhZtXsic8p0fzQ=Yk1tSqkhL+NuvqCQw@mail.gmail.com>
References: <CA+1nnr=-6UkJT=TWjDHhZtXsic8p0fzQ=Yk1tSqkhL+NuvqCQw@mail.gmail.com>
Message-ID: <bbc5e5fc-7273-9799-2b41-e12c9c7d0030@osc.co.cr>

currencyCode and cryptoCurrencyCode seem to assume that merchants will
always want to sell for fiat.  But a merchant might want to sell for
another cryptocurrency instead.

Why not make it more generic, like buySymbol and sellSymbol?

>         "currencyCode" : "CAD",
>         "cryptoCurrencyCode" : "BTC",



From sjors at sprovoost.nl  Wed Dec 20 08:49:09 2017
From: sjors at sprovoost.nl (Sjors Provoost)
Date: Wed, 20 Dec 2017 09:49:09 +0100
Subject: [bitcoin-dev] BIP Proposal: Crypto Open Exchange Protocol (COX)
In-Reply-To: <CA+1nnr=-6UkJT=TWjDHhZtXsic8p0fzQ=Yk1tSqkhL+NuvqCQw@mail.gmail.com>
References: <CA+1nnr=-6UkJT=TWjDHhZtXsic8p0fzQ=Yk1tSqkhL+NuvqCQw@mail.gmail.com>
Message-ID: <A2014DA0-F6F8-470F-A167-E66723281269@sprovoost.nl>



I think this could be quite useful, although I don?t know if it will get adopted. If any such small local exchanges want to weigh in on this proposal, that would help. Same goes for shopping cart integrators, e.g. the folks writing WooCommerce and Shopify plugins.

Consider adding some requirements around the use of SSL and certificate pinning. Can you refer to the kind of best practices Stripe and PayPal recommend? Should some additional shared-secret or cookie / macaroon based authentication be added?

Can you clarify if this integration can run in a browser, or due to security / privacy constraints must be server-to-server?

Though it?s important to remain future-proof by being flexible, leaving the above details to individual implementers is probably going to result in bad things.

What are your thoughts on rate limiting vs. privacy? Should a payment source never return the same address even if nothing is paid to it? Otherwise someone could just crawl webshops to create an inventory of payment addresses. A new address every page reload could be a DDOS vector. It also wouldn't be compatible with BIP44 because of its gap limit, although I don?t think that?s a huge problem for exchanges.

Can this be combined with an invoice mechanism similar to Lightning, e.g. where the exchange sends a pre-image to the users wallet (relayed via and retained by the web shop) upon receipt of the funds, which they can then present to the merchant in case something went wrong. Exchanges might be happy to support this protocol, but they don?t want the burden of dealing with user support requests, so having signed invoices could help with that.

I would consider a more specific name like Delegated UTXO or something. ?Exchange? suggests is more like 0X or Bisq.

Speaking of Bisq, it would be neat if merchants can rely on random peer to peer counterparties to convert to fiat, so their customer information and revenue figures aren?t in the hands of a single counter party. Obviously that?s a can of worms today, but it would be nice if the protocol was able to support that if one day someone figures out the fraud, compliance and bookkeeping stuff.

Finally, why only exchanges? It could make sense fo shopping cart software to talk to a Bitcoin wallet that?s hosted somewhere else for similar reasons. Right now the best these plugins can do is hold on to an XPUB, and I?ve even seen solutions that just send the customers coins to their own backend wallet and then forward it.

Sjors

> Op 20 dec. 2017, om 07:28 heeft Nicolas Dorier via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> het volgende geschreven:
> 
> Hi everyone,
> 
> As some of you know, I am working on a complete open source replacement of Bitpay for allowing merchant to accept cryptocurrency payments while having a way to sell automatically.
> 
> A crucial, missing part, is fiat conversion. And I figured out a simple protocol that exchanges (or adapters) can implement to allow any merchant to cash out BTC in fiat while giving them the freedom to choose their own payment processor solution.
> 
> This also have positive impact on scalability: Before, a merchant would receive the bitcoin from the customer then would send to the exchange, resulting in two transactions.
> With this specification, it would be one transaction.
> 
> Special thanks to anditto and kallewoof for reviewing. I am waiting for your feedback:
> 
> Github link: https://github.com/NicolasDorier/bips/blob/master/bip-xxx.mediawiki <https://github.com/NicolasDorier/bips/blob/master/bip-xxx.mediawiki>
> 
> <pre>
>   BIP: XXX
>   Layer: Applications
>   Title: Crypto Open Exchange Protocol (COX)
>   Author: Nicolas Dorier <nicolas.dorier at gmail.com <mailto:nicolas.dorier at gmail.com>>
>   Comments-Summary: No comments yet.
>   Comments-URI: https://github.com/bitcoin/bips/wiki/Comments:BIP-XXX <https://github.com/bitcoin/bips/wiki/Comments:BIP-XXX>
>   Status: Draft
>   Type: Standards Track
>   Created: 2017-12-20
>   License: BSD-3-Clause
>            CC0-1.0
> </pre>
> 
> ==Abstract==
> 
> A simple protocol for decoupling payment processor solutions from exchanges.
> 
> ==Motivation==
> 
> Cryptocurrency merchant adoption is mainly driven by availability, ease of use and means of acceptance.
> We call such solutions `Payment Processors`.
> 
> Until now, payment processing solutions fall into one of the two following categories:
> 
> # Self-hosted with the customer paying in cryptocurrency and the merchant receiving it directly.
> # Centralized, coupled with an exchange feature, with the customer paying in cryptocurrency to the merchant, and receiving fiat or cryptocurrency on his exchange account.
> 
> The self-hosted solution has two issues:
> 
> # The merchant becomes vulnerable to the wild volatility of cryptocurrencies.
> # It is wasteful of blockchain space, if the merchant does not pay suppliers in crypto, as they need a second transaction to change to his exchange,
> 
> The centralized solution has two issues:
> 
> # It locks-in the merchant to a particular payment processor whose intentions might not be aligned (e.g. Bitpay who tried to redefine Bitcoin as being a different chain, without merchant approval)
> # It has to deal with local regulations (e.g. Bitpay does not provide fiat CAD to canadian merchants)
> 
> The goal of this BIP is to specify a simple protocol which makes possible decoupling of payment processors from exchanges.
> 
> We believe this BIP will gather a lot of interest among local exchanges which do not have the resources to develop their own payment solutions.
> 
> Their customers can decide which payment processor solution they prefer, while the exchanges give them a way to protect against cryptocurrency volatility.
> 
> ==Summary==
> 
> The merchant log in to its exchange website, go into "Address sources" section of it, an click on "Create a new address source".
> 
> The address source creation wizard asks him questions about what to do when crypto currency is sent to this the address source. (Cryptocurrency, Market sell order, limit order of past day average etc...)
> 
> The merchant receives an "address source URI" which they can input inside the payment processor.
> 
> An exchange compatible with the Crypto Open Exchange Protocol would reply to any HTTP POST request to this  "address source URI" returning the following information (more details in the Specification part)
> 
> # A deposit address for accepting a payment
> # The current rate
> # Optional: If the exchange is willing to take the risk of rate fluctuation, until when this rate is guaranteed and under which conditions.
> 
> <img src="bip-xxx/overview.png"></img>
> 
> ===Interaction===
> 
> * Manny (the "merchant") wants to accept Bitcoin payments on his e-commerce website.
> * Manny chooses the payment processor "PROCCO" which has a powerful plugin for his e-commerce website.
> * Manny is based in Canada and already has an account on the exchange "MYCOIN" which supports the Crypto Open Exchange Protocol.
> * Manny connects to the exchange website, and creates a new address source.
> * In the configuration screen of the address source, for each payment sent to this address source, Manny decides to keep 30% in Bitcoin and place a market sell order for the remaining 70% of the amount.
> * "MYCOIN" creates the address source, and gives the "address source URI" to the merchant. (e.g. https://example.com/addresssources/abd29ddn92 <https://example.com/addresssources/abd29ddn92>)
> * Manny copies the address source URI and goes inside "PROCCO" settings, and configures his store to use this address source URI.
> 
> Now a customer, Carol, wants to order a brand new phone for 0.01 BTC on Manny's store and decides to pay in Bitcoin.
> 
> * The E-Commerce website plugin requests the creation of an invoice from PROCCO.
> * PROCCO queries the "address source URI" and retrieves the rate, the expiration of this rate and conditions.
> * PROCCO can now show the Bitcoin Payment Checkout page.
> * Carla pays.
> * PROCCO marks the payment as paid and redirects to the e-commerce website.
> * MYCOIN, under its own policy (typically after 6 confirmations), credits Manny's account of 0.01 BTC and simultaneously creates a market sell order of 0.007 BTC on behalf of Manny.
> 
> ==Specification==
> 
> The payment processor sends a POST request to the "address source URI", the response from a Crypto Open Exchange Protocol exchange would be:
> 
> If the exchange does not guarantee the rate:
> 
>     {
>         "depositAddress" : "13....abd",
>         "currencyCode" : "CAD",
>         "cryptoCurrencyCode" : "BTC",
>         "rate" : "15600",
>         # When the merchant account get credited on the exchange
>         "requiredConfirmations" : blockcount
>     }
> 
> 
> If the exchange guarantee the rate:
> 
>     {
>         "depositAddress" : "13....abd",
>         "currencyCode" : "CAD",
>         "cryptoCurrencyCode" : "BTC",
>         "rate" : "15600",
>         "requiredConfirmations" : blockcount
>         "conditions" :
>         {
>             # When the transaction should be seen on the blockchain to guarantee the rate
>             "receivedBefore" : timestamp,
>             # When the transaction should be confirmed on the blockchain to guarantee the rate
>             "confirmedBefore" : timestamp
>         }
>     }
> 
> 
> The payment processor is responsible for giving feedback to the customer if the fees of the received transaction are not enough to guarantee the rate.
> 
> ==Note on adoption==
> 
> While local exchanges have incentives to implement this simple protocol, it is not strictly needed.
> 
> An alternative is to develop an adapter server which expose Crypto Open Exchange Protocol endpoint and connect to underlying exchange's API.
> 
> The only downside is that the rate can't be guaranteed.
> 
> ==Copyright==
> 
> This document is dual licensed as BSD 3-clause, and Creative Commons CC0 1.0 Universal.
> 
> 
> Nicolas,
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171220/ff1cb09d/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: Message signed with OpenPGP
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171220/ff1cb09d/attachment-0001.sig>

From nicolas.dorier at gmail.com  Thu Dec 21 08:20:11 2017
From: nicolas.dorier at gmail.com (Nicolas Dorier)
Date: Thu, 21 Dec 2017 17:20:11 +0900
Subject: [bitcoin-dev] BIP Proposal: Crypto Open Exchange Protocol (COX)
In-Reply-To: <A2014DA0-F6F8-470F-A167-E66723281269@sprovoost.nl>
References: <CA+1nnr=-6UkJT=TWjDHhZtXsic8p0fzQ=Yk1tSqkhL+NuvqCQw@mail.gmail.com>
	<A2014DA0-F6F8-470F-A167-E66723281269@sprovoost.nl>
Message-ID: <CA+1nnr=oCWwibecFGXpOJbtWnQ1b9=+Qx0nQcKoJRgdxyWZVrg@mail.gmail.com>

Thanks a lot for the feedback

> I think this could be quite useful, although I don?t know if it will get
adopted.

The good part is that it does not have to be adopted by exchanges. If
popular exchanges do not adopt it, it is trivial to make an adapter service
which translate COX to whatever proprietary API of the exchange.

Collaboration with the exchange is only needed if the exchange wants to
provide a service for taking the risk of volatility.

> I have personally been integrating BitPay into a website for payments in
BTC and like what you are trying to do.  One of the biggest hurdle?s I see
for merchants to adopt BitCoin today is the transaction fee.

This BIP supports alternatives currencies.

>  Can you refer to the kind of best practices Stripe and PayPal recommend?
Should some additional shared-secret or cookie / macaroon based
authentication be added?

Yes, I must add guidelines (SSL and how to manage the addresses). I don't
think authentication is needed as the merchant is the only one having
access to the source URI. This can be considered as a shared secret.
Even if this secret leaks, no funds are in danger.

> Can you clarify if this integration can run in a browser, or due to
security / privacy constraints must be server-to-server?

Thanks, I need to clarify the scope. But indeed, this is not meant to be
used by a browser, as merchants will not host their payment processors on
their mobile or browser.

> Though it?s important to remain future-proof by being flexible, leaving
the above details to individual implementers is probably going to result in
bad things.

Thanks, I think you are right I should add more recommendations for
implementers.

> What are your thoughts on rate limiting vs. privacy? Should a payment
source never return the same address even if nothing is paid to it?
Otherwise someone could just crawl webshops to create an inventory of
payment addresses. A new address every page reload could be a DDOS vector.
It also wouldn't be compatible with BIP44 because of its gap limit,
although I don?t think that?s a huge problem for exchanges.

You are right, I must introduce a sort of "order id" so that one order map
to exactly one address response.
The DDOS vector will then be on the shoulder of the ecommerce website by
preventing users to create too much orders. (they certainly already do)

> Can this be combined with an invoice mechanism similar to Lightning, e.g.
where the exchange sends a pre-image to the users wallet (relayed via and
retained by the web shop) upon receipt of the funds, which they can then
present to the merchant in case something went wrong. Exchanges might be
happy to support this protocol, but they don?t want the burden of dealing
with user support requests, so having signed invoices could help with that.

This protocol can be expanded later for lightning trivially, where the call
to the address source uri also returns a lightning payment request. (BOLT11)

> Speaking of Bisq, it would be neat if merchants can rely on random peer
to peer counterparties to convert to fiat, so their customer information
and revenue figures aren?t in the hands of a single counter party.
Obviously that?s a can of worms today, but it would be nice if the protocol
was able to support that if one day someone figures out the fraud,
compliance and bookkeeping stuff.

Conversion to fiat always need trust, so we must rule out anonymous
parties. If you want to spread on several trusted party, this can be done
transparently at the payment processor level, and does not requires change
to the protocol.

> Finally, why only exchanges? It could make sense fo shopping cart
software to talk to a Bitcoin wallet that?s hosted somewhere else for
similar reasons. Right now the best these plugins can do is hold on to an
XPUB, and I?ve even seen solutions that just send the customers coins to
their own backend wallet and then forward it.

Because BIP70/XPUB already solves the problem. (Which I already use in
BTCPay)
BIP70 is a pain in the ass to implement and does not provide any benefits,
and it does not define a way for the exchange to communicate a rate
attached to the bitcoin address, nor define a way to communicate to the
payment processor the conditions under which they can bear volatility risk.

I will revisit the BIP based on your feedback.

Nicolas,

On Wed, Dec 20, 2017 at 5:49 PM, Sjors Provoost <sjors at sprovoost.nl> wrote:

>
>
> I think this could be quite useful, although I don?t know if it will get
> adopted. If any such small local exchanges want to weigh in on this
> proposal, that would help. Same goes for shopping cart integrators, e.g.
> the folks writing WooCommerce and Shopify plugins.
>
> Consider adding some requirements around the use of SSL and certificate
> pinning. Can you refer to the kind of best practices Stripe and PayPal
> recommend? Should some additional shared-secret or cookie / macaroon based
> authentication be added?
>
> Can you clarify if this integration can run in a browser, or due to
> security / privacy constraints must be server-to-server?
>
> Though it?s important to remain future-proof by being flexible, leaving
> the above details to individual implementers is probably going to result in
> bad things.
>
> What are your thoughts on rate limiting vs. privacy? Should a payment
> source never return the same address even if nothing is paid to it?
> Otherwise someone could just crawl webshops to create an inventory of
> payment addresses. A new address every page reload could be a DDOS vector.
> It also wouldn't be compatible with BIP44 because of its gap limit,
> although I don?t think that?s a huge problem for exchanges.
>
> Can this be combined with an invoice mechanism similar to Lightning, e.g.
> where the exchange sends a pre-image to the users wallet (relayed via and
> retained by the web shop) upon receipt of the funds, which they can then
> present to the merchant in case something went wrong. Exchanges might be
> happy to support this protocol, but they don?t want the burden of dealing
> with user support requests, so having signed invoices could help with that.
>
> I would consider a more specific name like Delegated UTXO or something.
> ?Exchange? suggests is more like 0X or Bisq.
>
> Speaking of Bisq, it would be neat if merchants can rely on random peer to
> peer counterparties to convert to fiat, so their customer information and
> revenue figures aren?t in the hands of a single counter party. Obviously
> that?s a can of worms today, but it would be nice if the protocol was able
> to support that if one day someone figures out the fraud, compliance and
> bookkeeping stuff.
>
> Finally, why only exchanges? It could make sense fo shopping cart software
> to talk to a Bitcoin wallet that?s hosted somewhere else for similar
> reasons. Right now the best these plugins can do is hold on to an XPUB, and
> I?ve even seen solutions that just send the customers coins to their own
> backend wallet and then forward it.
>
> Sjors
>
> Op 20 dec. 2017, om 07:28 heeft Nicolas Dorier via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> het volgende geschreven:
>
> Hi everyone,
>
> As some of you know, I am working on a complete open source replacement of
> Bitpay for allowing merchant to accept cryptocurrency payments while having
> a way to sell automatically.
>
> A crucial, missing part, is fiat conversion. And I figured out a simple
> protocol that exchanges (or adapters) can implement to allow any merchant
> to cash out BTC in fiat while giving them the freedom to choose their own
> payment processor solution.
>
> This also have positive impact on scalability: Before, a merchant would
> receive the bitcoin from the customer then would send to the exchange,
> resulting in two transactions.
> With this specification, it would be one transaction.
>
> Special thanks to anditto and kallewoof for reviewing. I am waiting for
> your feedback:
>
> Github link: https://github.com/NicolasDorier/bips/blob/
> master/bip-xxx.mediawiki
>
> <pre>
>   BIP: XXX
>   Layer: Applications
>   Title: Crypto Open Exchange Protocol (COX)
>   Author: Nicolas Dorier <nicolas.dorier at gmail.com>
>   Comments-Summary: No comments yet.
>   Comments-URI: https://github.com/bitcoin/bips/wiki/Comments:BIP-XXX
>   Status: Draft
>   Type: Standards Track
>   Created: 2017-12-20
>   License: BSD-3-Clause
>            CC0-1.0
> </pre>
>
> ==Abstract==
>
> A simple protocol for decoupling payment processor solutions from
> exchanges.
>
> ==Motivation==
>
> Cryptocurrency merchant adoption is mainly driven by availability, ease of
> use and means of acceptance.
> We call such solutions `Payment Processors`.
>
> Until now, payment processing solutions fall into one of the two following
> categories:
>
> # Self-hosted with the customer paying in cryptocurrency and the merchant
> receiving it directly.
> # Centralized, coupled with an exchange feature, with the customer paying
> in cryptocurrency to the merchant, and receiving fiat or cryptocurrency on
> his exchange account.
>
> The self-hosted solution has two issues:
>
> # The merchant becomes vulnerable to the wild volatility of
> cryptocurrencies.
> # It is wasteful of blockchain space, if the merchant does not pay
> suppliers in crypto, as they need a second transaction to change to his
> exchange,
>
> The centralized solution has two issues:
>
> # It locks-in the merchant to a particular payment processor whose
> intentions might not be aligned (e.g. Bitpay who tried to redefine Bitcoin
> as being a different chain, without merchant approval)
> # It has to deal with local regulations (e.g. Bitpay does not provide fiat
> CAD to canadian merchants)
>
> The goal of this BIP is to specify a simple protocol which makes possible
> decoupling of payment processors from exchanges.
>
> We believe this BIP will gather a lot of interest among local exchanges
> which do not have the resources to develop their own payment solutions.
>
> Their customers can decide which payment processor solution they prefer,
> while the exchanges give them a way to protect against cryptocurrency
> volatility.
>
> ==Summary==
>
> The merchant log in to its exchange website, go into "Address sources"
> section of it, an click on "Create a new address source".
>
> The address source creation wizard asks him questions about what to do
> when crypto currency is sent to this the address source. (Cryptocurrency,
> Market sell order, limit order of past day average etc...)
>
> The merchant receives an "address source URI" which they can input inside
> the payment processor.
>
> An exchange compatible with the Crypto Open Exchange Protocol would reply
> to any HTTP POST request to this  "address source URI" returning the
> following information (more details in the Specification part)
>
> # A deposit address for accepting a payment
> # The current rate
> # Optional: If the exchange is willing to take the risk of rate
> fluctuation, until when this rate is guaranteed and under which conditions.
>
> <img src="bip-xxx/overview.png"></img>
>
> ===Interaction===
>
> * Manny (the "merchant") wants to accept Bitcoin payments on his
> e-commerce website.
> * Manny chooses the payment processor "PROCCO" which has a powerful plugin
> for his e-commerce website.
> * Manny is based in Canada and already has an account on the exchange
> "MYCOIN" which supports the Crypto Open Exchange Protocol.
> * Manny connects to the exchange website, and creates a new address source.
> * In the configuration screen of the address source, for each payment sent
> to this address source, Manny decides to keep 30% in Bitcoin and place a
> market sell order for the remaining 70% of the amount.
> * "MYCOIN" creates the address source, and gives the "address source URI"
> to the merchant. (e.g. https://example.com/addresssources/abd29ddn92)
> * Manny copies the address source URI and goes inside "PROCCO" settings,
> and configures his store to use this address source URI.
>
> Now a customer, Carol, wants to order a brand new phone for 0.01 BTC on
> Manny's store and decides to pay in Bitcoin.
>
> * The E-Commerce website plugin requests the creation of an invoice from
> PROCCO.
> * PROCCO queries the "address source URI" and retrieves the rate, the
> expiration of this rate and conditions.
> * PROCCO can now show the Bitcoin Payment Checkout page.
> * Carla pays.
> * PROCCO marks the payment as paid and redirects to the e-commerce website.
> * MYCOIN, under its own policy (typically after 6 confirmations), credits
> Manny's account of 0.01 BTC and simultaneously creates a market sell order
> of 0.007 BTC on behalf of Manny.
>
> ==Specification==
>
> The payment processor sends a POST request to the "address source URI",
> the response from a Crypto Open Exchange Protocol exchange would be:
>
> If the exchange does not guarantee the rate:
>
>     {
>         "depositAddress" : "13....abd",
>         "currencyCode" : "CAD",
>         "cryptoCurrencyCode" : "BTC",
>         "rate" : "15600",
>         # When the merchant account get credited on the exchange
>         "requiredConfirmations" : blockcount
>     }
>
>
> If the exchange guarantee the rate:
>
>     {
>         "depositAddress" : "13....abd",
>         "currencyCode" : "CAD",
>         "cryptoCurrencyCode" : "BTC",
>         "rate" : "15600",
>         "requiredConfirmations" : blockcount
>         "conditions" :
>         {
>             # When the transaction should be seen on the blockchain to
> guarantee the rate
>             "receivedBefore" : timestamp,
>             # When the transaction should be confirmed on the blockchain
> to guarantee the rate
>             "confirmedBefore" : timestamp
>         }
>     }
>
>
> The payment processor is responsible for giving feedback to the customer
> if the fees of the received transaction are not enough to guarantee the
> rate.
>
> ==Note on adoption==
>
> While local exchanges have incentives to implement this simple protocol,
> it is not strictly needed.
>
> An alternative is to develop an adapter server which expose Crypto Open
> Exchange Protocol endpoint and connect to underlying exchange's API.
>
> The only downside is that the rate can't be guaranteed.
>
> ==Copyright==
>
> This document is dual licensed as BSD 3-clause, and Creative Commons CC0
> 1.0 Universal.
>
>
> Nicolas,
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171221/d6e0ce81/attachment-0001.html>

From willtech at live.com.au  Thu Dec 21 11:19:52 2017
From: willtech at live.com.au (Damian Williamson)
Date: Thu, 21 Dec 2017 11:19:52 +0000
Subject: [bitcoin-dev] Sign / Verify message against SegWit P2SH addresses.
In-Reply-To: <725C679B-60E2-4E21-9F7D-10F67118D58D@friedenbach.org>
References: <CAAUFj10gEPBS3nTZ6aJn4UazhcJKPni6_pYGWwOs+QNeDo9NaA@mail.gmail.com>
	<52b65bab-ff84-7e21-e35a-f6ebd8106767@satoshilabs.com>,
	<725C679B-60E2-4E21-9F7D-10F67118D58D@friedenbach.org>
Message-ID: <PS2P216MB01795FCE6D61A62EBEA79AD79D0D0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>

In all seriousness, being able to sign a message is an important feature whether it is with Bitcoin Core or, with some other method. It is a good feature and it would be worthwhile IMHO to update it for SegWit addresses. I don't know about renewing it altogether, I like the current simplicity.


Regards,

Damian Williamson


------------------------------------

Sometimes I like to sign a message just to verify that is what I have said.

-

Bitcoin: 1PMUf9aaQ41M4bgVbCAPVwAeuKvj8CwxJg

------------------------------------

Signature:
HwJPqyWF0CbdsR7x737HbNIDoRufsrMI5XYQsKZ+MrWCJ6K7imtLY00sTCmSMDigZxRuoxyYZyQUw/lL0m/MV9M=

(Of course, signed messages will verify better usually with plain text and not HTML interpreted email - need a switch for outlook.com to send plaintext.)
________________________________
From: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Mark Friedenbach via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>
Sent: Wednesday, 20 December 2017 8:58 AM
To: Pavol Rusnak; Bitcoin Protocol Discussion
Subject: Re: [bitcoin-dev] Sign / Verify message against SegWit P2SH addresses.

For what it?s worth, I think it would be quite easy to do better than the implied solution of rejiggering the message signing system to support non-P2PKH scripts. Instead, have the signature be an actual bitcoin transaction with inputs that have the script being signed. Use the salted hash of the message being signed as the FORKID as if this were a spin-off with replay protection. This accomplishes three things:

(1) This enables signing by any infrastructure out there ? including hardware wallets and 2FA signing services ? that have enabled support for FORKID signing, which is a wide swath of the ecosystem because of Bitcoin Cash and Bitcoin Gold.

(2) It generalizes the message signing to allow multi-party signing setups as complicated (via sighash, etc.) as those bitcoin transactions allow, using existing and future tools based on Partially Signed Bitcoin Transactions; and

(3) It unifies a single approach for message signing, proof of reserve (where the inputs are actual UTXOs), and off-chain colored coins.

There?s the issue of size efficiency, but for the single-party message signing application that can be handled by a BIP that specifies a template for constructing the pseudo-transaction and its inputs from a raw script.

Mark

> On Dec 19, 2017, at 1:36 PM, Pavol Rusnak via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
>
> On 08/12/17 19:25, Dan Bryant via bitcoin-dev wrote:
>> I know there are posts, and an issue opened against it, but is there
>> anyone writing a BIP for Sign / Verify message against a SegWit address?
>
> Dan, are you still planning to write this BIP?
>
> --
> Best Regards / S pozdravom,
>
> Pavol "stick" Rusnak
> CTO, SatoshiLabs
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

_______________________________________________
bitcoin-dev mailing list
bitcoin-dev at lists.linuxfoundation.org
https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171221/2ae67657/attachment.html>

From sjors at sprovoost.nl  Thu Dec 21 09:04:44 2017
From: sjors at sprovoost.nl (Sjors Provoost)
Date: Thu, 21 Dec 2017 10:04:44 +0100
Subject: [bitcoin-dev] BIP Proposal: Crypto Open Exchange Protocol (COX)
In-Reply-To: <CA+1nnr=oCWwibecFGXpOJbtWnQ1b9=+Qx0nQcKoJRgdxyWZVrg@mail.gmail.com>
References: <CA+1nnr=-6UkJT=TWjDHhZtXsic8p0fzQ=Yk1tSqkhL+NuvqCQw@mail.gmail.com>
	<A2014DA0-F6F8-470F-A167-E66723281269@sprovoost.nl>
	<CA+1nnr=oCWwibecFGXpOJbtWnQ1b9=+Qx0nQcKoJRgdxyWZVrg@mail.gmail.com>
Message-ID: <F4631D31-54E2-43EF-B6BA-69B7371F1E6D@sprovoost.nl>

Just to clarify two points:

> The good part is that it does not have to be adopted by exchanges. If popular exchanges do not adopt it, it is trivial to make an adapter service which translate COX to whatever proprietary API of the exchange.

Be sure to elaborate on the difference in trust assumptions between a merchant running such an adapter on their own infrastructure vs. trusting a SAAS that sits in between the exchange and the merchants infrastructure.

In general adapters would create additional risks to think about, depending on how fine-tuned the API key permissions are. E.g. if API keys come with full permissions you don?t want to install an adaptor plugin if your shop is hosted on wordpress.com. PayPal and Stripe make sure their API keys can?t do too much damage in case the merchant shop hosting is compromised.

> > Can this be combined with an invoice mechanism similar to Lightning, e.g. where the exchange sends a pre-image to the users wallet (relayed via and retained by the web shop) upon receipt of the funds, which they can then present to the merchant in case something went wrong. Exchanges might be happy to support this protocol, but they don?t want the burden of dealing with user support requests, so having signed invoices could help with that.
> 
> This protocol can be expanded later for lightning trivially, where the call to the address source uri also returns a lightning payment request. (BOLT11)

I didn?t mean adding Lightning support (though that would be cool), I mean adding an invoice system to your proposal that is similar to how Lightning invoices work. Right now if the customer pays and the merchant has a poorly functioning shopping cart system, which I?ve seen more often than not, the customer would have to email their transaction id to the merchant, who then needs to login to their exchange to check if that address indeed belongs to them. But a merchant shouldn?t give all their support staff such access, and support staff may not have the right training, or even permission, to assess whether a transaction is cleared (?computer says no").

So you?d want some sort of signed message as part of the protocol that says ?if this transaction ID confirms, this order ID is paid for?.   Although this specific example wouldn?t play well with RBF. So maybe ?if the confirmed balance of this address is >= X, this order ID is paid for?, but then the exchange can?t sweep it. So maybe instead you need a callback from the exchange to just tell you when it?s (expected to be) confirmed. BitPay offers merchants various risk settings for this, so that might be worth looking into.

Sjors
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171221/a7167172/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: Message signed with OpenPGP
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171221/a7167172/attachment.sig>

From mark at friedenbach.org  Thu Dec 21 16:29:13 2017
From: mark at friedenbach.org (Mark Friedenbach)
Date: Thu, 21 Dec 2017 08:29:13 -0800
Subject: [bitcoin-dev] Sign / Verify message against SegWit P2SH
	addresses.
In-Reply-To: <PS2P216MB01795FCE6D61A62EBEA79AD79D0D0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
References: <CAAUFj10gEPBS3nTZ6aJn4UazhcJKPni6_pYGWwOs+QNeDo9NaA@mail.gmail.com>
	<52b65bab-ff84-7e21-e35a-f6ebd8106767@satoshilabs.com>
	<725C679B-60E2-4E21-9F7D-10F67118D58D@friedenbach.org>
	<PS2P216MB01795FCE6D61A62EBEA79AD79D0D0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
Message-ID: <1EE8D3E5-E9BA-4276-A139-E028D1F0BA4A@friedenbach.org>

It doesn?t matter what it does under the hood. The api could be the same.

> On Dec 21, 2017, at 3:19 AM, Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
> 
> In all seriousness, being able to sign a message is an important feature whether it is with Bitcoin Core or, with some other method. It is a good feature and it would be worthwhile IMHO to update it for SegWit addresses. I don't know about renewing it altogether, I like the current simplicity.
> 
> Regards,
> Damian Williamson
> 
> ------------------------------------
> Sometimes I like to sign a message just to verify that is what I have said.
> -
> Bitcoin: 1PMUf9aaQ41M4bgVbCAPVwAeuKvj8CwxJg
> ------------------------------------
> Signature:
> HwJPqyWF0CbdsR7x737HbNIDoRufsrMI5XYQsKZ+MrWCJ6K7imtLY00sTCmSMDigZxRuoxyYZyQUw/lL0m/MV9M=
> 
> (Of course, signed messages will verify better usually with plain text and not HTML interpreted email - need a switch for outlook.com to send plaintext.)
> From: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Mark Friedenbach via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>
> Sent: Wednesday, 20 December 2017 8:58 AM
> To: Pavol Rusnak; Bitcoin Protocol Discussion
> Subject: Re: [bitcoin-dev] Sign / Verify message against SegWit P2SH addresses.
>  
> For what it?s worth, I think it would be quite easy to do better than the implied solution of rejiggering the message signing system to support non-P2PKH scripts. Instead, have the signature be an actual bitcoin transaction with inputs that have the script being signed. Use the salted hash of the message being signed as the FORKID as if this were a spin-off with replay protection. This accomplishes three things:
> 
> (1) This enables signing by any infrastructure out there ? including hardware wallets and 2FA signing services ? that have enabled support for FORKID signing, which is a wide swath of the ecosystem because of Bitcoin Cash and Bitcoin Gold.
> 
> (2) It generalizes the message signing to allow multi-party signing setups as complicated (via sighash, etc.) as those bitcoin transactions allow, using existing and future tools based on Partially Signed Bitcoin Transactions; and
> 
> (3) It unifies a single approach for message signing, proof of reserve (where the inputs are actual UTXOs), and off-chain colored coins.
> 
> There?s the issue of size efficiency, but for the single-party message signing application that can be handled by a BIP that specifies a template for constructing the pseudo-transaction and its inputs from a raw script.
> 
> Mark
> 
> > On Dec 19, 2017, at 1:36 PM, Pavol Rusnak via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
> > 
> > On 08/12/17 19:25, Dan Bryant via bitcoin-dev wrote:
> >> I know there are posts, and an issue opened against it, but is there
> >> anyone writing a BIP for Sign / Verify message against a SegWit address?
> > 
> > Dan, are you still planning to write this BIP?
> > 
> > -- 
> > Best Regards / S pozdravom,
> > 
> > Pavol "stick" Rusnak
> > CTO, SatoshiLabs
> > _______________________________________________
> > bitcoin-dev mailing list
> > bitcoin-dev at lists.linuxfoundation.org
> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> 
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171221/0ae39224/attachment-0001.html>

From jason at dreyzehner.com  Thu Dec 21 17:23:49 2017
From: jason at dreyzehner.com (Jason Dreyzehner)
Date: Thu, 21 Dec 2017 17:23:49 +0000
Subject: [bitcoin-dev] Sign / Verify message against SegWit P2SH
	addresses.
In-Reply-To: <725C679B-60E2-4E21-9F7D-10F67118D58D@friedenbach.org>
References: <CAAUFj10gEPBS3nTZ6aJn4UazhcJKPni6_pYGWwOs+QNeDo9NaA@mail.gmail.com>
	<52b65bab-ff84-7e21-e35a-f6ebd8106767@satoshilabs.com>
	<725C679B-60E2-4E21-9F7D-10F67118D58D@friedenbach.org>
Message-ID: <CALunu-GWw1P6BJ8sZdr1ApKJVHawd7LJ9JHfEWP-Z0nacc8bhg@mail.gmail.com>

You might be interested in this proposal, which is very similar. The repo
contains a very basic implementation in typescript:
https://github.com/bitauth/bitauth2017/blob/master/bips/0-bitauth.mediawiki

https://github.com/bitauth/bitauth2017/

On Tue, Dec 19, 2017 at 4:59 PM Mark Friedenbach via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> For what it?s worth, I think it would be quite easy to do better than the
> implied solution of rejiggering the message signing system to support
> non-P2PKH scripts. Instead, have the signature be an actual bitcoin
> transaction with inputs that have the script being signed. Use the salted
> hash of the message being signed as the FORKID as if this were a spin-off
> with replay protection. This accomplishes three things:
>
> (1) This enables signing by any infrastructure out there ? including
> hardware wallets and 2FA signing services ? that have enabled support for
> FORKID signing, which is a wide swath of the ecosystem because of Bitcoin
> Cash and Bitcoin Gold.
>
> (2) It generalizes the message signing to allow multi-party signing setups
> as complicated (via sighash, etc.) as those bitcoin transactions allow,
> using existing and future tools based on Partially Signed Bitcoin
> Transactions; and
>
> (3) It unifies a single approach for message signing, proof of reserve
> (where the inputs are actual UTXOs), and off-chain colored coins.
>
> There?s the issue of size efficiency, but for the single-party message
> signing application that can be handled by a BIP that specifies a template
> for constructing the pseudo-transaction and its inputs from a raw script.
>
> Mark
>
> > On Dec 19, 2017, at 1:36 PM, Pavol Rusnak via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
> >
> > On 08/12/17 19:25, Dan Bryant via bitcoin-dev wrote:
> >> I know there are posts, and an issue opened against it, but is there
> >> anyone writing a BIP for Sign / Verify message against a SegWit address?
> >
> > Dan, are you still planning to write this BIP?
> >
> > --
> > Best Regards / S pozdravom,
> >
> > Pavol "stick" Rusnak
> > CTO, SatoshiLabs
> > _______________________________________________
> > bitcoin-dev mailing list
> > bitcoin-dev at lists.linuxfoundation.org
> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171221/d296ba4f/attachment.html>

From melvincarvalho at gmail.com  Thu Dec 21 21:30:20 2017
From: melvincarvalho at gmail.com (Melvin Carvalho)
Date: Thu, 21 Dec 2017 22:30:20 +0100
Subject: [bitcoin-dev] Total fees have almost crossed the block reward
Message-ID: <CAKaEYhJ0vC8wf9yYjovfoZLB-TTvEnVB2a3mkC-YDzmnLwtz1Q@mail.gmail.com>

I asked adam back at hcpp how the block chain would be secured in the long
term, once the reward goes away.  The base idea has always been that fees
would replace the block reward.

At that time fees were approximately 10% of the block reward, but have now
reached 45%, with 50% potentially being crossed soon

https://fork.lol/reward/feepct

While this bodes well for the long term security of the coin, I think there
is some legitimate concern that the fee per tx is prohibitive for some use
cases, at this point in the adoption curve.

Observations of segwit adoption show around 10% at this point

http://segwit.party/charts/

Watching the mempool shows that the congestion is at a peak, though it's
quite possible this will come down over the long weekend.  I wonder if this
is of concern to some.

https://dedi.jochen-hoenicke.de/queue/more/#24h

I thought these data points may be of interest and are mainly FYI.  Though
if further discussion is deemed appropriate, it would be interesting to
hear thoughts.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171221/d2feec02/attachment.html>

From jameson.lopp at gmail.com  Thu Dec 21 22:02:37 2017
From: jameson.lopp at gmail.com (Jameson Lopp)
Date: Thu, 21 Dec 2017 17:02:37 -0500
Subject: [bitcoin-dev] Total fees have almost crossed the block reward
In-Reply-To: <CAKaEYhJ0vC8wf9yYjovfoZLB-TTvEnVB2a3mkC-YDzmnLwtz1Q@mail.gmail.com>
References: <CAKaEYhJ0vC8wf9yYjovfoZLB-TTvEnVB2a3mkC-YDzmnLwtz1Q@mail.gmail.com>
Message-ID: <CADL_X_fw01-PfyTPXqYAyzwV9CO8tPLrd1_eZu16Z_kz-xM7LQ@mail.gmail.com>

I'd hope that the incentives are in place to encourage high volume senders
to be more efficient in their use of block space by batching transactions
and implementing SegWit, though this may not be the case for providers that
pass transaction fees along to their users.

We've been trying to be more proactive about outreach regarding efficient
use of block space to our own customers at BitGo - when we break down the
cost savings of implementing a new technique, it generally helps to hasten
their adoption. I suspect that in many cases this is an issue of education
- we should be more proactive in calling out inefficient uses of block
space.

Good resources to bookmark and share:

https://bitcointechtalk.com/saving-up-to-80-on-bitcoin-transaction-fees-by-batching-payments-4147ab7009fb

https://blog.zebpay.com/how-zebpay-reduced-bitcoin-transaction-fees-a9e24c788598

- Jameson

On Thu, Dec 21, 2017 at 4:30 PM, Melvin Carvalho via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> I asked adam back at hcpp how the block chain would be secured in the long
> term, once the reward goes away.  The base idea has always been that fees
> would replace the block reward.
>
> At that time fees were approximately 10% of the block reward, but have now
> reached 45%, with 50% potentially being crossed soon
>
> https://fork.lol/reward/feepct
>
> While this bodes well for the long term security of the coin, I think
> there is some legitimate concern that the fee per tx is prohibitive for
> some use cases, at this point in the adoption curve.
>
> Observations of segwit adoption show around 10% at this point
>
> http://segwit.party/charts/
>
> Watching the mempool shows that the congestion is at a peak, though it's
> quite possible this will come down over the long weekend.  I wonder if this
> is of concern to some.
>
> https://dedi.jochen-hoenicke.de/queue/more/#24h
>
> I thought these data points may be of interest and are mainly FYI.  Though
> if further discussion is deemed appropriate, it would be interesting to
> hear thoughts.
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171221/65f4e581/attachment.html>

From dkbryant at gmail.com  Thu Dec 21 22:22:58 2017
From: dkbryant at gmail.com (Dan Bryant)
Date: Thu, 21 Dec 2017 16:22:58 -0600
Subject: [bitcoin-dev] Sign / Verify message against SegWit P2SH
	addresses.
In-Reply-To: <52b65bab-ff84-7e21-e35a-f6ebd8106767@satoshilabs.com>
References: <CAAUFj10gEPBS3nTZ6aJn4UazhcJKPni6_pYGWwOs+QNeDo9NaA@mail.gmail.com>
	<52b65bab-ff84-7e21-e35a-f6ebd8106767@satoshilabs.com>
Message-ID: <CAAUFj12MWgSuz5MgJqguwMW0e_kewb0k4B0Zrnh-GRS4isnruw@mail.gmail.com>

legacy message sign verify BIP to get the ball rolling.

early draft:
https://github.com/brianddk/bips/blob/legacysignverify/bip-0xyz.mediawiki

On Tue, Dec 19, 2017 at 3:36 PM, Pavol Rusnak <stick at satoshilabs.com> wrote:

> On 08/12/17 19:25, Dan Bryant via bitcoin-dev wrote:
> > I know there are posts, and an issue opened against it, but is there
> > anyone writing a BIP for Sign / Verify message against a SegWit address?
>
> Dan, are you still planning to write this BIP?
>
> --
> Best Regards / S pozdravom,
>
> Pavol "stick" Rusnak
> CTO, SatoshiLabs
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171221/ce3abe15/attachment-0001.html>

From dkbryant at gmail.com  Thu Dec 21 22:26:25 2017
From: dkbryant at gmail.com (Dan Bryant)
Date: Thu, 21 Dec 2017 16:26:25 -0600
Subject: [bitcoin-dev] BIP for Legacy Sign Verify functions
Message-ID: <CAAUFj100ULfTbEorSK2PF5nvW-R_TCMOiboBBEMj+eS5upgU8Q@mail.gmail.com>

https://github.com/brianddk/bips/blob/legacysignverify/bip-0xyz.mediawiki

Although this is a well established functionality, it has never been
published in a BIP.  My proposal is simply to provide a reference point for
future expansion of these capabilities into new address schemes.

Original reference thread [Sign / Verify message against SegWit P2SH
addresses]
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171221/1407a823/attachment.html>

From jim.rogers.907 at gmail.com  Thu Dec 21 22:18:32 2017
From: jim.rogers.907 at gmail.com (Jim Rogers)
Date: Thu, 21 Dec 2017 13:18:32 -0900
Subject: [bitcoin-dev] Total fees have almost crossed the block reward
In-Reply-To: <CADL_X_fw01-PfyTPXqYAyzwV9CO8tPLrd1_eZu16Z_kz-xM7LQ@mail.gmail.com>
References: <CAKaEYhJ0vC8wf9yYjovfoZLB-TTvEnVB2a3mkC-YDzmnLwtz1Q@mail.gmail.com>
	<CADL_X_fw01-PfyTPXqYAyzwV9CO8tPLrd1_eZu16Z_kz-xM7LQ@mail.gmail.com>
Message-ID: <002d01d37aa9$a513db40$ef3b91c0$@gmail.com>

It seems that the exchanges are doing everything that they can to slow things. Not only have the major exchanges not implemented segwit yet, but a bigger, less addressed issue is that they have start applying transfer limits on crypto as well as cash. They do not respond for months to requests to upgrade limits, and this results in many transactions instead of one to transfer crypto to cold storage devices. 

 

These issues may self-resolve over time, since I think they are all impacted by KYC and the explosive growth. 

 

 

From: bitcoin-dev-bounces at lists.linuxfoundation.org [mailto:bitcoin-dev-bounces at lists.linuxfoundation.org] On Behalf Of Jameson Lopp via bitcoin-dev
Sent: Thursday, December 21, 2017 1:03 PM
To: Melvin Carvalho <melvincarvalho at gmail.com>; Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>
Subject: Re: [bitcoin-dev] Total fees have almost crossed the block reward

 

I'd hope that the incentives are in place to encourage high volume senders to be more efficient in their use of block space by batching transactions and implementing SegWit, though this may not be the case for providers that pass transaction fees along to their users.

 

We've been trying to be more proactive about outreach regarding efficient use of block space to our own customers at BitGo - when we break down the cost savings of implementing a new technique, it generally helps to hasten their adoption. I suspect that in many cases this is an issue of education - we should be more proactive in calling out inefficient uses of block space.

 

Good resources to bookmark and share:

 

https://bitcointechtalk.com/saving-up-to-80-on-bitcoin-transaction-fees-by-batching-payments-4147ab7009fb

 

https://blog.zebpay.com/how-zebpay-reduced-bitcoin-transaction-fees-a9e24c788598

 

- Jameson

 

On Thu, Dec 21, 2017 at 4:30 PM, Melvin Carvalho via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org> > wrote:

I asked adam back at hcpp how the block chain would be secured in the long term, once the reward goes away.  The base idea has always been that fees would replace the block reward.

At that time fees were approximately 10% of the block reward, but have now reached 45%, with 50% potentially being crossed soon

https://fork.lol/reward/feepct

While this bodes well for the long term security of the coin, I think there is some legitimate concern that the fee per tx is prohibitive for some use cases, at this point in the adoption curve.

Observations of segwit adoption show around 10% at this point

http://segwit.party/charts/

Watching the mempool shows that the congestion is at a peak, though it's quite possible this will come down over the long weekend.  I wonder if this is of concern to some.

https://dedi.jochen-hoenicke.de/queue/more/#24h

I thought these data points may be of interest and are mainly FYI.  Though if further discussion is deemed appropriate, it would be interesting to hear thoughts.


_______________________________________________
bitcoin-dev mailing list
bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org> 
https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171221/08b9c9a0/attachment.html>

From greg at xiph.org  Thu Dec 21 22:44:32 2017
From: greg at xiph.org (Gregory Maxwell)
Date: Thu, 21 Dec 2017 22:44:32 +0000
Subject: [bitcoin-dev] Total fees have almost crossed the block reward
In-Reply-To: <CAKaEYhJ0vC8wf9yYjovfoZLB-TTvEnVB2a3mkC-YDzmnLwtz1Q@mail.gmail.com>
References: <CAKaEYhJ0vC8wf9yYjovfoZLB-TTvEnVB2a3mkC-YDzmnLwtz1Q@mail.gmail.com>
Message-ID: <CAAS2fgQSNdzuiPS3AZ_TjQ2OvkhYJ3ZJUBo7ovP6_O2snuwEMg@mail.gmail.com>

Personally, I'm pulling out the champaign that market behaviour is
indeed producing activity levels that can pay for security without
inflation, and also producing fee paying backlogs needed to stabilize
consensus progress as the subsidy declines.

I'd also personally prefer to pay lower fees-- current levels even
challenge my old comparison with wire transfer costs-- but we should
look most strongly at difficult to forge market signals rather than
just claims-- segwit usage gives us a pretty good indicator since most
users would get a 50-70% fee reduction without even considering the
second order effects from increased capacity.

As Jameson Lopp notes, more can be done for education though-- perhaps
that market signal isn't efficient yet. But we should get it there.

But even independently of segwit we can also look at other inefficient
transaction styles: uncompressed keys, unconfirmed chaining instead of
send many batching, fee overpayment, etc... and the message there is
similar.

I've also seen some evidence that a portion of the current high rate
congestion is contrived traffic. To the extent that it's true there
also should be some relief there soon as the funding for that runs
out, in addition to expected traffic patterns, difficulty changes,
etc.


On Thu, Dec 21, 2017 at 9:30 PM, Melvin Carvalho via bitcoin-dev
<bitcoin-dev at lists.linuxfoundation.org> wrote:
> I asked adam back at hcpp how the block chain would be secured in the long
> term, once the reward goes away.  The base idea has always been that fees
> would replace the block reward.
>
> At that time fees were approximately 10% of the block reward, but have now
> reached 45%, with 50% potentially being crossed soon
>
> https://fork.lol/reward/feepct
>
> While this bodes well for the long term security of the coin, I think there
> is some legitimate concern that the fee per tx is prohibitive for some use
> cases, at this point in the adoption curve.
>
> Observations of segwit adoption show around 10% at this point
>
> http://segwit.party/charts/
>
> Watching the mempool shows that the congestion is at a peak, though it's
> quite possible this will come down over the long weekend.  I wonder if this
> is of concern to some.
>
> https://dedi.jochen-hoenicke.de/queue/more/#24h
>
> I thought these data points may be of interest and are mainly FYI.  Though
> if further discussion is deemed appropriate, it would be interesting to hear
> thoughts.
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>

From luke at dashjr.org  Thu Dec 21 23:09:05 2017
From: luke at dashjr.org (Luke Dashjr)
Date: Thu, 21 Dec 2017 23:09:05 +0000
Subject: [bitcoin-dev] BIP for Legacy Sign Verify functions
In-Reply-To: <CAAUFj100ULfTbEorSK2PF5nvW-R_TCMOiboBBEMj+eS5upgU8Q@mail.gmail.com>
References: <CAAUFj100ULfTbEorSK2PF5nvW-R_TCMOiboBBEMj+eS5upgU8Q@mail.gmail.com>
Message-ID: <201712212309.07243.luke@dashjr.org>

On Thursday 21 December 2017 10:26:25 PM Dan Bryant via bitcoin-dev wrote:
> https://github.com/brianddk/bips/blob/legacysignverify/bip-0xyz.mediawiki

It's not even correct... Your first "verify message" step is not possible; you 
can't get a public key from an address.

What is actually done, is using the signature + message to perform key 
recovery, to extract the public key of the signer, and then hashing that and 
comparing it to the address provided.

> Although this is a well established functionality, it has never been
> published in a BIP.  My proposal is simply to provide a reference point for
> future expansion of these capabilities into new address schemes.

New schemes should probably NOT be based on the current one.

Luke

From dkbryant at gmail.com  Thu Dec 21 23:21:24 2017
From: dkbryant at gmail.com (Dan Bryant)
Date: Thu, 21 Dec 2017 17:21:24 -0600
Subject: [bitcoin-dev] BIP for Legacy Sign Verify functions
In-Reply-To: <201712212309.07243.luke@dashjr.org>
References: <CAAUFj100ULfTbEorSK2PF5nvW-R_TCMOiboBBEMj+eS5upgU8Q@mail.gmail.com>
	<201712212309.07243.luke@dashjr.org>
Message-ID: <CAAUFj127=fNaPh+RtGgTbqDfxS=+ihCwDDWhkRpvdRSLtRf7xA@mail.gmail.com>

Thank you... I've updated.

> New schemes should probably NOT be based on the current one.

Fair enough... I still think there are those who would still like an
existing sign/verify BIP to reference.

On Thu, Dec 21, 2017 at 5:09 PM, Luke Dashjr <luke at dashjr.org> wrote:

> On Thursday 21 December 2017 10:26:25 PM Dan Bryant via bitcoin-dev wrote:
> > https://github.com/brianddk/bips/blob/legacysignverify/
> bip-0xyz.mediawiki
>
> It's not even correct... Your first "verify message" step is not possible;
> you
> can't get a public key from an address.
>
> What is actually done, is using the signature + message to perform key
> recovery, to extract the public key of the signer, and then hashing that
> and
> comparing it to the address provided.
>
> > Although this is a well established functionality, it has never been
> > published in a BIP.  My proposal is simply to provide a reference point
> for
> > future expansion of these capabilities into new address schemes.
>
> New schemes should probably NOT be based on the current one.
>
> Luke
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171221/9543aa61/attachment-0001.html>

From lists at benappy.com  Thu Dec 21 23:15:18 2017
From: lists at benappy.com (Michel 'ic' Luczak)
Date: Fri, 22 Dec 2017 00:15:18 +0100
Subject: [bitcoin-dev] Total fees have almost crossed the block reward
In-Reply-To: <CADL_X_fw01-PfyTPXqYAyzwV9CO8tPLrd1_eZu16Z_kz-xM7LQ@mail.gmail.com>
References: <CAKaEYhJ0vC8wf9yYjovfoZLB-TTvEnVB2a3mkC-YDzmnLwtz1Q@mail.gmail.com>
	<CADL_X_fw01-PfyTPXqYAyzwV9CO8tPLrd1_eZu16Z_kz-xM7LQ@mail.gmail.com>
Message-ID: <EE3998F3-FB96-4D7C-BB0F-48EFEEE3324D@benappy.com>

Hi,

This is the first time I post on this list.

First of all, Thank you Jameson for the interview you gave yesterday, it?s been a model of calm and self-control for all of us.

I deeply believe the high average fees we experience right now are mostly due to the miscalculations of most of the hardware (ledger & trezor) wallets (and probably software too) on the market.

I personally made transactions at the worst period for the Blockchain with less than 40 sat/WU of fees and got confirmed in less than a day.

I think there?s a lot of work to do in used education to make them understand that for a low amount of fees they can still get a transaction confirmed and that?s the POS? work to make sure the transaction is legit.

Regards, Michel.

> On 21 Dec 2017, at 23:02, Jameson Lopp via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
> 
> I'd hope that the incentives are in place to encourage high volume senders to be more efficient in their use of block space by batching transactions and implementing SegWit, though this may not be the case for providers that pass transaction fees along to their users.
> 
> We've been trying to be more proactive about outreach regarding efficient use of block space to our own customers at BitGo - when we break down the cost savings of implementing a new technique, it generally helps to hasten their adoption. I suspect that in many cases this is an issue of education - we should be more proactive in calling out inefficient uses of block space.
> 
> Good resources to bookmark and share:
> 
> https://bitcointechtalk.com/saving-up-to-80-on-bitcoin-transaction-fees-by-batching-payments-4147ab7009fb <https://bitcointechtalk.com/saving-up-to-80-on-bitcoin-transaction-fees-by-batching-payments-4147ab7009fb>
> 
> https://blog.zebpay.com/how-zebpay-reduced-bitcoin-transaction-fees-a9e24c788598 <https://blog.zebpay.com/how-zebpay-reduced-bitcoin-transaction-fees-a9e24c788598>
> 
> - Jameson
> 
> On Thu, Dec 21, 2017 at 4:30 PM, Melvin Carvalho via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:
> I asked adam back at hcpp how the block chain would be secured in the long term, once the reward goes away.  The base idea has always been that fees would replace the block reward.
> 
> At that time fees were approximately 10% of the block reward, but have now reached 45%, with 50% potentially being crossed soon
> 
> https://fork.lol/reward/feepct <https://fork.lol/reward/feepct>
> 
> While this bodes well for the long term security of the coin, I think there is some legitimate concern that the fee per tx is prohibitive for some use cases, at this point in the adoption curve.
> 
> Observations of segwit adoption show around 10% at this point
> 
> http://segwit.party/charts/ <http://segwit.party/charts/>
> 
> Watching the mempool shows that the congestion is at a peak, though it's quite possible this will come down over the long weekend.  I wonder if this is of concern to some.
> 
> https://dedi.jochen-hoenicke.de/queue/more/#24h <https://dedi.jochen-hoenicke.de/queue/more/#24h>
> 
> I thought these data points may be of interest and are mainly FYI.  Though if further discussion is deemed appropriate, it would be interesting to hear thoughts.
> 
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>
> 
> 
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171222/9bafeb37/attachment.html>

From piverson1024 at gmail.com  Thu Dec 21 23:35:28 2017
From: piverson1024 at gmail.com (Paul Iverson)
Date: Thu, 21 Dec 2017 15:35:28 -0800
Subject: [bitcoin-dev] Total fees have almost crossed the block reward
In-Reply-To: <CAAS2fgQSNdzuiPS3AZ_TjQ2OvkhYJ3ZJUBo7ovP6_O2snuwEMg@mail.gmail.com>
References: <CAKaEYhJ0vC8wf9yYjovfoZLB-TTvEnVB2a3mkC-YDzmnLwtz1Q@mail.gmail.com>
	<CAAS2fgQSNdzuiPS3AZ_TjQ2OvkhYJ3ZJUBo7ovP6_O2snuwEMg@mail.gmail.com>
Message-ID: <CAAeo5+gYrr=KaqrLibmAoUWG4F_EdR5SQTE9U6-jsYYVT23kTQ@mail.gmail.com>

I agree with Greg.  What is happening is a cause for celebration: it is the
manifestation of our long-desired fee market in action.  That people are
willing to pay upwards of $100 per transaction shows the huge demand to
transact on the world's most secure ledger. This is what success looks
like, folks!

Now that BTC is being phased out as a means of payment nearly everywhere
(e.g., Steam dropping BTC as a payment option) (to be replaced with the
more-suitable LN when ready), I'd propose that we address the stuck
transaction issue by making replace-by-fee (RBF) ubiquitous.  Why not make
every transaction RBF by default, and then encourage via outreach and
education other wallet developers to do the same?

The frustration with BTC today is less so the high-fees (people realize
on-chain transactions in a secure decentralized ledger are necessarily
costly) but by the feeling of helplessness when their transaction is
stuck.  Being able to easily bump a transaction's fee for users who are in
a hurry would go a long way to improving the user experience.

Paul.


On Thu, Dec 21, 2017 at 2:44 PM, Gregory Maxwell via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Personally, I'm pulling out the champaign that market behaviour is
> indeed producing activity levels that can pay for security without
> inflation, and also producing fee paying backlogs needed to stabilize
> consensus progress as the subsidy declines.
>
> I'd also personally prefer to pay lower fees-- current levels even
> challenge my old comparison with wire transfer costs-- but we should
> look most strongly at difficult to forge market signals rather than
> just claims-- segwit usage gives us a pretty good indicator since most
> users would get a 50-70% fee reduction without even considering the
> second order effects from increased capacity.
>
> As Jameson Lopp notes, more can be done for education though-- perhaps
> that market signal isn't efficient yet. But we should get it there.
>
> But even independently of segwit we can also look at other inefficient
> transaction styles: uncompressed keys, unconfirmed chaining instead of
> send many batching, fee overpayment, etc... and the message there is
> similar.
>
> I've also seen some evidence that a portion of the current high rate
> congestion is contrived traffic. To the extent that it's true there
> also should be some relief there soon as the funding for that runs
> out, in addition to expected traffic patterns, difficulty changes,
> etc.
>
>
> On Thu, Dec 21, 2017 at 9:30 PM, Melvin Carvalho via bitcoin-dev
> <bitcoin-dev at lists.linuxfoundation.org> wrote:
> > I asked adam back at hcpp how the block chain would be secured in the
> long
> > term, once the reward goes away.  The base idea has always been that fees
> > would replace the block reward.
> >
> > At that time fees were approximately 10% of the block reward, but have
> now
> > reached 45%, with 50% potentially being crossed soon
> >
> > https://fork.lol/reward/feepct
> >
> > While this bodes well for the long term security of the coin, I think
> there
> > is some legitimate concern that the fee per tx is prohibitive for some
> use
> > cases, at this point in the adoption curve.
> >
> > Observations of segwit adoption show around 10% at this point
> >
> > http://segwit.party/charts/
> >
> > Watching the mempool shows that the congestion is at a peak, though it's
> > quite possible this will come down over the long weekend.  I wonder if
> this
> > is of concern to some.
> >
> > https://dedi.jochen-hoenicke.de/queue/more/#24h
> >
> > I thought these data points may be of interest and are mainly FYI.
> Though
> > if further discussion is deemed appropriate, it would be interesting to
> hear
> > thoughts.
> >
> > _______________________________________________
> > bitcoin-dev mailing list
> > bitcoin-dev at lists.linuxfoundation.org
> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> >
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171221/57708e63/attachment.html>

From mark at friedenbach.org  Fri Dec 22 00:30:52 2017
From: mark at friedenbach.org (Mark Friedenbach)
Date: Thu, 21 Dec 2017 16:30:52 -0800
Subject: [bitcoin-dev] Total fees have almost crossed the block reward
In-Reply-To: <CAAeo5+gYrr=KaqrLibmAoUWG4F_EdR5SQTE9U6-jsYYVT23kTQ@mail.gmail.com>
References: <CAKaEYhJ0vC8wf9yYjovfoZLB-TTvEnVB2a3mkC-YDzmnLwtz1Q@mail.gmail.com>
	<CAAS2fgQSNdzuiPS3AZ_TjQ2OvkhYJ3ZJUBo7ovP6_O2snuwEMg@mail.gmail.com>
	<CAAeo5+gYrr=KaqrLibmAoUWG4F_EdR5SQTE9U6-jsYYVT23kTQ@mail.gmail.com>
Message-ID: <9EB76B68-E8AC-4BE8-8279-BA18033CBF9F@friedenbach.org>

Every transaction is replace-by-fee capable already. Opt-in replace by fee as specified in BIP 125 is a fiction that held sway only while the income from fees or fee replacement was so much smaller than subsidy.

> On Dec 21, 2017, at 3:35 PM, Paul Iverson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
> 
> I agree with Greg.  What is happening is a cause for celebration: it is the manifestation of our long-desired fee market in action.  That people are willing to pay upwards of $100 per transaction shows the huge demand to transact on the world's most secure ledger. This is what success looks like, folks!
> 
> Now that BTC is being phased out as a means of payment nearly everywhere (e.g., Steam dropping BTC as a payment option) (to be replaced with the more-suitable LN when ready), I'd propose that we address the stuck transaction issue by making replace-by-fee (RBF) ubiquitous.  Why not make every transaction RBF by default, and then encourage via outreach and education other wallet developers to do the same?  
> 
> The frustration with BTC today is less so the high-fees (people realize on-chain transactions in a secure decentralized ledger are necessarily costly) but by the feeling of helplessness when their transaction is stuck.  Being able to easily bump a transaction's fee for users who are in a hurry would go a long way to improving the user experience.  
> 
> Paul.
> 
> 
> On Thu, Dec 21, 2017 at 2:44 PM, Gregory Maxwell via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:
> Personally, I'm pulling out the champaign that market behaviour is
> indeed producing activity levels that can pay for security without
> inflation, and also producing fee paying backlogs needed to stabilize
> consensus progress as the subsidy declines.
> 
> I'd also personally prefer to pay lower fees-- current levels even
> challenge my old comparison with wire transfer costs-- but we should
> look most strongly at difficult to forge market signals rather than
> just claims-- segwit usage gives us a pretty good indicator since most
> users would get a 50-70% fee reduction without even considering the
> second order effects from increased capacity.
> 
> As Jameson Lopp notes, more can be done for education though-- perhaps
> that market signal isn't efficient yet. But we should get it there.
> 
> But even independently of segwit we can also look at other inefficient
> transaction styles: uncompressed keys, unconfirmed chaining instead of
> send many batching, fee overpayment, etc... and the message there is
> similar.
> 
> I've also seen some evidence that a portion of the current high rate
> congestion is contrived traffic. To the extent that it's true there
> also should be some relief there soon as the funding for that runs
> out, in addition to expected traffic patterns, difficulty changes,
> etc.
> 
> 
> On Thu, Dec 21, 2017 at 9:30 PM, Melvin Carvalho via bitcoin-dev
> <bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:
> > I asked adam back at hcpp how the block chain would be secured in the long
> > term, once the reward goes away.  The base idea has always been that fees
> > would replace the block reward.
> >
> > At that time fees were approximately 10% of the block reward, but have now
> > reached 45%, with 50% potentially being crossed soon
> >
> > https://fork.lol/reward/feepct <https://fork.lol/reward/feepct>
> >
> > While this bodes well for the long term security of the coin, I think there
> > is some legitimate concern that the fee per tx is prohibitive for some use
> > cases, at this point in the adoption curve.
> >
> > Observations of segwit adoption show around 10% at this point
> >
> > http://segwit.party/charts/ <http://segwit.party/charts/>
> >
> > Watching the mempool shows that the congestion is at a peak, though it's
> > quite possible this will come down over the long weekend.  I wonder if this
> > is of concern to some.
> >
> > https://dedi.jochen-hoenicke.de/queue/more/#24h <https://dedi.jochen-hoenicke.de/queue/more/#24h>
> >
> > I thought these data points may be of interest and are mainly FYI.  Though
> > if further discussion is deemed appropriate, it would be interesting to hear
> > thoughts.
> >
> > _______________________________________________
> > bitcoin-dev mailing list
> > bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>
> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>
> >
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>
> 
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171221/d675d05f/attachment-0001.html>

From greg at xiph.org  Fri Dec 22 01:15:46 2017
From: greg at xiph.org (Gregory Maxwell)
Date: Fri, 22 Dec 2017 01:15:46 +0000
Subject: [bitcoin-dev] Total fees have almost crossed the block reward
In-Reply-To: <9EB76B68-E8AC-4BE8-8279-BA18033CBF9F@friedenbach.org>
References: <CAKaEYhJ0vC8wf9yYjovfoZLB-TTvEnVB2a3mkC-YDzmnLwtz1Q@mail.gmail.com>
	<CAAS2fgQSNdzuiPS3AZ_TjQ2OvkhYJ3ZJUBo7ovP6_O2snuwEMg@mail.gmail.com>
	<CAAeo5+gYrr=KaqrLibmAoUWG4F_EdR5SQTE9U6-jsYYVT23kTQ@mail.gmail.com>
	<9EB76B68-E8AC-4BE8-8279-BA18033CBF9F@friedenbach.org>
Message-ID: <CAAS2fgTkfNcJuFPPwppwOt9mvWp4nX3FyhJBmZyTbg=3ZsNDBg@mail.gmail.com>

On Fri, Dec 22, 2017 at 12:30 AM, Mark Friedenbach via bitcoin-dev
<bitcoin-dev at lists.linuxfoundation.org> wrote:
> Every transaction is replace-by-fee capable already. Opt-in replace by fee
> as specified in BIP 125 is a fiction that held sway only while the income
> from fees or fee replacement was so much smaller than subsidy.

The distinction is does a next fee replacement hit the next block 99%
of the time or does it do so with 10% probability each successive
block that the original remains unconfirmed; eventually converging to
the same 99% but only after a non-trivial additional delay.  As a
result it's still useful to flip it on.

I believe electrum has been defaulting to opt-in without any big problems.

There was discussion in the bitcoin core weekly irc meeting today
about defaulting it on.  Some expressed the view that perhaps it
should be left off by default for the RPC because some industrial
users but I'm of the view that those users are both most likely to
want it on and also the most able to see it in the release notes and
change their settings.

From vitteaymeric at gmail.com  Fri Dec 22 10:29:13 2017
From: vitteaymeric at gmail.com (Aymeric Vitte)
Date: Fri, 22 Dec 2017 11:29:13 +0100
Subject: [bitcoin-dev] BIP for Legacy Sign Verify functions
In-Reply-To: <201712212309.07243.luke@dashjr.org>
References: <CAAUFj100ULfTbEorSK2PF5nvW-R_TCMOiboBBEMj+eS5upgU8Q@mail.gmail.com>
	<201712212309.07243.luke@dashjr.org>
Message-ID: <4789faec-c6fb-3d05-1b4b-95ce7aefb373@gmail.com>



Le 22/12/2017 ? 00:09, Luke Dashjr via bitcoin-dev a ?crit?:
> What is actually done, is using the signature + message to perform key 
> recovery, to extract the public key of the signer, and then hashing that and 
> comparing it to the address provided.
I already posted about this, then what is doing the pubkey in sigscript
for standard p2pkh transactions? (this was not the case some time ago)

-- 
Bitcoin transactions made simple: https://github.com/Ayms/bitcoin-transactions
Zcash wallets made simple: https://github.com/Ayms/zcash-wallets
Bitcoin wallets made simple: https://github.com/Ayms/bitcoin-wallets
Get the torrent dynamic blocklist: http://peersm.com/getblocklist
Check the 10 M passwords list: http://peersm.com/findmyass
Anti-spies and private torrents, dynamic blocklist: http://torrent-live.org
Peersm : http://www.peersm.com
torrent-live: https://github.com/Ayms/torrent-live
node-Tor : https://www.github.com/Ayms/node-Tor
GitHub : https://www.github.com/Ayms


From petdog at gmail.com  Fri Dec 22 08:26:12 2017
From: petdog at gmail.com (oscar)
Date: Fri, 22 Dec 2017 09:26:12 +0100
Subject: [bitcoin-dev] what do you think about having a maximum fee rate?
Message-ID: <CAMjoVH+5W+1pO2bJSPNr20sGJDVvwrKS85KZZYsSdXjSL65jLA@mail.gmail.com>

Hello,
I'm not a bitcoin developer, but I'd like to receive feedback on what
I think is a serious problem. Hope I'm not wasting your time.
I'm also sure this was already discussed, but google doesn't give me
any good result.

Let me explain: I think that the current incentive system doesn't
really align with the way miners are distributed (not very
decentralized, due to pools and huge asic producers).
I think big miners are incentivized to spam the network with low(ish)
fee transactions, thereby forcing regular users into paying extremely
high fees to be able to get their transactions confirmed.

Obviously this is the result of insufficient mining decentralization,
but as I will try to show, such an attack could be profitable even if
you are controlling just 5-10% of the hashing power, which could
always be easy for a big player and with some collusion.

Let's look at some numbers: https://i.imgur.com/sCn4eDG.png

These are 10 blocks mined yesterday, and they all have rewards hugely
exceeding the normal 12.5 mining output. Even taking the lowest value
of 20, it's a nice 60% extra profit for the miner. Let's say you
control 10% of the hashing power, and you spam enough transactions to
fill 144 blocks (1 day's worth) at 50 satoshi/byte, losing just 72 BTC
in fees.

(blocksize-in-bytes * fee-per-byte * Nblocks)/satoshis-in-btc => (1e6
* 50 * 144)/1e8 => 72

At the same time you will discover about 144*0.1=14.4 blocks per day.
Assuming the situation we see in the previous screenshot is what
happens when you have a mempool bigger than one day's worth of blocks,
you would get 20-12.5=7.5 extra BTC per block, which is 14.4*7.5=108
BTC, given your investment of 72 to spam the mempool. 32 btc extra
profit.

The big assumption here is that spamming 1 day of backlog in the
50satoshi/b range will get people to compete enough to push 7.5 btc of
fees in each block, but:

* https://jochen-hoenicke.de/queue/#30d this seems to confirm that
about half the mempool is in the 50satoshi/b range or less.
* https://blockchain.info/pools there are miners that control more than 10%
* if you get enough new real transactions, it's not necessary to spam
a full 144 blocks worth each day, probably just ~50 would be enough,
cutting the spam cost substantially
* other miners could be playing the same game, helping you spam and
further reduce the costs of the attack
* you actually get 10% of the fees back by avoiding mining your spam
transactions in your own blocks
* most of the spam transactions won't actually end up in blocks if
there is enough pressure coming from real usage

This seems to indicate that you would actually get much higher profit
margins than my estimates. **PLEASE** correct me if my calculations or
my assumptions are wrong.

You might also say that doing this would force users out of the
system, decreasing the value of btc and disincentivizing miners from
continuing. On the other hand, a backlogged mempool could create the
impression of high(er) usage and increase scarcity by slowing down
movements, which could actually push the price upwards.

Of course, it's impossible to prove that this is happening. But the
fact that it is profitable makes me believe that it is happening.

I see some solutions to this, all with their own downsides:

- increasing block size every time there is sustained pressure
this attack wouldn't work, but the downsides have already been
discussed to death.

- change POW
Not clear it would fix this, aside from stimulating terrible
infighting. Controlling 5 to 10% of the hashing power seems too easy,
and I don't think it would be practical to change pow every time that
happens, as it would prevent the development of a solid POW support.

- protocol level MAX transaction fee
I personally think this would totally invalidate the attack by making
the spam more expensive than the fees you would recover.
There already is a minimum fee accepted by the nodes, at 1 satoshi per
byte. The maximum fee could be N times the minimum, maybe 100-200.
Meaning a maximum of 1-2btc in total fee rewards when the block size
is 1mb. Of course the actual values need more analysis, but 2btc -
together with the deflationary structure - seems enough to continue
motivating miners, without giving unfair advantage.

Yes, this would make it impossible to spend your way out of a
congested mempool. But if the mempool stays congested after this
change, you could have a bigger confidence that it's coming from real
usage or from someone willfully burning money, making a block size
increase much more justified.

Hope to hear your opinion,
have a nice day.

oscar

From willtech at live.com.au  Fri Dec 22 06:22:40 2017
From: willtech at live.com.au (Damian Williamson)
Date: Fri, 22 Dec 2017 06:22:40 +0000
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction
 Priority For Ordering Transactions In Blocks
In-Reply-To: <PS2P216MB017991D78147E2B1EC14C3059D0F0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
References: <PS2P216MB01794ABD544248B27BF0DFD99D330@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<PS2P216MB01795BFC05612E021CCEDD7C9D0B0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<5upGmF0IhXUWhcikhdV-e9Pqg-kXfUuXe0kOpGxumie_TO2jLvCgTZ5c6vgBRtaqkL6DmOJb1YftK0osufB5RkhW7YhAhhCI0zBTH3YcORY=@protonmail.com>
	<PS2P216MB0179544A6503C2992190CEB69D0B0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<PS2P216MB0179D6A5965D0CFFEFB2880A9D090@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>,
	<AB6BF756-29F1-4442-85A9-B81228E829EC@friedenbach.org>,
	<PS2P216MB017991D78147E2B1EC14C3059D0F0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
Message-ID: <PS2P216MB0179FC39F4A63A43BB70011A9D020@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>

If the cash value of Bitcoin was high enough and zero fee transactions were never accepted and not counted when calculating the transaction pool size then I do not think it would be such an issue. Why is it even possible to create zero fee transactions?


Regards,

Damian Williamson

________________________________
From: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>
Sent: Tuesday, 19 December 2017 6:51 PM
To: Mark Friedenbach
Cc: bitcoin-dev at lists.linuxfoundation.org
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks


Thank you for your constructive feedback. I now see that the proposal introduces a potential issue.


>Finally in terms of the broad goal, having block size based on the number of transactions is NOT something desirable in the first place, even if it did work. That?s effectively the same as an infinite block size since anyone anywhere can create transactions in the mempool at no cost.


Do you have any critical suggestion as to how transaction bandwidth limit could be addressed, it will eventually become an issue if nothing is changed regardless of how high fees go?


Regards,

Damian Williamson



________________________________
From: Mark Friedenbach <mark at friedenbach.org>
Sent: Tuesday, 19 December 2017 3:08 AM
To: Damian Williamson
Subject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks

Damian, you seem to be misunderstanding that either

(1) the strong form of your proposal requires validating the commitment to the mempool properties, in which case the mempool becomes consensus critical (an impossible requirement); or

(2) in the weak form where the current block is dependent on the commitment in the last block only it is becomes a miner-selected field they can freely parameterize with no repercussions for setting values totally independent of the actual mempool.

If you want to make the block size dependent on the properties of the mempool in a consensus critical way, flex cap achieves this. If you want to make the contents or properties of the mempool known to well-connected nodes, weak blocks achieves that. But you can?t stick the mempool in consensus because it fundamentally is not something the nodes have consensus over. That?s a chicken-and-the-egg assumption.

Finally in terms of the broad goal, having block size based on the number of transactions is NOT something desirable in the first place, even if it did work. That?s effectively the same as an infinite block size since anyone anywhere can create transactions in the mempool at no cost.

On Dec 16, 2017, at 8:14 PM, Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:

I do not know why people make the leap that the proposal requires a consensus on the transaction pool. It does not.

It may be helpful to have the discussion from the previous thread linked here.
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/015370.html

Where I speak of validating that a block conforms to the broadcast next block size, I do not propose validating the number broadcast for the next block size itself, only that the next generated block is that size.

Regards,
Damian Williamson


________________________________
From: Damian Williamson <willtech at live.com.au<mailto:willtech at live.com.au>>
Sent: Saturday, 16 December 2017 7:59 AM
To: Rhavar
Cc: Bitcoin Protocol Discussion
Subject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks

There are really two separate problems to solve.


  1.  How does Bitcoin scale with fixed block size?
  2.  How do we ensure that all valid transactions are eventually included in the blockchain?

Those are the two issues that the proposal attempts to address. It makes sense to resolve these two problems together. Using the proposed system for variable block sizes would solve the first problem but there would still be a whole bunch of never confirming transactions. I am not sure how to reliably solve the second problem at scale without first solving the first.

>* Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.

I do not suggest a consensus. Depending on which node solves a block the value for next block size will be different. The consensus would be that blocks will adhere to the next block size value transmitted with the current block. It is easy to verify that the consensus is being adhered to once in place.

>* Increasing the entropy in a block to make it more unpredictable doesn't really make sense.

Not a necessary function, just an effect of using a probability-based distribution.

>* Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by "priority".  What are you going to do if a "malicious" miner decides to go after their profits and order by what makes them the most money. Add "ordered by priority" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.

I entirely agree with your sentiment that Bitcoin must be incentive compatible. It is necessary.

It is in only miners immediate interest to make the most profitable block from the available transaction pool. As with so many other things, it is necessary to partially ignore short-term gain for long-term benefit. It is in miners and everybody's long-term interest to have a reliable transaction service. A busy transaction service that confirms lots of transactions per hour will become more profitable as demand increases and more users are prepared to pay for priority. As it is there is currently no way to fully scale because of the transaction bandwidth limit and that is problematic. If all valid transactions must eventually confirm then there must be a way to resolve that problem.

Bitcoin deliberately removes traditional scale by ensuring blocks take ten minutes on average to solve, an ingenious idea and, incentive compatible but, fixed block sizes leaves us with a problem to solve when we want to scale.

>If you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.

I am confident that the math to verify blocks based on the proposal can be developed (and I think it will not be too complex for a mathematician with the relevant experience), however, I am nowhere near experienced enough with probability and statistical analysis to do it. Yes, if Bitcoin doesn't then it might make another great opportunity for an altcoin but I am not even nearly interested in promoting any altcoins.

If not the proposal that I have put forward, then, hopefully, someone can come up with a better solution. The important thing is that the issues are resolved.

Regards,
Damian Williamson


________________________________
From: Rhavar <rhavar at protonmail.com<mailto:rhavar at protonmail.com>>
Sent: Saturday, 16 December 2017 3:38 AM
To: Damian Williamson
Cc: Bitcoin Protocol Discussion
Subject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks

> I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?

Unfortunately your proposal is really fundamentally broken, on a few levels. I think you might need to do a bit more research into how bitcoin works before coming up with such improvements =)

But just some quick notes:

* Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.

* Increasing the entropy in a block to make it more unpredictable doesn't really make sense.

* Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by "priority".  What are you going to do if a "malicious" miner decides to go after their profits and order by what makes them the most money. Add "ordered by priority" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.

If you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.




-Ryan


-------- Original Message --------
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks
Local Time: December 15, 2017 3:42 AM
UTC Time: December 15, 2017 9:42 AM
From: bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>
To: Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>>



I should not take it that the lack of critical feedback to this revised proposal is a glowing endorsement. I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?

I suppose that it if is difficult to determine how long a transaction has been waiting in the pool then, each node could simply keep track of when a transaction was first seen. This may have implications for a verify routine, however, for example, if a node was offline, how should it differentiate how long each transaction was waiting in that case? If a node was restarted daily would it always think that all transactions had been waiting in the pool less than one day If each node keeps the current transaction pool in a file and updates it, as transactions are included in blocks and, as new transactions appear in the pool, then that would go some way to alleviate the issue, apart from entirely new nodes. There should be no reason the contents of a transaction pool files cannot be shared without agreement as to the transaction pool between nodes, just as nodes transmit new transactions freely.

It has been questioned why miners could not cheat. For the question of how many transactions to include in a block, I say it is a standoff and miners will conform to the proposal, not wanting to leave transactions with valid fees standing, and, not wanting to shrink the transaction pool. In any case, if miners shrink the transaction pool then I am not immediately concerned since it provides a more efficient service. For the question of including transactions according to the proposal, I say if it is possible to keep track of how long transactions are waiting in the pool so that they can be included on a probability curve then it is possible to verify that blocks conform to the proposal, since the input is a probability, the output should conform to a probability curve.


If someone has the necessary skill, would anyone be willing to develop the math necessary for the proposal?

Regards,
Damian Williamson


________________________________

From: bitcoin-dev-bounces at lists.linuxfoundation.org<mailto:bitcoin-dev-bounces at lists.linuxfoundation.org> <bitcoin-dev-bounces at lists.linuxfoundation.org<mailto:bitcoin-dev-bounces at lists.linuxfoundation.org>> on behalf of Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>>
Sent: Friday, 8 December 2017 8:01 AM
To: bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks


Good afternoon,

The need for this proposal:

We all must learn to admit that transaction bandwidth is still lurking as a serious issue for the operation, reliability, safety, consumer acceptance, uptake and, for the value of Bitcoin.

I recently sent a payment which was not urgent so; I chose three-day target confirmation from the fee recommendation. That transaction has still not confirmed after now more than six days - even waiting twice as long seems quite reasonable to me. That transaction is a valid transaction; it is not rubbish, junk or, spam. Under the current model with transaction bandwidth limitation, the longer a transaction waits, the less likely it is ever to confirm due to rising transaction numbers and being pushed back by transactions with rising fees.

I argue that no transactions are rubbish or junk, only some zero fee transactions might be spam. Having an ever-increasing number of valid transactions that do not confirm as more new transactions with higher fees are created is the opposite of operating a robust, reliable transaction system.

Business cannot operate with a model where transactions may or may not confirm. Even a business choosing a modest fee has no guarantee that their valid transaction will not be shuffled down by new transactions to the realm of never confirming after it is created. Consumers also will not accept this model as Bitcoin expands. If Bitcoin cannot be a reliable payment system for confirmed transactions then consumers, by and large, will simply not accept the model once they understand. Bitcoin will be a dirty payment system, and this will kill the value of Bitcoin.

Under the current system, a minority of transactions will eventually be the lucky few who have fees high enough to escape being pushed down the list.

Once there are more than x transactions (transaction bandwidth limit) every ten minutes, only those choosing twenty-minute confirmation (2 blocks) will have initially at most a fifty percent chance of ever having their payment confirm. Presently, not even using fee recommendations can ensure a sufficiently high fee is paid to ensure transaction confirmation.

I also argue that the current auction model for limited transaction bandwidth is wrong, is not suitable for a reliable transaction system and, is wrong for Bitcoin. All transactions must confirm in due time. Currently, Bitcoin is not a safe way to send payments.

I do not believe that consumers and business are against paying fees, even high fees. What is required is operational reliability.

This great issue needs to be resolved for the safety and reliability of Bitcoin. The time to resolve issues in commerce is before they become great big issues. The time to resolve this issue is now. We must have the foresight to identify and resolve problems before they trip us over.  Simply doubling block sizes every so often is reactionary and is not a reliable permanent solution. I have written a BIP proposal for a technical solution but, need your help to write it up to an acceptable standard to be a full BIP.

I have formatted the following with markdown which is human readable so, I hope nobody minds. I have done as much with this proposal as I feel that I am able so far but continue to take your feedback.

# BIP Proposal: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks

## The problem:
Everybody wants value. Miners want to maximize revenue from fees (and we presume, to minimize block size). Consumers need transaction reliability and, (we presume) want low fees.

The current transaction bandwidth limit is a limiting factor for both. As the operational safety of transactions is limited, so is consumer confidence as they realize the issue and, accordingly, uptake is limited. Fees are artificially inflated due to bandwidth limitations while failing to provide a full confirmation service for all transactions.

Current fee recommendations provide no satisfaction for transaction reliability and, as Bitcoin scales, this will worsen.

Bitcoin must be a fully scalable and reliable service, providing full transaction confirmation for every valid transaction.

The possibility to send a transaction with a fee lower than one that is acceptable to allow eventual transaction confirmation should be removed from the protocol and also from the user interface.

## Solution summary:
Provide each transaction with an individual transaction priority each time before choosing transactions to include in the current block, the priority being a function of the fee paid (on a curve), and the time waiting in the transaction pool (also on a curve) out to n days (n=60 ?). The transaction priority to serve as the likelihood of a transaction being included in the current block, and for determining the order in which transactions are tried to see if they will be included.

Use a target block size. Determine the target block size using; current transaction pool size x ( 1 / (144 x n days ) ) = number of transactions to be included in the current block. Broadcast the next target block size with the current block when it is solved so that nodes know the next target block size for the block that they are building on.

The curves used for the priority of transactions would have to be appropriate. Perhaps a mathematician with experience in probability can develop the right formulae. My thinking is a steep curve. I suppose that the probability of all transactions should probably account for a sufficient number of inclusions that the target block size is met although, it may not always be. As a suggestion, consider including some zero fee transactions to pad, highest BTC value first?

**Explanation of the operation of priority:**
> If transaction priority is, for example, a number between one (low) and one-hundred (high) it can be directly understood as the percentage chance in one-hundred of a transaction being included in the block. Using probability or likelihood infers that there is some function of random. If random (100) < transaction priority then the transaction is included.

>To break it down further, if both the fee on a curve value and the time waiting on a curve value are each a number between one and one-hundred, a rudimentary method may be to simply multiply those two numbers, to find the priority number. For example, a middle fee transaction waiting thirty days (if n = 60 days) may have a value of five for each part  (yes, just five, the values are on a curve). When multiplied that will give a priority value of twenty-five, or,  a twenty-five percent chance at that moment of being included in the block; it will likely be included in one of the next four blocks, getting more likely each chance. If it is still not included then the value of time waiting will be higher, making for more probability. A very low fee transaction would have a value for the fee of one. It would not be until near sixty-days that the particular low fee transaction has a high likelihood of being included in the block.

I am not concerned with low (or high) transaction fees, the primary reason for addressing the issue is to ensure transactional reliability and scalability while having each transaction confirm in due time.

## Pros:
* Maximizes transaction reliability.
* Fully scalable.
* Maximizes possibility for consumer and business uptake.
* Maximizes total fees paid per block without reducing reliability; because of reliability, in time confidence and overall uptake are greater; therefore, more transactions.
* Market determines fee paid for transaction priority.
* Fee recommendations work all the way out to 30 days or greater.
* Provides additional block entropy; greater security since there is less probability of predicting the next block.

## Cons:
* Could initially lower total transaction fees per block.
* Must be first be programmed.

## Solution operation:
This is a simplistic view of the operation. The actual operation will need to be determined in a spec for the programmer.

1. Determine the target block size for the current block.
2. Assign a transaction priority to each transaction in the pool.
3. Select transactions to include in the current block using probability in transaction priority order until the target block size is met.
5. Solve block.
6. Broadcast the next target block size with the current block when it is solved.
7. Block is received.
8. Block verification process.
9. Accept/reject block based on verification result.
10. Repeat.

## Closing comments:
It may be possible to verify blocks conform to the proposal by showing that the probability for all transactions included in the block statistically conforms to a probability distribution curve, *if* the individual transaction priority can be recreated. I am not that deep into the mathematics; however, it may also be possible to use a similar method to do this just based on the fee, that statistically, the blocks conform to a fee distribution. Any zero fee transactions would have to be ignored. This solution needs a clever mathematician.

I implore, at the very least, that we use some method that validates full transaction reliability and enables scalability of block sizes. If not this proposal, an alternative.

Regards,
Damian Williamson


_______________________________________________
bitcoin-dev mailing list
bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>
https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171222/5a0d006a/attachment-0001.html>

From spartacusrex99 at gmail.com  Fri Dec 22 18:07:49 2017
From: spartacusrex99 at gmail.com (Spartacus Rex)
Date: Fri, 22 Dec 2017 18:07:49 +0000
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction
 Priority For Ordering Transactions In Blocks
In-Reply-To: <PS2P216MB0179FC39F4A63A43BB70011A9D020@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
References: <PS2P216MB01794ABD544248B27BF0DFD99D330@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<PS2P216MB01795BFC05612E021CCEDD7C9D0B0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<5upGmF0IhXUWhcikhdV-e9Pqg-kXfUuXe0kOpGxumie_TO2jLvCgTZ5c6vgBRtaqkL6DmOJb1YftK0osufB5RkhW7YhAhhCI0zBTH3YcORY=@protonmail.com>
	<PS2P216MB0179544A6503C2992190CEB69D0B0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<PS2P216MB0179D6A5965D0CFFEFB2880A9D090@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<AB6BF756-29F1-4442-85A9-B81228E829EC@friedenbach.org>
	<PS2P216MB017991D78147E2B1EC14C3059D0F0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<PS2P216MB0179FC39F4A63A43BB70011A9D020@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CA+Cf5AaX5a5yuLcnkk=7boiqrSrZf4KG_RjSOF1-2qJtB9ds+Q@mail.gmail.com>

Hi Damian,

Thought I'd chip in.  This is a hard fork scenario. This system has flaws,
they all do.

If you had a fixed fee per block, so that every txn in that block paid the
same fee, that might make it easier to include all txns eventually, as you
envisage.

The fee could be calculated as the average of the amount txns are prepared
to pay in the last 1000 blocks.

A txn would say ' I'll pay up to X bitcoins ' and as long as that is more
than the value required for the block your txn can be added. This is to
ensure you don't pay more than you are willing.  It also ensures that
putting an enormous fee will not ensure your txn is processed quickly..

Calculating what the outputs are given a variable fee needs a new mechanism
all of it's own, but I'm sure it's possible.

The simple fact is that there is currently no known system that works as
well as the current system..

But there are other systems.


On Dec 22, 2017 15:09, "Damian Williamson via bitcoin-dev" <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> If the cash value of Bitcoin was high enough and zero fee transactions
> were never accepted and not counted when calculating the transaction pool
> size then I do not think it would be such an issue. Why is it even possible
> to create zero fee transactions?
>
>
> Regards,
>
> Damian Williamson
>
> ------------------------------
> *From:* bitcoin-dev-bounces at lists.linuxfoundation.org <
> bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Damian
> Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>
> *Sent:* Tuesday, 19 December 2017 6:51 PM
> *To:* Mark Friedenbach
> *Cc:* bitcoin-dev at lists.linuxfoundation.org
> *Subject:* [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use
> Transaction Priority For Ordering Transactions In Blocks
>
>
> Thank you for your constructive feedback. I now see that the proposal
> introduces a potential issue.
>
>
> >Finally in terms of the broad goal, having block size based on the number
> of transactions is NOT something desirable in the first place, even if it
> did work. That?s effectively the same as an infinite block size since
> anyone anywhere can create transactions in the mempool at no cost.
>
>
> Do you have any critical suggestion as to how transaction bandwidth limit
> could be addressed, it will eventually become an issue if nothing is
> changed regardless of how high fees go?
>
>
> Regards,
> Damian Williamson
>
>
>
> ------------------------------
> *From:* Mark Friedenbach <mark at friedenbach.org>
> *Sent:* Tuesday, 19 December 2017 3:08 AM
> *To:* Damian Williamson
> *Subject:* Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use
> Transaction Priority For Ordering Transactions In Blocks
>
> Damian, you seem to be misunderstanding that either
>
> (1) the strong form of your proposal requires validating the commitment to
> the mempool properties, in which case the mempool becomes consensus
> critical (an impossible requirement); or
>
> (2) in the weak form where the current block is dependent on the
> commitment in the last block only it is becomes a miner-selected field they
> can freely parameterize with no repercussions for setting values totally
> independent of the actual mempool.
>
> If you want to make the block size dependent on the properties of the
> mempool in a consensus critical way, flex cap achieves this. If you want to
> make the contents or properties of the mempool known to well-connected
> nodes, weak blocks achieves that. But you can?t stick the mempool in
> consensus because it fundamentally is not something the nodes have
> consensus over. That?s a chicken-and-the-egg assumption.
>
> Finally in terms of the broad goal, having block size based on the number
> of transactions is NOT something desirable in the first place, even if it
> did work. That?s effectively the same as an infinite block size since
> anyone anywhere can create transactions in the mempool at no cost.
>
> On Dec 16, 2017, at 8:14 PM, Damian Williamson via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
> I do not know why people make the leap that the proposal requires a
> consensus on the transaction pool. It does not.
>
> It may be helpful to have the discussion from the previous thread linked
> here.
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/
> 2017-December/015370.html
>
> Where I speak of validating that a block conforms to the broadcast next
> block size, I do not propose validating the number broadcast for the next
> block size itself, only that the next generated block is that size.
>
> Regards,
> Damian Williamson
>
>
> ------------------------------
> *From:* Damian Williamson <willtech at live.com.au>
> *Sent:* Saturday, 16 December 2017 7:59 AM
> *To:* Rhavar
> *Cc:* Bitcoin Protocol Discussion
> *Subject:* Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use
> Transaction Priority For Ordering Transactions In Blocks
>
> There are really two separate problems to solve.
>
>
>    1. How does Bitcoin scale with fixed block size?
>    2. How do we ensure that all valid transactions are eventually
>    included in the blockchain?
>
>
> Those are the two issues that the proposal attempts to address. It makes
> sense to resolve these two problems together. Using the proposed system for
> variable block sizes would solve the first problem but there would still be
> a whole bunch of never confirming transactions. I am not sure how to
> reliably solve the second problem at scale without first solving the first.
>
> >* Every node has a (potentially) different mempool, you can't use it to
> decide consensus values like the max block size.
>
> I do not suggest a consensus. Depending on which node solves a block the
> value for next block size will be different. The consensus would be that
> blocks will adhere to the next block size value transmitted with the
> current block. It is easy to verify that the consensus is being adhered to
> once in place.
>
> >* Increasing the entropy in a block to make it more unpredictable doesn't
> really make sense.
>
> Not a necessary function, just an effect of using a probability-based
> distribution.
>
> >* Bitcoin should be roughly incentive compatible. Your proposal explicits
> asks miners to ignore their best interests, and confirm transactions by
> "priority".  What are you going to do if a "malicious" miner decides to go
> after their profits and order by what makes them the most money. Add
> "ordered by priority" as a consensus requirement? And even if you miners
> can still sort their mempool by fee, and then order the top 1MB by priority.
>
> I entirely agree with your sentiment that Bitcoin must be incentive
> compatible. It is necessary.
>
> It is in only miners immediate interest to make the most profitable block
> from the available transaction pool. As with so many other things, it is
> necessary to partially ignore short-term gain for long-term benefit. It is
> in miners and everybody's long-term interest to have a reliable transaction
> service. A busy transaction service that confirms lots of transactions per
> hour will become more profitable as demand increases and more users are
> prepared to pay for priority. As it is there is currently no way to fully
> scale because of the transaction bandwidth limit and that is problematic.
> If all valid transactions must eventually confirm then there must be a way
> to resolve that problem.
>
> Bitcoin deliberately removes traditional scale by ensuring blocks take ten
> minutes on average to solve, an ingenious idea and, incentive compatible
> but, fixed block sizes leaves us with a problem to solve when we want to
> scale.
>
> >If you could find a good solution that would allow you to know if miners
> were following your rule or not (and thus ignore it if it doesn't) then you
> wouldn't even need bitcoin in the first place.
>
> I am confident that the math to verify blocks based on the proposal can be
> developed (and I think it will not be too complex for a mathematician with
> the relevant experience), however, I am nowhere near experienced enough
> with probability and statistical analysis to do it. Yes, if Bitcoin doesn't
> then it might make another great opportunity for an altcoin but I am not
> even nearly interested in promoting any altcoins.
>
>
> If not the proposal that I have put forward, then, hopefully, someone can
> come up with a better solution. The important thing is that the issues are
> resolved.
>
> Regards,
> Damian Williamson
>
>
> ------------------------------
> *From:* Rhavar <rhavar at protonmail.com>
> *Sent:* Saturday, 16 December 2017 3:38 AM
> *To:* Damian Williamson
> *Cc:* Bitcoin Protocol Discussion
> *Subject:* Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use
> Transaction Priority For Ordering Transactions In Blocks
>
> > I understand that there would be technical issues to resolve in
> implementation, but, are there no fundamental errors?
>
> Unfortunately your proposal is really fundamentally broken, on a few
> levels. I think you might need to do a bit more research into how bitcoin
> works before coming up with such improvements =)
>
> But just some quick notes:
>
> * Every node has a (potentially) different mempool, you can't use it to
> decide consensus values like the max block size.
>
> * Increasing the entropy in a block to make it more unpredictable doesn't
> really make sense.
>
> * Bitcoin should be roughly incentive compatible. Your proposal explicits
> asks miners to ignore their best interests, and confirm transactions by
> "priority".  What are you going to do if a "malicious" miner decides to go
> after their profits and order by what makes them the most money. Add
> "ordered by priority" as a consensus requirement? And even if you miners
> can still sort their mempool by fee, and then order the top 1MB by priority.
>
> If you could find a good solution that would allow you to know if miners
> were following your rule or not (and thus ignore it if it doesn't) then you
> wouldn't even need bitcoin in the first place.
>
>
>
>
> -Ryan
>
>
> -------- Original Message --------
> Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction
> Priority For Ordering Transactions In Blocks
> Local Time: December 15, 2017 3:42 AM
> UTC Time: December 15, 2017 9:42 AM
> From: bitcoin-dev at lists.linuxfoundation.org
> To: Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>
>
>
>
> I should not take it that the lack of critical feedback to this revised
> proposal is a glowing endorsement. I understand that there would be
> technical issues to resolve in implementation, but, are there no
> fundamental errors?
>
> I suppose that it if is difficult to determine how long a transaction has
> been waiting in the pool then, each node could simply keep track of when a
> transaction was first seen. This may have implications for a verify
> routine, however, for example, if a node was offline, how should it
> differentiate how long each transaction was waiting in that case? If a node
> was restarted daily would it always think that all transactions had been
> waiting in the pool less than one day If each node keeps the current
> transaction pool in a file and updates it, as transactions are included in
> blocks and, as new transactions appear in the pool, then that would go some
> way to alleviate the issue, apart from entirely new nodes. There should be
> no reason the contents of a transaction pool files cannot be shared without
> agreement as to the transaction pool between nodes, just as nodes
> transmit new transactions freely.
>
> It has been questioned why miners could not cheat. For the question of how
> many transactions to include in a block, I say it is a standoff and miners
> will conform to the proposal, not wanting to leave transactions with valid
> fees standing, and, not wanting to shrink the transaction pool. In any
> case, if miners shrink the transaction pool then I am not immediately
> concerned since it provides a more efficient service. For the question of
> including transactions according to the proposal, I say if it is possible
> to keep track of how long transactions are waiting in the pool so that they
> can be included on a probability curve then it is possible to verify that
> blocks conform to the proposal, since the input is a probability, the
> output should conform to a probability curve.
>
>
> If someone has the necessary skill, would anyone be willing to develop the
> math necessary for the proposal?
>
> Regards,
> Damian Williamson
>
>
> ------------------------------
>
> *From:* bitcoin-dev-bounces at lists.linuxfoundation.org <bit
> coin-dev-bounces at lists.linuxfoundation.org> on behalf of Damian
> Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>
> *Sent:* Friday, 8 December 2017 8:01 AM
> *To:* bitcoin-dev at lists.linuxfoundation.org
> *Subject:* [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use
> Transaction Priority For Ordering Transactions In Blocks
>
>
> Good afternoon,
>
> The need for this proposal:
>
> We all must learn to admit that transaction bandwidth is still lurking as
> a serious issue for the operation, reliability, safety, consumer
> acceptance, uptake and, for the value of Bitcoin.
>
> I recently sent a payment which was not urgent so; I chose three-day
> target confirmation from the fee recommendation. That transaction has still
> not confirmed after now more than six days - even waiting twice as long
> seems quite reasonable to me. That transaction is a valid transaction; it
> is not rubbish, junk or, spam. Under the current model with transaction
> bandwidth limitation, the longer a transaction waits, the less likely it is
> ever to confirm due to rising transaction numbers and being pushed back by
> transactions with rising fees.
>
> I argue that no transactions are rubbish or junk, only some zero fee
> transactions might be spam. Having an ever-increasing number of valid
> transactions that do not confirm as more new transactions with higher fees
> are created is the opposite of operating a robust, reliable transaction
> system.
>
> Business cannot operate with a model where transactions may or may not
> confirm. Even a business choosing a modest fee has no guarantee that their
> valid transaction will not be shuffled down by new transactions to the
> realm of never confirming after it is created. Consumers also will not
> accept this model as Bitcoin expands. If Bitcoin cannot be a reliable
> payment system for confirmed transactions then consumers, by and large,
> will simply not accept the model once they understand. Bitcoin will be a
> dirty payment system, and this will kill the value of Bitcoin.
>
> Under the current system, a minority of transactions will eventually be
> the lucky few who have fees high enough to escape being pushed down the
> list.
>
> Once there are more than x transactions (transaction bandwidth limit)
> every ten minutes, only those choosing twenty-minute confirmation (2
> blocks) will have initially at most a fifty percent chance of ever having
> their payment confirm. Presently, not even using fee recommendations can
> ensure a sufficiently high fee is paid to ensure transaction confirmation.
>
> I also argue that the current auction model for limited transaction
> bandwidth is wrong, is not suitable for a reliable transaction system and,
> is wrong for Bitcoin. All transactions must confirm in due time. Currently,
> Bitcoin is not a safe way to send payments.
>
> I do not believe that consumers and business are against paying fees, even
> high fees. What is required is operational reliability.
>
> This great issue needs to be resolved for the safety and reliability of
> Bitcoin. The time to resolve issues in commerce is before they become great
> big issues. The time to resolve this issue is now. We must have the
> foresight to identify and resolve problems before they trip us over.
> Simply doubling block sizes every so often is reactionary and is not a
> reliable permanent solution. I have written a BIP proposal for a technical
> solution but, need your help to write it up to an acceptable standard to be
> a full BIP.
>
> I have formatted the following with markdown which is human readable so, I
> hope nobody minds. I have done as much with this proposal as I feel that I
> am able so far but continue to take your feedback.
>
> # BIP Proposal: UTPFOTIB - Use Transaction Priority For Ordering
> Transactions In Blocks
>
> ## The problem:
> Everybody wants value. Miners want to maximize revenue from fees (and we
> presume, to minimize block size). Consumers need transaction reliability
> and, (we presume) want low fees.
>
> The current transaction bandwidth limit is a limiting factor for both. As
> the operational safety of transactions is limited, so is consumer
> confidence as they realize the issue and, accordingly, uptake is limited.
> Fees are artificially inflated due to bandwidth limitations while failing
> to provide a full confirmation service for all transactions.
>
> Current fee recommendations provide no satisfaction for transaction
> reliability and, as Bitcoin scales, this will worsen.
>
> Bitcoin must be a fully scalable and reliable service, providing full
> transaction confirmation for every valid transaction.
>
> The possibility to send a transaction with a fee lower than one that is
> acceptable to allow eventual transaction confirmation should be removed
> from the protocol and also from the user interface.
>
> ## Solution summary:
> Provide each transaction with an individual transaction priority each time
> before choosing transactions to include in the current block, the priority
> being a function of the fee paid (on a curve), and the time waiting in the
> transaction pool (also on a curve) out to n days (n=60 ?). The transaction
> priority to serve as the likelihood of a transaction being included in the
> current block, and for determining the order in which transactions are
> tried to see if they will be included.
>
> Use a target block size. Determine the target block size using; current
> transaction pool size x ( 1 / (144 x n days ) ) = number of transactions to
> be included in the current block. Broadcast the next target block size with
> the current block when it is solved so that nodes know the next target
> block size for the block that they are building on.
>
> The curves used for the priority of transactions would have to be
> appropriate. Perhaps a mathematician with experience in probability can
> develop the right formulae. My thinking is a steep curve. I suppose that
> the probability of all transactions should probably account for a
> sufficient number of inclusions that the target block size is met although,
> it may not always be. As a suggestion, consider including some zero fee
> transactions to pad, highest BTC value first?
>
> **Explanation of the operation of priority:**
> > If transaction priority is, for example, a number between one (low) and
> one-hundred (high) it can be directly understood as the percentage chance
> in one-hundred of a transaction being included in the block. Using
> probability or likelihood infers that there is some function of random. If
> random (100) < transaction priority then the transaction is included.
>
> >To break it down further, if both the fee on a curve value and the time
> waiting on a curve value are each a number between one and one-hundred, a
> rudimentary method may be to simply multiply those two numbers, to find the
> priority number. For example, a middle fee transaction waiting thirty days
> (if n = 60 days) may have a value of five for each part  (yes, just five,
> the values are on a curve). When multiplied that will give a priority value
> of twenty-five, or,  a twenty-five percent chance at that moment of being
> included in the block; it will likely be included in one of the next four
> blocks, getting more likely each chance. If it is still not included then
> the value of time waiting will be higher, making for more probability. A
> very low fee transaction would have a value for the fee of one. It would
> not be until near sixty-days that the particular low fee transaction has a
> high likelihood of being included in the block.
>
> I am not concerned with low (or high) transaction fees, the primary reason
> for addressing the issue is to ensure transactional reliability and
> scalability while having each transaction confirm in due time.
>
> ## Pros:
> * Maximizes transaction reliability.
> * Fully scalable.
> * Maximizes possibility for consumer and business uptake.
> * Maximizes total fees paid per block without reducing reliability;
> because of reliability, in time confidence and overall uptake are greater;
> therefore, more transactions.
> * Market determines fee paid for transaction priority.
> * Fee recommendations work all the way out to 30 days or greater.
> * Provides additional block entropy; greater security since there is less
> probability of predicting the next block.
>
> ## Cons:
> * Could initially lower total transaction fees per block.
> * Must be first be programmed.
>
> ## Solution operation:
> This is a simplistic view of the operation. The actual operation will need
> to be determined in a spec for the programmer.
>
> 1. Determine the target block size for the current block.
> 2. Assign a transaction priority to each transaction in the pool.
> 3. Select transactions to include in the current block using probability
> in transaction priority order until the target block size is met.
> 5. Solve block.
> 6. Broadcast the next target block size with the current block when it is
> solved.
> 7. Block is received.
> 8. Block verification process.
> 9. Accept/reject block based on verification result.
> 10. Repeat.
>
> ## Closing comments:
> It may be possible to verify blocks conform to the proposal by showing
> that the probability for all transactions included in the block
> statistically conforms to a probability distribution curve, *if* the
> individual transaction priority can be recreated. I am not that deep into
> the mathematics; however, it may also be possible to use a similar method
> to do this just based on the fee, that statistically, the blocks conform to
> a fee distribution. Any zero fee transactions would have to be ignored.
> This solution needs a clever mathematician.
>
> I implore, at the very least, that we use some method that validates full
> transaction reliability and enables scalability of block sizes. If not this
> proposal, an alternative.
>
> Regards,
> Damian Williamson
>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171222/01401d28/attachment-0001.html>

From vitteaymeric at gmail.com  Fri Dec 22 23:06:20 2017
From: vitteaymeric at gmail.com (Aymeric Vitte)
Date: Sat, 23 Dec 2017 00:06:20 +0100
Subject: [bitcoin-dev] BIP for Legacy Sign Verify functions
In-Reply-To: <4789faec-c6fb-3d05-1b4b-95ce7aefb373@gmail.com>
References: <CAAUFj100ULfTbEorSK2PF5nvW-R_TCMOiboBBEMj+eS5upgU8Q@mail.gmail.com>
	<201712212309.07243.luke@dashjr.org>
	<4789faec-c6fb-3d05-1b4b-95ce7aefb373@gmail.com>
Message-ID: <2b73d37b-812a-1653-a0be-e4b8c0fb6772@gmail.com>

Scriptsig not "sigscript" below

Now you must answer this question, because this is what we call a hard fork


Le 22/12/2017 ? 11:29, Aymeric Vitte a ?crit?:
>
> Le 22/12/2017 ? 00:09, Luke Dashjr via bitcoin-dev a ?crit?:
>> What is actually done, is using the signature + message to perform key 
>> recovery, to extract the public key of the signer, and then hashing that and 
>> comparing it to the address provided.
> I already posted about this, then what is doing the pubkey in sigscript
> for standard p2pkh transactions? (this was not the case some time ago)
>

-- 
Bitcoin transactions made simple: https://github.com/Ayms/bitcoin-transactions
Zcash wallets made simple: https://github.com/Ayms/zcash-wallets
Bitcoin wallets made simple: https://github.com/Ayms/bitcoin-wallets
Get the torrent dynamic blocklist: http://peersm.com/getblocklist
Check the 10 M passwords list: http://peersm.com/findmyass
Anti-spies and private torrents, dynamic blocklist: http://torrent-live.org
Peersm : http://www.peersm.com
torrent-live: https://github.com/Ayms/torrent-live
node-Tor : https://www.github.com/Ayms/node-Tor
GitHub : https://www.github.com/Ayms


From willtech at live.com.au  Sat Dec 23 01:24:28 2017
From: willtech at live.com.au (Damian Williamson)
Date: Sat, 23 Dec 2017 01:24:28 +0000
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction
 Priority For Ordering Transactions In Blocks
In-Reply-To: <AB6BF756-29F1-4442-85A9-B81228E829EC@friedenbach.org>
References: <PS2P216MB01794ABD544248B27BF0DFD99D330@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<PS2P216MB01795BFC05612E021CCEDD7C9D0B0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<5upGmF0IhXUWhcikhdV-e9Pqg-kXfUuXe0kOpGxumie_TO2jLvCgTZ5c6vgBRtaqkL6DmOJb1YftK0osufB5RkhW7YhAhhCI0zBTH3YcORY=@protonmail.com>
	<PS2P216MB0179544A6503C2992190CEB69D0B0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<PS2P216MB0179D6A5965D0CFFEFB2880A9D090@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>,
	<AB6BF756-29F1-4442-85A9-B81228E829EC@friedenbach.org>
Message-ID: <PS2P216MB0179EB4AAB0157A703C36ED09D030@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>

I suppose what I intended is (2) the weak form but, what is essentially needed is (1) the strong form. The answer may be somewhere in-between.


I do not see that an entire consensus for the mempool is needed, each node just needs a loose understanding of the average number of non-zero fee transactions in the mempool.


As a pre-rollout, it would be possible to give each node a serial ID and, calculate the average number of non-zero fee transactions from the information it has and, say every ten minutes, distribute information it has about the number of transactions in the mempool. Each node would be able to form its own picture of the average number of non-zero fee transactions in the mempool.


At rollout, this information would be the basis a node would use when a block is solved to provide the next expected block size. This would still not stop cheating by providing especially a number lower than the proposal would allow for, to game the system and hike fees. If miners will not act in the long-term interest of the stability and operation of the system then they should be ignored. If most miners will adhere to the proposal then the average effect would be stability in the operation of the proposal, having a few or even several nodes posting low numbers for the number of transactions expected in the next expected block size would not destroy the operation. If some node posted an insanely high number for next expected block size that resulted in the mempool being emptied then the proposal would be offended but I do not actually care. If no number is posted, just create a block the appropriate size ensure conformity. Nodes that have not adopted the proposal could just continue to create 1MB blocks.


Actually, the operation could be simplified using the distributed information directly to just create blocks of the appropriate size with no need to provide next block size. Flexible block size.


The proposal should also specify a minimum number of transactions to include for the next block to give at a minimum a 1MB block.


I currently have no information on flex cap, do you have a link?


Regards,

Damian Williamson


________________________________
From: Mark Friedenbach <mark at friedenbach.org>
Sent: Tuesday, 19 December 2017 3:08 AM
To: Damian Williamson
Subject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks

Damian, you seem to be misunderstanding that either

(1) the strong form of your proposal requires validating the commitment to the mempool properties, in which case the mempool becomes consensus critical (an impossible requirement); or

(2) in the weak form where the current block is dependent on the commitment in the last block only it is becomes a miner-selected field they can freely parameterize with no repercussions for setting values totally independent of the actual mempool.

If you want to make the block size dependent on the properties of the mempool in a consensus critical way, flex cap achieves this. If you want to make the contents or properties of the mempool known to well-connected nodes, weak blocks achieves that. But you can?t stick the mempool in consensus because it fundamentally is not something the nodes have consensus over. That?s a chicken-and-the-egg assumption.

Finally in terms of the broad goal, having block size based on the number of transactions is NOT something desirable in the first place, even if it did work. That?s effectively the same as an infinite block size since anyone anywhere can create transactions in the mempool at no cost.

On Dec 16, 2017, at 8:14 PM, Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:

I do not know why people make the leap that the proposal requires a consensus on the transaction pool. It does not.

It may be helpful to have the discussion from the previous thread linked here.
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/015370.html

Where I speak of validating that a block conforms to the broadcast next block size, I do not propose validating the number broadcast for the next block size itself, only that the next generated block is that size.

Regards,
Damian Williamson


________________________________
From: Damian Williamson <willtech at live.com.au<mailto:willtech at live.com.au>>
Sent: Saturday, 16 December 2017 7:59 AM
To: Rhavar
Cc: Bitcoin Protocol Discussion
Subject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks

There are really two separate problems to solve.


  1.  How does Bitcoin scale with fixed block size?
  2.  How do we ensure that all valid transactions are eventually included in the blockchain?

Those are the two issues that the proposal attempts to address. It makes sense to resolve these two problems together. Using the proposed system for variable block sizes would solve the first problem but there would still be a whole bunch of never confirming transactions. I am not sure how to reliably solve the second problem at scale without first solving the first.

>* Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.

I do not suggest a consensus. Depending on which node solves a block the value for next block size will be different. The consensus would be that blocks will adhere to the next block size value transmitted with the current block. It is easy to verify that the consensus is being adhered to once in place.

>* Increasing the entropy in a block to make it more unpredictable doesn't really make sense.

Not a necessary function, just an effect of using a probability-based distribution.

>* Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by "priority".  What are you going to do if a "malicious" miner decides to go after their profits and order by what makes them the most money. Add "ordered by priority" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.

I entirely agree with your sentiment that Bitcoin must be incentive compatible. It is necessary.

It is in only miners immediate interest to make the most profitable block from the available transaction pool. As with so many other things, it is necessary to partially ignore short-term gain for long-term benefit. It is in miners and everybody's long-term interest to have a reliable transaction service. A busy transaction service that confirms lots of transactions per hour will become more profitable as demand increases and more users are prepared to pay for priority. As it is there is currently no way to fully scale because of the transaction bandwidth limit and that is problematic. If all valid transactions must eventually confirm then there must be a way to resolve that problem.

Bitcoin deliberately removes traditional scale by ensuring blocks take ten minutes on average to solve, an ingenious idea and, incentive compatible but, fixed block sizes leaves us with a problem to solve when we want to scale.

>If you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.

I am confident that the math to verify blocks based on the proposal can be developed (and I think it will not be too complex for a mathematician with the relevant experience), however, I am nowhere near experienced enough with probability and statistical analysis to do it. Yes, if Bitcoin doesn't then it might make another great opportunity for an altcoin but I am not even nearly interested in promoting any altcoins.

If not the proposal that I have put forward, then, hopefully, someone can come up with a better solution. The important thing is that the issues are resolved.

Regards,
Damian Williamson


________________________________
From: Rhavar <rhavar at protonmail.com<mailto:rhavar at protonmail.com>>
Sent: Saturday, 16 December 2017 3:38 AM
To: Damian Williamson
Cc: Bitcoin Protocol Discussion
Subject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks

> I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?

Unfortunately your proposal is really fundamentally broken, on a few levels. I think you might need to do a bit more research into how bitcoin works before coming up with such improvements =)

But just some quick notes:

* Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.

* Increasing the entropy in a block to make it more unpredictable doesn't really make sense.

* Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by "priority".  What are you going to do if a "malicious" miner decides to go after their profits and order by what makes them the most money. Add "ordered by priority" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.

If you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.




-Ryan


-------- Original Message --------
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks
Local Time: December 15, 2017 3:42 AM
UTC Time: December 15, 2017 9:42 AM
From: bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>
To: Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>>



I should not take it that the lack of critical feedback to this revised proposal is a glowing endorsement. I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?

I suppose that it if is difficult to determine how long a transaction has been waiting in the pool then, each node could simply keep track of when a transaction was first seen. This may have implications for a verify routine, however, for example, if a node was offline, how should it differentiate how long each transaction was waiting in that case? If a node was restarted daily would it always think that all transactions had been waiting in the pool less than one day If each node keeps the current transaction pool in a file and updates it, as transactions are included in blocks and, as new transactions appear in the pool, then that would go some way to alleviate the issue, apart from entirely new nodes. There should be no reason the contents of a transaction pool files cannot be shared without agreement as to the transaction pool between nodes, just as nodes transmit new transactions freely.

It has been questioned why miners could not cheat. For the question of how many transactions to include in a block, I say it is a standoff and miners will conform to the proposal, not wanting to leave transactions with valid fees standing, and, not wanting to shrink the transaction pool. In any case, if miners shrink the transaction pool then I am not immediately concerned since it provides a more efficient service. For the question of including transactions according to the proposal, I say if it is possible to keep track of how long transactions are waiting in the pool so that they can be included on a probability curve then it is possible to verify that blocks conform to the proposal, since the input is a probability, the output should conform to a probability curve.


If someone has the necessary skill, would anyone be willing to develop the math necessary for the proposal?

Regards,
Damian Williamson


________________________________

From: bitcoin-dev-bounces at lists.linuxfoundation.org<mailto:bitcoin-dev-bounces at lists.linuxfoundation.org> <bitcoin-dev-bounces at lists.linuxfoundation.org<mailto:bitcoin-dev-bounces at lists.linuxfoundation.org>> on behalf of Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>>
Sent: Friday, 8 December 2017 8:01 AM
To: bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks


Good afternoon,

The need for this proposal:

We all must learn to admit that transaction bandwidth is still lurking as a serious issue for the operation, reliability, safety, consumer acceptance, uptake and, for the value of Bitcoin.

I recently sent a payment which was not urgent so; I chose three-day target confirmation from the fee recommendation. That transaction has still not confirmed after now more than six days - even waiting twice as long seems quite reasonable to me. That transaction is a valid transaction; it is not rubbish, junk or, spam. Under the current model with transaction bandwidth limitation, the longer a transaction waits, the less likely it is ever to confirm due to rising transaction numbers and being pushed back by transactions with rising fees.

I argue that no transactions are rubbish or junk, only some zero fee transactions might be spam. Having an ever-increasing number of valid transactions that do not confirm as more new transactions with higher fees are created is the opposite of operating a robust, reliable transaction system.

Business cannot operate with a model where transactions may or may not confirm. Even a business choosing a modest fee has no guarantee that their valid transaction will not be shuffled down by new transactions to the realm of never confirming after it is created. Consumers also will not accept this model as Bitcoin expands. If Bitcoin cannot be a reliable payment system for confirmed transactions then consumers, by and large, will simply not accept the model once they understand. Bitcoin will be a dirty payment system, and this will kill the value of Bitcoin.

Under the current system, a minority of transactions will eventually be the lucky few who have fees high enough to escape being pushed down the list.

Once there are more than x transactions (transaction bandwidth limit) every ten minutes, only those choosing twenty-minute confirmation (2 blocks) will have initially at most a fifty percent chance of ever having their payment confirm. Presently, not even using fee recommendations can ensure a sufficiently high fee is paid to ensure transaction confirmation.

I also argue that the current auction model for limited transaction bandwidth is wrong, is not suitable for a reliable transaction system and, is wrong for Bitcoin. All transactions must confirm in due time. Currently, Bitcoin is not a safe way to send payments.

I do not believe that consumers and business are against paying fees, even high fees. What is required is operational reliability.

This great issue needs to be resolved for the safety and reliability of Bitcoin. The time to resolve issues in commerce is before they become great big issues. The time to resolve this issue is now. We must have the foresight to identify and resolve problems before they trip us over.  Simply doubling block sizes every so often is reactionary and is not a reliable permanent solution. I have written a BIP proposal for a technical solution but, need your help to write it up to an acceptable standard to be a full BIP.

I have formatted the following with markdown which is human readable so, I hope nobody minds. I have done as much with this proposal as I feel that I am able so far but continue to take your feedback.

# BIP Proposal: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks

## The problem:
Everybody wants value. Miners want to maximize revenue from fees (and we presume, to minimize block size). Consumers need transaction reliability and, (we presume) want low fees.

The current transaction bandwidth limit is a limiting factor for both. As the operational safety of transactions is limited, so is consumer confidence as they realize the issue and, accordingly, uptake is limited. Fees are artificially inflated due to bandwidth limitations while failing to provide a full confirmation service for all transactions.

Current fee recommendations provide no satisfaction for transaction reliability and, as Bitcoin scales, this will worsen.

Bitcoin must be a fully scalable and reliable service, providing full transaction confirmation for every valid transaction.

The possibility to send a transaction with a fee lower than one that is acceptable to allow eventual transaction confirmation should be removed from the protocol and also from the user interface.

## Solution summary:
Provide each transaction with an individual transaction priority each time before choosing transactions to include in the current block, the priority being a function of the fee paid (on a curve), and the time waiting in the transaction pool (also on a curve) out to n days (n=60 ?). The transaction priority to serve as the likelihood of a transaction being included in the current block, and for determining the order in which transactions are tried to see if they will be included.

Use a target block size. Determine the target block size using; current transaction pool size x ( 1 / (144 x n days ) ) = number of transactions to be included in the current block. Broadcast the next target block size with the current block when it is solved so that nodes know the next target block size for the block that they are building on.

The curves used for the priority of transactions would have to be appropriate. Perhaps a mathematician with experience in probability can develop the right formulae. My thinking is a steep curve. I suppose that the probability of all transactions should probably account for a sufficient number of inclusions that the target block size is met although, it may not always be. As a suggestion, consider including some zero fee transactions to pad, highest BTC value first?

**Explanation of the operation of priority:**
> If transaction priority is, for example, a number between one (low) and one-hundred (high) it can be directly understood as the percentage chance in one-hundred of a transaction being included in the block. Using probability or likelihood infers that there is some function of random. If random (100) < transaction priority then the transaction is included.

>To break it down further, if both the fee on a curve value and the time waiting on a curve value are each a number between one and one-hundred, a rudimentary method may be to simply multiply those two numbers, to find the priority number. For example, a middle fee transaction waiting thirty days (if n = 60 days) may have a value of five for each part  (yes, just five, the values are on a curve). When multiplied that will give a priority value of twenty-five, or,  a twenty-five percent chance at that moment of being included in the block; it will likely be included in one of the next four blocks, getting more likely each chance. If it is still not included then the value of time waiting will be higher, making for more probability. A very low fee transaction would have a value for the fee of one. It would not be until near sixty-days that the particular low fee transaction has a high likelihood of being included in the block.

I am not concerned with low (or high) transaction fees, the primary reason for addressing the issue is to ensure transactional reliability and scalability while having each transaction confirm in due time.

## Pros:
* Maximizes transaction reliability.
* Fully scalable.
* Maximizes possibility for consumer and business uptake.
* Maximizes total fees paid per block without reducing reliability; because of reliability, in time confidence and overall uptake are greater; therefore, more transactions.
* Market determines fee paid for transaction priority.
* Fee recommendations work all the way out to 30 days or greater.
* Provides additional block entropy; greater security since there is less probability of predicting the next block.

## Cons:
* Could initially lower total transaction fees per block.
* Must be first be programmed.

## Solution operation:
This is a simplistic view of the operation. The actual operation will need to be determined in a spec for the programmer.

1. Determine the target block size for the current block.
2. Assign a transaction priority to each transaction in the pool.
3. Select transactions to include in the current block using probability in transaction priority order until the target block size is met.
5. Solve block.
6. Broadcast the next target block size with the current block when it is solved.
7. Block is received.
8. Block verification process.
9. Accept/reject block based on verification result.
10. Repeat.

## Closing comments:
It may be possible to verify blocks conform to the proposal by showing that the probability for all transactions included in the block statistically conforms to a probability distribution curve, *if* the individual transaction priority can be recreated. I am not that deep into the mathematics; however, it may also be possible to use a similar method to do this just based on the fee, that statistically, the blocks conform to a fee distribution. Any zero fee transactions would have to be ignored. This solution needs a clever mathematician.

I implore, at the very least, that we use some method that validates full transaction reliability and enables scalability of block sizes. If not this proposal, an alternative.

Regards,
Damian Williamson


_______________________________________________
bitcoin-dev mailing list
bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>
https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171223/9e2aa96b/attachment-0001.html>

From lf-lists at mattcorallo.com  Sat Dec 23 16:25:08 2017
From: lf-lists at mattcorallo.com (Matt Corallo)
Date: Sat, 23 Dec 2017 16:25:08 +0000
Subject: [bitcoin-dev] BIP-21 amendment proposal: -no125
In-Reply-To: <20171211181943.GA9855@savin.petertodd.org>
References: <AE14915B-37DF-4D94-A0B1-E32A26903807@sprovoost.nl>
	<201712051939.33238.luke@dashjr.org>
	<20171211181943.GA9855@savin.petertodd.org>
Message-ID: <790E0150-E6A3-49D5-8369-BF5A556FA24C@mattcorallo.com>

While the usability of non-RBF transactions tends to be quite poor, there are some legitimate risk-analysis-based reasons why people use them (eg to sell BTC based on a incoming transaction which you will need to convert to fiat, which has low cost if the transaction doesn't confirm), and if people want to overpay on fees to do so, no reason not to let them, including if the merchant is willing to CPFP to do so.

Honestly, I anticipate very low usage of such a flag, which is appropriate, but also strongly support including it. If things turn out differently with merchants reducing the usability of BTC without taking over the CPFP responsibility we could make the option imply receiver-pays-fee, but no reason to overcomplicate it yet.

On December 11, 2017 1:19:43 PM EST, Peter Todd via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
>On Tue, Dec 05, 2017 at 07:39:32PM +0000, Luke Dashjr via bitcoin-dev
>wrote:
>> On Tuesday 05 December 2017 7:24:04 PM Sjors Provoost wrote:
>> > I recently submitted a pull request that would turn on RBF by
>default,
>> > which triggered some discussion [2]. To ease the transition for
>merchants
>> > who are reluctant to see their customers use RBF, Matt Corallo
>suggested
>> > that wallets honor a no125=1 flag.
>> > 
>> > So a BIP-21 URI would look like this:
>> > bitcoin:175t...45W?amount=20.3&no125=1
>> > 
>> > When this flag is set, wallets should not use RBF, regardless of
>their
>> > default, unless the user explicitly overrides the merchant's
>preference.
>> 
>> This seems counterproductive. There is no reason to ever avoid the
>RBF flag. 
>> I'm not aware of any evidence it even reduces risk of, and it
>certainly 
>> doesn't prevent double spending. Plenty of miners allow RBF
>regardless of the 
>> flag, and malicious double spending doesn't benefit much from RBF in
>any case.
>
>I'll second the objection to a no-RBF flag.
>
>-- 
>https://petertodd.org 'peter'[:-1]@petertodd.org
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171223/feda2c15/attachment.html>

From piverson1024 at gmail.com  Sat Dec 23 18:33:21 2017
From: piverson1024 at gmail.com (Paul Iverson)
Date: Sat, 23 Dec 2017 10:33:21 -0800
Subject: [bitcoin-dev] BIP-21 amendment proposal: -no125
In-Reply-To: <790E0150-E6A3-49D5-8369-BF5A556FA24C@mattcorallo.com>
References: <AE14915B-37DF-4D94-A0B1-E32A26903807@sprovoost.nl>
	<201712051939.33238.luke@dashjr.org>
	<20171211181943.GA9855@savin.petertodd.org>
	<790E0150-E6A3-49D5-8369-BF5A556FA24C@mattcorallo.com>
Message-ID: <CAAeo5+j01Wtyy9mm-adN+wbFZNo3jFDpUc=BzHgncoWWytUU3A@mail.gmail.com>

Allowing a "no-RBF" flag serves only to fool new users into believing that
0-conf is more secure than it is. There is already too much confusion about
this point.

In Bitcoin was assume that miners are profit-maximizing agents, and so we
must assume that (flag or not) miners will replace transactions from
mempool with conflicts paying a higher fee. From that viewpoint, full RBF
is already "de facto" policy in Bitcoin. So I agree with Luke and Peter:
remove the flag and make all transactions RBF as "de jure" policy too.

At the same time, we need more outreach and education to clarify the risks
of 0-conf, and we need to show miners how they can earn more profits by
adopting full RBF.

Paul.

On Sat, Dec 23, 2017 at 8:25 AM, Matt Corallo via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> While the usability of non-RBF transactions tends to be quite poor, there
> are some legitimate risk-analysis-based reasons why people use them (eg to
> sell BTC based on a incoming transaction which you will need to convert to
> fiat, which has low cost if the transaction doesn't confirm), and if people
> want to overpay on fees to do so, no reason not to let them, including if
> the merchant is willing to CPFP to do so.
>
> Honestly, I anticipate very low usage of such a flag, which is
> appropriate, but also strongly support including it. If things turn out
> differently with merchants reducing the usability of BTC without taking
> over the CPFP responsibility we could make the option imply
> receiver-pays-fee, but no reason to overcomplicate it yet.
>
> On December 11, 2017 1:19:43 PM EST, Peter Todd via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>>
>> On Tue, Dec 05, 2017 at 07:39:32PM +0000, Luke Dashjr via bitcoin-dev wrote:
>>
>>>  On Tuesday 05 December 2017 7:24:04 PM Sjors Provoost wrote:
>>>
>>>>  I recently submitted a pull request that would turn on RBF by default,
>>>>  which triggered some discussion [2]. To ease the transition for merchants
>>>>  who are reluctant to see their customers use RBF, Matt Corallo suggested
>>>>  that wallets honor a no125=1 flag.
>>>>
>>>>  So a BIP-21 URI would look like this:
>>>>  bitcoin:175t...45W?amount=20.3&no125=1
>>>>
>>>>  When this flag is set, wallets should not use RBF, regardless of their
>>>>  default, unless the user explicitly overrides the merchant's preference.
>>>>
>>>
>>>  This seems counterproductive. There is no reason to ever avoid the RBF flag.
>>>  I'm not aware of any evidence it even reduces risk of, and it certainly
>>>  doesn't prevent double spending. Plenty of miners allow RBF regardless of the
>>>  flag, and malicious double spending doesn't benefit much from RBF in any case.
>>>
>>
>> I'll second the objection to a no-RBF flag.
>>
>>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171223/5d90c5a8/attachment.html>

From millibitcoins at gmail.com  Sat Dec 23 19:05:20 2017
From: millibitcoins at gmail.com (sumBTC)
Date: Sat, 23 Dec 2017 20:05:20 +0100
Subject: [bitcoin-dev] BIP 176: Utilization of bits denomination
Message-ID: <24df5707-b256-fe5f-fe80-675b1e7dd147@gmail.com>

Why not use "coinbit". A bitcoin is equal to 1 million coinbits.

A bit could then be seen/used as an abbreviation of coinbit.


From tamas.blummer at gmail.com  Sun Dec 24 04:26:04 2017
From: tamas.blummer at gmail.com (Tamas Blummer)
Date: Sun, 24 Dec 2017 05:26:04 +0100
Subject: [bitcoin-dev] BIP Proposal: Utilization of bits denomination
Message-ID: <6F79A8C5-C662-49BA-8EA0-7C7017AB9ADE@gmail.com>

I see further arguments supporting the ?bit" denomination:

huge benefit:
	- amounts denominated in bits fit nicely into legacy database structures and UIs with two decimal places for currency. This change to the usual currrency precision is a huge benefit for integration into existing financial software.

nice to have:
	- while fraction prefixes m for 1/1000 and u for 1/1000000 are obvious to engineers and geeks, they are a foreign concept to many. Chances confusing magnitudes would be high if alternative scales were offered.
	- bit assigns an easy to comprehend meaning to the second part of the Bitcoin name: I think the term ?(a whole) coin" would quickly catch on as a synonym for a million bits.


Tamas Blummer

From willtech at live.com.au  Sun Dec 24 02:57:38 2017
From: willtech at live.com.au (Damian Williamson)
Date: Sun, 24 Dec 2017 02:57:38 +0000
Subject: [bitcoin-dev] BIP 177: UTPFOTIB - Use Transaction Priority For
 Ordering Transactions In Blocks
Message-ID: <PS2P216MB0179FE1CAF04AB860A5F36719D000@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>

BIP 177: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks


This BIP proposes to address the issue of transactional reliability in Bitcoin, where valid transactions may be stuck in the mempool for extended periods.


There are two key issues to be resolved:


  1.  The current transaction bandwidth limit.
  2.  The current ad-hoc methods of including transactions in blocks resulting in variable and confusing confirmation times for valid transactions, including transactions with a valid fee that may never confirm.


It is important with any change to protect the value of fees as these will eventually be the only payment that miners receive. Rather than an auction model for limited bandwidth, the proposal results in a stable fee for priority service auction model.


I will post the full proposal up on to my blog in the coming days and, re-review incorporating feedback that I have received on and off thread. It would not be true to suggest that all feedback received has been entirely positive although, most of it has been constructive.


The previous threads for this BIP are available here:

https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/subject.html


Regards,

Damian Williamson
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171224/1f991190/attachment-0001.html>

From willtech at live.com.au  Sun Dec 24 01:13:27 2017
From: willtech at live.com.au (Damian Williamson)
Date: Sun, 24 Dec 2017 01:13:27 +0000
Subject: [bitcoin-dev]  what do you think about having a maximum fee rate?
In-Reply-To: <CAMjoVH+5W+1pO2bJSPNr20sGJDVvwrKS85KZZYsSdXjSL65jLA@mail.gmail.com>
References: <CAMjoVH+5W+1pO2bJSPNr20sGJDVvwrKS85KZZYsSdXjSL65jLA@mail.gmail.com>
Message-ID: <PS2P216MB0179A68450E8AA5E4E77915B9D000@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>

If all transactions pay the proposed max then fee there are still going to be an awful lot of never confirming transactions once the transaction bandwidth limit is surpassed, as I suppose that it roughly is now:

https://bitinfocharts.com/comparison/bitcoin-transactions.html


This is what I have been working on as an alternative:

https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/015371.html


There is a previous thread, linked later on in the linked thread.


Regards,

Damian Williamson


________________________________
From: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of oscar via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>
Sent: Friday, 22 December 2017 7:26:12 PM
To: bitcoin-dev at lists.linuxfoundation.org
Subject: [bitcoin-dev] what do you think about having a maximum fee rate?

Hello,
I'm not a bitcoin developer, but I'd like to receive feedback on what
I think is a serious problem. Hope I'm not wasting your time.
I'm also sure this was already discussed, but google doesn't give me
any good result.

Let me explain: I think that the current incentive system doesn't
really align with the way miners are distributed (not very
decentralized, due to pools and huge asic producers).
I think big miners are incentivized to spam the network with low(ish)
fee transactions, thereby forcing regular users into paying extremely
high fees to be able to get their transactions confirmed.

Obviously this is the result of insufficient mining decentralization,
but as I will try to show, such an attack could be profitable even if
you are controlling just 5-10% of the hashing power, which could
always be easy for a big player and with some collusion.

Let's look at some numbers: https://i.imgur.com/sCn4eDG.png

[https://i.imgur.com/sCn4eDG.png]


These are 10 blocks mined yesterday, and they all have rewards hugely
exceeding the normal 12.5 mining output. Even taking the lowest value
of 20, it's a nice 60% extra profit for the miner. Let's say you
control 10% of the hashing power, and you spam enough transactions to
fill 144 blocks (1 day's worth) at 50 satoshi/byte, losing just 72 BTC
in fees.

(blocksize-in-bytes * fee-per-byte * Nblocks)/satoshis-in-btc => (1e6
* 50 * 144)/1e8 => 72

At the same time you will discover about 144*0.1=14.4 blocks per day.
Assuming the situation we see in the previous screenshot is what
happens when you have a mempool bigger than one day's worth of blocks,
you would get 20-12.5=7.5 extra BTC per block, which is 14.4*7.5=108
BTC, given your investment of 72 to spam the mempool. 32 btc extra
profit.

The big assumption here is that spamming 1 day of backlog in the
50satoshi/b range will get people to compete enough to push 7.5 btc of
fees in each block, but:

* https://jochen-hoenicke.de/queue/#30d this seems to confirm that
[https://jochen-hoenicke.de/queue/mempool-20170608.png]<https://jochen-hoenicke.de/queue/#30d>

Johoe's Mempool Size Statistics - jochen-hoenicke.de/queue<https://jochen-hoenicke.de/queue/#30d>
jochen-hoenicke.de
This page displays the number and size of the unconfirmed bitcoin transactions, also known as the transactions in the mempool. It gives a real-time view and shows how ...


about half the mempool is in the 50satoshi/b range or less.
* https://blockchain.info/pools there are miners that control more than 10%
Bitcoin Hashrate Distribution - Blockchain.info<https://blockchain.info/pools>
blockchain.info
A pie chart showing the hashrate distribution between the major bitcoin mining pools - Blockchain


* if you get enough new real transactions, it's not necessary to spam
a full 144 blocks worth each day, probably just ~50 would be enough,
cutting the spam cost substantially
* other miners could be playing the same game, helping you spam and
further reduce the costs of the attack
* you actually get 10% of the fees back by avoiding mining your spam
transactions in your own blocks
* most of the spam transactions won't actually end up in blocks if
there is enough pressure coming from real usage

This seems to indicate that you would actually get much higher profit
margins than my estimates. **PLEASE** correct me if my calculations or
my assumptions are wrong.

You might also say that doing this would force users out of the
system, decreasing the value of btc and disincentivizing miners from
continuing. On the other hand, a backlogged mempool could create the
impression of high(er) usage and increase scarcity by slowing down
movements, which could actually push the price upwards.

Of course, it's impossible to prove that this is happening. But the
fact that it is profitable makes me believe that it is happening.

I see some solutions to this, all with their own downsides:

- increasing block size every time there is sustained pressure
this attack wouldn't work, but the downsides have already been
discussed to death.

- change POW
Not clear it would fix this, aside from stimulating terrible
infighting. Controlling 5 to 10% of the hashing power seems too easy,
and I don't think it would be practical to change pow every time that
happens, as it would prevent the development of a solid POW support.

- protocol level MAX transaction fee
I personally think this would totally invalidate the attack by making
the spam more expensive than the fees you would recover.
There already is a minimum fee accepted by the nodes, at 1 satoshi per
byte. The maximum fee could be N times the minimum, maybe 100-200.
Meaning a maximum of 1-2btc in total fee rewards when the block size
is 1mb. Of course the actual values need more analysis, but 2btc -
together with the deflationary structure - seems enough to continue
motivating miners, without giving unfair advantage.

Yes, this would make it impossible to spend your way out of a
congested mempool. But if the mempool stays congested after this
change, you could have a bigger confidence that it's coming from real
usage or from someone willfully burning money, making a block size
increase much more justified.

Hope to hear your opinion,
have a nice day.

oscar
_______________________________________________
bitcoin-dev mailing list
bitcoin-dev at lists.linuxfoundation.org
https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
bitcoin-dev Info Page - Linux Foundation<https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>
lists.linuxfoundation.org
Bitcoin development and protocol discussion. This list is lightly moderated. - No offensive posts, no personal attacks. - Posts must concern development of bitcoin ...


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171224/3a73592f/attachment-0001.html>

From luke at dashjr.org  Sun Dec 24 07:21:24 2017
From: luke at dashjr.org (Luke Dashjr)
Date: Sun, 24 Dec 2017 07:21:24 +0000
Subject: [bitcoin-dev] BIP 177: UTPFOTIB - Use Transaction Priority For
	Ordering Transactions In Blocks
In-Reply-To: <PS2P216MB0179FE1CAF04AB860A5F36719D000@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
References: <PS2P216MB0179FE1CAF04AB860A5F36719D000@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
Message-ID: <201712240721.24971.luke@dashjr.org>

BIP 177 is NOT assigned. Do not self-assign BIP numbers!

Please read BIP 2:

    https://github.com/bitcoin/bips/blob/master/bip-0002.mediawiki

Luke


On Sunday 24 December 2017 2:57:38 AM Damian Williamson via bitcoin-dev wrote:
> BIP 177: UTPFOTIB - Use Transaction Priority For Ordering Transactions In
> Blocks
> 
> 
> This BIP proposes to address the issue of transactional reliability in
> Bitcoin, where valid transactions may be stuck in the mempool for extended
> periods.
> 
> 
> There are two key issues to be resolved:
> 
> 
>   1.  The current transaction bandwidth limit.
>   2.  The current ad-hoc methods of including transactions in blocks
> resulting in variable and confusing confirmation times for valid
> transactions, including transactions with a valid fee that may never
> confirm.
> 
> 
> It is important with any change to protect the value of fees as these will
> eventually be the only payment that miners receive. Rather than an auction
> model for limited bandwidth, the proposal results in a stable fee for
> priority service auction model.
> 
> 
> I will post the full proposal up on to my blog in the coming days and,
> re-review incorporating feedback that I have received on and off thread.
> It would not be true to suggest that all feedback received has been
> entirely positive although, most of it has been constructive.
> 
> 
> The previous threads for this BIP are available here:
> 
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/subje
> ct.html
> 
> 
> Regards,
> 
> Damian Williamson

From willtech at live.com.au  Sun Dec 24 22:20:50 2017
From: willtech at live.com.au (Damian Williamson)
Date: Sun, 24 Dec 2017 22:20:50 +0000
Subject: [bitcoin-dev] BIP 177: UTPFOTIB - Use Transaction Priority For
 Ordering Transactions In Blocks
In-Reply-To: <201712240721.24971.luke@dashjr.org>
References: <PS2P216MB0179FE1CAF04AB860A5F36719D000@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>,
	<201712240721.24971.luke@dashjr.org>
Message-ID: <PS2P216MB01796F03E182D783210DFF2B9D000@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>

My mistake, apologies all.


 - I honestly thought everyone just took the next available number and published up their BIP's.


And, I see you have something of a master list.


As a suggestion, would it be worth considering linking to some of that information in the list welcome email? Web search is not always your friend for locating everything relevant.


Regards,

Damian Williamson

________________________________
From: Luke Dashjr <luke at dashjr.org>
Sent: Sunday, 24 December 2017 6:21:24 PM
To: Damian Williamson
Cc: bitcoin-dev at lists.linuxfoundation.org
Subject: Re: [bitcoin-dev] BIP 177: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks

BIP 177 is NOT assigned. Do not self-assign BIP numbers!

Please read BIP 2:

    https://github.com/bitcoin/bips/blob/master/bip-0002.mediawiki
[https://avatars0.githubusercontent.com/u/528860?s=400&v=4]<https://github.com/bitcoin/bips/blob/master/bip-0002.mediawiki>

bips/bip-0002.mediawiki at master ? bitcoin/bips ? GitHub<https://github.com/bitcoin/bips/blob/master/bip-0002.mediawiki>
github.com
Abstract. A Bitcoin Improvement Proposal (BIP) is a design document providing information to the Bitcoin community, or describing a new feature for Bitcoin or its ...



Luke


On Sunday 24 December 2017 2:57:38 AM Damian Williamson via bitcoin-dev wrote:
> BIP 177: UTPFOTIB - Use Transaction Priority For Ordering Transactions In
> Blocks
>
>
> This BIP proposes to address the issue of transactional reliability in
> Bitcoin, where valid transactions may be stuck in the mempool for extended
> periods.
>
>
> There are two key issues to be resolved:
>
>
>   1.  The current transaction bandwidth limit.
>   2.  The current ad-hoc methods of including transactions in blocks
> resulting in variable and confusing confirmation times for valid
> transactions, including transactions with a valid fee that may never
> confirm.
>
>
> It is important with any change to protect the value of fees as these will
> eventually be the only payment that miners receive. Rather than an auction
> model for limited bandwidth, the proposal results in a stable fee for
> priority service auction model.
>
>
> I will post the full proposal up on to my blog in the coming days and,
> re-review incorporating feedback that I have received on and off thread.
> It would not be true to suggest that all feedback received has been
> entirely positive although, most of it has been constructive.
>
>
> The previous threads for this BIP are available here:
>
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/subje
> ct.html
>
>
> Regards,
>
> Damian Williamson
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171224/8e260a6c/attachment.html>

From petdog at gmail.com  Sun Dec 24 13:59:23 2017
From: petdog at gmail.com (oscar)
Date: Sun, 24 Dec 2017 14:59:23 +0100
Subject: [bitcoin-dev] what do you think about having a maximum fee rate?
In-Reply-To: <PS2P216MB0179A68450E8AA5E4E77915B9D000@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
References: <CAMjoVH+5W+1pO2bJSPNr20sGJDVvwrKS85KZZYsSdXjSL65jLA@mail.gmail.com>
	<PS2P216MB0179A68450E8AA5E4E77915B9D000@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CAMjoVH+qEOgMSLmoJ+1qcbiKJ0L2pcr_48Sn5AOttXg+hReHxg@mail.gmail.com>

On Sun, Dec 24, 2017 at 2:13 AM, Damian Williamson <willtech at live.com.au> wrote:
> If all transactions pay the proposed max then fee there are still going to
> be an awful lot of never confirming transactions once the transaction
> bandwidth limit is surpassed

Yes obviously. That would be the unequivocal sign that it's time to
bump the block size.

Why not just bump now then? My main worry is that wasting space should
not be profitable for anybody. If it is, it's an encouragement to
waste space, and imho we have such an encouragement in place.

Fees should be allowed to get high enough as to discourage wasteful
usage of blockchain space, but not high enough as to make it
*profitable* to waste space, if you are a sufficiently big miner. The
fact that it is now profitable, and that such big miners exist, makes
me believe that a lot of blockchain space is wasted on purpose.

> This is what I have been working on as an alternative:
>
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/015371.html

I read your proposal, but the value that I see in mine is that it is
extremely simple. It would be trivial to have nodes stop propagating
transactions with fees over the max, and miners can trivially reject
blocks where coinbase > block reward + max fee rate * block size, if
they are on board.

It would also be quite simple to adapt wallets, given that the fee
range is fixed. If nodes had an rpc method giving you some mempool
statistics, it would also be simple to correctly recommend fees
according to the time expected to first confirmation.

Sure, at some point, if there is real congestion, it would just start
always recommending the max fee. Again, this means that it's time to
bump the block size. I think this is ultimately unavoidable, but I
understand the reservations, and I agree that increasing the block
size without incentivizing efficient usage would be counterproductive.
I think the current fees are certainly incentivizing efficient usage
to users, but not to miners. My (maybe naive) idea is that it would be
possible to find an appropriate maximum fee value that would move
things towards efficient usage by both users and big miners.

This would work very well if coupled with some proposals I've read to
slowly increase the block size with a process similar to difficulty
adjustment, like adding 100kb if 95% of the last 2016 blocks were
full. Without max fees, a big miner could easily destroy this strategy
by always applying just enough pressure as to always skyrocket fees
and profit, while the blocksize slowly increases.

The way I see it, unbounded fees together with small blocks and big
miners introduce a terrible flaw in the incentives equilibrium.
I would really like an open discussion on this topic.

From nullius at nym.zone  Mon Dec 25 21:21:57 2017
From: nullius at nym.zone (nullius)
Date: Mon, 25 Dec 2017 21:21:57 +0000
Subject: [bitcoin-dev] Bravo Charlie One: Branding Bech32
Message-ID: <9b39902347ba7cd03974f6068f025c98@nym.zone>

I here record for the devs a thought I had a few days ago on the Bitcoin 
Forum about BIP 173 Bech32 addresses.  I?ve heard Greg Maxwell say that 
?Bech32 is designed for human use and basically nothing else?; so I hope 
I be not untoward in considering the following human-friendliness 
enhancement to entwine with the technical ambit of this list.  This MAY 
be suitable for mention in an informative specification, or informative 
section thereof.

To help gain user familiarity with and acceptance of the 
error-correcting, case-insensitive Bitcoin addresses of the future, I 
propose a need for what I think marketers call ?branding?.  The best 
branding is that which derives naturally from some intrinsic quality of 
a thing; wherefore I look to what may perhaps be a bit of serendipity in 
the specification.

I expect that in practical use, one of the great advantages of Bech32 
addresses will be the relative ease of communicating them 
aloud?especially over the phone.  In similar circumstances, when trying 
to convey unusual names or pseudorandom strings, I?ve found radio 
alphabets to work well at their intended purpose.  And when reading 
Bech32 Bitcoin addresses in the most popular radio alphabet, they will 
always start with a catchy phrase:  ?Bravo Charlie One?.

That?s memorable, $SEARCH-able, and yet also one of those unique, 
otherwise meaningless phrases which gets marketers excited.  Keeping to 
a word triplet, I hereby submit for consideration as the official 
nickname for Bech32 Bitcoin use:  ?Bravo Charlie Addresses?.  These are 
the Bitcoin addresses with the magic words, suitable for a motto:  
?Bravo Charlie One means money.?  Add a logo ? la Segwit?s, and raise 
user awareness of this exciting new technology!

Beyond the branding issue, recommendations for Bitcoin spelling-alphabet 
use in English and other languages may perhaps be a suitable matter for 
such standardization as would facilitate coherent user documentation.  I 
invite discussion.

Of course, this branding only applies directly to Bitcoin Bech32 
addresses.  The BIP 173 authors were gracious to make the standard 
generally adaptable; and it has already seen some uptake amongst 
altcoins.  I myself am now contemplating how Bech32 would be a superior 
human-facing format for key fingerprints for PGP, SSH, and even TLS, 
with HRPs of ?pgp?, ?ssh?, ?tls?, etc. and some appropriate means of 
embedding the key type just as ?bc? embeds the witness version.  There 
is an urgent general need for a specification which reduces the inherent 
pain of wetware in handling pseudorandom strings; and I do think that 
anything which familiarizes users with Bech32 in a specific use will be 
beneficial to Bech32 adoption generally.

To celebrate, as seen in my sig, I created for myself a new Bravo 
Charlie Address which expresses that I am pleased:  Now, I have an 
error-correcting, case-insensitive address which can receive only 
genuine Bitcoin cash money.  Because ?Bravo Charlie One means money.?

Here?s to the Bitcoin address format of the future!

-- 
nullius at nym.zone | PGP ECC: 0xC2E91CD74A4C57A105F6C21B5A00591B2F307E0C
Bitcoin: bc1qcash96s5jqppzsp8hy8swkggf7f6agex98an7h | (Segwit nested:
3NULL3ZCUXr7RDLxXeLPDMZDZYxuaYkCnG)  (PGP RSA: 0x36EBB4AB699A10EE)
??If you?re not doing anything wrong, you have nothing to hide.?
No!  Because I do nothing wrong, I have nothing to show.? ? nullius
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 228 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171225/b743b321/attachment.sig>

From spartacusrex99 at gmail.com  Sun Dec 24 09:02:09 2017
From: spartacusrex99 at gmail.com (Spartacus Rex)
Date: Sun, 24 Dec 2017 09:02:09 +0000
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction
 Priority For Ordering Transactions In Blocks
In-Reply-To: <PS2P216MB0179D452E5D478511B46E0879D000@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
References: <PS2P216MB01794ABD544248B27BF0DFD99D330@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<PS2P216MB01795BFC05612E021CCEDD7C9D0B0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<5upGmF0IhXUWhcikhdV-e9Pqg-kXfUuXe0kOpGxumie_TO2jLvCgTZ5c6vgBRtaqkL6DmOJb1YftK0osufB5RkhW7YhAhhCI0zBTH3YcORY=@protonmail.com>
	<PS2P216MB0179544A6503C2992190CEB69D0B0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<PS2P216MB0179D6A5965D0CFFEFB2880A9D090@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<AB6BF756-29F1-4442-85A9-B81228E829EC@friedenbach.org>
	<PS2P216MB017991D78147E2B1EC14C3059D0F0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<PS2P216MB0179FC39F4A63A43BB70011A9D020@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<CA+Cf5AaX5a5yuLcnkk=7boiqrSrZf4KG_RjSOF1-2qJtB9ds+Q@mail.gmail.com>
	<PS2P216MB0179D452E5D478511B46E0879D000@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CA+Cf5Aaabg2mVz1oZBanp5=bX99LZuqfQweeY49ODpG41jvgDw@mail.gmail.com>

..What you have proposed is interesting but seems to do nothing for the
issue of transaction
bandwidth, which seems to be approaching its threshold:
..

This system just shows one way of changing the way a miner calculates txn
priority.

A miners should always do what makes him the most money, so an old txn will
never get priority if a newer one offering more fees comes along. This is
why some txns will never get confirmation.

In this system a txn cannot just pay more fees, as you all pay the same
fees in a block, so an old txn that has a high enough threshold will be
worth just as much to a miner as any txn coming later on.

This way you can be sure that your txn will confirm at some point, and not
just be relegated to the 'never' confirmed pile.


On Dec 24, 2017 03:44, "Damian Williamson" <willtech at live.com.au> wrote:

>.. This system has flaws, they all do.


>The simple fact is that there is currently no known system that works as
well as the current system..


Alright, but, we seem to agree, the current system also has flaws. The
transaction bandwidth limit is a serious issue for transactional
reliability.


What you have proposed is interesting but seems to do nothing for the issue
of transaction bandwidth, which seems to be approaching its threshold:

https://bitinfocharts.com/comparison/bitcoin-transactions.html


Regards,

Damian Williamson
------------------------------
*From:* Spartacus Rex <spartacusrex99 at gmail.com>
*Sent:* Saturday, 23 December 2017 5:07:49 AM
*To:* Damian Williamson; Bitcoin Protocol Discussion

*Subject:* Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use
Transaction Priority For Ordering Transactions In Blocks

Hi Damian,

Thought I'd chip in.  This is a hard fork scenario. This system has flaws,
they all do.

If you had a fixed fee per block, so that every txn in that block paid the
same fee, that might make it easier to include all txns eventually, as you
envisage.

The fee could be calculated as the average of the amount txns are prepared
to pay in the last 1000 blocks.

A txn would say ' I'll pay up to X bitcoins ' and as long as that is more
than the value required for the block your txn can be added. This is to
ensure you don't pay more than you are willing.  It also ensures that
putting an enormous fee will not ensure your txn is processed quickly..

Calculating what the outputs are given a variable fee needs a new mechanism
all of it's own, but I'm sure it's possible.

The simple fact is that there is currently no known system that works as
well as the current system..

But there are other systems.


On Dec 22, 2017 15:09, "Damian Williamson via bitcoin-dev" <
bitcoin-dev at lists.linuxfoundation.org> wrote:

If the cash value of Bitcoin was high enough and zero fee transactions were
never accepted and not counted when calculating the transaction pool size
then I do not think it would be such an issue. Why is it even possible to
create zero fee transactions?


Regards,

Damian Williamson

------------------------------
*From:* bitcoin-dev-bounces at lists.linuxfoundation.org <
bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of Damian
Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>
*Sent:* Tuesday, 19 December 2017 6:51 PM
*To:* Mark Friedenbach
*Cc:* bitcoin-dev at lists.linuxfoundation.org
*Subject:* [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction
Priority For Ordering Transactions In Blocks


Thank you for your constructive feedback. I now see that the proposal
introduces a potential issue.


>Finally in terms of the broad goal, having block size based on the number
of transactions is NOT something desirable in the first place, even if it
did work. That?s effectively the same as an infinite block size since
anyone anywhere can create transactions in the mempool at no cost.


Do you have any critical suggestion as to how transaction bandwidth limit
could be addressed, it will eventually become an issue if nothing is
changed regardless of how high fees go?


Regards,
Damian Williamson



------------------------------
*From:* Mark Friedenbach <mark at friedenbach.org>
*Sent:* Tuesday, 19 December 2017 3:08 AM
*To:* Damian Williamson
*Subject:* Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use
Transaction Priority For Ordering Transactions In Blocks

Damian, you seem to be misunderstanding that either

(1) the strong form of your proposal requires validating the commitment to
the mempool properties, in which case the mempool becomes consensus
critical (an impossible requirement); or

(2) in the weak form where the current block is dependent on the commitment
in the last block only it is becomes a miner-selected field they can freely
parameterize with no repercussions for setting values totally independent
of the actual mempool.

If you want to make the block size dependent on the properties of the
mempool in a consensus critical way, flex cap achieves this. If you want to
make the contents or properties of the mempool known to well-connected
nodes, weak blocks achieves that. But you can?t stick the mempool in
consensus because it fundamentally is not something the nodes have
consensus over. That?s a chicken-and-the-egg assumption.

Finally in terms of the broad goal, having block size based on the number
of transactions is NOT something desirable in the first place, even if it
did work. That?s effectively the same as an infinite block size since
anyone anywhere can create transactions in the mempool at no cost.

On Dec 16, 2017, at 8:14 PM, Damian Williamson via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

I do not know why people make the leap that the proposal requires a
consensus on the transaction pool. It does not.

It may be helpful to have the discussion from the previous thread linked
here.
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017
-December/015370.html

Where I speak of validating that a block conforms to the broadcast next
block size, I do not propose validating the number broadcast for the next
block size itself, only that the next generated block is that size.

Regards,
Damian Williamson


------------------------------
*From:* Damian Williamson <willtech at live.com.au>
*Sent:* Saturday, 16 December 2017 7:59 AM
*To:* Rhavar
*Cc:* Bitcoin Protocol Discussion
*Subject:* Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use
Transaction Priority For Ordering Transactions In Blocks

There are really two separate problems to solve.


   1. How does Bitcoin scale with fixed block size?
   2. How do we ensure that all valid transactions are eventually included
   in the blockchain?


Those are the two issues that the proposal attempts to address. It makes
sense to resolve these two problems together. Using the proposed system for
variable block sizes would solve the first problem but there would still be
a whole bunch of never confirming transactions. I am not sure how to
reliably solve the second problem at scale without first solving the first.

>* Every node has a (potentially) different mempool, you can't use it to
decide consensus values like the max block size.

I do not suggest a consensus. Depending on which node solves a block the
value for next block size will be different. The consensus would be that
blocks will adhere to the next block size value transmitted with the
current block. It is easy to verify that the consensus is being adhered to
once in place.

>* Increasing the entropy in a block to make it more unpredictable doesn't
really make sense.

Not a necessary function, just an effect of using a probability-based
distribution.

>* Bitcoin should be roughly incentive compatible. Your proposal explicits
asks miners to ignore their best interests, and confirm transactions by
"priority".  What are you going to do if a "malicious" miner decides to go
after their profits and order by what makes them the most money. Add
"ordered by priority" as a consensus requirement? And even if you miners
can still sort their mempool by fee, and then order the top 1MB by priority.

I entirely agree with your sentiment that Bitcoin must be incentive
compatible. It is necessary.

It is in only miners immediate interest to make the most profitable block
from the available transaction pool. As with so many other things, it is
necessary to partially ignore short-term gain for long-term benefit. It is
in miners and everybody's long-term interest to have a reliable transaction
service. A busy transaction service that confirms lots of transactions per
hour will become more profitable as demand increases and more users are
prepared to pay for priority. As it is there is currently no way to fully
scale because of the transaction bandwidth limit and that is problematic.
If all valid transactions must eventually confirm then there must be a way
to resolve that problem.

Bitcoin deliberately removes traditional scale by ensuring blocks take ten
minutes on average to solve, an ingenious idea and, incentive compatible
but, fixed block sizes leaves us with a problem to solve when we want to
scale.

>If you could find a good solution that would allow you to know if miners
were following your rule or not (and thus ignore it if it doesn't) then you
wouldn't even need bitcoin in the first place.

I am confident that the math to verify blocks based on the proposal can be
developed (and I think it will not be too complex for a mathematician with
the relevant experience), however, I am nowhere near experienced enough
with probability and statistical analysis to do it. Yes, if Bitcoin doesn't
then it might make another great opportunity for an altcoin but I am not
even nearly interested in promoting any altcoins.


If not the proposal that I have put forward, then, hopefully, someone can
come up with a better solution. The important thing is that the issues are
resolved.

Regards,
Damian Williamson


------------------------------
*From:* Rhavar <rhavar at protonmail.com>
*Sent:* Saturday, 16 December 2017 3:38 AM
*To:* Damian Williamson
*Cc:* Bitcoin Protocol Discussion
*Subject:* Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use
Transaction Priority For Ordering Transactions In Blocks

> I understand that there would be technical issues to resolve in
implementation, but, are there no fundamental errors?

Unfortunately your proposal is really fundamentally broken, on a few
levels. I think you might need to do a bit more research into how bitcoin
works before coming up with such improvements =)

But just some quick notes:

* Every node has a (potentially) different mempool, you can't use it to
decide consensus values like the max block size.

* Increasing the entropy in a block to make it more unpredictable doesn't
really make sense.

* Bitcoin should be roughly incentive compatible. Your proposal explicits
asks miners to ignore their best interests, and confirm transactions by
"priority".  What are you going to do if a "malicious" miner decides to go
after their profits and order by what makes them the most money. Add
"ordered by priority" as a consensus requirement? And even if you miners
can still sort their mempool by fee, and then order the top 1MB by priority.

If you could find a good solution that would allow you to know if miners
were following your rule or not (and thus ignore it if it doesn't) then you
wouldn't even need bitcoin in the first place.




-Ryan


-------- Original Message --------
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction
Priority For Ordering Transactions In Blocks
Local Time: December 15, 2017 3:42 AM
UTC Time: December 15, 2017 9:42 AM
From: bitcoin-dev at lists.linuxfoundation.org
To: Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>



I should not take it that the lack of critical feedback to this revised
proposal is a glowing endorsement. I understand that there would be
technical issues to resolve in implementation, but, are there no
fundamental errors?

I suppose that it if is difficult to determine how long a transaction has
been waiting in the pool then, each node could simply keep track of when a
transaction was first seen. This may have implications for a verify
routine, however, for example, if a node was offline, how should it
differentiate how long each transaction was waiting in that case? If a node
was restarted daily would it always think that all transactions had been
waiting in the pool less than one day If each node keeps the current
transaction pool in a file and updates it, as transactions are included in
blocks and, as new transactions appear in the pool, then that would go some
way to alleviate the issue, apart from entirely new nodes. There should be
no reason the contents of a transaction pool files cannot be shared without
agreement as to the transaction pool between nodes, just as nodes transmit
new transactions freely.

It has been questioned why miners could not cheat. For the question of how
many transactions to include in a block, I say it is a standoff and miners
will conform to the proposal, not wanting to leave transactions with valid
fees standing, and, not wanting to shrink the transaction pool. In any
case, if miners shrink the transaction pool then I am not immediately
concerned since it provides a more efficient service. For the question of
including transactions according to the proposal, I say if it is possible
to keep track of how long transactions are waiting in the pool so that they
can be included on a probability curve then it is possible to verify that
blocks conform to the proposal, since the input is a probability, the
output should conform to a probability curve.


If someone has the necessary skill, would anyone be willing to develop the
math necessary for the proposal?

Regards,
Damian Williamson


------------------------------

*From:* bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin
-dev-bounces at lists.linuxfoundation.org> on behalf of Damian Williamson via
bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>
*Sent:* Friday, 8 December 2017 8:01 AM
*To:* bitcoin-dev at lists.linuxfoundation.org
*Subject:* [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction
Priority For Ordering Transactions In Blocks


Good afternoon,

The need for this proposal:

We all must learn to admit that transaction bandwidth is still lurking as a
serious issue for the operation, reliability, safety, consumer acceptance,
uptake and, for the value of Bitcoin.

I recently sent a payment which was not urgent so; I chose three-day target
confirmation from the fee recommendation. That transaction has still not
confirmed after now more than six days - even waiting twice as long seems
quite reasonable to me. That transaction is a valid transaction; it is not
rubbish, junk or, spam. Under the current model with transaction bandwidth
limitation, the longer a transaction waits, the less likely it is ever to
confirm due to rising transaction numbers and being pushed back by
transactions with rising fees.

I argue that no transactions are rubbish or junk, only some zero fee
transactions might be spam. Having an ever-increasing number of valid
transactions that do not confirm as more new transactions with higher fees
are created is the opposite of operating a robust, reliable transaction
system.

Business cannot operate with a model where transactions may or may not
confirm. Even a business choosing a modest fee has no guarantee that their
valid transaction will not be shuffled down by new transactions to the
realm of never confirming after it is created. Consumers also will not
accept this model as Bitcoin expands. If Bitcoin cannot be a reliable
payment system for confirmed transactions then consumers, by and large,
will simply not accept the model once they understand. Bitcoin will be a
dirty payment system, and this will kill the value of Bitcoin.

Under the current system, a minority of transactions will eventually be the
lucky few who have fees high enough to escape being pushed down the list.

Once there are more than x transactions (transaction bandwidth limit) every
ten minutes, only those choosing twenty-minute confirmation (2 blocks) will
have initially at most a fifty percent chance of ever having their payment
confirm. Presently, not even using fee recommendations can ensure a
sufficiently high fee is paid to ensure transaction confirmation.

I also argue that the current auction model for limited transaction
bandwidth is wrong, is not suitable for a reliable transaction system and,
is wrong for Bitcoin. All transactions must confirm in due time. Currently,
Bitcoin is not a safe way to send payments.

I do not believe that consumers and business are against paying fees, even
high fees. What is required is operational reliability.

This great issue needs to be resolved for the safety and reliability of
Bitcoin. The time to resolve issues in commerce is before they become great
big issues. The time to resolve this issue is now. We must have the
foresight to identify and resolve problems before they trip us over.
Simply doubling block sizes every so often is reactionary and is not a
reliable permanent solution. I have written a BIP proposal for a technical
solution but, need your help to write it up to an acceptable standard to be
a full BIP.

I have formatted the following with markdown which is human readable so, I
hope nobody minds. I have done as much with this proposal as I feel that I
am able so far but continue to take your feedback.

# BIP Proposal: UTPFOTIB - Use Transaction Priority For Ordering
Transactions In Blocks

## The problem:
Everybody wants value. Miners want to maximize revenue from fees (and we
presume, to minimize block size). Consumers need transaction reliability
and, (we presume) want low fees.

The current transaction bandwidth limit is a limiting factor for both. As
the operational safety of transactions is limited, so is consumer
confidence as they realize the issue and, accordingly, uptake is limited.
Fees are artificially inflated due to bandwidth limitations while failing
to provide a full confirmation service for all transactions.

Current fee recommendations provide no satisfaction for transaction
reliability and, as Bitcoin scales, this will worsen.

Bitcoin must be a fully scalable and reliable service, providing full
transaction confirmation for every valid transaction.

The possibility to send a transaction with a fee lower than one that is
acceptable to allow eventual transaction confirmation should be removed
from the protocol and also from the user interface.

## Solution summary:
Provide each transaction with an individual transaction priority each time
before choosing transactions to include in the current block, the priority
being a function of the fee paid (on a curve), and the time waiting in the
transaction pool (also on a curve) out to n days (n=60 ?). The transaction
priority to serve as the likelihood of a transaction being included in the
current block, and for determining the order in which transactions are
tried to see if they will be included.

Use a target block size. Determine the target block size using; current
transaction pool size x ( 1 / (144 x n days ) ) = number of transactions to
be included in the current block. Broadcast the next target block size with
the current block when it is solved so that nodes know the next target
block size for the block that they are building on.

The curves used for the priority of transactions would have to be
appropriate. Perhaps a mathematician with experience in probability can
develop the right formulae. My thinking is a steep curve. I suppose that
the probability of all transactions should probably account for a
sufficient number of inclusions that the target block size is met although,
it may not always be. As a suggestion, consider including some zero fee
transactions to pad, highest BTC value first?

**Explanation of the operation of priority:**
> If transaction priority is, for example, a number between one (low) and
one-hundred (high) it can be directly understood as the percentage chance
in one-hundred of a transaction being included in the block. Using
probability or likelihood infers that there is some function of random. If
random (100) < transaction priority then the transaction is included.

>To break it down further, if both the fee on a curve value and the time
waiting on a curve value are each a number between one and one-hundred, a
rudimentary method may be to simply multiply those two numbers, to find the
priority number. For example, a middle fee transaction waiting thirty days
(if n = 60 days) may have a value of five for each part  (yes, just five,
the values are on a curve). When multiplied that will give a priority value
of twenty-five, or,  a twenty-five percent chance at that moment of being
included in the block; it will likely be included in one of the next four
blocks, getting more likely each chance. If it is still not included then
the value of time waiting will be higher, making for more probability. A
very low fee transaction would have a value for the fee of one. It would
not be until near sixty-days that the particular low fee transaction has a
high likelihood of being included in the block.

I am not concerned with low (or high) transaction fees, the primary reason
for addressing the issue is to ensure transactional reliability and
scalability while having each transaction confirm in due time.

## Pros:
* Maximizes transaction reliability.
* Fully scalable.
* Maximizes possibility for consumer and business uptake.
* Maximizes total fees paid per block without reducing reliability; because
of reliability, in time confidence and overall uptake are greater;
therefore, more transactions.
* Market determines fee paid for transaction priority.
* Fee recommendations work all the way out to 30 days or greater.
* Provides additional block entropy; greater security since there is less
probability of predicting the next block.

## Cons:
* Could initially lower total transaction fees per block.
* Must be first be programmed.

## Solution operation:
This is a simplistic view of the operation. The actual operation will need
to be determined in a spec for the programmer.

1. Determine the target block size for the current block.
2. Assign a transaction priority to each transaction in the pool.
3. Select transactions to include in the current block using probability in
transaction priority order until the target block size is met.
5. Solve block.
6. Broadcast the next target block size with the current block when it is
solved.
7. Block is received.
8. Block verification process.
9. Accept/reject block based on verification result.
10. Repeat.

## Closing comments:
It may be possible to verify blocks conform to the proposal by showing that
the probability for all transactions included in the block statistically
conforms to a probability distribution curve, *if* the individual
transaction priority can be recreated. I am not that deep into the
mathematics; however, it may also be possible to use a similar method to do
this just based on the fee, that statistically, the blocks conform to a fee
distribution. Any zero fee transactions would have to be ignored. This
solution needs a clever mathematician.

I implore, at the very least, that we use some method that validates full
transaction reliability and enables scalability of block sizes. If not this
proposal, an alternative.

Regards,
Damian Williamson


_______________________________________________
bitcoin-dev mailing list
bitcoin-dev at lists.linuxfoundation.org
https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev



_______________________________________________
bitcoin-dev mailing list
bitcoin-dev at lists.linuxfoundation.org
https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171224/a8ce1cb4/attachment-0001.html>

From willtech at live.com.au  Sun Dec 24 03:44:26 2017
From: willtech at live.com.au (Damian Williamson)
Date: Sun, 24 Dec 2017 03:44:26 +0000
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction
 Priority For Ordering Transactions In Blocks
In-Reply-To: <CA+Cf5AaX5a5yuLcnkk=7boiqrSrZf4KG_RjSOF1-2qJtB9ds+Q@mail.gmail.com>
References: <PS2P216MB01794ABD544248B27BF0DFD99D330@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<PS2P216MB01795BFC05612E021CCEDD7C9D0B0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<5upGmF0IhXUWhcikhdV-e9Pqg-kXfUuXe0kOpGxumie_TO2jLvCgTZ5c6vgBRtaqkL6DmOJb1YftK0osufB5RkhW7YhAhhCI0zBTH3YcORY=@protonmail.com>
	<PS2P216MB0179544A6503C2992190CEB69D0B0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<PS2P216MB0179D6A5965D0CFFEFB2880A9D090@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<AB6BF756-29F1-4442-85A9-B81228E829EC@friedenbach.org>
	<PS2P216MB017991D78147E2B1EC14C3059D0F0@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
	<PS2P216MB0179FC39F4A63A43BB70011A9D020@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>,
	<CA+Cf5AaX5a5yuLcnkk=7boiqrSrZf4KG_RjSOF1-2qJtB9ds+Q@mail.gmail.com>
Message-ID: <PS2P216MB0179D452E5D478511B46E0879D000@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>

>.. This system has flaws, they all do.


>The simple fact is that there is currently no known system that works as well as the current system..


Alright, but, we seem to agree, the current system also has flaws. The transaction bandwidth limit is a serious issue for transactional reliability.


What you have proposed is interesting but seems to do nothing for the issue of transaction bandwidth, which seems to be approaching its threshold:

https://bitinfocharts.com/comparison/bitcoin-transactions.html


Regards,

Damian Williamson

________________________________
From: Spartacus Rex <spartacusrex99 at gmail.com>
Sent: Saturday, 23 December 2017 5:07:49 AM
To: Damian Williamson; Bitcoin Protocol Discussion
Subject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks

Hi Damian,

Thought I'd chip in.  This is a hard fork scenario. This system has flaws, they all do.

If you had a fixed fee per block, so that every txn in that block paid the same fee, that might make it easier to include all txns eventually, as you envisage.

The fee could be calculated as the average of the amount txns are prepared to pay in the last 1000 blocks.

A txn would say ' I'll pay up to X bitcoins ' and as long as that is more than the value required for the block your txn can be added. This is to ensure you don't pay more than you are willing.  It also ensures that putting an enormous fee will not ensure your txn is processed quickly..

Calculating what the outputs are given a variable fee needs a new mechanism all of it's own, but I'm sure it's possible.

The simple fact is that there is currently no known system that works as well as the current system..

But there are other systems.


On Dec 22, 2017 15:09, "Damian Williamson via bitcoin-dev" <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:

If the cash value of Bitcoin was high enough and zero fee transactions were never accepted and not counted when calculating the transaction pool size then I do not think it would be such an issue. Why is it even possible to create zero fee transactions?


Regards,

Damian Williamson

________________________________
From: bitcoin-dev-bounces at lists.linuxfoundation.org<mailto:bitcoin-dev-bounces at lists.linuxfoundation.org> <bitcoin-dev-bounces at lists.linuxfoundation.org<mailto:bitcoin-dev-bounces at lists.linuxfoundation.org>> on behalf of Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>>
Sent: Tuesday, 19 December 2017 6:51 PM
To: Mark Friedenbach
Cc: bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks


Thank you for your constructive feedback. I now see that the proposal introduces a potential issue.


>Finally in terms of the broad goal, having block size based on the number of transactions is NOT something desirable in the first place, even if it did work. That?s effectively the same as an infinite block size since anyone anywhere can create transactions in the mempool at no cost.


Do you have any critical suggestion as to how transaction bandwidth limit could be addressed, it will eventually become an issue if nothing is changed regardless of how high fees go?


Regards,

Damian Williamson



________________________________
From: Mark Friedenbach <mark at friedenbach.org<mailto:mark at friedenbach.org>>
Sent: Tuesday, 19 December 2017 3:08 AM
To: Damian Williamson
Subject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks

Damian, you seem to be misunderstanding that either

(1) the strong form of your proposal requires validating the commitment to the mempool properties, in which case the mempool becomes consensus critical (an impossible requirement); or

(2) in the weak form where the current block is dependent on the commitment in the last block only it is becomes a miner-selected field they can freely parameterize with no repercussions for setting values totally independent of the actual mempool.

If you want to make the block size dependent on the properties of the mempool in a consensus critical way, flex cap achieves this. If you want to make the contents or properties of the mempool known to well-connected nodes, weak blocks achieves that. But you can?t stick the mempool in consensus because it fundamentally is not something the nodes have consensus over. That?s a chicken-and-the-egg assumption.

Finally in terms of the broad goal, having block size based on the number of transactions is NOT something desirable in the first place, even if it did work. That?s effectively the same as an infinite block size since anyone anywhere can create transactions in the mempool at no cost.

On Dec 16, 2017, at 8:14 PM, Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:

I do not know why people make the leap that the proposal requires a consensus on the transaction pool. It does not.

It may be helpful to have the discussion from the previous thread linked here.
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/015370.html

Where I speak of validating that a block conforms to the broadcast next block size, I do not propose validating the number broadcast for the next block size itself, only that the next generated block is that size.

Regards,
Damian Williamson


________________________________
From: Damian Williamson <willtech at live.com.au<mailto:willtech at live.com.au>>
Sent: Saturday, 16 December 2017 7:59 AM
To: Rhavar
Cc: Bitcoin Protocol Discussion
Subject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks

There are really two separate problems to solve.


  1.  How does Bitcoin scale with fixed block size?
  2.  How do we ensure that all valid transactions are eventually included in the blockchain?

Those are the two issues that the proposal attempts to address. It makes sense to resolve these two problems together. Using the proposed system for variable block sizes would solve the first problem but there would still be a whole bunch of never confirming transactions. I am not sure how to reliably solve the second problem at scale without first solving the first.

>* Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.

I do not suggest a consensus. Depending on which node solves a block the value for next block size will be different. The consensus would be that blocks will adhere to the next block size value transmitted with the current block. It is easy to verify that the consensus is being adhered to once in place.

>* Increasing the entropy in a block to make it more unpredictable doesn't really make sense.

Not a necessary function, just an effect of using a probability-based distribution.

>* Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by "priority".  What are you going to do if a "malicious" miner decides to go after their profits and order by what makes them the most money. Add "ordered by priority" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.

I entirely agree with your sentiment that Bitcoin must be incentive compatible. It is necessary.

It is in only miners immediate interest to make the most profitable block from the available transaction pool. As with so many other things, it is necessary to partially ignore short-term gain for long-term benefit. It is in miners and everybody's long-term interest to have a reliable transaction service. A busy transaction service that confirms lots of transactions per hour will become more profitable as demand increases and more users are prepared to pay for priority. As it is there is currently no way to fully scale because of the transaction bandwidth limit and that is problematic. If all valid transactions must eventually confirm then there must be a way to resolve that problem.

Bitcoin deliberately removes traditional scale by ensuring blocks take ten minutes on average to solve, an ingenious idea and, incentive compatible but, fixed block sizes leaves us with a problem to solve when we want to scale.

>If you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.

I am confident that the math to verify blocks based on the proposal can be developed (and I think it will not be too complex for a mathematician with the relevant experience), however, I am nowhere near experienced enough with probability and statistical analysis to do it. Yes, if Bitcoin doesn't then it might make another great opportunity for an altcoin but I am not even nearly interested in promoting any altcoins.

If not the proposal that I have put forward, then, hopefully, someone can come up with a better solution. The important thing is that the issues are resolved.

Regards,
Damian Williamson


________________________________
From: Rhavar <rhavar at protonmail.com<mailto:rhavar at protonmail.com>>
Sent: Saturday, 16 December 2017 3:38 AM
To: Damian Williamson
Cc: Bitcoin Protocol Discussion
Subject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks

> I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?

Unfortunately your proposal is really fundamentally broken, on a few levels. I think you might need to do a bit more research into how bitcoin works before coming up with such improvements =)

But just some quick notes:

* Every node has a (potentially) different mempool, you can't use it to decide consensus values like the max block size.

* Increasing the entropy in a block to make it more unpredictable doesn't really make sense.

* Bitcoin should be roughly incentive compatible. Your proposal explicits asks miners to ignore their best interests, and confirm transactions by "priority".  What are you going to do if a "malicious" miner decides to go after their profits and order by what makes them the most money. Add "ordered by priority" as a consensus requirement? And even if you miners can still sort their mempool by fee, and then order the top 1MB by priority.

If you could find a good solution that would allow you to know if miners were following your rule or not (and thus ignore it if it doesn't) then you wouldn't even need bitcoin in the first place.




-Ryan


-------- Original Message --------
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks
Local Time: December 15, 2017 3:42 AM
UTC Time: December 15, 2017 9:42 AM
From: bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>
To: Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>>



I should not take it that the lack of critical feedback to this revised proposal is a glowing endorsement. I understand that there would be technical issues to resolve in implementation, but, are there no fundamental errors?

I suppose that it if is difficult to determine how long a transaction has been waiting in the pool then, each node could simply keep track of when a transaction was first seen. This may have implications for a verify routine, however, for example, if a node was offline, how should it differentiate how long each transaction was waiting in that case? If a node was restarted daily would it always think that all transactions had been waiting in the pool less than one day If each node keeps the current transaction pool in a file and updates it, as transactions are included in blocks and, as new transactions appear in the pool, then that would go some way to alleviate the issue, apart from entirely new nodes. There should be no reason the contents of a transaction pool files cannot be shared without agreement as to the transaction pool between nodes, just as nodes transmit new transactions freely.

It has been questioned why miners could not cheat. For the question of how many transactions to include in a block, I say it is a standoff and miners will conform to the proposal, not wanting to leave transactions with valid fees standing, and, not wanting to shrink the transaction pool. In any case, if miners shrink the transaction pool then I am not immediately concerned since it provides a more efficient service. For the question of including transactions according to the proposal, I say if it is possible to keep track of how long transactions are waiting in the pool so that they can be included on a probability curve then it is possible to verify that blocks conform to the proposal, since the input is a probability, the output should conform to a probability curve.


If someone has the necessary skill, would anyone be willing to develop the math necessary for the proposal?

Regards,
Damian Williamson


________________________________

From: bitcoin-dev-bounces at lists.linuxfoundation.org<mailto:bitcoin-dev-bounces at lists.linuxfoundation.org> <bitcoin-dev-bounces at lists.linuxfoundation.org<mailto:bitcoin-dev-bounces at lists.linuxfoundation.org>> on behalf of Damian Williamson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>>
Sent: Friday, 8 December 2017 8:01 AM
To: bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks


Good afternoon,

The need for this proposal:

We all must learn to admit that transaction bandwidth is still lurking as a serious issue for the operation, reliability, safety, consumer acceptance, uptake and, for the value of Bitcoin.

I recently sent a payment which was not urgent so; I chose three-day target confirmation from the fee recommendation. That transaction has still not confirmed after now more than six days - even waiting twice as long seems quite reasonable to me. That transaction is a valid transaction; it is not rubbish, junk or, spam. Under the current model with transaction bandwidth limitation, the longer a transaction waits, the less likely it is ever to confirm due to rising transaction numbers and being pushed back by transactions with rising fees.

I argue that no transactions are rubbish or junk, only some zero fee transactions might be spam. Having an ever-increasing number of valid transactions that do not confirm as more new transactions with higher fees are created is the opposite of operating a robust, reliable transaction system.

Business cannot operate with a model where transactions may or may not confirm. Even a business choosing a modest fee has no guarantee that their valid transaction will not be shuffled down by new transactions to the realm of never confirming after it is created. Consumers also will not accept this model as Bitcoin expands. If Bitcoin cannot be a reliable payment system for confirmed transactions then consumers, by and large, will simply not accept the model once they understand. Bitcoin will be a dirty payment system, and this will kill the value of Bitcoin.

Under the current system, a minority of transactions will eventually be the lucky few who have fees high enough to escape being pushed down the list.

Once there are more than x transactions (transaction bandwidth limit) every ten minutes, only those choosing twenty-minute confirmation (2 blocks) will have initially at most a fifty percent chance of ever having their payment confirm. Presently, not even using fee recommendations can ensure a sufficiently high fee is paid to ensure transaction confirmation.

I also argue that the current auction model for limited transaction bandwidth is wrong, is not suitable for a reliable transaction system and, is wrong for Bitcoin. All transactions must confirm in due time. Currently, Bitcoin is not a safe way to send payments.

I do not believe that consumers and business are against paying fees, even high fees. What is required is operational reliability.

This great issue needs to be resolved for the safety and reliability of Bitcoin. The time to resolve issues in commerce is before they become great big issues. The time to resolve this issue is now. We must have the foresight to identify and resolve problems before they trip us over.  Simply doubling block sizes every so often is reactionary and is not a reliable permanent solution. I have written a BIP proposal for a technical solution but, need your help to write it up to an acceptable standard to be a full BIP.

I have formatted the following with markdown which is human readable so, I hope nobody minds. I have done as much with this proposal as I feel that I am able so far but continue to take your feedback.

# BIP Proposal: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks

## The problem:
Everybody wants value. Miners want to maximize revenue from fees (and we presume, to minimize block size). Consumers need transaction reliability and, (we presume) want low fees.

The current transaction bandwidth limit is a limiting factor for both. As the operational safety of transactions is limited, so is consumer confidence as they realize the issue and, accordingly, uptake is limited. Fees are artificially inflated due to bandwidth limitations while failing to provide a full confirmation service for all transactions.

Current fee recommendations provide no satisfaction for transaction reliability and, as Bitcoin scales, this will worsen.

Bitcoin must be a fully scalable and reliable service, providing full transaction confirmation for every valid transaction.

The possibility to send a transaction with a fee lower than one that is acceptable to allow eventual transaction confirmation should be removed from the protocol and also from the user interface.

## Solution summary:
Provide each transaction with an individual transaction priority each time before choosing transactions to include in the current block, the priority being a function of the fee paid (on a curve), and the time waiting in the transaction pool (also on a curve) out to n days (n=60 ?). The transaction priority to serve as the likelihood of a transaction being included in the current block, and for determining the order in which transactions are tried to see if they will be included.

Use a target block size. Determine the target block size using; current transaction pool size x ( 1 / (144 x n days ) ) = number of transactions to be included in the current block. Broadcast the next target block size with the current block when it is solved so that nodes know the next target block size for the block that they are building on.

The curves used for the priority of transactions would have to be appropriate. Perhaps a mathematician with experience in probability can develop the right formulae. My thinking is a steep curve. I suppose that the probability of all transactions should probably account for a sufficient number of inclusions that the target block size is met although, it may not always be. As a suggestion, consider including some zero fee transactions to pad, highest BTC value first?

**Explanation of the operation of priority:**
> If transaction priority is, for example, a number between one (low) and one-hundred (high) it can be directly understood as the percentage chance in one-hundred of a transaction being included in the block. Using probability or likelihood infers that there is some function of random. If random (100) < transaction priority then the transaction is included.

>To break it down further, if both the fee on a curve value and the time waiting on a curve value are each a number between one and one-hundred, a rudimentary method may be to simply multiply those two numbers, to find the priority number. For example, a middle fee transaction waiting thirty days (if n = 60 days) may have a value of five for each part  (yes, just five, the values are on a curve). When multiplied that will give a priority value of twenty-five, or,  a twenty-five percent chance at that moment of being included in the block; it will likely be included in one of the next four blocks, getting more likely each chance. If it is still not included then the value of time waiting will be higher, making for more probability. A very low fee transaction would have a value for the fee of one. It would not be until near sixty-days that the particular low fee transaction has a high likelihood of being included in the block.

I am not concerned with low (or high) transaction fees, the primary reason for addressing the issue is to ensure transactional reliability and scalability while having each transaction confirm in due time.

## Pros:
* Maximizes transaction reliability.
* Fully scalable.
* Maximizes possibility for consumer and business uptake.
* Maximizes total fees paid per block without reducing reliability; because of reliability, in time confidence and overall uptake are greater; therefore, more transactions.
* Market determines fee paid for transaction priority.
* Fee recommendations work all the way out to 30 days or greater.
* Provides additional block entropy; greater security since there is less probability of predicting the next block.

## Cons:
* Could initially lower total transaction fees per block.
* Must be first be programmed.

## Solution operation:
This is a simplistic view of the operation. The actual operation will need to be determined in a spec for the programmer.

1. Determine the target block size for the current block.
2. Assign a transaction priority to each transaction in the pool.
3. Select transactions to include in the current block using probability in transaction priority order until the target block size is met.
5. Solve block.
6. Broadcast the next target block size with the current block when it is solved.
7. Block is received.
8. Block verification process.
9. Accept/reject block based on verification result.
10. Repeat.

## Closing comments:
It may be possible to verify blocks conform to the proposal by showing that the probability for all transactions included in the block statistically conforms to a probability distribution curve, *if* the individual transaction priority can be recreated. I am not that deep into the mathematics; however, it may also be possible to use a similar method to do this just based on the fee, that statistically, the blocks conform to a fee distribution. Any zero fee transactions would have to be ignored. This solution needs a clever mathematician.

I implore, at the very least, that we use some method that validates full transaction reliability and enables scalability of block sizes. If not this proposal, an alternative.

Regards,
Damian Williamson


_______________________________________________
bitcoin-dev mailing list
bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>
https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev


_______________________________________________
bitcoin-dev mailing list
bitcoin-dev at lists.linuxfoundation.org<mailto:bitcoin-dev at lists.linuxfoundation.org>
https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171224/7a79fb9d/attachment-0001.html>

From willtech at live.com.au  Tue Dec 26 05:14:14 2017
From: willtech at live.com.au (Damian Williamson)
Date: Tue, 26 Dec 2017 05:14:14 +0000
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction
 Priority For Ordering Transactions In Blocks
Message-ID: <PS2P216MB01797C7635C98C5CEF1015529D060@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>

I have needed to re-tac my intentions somewhat, there is still much
work to be done.

This is a request for assistance and further discussion of the re-
revised proposal. I am sure there are still issues to be resolved.

##?BIP Proposal: UTPFOTIB - Use Transaction Priority For Ordering
Transactions In Blocks

Schema:??
##########??
Document: BIP Proposal??
Title: UTPFOTIB - Use Transaction Priority For Ordering Transactions In
Blocks??
Date: 26-12-2017??
Author: Damian Williamson &lt;willtech at live.com.au&gt; ?
Licence: Creative Commons Attribution-ShareAlike 4.0 International
License.??
URL: http://thekingjameshrmh.tumblr.com/post/168948530950/bip-proposal-
utpfotib-use-transaction-priority-for-order??
##########??

### 1. Abstract

This document proposes to address the issue of transactional
reliability in Bitcoin, where valid transactions may be stuck in the
transaction pool for extended periods or never confirm.

There are two key issues to be resolved to achieve this:

1.??The current transaction bandwidth limit.
2.??The current ad-hoc methods of including transactions in blocks
resulting in variable and confusing confirmation times for valid
transactions, including transactions with a valid fee that may never
confirm.

It is important with any change to protect the value of fees as these
will eventually be the only payment that miners receive. Rather than an
auction model for limited bandwidth, the proposal results in a fee for
priority service auction model.

It would not be true to suggest that all feedback received so far has
been entirely positive although, most of it has been constructive.

The previous threads for this proposal are available here: ?
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-December/s
ubject.html

In all parts of this proposal, references to a transaction, a valid
transaction, a transaction with a valid fee, a valid fee, etc. is
defined as any transaction that is otherwise valid with a fee of at
least 0.00001000 BTC/KB as defined as the dust level, interpreting from
Bitcoin Core GUI. Transactions with a fee lower than this rate are
considered dust.

In all parts of this proposal, dust and zero-fee transactions are
always ignored and/or excluded unless specifically mentioned.

It is generally assumed that miners currently prefer to include
transactions with higher fees.

### 2. The need for this proposal

We all must learn to admit that transaction bandwidth is still lurking
as a serious issue for the operation, reliability, safety, consumer
acceptance, uptake and, for the value of Bitcoin.

I recently sent a payment which was not urgent so; I chose three-day
target confirmation from the fee recommendation. That transaction has
still not confirmed after now more than six days - even waiting twice
as long seems quite reasonable to me (note for accuracy: it did
eventually confirm). That transaction is a valid transaction; it is not
rubbish, junk or, spam. Under the current model with transaction
bandwidth limitation, the longer a transaction waits, the less likely
it is ever to confirm due to rising transaction numbers and being
pushed back by transactions with rising fees.

I argue that no transactions with fees above the dust level are rubbish
or junk, only some zero fee transactions might be spam. Having an ever-
increasing number of valid transactions that do not confirm as more new
transactions with higher fees are created is the opposite of operating
a robust, reliable transaction system.

Business cannot operate with a model where transactions may or may not
confirm. Even a business choosing a modest fee has no guarantee that
their valid transaction will not be shuffled down by new transactions
to the realm of never confirming after it is created. Consumers also
will not accept this model as Bitcoin expands. If Bitcoin cannot be a
reliable payment system for confirmed transactions then consumers, by
and large, will simply not accept the model once they understand.
Bitcoin will be a dirty payment system, and this will kill the value of
Bitcoin.

Under the current system, a minority of transactions will eventually be
the lucky few who have fees high enough to escape being pushed down the
list.

Once there are more than x transactions (transaction bandwidth limit)
every ten minutes, only those choosing twenty-minute confirmation (2
blocks) from the fee recommendations will have initially at most a
fifty percent chance of ever having their payment confirm when 2x
transactions is reached. Presently, not even using fee recommendations
can ensure a sufficiently high fee is paid to ensure transaction
confirmation.

I also argue that the current auction model for limited transaction
bandwidth is wrong, is not suitable for a reliable transaction system
and, is wrong for Bitcoin. All transactions with valid fees must
confirm in due time. Currently, Bitcoin is not a safe way to send
payments.

I do not believe that consumers and business are against paying fees,
even high fees. What is required is operational reliability.

This great issue needs to be resolved for the safety and reliability of
Bitcoin. The time to resolve issues in commerce is before they become
great big issues. The time to resolve this issue is now. We must have
the foresight to identify and resolve problems before they trip us
over.??Simply doubling block sizes every so often is reactionary and is
not a reliable permanent solution.

I have written this proposal for a technical solution but, need your
help to write it up to an acceptable standard to be a full BIP.

### 3. The problem

Everybody wants value. Miners want to maximise revenue from fees (and
we presume, to minimise block size). Consumers need transaction
reliability and, (we presume) want low fees.

The current transaction bandwidth limit is a limiting factor for both.
As the operational safety of transactions is limited, so is consumer
confidence as they realise the issue and, accordingly, uptake is
limited. Fees are artificially inflated due to bandwidth limitations
while failing to provide a full confirmation service for all valid
transactions.

Current fee recommendations provide no satisfaction for transaction
reliability and, as Bitcoin scales, this will worsen.

Transactions are included in blocks by miners using whatever basis they
prefer. We expect that this is usually a fee-based priority. However,
even transactions with a valid fee may be left in the transaction pool
for some time. As transaction bandwidth becomes an issue, not even
extreme fees can ensure a transaction is processed in a timely manner
or at all.

Bitcoin must be a fully scalable and reliable service, providing full
transaction confirmation for every valid transaction.

The possibility to send a transaction with a fee lower than one that is
acceptable to allow eventual transaction confirmation should be removed
from the protocol and also from the user interface.

### 4. Solution summary

#### Main solution

Provide each valid transaction in the mempool with an individual
transaction priority each time before choosing transactions to include
in the current block. The priority being a function of the fee (on a
curve), and the time waiting in the transaction pool (also on a curve)
out to n days (n = 60 days ?), and extending past n days. The value for
fee on a curve may need an upper limit. The transaction priority to
serve as the likelihood of a transaction being included in the current
block, and for determining the order in which transactions are tried to
see if they will be included.

Nodes will need to keep track of when a transaction is first seen. It
is satisfactory for each node to do this independently provided the
information survives node restart. If there is a more reliable way to
determine when a transaction was first seen on the network then it
should be utilised.

Use a dynamic target block size to make the current block. If the block
size is consistently too small then I expect ageing transactions will
be overrepresented as a portion of the block contents, to the point
where blocks will only contain the oldest transactions as they age past
n days. If block size is too large on average then this will shrink the
transaction pool. Determine the target block size using; pre-
rollout(current average valid transaction pool size) x ( 1 / (144 x n
days ) ) = number of transactions to be included in the current block.
The block created should be a minimum 1MB in size regardless if the
target block size is lower.

Nodes that have not yet adopted the proposal will just continue to
create 1MB unordered blocks.

The default value for mempoolexpiry may in future need to be adjusted
to match n days or, perhaps using less than n = 14 days may be a more
sensible approach?

All block created with dynamic size should be verified to ensure
conformity to a probability distribution curve resulting from the
priority method. Since the input is a probability, the output should
conform to a probability distribution.

The curves used for the priority of transactions would have to be
appropriate. Perhaps a mathematician with experience in probability can
develop the right formulae. My thinking is a steep curve. I suppose
that the probability of all transactions should probably account for a
sufficient number of inclusions that the target block size is met on
average although, it may not always be. As a suggestion, consider
including some dust or zero-fee transactions to pad if each valid
transaction is tried and the target block size is not yet met, highest
BTC transaction value first?

**Explanation of the operation of priority:**

> If transaction priority is, for example, a number between one (low)
and one-hundred (high) it can be directly understood as the percentage
chance in one-hundred of a transaction being included in the block.
Using probability or likelihood infers that there is some function of
random. Try the transactions in priority order from highest to lowest,
if random (100) < transaction priority then the transaction is included
until the target block size is met.

> To break it down further, if both the fee on a curve value and the
time waiting on a curve value are each a number between one and one-
hundred, a rudimentary method may be to simply multiply those two
numbers, to find the priority number. For example, a middle fee
transaction waiting thirty days (if n = 60 days) may have a value of
five for each part??(yes, just five, the values are on a curve). When
multiplied that will give a priority value of twenty-five, or, a
twenty-five percent chance at that moment of being included in the
block; it will likely be included in one of the next four blocks,
getting more likely each chance. If it is still not included then the
value of time waiting will be higher, making for more probability. A
very low fee transaction would have a value for the fee of one. It
would not be until near sixty-days that the particular low fee
transaction has a high likelihood of being included in the block.

In practice it may be more useful to use numbers representative of one-
hundred for the highest fee priority curve down to a small fraction of
one for the lowest fee and, from one for a newly seen transaction up to
a proportionately high number above one-hundred for the time waiting
curve. It is truely beyond my level of math to resolve probability
curves accurately without much trial and error.

The primary reason for addressing the issue is to ensure transactional
reliability and scalability while having each valid transaction confirm
in due time.

#### Pros

*???Maximizes transaction reliability.
*???Overcomes transaction bandwidth limit.
*???Fully scalable.
*???Maximizes possibility for consumer and business uptake.
*???Maximizes total fees paid per block without reducing reliability;
because of reliability, in time confidence and overall uptake are
greater; therefore, more transactions.
*???Market determines fee paid for transaction priority.
*???Fee recommendations work all the way out to 30 days or greater.
*???Provides additional block entropy; greater security since there is
less probability of predicting the next block. _Although this is not
necessary it is a product of the operation of this proposal._

#### Cons

*???Could initially lower total transaction fees per block.
*???Must be first be programmed.

#### Pre-rollout

Nodes need to have at a minimum a loose understanding of the average
(since there is no consensus) size of the transaction pool as a
requirement to enable future changes to the way blocks are constructed.

A new network service should be constructed to meet this need. This
service makes no changes to any existing operation or function of the
node. Initially, Bitcoin Core is a suitable candidate.

**The service must:**

*???Have an individual temporary (runtime permanent only) Serial Node
ID.
*???Accept communication of the number of valid transactions in the
mempool of another valid Bitcoin node along with the Serial Node ID of
the node whose value is provided.
*???Disconnect the service from any non-Bitcoin node. Bitcoin Core may
handle this already?
*???Expire any value not updated for k minutes (k = 30 minutes?).
*???Broadcast all mempool information the node has every m minutes (m =
10 minutes?), including its own.
*???Nodes own mempool information should not be broadcast or used in
calculation until the node has been up long enough for the mempool to
normalise for at least o minutes (o = 300 minutes ?)
*???Only new or updated mempool values should be transmitted to the
same node. Updated includes updated with no change.
*???All known mempool information must survive node restart.
*???If the nodes own mempool is not normalised and network information
is not available to calculate an average just display zero.
*???Internally, the average transaction pool size must return the
calculated average if an average is available or, if none is available
just the number of valid transactions in the node's own mempool
regardless if it is normalised.

Bitcoin Core must use all collated information on mempool size to
calculate a figure for the average mempool size.

The calculated figure should be displayed in the appropriate place in
the Debug window alongside the text Network average transactions.

Consideration must be given before development of the network bandwidth
this would require. All programming must be consistent with the current
operation and conventions of Bitcoin Core. Methods must work on all
platforms.

As this new service does not affect any existing service or feature of
Bitcoin or Bitcoin Core, this can technically be programmed now and
included in Bitcoin Core at any time.

### 5. Solution operation

This is a simplistic view of the operation. The actual operation will
need to be determined accurately in a spec for the programmer.

1.??Determine the target block size for the current block.
2.??Assign a transaction priority to each valid transaction in the
mempool.
3.??Select transactions to include in the current block using
probability in transaction priority order until the target block size
is met. If target block size is not met, include dust and zero-fee
transactions to pad.
4.??Solve block.
5.??Broadcast the current block when it is solved.
6.??Block is received.
7.??Block verification process.
8.??Accept/reject block based on verification result.
9.??Repeat.

### 6. Closing comments

It may be possible to verify blocks conform to the proposal by showing
that the probability for all transactions included in the block
statistically conforms to a probability distribution curve, *if* the
individual transaction priority can be recreated. I am not that deep
into the mathematics; however, it may also be possible to use a similar
method to do this just based on the fee, that statistically, the block
conforms to a fee distribution. Any dust and zero-fee transactions
would have to be ignored. This solution needs a competent mathematician
with experience in probability and statistical distribution.

There has been some concern expressed over spam and very low fee
transactions, and an infinite block size resulting. I hope that for
those concerned using the dust level addresses the issue, especially as
the value of Bitcoin grows.

This proposal is necessary. I implore, at the very least, that we use
some method that validates full transaction reliability and enables
scalability of Bitcoin. If not this proposal, an alternative.

I have done as much with this proposal as I feel that I am able so far
but continue to take your feedback.

Regards,??
Damian Williamson

[![Creative Commons License](https://i.creativecommons.org/l/by-sa/4.0/
88x31.png)](http://creativecommons.org/licenses/by-sa/4.0/)??
<span xmlns:dct="http://purl.org/dc/terms/"
href="http://purl.org/dc/dcmitype/Text" property="dct:title"
rel="dct:type">BIP Proposal: UTPFOTIB - Use Transaction Priority For
Ordering Transactions In Blocks</span> by [Damian Williamson
&lt;willtech at live.com.au&gt;](http://thekingjameshrmh.tumblr.com/post/1
68948530950/bip-proposal-utpfotib-use-transaction-priority-for-order)
is licensed under a [Creative Commons Attribution-ShareAlike 4.0
International License](http://creativecommons.org/licenses/by-sa/4.0/).
Based on a work at [https://lists.linuxfoundation.org/pipermail/bitcoin
-dev/2017-
December/015371.html](https://lists.linuxfoundation.org/pipermail/bitco
in-dev/2017-December/015371.html).
Permissions beyond the scope of this license may be available at [https
://opensource.org/licenses/BSD-3-
Clause](https://opensource.org/licenses/BSD-3-Clause).

From ZmnSCPxj at protonmail.com  Wed Dec 27 03:55:43 2017
From: ZmnSCPxj at protonmail.com (ZmnSCPxj)
Date: Tue, 26 Dec 2017 22:55:43 -0500
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction
	Priority For Ordering Transactions In Blocks
In-Reply-To: <PS2P216MB01797C7635C98C5CEF1015529D060@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
References: <PS2P216MB01797C7635C98C5CEF1015529D060@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>
Message-ID: <ONt0j-_38AOpm9ldDOakEZXEmS-psPbkKn2NFscLYYZ8Q_VEMdbrmQBeSXlqmg2C_O8BmniVTY-CVrh-AzhSv8x7UXuuzvziqPQH8mM_fpA=@protonmail.com>

Good morning Damian,

I see you have modified your proposal to be purely driven by miners, with fullnodes not actually being able to create a strict "yes-or-no" answer as to block validity under your rules.  This implies that your rules cannot be enforced and that rational miners will ignore your proposal unless it brings in more money for them.  The fact that your proposal provides some mechanism to increase block size means that miners will be incentivized to falsify data (by making up their own transactions just above your fixed "dust size" threshhold whatever that threshhold may be -- and remember, miners get at least 12.5 BTC per block, so they can make a lot of little falsified transactions to justify every block size increase) until the block size increase per block is the maximum possible block size increase.

--

Let me then explain proof-of-work and the arrow of time in Physics.  It may seem a digression, but please, bear with me.

Proof-of-work proves that work was performed, and (crucially) that this work was done in the past.

This is important because of the arrow of time.

In principle, every physical interaction is reversible.  Visualize a video of two indivisible particles.  The two particles move towards each other, collide, and because of the collision, fly apart. If you ran this video in reverse, or in forward, it would not be distinguishable to you, as an outside observer, whether the video was running in reverse or not.  It seems at some level, time does not exist.

And yet time exists.

Consider another video, that of a vase being dropped on a hard surface.  The vase hits the surface and shatters.  Played in reverse, we can judge it as nonsensical: scattered pieces of ceramic spontaneously forming a vase and then flying upwards.  This orients our arrow of time: the arrow of time points from states of the universe where lesser entropy exists (the vase is whole) to where greater entropy exists (the vase is in many pieces).

Indeed, all measures of time are, directly or indirectly, measures of increases in entropy.  Consider a simple hourglass: you place it into a state of low entropy and high energy with most of the sand is in the upper part of the hourglass.  As sand falls, and more of that energy is lost into entropy, you judge that time passes.

Consider a proof-of-work algorithm: you place electrons into a state of low entropy and high energy.  As electrons go through the mining hardware, producing hashes that pass the difficulty requirement, the energy in those electrons is lost into entropy (heat), and from the hashes produced (which proves not only that work was done, but in particular, that entropy increased due to work being done), you judge that time passes.

--

Thus, the blockchain itself is already a service that provides a measure of time.  When a block commits to a transaction, then that transaction is known to have existed at that block height, at the latest.

Thus one idea, is to have each block commit to some view of the mempool.  If a transaction exists in this mempool-view, then you know that the transaction is at least that old, and can judge the age from this and use this to compute the "transaction priority".

Unfortunately, transferring the data to prove that the mempool-view is valid, is equivalent to always sweeping the entire mempool contents per block.  In that case you might as well not have a block size limit.

In addition, miners may still commit to a falsely-empty mempool and deny that your transaction is old and therefore priority and therefore will simply fill their blocks with transactions that have high feerates rather than high priority.  Thus feerate will still be the ultimate measure.

Rather than attempt this, perhaps developers should be encouraged to make use of existing mechanisms, RBF and CPFP, to allow transactions to be sped up by directly manipulating feerates, as priority (by your measure) is not practically computable.

Regards,
ZmnSCPxj
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171226/61caf1d1/attachment.html>

From th.heuer at gmail.com  Wed Dec 27 12:09:17 2017
From: th.heuer at gmail.com (Tim-Hinnerk Heuer)
Date: Wed, 27 Dec 2017 12:09:17 +0000
Subject: [bitcoin-dev] Hash Graph - Applied to BTC?
Message-ID: <CAApG7tYjZeGCfcsPHgFPDK5bfN_m9UrF5kNTZP5ov2Q0ed2afw@mail.gmail.com>

Is it possible to make a hard fork of Bitcoin that implements Hash Graph?
Is this legal as Hash Graph is proprietary licensed? Even though the
license does not agree with open source, the algorithm is open and
potentially could be implemented while still giving value to "old" crypto
currency tokens and keys.

Bitcoin to scale to billions if not trillions of transactions per second.

It is known that Bitcoin has a scaling problem. 6 transactions per second
is not enough to sustain a global economy. Lightning promises to solve this
but it's still not implemented fully?!

I transferred a small amount of BTC to Ethereum and it took several days on
a small priority.

Just a simple Wallet (Coinomi).

Have installed a full Bitcoin wallet but tried also easier to use
implementations such as Jaxx and Coinomi.

I'm happy to do some coding as I am a programmer, but haven't had any
notable experience with implementing crypto algorithms before. However, I
have plenty of experience implementing algorithms.

No debug log at this time.


Regards,

Tim
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171227/9d22877d/attachment.html>

From dkbryant at gmail.com  Thu Dec 28 19:55:01 2017
From: dkbryant at gmail.com (Dan Bryant)
Date: Thu, 28 Dec 2017 13:55:01 -0600
Subject: [bitcoin-dev] Transaction aging to relieve user concerns.
Message-ID: <CAAUFj12x+kRUkcWECesJJRybDsQWfNL_7-D3wYexr6mOUzBY9g@mail.gmail.com>

I was considering starting a BIP, but wanted to ask the thread if anything
like this was already done or in the works.  My proposal is to expand the
TXN format to include chain-height (block number) in the TXN.  This would
allow nodes / miners to age the TXN and choose (optionally) not to
rebroadcast it after a certain age threshold.  Currently (as I understand
it), nodes and miners keep effectively a "seen-list" of TXNs and age them
based upon when they were last seen.  This is very effective as it reduces
TXN size and frees the TXN from having to declare its age.  The downside to
this is that those TXNs could be broadcast forever, assuming (big assume)
that the UTXO never got spent.

The goal here is not to enhance the protocol... if anything this would
increase TXN cost as it would add a few bytes to it.  The goal here is to
make it easier for users to know with better certainty when an TXN is going
to age out.  Obviously RBF is a better solution, but there may be some
instances when a user wants to effectively cancel a TXN.

Possible abuse vectors might include:

* Bad party broadcasting a low fee TXN at the edge of the age-out threshold
and trying to get goods, realizing the TXN will age out at the very next
block.

If this proposal might be something that core would entertain in a BIP
proposal I'll start drafting something.  If there are suggestions about
where to place the block number to have minimal impact and ensure backward
compatibility, that would be great to.  If this is simply silly and should
not be entertained, no harm there either.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171228/8dd7f6b2/attachment.html>

From mark at friedenbach.org  Thu Dec 28 20:49:38 2017
From: mark at friedenbach.org (Mark Friedenbach)
Date: Thu, 28 Dec 2017 12:49:38 -0800
Subject: [bitcoin-dev] Transaction aging to relieve user concerns.
In-Reply-To: <CAAUFj12x+kRUkcWECesJJRybDsQWfNL_7-D3wYexr6mOUzBY9g@mail.gmail.com>
References: <CAAUFj12x+kRUkcWECesJJRybDsQWfNL_7-D3wYexr6mOUzBY9g@mail.gmail.com>
Message-ID: <6A60B31A-41CE-40FF-A604-05EB97CAA3B4@friedenbach.org>

However users can?t know with any certainty whether transactions will ?age out? as indicated, since this is only relay policy. Exceeding the specified timeout doesn?t prevent a miner from including it in the chain, and therefore doesn?t really provide any actionable information.

> On Dec 28, 2017, at 11:55 AM, Dan Bryant via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
> 
> The goal here is to make it easier for users to know with better certainty when an TXN is going to age out

From willtech at live.com.au  Wed Dec 27 12:29:41 2017
From: willtech at live.com.au (Damian Williamson)
Date: Wed, 27 Dec 2017 12:29:41 +0000
Subject: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction
 Priority For Ordering Transactions In Blocks
In-Reply-To: <ONt0j-_38AOpm9ldDOakEZXEmS-psPbkKn2NFscLYYZ8Q_VEMdbrmQBeSXlqmg2C_O8BmniVTY-CVrh-AzhSv8x7UXuuzvziqPQH8mM_fpA=@protonmail.com>
References: <PS2P216MB01797C7635C98C5CEF1015529D060@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>,
	<ONt0j-_38AOpm9ldDOakEZXEmS-psPbkKn2NFscLYYZ8Q_VEMdbrmQBeSXlqmg2C_O8BmniVTY-CVrh-AzhSv8x7UXuuzvziqPQH8mM_fpA=@protonmail.com>
Message-ID: <PS2P216MB0179B1A36650D63AA04566029D070@PS2P216MB0179.KORP216.PROD.OUTLOOK.COM>

Good evening ZmnSCPxj,


That you for your considered discussion.


Am I wrong to think that any fullnode can validate blocks conform to a probability distribution? In my understanding after adoption of the proposal, any full node could validate all properties that a block has that they now validate, apart from block size, and additionally that the block conforms to a probability distribution. It seems a yes-no result. Let us assume that such a probability distribution exists since the input is a probability.

Before or after the proposal, miners could falsify transactions if there is a feasible way for them to do this. The introduction of the proposal does not change that fact. At the moment the incentive to falsify transactions is to fill blocks so that real transactions must pay the highest possible fees in the auction for limited transaction bandwidth resulting in a net gain for miners. Simply making bigger blocks serves no economic purpose in itself, since the miners we presume must pay the fees for their falsified transactions, there is no net gain, the fee will be distributed through the pool. Unless, by miners, I may presume we mostly mean mining pools and collusion. Still, where is the gain? It is only the blocks that will be larger with no economic advantage.

In a fee for priority service auction, there is always limited space in each new block since it represents only a small fraction of the size of the mempool. Presenting fraudulent transactions at the bottom end of the scale has limited effect on the cost of being near the front of the queue, at priority. As the fraudulent transactions age they would be included in blocks presuming the fee is above dust level, but the block size would grow to accommodate them since the valid mempool is larger. The auction for priority still continues uninterrupted at the top of the priority curve. There is nothing stopping a motivated individual now from writing a script to create a million pointless dust transactions per day, flooding the mempool. Even if the fee is above dust level the proposal does not change this but, ensures transactional reliability for valid transactions.

In an idealist world, all nodes could agree on the state of the mempool. I agree, there is no feasible way currently to hold the mempool to consensus without a network of dedicated mempool servers. As it is, it has been suggested that all long-running nodes will have approximately a similar view of the mempool. Sweeping the entire mempool contents per block would achieve what is required if there was a mempool consensus but since it will just be one node's view of the mempool that will not be the result.

My speculation is that as a result of the proposal, through increased adoption of Bitcoin over time there would, in fact, be more transactions and greater net fees paid per day. An increased value of BTC that we suppose would follow from increased usage would augment this fee value increase. It surely follows that a more stable and reliable service will have greater consumer and business acceptance, and there it follows that this is in miners financial interest.

I have not considered a maxblocksize since I consider that the mempool can eventually grow infinitely in size just in valid transactions, without even any fraudulent transactions. I suppose that in time it will become necessary to start all new nodes in pruned mode by default due to the onerous storage requirements of the full blockchain. I do not think that the proposed changes alter this.

I am sure that there is much more to write.

Regards,
Damian Williamson



________________________________
From: ZmnSCPxj <ZmnSCPxj at protonmail.com>
Sent: Wednesday, 27 December 2017 2:55 PM
To: Damian Williamson
Cc: bitcoin-dev at lists.linuxfoundation.org
Subject: Re: [bitcoin-dev] BIP Proposal: Revised: UTPFOTIB - Use Transaction Priority For Ordering Transactions In Blocks

Good morning Damian,

I see you have modified your proposal to be purely driven by miners, with fullnodes not actually being able to create a strict "yes-or-no" answer as to block validity under your rules.  This implies that your rules cannot be enforced and that rational miners will ignore your proposal unless it brings in more money for them.  The fact that your proposal provides some mechanism to increase block size means that miners will be incentivized to falsify data (by making up their own transactions just above your fixed "dust size" threshhold whatever that threshhold may be -- and remember, miners get at least 12.5 BTC per block, so they can make a lot of little falsified transactions to justify every block size increase) until the block size increase per block is the maximum possible block size increase.



--

Let me then explain proof-of-work and the arrow of time in Physics.  It may seem a digression, but please, bear with me.

Proof-of-work proves that work was performed, and (crucially) that this work was done in the past.

This is important because of the arrow of time.

In principle, every physical interaction is reversible.  Visualize a video of two indivisible particles.  The two particles move towards each other, collide, and because of the collision, fly apart. If you ran this video in reverse, or in forward, it would not be distinguishable to you, as an outside observer, whether the video was running in reverse or not.  It seems at some level, time does not exist.

And yet time exists.

Consider another video, that of a vase being dropped on a hard surface.  The vase hits the surface and shatters.  Played in reverse, we can judge it as nonsensical: scattered pieces of ceramic spontaneously forming a vase and then flying upwards.  This orients our arrow of time: the arrow of time points from states of the universe where lesser entropy exists (the vase is whole) to where greater entropy exists (the vase is in many pieces).

Indeed, all measures of time are, directly or indirectly, measures of increases in entropy.  Consider a simple hourglass: you place it into a state of low entropy and high energy with most of the sand is in the upper part of the hourglass.  As sand falls, and more of that energy is lost into entropy, you judge that time passes.

Consider a proof-of-work algorithm: you place electrons into a state of low entropy and high energy.  As electrons go through the mining hardware, producing hashes that pass the difficulty requirement, the energy in those electrons is lost into entropy (heat), and from the hashes produced (which proves not only that work was done, but in particular, that entropy increased due to work being done), you judge that time passes.

--

Thus, the blockchain itself is already a service that provides a measure of time.  When a block commits to a transaction, then that transaction is known to have existed at that block height, at the latest.

Thus one idea, is to have each block commit to some view of the mempool.  If a transaction exists in this mempool-view, then you know that the transaction is at least that old, and can judge the age from this and use this to compute the "transaction priority".

Unfortunately, transferring the data to prove that the mempool-view is valid, is equivalent to always sweeping the entire mempool contents per block.  In that case you might as well not have a block size limit.

In addition, miners may still commit to a falsely-empty mempool and deny that your transaction is old and therefore priority and therefore will simply fill their blocks with transactions that have high feerates rather than high priority.  Thus feerate will still be the ultimate measure.

Rather than attempt this, perhaps developers should be encouraged to make use of existing mechanisms, RBF and CPFP, to allow transactions to be sped up by directly manipulating feerates, as priority (by your measure) is not practically computable.

Regards,
ZmnSCPxj
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171227/9f8f65b4/attachment-0001.html>

From cannon at cannon-ciota.info  Sun Dec 31 23:39:17 2017
From: cannon at cannon-ciota.info (CANNON)
Date: Sun, 31 Dec 2017 23:39:17 +0000
Subject: [bitcoin-dev] Single signature for all transactions in a block?
Message-ID: <b50376f5-1a40-1475-04be-1b6aef0bbd74@cannon-ciota.info>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

I had a question relating to scaling and privacy enhancements.
I believe that segwit combined with aggregated signatures
and coinjoin can potentially achieve such. The idea is to
use aggregated signatures in conjunction with coinjoin. So
that all inputs of a coinjoin transaction would have a single
signature vastly decreasing size while having privacy at the
same time. If majority of transactions in a block did this I
assume that significant more transactions could be fit into a
block? However the question I have, with the extra blockspace
made possible by segwit, is this extra blockspace limited to only
witness data or can it be used for transaction data such as the
scenario I have described here?

- --
Cannon
PGP Fingerprint: 2BB5 15CD 66E7 4E28 45DC 6494 A5A2 2879 3F06 E832 
Email: cannon at cannon-ciota.info

NOTICE: ALL EMAIL CORRESPONDENCE NOT SIGNED/ENCRYPTED WITH PGP SHOULD 
BE CONSIDERED POTENTIALLY FORGED, AND NOT PRIVATE.
-----BEGIN PGP SIGNATURE-----

iQIcBAEBCgAGBQJaSXSNAAoJEAYDai9lH2mwRy4QAMqhl6UWNqRy7ziDuxukm+nZ
jWtjyc8G38b9r9Nya13/GslHWeEDdSmma6e7afFMVX1y9Qj+t0EZDJVlMMy8JRZr
zDmSdXDxStNv6T+L3NVbSOBhdP+1MpcsvAAs3yd0Nl5cxfBF87ArHlXMbTLJF86S
1gijI4pg3x83tDg/Di6gf9BHk2oXGDc4vraF6LsMDTfQmp7S8pivnswaaEyb6etH
39ei6L3wkV7LvTmA2onCAB8vZtTuARhNuLTYSPfH5LAC4hha2bOCXci3p4Mz4qh3
U4LqUnuYVR8nYOFFsrfhKggN3kptVWhrbDAoHR2fLoYDmfbMkqUdyjdmmc2Rvlgm
eMJvpG91dYb+Q6JqTrar6DH+XSvoOVSWnBLe8Uwf4AnzGxMUpkTDzkyaBxGq4K1u
Vv2Yg808KwA47MKKpvKSckB350YAq9Cr276Lq/giUrxmS1gOyDKDjm1e3yFLM+6d
NancAwgnp17q43FwSX44cT0ISxk9USnWVhaKDQjSGK8MnirkZ1vuu2SshEW1AVhm
44Bt5nQdLmJDw7rqwkjv66sxofXvmCAnPD+p4yiVyfLNZ7OKw6XNcKm3zKAch2Fy
fefWbZnw0yEA3IhNPiMZOSv/YnwTtfzpFUNuTCtLehs+3Xkp0bl72JDz0HRVYbHM
RbsrLp60rD5kuJBq5dl7
=3gku
-----END PGP SIGNATURE-----

From kanzure at gmail.com  Sun Dec 31 23:46:57 2017
From: kanzure at gmail.com (Bryan Bishop)
Date: Sun, 31 Dec 2017 17:46:57 -0600
Subject: [bitcoin-dev] Single signature for all transactions in a block?
In-Reply-To: <b50376f5-1a40-1475-04be-1b6aef0bbd74@cannon-ciota.info>
References: <b50376f5-1a40-1475-04be-1b6aef0bbd74@cannon-ciota.info>
Message-ID: <CABaSBayhm5TChEAbHboA7CLAye0nyDBqXty3bAmJ9+uC7RahMQ@mail.gmail.com>

On Sun, Dec 31, 2017 at 5:39 PM, CANNON via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:
>
> I had a question relating to scaling and privacy enhancements.
> I believe that segwit combined with aggregated signatures
> and coinjoin can potentially achieve such. The idea is to
> use aggregated signatures in conjunction with coinjoin. So
> that all inputs of a coinjoin transaction would have a single
> signature vastly decreasing size while having privacy at the
> same time. If majority of transactions in a block did this I
> assume that significant more transactions could be fit into a
> block?


Here are some resources to read regarding signature aggregation and
scalability:

https://diyhpl.us/wiki/transcripts/bitcoin-core-dev-tech/2017-09-06-signature-aggregation/
https://diyhpl.us/wiki/transcripts/gmaxwell-2017-08-28-deep-dive-bitcoin-core-v0.15/#signature-aggregation
https://diyhpl.us/wiki/transcripts/scalingbitcoin/milan/schnorr-signatures/
https://bitcoincore.org/en/2017/03/23/schnorr-signature-aggregation/
https://bitcointalk.org/index.php?topic=1377298.0
https://bitcoincore.org/logs/2016-05-zurich-meeting-notes.html
https://github.com/sipa/secp256k1/blob/968e2f415a5e764d159ee03e95815ea11460854e/src/modules/schnorr/schnorr.md
https://diyhpl.us/wiki/transcripts/2016-july-bitcoin-developers-miners-meeting/dan-boneh/

- Bryan
http://heybryan.org/
1 512 203 0507
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171231/515a6708/attachment.html>

From rhavar at protonmail.com  Sun Dec 31 23:49:15 2017
From: rhavar at protonmail.com (Rhavar)
Date: Sun, 31 Dec 2017 18:49:15 -0500
Subject: [bitcoin-dev] Single signature for all transactions in a block?
In-Reply-To: <b50376f5-1a40-1475-04be-1b6aef0bbd74@cannon-ciota.info>
References: <b50376f5-1a40-1475-04be-1b6aef0bbd74@cannon-ciota.info>
Message-ID: <34hyEIZ-7PQWs6oG5bZtBatPvtmrHJXLCpR4NVXPkxfme5My8KCg9OwZF8rQATaWfm26HVes7uaV0XQIQnOdJcApabyRSw4GaIgINr9cJNs=@protonmail.com>

The key to understanding how it works is to stop thinking in terms of a block size limit, but rather a block weight limit. 1 byte of witness data counts as 1 weight, the rest counts for 4 weight. A block must be less than 4 million weight. There's no separate limits at all, so any saving in the witness space (e.g. through signature aggregation) is useful for both witness/non-witness data.

-Ryan

> -------- Original Message --------
> Subject: [bitcoin-dev] Single signature for all transactions in a block?
> Local Time: December 31, 2017 5:39 PM
> UTC Time: December 31, 2017 11:39 PM
> From: bitcoin-dev at lists.linuxfoundation.org
> To: Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>
>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA512
>
> I had a question relating to scaling and privacy enhancements.
> I believe that segwit combined with aggregated signatures
> and coinjoin can potentially achieve such. The idea is to
> use aggregated signatures in conjunction with coinjoin. So
> that all inputs of a coinjoin transaction would have a single
> signature vastly decreasing size while having privacy at the
> same time. If majority of transactions in a block did this I
> assume that significant more transactions could be fit into a
> block? However the question I have, with the extra blockspace
> made possible by segwit, is this extra blockspace limited to only
> witness data or can it be used for transaction data such as the
> scenario I have described here?
>
> ---------------------------------------------------------------
>
> Cannon
> PGP Fingerprint: 2BB5 15CD 66E7 4E28 45DC 6494 A5A2 2879 3F06 E832
> Email: cannon at cannon-ciota.info
>
> NOTICE: ALL EMAIL CORRESPONDENCE NOT SIGNED/ENCRYPTED WITH PGP SHOULD
> BE CONSIDERED POTENTIALLY FORGED, AND NOT PRIVATE.
> -----BEGIN PGP SIGNATURE-----
>
> iQIcBAEBCgAGBQJaSXSNAAoJEAYDai9lH2mwRy4QAMqhl6UWNqRy7ziDuxukm+nZ
> jWtjyc8G38b9r9Nya13/GslHWeEDdSmma6e7afFMVX1y9Qj+t0EZDJVlMMy8JRZr
> zDmSdXDxStNv6T+L3NVbSOBhdP+1MpcsvAAs3yd0Nl5cxfBF87ArHlXMbTLJF86S
> 1gijI4pg3x83tDg/Di6gf9BHk2oXGDc4vraF6LsMDTfQmp7S8pivnswaaEyb6etH
> 39ei6L3wkV7LvTmA2onCAB8vZtTuARhNuLTYSPfH5LAC4hha2bOCXci3p4Mz4qh3
> U4LqUnuYVR8nYOFFsrfhKggN3kptVWhrbDAoHR2fLoYDmfbMkqUdyjdmmc2Rvlgm
> eMJvpG91dYb+Q6JqTrar6DH+XSvoOVSWnBLe8Uwf4AnzGxMUpkTDzkyaBxGq4K1u
> Vv2Yg808KwA47MKKpvKSckB350YAq9Cr276Lq/giUrxmS1gOyDKDjm1e3yFLM+6d
> NancAwgnp17q43FwSX44cT0ISxk9USnWVhaKDQjSGK8MnirkZ1vuu2SshEW1AVhm
> 44Bt5nQdLmJDw7rqwkjv66sxofXvmCAnPD+p4yiVyfLNZ7OKw6XNcKm3zKAch2Fy
> fefWbZnw0yEA3IhNPiMZOSv/YnwTtfzpFUNuTCtLehs+3Xkp0bl72JDz0HRVYbHM
> RbsrLp60rD5kuJBq5dl7
> =3gku
> -----END PGP SIGNATURE-----
> ---------------------------------------------------------------
>
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171231/3562c354/attachment.html>

