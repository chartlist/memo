From billy.tetrud at gmail.com  Mon Nov  1 01:19:42 2021
From: billy.tetrud at gmail.com (Billy Tetrud)
Date: Sun, 31 Oct 2021 20:19:42 -0500
Subject: [bitcoin-dev] Covenant opcode proposal OP_CONSTRAINDESTINATION
 (an alternative to OP_CTV)
In-Reply-To: <CAGpPWDZcK7gV0ZC92NzWYk58mYxR6E_UOZ-3W8FPSRLe7cvnmA@mail.gmail.com>
References: <CAGpPWDZ0aos5qHw2=popCpjuH7OXC0geEj8i3dwDTfP0j=or4w@mail.gmail.com>
 <20210725053803.fnmd6etv3f7x3u3p@ganymede>
 <CAGpPWDZ8EWd7kGV5pFZadQM1kqETrTK2zybsGF1hW9fx2oZb7w@mail.gmail.com>
 <CAH+Axy7cPufMUCMQbCz2MUgRqQbgenAozPBFD8kPYrSjwcRG8w@mail.gmail.com>
 <CAGpPWDb8yzGO-VtCO-x09e-phKHT7ezOms+DzeWc9vS3rN1AAw@mail.gmail.com>
 <CAJ4-pEDWuNfdE4NXkZBsOnuSQ4YOv28YVwGavyiU+FPvpC6y1w@mail.gmail.com>
 <CAGpPWDZL6BpzoNa0Qgf-Ux60fyWPjZH=NESkgbhEQO_My=XiAg@mail.gmail.com>
 <CAJ4-pEBwdUJ3kg=yb-kWZLoaX5f_2t353K7Tr+dJy+JpAoKTmQ@mail.gmail.com>
 <CAGpPWDYMZ+w3VSaLhR68f4WVq7NCUp3SedwW2e8QnRHOgLQqQg@mail.gmail.com>
 <CAD5xwhhAcup2pKyazopqz7aYAWYmXCJsq1OPni94+OJ8ErUXjQ@mail.gmail.com>
 <CAGpPWDZcK7gV0ZC92NzWYk58mYxR6E_UOZ-3W8FPSRLe7cvnmA@mail.gmail.com>
Message-ID: <CAGpPWDawafVC+HMcyRo-H-QOvb_KGuHb=SrhM1=PgXvathx_4Q@mail.gmail.com>

FYI I broke out the fee limiting functionality from OP_CD into an opcode
called OP_LIMITFEECONTRIBUTION
<https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/lfc/bip-limit-fee-contribution.md>
as
Jeremy suggested.

On Fri, Jul 30, 2021 at 1:42 PM Billy Tetrud <billy.tetrud at gmail.com> wrote:

> Thanks for taking another look Jeremy. That's an interesting idea to split
> it up into simpler opcodes, however there are some
> limitations/considerations there.
>
> For example, with output addresses, I added specifying amounts to outputs
> in order to make script evaluation simpler and eliminate a potential DOS
> vector. I wrote about this in the section 'Specifying values sent to each
> output
> <https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/cd/bip-constraindestination.md#specifying-values-sent-to-each-output>'.
> Originally, I designed OP_CD without specifying what amounts an input
> contributes to what outputs, but it seemed like this would require
> calculating various combinations of inequalities, which could get expensive
> in scenarios where many inputs had overlapping destinations. See the
> examples under the OP_CD section in this commit
> <https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/commit/9b2257410b5f0fc991f68e774c3faf601c02cc5d>
> .
>
> Maybe there's an elegant and cheap way of verifying that a number of
> inputs that have destination address limitations is within limits, but if
> so I don't know how to do that. If there was a good way to do that, then I
> wouldn't want to propose the ability to validate that specific amounts go
> to specific outputs. So unless there's a simple and dos-vector-free way of
> evaluating what addresses an input goes to without knowing what amounts an
> input contributes to each output, I don't think these functionalities
> should be separated.
>
> And about a fee-limit opcode, that could certainly be done on its own.
> However, a version of OP_CD that doesn't specify fees would have to take
> the fee-limit into account, and the calculation for the stand-alone
> fee-limit operation would be moot for that output.
>
> So I think it could make sense to split the fee limit off from the rest of
> OP_CD. I'm curious to know what others think of that.
>
> > all transactions are twice as large as they might otherwise need to be
> for simple things like congestion control trees, since you have to repeat
> all of the output data twice
>
> Well, the transaction wouldn't be quite twice as large. Each output would
> add 9 bytes to the transaction, and outputs already are a minimum of about
> 30 bytes I think? So for transactions with a lot of outputs, it could make
> the transaction about 1/3 larger. I'll add a section on this into my
> proposal.
>
> Perhaps it would be a reasonable optimization to allow omitting an output
> value in cases where the entire output amount is contributed by that input.
> This would reduce the overhead of specifying output amounts to 2 bytes for
> most outputs (1 byte for the index, another to indicate the full value),
> meaning that it would only make the transaction about 7% larger. What do
> you think about that idea?
>
> On Wed, Jul 28, 2021 at 3:30 PM Jeremy via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>> High level feedback:
>>
>> you should spec out the opcodes as separate pieces of functionality as it
>> sounds like OP_CD is really 3 or 4 opcodes in one (e.g., amounts to
>> outputs, output addresses, something with fees).
>>
>> One major drawback of your approach is that all transactions are twice as
>> large as they might otherwise need to be for simple things like congestion
>> control trees, since you have to repeat all of the output data twice.
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20211031/be0e60ae/attachment.html>

From bitcoin-dev at wuille.net  Mon Nov  1 18:48:49 2021
From: bitcoin-dev at wuille.net (Pieter Wuille)
Date: Mon, 01 Nov 2021 18:48:49 +0000
Subject: [bitcoin-dev] BIP341 test vectors for wallet implementations
Message-ID: <Vhp3DuXMyu5U7nc8nK6nRT3UiPbWtsTBX6eo1k-VyKRmVizUSyF017nD7XNOY2GNAkcWdnZdjtU5DBhEfB3N43HYKGnbXzERDaXBfV0XpBI=@wuille.net>

Hi all,

I wanted to bring some attention to a set of test vectors I'm proposing to add to BIP341 in https://github.com/bitcoin/bips/pull/1225.

These are focused on wallet implementations, covering Merkle root / tweak / scriptPubKey computation from key/scripts, sigmsg/sighash/signature computation for key path spending, and control block computation for script path spending.

Given the short time that remains before BIP341's activation, I think this may be helpful to people working on implementations, even before it's merged. All values in it are automatically generated from an actual scenario tested against Bitcoin Core (which involves constructing and mining transactions with specified data).

The tests are mostly focused on features that are likely useful/testable in implementations right now, and e.g. excludes sighashes that involve annexes for that reason. It's also specific to BIP341, and doesn't cover BIP342 script semantics. Still, if anyone relies on features that are useful, but aren't covered, I'm happy to add more scenarios.

Cheers,

--
Pieter
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20211101/10da2406/attachment.html>

From ZmnSCPxj at protonmail.com  Wed Nov  3 10:12:57 2021
From: ZmnSCPxj at protonmail.com (ZmnSCPxj)
Date: Wed, 03 Nov 2021 10:12:57 +0000
Subject: [bitcoin-dev] death to the mempool, long live the mempool
In-Reply-To: <DS-9LyYKokVu_2m2j7ZxpVY3CmOLF_efYCGftH4pqHF1Wk2mFBQNl_ILazvKXJvTiVSQ3b_v5vg29DRFQs301wwNwfEgKUCPo3MOq_VIPm0=@protonmail.com>
References: <CAM1a7P04apCwwmqNp4VLRam5_uk59tVRWv74UVD_g0-DUGNghw@mail.gmail.com>
 <CAFXO6=Jk0MAqQ6u5JCrpC3eMv=bF3DT6wH6Y60zb_b-beU4mcg@mail.gmail.com>
 <DS-9LyYKokVu_2m2j7ZxpVY3CmOLF_efYCGftH4pqHF1Wk2mFBQNl_ILazvKXJvTiVSQ3b_v5vg29DRFQs301wwNwfEgKUCPo3MOq_VIPm0=@protonmail.com>
Message-ID: <QaedcBglsKRe2DdN4NFtods5JuJfdGxfI9B_Uc4rxPdRJ-rosEkncQuaRG_fH-svXmFGjKOndOM3StRP10CJyLGqARJOmuFQ8dVNwAi1i2o=@protonmail.com>

Good morning list,



> I describe here an algorithm based on semispace GC, but the GC algorithm space is well-studied and other algorithms may also be devised (in particular, spam is likely to match quite well with "infant mortality" concept in GC, i.e. "most objects die young", so some kind of nursery / generational GC may work better against spam in practice).


This "nursery GC" variation would be very similar to these "pre-mempool" / "memswamp" proposals, as well:

* https://github.com/bitcoin/bitcoin/issues/14895#issuecomment-665975441
* https://github.com/bitcoin/bitcoin/issues/14895#issuecomment-666267749

It may be better to continue thinking along those lines than to consider this GC concept.

Regards,
ZmnSCPxj


From laolu32 at gmail.com  Thu Nov  4 22:01:13 2021
From: laolu32 at gmail.com (Olaoluwa Osuntokun)
Date: Thu, 4 Nov 2021 15:01:13 -0700
Subject: [bitcoin-dev] Neutrino, Taproot, and The Evolution of BiPs 157/158
Message-ID: <CAO3Pvs-Jazo27Vmi3Rforke++T5rkboS=2PK9CSSTtCk4enF2w@mail.gmail.com>

Hi y'all,

If you're an active user of neutrino [8], then you probably heard about what
went down over the past week or so on testnet as related to Taproot. First,
i just wanted to reassure everyone that nothing is fundamentally broken with
BIP 157/158 as it relates to taproot, and we already have a mitigation patch
in place for the issue we encountered.

The rest of this mail is structured in a FAQ style to make it easy to skim
and extract the information that may be relevant to the reader.

## What happened on testnet?

Neutrino nodes on testnet rejected a filter (thinking it was invalid) due
to this transaction spending a taproot input [1]. This was due to a faulty
heuristics in the neutrino _client code_ (not part of the protocol) that
attempted to verify the contents of a filter more completely.

In retrospect, the heuristic in question wasn't full proof, as it attempted
to derive the _pk script_ of a transaction based on its input
witness/sigScript. This worked pretty well in the context of segwit v0, but
it isn't possible to exhaustively do as we don't know what future spends
will look like.

## Is neutrino broken?

No, the client side is fine, and the protocol is fine.

The problematic heuristic has been removed in this PR [2], which will be
included in lnd 0.14, and has been tagged with neutrino 0.13 [3].

To dig into _why_ we attempted to use such a heuristic, we'll need to
revisit how BIP 158 works briefly. For each block, we insert the `pkScript`s
of all the outputs, and also the prev out's pkScript (the script being
spent) as well. This lets the filter compress script re-use in both inputs
and outputs, and also makes it possible to implement some protocols in a
more light-client friendly manner (for example Loop uses this to has the
client watch HTLC _scripts_ being spent, as it doesn't necessarily know the
txid/outpoint).

The one issue with this, is that while clients can ensure that all the
`pkScripts` of outputs have been inserted, they can't do the same for the
inputs (which is why we added that heuristic in the client code). Luckily we
know how to properly fix this at the protocol level, more on that below.

## How can I make sure my neutrino clients handle the Taproot upgrade on
mainnet smoothly?

Upgrade to 0.14 (assuming it's out in time), or apply this small patch [4].
The patch just demotes an error case to a warning message, so anyone running
a fork should be able to easily apply the fix.

Alongside, optionally extend these filter header guides [7].

We're looking into some intermediate ground where we can verify the scripts
that we know are relevant to the node.

## How will BIP 158/157 evolve post taproot?

In terms of adding more taproot specific functionality, I've had a number of
items in my laundry list such as:

  * creating new segwit-only filters with re-parameterized fp rates (also
    examine other filter types such as pure outpoints, etc)

  * creating filters that include witness data to allow matching on
    internal/external keys, the control block, merkle root, annex, etc

  * add a new protocol extension to btcd (with a corresponding BIP) to
    allow notes to fetch block undo data (as described here [5]) to fully
    verify fetched filters or a node needs to reconcile conflicting filters

  * new filters that span across multiple blocks as previously worked on by
    Kalle Alm (couldn't find a link to his PR when typing this...)

Make further progress towards a proposal that allows filters to be committed
either as a soft-fork, or a "velvet fork" [6] where miners optionally
commit to
the past filter header chain.


-- Laolu

[1]:
https://mempool.space/testnet/tx/4b425a1f5c0fcf4794c48b810c53078773fb768acd2be1398e3f561cc3f19fb8
[2]: https://github.com/lightninglabs/neutrino/pull/234
[3]: https://github.com/lightninglabs/neutrino/releases/tag/v0.13.0
[4]: https://github.com/lightninglabs/neutrino/pull/234/files
[5]:
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-February/016649.html
[6]: https://eprint.iacr.org/2018/087
[7]:
https://github.com/lightninglabs/neutrino/blob/5e09bd9b5d65e90c6ff07aa11b3b9d80d42afb86/chainsync/filtercontrol.go#L15
[8]: https://github.com/lightninglabs/neutrino
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20211104/e5d7b150/attachment.html>

From laolu32 at gmail.com  Thu Nov  4 22:07:52 2021
From: laolu32 at gmail.com (Olaoluwa Osuntokun)
Date: Thu, 4 Nov 2021 15:07:52 -0700
Subject: [bitcoin-dev] Neutrino, Taproot,
	and The Evolution of BiPs 157/158
In-Reply-To: <CAO3Pvs-Jazo27Vmi3Rforke++T5rkboS=2PK9CSSTtCk4enF2w@mail.gmail.com>
References: <CAO3Pvs-Jazo27Vmi3Rforke++T5rkboS=2PK9CSSTtCk4enF2w@mail.gmail.com>
Message-ID: <CAO3Pvs_hLDGtBRP9J4Zokk6BpaBTUQAy01O3BjC6xbBzsudKjg@mail.gmail.com>

> In terms of adding more taproot specific functionality, I've had a number
of
> items in my laundry list such as:

Forgot to add this other item (also the list wasn't meant to be only tapoot
stuff):
  * reviving old projects to include a micropayment-for-data layer to
    incentivize nodes to serve the filters and other data

On Thu, Nov 4, 2021 at 3:01 PM Olaoluwa Osuntokun <laolu32 at gmail.com> wrote:

> Hi y'all,
>
> If you're an active user of neutrino [8], then you probably heard about
> what
> went down over the past week or so on testnet as related to Taproot. First,
> i just wanted to reassure everyone that nothing is fundamentally broken
> with
> BIP 157/158 as it relates to taproot, and we already have a mitigation
> patch
> in place for the issue we encountered.
>
> The rest of this mail is structured in a FAQ style to make it easy to skim
> and extract the information that may be relevant to the reader.
>
> ## What happened on testnet?
>
> Neutrino nodes on testnet rejected a filter (thinking it was invalid) due
> to this transaction spending a taproot input [1]. This was due to a faulty
> heuristics in the neutrino _client code_ (not part of the protocol) that
> attempted to verify the contents of a filter more completely.
>
> In retrospect, the heuristic in question wasn't full proof, as it attempted
> to derive the _pk script_ of a transaction based on its input
> witness/sigScript. This worked pretty well in the context of segwit v0, but
> it isn't possible to exhaustively do as we don't know what future spends
> will look like.
>
> ## Is neutrino broken?
>
> No, the client side is fine, and the protocol is fine.
>
> The problematic heuristic has been removed in this PR [2], which will be
> included in lnd 0.14, and has been tagged with neutrino 0.13 [3].
>
> To dig into _why_ we attempted to use such a heuristic, we'll need to
> revisit how BIP 158 works briefly. For each block, we insert the
> `pkScript`s
> of all the outputs, and also the prev out's pkScript (the script being
> spent) as well. This lets the filter compress script re-use in both inputs
> and outputs, and also makes it possible to implement some protocols in a
> more light-client friendly manner (for example Loop uses this to has the
> client watch HTLC _scripts_ being spent, as it doesn't necessarily know the
> txid/outpoint).
>
> The one issue with this, is that while clients can ensure that all the
> `pkScripts` of outputs have been inserted, they can't do the same for the
> inputs (which is why we added that heuristic in the client code). Luckily
> we
> know how to properly fix this at the protocol level, more on that below.
>
> ## How can I make sure my neutrino clients handle the Taproot upgrade on
> mainnet smoothly?
>
> Upgrade to 0.14 (assuming it's out in time), or apply this small patch [4].
> The patch just demotes an error case to a warning message, so anyone
> running
> a fork should be able to easily apply the fix.
>
> Alongside, optionally extend these filter header guides [7].
>
> We're looking into some intermediate ground where we can verify the scripts
> that we know are relevant to the node.
>
> ## How will BIP 158/157 evolve post taproot?
>
> In terms of adding more taproot specific functionality, I've had a number
> of
> items in my laundry list such as:
>
>   * creating new segwit-only filters with re-parameterized fp rates (also
>     examine other filter types such as pure outpoints, etc)
>
>   * creating filters that include witness data to allow matching on
>     internal/external keys, the control block, merkle root, annex, etc
>
>   * add a new protocol extension to btcd (with a corresponding BIP) to
>     allow notes to fetch block undo data (as described here [5]) to fully
>     verify fetched filters or a node needs to reconcile conflicting filters
>
>   * new filters that span across multiple blocks as previously worked on by
>     Kalle Alm (couldn't find a link to his PR when typing this...)
>
> Make further progress towards a proposal that allows filters to be
> committed
> either as a soft-fork, or a "velvet fork" [6] where miners optionally
> commit to
> the past filter header chain.
>
>
> -- Laolu
>
> [1]:
> https://mempool.space/testnet/tx/4b425a1f5c0fcf4794c48b810c53078773fb768acd2be1398e3f561cc3f19fb8
> [2]: https://github.com/lightninglabs/neutrino/pull/234
> [3]: https://github.com/lightninglabs/neutrino/releases/tag/v0.13.0
> [4]: https://github.com/lightninglabs/neutrino/pull/234/files
> [5]:
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-February/016649.html
> [6]: https://eprint.iacr.org/2018/087
> [7]:
> https://github.com/lightninglabs/neutrino/blob/5e09bd9b5d65e90c6ff07aa11b3b9d80d42afb86/chainsync/filtercontrol.go#L15
> [8]: https://github.com/lightninglabs/neutrino
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20211104/f67e66e8/attachment.html>

From prayank at tutanota.de  Fri Nov  5 08:17:22 2021
From: prayank at tutanota.de (Prayank)
Date: Fri, 5 Nov 2021 09:17:22 +0100 (CET)
Subject: [bitcoin-dev] bitcoin.org missing bitcoin core version 22.0
In-Reply-To: <CAHiDt8A30DZtvsPnDDdtyVpho-NKKQhbP_4g8d0MGATawWvg_w@mail.gmail.com>
References: <MmT9umZ--3-2@tutanota.de>
 <20211020192054.GA117785@jauntyelephant.191.37.198.vultr.com>
 <CAHiDt8A30DZtvsPnDDdtyVpho-NKKQhbP_4g8d0MGATawWvg_w@mail.gmail.com>
Message-ID: <MnjA6g0--3-2@tutanota.de>

Hi Kate,

> He is taking the most sensible way forward, decreasing bus factor.

Agree. Work being shared with other maintainers is an improvement.

> Read: https://laanwj.github.io/2021/01/21/decentralize.html

Interesting blog post. First paragraph talks about strange expectations, not sure what other people expected however I expected present maintainers will always have respect for the Founder of Bitcoin, keep important docs in repository, website etc. forever and respond with appropriate things if any rich scammers try to remove anything important. Anyway that chapter is over and this PR will always remain in history for others to see and make their own opinions about it: https://github.com/bitcoin-core/bitcoincore.org/pull/740

What followed it (whitepaper being shared on different websites) was true decentralization and we need something similar in other aspects of full node implementations. Few things that can improve decentralization:

1.More people using alternative full node implementations. Right now 98% of nodes use Bitcoin Core.
2.More people like Luke Dashjr and Amir Taaki who do not simp for anyone. Being a contributor or maintainer in Bitcoin full node implementation is different from other open source projects. It was never going to be easy and it will get difficult with time,
3.More people from different countries getting involved in important roles.
4.Few anons.
5.Individuals and organizations who fund different Bitcoin projects should consider contributing in alternative. full node implementations as well. Maybe start with Bitcoin Knots.

I am sure lot of people will find this controversial or disagree with it however this is my opinion and things that I think can improve Bitcoin. Will quote something from my recent medium post about a dev meetup and Knots:

Accepting the problems, looking for solutions and trying to improve things is the best approach we as engineers can follow to do better things in Bitcoin. Irrational optimism is as toxic as irrational pessimism.

https://prayankgahlot.medium.com/op-halloween21-and-bitcoin-knots-b8a4da4fa0bd

Only ~1337 blocks left for Taproot to activate. So cheers to another soft fork being a success and Bitcoin improving regularly. Thanks to everyone who contributed including reviewers. Hoping most of the people will start using latest version of Bitcoin Core or other full node implementations soon.
.
-- 
Prayank

A3B1 E430 2298 178F



Oct 21, 2021, 01:48 by mercedes.catherine.salazar at gmail.com:

> Hi Owen,
>
> On Wed, Oct 20, 2021 at 9:25 PM Owen Gunden via bitcoin-dev <> bitcoin-dev at lists.linuxfoundation.org> > wrote:
>
>> On Wed, Oct 20, 2021 at 04:47:17PM +0200, Prayank wrote:
>>  > > It seems confusing to have two sites that seemingly both represent
>>  > > bitcoin core.
>>  >
>>  > There is only one website which represents Bitcoin Core full node
>>  > implementation. You can download Bitcoin Core from
>>  > >> https://bitcoincore.org
>>  
>>  I also notice that, as of 22.0, Wladimir is no longer signing the
>>  releases, and I have no trust in my gpg network of the people who seem
>>  to have replaced him.
>>
>
> He is taking the most sensible way forward, decreasing bus factor.
>
> Read:?> https://laanwj.github.io/2021/01/21/decentralize.html
> ?
>
>>
>> Given the level of security at stake here, my eyebrows are raised at
>>  this combination of items changing (new website + new gpg signers at the
>>  same time).
>>
>
> Don't worry and build your own release;
> but if you do, always verify the tree hash.
> Trust signed annotated tags.
> Cheers!
> ?
>
>>
>> _______________________________________________
>>  bitcoin-dev mailing list
>>  >> bitcoin-dev at lists.linuxfoundation.org
>>  >> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20211105/cd5ec286/attachment-0001.html>

From damian at willtech.com.au  Fri Nov  5 10:52:00 2021
From: damian at willtech.com.au (damian at willtech.com.au)
Date: Fri, 05 Nov 2021 03:52:00 -0700
Subject: [bitcoin-dev] bitcoin.org missing bitcoin core version 22.0
In-Reply-To: <MnjA6g0--3-2@tutanota.de>
References: <MmT9umZ--3-2@tutanota.de>
 <20211020192054.GA117785@jauntyelephant.191.37.198.vultr.com>
 <CAHiDt8A30DZtvsPnDDdtyVpho-NKKQhbP_4g8d0MGATawWvg_w@mail.gmail.com>
 <MnjA6g0--3-2@tutanota.de>
Message-ID: <d86119700edb2eeaf9672375935bb74f@willtech.com.au>

Good Afternoon,

Talk about the present and the future is misguided if it concludes that 
the decentralisation of a project itself is responsible even if the 
operation of the project is to produce a specification, and a software 
capable of performing transactions in a decentralised manner. There is 
no advantage or disadvantage to the project to have several choices of 
the software implementation unless buffoons are misguided and wish to 
attack fungibility or consensus, which the operation of consensus must 
defend, in which case use [Bitcoin Core at version 
21](https://github.com/bitcoin/bitcoin/tree/0.21) and [create a 
fork](https://docs.github.com/en/get-started/quickstart/fork-a-repo) and 
start developing. As you can see [Bitcoin Core version 20 has been 
modified](https://github.com/bitcoin/bitcoin/branches) and no longer 
passes checks similarly with version 18 which makes it more difficult to 
compile make build. A person't own contributions are theirs, to delegate 
is responsible, to try and create a seven headed lion to keep under 
command like one would a gryphon is an infirmity.

Creating a properly delegated organisation, being a foundation for the 
purpose of the maintenance of the consensus of Bitcoin a fungible 
decentralised currency and the Bitcoin Core software is the sort of 
thing I would easily consider but it is far more centralised to be an 
operable concern. In short, as at the beginning, Bitcoin needs a few 
heroes that can understand the whitepaper and write software and if the 
work is too much one organisational foundation that does is correctly 
stewardship. To decentralise one's own work only requires that there are 
several offices available for those you employ to delegate to, but still 
there requires for your project a headship.

Once the currency is fungible as you should now consider, just today 
there was a public announcement that the Commonwealth Bank Of Australia 
is going to allow buying and selling Bitcoin as one of its services, the 
primary requirements are to defend the existing consensus as the right 
of trade in every UTXO has value because of that consensus, and 
particularly because of the ease of that trade.

I do not expect anybody is eligible to be dictated to in the Bitcoin 
project, but people, be sensible, everybody has worked hard and the 
project is becoming a success. Opportunities to further develop the 
software of the coin and the protocol do not form part of the current 
value, hardly. Several groaning seven headed lion's are 
counterproductive if all they do is search for opportunities for change. 
Change is the diametrically opposed of consensus and is consensus that 
brings fungibility. You can already make any manner of instrument for 
smart contract with your solicitor's office. What is necessary is the 
operation of the Bitcoin protocol. The alternative to the deliberately 
chosen consensus is a democracy, and you cannot build any software with 
democracy, and people do not know what is good for them or they could 
govern themselves. A few lessons in history assures government is 
necessary to enshrine law and insist as the delegates of democracy for 
its operation, to ensure a civilised and decent civility can exist.

Please, if you have concerned for Bitcoin, revoke your positions until 
you fight for consensus.

KING JAMES HRMH
Great British Empire

Regards,
The Australian
LORD HIS EXCELLENCY JAMES HRMH (& HMRH)
of Hougun Manor & Glencoe & British Empire
MR. Damian A. James Williamson
Wills

et al.


Willtech
www.willtech.com.au
www.go-overt.com
duigco.org DUIGCO API
and other projects


m. 0487135719
f. +61261470192


This email does not constitute a general advice. Please disregard this 
email if misdelivered.
On 2021-11-05 01:17, Prayank via bitcoin-dev wrote:
> Hi Kate,
> 
>> He is taking the most sensible way forward, decreasing bus factor.
> 
> Agree. Work being shared with other maintainers is an improvement.
> 
>> Read: https://laanwj.github.io/2021/01/21/decentralize.html
> 
> Interesting blog post. First paragraph talks about strange
> expectations, not sure what other people expected however I expected
> present maintainers will always have respect for the Founder of
> Bitcoin, keep important docs in repository, website etc. forever and
> respond with appropriate things if any rich scammers try to remove
> anything important. Anyway that chapter is over and this PR will
> always remain in history for others to see and make their own opinions
> about it: https://github.com/bitcoin-core/bitcoincore.org/pull/740
> 
> What followed it (whitepaper being shared on different websites) was
> true decentralization and we need something similar in other aspects
> of full node implementations. Few things that can improve
> decentralization:
> 
> 1.More people using alternative full node implementations. Right now
> 98% of nodes use Bitcoin Core.
> 
> 2.More people like Luke Dashjr and Amir Taaki who do not simp for
> anyone. Being a contributor or maintainer in Bitcoin full node
> implementation is different from other open source projects. It was
> never going to be easy and it will get difficult with time,
> 
> 3.More people from different countries getting involved in important
> roles.
> 
> 4.Few anons.
> 
> 5.Individuals and organizations who fund different Bitcoin projects
> should consider contributing in alternative. full node implementations
> as well. Maybe start with Bitcoin Knots.
> 
> I am sure lot of people will find this controversial or disagree with
> it however this is my opinion and things that I think can improve
> Bitcoin. Will quote something from my recent medium post about a dev
> meetup and Knots:
> 
> Accepting the problems, looking for solutions and trying to improve
> things is the best approach we as engineers can follow to do better
> things in Bitcoin. Irrational optimism is as toxic as irrational
> pessimism.
> 
> https://prayankgahlot.medium.com/op-halloween21-and-bitcoin-knots-b8a4da4fa0bd
> 
> Only ~1337 blocks left for Taproot to activate. So cheers to another
> soft fork being a success and Bitcoin improving regularly. Thanks to
> everyone who contributed including reviewers. Hoping most of the
> people will start using latest version of Bitcoin Core or other full
> node implementations soon.
> 
> .
> 
> --
> 
> Prayank
> 
> A3B1 E430 2298 178F
> 
> Oct 21, 2021, 01:48 by mercedes.catherine.salazar at gmail.com:
> 
>> Hi Owen,
>> 
>> On Wed, Oct 20, 2021 at 9:25 PM Owen Gunden via bitcoin-dev
>> <bitcoin-dev at lists.linuxfoundation.org> wrote:
>> 
>>> On Wed, Oct 20, 2021 at 04:47:17PM +0200, Prayank wrote:
>>> 
>>>>> It seems confusing to have two sites that seemingly both
>>> represent
>>> 
>>>>> bitcoin core.
>>> 
>>>> 
>>> 
>>>> There is only one website which represents Bitcoin Core full
>>> node
>>> 
>>>> implementation. You can download Bitcoin Core from
>>> 
>>>> https://bitcoincore.org
>>> 
>>> I also notice that, as of 22.0, Wladimir is no longer signing the
>>> 
>>> releases, and I have no trust in my gpg network of the people who
>>> seem
>>> 
>>> to have replaced him.
>> 
>> He is taking the most sensible way forward, decreasing bus factor.
>> 
>> Read: https://laanwj.github.io/2021/01/21/decentralize.html
>> 
>>> Given the level of security at stake here, my eyebrows are raised
>>> at
>>> 
>>> this combination of items changing (new website + new gpg signers
>>> at the
>>> 
>>> same time).
>> 
>> Don't worry and build your own release;
>> 
>> but if you do, always verify the tree hash.
>> 
>> Trust signed annotated tags.
>> 
>> Cheers!
>> 
>>> _______________________________________________
>>> 
>>> bitcoin-dev mailing list
>>> 
>>> bitcoin-dev at lists.linuxfoundation.org
>>> 
>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

From yanmaani at cock.li  Fri Nov  5 14:45:36 2021
From: yanmaani at cock.li (yanmaani at cock.li)
Date: Fri, 05 Nov 2021 14:45:36 +0000
Subject: [bitcoin-dev] bitcoin.org missing bitcoin core version 22.0
In-Reply-To: <MnjA6g0--3-2@tutanota.de>
References: <MmT9umZ--3-2@tutanota.de>
 <20211020192054.GA117785@jauntyelephant.191.37.198.vultr.com>
 <CAHiDt8A30DZtvsPnDDdtyVpho-NKKQhbP_4g8d0MGATawWvg_w@mail.gmail.com>
 <MnjA6g0--3-2@tutanota.de>
Message-ID: <3d686c3a100338514c3ebcc264ec24f2@cock.li>

On 2021-11-05 08:17, Prayank via bitcoin-dev wrote:
> What followed it (whitepaper being shared on different websites) was
> true decentralization and we need something similar in other aspects
> of full node implementations. Few things that can improve
> decentralization:
> 
> 1.More people using alternative full node implementations. Right now
> 98% of nodes use Bitcoin Core.

Unfortunately, this isn't really possible. If they did that, you could 
get consensus splits. This is why all the other stuff is so important - 
if Bitcoin is subverted via soft-fork, you *can't* just run your own 
fork.

Theoretically, I suppose you could run two implementations and do 
something if they differ, but what?
1. Bitcoin Core and <AltImpl> both say block is valid -> valid
2. Bitcoin Core and <AltImpl> both say block is invalid -> invalid
3. Bitcoin Core says valid, <AltImpl> says invalid -> valid (or get 
forked off)
4. Bitcoin Core says invalid, <AltImpl> says valid -> invalid (or 
hardfork)

> 2.More people like Luke Dashjr and Amir Taaki who do not simp for
> anyone. Being a contributor or maintainer in Bitcoin full node
> implementation is different from other open source projects. It was
> never going to be easy and it will get difficult with time,

This is all about the money - it's easy to have people be independent 
when their source of money is independent. But nobody's crazy enough to 
bite the hand that feeds them, and you couldn't really build a system on 
that basis. Our best hope is gentle hands, or contributors wealthy 
enough not to have to care.

(Whatever happened to Amir Taaki, by the way?)

> 3.More people from different countries getting involved in important
> roles.

Isn't Bitcoin already plenty distributed? Funding people in 
under-represented countries seems to me like a textbook exercise in 
'box-ticking, but moreover, I'd frankly rather have reasonably well-off 
guys from Western Europe/America who have the financial backbone to not 
worry that much about attacks to their funding, than mercenaries who 
have to follow orders or get fired. Even if they're from West 
Uzbekistan.

(Maybe they need a union?)

> 4.Few anons.

Gonna guess you mean "a few anons," not fewer anons.

Again, problem is money. These days, nobody threatens anyone with 
anything substantive, like murder - the threats all involve cutting off 
some funding. So having anonymous people being funded by non-robust 
sources doesn't really buy you that much, because the weakest link will 
pretty much never be the de-jure, legal freedom of an individual.

Having a system that allows people to fund anonymous people better would 
be interesting, but it has some challenges with trust and so on.

> 5.Individuals and organizations who fund different Bitcoin projects
> should consider contributing in alternative. full node implementations
> as well. Maybe start with Bitcoin Knots.

See above. Bitcoin Knots isn't really independent. btcd in Go is, so I 
guess they could try that. But at the end of the day, it wouldn't help - 
btcd has to be bug-for-bug compatible with Core, and it couldn't really 
be any other way.

For my $0.05, what's needed is more "hard money" - if people could make 
donations into a fund, with the fund then paying out to developers, and 
that fund be controlled in a civilized and non-centralized way (that's 
the hard part!), this would somewhat insulate developers from people 
threatening to stop their contributions to The Fund, at the price of 
having developers being able to be coerced by The Fund.

You could also look into a system like Monero's CCS. But at the end of 
the day, funding is really a very difficult problem, no matter how you 
slice it. The money still has to enter the system somehow. Since Bitcoin 
is a public good, you can't really capture its value, and this means 
individuals who can (e.g. by malicious activity) will always have the 
leg up.

From ZmnSCPxj at protonmail.com  Mon Nov  8 03:02:33 2021
From: ZmnSCPxj at protonmail.com (ZmnSCPxj)
Date: Mon, 08 Nov 2021 03:02:33 +0000
Subject: [bitcoin-dev] bitcoin.org missing bitcoin core version 22.0
In-Reply-To: <3d686c3a100338514c3ebcc264ec24f2@cock.li>
References: <MmT9umZ--3-2@tutanota.de>
 <20211020192054.GA117785@jauntyelephant.191.37.198.vultr.com>
 <CAHiDt8A30DZtvsPnDDdtyVpho-NKKQhbP_4g8d0MGATawWvg_w@mail.gmail.com>
 <MnjA6g0--3-2@tutanota.de> <3d686c3a100338514c3ebcc264ec24f2@cock.li>
Message-ID: <d-6yONWH6zDSQXl7l6cJR2QsGw_iL-CyTJI16XZ4AkAwAdT65p3JylrIZ4VLbAAFQyfxyaDA3zUhctgiEkJKVQvfhzA-slPmPYdKW1L8M_4=@protonmail.com>

Good morning yanmaani,


> > 3.More people from different countries getting involved in important
> > roles.
>
> Isn't Bitcoin already plenty distributed? Funding people in
> under-represented countries seems to me like a textbook exercise in
> 'box-ticking, but moreover, I'd frankly rather have reasonably well-off
> guys from Western Europe/America who have the financial backbone to not
> worry that much about attacks to their funding, than mercenaries who
> have to follow orders or get fired. Even if they're from West
> Uzbekistan.
>
> (Maybe they need a union?)
>
> > 4.Few anons.
>
> Gonna guess you mean "a few anons," not fewer anons.
>
> Again, problem is money. These days, nobody threatens anyone with
> anything substantive, like murder - the threats all involve cutting off
> some funding. So having anonymous people being funded by non-robust
> sources doesn't really buy you that much, because the weakest link will
> pretty much never be the de-jure, legal freedom of an individual.
>
> Having a system that allows people to fund anonymous people better would
> be interesting, but it has some challenges with trust and so on.

<ZmnSCPxj coughs quietly in GMT+8 timezone>

On the other hand, one can argue that "ZmnSCPxj" at this point is a bonafide name (that happens to once have been simply a random sequence of letters) rather than an anonymous cover.

As to box-ticking: the simple fact of the matter is that smart humans will arise everywhere.
It is to the interest of Bitcoin users that more of thhem contribute to the success of Bitcoin.
The alternative by default is that smart people who became smart because they happened to start out with the disadvantage of having to fight tooth and claw in a bad environment will be quite willing to do anything, including attack Bitcoin, just to get out of such a situation.

Regards,
ZmnSCPxj

From prayank at tutanota.de  Tue Nov  9 12:49:14 2021
From: prayank at tutanota.de (Prayank)
Date: Tue, 9 Nov 2021 13:49:14 +0100 (CET)
Subject: [bitcoin-dev] bitcoin.org missing bitcoin core version 22.0
In-Reply-To: <3d686c3a100338514c3ebcc264ec24f2@cock.li>
References: <MmT9umZ--3-2@tutanota.de>
 <20211020192054.GA117785@jauntyelephant.191.37.198.vultr.com>
 <CAHiDt8A30DZtvsPnDDdtyVpho-NKKQhbP_4g8d0MGATawWvg_w@mail.gmail.com>
 <MnjA6g0--3-2@tutanota.de> <3d686c3a100338514c3ebcc264ec24f2@cock.li>
Message-ID: <Mo3jgtg--3-2@tutanota.de>

Hi Yanmaani,

> Unfortunately, this isn't really possible. If they did that, you could get consensus splits. This is why all the other stuff is so important - if Bitcoin is subverted via soft-fork, you *can't* just run your own fork.

I am aware of this problem however looking for solutions or workarounds. Is it possible to have one library for things related to consensus which is used by all full node implementations? There are lot of other things in any full node implementation apart from consensus related code.

> This is all about the money - it's easy to have people be independent when their source of money is independent. But nobody's crazy enough to bite the hand that feeds them, and you couldn't really build a system on that basis. Our best hope is gentle hands, or contributors wealthy enough not to have to care.

Sorry neither I agree with this nor its "all about money" for me. I am assuming there are few others as well with similar thoughts.

I had shared few reasons why someone might contribute to Bitcoin Core: https://bitcoin.stackexchange.com/a/108017/

> Isn't Bitcoin already plenty distributed? Funding people in under-represented countries seems to me like a textbook exercise in 'box-ticking, but moreover, I'd frankly rather have reasonably well-off guys from Western Europe/America who have the financial backbone to not worry that much about attacks to their funding, than mercenaries who have to follow orders or get fired. Even if they're from West Uzbekistan.

Sorry I don't agree with this approach. Its not about 'box-ticking' textbook exercise but to make the attacks more difficult by any governments or people with malicious intent. Few years back when I was in college and Tor wasn't as famous as it is now, we used normal socks proxies for pentesting. My mentor Godzilla had suggested us to use IP of different countries not because it is some textbook exercise but it helps when someone tries to trace your requests. Similarly, if we have people from different countries in different full node implementations as maintainers it will be difficult for people to try crazy things.

> See above. Bitcoin Knots isn't really independent.

I understand there are other implementations like btcd, bcoin, gocoin, libbitcoin, bitcore etc. and Knots is a derivative of Core. However there are lot of differences and it changes your experience as a user while running node and using it for different things. I have mentioned few things in the medium post shared in last email.

> You could also look into a system like Monero's CCS.

Yes I like it and suggested once in bitcoin.org repository even though it can be done by anyone as there is no official website for Bitcoin: https://github.com/bitcoin-dot-org/Bitcoin.org/issues/3545


-- 
Prayank

A3B1 E430 2298 178F



Nov 5, 2021, 20:15 by yanmaani at cock.li:

> On 2021-11-05 08:17, Prayank via bitcoin-dev wrote:
>
>> What followed it (whitepaper being shared on different websites) was
>> true decentralization and we need something similar in other aspects
>> of full node implementations. Few things that can improve
>> decentralization:
>>
>> 1.More people using alternative full node implementations. Right now
>> 98% of nodes use Bitcoin Core.
>>
>
> Unfortunately, this isn't really possible. If they did that, you could get consensus splits. This is why all the other stuff is so important - if Bitcoin is subverted via soft-fork, you *can't* just run your own fork.
>
> Theoretically, I suppose you could run two implementations and do something if they differ, but what?
> 1. Bitcoin Core and <AltImpl> both say block is valid -> valid
> 2. Bitcoin Core and <AltImpl> both say block is invalid -> invalid
> 3. Bitcoin Core says valid, <AltImpl> says invalid -> valid (or get forked off)
> 4. Bitcoin Core says invalid, <AltImpl> says valid -> invalid (or hardfork)
>
>> 2.More people like Luke Dashjr and Amir Taaki who do not simp for
>> anyone. Being a contributor or maintainer in Bitcoin full node
>> implementation is different from other open source projects. It was
>> never going to be easy and it will get difficult with time,
>>
>
> This is all about the money - it's easy to have people be independent when their source of money is independent. But nobody's crazy enough to bite the hand that feeds them, and you couldn't really build a system on that basis. Our best hope is gentle hands, or contributors wealthy enough not to have to care.
>
> (Whatever happened to Amir Taaki, by the way?)
>
>> 3.More people from different countries getting involved in important
>> roles.
>>
>
> Isn't Bitcoin already plenty distributed? Funding people in under-represented countries seems to me like a textbook exercise in 'box-ticking, but moreover, I'd frankly rather have reasonably well-off guys from Western Europe/America who have the financial backbone to not worry that much about attacks to their funding, than mercenaries who have to follow orders or get fired. Even if they're from West Uzbekistan.
>
> (Maybe they need a union?)
>
>> 4.Few anons.
>>
>
> Gonna guess you mean "a few anons," not fewer anons.
>
> Again, problem is money. These days, nobody threatens anyone with anything substantive, like murder - the threats all involve cutting off some funding. So having anonymous people being funded by non-robust sources doesn't really buy you that much, because the weakest link will pretty much never be the de-jure, legal freedom of an individual.
>
> Having a system that allows people to fund anonymous people better would be interesting, but it has some challenges with trust and so on.
>
>> 5.Individuals and organizations who fund different Bitcoin projects
>> should consider contributing in alternative. full node implementations
>> as well. Maybe start with Bitcoin Knots.
>>
>
> See above. Bitcoin Knots isn't really independent. btcd in Go is, so I guess they could try that. But at the end of the day, it wouldn't help - btcd has to be bug-for-bug compatible with Core, and it couldn't really be any other way.
>
> For my $0.05, what's needed is more "hard money" - if people could make donations into a fund, with the fund then paying out to developers, and that fund be controlled in a civilized and non-centralized way (that's the hard part!), this would somewhat insulate developers from people threatening to stop their contributions to The Fund, at the price of having developers being able to be coerced by The Fund.
>
> You could also look into a system like Monero's CCS. But at the end of the day, funding is really a very difficult problem, no matter how you slice it. The money still has to enter the system somehow. Since Bitcoin is a public good, you can't really capture its value, and this means individuals who can (e.g. by malicious activity) will always have the leg up.
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20211109/96c00682/attachment.html>

From shymaa.arafat at gmail.com  Thu Nov 11 22:28:39 2021
From: shymaa.arafat at gmail.com (shymaa arafat)
Date: Fri, 12 Nov 2021 00:28:39 +0200
Subject: [bitcoin-dev] Providing "non-inclusion proofs" to "append to the
 right Merkles" with minimized overhead
Message-ID: <CAM98U8nTn+fG-rR16q1yf=uvzbRHmxve0g+szJPsvUfmKJP7Cg@mail.gmail.com>

Dear Bitcoin Developers,
Hi everybody,
Please allow me to suggest this idea, hope you find it worth reading &
commenting....

While append to the right UTXO Merkles have the much needed advantage of
locality of reference that leads to shorter batch proofs, they're
criticized by some for not providing non-inclusion proofs. This is a
suggestion to slightly change the needed anyway map/dictionary to map the
UTXOS to their positions as leaves given their hash value, so that it can
provide non-inclusion proofs....

1-A 2?? (could be tuned*) pointer vector is allocated to put the  UTXO in a
bucket according to its hash.
2-Due to the Cryptographic hash robustness & bit randomness UTXO hashes
should fall uniformly as all buckets are equiprobable and each bucket is
expected to contain 1-2 UTXOS (less than Go lang map load factor which is
6.5-8, 2?? entry may lead to the same)
3-Insertion is adding a node (in order)to the bucket linked list, deletion
is deleting a node from the bucket list; the vector bucket pointer maybe
adjusted in the process from or to NULL value.
.
The strucutre should be as in attached figure:
Vector of pointers to buckets that could be linked lists with the following
fields in each node:
-A pointer to the UTXO leaf in the main Merkle
-The value of the remaining hash bits, or could be omitted with its value
with the leaf node.
-two bit flag that will be explained shortly.
.
4-To save computation time, we may calculate and send the accumulated root
value of this secondary tree only once per block; either at the end if
valid or when encountering an invalid UTXO to send the non-inclusion proof
and abort the whole block. Like the Tx Merkle, maybe no need to store the
tree or maybe it will save time for the non changed parts (experimental).
5-The non-inclusion proof will be send according to the previous block
accumulated root, so during batch preparation a newly inserted  UTXO will
be flagged 1, a deleted UTXO is  flagged -1, and 0 means value the same as
previous block.
6-If the block is valid, update and reset flags to 0 while computing the
new root. A hash of a bucket is the concatenation of all its nodes(expected
to be2), and empty buckets are substituted by a default NULL hash value.
7-If we had an invalid UTXO, we have two cases:
a)-The hash doesn't exist in any case ( not even with a deleted flag), in
this case we send the usual non-inclusion proof considering old status
before any UTXO from this block.
b)-The UTXO hash is there, but has a deleted flag (it was spent before
during this block); ie, a double spend within the same block.
Now, in this case I do have some doubts and suggestions or comments are
welcomed:
I think we should resend the previous inclusion proof along saying
something like "TX ID ....spent it with proof...."
I guess this an implementation detail of how to point out to a previous
proof in the same block
( I assume such a block is going to be aborted anyways after the invalid
UTXO and old status will be resumed, if this is wrong please say so)
.
That's all, thank you for your time,
Shymaa M. Arafat
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20211112/d58c7732/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: IMG_20211109_003226.jpg
Type: image/jpeg
Size: 182701 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20211112/d58c7732/attachment-0001.jpg>

From luke at dashjr.org  Fri Nov 12 01:53:29 2021
From: luke at dashjr.org (Luke Dashjr)
Date: Fri, 12 Nov 2021 01:53:29 +0000
Subject: [bitcoin-dev] Bitcoin Knots 22.0.knots20211108 released
Message-ID: <202111120153.34195.luke@dashjr.org>

Bitcoin Knots version 22.0.knots20211108 is now available from:

  https://bitcoinknots.org/files/22.x/22.0.knots20211108/

This release includes new features, various bug fixes and performance 
improvements, as well as updated translations.

Note that I also plan to release a Long-Term Support 21.2 in the near future, 
for users who prefer to minimise new feature risks. If you prefer to use a 
LTS branch, I recommend *not* upgrading to 22.x and waiting for 21.2 instead.

Please report bugs using the issue tracker at GitHub:

  https://github.com/bitcoinknots/bitcoin/issues

To receive security and update notifications, please subscribe to:

  https://bitcoinknots.org/list/announcements/join/

For the full release notes and change log, see:

https://github.com/bitcoinknots/bitcoin/blob/v22.0.knots20211108/doc/release-notes.md
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 1528 bytes
Desc: This is a digitally signed message part.
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20211112/6b53e516/attachment.sig>

From michaelfolkson at protonmail.com  Mon Nov 15 14:42:44 2021
From: michaelfolkson at protonmail.com (Michael Folkson)
Date: Mon, 15 Nov 2021 14:42:44 +0000
Subject: [bitcoin-dev] Taproot activates - A time/block line
Message-ID: <HaQ-hY5Xi9DebQ3qteJXbi48IY8ojYlMWXeYrWcEFiKuy31TKY7lNAc42rTb2Sf_FMyhgCz9vp-cf8y-fVpFZ6XtWuR-sBsox1lOoSeGtxQ=@protonmail.com>

I thought I would collect together the highlights from Taproot activating for those strange Bitcoin history buffs (including myself). If you?d rather watch in video form 0xB10C provided an excellent livestream [0] showing blocks and transactions in the run up to and directly after Taproot activating.

Back in July [1] 0xB10C (with the help of F2Pool) spent from Taproot (P2TR) outputs months before Taproot activated. Taproot rules weren?t being enforced and hence these spends were treated as anyone-can-spend. Hence I won?t treat these as the ?first? Taproot spends as they didn?t need to meet Taproot consensus rules.

Block 709631: The last block before Taproot rules were enforced was mined by AntPool. By this point there were various P2TR outputs in blocks, some timelocked for higher than block 709631 but others not timelocked. These non-timelocked P2TR outputs were in effect anyone-can-spend like the ones 0xB10C spent from in July as Taproot rules were not yet being enforced. No P2TR outputs were spent immediately before activation as far as I can tell.

Block 709632: The first block where full nodes started enforcing Taproot rules was mined by F2Pool. It seems [2] F2Pool wasn?t enforcing Taproot rules and did not include any Taproot spends (some with high fee rates) in this block. More seriously an invalid Taproot spend included in this block could have cost them the block reward and caused a re-org when full nodes (and miners) enforcing Taproot rules rejected this block. Given they didn?t include any attempted Taproot spends (valid or invalid) in the block this protected them from that but it does lead to discussions for a later time on whether Speedy Trial signaling was effective if some mining pools signaled readiness months previous but then did not enforce the new soft fork rules on activation.

Block 709633: Mined by AntPool. Similar to F2Pool they didn?t include any Taproot spends in this block and one would assume that they also weren?t enforcing Taproot rules though this has not been confirmed.

Block 709634: Also mined by AntPool.

Block 709635: The first block which included (numerous) valid Taproot spends (and no invalid Taproot spends) was mined by Foundry USA.

The first Taproot spend [3] was completed by bitbug42. It was a key path spend and the OP_RETURN in this first Taproot spend contained the message ?I like Schnorr sigs and I cannot lie?.

Andrew Chow had the second Taproot spend [4] but the first script path spend. He also spent from two Taproot vanity addresses beginning bc1ptapr00t which were presumably generated using his Rust Bitcoin Vanity Address Generator [5].

Pieter Wuille had the third Taproot spend [6]. He also had the bronze medal for SegWit spends on SegWit activation in 2017 [7], he was third then too. However, his vanity address game stepped up for Taproot. For SegWit he spent from one vanity address beginning 35Segwit. This time he spent from vanity addresses beginning bc1ptapr00tearly, bc1pay2tapr00t, bc1pmyusetapr00t, bc1partytaptap and this isn?t including all the vanity addresses that were sent to. He (with Greg Maxwell?s help) searched 2.4 quadrillion keys in a week [8].

BitGo had the fourth Taproot spend [9] and the first Taproot multisig spend via the script path. The script used OP_CHECKSIG and OP_CHECKSIGVERIFY which have been modified with the Taproot upgrade to check Schnorr signatures but it didn?t use the new opcode OP_CHECKSIGADD that has been introduced for threshold (and multi) signatures. It contained an OP_RETURN message with ?Thx Satoshi! ?/21mil First Taproot multisig spend -BitGo?

jaoNoctus claimed the fifth Taproot spend and narcelio and ottosch claimed the sixth and seventh Taproot spends.

The first use of OP_CHECKSIGADD on mainnet was completed [10] by Alekos Filini using modified code [11] from the BDK (Bitcoin Dev Kit) library.

Any errors are my own and I will gladly correct. Thanks to 0xB10C, Greg Maxwell, Pieter Wuille, Murch, Andrew Chow, BitGo, Daniel McNally, Rearden Code, Alekos Filini, Chun, pinheadmz for highlighting these various events online. Thanks to the various block explorers (Esplora, mempool.space etc) that were very useful for monitoring Taproot activation. And thanks to the community as a whole for participating and engaging with this successful upgrade. Without participation and engagement these upgrades are meaningless and it is a great sign for Bitcoin?s future that there was so much interest and scrutiny of this upgrade.

[0]: https://www.youtube.com/watch?v=1jijKVB1cNA, https://www.twitch.tv/0xb10c/video/1204909643
[1]: https://b10c.me/blog/007-spending-p2tr-pre-activation/
[2]: https://twitter.com/satofishi/status/1459868549674065926?s=20
[3]: 33e794d097969002ee05d336686fc03c9e15a597c1b9827669460fac98799036
[4]: 37777defed8717c581b4c0509329550e344bdc14ac38f71fc050096887e535c8
[5]: https://github.com/achow101/rust-vanitygen
[6]: 83c8e0289fecf93b5a284705396f5a652d9886cbd26236b0d647655ad8a37d82
[7]: https://twitter.com/0xB10C/status/1459592608305582090?s=20
[8]: https://twitter.com/pwuille/status/1459778731548057603?s=20
[9]: 905ecdf95a84804b192f4dc221cfed4d77959b81ed66013a7e41a6e61e7ed530
[10]: 2eb8dbaa346d4be4e82fe444c2f0be00654d8cfd8c4a9a61b11aeaab8c00b272
[11]: https://gist.github.com/afilini/7c2c33af095ea975f52f5d68302c91d6

--

Michael Folkson
Email: michaelfolkson at protonmail.com
Keybase: michaelfolkson
PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20211115/bb3c2818/attachment.html>

From n1ms0s at protonmail.com  Wed Nov 17 03:17:13 2021
From: n1ms0s at protonmail.com (n1ms0s)
Date: Wed, 17 Nov 2021 03:17:13 +0000
Subject: [bitcoin-dev] bitcoinj fork with Taproot support
Message-ID: <n_5M6FQe3Q_E3lZIM99BDUfpKrYUvewgiGPWFfM_r01huHHQq_3roT3TwVp2QEciCD5cCnT1F66VhjuMcPYeagTaHFPcp0Xl43j2mQpM4Zo=@protonmail.com>

Hello all,
I am currently working on a fork of bitcoinj with basic Taproot support. Currently it supports basic sending and receiving with Taproot addresses using a bitcoinj SPV wallet.
See here: https://github.com/n1ms0s/bitcoinj

It supports the above along with public/private key tweaking. Feel free to take a look, and leave feedback or even work on it yourself and submit a pull request.

One issue I am running into right now though is when broadcasting a Taproot transaction to older nodes (old as in ~0.18.0) I get an error response of "Witness version reserved for soft-fork upgrades". Anyone have any idea why this happens? I have a stackexchange question open here for it:
https://bitcoin.stackexchange.com/questions/110787/issue-when-broadcasting-taproot-transaction-to-older-nodes

n1ms0s
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20211117/8e78d0c2/attachment.html>

From achow101-lists at achow101.com  Wed Nov 17 18:07:07 2021
From: achow101-lists at achow101.com (Andrew Chow)
Date: Wed, 17 Nov 2021 18:07:07 +0000
Subject: [bitcoin-dev] bitcoinj fork with Taproot support
Message-ID: <ff9aecf5-70ad-f532-49f3-513b5a6beee9@achow101.com>

Prior to 0.19.0, creating outputs with an unknown witness version was considered non-standard. This was a violation of BIP 173 and was fixed for 0.19.0+ in PR #15846.

On 11/16/2021 10:17 PM, n1ms0s via bitcoin-dev wrote:

> Hello all,
> I am currently working on a fork of bitcoinj with basic Taproot support. Currently it supports basic sending and receiving with Taproot addresses using a bitcoinj SPV wallet.
> See here: https://github.com/n1ms0s/bitcoinj
>
> It supports the above along with public/private key tweaking. Feel free to take a look, and leave feedback or even work on it yourself and submit a pull request.
>
> One issue I am running into right now though is when broadcasting a Taproot transaction to older nodes (old as in ~0.18.0) I get an error response of "Witness version reserved for soft-fork upgrades". Anyone have any idea why this happens? I have a stackexchange question open here for it:
> https://bitcoin.stackexchange.com/questions/110787/issue-when-broadcasting-taproot-transaction-to-older-nodes
>
> n1ms0s
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20211117/d99c1571/attachment.html>

From bitcoin-dev at wuille.net  Wed Nov 17 19:00:43 2021
From: bitcoin-dev at wuille.net (Pieter Wuille)
Date: Wed, 17 Nov 2021 19:00:43 +0000
Subject: [bitcoin-dev] bitcoinj fork with Taproot support
In-Reply-To: <ff9aecf5-70ad-f532-49f3-513b5a6beee9@achow101.com>
References: <ff9aecf5-70ad-f532-49f3-513b5a6beee9@achow101.com>
Message-ID: <pkT64UkQSpTNVJGb12FQK5RTkD8SDOuyWiGOfIQmdX77_eCqBvCzfOerRCPElADFZqqcwfUZhUaRM_SXRKgvO7fXHftDBCybkreTBLahbFc=@wuille.net>

On Wednesday, November 17th, 2021 at 1:07 PM, Andrew Chow via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:

> Prior to 0.19.0, creating outputs with an unknown witness version was considered non-standard. This was a violation of BIP 173 and was fixed for 0.19.0+ in PR #15846.

That's correct, but I think OP's problem is with getting P2TR _spends_ to relay. Those will be rejected by all post-segwit pre-taproot Bitcoin Core releases, as far as I know.

--
Pieter
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20211117/be85de1c/attachment.html>

From n1ms0s at protonmail.com  Wed Nov 17 20:05:55 2021
From: n1ms0s at protonmail.com (n1ms0s)
Date: Wed, 17 Nov 2021 20:05:55 +0000
Subject: [bitcoin-dev] bitcoinj fork with Taproot support
In-Reply-To: <pkT64UkQSpTNVJGb12FQK5RTkD8SDOuyWiGOfIQmdX77_eCqBvCzfOerRCPElADFZqqcwfUZhUaRM_SXRKgvO7fXHftDBCybkreTBLahbFc=@wuille.net>
References: <ff9aecf5-70ad-f532-49f3-513b5a6beee9@achow101.com>
 <pkT64UkQSpTNVJGb12FQK5RTkD8SDOuyWiGOfIQmdX77_eCqBvCzfOerRCPElADFZqqcwfUZhUaRM_SXRKgvO7fXHftDBCybkreTBLahbFc=@wuille.net>
Message-ID: <cgu5Br8FsrOR7Ly3W5YBg__byG9CdtuhCDnZ8fwN7wBha3G9-kGrooK5gyN-SESmgCHweZzXfpt843Y1yka_yx-ANmYEmF64Xg1o1OJjcG4=@protonmail.com>

This seems to be the case. I saw your reply on Bitcoin StackExchange as well. In bitcoinj I just made it so the client only connects to nodes with at least protocol version 70016. Seems to work well.

??????? Original Message ???????
On Wednesday, November 17, 2021 7:00 PM, Pieter Wuille via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:

> On Wednesday, November 17th, 2021 at 1:07 PM, Andrew Chow via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>> Prior to 0.19.0, creating outputs with an unknown witness version was considered non-standard. This was a violation of BIP 173 and was fixed for 0.19.0+ in PR #15846.
>
> That's correct, but I think OP's problem is with getting P2TR _spends_ to relay. Those will be rejected by all post-segwit pre-taproot Bitcoin Core releases, as far as I know.
>
> --
> Pieter
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20211117/61d7eafc/attachment.html>

From prayank at tutanota.de  Thu Nov 18 20:29:24 2021
From: prayank at tutanota.de (Prayank)
Date: Thu, 18 Nov 2021 21:29:24 +0100 (CET)
Subject: [bitcoin-dev] Mock introducing vulnerability in important
 Bitcoin projects
In-Reply-To: <sez9AuvBEnKKkLkJ4aivnaLJz5M5VFz3yTOdreTGmFb6RzwMv7h0dRFbEiB1_aup4Daw7t9YwlZKp2YvbgCu1fzym28cHhlzRVC3efmfBpE=@protonmail.com>
References: <MkdYcV9--3-2@tutanota.de>
 <CAPv7TjbvRE-b33MeYucUfr6CTooCRSH42hwSn5dMiJ4LODATRQ@mail.gmail.com>
 <MktnWM7--3-2@tutanota.de>
 <qNjz-H23x07OJjnf5Try4Qp8l5s23SQxhEE8yAfNbrniN34u2vM72FVFSDJxHg4HNTL8tdcm-KKT8h6XVRwOwN0ZmckxzWiMlNFmLbMNuHc=@protonmail.com>
 <MkwZGYl--7-2@tutanota.de>
 <CAMnpzfrNZ0vpiMVoH=0KW9jy1-vppudX3D7Z+aXpSp4h_7s=zw@mail.gmail.com>
 <Ml-IIuL--3-2@tutanota.de>
 <CAAxiurb1_-p2yO8183MvB2x_i9H+WAo9t0RH85faRrrKz9YxGg@mail.gmail.com>
 <202110032133.44726.luke@dashjr.org>
 <sez9AuvBEnKKkLkJ4aivnaLJz5M5VFz3yTOdreTGmFb6RzwMv7h0dRFbEiB1_aup4Daw7t9YwlZKp2YvbgCu1fzym28cHhlzRVC3efmfBpE=@protonmail.com>
Message-ID: <MoojKWD--3-2@tutanota.de>

Good morning ZmnSCPxj,

> Indeed, I believe we should take the position that "review process is as much a part of the code as the code itself, and should be tested regularly".

Agree. Review process is an important part of open source Bitcoin projects. We should test and verify if everything is working as expected or there is any scope for improvement.

> as they cannot opt out of "the real thing" other than to stop developing entirely

True and it won't be as obvious as this. Nobody will announce it on dev mailing list and will use proxies (not networks but humans)

After reading all the emails, personally experiencing review process especially on important issues like privacy and security, re-evaluating everything and considering the time I can spend on this, I have decided to do this exercise for 3 projects with just 1 account. I have created a salted hash for the username as you had mentioned in the first email:

f40bcb13dbcbf7b6245becb757777586c22798ed7360cd9853572152ddf07a39

3 Bitcoin projects are Bitcoin Core (full node implementation), LND (LN implementation) and Bisq (DEX).

Pull requests will be created in next 6 months. If vulnerability gets caught during review, will publicly announce here that the project caught the PR and reveal the de-commitment publicly. If not caught during review, will privately reveal both the inserted vulnerability and the review failure via the normal private vulnerability-reporting channels. A summary with all the details will be shared later.

This exercise cannot be same as one of the active developers trying to do the same thing because of few reasons mentioned by Ryan Grant in one of the emails: uneven reputation factor of various devs, and uneven review attention for new pull requests. However, I am expecting few interesting results which will help improve the review process hence make Bitcoin more secure.

Will end the email by rephrasing one of the tweets from a respected cypherpunk recently: Independent thought is critical in aircraft crash investigations and in bitcoin development. Immunity from peer pressure can be very helpful during review process.


-- 
Prayank

A3B1 E430 2298 178F



Oct 4, 2021, 09:29 by ZmnSCPxj at protonmail.com:

>
> Good morning Luke,
>
>> All attempts are harmful, no matter the intent, in that they waste
>> contributors' time that could be better spent on actual development.
>>
>> However, I do also see the value in studying and improving the review process
>> to harden it against such inevitable attacks. The fact that we know the NSA
>> engages in such things, and haven't caught one yet should be a red flag.
>>
>
> Indeed, I believe we should take the position that "review process is as much a part of the code as the code itself, and should be tested regularly".
>
>> Therefore, I think any such a scheme needs to be at least opt-out, if not
>> opt-in. Please ensure there's a simple way for developers with limited time
>> (or other reasons) to be informed of which PRs to ignore to opt-out of this
>> study. (Ideally it would also prevent maintainers from merging - maybe
>> possible since we use a custom merging script, but what it really needs to
>> limit is the push, not the dry-run.)
>>
>
> Assuming developers are normal humans with typical human neurology (in particular a laziness circuit), perhaps this would work?
>
> Every commit message is required to have a pair of 256-bit hex words.
>
> Public attempts at attack / testing of the review process will use the first 256-bit as a salt, and when the salt is prepended to the string "THIS IS AN ATTACK" and then hashed with e.g. SHA256, should result in the second 256-bit word.
>
> Non-attacks / normal commits just use random 256-bit numbers.
>
> Those opting-out to this will run a script that checks commit messages for whether the first 256-bit hexword concatenated with "THIS IS AN ATTACK", then hashed, is the second 256-bit hexword.
>
> Those opting-in will not run that script and ignore the numbers.
>
> The script can be run as well at the maintainer.
>
> Hopefully, people who are not deliberately opting out will be too lazy to run the script (as is neurotypical for humans) and getting "spoilered" on this.
>
> ***HOWEVER***
>
> We should note that a putative NSA attack would of course not use the above protocol, and thus no developer can ever opt out of an NSA attempt at inserting vulnerabilities; thus, I think it is better if all developers are forced to opt in on the "practice rounds", as they cannot opt out of "the real thing" other than to stop developing entirely.
>
> Regards,
> ZmnSCPxj
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20211118/0b378431/attachment.html>

From dave at dtrt.org  Sun Nov 21 06:31:31 2021
From: dave at dtrt.org (David A. Harding)
Date: Sun, 21 Nov 2021 06:31:31 +0000
Subject: [bitcoin-dev] Finding peers that relay taproot spends,
 was Re: bitcoinj fork with Taproot support
In-Reply-To: <cgu5Br8FsrOR7Ly3W5YBg__byG9CdtuhCDnZ8fwN7wBha3G9-kGrooK5gyN-SESmgCHweZzXfpt843Y1yka_yx-ANmYEmF64Xg1o1OJjcG4=@protonmail.com>
References: <ff9aecf5-70ad-f532-49f3-513b5a6beee9@achow101.com>
 <pkT64UkQSpTNVJGb12FQK5RTkD8SDOuyWiGOfIQmdX77_eCqBvCzfOerRCPElADFZqqcwfUZhUaRM_SXRKgvO7fXHftDBCybkreTBLahbFc=@wuille.net>
 <cgu5Br8FsrOR7Ly3W5YBg__byG9CdtuhCDnZ8fwN7wBha3G9-kGrooK5gyN-SESmgCHweZzXfpt843Y1yka_yx-ANmYEmF64Xg1o1OJjcG4=@protonmail.com>
Message-ID: <0100017d413154f5-866f57e9-5545-4f92-83d9-d2d28649713a-000000@email.amazonses.com>

On Wed, Nov 17, 2021 at 08:05:55PM +0000, n1ms0s via bitcoin-dev wrote:
> This seems to be the case. I saw your reply on Bitcoin StackExchange
> as well. In bitcoinj I just made it so the client only connects to
> nodes with at least protocol version 70016. Seems to work well.

Hi,

This is a clever solution, but when I looked into this I found that P2P
protocol version 70016 was introduced in Bitcoin Core version 0.21.0[1].
This release will not ever relay taproot spends because it doesn't
contain taproot activation parameters[2].  So this heuristic is
imperfect: it only works when it happens to connect to the 0.21.1 and
22.0 versions of Bitcoin Core (or compatible nodes) which were
programmed to begin relaying taproot spends starting one block before
activation.

Can anyone recommend a better heuristic lite wallets can use to ensure
they're connecting to a taproot-activated node?  (If not, maybe this is
something we want nodes to advertise during activation of future
protocol extensions.)

Thanks,

-Dave

[1] https://github.com/bitcoin/bitcoin/commit/ccef10261efc235c8fcc8aad54556615b0cc23be
    https://bitcoincore.org/en/releases/0.21.0/

[2] https://github.com/bitcoin/bitcoin/pull/20165
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20211121/d3dda5b4/attachment.sig>

From sjors at sprovoost.nl  Wed Nov 24 12:44:46 2021
From: sjors at sprovoost.nl (Sjors Provoost)
Date: Wed, 24 Nov 2021 13:44:46 +0100
Subject: [bitcoin-dev] Taproot Fields for PSBT
In-Reply-To: <795f917b-3883-1827-f39b-35123b500f36@achow101.com>
References: <795f917b-3883-1827-f39b-35123b500f36@achow101.com>
Message-ID: <E2219CF0-4044-42BC-B782-69DCFF33A5A0@sprovoost.nl>

Hi Andrew,

I'm confused why PSBT_IN_TAP_BIP32_DERIVATION and PSBT_OUT_TAP_BIP32_DERIVATION
contain not just the derivation path for the xonlypubkey, but also the tapleaf merkle path.

First I thought it was perhaps necessary in order for a signer to guess which
script leaves it can sign with its own keys. But you can't really know that without
actually seeing the script. When a signer looks at a script, it presumably already
knows the leaf path.

- Sjors

> Op 22 jun. 2021, om 23:22 heeft Andrew Chow via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> het volgende geschreven:
> 
> Hi All,
> 
> I would like to propose a BIP which defines new fields for Taproot
> support in PSBT.
> 
> The full text is below, and the rendered file can be found at

Now at: https://github.com/bitcoin/bips/blob/master/bip-0174.mediawiki <https://github.com/bitcoin/bips/blob/master/bip-0174.mediawiki>

> -
> | Taproot Key BIP 32 Derivation Path
> | <tt>PSBT_IN_TAP_BIP32_DERIVATION = 0x16</tt>
> | <tt><xonlypubkey></tt>
> | The 32 byte X-only public key
> | <tt><hashes len> <leaf hash>* <32-bit uint> <32-bit uint>*</tt>
> | A compact size unsigned integer representing the number of leaf
> hashes, followed by a list of leaf hashes, followed by the master key
> fingerprint concatenated with the derivation path of the public key. The
> derivation path is represented as 32-bit little endian unsigned integer
> indexes concatenated with each other. Public keys are those needed to
> spend this output. The leaf hashes are of the leaves which involve this
> public key.

> |-
> | Taproot Key BIP 32 Derivation Path
> | <tt>PSBT_OUT_TAP_BIP32_DERIVATION = 0x07</tt>
> | <tt><xonlypubkey></tt>
> | The 32 byte X-only public key
> | <tt><hashes len> <leaf hash>* <32-bit uint> <32-bit uint>*</tt>
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20211124/44e36110/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: Message signed with OpenPGP
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20211124/44e36110/attachment.sig>

From gsanders87 at gmail.com  Wed Nov 24 16:00:42 2021
From: gsanders87 at gmail.com (Greg Sanders)
Date: Thu, 25 Nov 2021 00:00:42 +0800
Subject: [bitcoin-dev] Taproot Fields for PSBT
In-Reply-To: <E2219CF0-4044-42BC-B782-69DCFF33A5A0@sprovoost.nl>
References: <795f917b-3883-1827-f39b-35123b500f36@achow101.com>
 <E2219CF0-4044-42BC-B782-69DCFF33A5A0@sprovoost.nl>
Message-ID: <CAB3F3DuR3fETgD=h0cWZ_j6XcNRqHub_KReNj3-oa7DhaCq-iQ@mail.gmail.com>

I may be misunderstanding the question, but it seems essential data for the
finalizer role, which may not know such information on its own.

On Wed, Nov 24, 2021 at 11:15 PM Sjors Provoost via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Hi Andrew,
>
> I'm confused why PSBT_IN_TAP_BIP32_DERIVATION and
> PSBT_OUT_TAP_BIP32_DERIVATION
> contain not just the derivation path for the xonlypubkey, but also the
> tapleaf merkle path.
>
> First I thought it was perhaps necessary in order for a signer to guess
> which
> script leaves it can sign with its own keys. But you can't really know
> that without
> actually seeing the script. When a signer looks at a script, it presumably
> already
> knows the leaf path.
>
> - Sjors
>
> Op 22 jun. 2021, om 23:22 heeft Andrew Chow via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> het volgende geschreven:
>
> Hi All,
>
> I would like to propose a BIP which defines new fields for Taproot
> support in PSBT.
>
> The full text is below, and the rendered file can be found at
>
>
> Now at: https://github.com/bitcoin/bips/blob/master/bip-0174.mediawiki
>
> -
> | Taproot Key BIP 32 Derivation Path
> | <tt>PSBT_IN_TAP_BIP32_DERIVATION = 0x16</tt>
> | <tt><xonlypubkey></tt>
> | The 32 byte X-only public key
> | <tt><hashes len> <leaf hash>* <32-bit uint> <32-bit uint>*</tt>
> | A compact size unsigned integer representing the number of leaf
> hashes, followed by a list of leaf hashes, followed by the master key
> fingerprint concatenated with the derivation path of the public key. The
> derivation path is represented as 32-bit little endian unsigned integer
> indexes concatenated with each other. Public keys are those needed to
> spend this output. The leaf hashes are of the leaves which involve this
> public key.
>
>
> |-
> | Taproot Key BIP 32 Derivation Path
> | <tt>PSBT_OUT_TAP_BIP32_DERIVATION = 0x07</tt>
> | <tt><xonlypubkey></tt>
> | The 32 byte X-only public key
> | <tt><hashes len> <leaf hash>* <32-bit uint> <32-bit uint>*</tt>
>
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20211125/1b84c9b6/attachment.html>

From bitcoin-dev at wuille.net  Wed Nov 24 16:08:18 2021
From: bitcoin-dev at wuille.net (Pieter Wuille)
Date: Wed, 24 Nov 2021 16:08:18 +0000
Subject: [bitcoin-dev] Taproot Fields for PSBT
In-Reply-To: <E2219CF0-4044-42BC-B782-69DCFF33A5A0@sprovoost.nl>
References: <795f917b-3883-1827-f39b-35123b500f36@achow101.com>
 <E2219CF0-4044-42BC-B782-69DCFF33A5A0@sprovoost.nl>
Message-ID: <OkfdZZt7BDS6oE3RU5bosuDuUFnR5oj1alPXP23DQfXXBup61cMCIJj_DUZVi6nXwwCdilVqdj38wL-w7eXwX9HtdSg6FVoF1UevPfD4yCw=@wuille.net>

On Wednesday, November 24th, 2021 at 7:44 AM, Sjors Provoost via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:

> Hi Andrew,
>
> I'm confused why PSBT_IN_TAP_BIP32_DERIVATION and PSBT_OUT_TAP_BIP32_DERIVATION
> contain not just the derivation path for the xonlypubkey, but also the tapleaf merkle path.
>
> First I thought it was perhaps necessary in order for a signer to guess which
> script leaves it can sign with its own keys. But you can't really know that without
> actually seeing the script. When a signer looks at a script, it presumably already
> knows the leaf path.

No, that's exactly it. Signers aren't expected to know or understand scripts ahead of time. With a field telling them which keys are present in which leaves, and how those keys are derived, they can sign without fully understanding the script, or needing the ability to parse the relevant script at all. The actual script information is there too of course, for those that do want to analyze it, or factor that into the decision whether to sign or not.

Cheers,

--
Pieter
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20211124/30416f16/attachment-0001.html>

From 0xb10c at gmail.com  Wed Nov 24 17:29:54 2021
From: 0xb10c at gmail.com (0xB10C)
Date: Wed, 24 Nov 2021 18:29:54 +0100
Subject: [bitcoin-dev] Taproot activates - A time/block line
In-Reply-To: <HaQ-hY5Xi9DebQ3qteJXbi48IY8ojYlMWXeYrWcEFiKuy31TKY7lNAc42rTb2Sf_FMyhgCz9vp-cf8y-fVpFZ6XtWuR-sBsox1lOoSeGtxQ=@protonmail.com>
References: <HaQ-hY5Xi9DebQ3qteJXbi48IY8ojYlMWXeYrWcEFiKuy31TKY7lNAc42rTb2Sf_FMyhgCz9vp-cf8y-fVpFZ6XtWuR-sBsox1lOoSeGtxQ=@protonmail.com>
Message-ID: <b6046d93-d8d1-bef4-5ed8-97f95b9f9e0d@gmail.com>

Thanks, Michael, for writing this up. I agree that it's good to archive
events like, for example, soft-fork activations in an ML post.

All bigger pools have now included multiple P2TR spends in their blocks.
I have a few comments on what happened at F2Pool and to some extend also
at AntPool. These were pool number three and pool number five to signal
taproot readiness. I'm not affiliated with them but was happy to help
F2Pool out and return the favor[1] when they asked for help debugging
why they don't include P2TR spends. I have the permission to share some
pool internals and hope this can help make future soft-forks even smoother.

Please take my comments with a grain of salt. On the one hand, it could
be that I'm naive in believing what the pools have told me in private
communication. On the other hand, I'm not as marked from the blocksize
war as others might be.


On 11/15/21 3:42 PM, Michael Folkson via bitcoin-dev wrote:
> [..]
>
> Block 709632: The first block where full nodes started enforcing
> Taproot rules was mined by F2Pool. It seems [2] F2Pool wasn?t
> enforcing Taproot rules and did not include any Taproot spends (some
> with high fee rates) in this block. [..] but it does lead to
> discussions for a later time on whether Speedy Trial signaling was
> effective if some mining pools signaled readiness months previous but
> then did not enforce the new soft fork rules on activation.
>
> Block 709633: Mined by AntPool. Similar to F2Pool they didn?t include
> any Taproot spends in this block and one would assume that they also
> weren?t enforcing Taproot rules though this has not been confirmed.
>
> Block 709634: Also mined by AntPool.
>
> Block 709635: The first block which included (numerous) valid Taproot
> spends (and no invalid Taproot spends) was mined by Foundry USA.
>
> [..]
>
> [1]: https://b10c.me/blog/007-spending-p2tr-pre-activation/
> [2]: https://twitter.com/satofishi/status/1459868549674065926
> <https://twitter.com/satofishi/status/1459868549674065926?s=20>
>
> [..]

While F2Pool responded they "Will upgrade soon" [2] to my question if
they haven't upgraded their nodes yet, I think they were primarily
buying time as they them-self weren't sure what the issue is. "We are
looking into it" could have been a better and more fitting response.

An F2Pool engineer reached out on the 16th (two days after activation),
mentioning they had been running Bitcoin Core v0.21.1 for a few weeks
now and upgraded to v22.0 today (on the 16th) in the hope that this
would fix their problem of not including P2TR spends. They asked if I
could create and _not_ broadcast a P2TR spending transaction for them to
check with testmempoolaccept/sendrawtransaction/getblocktemplate.

I constructed and sent a P2TR spend and asked them to check the versions
of their nodes peers too. testmempoolaccept returned "allowed": true
(expected as they were running >= v0.21.1). However, it turned out that
they weren't connected to any P2TR-spend-relaying peers. They didn't
receive any P2TR spending transaction and couldn't include them in their
block templates. It seems like this was caused by a) using addnode to
directly connect to known, external peers that hadn't upgraded. But more
importantly, b) by applying a custom patch to their node's peer
selection behavior based on a heuristic that worked for a few years but
at some point broke without being noticed (I'm not publishing details on
purpose). F2Pool has fixed this. With connections to >= v0.21.1 nodes,
they started receiving and constructing blocks with P2TR spends.

I haven't been in contact with AntPool directly and don't know details
about their situation. Alejandro De La Torre (@bitentrepreneur)
communicated with them and said I can include the following:

"I spoke with antpool after I noticed from b10c?s tweet that they had
not included P2TR [spends]. They were quick to react when I inquired.
They had not updated to bitcoind 22.0, but had tested it and were
planning to update soon. The next day they indeed updated and were able
to include a tx with a P2TR spend."

and

?"[Anpool] said that the old peer issue that F2Pool faced 'may be the
issue'."

AntPool didn't provide more information to Alejandro. It's not clear to
me what the actual issues and fixes were.


I'll leave it to someone else to properly reflect on speedy trial. I,
however, want to add: F2Pool mentioned that they "upgraded to v0.21.1
several weeks ago". This indicates that they were signaling without
being ready. I don't blame them and assume they were not the only pool
just setting the version bit. IMO some of the motivations for fake
signaling: a) Immense community pressure (e.g., on Twitter) to just set
the bit and then get ready in the next six months. b) Running nodes with
custom patches. These require longer to upgrade, especially if you want
to ensure there aren't any bugs in your patches...


It's out of the scope of the Bitcoin Core project to consider people's
custom patches, and it's impossible if they are unpublished. In this
particular case, upstreaming the patch does not make sense.

However, with only just above 50% of taproot nodes[3] (more than a week
after activation), there might still be motivation for having a feature
(sometime before the next soft-fork) to alert/warn a node operator if
his node does not have any peers relaying soft-fork X transaction.
Should PROTOCOL_VERSION be bumped to show support for soft-fork
transaction relay? Or does a service flag for relay makes sense (it
seems complicated to decommission service flags reliably)? Parsing the
subver (e.g. "/Satoshi:0.21.1/") doesn't make sense as there are not
only Bitcoin Core nodes on the network. Could there be a message that is
exchanged between two nodes to indicate soft-fork readiness?

How a node operator can be alerted, besides logging, is an
implementation detail of Bitcoin Core. Maybe a getnodealerts RPC that a
node operator can hook up to his monitoring?

Additionally, for the next soft-fork where relay is affected,
instructions for mining pool signaling could state: "Upgrade to version
Z and make sure you have a few version Z peers before starting to signal
readiness".

Thanks,
0xB10C

[3] http://azure.erisian.com.au/~aj/taproot/taproot.html






From ali at notatether.com  Fri Nov 26 16:56:48 2021
From: ali at notatether.com (Ali Sherief)
Date: Fri, 26 Nov 2021 16:56:48 +0000
Subject: [bitcoin-dev] Trying to patch Core ZMQ "rawtx" topic to only
	publish unconfirmed transactions: How?
Message-ID: <i1UxLDIyGhAt1KS5mHXaZ1cjhjEDd1bwVm-GZjrCRpye8z4O9zuwkw1CNa_UER12p79KknIKbT5hjjW5e0hwV0fWlB0kag6mHAF5f8K1y2k=@notatether.com>

This has also been posted on Bitcointalk forum: https://bitcointalk.org/index.php?topic=5373341.msg58539261#msg58539261 I have republished it here hoping someone more knowledgeable can post some insight about this.
----
It appears that the ZeroMQ topic I'm listening to, "rawtx", not only emits a raw transaction when it appears on the mempool, but once it's already confirmed too.

This messes with my software, causing it to add txids, addresses, etc. a second time inside arrays (this means that the same transaction is received twice in total).

Array de-duping is not a viable solution long-term (because the array will quickly grow to be big eventually and then this has to happen every time a new element is added), so I'm trying to nip the problem from the source by instructing Core to only publish unconfirmed bitcoin transactions.

According to https://bitcoin.stackexchange.com/questions/52848/is-it-possible-to-configure-the-bitcoin-daemon-to-only-broadcast-unconfirmed-tra , it is not possible to configure this from a configuration or command-line option. The source code must directly be edited. But since the codebase has changed greatly, the proposed solution no longer works.

----

So basically, I know that something inside src/zmq/zmqnotificationinterface.cpp needs to be patched, but I'm not sure which function, or how to do it. Because I only need unconfirmed transactions to be published on ZeroMQ rawtx and not confirmed ones, it's one of the following functions that I need to patch for my own build:

CZMQNotificationInterface::TransactionRemovedFromMempool
void CZMQNotificationInterface::BlockDisconnected

Both of these call NotifyTransaction() method which I assume fires a message on "rawtx" channel.

In the Stack Exchange question I linked above, Jonas Schnelli suggested adding an `if (!pblock)` check, but that was several years ago and the function he was referencing no longer exists.

But I still wonder if the pblock check is still applicable in the present day (i.e. if it's indicating a block the transaction is inside).

- Ali Sherief
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20211126/f91da026/attachment.html>

From prayank at tutanota.de  Sat Nov 27 13:42:38 2021
From: prayank at tutanota.de (Prayank)
Date: Sat, 27 Nov 2021 14:42:38 +0100 (CET)
Subject: [bitcoin-dev] Trying to patch Core ZMQ "rawtx" topic to only
 publish unconfirmed transactions: How?
Message-ID: <MpWcX_f--F-2@tutanota.de>

Hi Ali,

Not sure if this is exactly what you are looking for but maybe trying to solve this I might also learn few things:

Save zmqpubsequence=tcp://127.0.0.1:28332 in bitcoin.conf

Run bitcoind

Run this python script: https://pastebin.com/raw/tNp2x5y3

You will see results like this: 
https://i.imgur.com/xKzFJbl.png
https://i.imgur.com/gpsTTHZ.png

A - Accepted, C- Connect (block) and R- Removal in the above screenshots

If you are looking for unconfirmed transactions printed in sequence I think this should help. Since transactions can be printed twice (accept,remove) in this case as well, python script can be modified to manage this IMO.

Other alternatives can be debug=mempool and reading debug.log for changes without polling.

-- 
Prayank

A3B1 E430 2298 178F
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20211127/d9d4e66e/attachment.html>

From 0xb10c at gmail.com  Mon Nov 29 09:32:15 2021
From: 0xb10c at gmail.com (0xB10C)
Date: Mon, 29 Nov 2021 10:32:15 +0100
Subject: [bitcoin-dev] Trying to patch Core ZMQ "rawtx" topic to only
 publish unconfirmed transactions: How?
In-Reply-To: <i1UxLDIyGhAt1KS5mHXaZ1cjhjEDd1bwVm-GZjrCRpye8z4O9zuwkw1CNa_UER12p79KknIKbT5hjjW5e0hwV0fWlB0kag6mHAF5f8K1y2k=@notatether.com>
References: <i1UxLDIyGhAt1KS5mHXaZ1cjhjEDd1bwVm-GZjrCRpye8z4O9zuwkw1CNa_UER12p79KknIKbT5hjjW5e0hwV0fWlB0kag6mHAF5f8K1y2k=@notatether.com>
Message-ID: <6dbaa89c-b658-e239-9f28-5f1609b8e746@gmail.com>

Hi Ali,

I've run into this multiple times myself. I've opened a draft PR [0]
adding a rawmempooltx publisher.

You're right. In zmq/zmqnotificationinterface.cpp the
CZMQNotificationInterface is notified about TransactionAddedToMempool.
Currently, this calls NotifyTransaction() (the publisher with the rawtx
topic) and NotifyTransactionAcceptance() (the publisher with the
sequence topic)[1]. I've added a call to a new
NotifyMempoolTransaction() function (the publisher with the rawmempooltx
topic).

I'd find a mempool transaction publisher with both the raw transaction
and transaction fee useful too. However, this requires changes to the
chain notifications in interfaces/chain.h.?

[0]: https://github.com/bitcoin/bitcoin/pull/23624
[1]:
https://github.com/bitcoin/bitcoin/pull/23624/files#diff-ac4b2d3a8de2c4dd41ad9d75505ea6ce4dc87a476710a9ebee8acf9bebf5cca2L146-L148?


Best,
0xB10C



On 11/26/21 5:56 PM, Ali Sherief via bitcoin-dev wrote:
>
> This has also been posted on Bitcointalk
> forum:?https://bitcointalk.org/index.php?topic=5373341.msg58539261#msg58539261
> <https://bitcointalk.org/index.php?topic=5373341.msg58539261#msg58539261>?I
> have republished it here hoping someone more knowledgeable can post
> some insight about this.
> ----
> It appears that the ZeroMQ topic I'm listening to, "rawtx", not only
> emits a raw transaction when it appears on the mempool, but once it's
> already confirmed too.
>
> This messes with my software, causing it to add txids, addresses, etc.
> a second time inside arrays (this means that the same transaction is
> received twice in total).
>
> Array de-duping is not a viable solution long-term (because the array
> will quickly grow to be big eventually and then this has to happen
> every time a new element is added), so I'm trying to nip the problem
> from the source by instructing Core to only publish unconfirmed
> bitcoin transactions.
>
> According to
> https://bitcoin.stackexchange.com/questions/52848/is-it-possible-to-configure-the-bitcoin-daemon-to-only-broadcast-unconfirmed-tra
> <https://bitcoin.stackexchange.com/questions/52848/is-it-possible-to-configure-the-bitcoin-daemon-to-only-broadcast-unconfirmed-tra>
> , it is not possible to configure this from a configuration or
> command-line option. The source code must directly be edited. But
> since the codebase has changed greatly, the proposed solution no
> longer works.
>
> ----
>
> So basically, I know that something inside
> src/zmq/zmqnotificationinterface.cpp needs to be patched, but I'm not
> sure which function, or how to do it. Because I only need unconfirmed
> transactions to be published on ZeroMQ rawtx and not confirmed ones,
> it's one of the following functions that I need to patch for my own build:
>
> CZMQNotificationInterface::TransactionRemovedFromMempool
> void CZMQNotificationInterface::BlockDisconnected
>
> Both of these call NotifyTransaction() method which I assume fires a
> message on "rawtx" channel.
>
> In the Stack Exchange question I linked above,?Jonas Schnelli
> suggested adding an `if (!pblock)` check, but that was several years
> ago and the function he was referencing no longer exists.
>
> But I still wonder if the pblock check is still applicable in the
> present day (i.e. if it's indicating a block the transaction is inside).
>
> - Ali Sherief
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev



From willtech at live.com.au  Mon Nov 29 14:10:11 2021
From: willtech at live.com.au (LORD HIS EXCELLENCY JAMES HRMH)
Date: Mon, 29 Nov 2021 14:10:11 +0000
Subject: [bitcoin-dev] Trying to patch Core ZMQ "rawtx" topic to only
 publish unconfirmed transactions: How?
In-Reply-To: <6dbaa89c-b658-e239-9f28-5f1609b8e746@gmail.com>
References: <i1UxLDIyGhAt1KS5mHXaZ1cjhjEDd1bwVm-GZjrCRpye8z4O9zuwkw1CNa_UER12p79KknIKbT5hjjW5e0hwV0fWlB0kag6mHAF5f8K1y2k=@notatether.com>
 <6dbaa89c-b658-e239-9f28-5f1609b8e746@gmail.com>
Message-ID: <PS2P216MB108925E1A218737486323FA19D669@PS2P216MB1089.KORP216.PROD.OUTLOOK.COM>

Wasn't this already not a problem because you can check if it was confirmed? The transaction is not finalised in the mempool it is just speculation of a transaction, so it makes sense to emit when the transaction is confirmed.  Just already check..

> It appears that the ZeroMQ topic I'm listening to, "rawtx", not only
> emits a raw transaction when it appears on the mempool, but once it's
> already confirmed too.

KING JAMES HRMH
Great British Empire

Regards,
The Australian
LORD HIS EXCELLENCY JAMES HRMH (& HMRH)
of Hougun Manor & Glencoe & British Empire
MR. Damian A. James Williamson
Wills

et al.


Willtech
www.willtech.com.au
www.go-overt.com
duigco.org DUIGCO API
and other projects


m. 0487135719
f. +61261470192


This email does not constitute a general advice. Please disregard this email if misdelivered.
________________________________
From: bitcoin-dev <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of 0xB10C via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>
Sent: Monday, 29 November 2021 8:32 PM
To: Ali Sherief <ali at notatether.com>; Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>
Subject: Re: [bitcoin-dev] Trying to patch Core ZMQ "rawtx" topic to only publish unconfirmed transactions: How?

Hi Ali,

I've run into this multiple times myself. I've opened a draft PR [0]
adding a rawmempooltx publisher.

You're right. In zmq/zmqnotificationinterface.cpp the
CZMQNotificationInterface is notified about TransactionAddedToMempool.
Currently, this calls NotifyTransaction() (the publisher with the rawtx
topic) and NotifyTransactionAcceptance() (the publisher with the
sequence topic)[1]. I've added a call to a new
NotifyMempoolTransaction() function (the publisher with the rawmempooltx
topic).

I'd find a mempool transaction publisher with both the raw transaction
and transaction fee useful too. However, this requires changes to the
chain notifications in interfaces/chain.h.

[0]: https://github.com/bitcoin/bitcoin/pull/23624
[1]:
https://github.com/bitcoin/bitcoin/pull/23624/files#diff-ac4b2d3a8de2c4dd41ad9d75505ea6ce4dc87a476710a9ebee8acf9bebf5cca2L146-L148


Best,
0xB10C



On 11/26/21 5:56 PM, Ali Sherief via bitcoin-dev wrote:
>
> This has also been posted on Bitcointalk
> forum: https://bitcointalk.org/index.php?topic=5373341.msg58539261#msg58539261
> <https://bitcointalk.org/index.php?topic=5373341.msg58539261#msg58539261> I
> have republished it here hoping someone more knowledgeable can post
> some insight about this.
> ----
> It appears that the ZeroMQ topic I'm listening to, "rawtx", not only
> emits a raw transaction when it appears on the mempool, but once it's
> already confirmed too.
>
> This messes with my software, causing it to add txids, addresses, etc.
> a second time inside arrays (this means that the same transaction is
> received twice in total).
>
> Array de-duping is not a viable solution long-term (because the array
> will quickly grow to be big eventually and then this has to happen
> every time a new element is added), so I'm trying to nip the problem
> from the source by instructing Core to only publish unconfirmed
> bitcoin transactions.
>
> According to
> https://bitcoin.stackexchange.com/questions/52848/is-it-possible-to-configure-the-bitcoin-daemon-to-only-broadcast-unconfirmed-tra
> <https://bitcoin.stackexchange.com/questions/52848/is-it-possible-to-configure-the-bitcoin-daemon-to-only-broadcast-unconfirmed-tra>
> , it is not possible to configure this from a configuration or
> command-line option. The source code must directly be edited. But
> since the codebase has changed greatly, the proposed solution no
> longer works.
>
> ----
>
> So basically, I know that something inside
> src/zmq/zmqnotificationinterface.cpp needs to be patched, but I'm not
> sure which function, or how to do it. Because I only need unconfirmed
> transactions to be published on ZeroMQ rawtx and not confirmed ones,
> it's one of the following functions that I need to patch for my own build:
>
> CZMQNotificationInterface::TransactionRemovedFromMempool
> void CZMQNotificationInterface::BlockDisconnected
>
> Both of these call NotifyTransaction() method which I assume fires a
> message on "rawtx" channel.
>
> In the Stack Exchange question I linked above, Jonas Schnelli
> suggested adding an `if (!pblock)` check, but that was several years
> ago and the function he was referencing no longer exists.
>
> But I still wonder if the pblock check is still applicable in the
> present day (i.e. if it's indicating a block the transaction is inside).
>
> - Ali Sherief
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev


_______________________________________________
bitcoin-dev mailing list
bitcoin-dev at lists.linuxfoundation.org
https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20211129/aeb29320/attachment-0001.html>

From ali at notatether.com  Mon Nov 29 14:13:37 2021
From: ali at notatether.com (Ali Sherief)
Date: Mon, 29 Nov 2021 14:13:37 +0000
Subject: [bitcoin-dev] Trying to patch Core ZMQ "rawtx" topic to only
	publish unconfirmed transactions: How?
In-Reply-To: <PS2P216MB108925E1A218737486323FA19D669@PS2P216MB1089.KORP216.PROD.OUTLOOK.COM>
References: <i1UxLDIyGhAt1KS5mHXaZ1cjhjEDd1bwVm-GZjrCRpye8z4O9zuwkw1CNa_UER12p79KknIKbT5hjjW5e0hwV0fWlB0kag6mHAF5f8K1y2k=@notatether.com>
 <6dbaa89c-b658-e239-9f28-5f1609b8e746@gmail.com>
 <PS2P216MB108925E1A218737486323FA19D669@PS2P216MB1089.KORP216.PROD.OUTLOOK.COM>
Message-ID: <ZfGkvWwDamDuAztUu9wG_ViYVSJkB9Tetf7qF6ke1eMXM1fzbkwt_sb6gu3Hgw1PzWYxui01OooxdySfYNBs_E5eC5UKj6hPsW9j1XOtoAk=@notatether.com>

Theoretically that would be the desired outcome for me but this change is going to be implemented as part of a casino which must display the status of new deposits that are made, even when they are unconfirmed to now. Hence why I need to receive the unconfirmed messages.

- Ali Sherief

On Mon, Nov 29, 2021 at 5:10 PM, LORD HIS EXCELLENCY JAMES HRMH <willtech at live.com.au> wrote:

> Wasn't this already not a problem because you can check if it was confirmed? The transaction is not finalised in the mempool it is just speculation of a transaction, so it makes sense to emit when the transaction is confirmed. Just already check..
>
>> It appears that the ZeroMQ topic I'm listening to, "rawtx", not only
>> emits a raw transaction when it appears on the mempool, but once it's
>> already confirmed too.
>
> KING JAMES HRMH
> Great British Empire
>
> Regards,
> The Australian
> LORD HIS EXCELLENCY JAMES HRMH (& HMRH)
> of Hougun Manor & Glencoe & British Empire
> MR. Damian A. James Williamson
> Wills
>
> et al.
>
> Willtech
> www.willtech.com.au
> www.go-overt.com
> duigco.org DUIGCO API
> and other projects
>
> m. 0487135719
> f. +61261470192
>
> This email does not constitute a general advice. Please disregard this email if misdelivered.
> ---------------------------------------------------------------
>
> From: bitcoin-dev <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of 0xB10C via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>
> Sent: Monday, 29 November 2021 8:32 PM
> To: Ali Sherief <ali at notatether.com>; Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>
> Subject: Re: [bitcoin-dev] Trying to patch Core ZMQ "rawtx" topic to only publish unconfirmed transactions: How?
>
> Hi Ali,
>
> I've run into this multiple times myself. I've opened a draft PR [0]
> adding a rawmempooltx publisher.
>
> You're right. In zmq/zmqnotificationinterface.cpp the
> CZMQNotificationInterface is notified about TransactionAddedToMempool.
> Currently, this calls NotifyTransaction() (the publisher with the rawtx
> topic) and NotifyTransactionAcceptance() (the publisher with the
> sequence topic)[1]. I've added a call to a new
> NotifyMempoolTransaction() function (the publisher with the rawmempooltx
> topic).
>
> I'd find a mempool transaction publisher with both the raw transaction
> and transaction fee useful too. However, this requires changes to the
> chain notifications in interfaces/chain.h.
>
> [0]: https://github.com/bitcoin/bitcoin/pull/23624
> [1]:
> https://github.com/bitcoin/bitcoin/pull/23624/files#diff-ac4b2d3a8de2c4dd41ad9d75505ea6ce4dc87a476710a9ebee8acf9bebf5cca2L146-L148
>
> Best,
> 0xB10C
>
> On 11/26/21 5:56 PM, Ali Sherief via bitcoin-dev wrote:
>>
>> This has also been posted on Bitcointalk
>> forum: https://bitcointalk.org/index.php?topic=5373341.msg58539261#msg58539261
>> <https://bitcointalk.org/index.php?topic=5373341.msg58539261#msg58539261> I
>> have republished it here hoping someone more knowledgeable can post
>> some insight about this.
>> ----
>> It appears that the ZeroMQ topic I'm listening to, "rawtx", not only
>> emits a raw transaction when it appears on the mempool, but once it's
>> already confirmed too.
>>
>> This messes with my software, causing it to add txids, addresses, etc.
>> a second time inside arrays (this means that the same transaction is
>> received twice in total).
>>
>> Array de-duping is not a viable solution long-term (because the array
>> will quickly grow to be big eventually and then this has to happen
>> every time a new element is added), so I'm trying to nip the problem
>> from the source by instructing Core to only publish unconfirmed
>> bitcoin transactions.
>>
>> According to
>> https://bitcoin.stackexchange.com/questions/52848/is-it-possible-to-configure-the-bitcoin-daemon-to-only-broadcast-unconfirmed-tra
>> <https://bitcoin.stackexchange.com/questions/52848/is-it-possible-to-configure-the-bitcoin-daemon-to-only-broadcast-unconfirmed-tra>
>> , it is not possible to configure this from a configuration or
>> command-line option. The source code must directly be edited. But
>> since the codebase has changed greatly, the proposed solution no
>> longer works.
>>
>> ----
>>
>> So basically, I know that something inside
>> src/zmq/zmqnotificationinterface.cpp needs to be patched, but I'm not
>> sure which function, or how to do it. Because I only need unconfirmed
>> transactions to be published on ZeroMQ rawtx and not confirmed ones,
>> it's one of the following functions that I need to patch for my own build:
>>
>> CZMQNotificationInterface::TransactionRemovedFromMempool
>> void CZMQNotificationInterface::BlockDisconnected
>>
>> Both of these call NotifyTransaction() method which I assume fires a
>> message on "rawtx" channel.
>>
>> In the Stack Exchange question I linked above, Jonas Schnelli
>> suggested adding an `if (!pblock)` check, but that was several years
>> ago and the function he was referencing no longer exists.
>>
>> But I still wonder if the pblock check is still applicable in the
>> present day (i.e. if it's indicating a block the transaction is inside).
>>
>> - Ali Sherief
>>
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20211129/af5366c7/attachment-0001.html>

From darosior at protonmail.com  Mon Nov 29 14:27:23 2021
From: darosior at protonmail.com (darosior)
Date: Mon, 29 Nov 2021 14:27:23 +0000
Subject: [bitcoin-dev] A fee-bumping model
Message-ID: <hBx6OYA5Mv9C_anoMQ-s-9l_XNwNFPfDVmOND9pXBJEBi7qsULF3bgPGpagtqjOsKDTXu8iOTVzvOjflz-M6EfnfwVH81Cu-nnai0kakouo=@protonmail.com>

Hi everyone,

Fee-bumping is paramount to the security of many protocols building on Bitcoin, as they require the
confirmation of a transaction (which might be presigned) before the expiration of a timelock at any
point after the establishment of the contract.

The part of Revault using presigned transactions (the delegation from a large to a smaller multisig)
is no exception. We have been working on how to approach this for a while now and i'd like to share
what we have in order to open a discussion on this problem so central to what seem to be The Right
Way [0] to build on Bitcoin but which has yet to be discussed in details (at least publicly).

I'll discuss what we came up with for Revault (at least for what will be its first iteration) but my
intent with posting to the mailing list is more to frame the questions to this problem we are all
going to face rather than present the results of our study tailored to the Revault usecase.
The discussion is still pretty Revault-centric (as it's the case study) but hopefully this can help
future protocol designers and/or start a discussion around what everyone's doing for existing ones.


## 1. Reminder about Revault

The part of Revault we are interested in for this study is the delegation process, and more
specifically the application of spending policies by network monitors (watchtowers).
Coins are received on a large multisig. Participants of this large multisig create 2 [1]
transactions. The Unvault, spending a deposit UTxO, creates an output paying either to the small
multisig after a timelock or to the large multisig immediately. The Cancel, spending the Unvault
output through the non-timelocked path, creates a new deposit UTxO.
Participants regularly exchange the Cancel transaction signatures for each deposit, sharing the
signatures with the watchtowers they operate. They then optionally [2] sign the Unvault transaction
and share the signatures with the small multisig participants who can in turn use them to proceed
with a spending. Watchtowers can enforce spending policies (say, can't Unvault outside of business
hours) by having the Cancel transaction be confirmed before the expiration of the timelock.


## 2. Problem statement

For any delegated vault, ensure the confirmation of a Cancel transaction in a configured number of
blocks at any point. In so doing, minimize the overpayments and the UTxO set footprint. Overpayments
increase the burden on the watchtower operator by increasing the required frequency of refills of the
fee-bumping wallet, which is already the worst user experience. You are likely to manage a number of
UTxOs with your number of vaults, which comes at a cost for you as well as everyone running a full
node.

Note that this assumes miners are economically rationale, are incentivized by *public* fees and that
you have a way to propagate your fee-bumped transaction to them. We also don't consider the block
space bounds.

In the previous paragraph and the following text, "vault" can generally be replaced with "offchain
contract".


## 3. With presigned transactions

As you all know, the first difficulty is to get to be able to unilaterally enforce your contract
onchain. That is, any participant must be able to unilaterally bump the fees of a transaction even
if it was co-signed by other participants.

For Revault we can afford to introduce malleability in the Cancel transaction since there is no
second-stage transaction depending on its txid. Therefore it is pre-signed with ANYONECANPAY. We
can't use ANYONECANPAY|SINGLE since it would open a pinning vector [3]. Note how we can't leverage
the carve out rule, and neither can any other more-than-two-parties contract.
This has a significant implication for the rest, as we are entirely burning fee-bumping UTxOs.

This opens up a pinning vector, or at least a significant nuisance: any other party can largely
increase the absolute fee without increasing the feerate, leveraging the RBF rules to prevent you
from replacing it without paying an insane fee. And you might not see it in your own mempool and
could only suppose it's happening by receiving non-full blocks or with transactions paying a lower
feerate.
Unfortunately i know of no other primitive that can be used by multi-party (i mean, >2) presigned
transactions protocols for fee-bumping that aren't (more) vulnerable to pinning.


## 4. We are still betting on future feerate

The problem is still missing one more constraint. "Ensuring confirmation at any time" involves ensuring
confirmation at *any* feerate, which you *cannot* do. So what's the limit? In theory you should be ready
to burn as much in fees as the value of the funds you want to get out of the contract. So... For us
it'd mean keeping for each vault an equivalent amount of funds sitting there on the watchtower's hot
wallet. For Lightning, it'd mean keeping an equivalent amount of funds as the sum of all your
channels balances sitting there unallocated "just in case". This is not reasonable.

So you need to keep a maximum feerate, above which you won't be able to ensure the enforcement of
all your contracts onchain at the same time. We call that the "reserve feerate" and you can have
different strategies for choosing it, for instance:
- The 85th percentile over the last year of transactions feerates
- The maximum historical feerate
- The maximum historical feerate adjusted in dollars (makes more sense but introduces a (set of?)
  trusted oracle(s) in a security-critical component)
- Picking a random high feerate (why not? It's an arbitrary assumption anyways)

Therefore, even if we don't have to bet on the broadcast-time feerate market at signing time anymore
(since we can unilaterally bump), we still need some kind of prediction in preparation of making
funds available to bump the fees at broadcast time.
Apart from judging that 500sat/vb is probably more reasonable than 10sat/vbyte, this unfortunately
sounds pretty much crystal-ball-driven.

We currently use the maximum of the 95th percentiles over 90-days windows over historical block chain
feerates. [4]


## 5. How much funds does my watchtower need?

That's what we call the "reserve". Depending on your reserve feerate strategy it might vary over
time. This is easier to reason about with a per-contract reserve. For Revault it's pretty
straightforward since the Cancel transaction size is static: `reserve_feerate * cancel_size`. For
other protocols with dynamic transaction sizes (or even packages of transactions) it's less so. For
your Lightning channel you would probably take the maximum size of your commitment transaction
according to your HTLC exposure settings + the size of as many `htlc_success` transaction?

Then you either have your software or your user guesstimate how many offchain contracts the
watchtower will have to watch, time that by the per-contract reserve and refill this amount (plus
some slack in practice). Once again, a UX tradeoff (not even mentioning the guesstimation UX):
overestimating leads to too many unallocated funds sitting on a hot wallet, underestimating means
(at best) inability to participate in new contracts or being "at risk" (not being able to enforce
all your contracts onchain at your reserve feerate) before a new refill.

For vaults you likely have large-value UTxOs and small transactions (the Cancel is one-in one-out in
Revault). For some other applications with large transactions and lower-value UTxOs on average it's
likely that only part of the offchain contracts might be enforceable at a reasonable feerate. Is it
reasonable?


## 6. UTxO pool layout

Now that you somehow managed to settle on a refill amount, how are you going to use these funds?
Also, you'll need to manage your pool across time (consolidating small coins, and probably fanning
out large ones).

You could keep a single large UTxO and peel it as you need to sponsor transactions. But this means
that you need to create a coin of a specific value according to your need at the current feerate
estimation, hope to have it confirmed in a few blocks (at least for now! [5]), and hope that the
value won't be obsolete by the time it confirmed. Also, you'd have to do that for any number of
Cancel, chaining feebump coin creation transactions off the change of the previous ones or replacing
them with more outputs. Both seem to become really un-manageable (and expensive) in many edge-cases,
shortening the time you have to confirm the actual Cancel transaction and creating uncertainty about
the reserve (how much is my just-in-time fanout going to cost me in fees that i need to refill in
advance on my watchtower wallet?).
This is less of a concern for protocols using CPFP to sponsor transactions, but they rely on a
policy rule specific to 2-parties contracts.

Therefore for Revault we fan-out the coins per-vault in advance. We do so at refill time so the
refiller can give an excess to pay for the fees of the fanout transaction (which is reasonable since
it will occur just after the refilling transaction confirms). When the watchtower is asked to watch
for a new delegated vault it will allocate coins from the pool of fanned-out UTxOs to it (failing
that, it would refuse the delegation).
What is a good distribution of UTxOs amounts per vault? We want to minimize the number of coins,
still have coins small enough to not overpay (remember, we can't have change) and be able to bump a
Cancel up to the reserve feerate using these coins. The two latter constraints are directly in
contradiction as the minimal value of a coin usable at the reserve feerate (paying for its own input
fee + bumping the feerate by, say, 5sat/vb) is already pretty high. Therefore we decided to go with
two distributions per vault. The "reserve distribution" alone ensures that we can bump up to the
reserve feerate and is usable for high feerates. The "bonus distribution" is not, but contains
smaller coins useful to prevent overpayments during low and medium fee periods (which is most of the
time).
Both distributions are based on a basic geometric suite [6]. Each value is half the previous one.
This exponentially decreases the value, limiting the number of coins. But this also allows for
pretty small coins to exist and each coin's value is equal to the sum of the smaller coins,
or smaller by at most the value of the smallest coin. Therefore bounding the maximum overpayment to
the smallest coin's value [7].

For the management of the UTxO pool across time we merged the consolidation with the fanout. When
fanning out a refilled UTxO, we scan the pool for coins that need to be consolidated according to a
heuristic. An instance of a heuristic is "the coin isn't allocated and would not have been able to
increase the fee at the median feerate over the past 90 days of blocks".
We had this assumption that feerate would tend to go up with time and therefore discarded having to
split some UTxOs from the pool. We however overlooked that a large increase in the exchange price of
BTC as we've seen during the past year could invalidate this assumption and that should arguably be
reconsidered.


## 7. Bumping and re-bumping

First of all, when to fee-bump? At fixed time intervals? At each block connection? It sounds like,
given a large enough timelock, you could try to greed by "trying your luck" at a lower feerate and
only re-bumping every N blocks. You would then start aggressively bumping at every block after M
blocks have passed. But that's actually a bet (in disguised?) that the next block feerate in M blocks
will be lower than the current one. In the absence of any predictive model it is more reasonable to
just start being aggressive immediately.
You probably want to base your estimates on `estimatesmartfee` and as a consequence you would re-bump
(if needed )after each block connection, when your estimates get updated and you notice your
transaction was not included in the block.

In the event that you notice a consequent portion of the block is filled with transactions paying
less than your own, you might want to start panicking and bump your transaction fees by a certain
percentage with no consideration for your fee estimator. You might skew miners incentives in doing
so: if you increase the fees by a factor of N, any miner with a fraction larger than 1/N of the
network hashrate now has an incentive to censor your transaction at first to get you to panic. Also
note this can happen if you want to pay the absolute fees for the 'pinning' attack mentioned in
section #2, and that might actually incentivize miners to perform it themselves..

The gist is that the most effective way to bump and rebump (RBF the Cancel tx) seems to just be to
consider the `estimatesmartfee 2 CONSERVATIVE` feerate at every block your tx isn't included in, and
to RBF it if the feerate is higher.
In addition, we fallback to a block chain based estimation when estimates aren't available (eg if
the user stopped their WT for say a hour and we come back up): we use the 85th percentile over the
feerates in the last 6 blocks. Sure, miners can try to have an influence on that by stuffing their
blocks with large fee self-paying transactions, but they would need to:
1. Be sure to catch a significant portion of the 6 blocks (at least 2, actually)
2. Give up on 25% of the highest fee-paying transactions (assuming they got the 6 blocks, it's
   proportionally larger and incertain as they get less of them)
3. Hope that our estimator will fail and we need to fall back to the chain-based estimation


## 8. Our study

We essentially replayed the historical data with different deployment configurations (number of
participants and timelock) and probability of an event occurring (event being say an Unvault, an
invalid Unvault, a new delegation, ..). We then observed different metrics such as the time at risk
(when we can't enforce all our contracts at the reserve feerate at the same time), or the
operational cost.
We got the historical fee estimates data from Statoshi [9], Txstats [10] and the historical chain
data from Riccardo Casatta's `blocks_iterator` [11]. Thanks!

The (research-quality..) code can be found at https://github.com/revault/research under the section
"Fee bumping". Again it's very Revault specific, but at least the data can probably be reused for
studying other protocols.


## 9. Insurances

Of course, given it's all hacks and workarounds and there is no good answer to "what is a reasonable
feerate up to which we need to make contracts enforceable onchain?", there is definitely room for an
insurance market. But this enters the realm of opinions. Although i do have some (having discussed
this topic for the past years with different people), i would like to keep this post focused on the
technical aspects of this problem.



[0] As far as i can tell, having offchain contracts be enforceable onchain by confirming a
transaction before the expiration of a timelock is a widely agreed-upon approach. And i don't think
we can opt for any other fundamentally different one, as you want to know you can claim back your
coins from a contract after a deadline before taking part in it.

[1] The Real Revault (tm) involves more transactions, but for the sake of conciseness i only
detailed a minimum instance of the problem.

[2] Only presigning part of the Unvault transactions allows to only delegate part of the coins,
which can be abstracted as "delegate x% of your stash" in the user interface.

[3] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-May/017835.html

[4] https://github.com/revault/research/blob/1df953813708287c32a15e771ba74957ec44f354/feebumping/model/statemachine.py#L323-L329

[5] https://github.com/bitcoin/bitcoin/pull/23121

[6] https://github.com/revault/research/blob/1df953813708287c32a15e771ba74957ec44f354/feebumping/model/statemachine.py#L494-L507

[7] Of course this assumes a combinatorial coin selection, but i believe it's ok given we limit the
number of coins beforehand.

[8] Although there is the argument to outbid a censorship, anyone censoring you isn't necessarily a
miner.

[9] https://www.statoshi.info/

[10] https://www.statoshi.info/

[11] https://github.com/RCasatta/blocks_iterator

From antoine.riard at gmail.com  Tue Nov 30 01:43:49 2021
From: antoine.riard at gmail.com (Antoine Riard)
Date: Mon, 29 Nov 2021 20:43:49 -0500
Subject: [bitcoin-dev] A fee-bumping model
In-Reply-To: <hBx6OYA5Mv9C_anoMQ-s-9l_XNwNFPfDVmOND9pXBJEBi7qsULF3bgPGpagtqjOsKDTXu8iOTVzvOjflz-M6EfnfwVH81Cu-nnai0kakouo=@protonmail.com>
References: <hBx6OYA5Mv9C_anoMQ-s-9l_XNwNFPfDVmOND9pXBJEBi7qsULF3bgPGpagtqjOsKDTXu8iOTVzvOjflz-M6EfnfwVH81Cu-nnai0kakouo=@protonmail.com>
Message-ID: <CALZpt+F6h8uLw48e4FRrkjPe2ci6Uqy-o9H=++hu5fx7+bxOZw@mail.gmail.com>

Hi Darosior,

Nice work, few thoughts binding further your model for Lightning.

> For any delegated vault, ensure the confirmation of a Cancel transaction
in a configured number of
> blocks at any point. In so doing, minimize the overpayments and the UTxO
set footprint. Overpayments
> increase the burden on the watchtower operator by increasing the required
frequency of refills of the
> fee-bumping wallet, which is already the worst user experience. You are
likely to manage a number of
> UTxOs with your number of vaults, which comes at a cost for you as well
as everyone running a full
> node.

For any opened channel, ensure the confirmation of a Commitment transaction
and the children HTLC-Success/HTLC-Timeout transactions. Note, in the
Lightning security game you have to consider (at least) 4 types of players
moves and incentives : your node, your channel counterparties, the miners,
the crowd of bitcoin users. The number of the last type of players is
unknown from your node, however it should not be forgotten you're in
competition for block space, therefore their block demands bids should be
anticipated and reacted to in consequence. With that remark in mind,
implications for your LN fee-bumping strategy will be raised afterwards.

For a LN service provider, on-chain overpayments are bearing on your
operational costs, thus downgrading your economic competitiveness. For the
average LN user, overpayment might price out outside a LN non-custodial
deployment, as you don't have the minimal security budget to be on your own.

> This opens up a pinning vector, or at least a significant nuisance: any
other party can largely
> increase the absolute fee without increasing the feerate, leveraging the
RBF rules to prevent you
> from replacing it without paying an insane fee. And you might not see it
in your own mempool and
> could only suppose it's happening by receiving non-full blocks or with
transactions paying a lower
> feerate.

Same issue with Lightning, we can be pinned today on the basis of
replace-by-fee rule 3. We can be also blinded by network mempool
partitions, a pinning counterparty can segregate all the full-nodes  in as
many subsets by broadcasting a revoked Commitment transaction different for
each. For Revault, I think you can also do unlimited partitions by mutating
the ANYONECANPAY-input of the Cancel.

That said, if you have a distributed towers deployment, spread across the
p2p network topology, and they can't be clustered together through
cross-layers or intra-layer heuristics, you should be able to reliably
observe such partitions. I think such distributed monitors are deployed by
few L1 merchants accepting 0-conf to detect naive double-spend.

> Unfortunately i know of no other primitive that can be used by
multi-party (i mean, >2) presigned
> transactions protocols for fee-bumping that aren't (more) vulnerable to
pinning.

Have we already discussed a fee-bumping "shared cache", a CPFP variation ?
Strawman idea: Alice and Bob commit collateral inputs to a separate UTXO
from the main "offchain contract" one. This UTXO is locked by a multi-sig.
For any Commitment transaction pre-signed, also counter-sign a CPFP with
top mempool feerate included, spending a Commitment anchor output and the
shared-cache UTXO. If the fees spike,  you can re-sign a high-feerate CPFP,
assuming interactivity. As the CPFP is counter-signed by everyone, the
outputs can be CSV-1 encumbered to prevent pinnings. If the share-cache is
feeded at parity, there shouldn't be an incentive to waste or maliciously
inflate the feerate. I think this solution can be easily generalized to
more than 2 counterparties by using a multi-signature scheme. Big issue, if
the feerate is short due to fee spikes and you need to re-sign a
higher-feerate CPFP, you're trusting your counterparty to interact, though
arguably not worse than the current update fee mechanism.

> For Lightning, it'd mean keeping an equivalent amount of funds as the sum
of all your
channels balances sitting there unallocated "just in case". This is not
reasonable.

Agree, game-theory wise, you would like to keep a full fee-bumping reserve,
ready to burn as much in fees as the contested HTLC value, as it's the
maximum gain of your counterparty. Though perfect equilibrium is hard to
achieve because your malicious counterparty might have an edge pushing you
to broadcast your Commitment first by witholding HTLC resolution.

Fractional fee-bumping reserves are much more realistic to expect in the LN
network. Lower fee-bumping reserve, higher liquidity deployed, in theory
higher routing fees. By observing historical feerates, average offchain
balances at risk and routing fees expected gains, you should be able to
discover an equilibrium where higher levels of reserve aren't worth the
opportunity cost. I guess this  equilibrium could be your LN fee-bumping
reserve max feerate.

Note, I think the LN approach is a bit different from what suits a custody
protocol like Revault,  as you compute a direct return of the frozen
fee-bumping liquidity. With Revault, if you have numerous bitcoins
protected, it's might be more interesting to adopt a "buy the mempool,
stupid" strategy than risking fund safety for few percentages of interest
returns.

> This is easier to reason about with a per-contract reserve.

For Lightning, this per-channel approach is safer too, as one Commitment
transaction pinned or jammed could affect the confirmation odds of your
remaining LN Commitment transactions.

> For your Lightning channel you would probably take the maximum size of
your commitment transaction
> according to your HTLC exposure settings + the size of as many
`htlc_success` transactions?

Yes, I guess it's your holder's `max_accepted_htcls` * `HTLC-Success
weight` + counterparty's `max_accepted_htlcs` * `HTLC-Timeout weight`
Better to adopt this worst-case as the base transaction weight to fee-bump,
as currently we can't dynamically update channel policies.

> For some other applications with large transactions and lower-value UTxOs
on average it's
> likely that only part of the offchain contracts might be enforceable at a
reasonable feerate. Is it
> reasonable?

This is where the "anticipate the crowd of bitcoin users move" point can be
laid out. As the crowd of bitcoin users' fee-bumping reserves are
ultimately unknown from your node knowledge, you should be ready to be a
bit more conservative than the vanilla fee-bumping strategies shipped by
default. In case of massive mempool congestion, your additional
conservatism might get your time-sensitive transactions and game on the
crowd of bitcoin users. First Problem: if all offchain bitcoin software
adopt that strategy we might inflate the worst-case feerate rate at the
benefit of the miners, without holistically improving block throughput.
Second problem : your class of offchain bitcoin softwares might have
ridiculous fee-bumping reserve compared
to other classes of offchain bitcoin softwares (Revault > Lightning) and
just be priced out bydesign in case of mempool congestion. Third problem :
as the number of offchain bitcoin applications should go up with time, your
fee-bumping reserve levels based from historical data might be always late
by one "bank-run" scenario.

For Lightning, if you're short in fee-bumping reserves you might still do
preemptive channel closures, either cooperatively or unilaterally and get
back the off-chain liquidity to protect the more economically interesting
channels. Though again, that kind of automatic behavior might be compelling
at the individual node-level, but make the mempol congestion worse
holistically.

> First of all, when to fee-bump? At fixed time intervals? At each block
connection?

In case of massive mempool congestion, you might try to front-run the crowd
of bitcoin users relying on block connections for fee-bumping, and thus
start your fee-bumping as soon as you observe feerate groups fluctuations
in your local mempool(s).

Also you might proceed your fee-bumping ticks on a local clock instead of
block connections in case of time-dilation or deeper eclipse attacks of
your local node. Your view of the chain might be compromised but not your
ability to broadcast transactions thanks to emergency channels (in the
non-LN sense...though in fact quid of txn wrapped in onions ?) of
communication.

> You might skew miners incentives in doing
> so: if you increase the fees by a factor of N, any miner with a fraction
larger than 1/N of the
> network hashrate now has an incentive to censor your transaction at first
to get you to panic.

Yes I think miner-harvesting attacks should be weighed carefully in the
design of offchain contracts fee-bumping strategies, at least in the future
when the mining reward exhausts further. I wonder if a more refined formula
should encompass the miner loss for empty blocks and ensure this loss stays
more substantial than the fees increased. So something like computing "for
X censored blocks, the Y average loss should be superior to the Z
fee-bumping increase".

> Of course, given it's all hacks and workarounds and there is no good
answer to "what is a reasonable
> feerate up to which we need to make contracts enforceable onchain?",
there is definitely room for an
> insurance market.

Yes, stay open the question on how you enforce this block insurance market.
Reputation, which might be to avoid due to the latent centralization
effect, might be hard to stack and audit reliably for an emergency
mechanism running, hopefully, once in a halvening period. Maybe maybe some
cryptographic or economically based mechanism on slashing or swaps could be
found...

Antoine

Le lun. 29 nov. 2021 ? 09:34, darosior via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> a ?crit :

> Hi everyone,
>
> Fee-bumping is paramount to the security of many protocols building on
> Bitcoin, as they require the
> confirmation of a transaction (which might be presigned) before the
> expiration of a timelock at any
> point after the establishment of the contract.
>
> The part of Revault using presigned transactions (the delegation from a
> large to a smaller multisig)
> is no exception. We have been working on how to approach this for a while
> now and i'd like to share
> what we have in order to open a discussion on this problem so central to
> what seem to be The Right
> Way [0] to build on Bitcoin but which has yet to be discussed in details
> (at least publicly).
>
> I'll discuss what we came up with for Revault (at least for what will be
> its first iteration) but my
> intent with posting to the mailing list is more to frame the questions to
> this problem we are all
> going to face rather than present the results of our study tailored to the
> Revault usecase.
> The discussion is still pretty Revault-centric (as it's the case study)
> but hopefully this can help
> future protocol designers and/or start a discussion around what everyone's
> doing for existing ones.
>
>
> ## 1. Reminder about Revault
>
> The part of Revault we are interested in for this study is the delegation
> process, and more
> specifically the application of spending policies by network monitors
> (watchtowers).
> Coins are received on a large multisig. Participants of this large
> multisig create 2 [1]
> transactions. The Unvault, spending a deposit UTxO, creates an output
> paying either to the small
> multisig after a timelock or to the large multisig immediately. The
> Cancel, spending the Unvault
> output through the non-timelocked path, creates a new deposit UTxO.
> Participants regularly exchange the Cancel transaction signatures for each
> deposit, sharing the
> signatures with the watchtowers they operate. They then optionally [2]
> sign the Unvault transaction
> and share the signatures with the small multisig participants who can in
> turn use them to proceed
> with a spending. Watchtowers can enforce spending policies (say, can't
> Unvault outside of business
> hours) by having the Cancel transaction be confirmed before the expiration
> of the timelock.
>
>
> ## 2. Problem statement
>
> For any delegated vault, ensure the confirmation of a Cancel transaction
> in a configured number of
> blocks at any point. In so doing, minimize the overpayments and the UTxO
> set footprint. Overpayments
> increase the burden on the watchtower operator by increasing the required
> frequency of refills of the
> fee-bumping wallet, which is already the worst user experience. You are
> likely to manage a number of
> UTxOs with your number of vaults, which comes at a cost for you as well as
> everyone running a full
> node.
>
> Note that this assumes miners are economically rationale, are incentivized
> by *public* fees and that
> you have a way to propagate your fee-bumped transaction to them. We also
> don't consider the block
> space bounds.
>
> In the previous paragraph and the following text, "vault" can generally be
> replaced with "offchain
> contract".
>
>
> ## 3. With presigned transactions
>
> As you all know, the first difficulty is to get to be able to unilaterally
> enforce your contract
> onchain. That is, any participant must be able to unilaterally bump the
> fees of a transaction even
> if it was co-signed by other participants.
>
> For Revault we can afford to introduce malleability in the Cancel
> transaction since there is no
> second-stage transaction depending on its txid. Therefore it is pre-signed
> with ANYONECANPAY. We
> can't use ANYONECANPAY|SINGLE since it would open a pinning vector [3].
> Note how we can't leverage
> the carve out rule, and neither can any other more-than-two-parties
> contract.
> This has a significant implication for the rest, as we are entirely
> burning fee-bumping UTxOs.
>
> This opens up a pinning vector, or at least a significant nuisance: any
> other party can largely
> increase the absolute fee without increasing the feerate, leveraging the
> RBF rules to prevent you
> from replacing it without paying an insane fee. And you might not see it
> in your own mempool and
> could only suppose it's happening by receiving non-full blocks or with
> transactions paying a lower
> feerate.
> Unfortunately i know of no other primitive that can be used by multi-party
> (i mean, >2) presigned
> transactions protocols for fee-bumping that aren't (more) vulnerable to
> pinning.
>
>
> ## 4. We are still betting on future feerate
>
> The problem is still missing one more constraint. "Ensuring confirmation
> at any time" involves ensuring
> confirmation at *any* feerate, which you *cannot* do. So what's the limit?
> In theory you should be ready
> to burn as much in fees as the value of the funds you want to get out of
> the contract. So... For us
> it'd mean keeping for each vault an equivalent amount of funds sitting
> there on the watchtower's hot
> wallet. For Lightning, it'd mean keeping an equivalent amount of funds as
> the sum of all your
> channels balances sitting there unallocated "just in case". This is not
> reasonable.
>
> So you need to keep a maximum feerate, above which you won't be able to
> ensure the enforcement of
> all your contracts onchain at the same time. We call that the "reserve
> feerate" and you can have
> different strategies for choosing it, for instance:
> - The 85th percentile over the last year of transactions feerates
> - The maximum historical feerate
> - The maximum historical feerate adjusted in dollars (makes more sense but
> introduces a (set of?)
>   trusted oracle(s) in a security-critical component)
> - Picking a random high feerate (why not? It's an arbitrary assumption
> anyways)
>
> Therefore, even if we don't have to bet on the broadcast-time feerate
> market at signing time anymore
> (since we can unilaterally bump), we still need some kind of prediction in
> preparation of making
> funds available to bump the fees at broadcast time.
> Apart from judging that 500sat/vb is probably more reasonable than
> 10sat/vbyte, this unfortunately
> sounds pretty much crystal-ball-driven.
>
> We currently use the maximum of the 95th percentiles over 90-days windows
> over historical block chain
> feerates. [4]
>
>
> ## 5. How much funds does my watchtower need?
>
> That's what we call the "reserve". Depending on your reserve feerate
> strategy it might vary over
> time. This is easier to reason about with a per-contract reserve. For
> Revault it's pretty
> straightforward since the Cancel transaction size is static:
> `reserve_feerate * cancel_size`. For
> other protocols with dynamic transaction sizes (or even packages of
> transactions) it's less so. For
> your Lightning channel you would probably take the maximum size of your
> commitment transaction
> according to your HTLC exposure settings + the size of as many
> `htlc_success` transaction?
>
> Then you either have your software or your user guesstimate how many
> offchain contracts the
> watchtower will have to watch, time that by the per-contract reserve and
> refill this amount (plus
> some slack in practice). Once again, a UX tradeoff (not even mentioning
> the guesstimation UX):
> overestimating leads to too many unallocated funds sitting on a hot
> wallet, underestimating means
> (at best) inability to participate in new contracts or being "at risk"
> (not being able to enforce
> all your contracts onchain at your reserve feerate) before a new refill.
>
> For vaults you likely have large-value UTxOs and small transactions (the
> Cancel is one-in one-out in
> Revault). For some other applications with large transactions and
> lower-value UTxOs on average it's
> likely that only part of the offchain contracts might be enforceable at a
> reasonable feerate. Is it
> reasonable?
>
>
> ## 6. UTxO pool layout
>
> Now that you somehow managed to settle on a refill amount, how are you
> going to use these funds?
> Also, you'll need to manage your pool across time (consolidating small
> coins, and probably fanning
> out large ones).
>
> You could keep a single large UTxO and peel it as you need to sponsor
> transactions. But this means
> that you need to create a coin of a specific value according to your need
> at the current feerate
> estimation, hope to have it confirmed in a few blocks (at least for now!
> [5]), and hope that the
> value won't be obsolete by the time it confirmed. Also, you'd have to do
> that for any number of
> Cancel, chaining feebump coin creation transactions off the change of the
> previous ones or replacing
> them with more outputs. Both seem to become really un-manageable (and
> expensive) in many edge-cases,
> shortening the time you have to confirm the actual Cancel transaction and
> creating uncertainty about
> the reserve (how much is my just-in-time fanout going to cost me in fees
> that i need to refill in
> advance on my watchtower wallet?).
> This is less of a concern for protocols using CPFP to sponsor
> transactions, but they rely on a
> policy rule specific to 2-parties contracts.
>
> Therefore for Revault we fan-out the coins per-vault in advance. We do so
> at refill time so the
> refiller can give an excess to pay for the fees of the fanout transaction
> (which is reasonable since
> it will occur just after the refilling transaction confirms). When the
> watchtower is asked to watch
> for a new delegated vault it will allocate coins from the pool of
> fanned-out UTxOs to it (failing
> that, it would refuse the delegation).
> What is a good distribution of UTxOs amounts per vault? We want to
> minimize the number of coins,
> still have coins small enough to not overpay (remember, we can't have
> change) and be able to bump a
> Cancel up to the reserve feerate using these coins. The two latter
> constraints are directly in
> contradiction as the minimal value of a coin usable at the reserve feerate
> (paying for its own input
> fee + bumping the feerate by, say, 5sat/vb) is already pretty high.
> Therefore we decided to go with
> two distributions per vault. The "reserve distribution" alone ensures that
> we can bump up to the
> reserve feerate and is usable for high feerates. The "bonus distribution"
> is not, but contains
> smaller coins useful to prevent overpayments during low and medium fee
> periods (which is most of the
> time).
> Both distributions are based on a basic geometric suite [6]. Each value is
> half the previous one.
> This exponentially decreases the value, limiting the number of coins. But
> this also allows for
> pretty small coins to exist and each coin's value is equal to the sum of
> the smaller coins,
> or smaller by at most the value of the smallest coin. Therefore bounding
> the maximum overpayment to
> the smallest coin's value [7].
>
> For the management of the UTxO pool across time we merged the
> consolidation with the fanout. When
> fanning out a refilled UTxO, we scan the pool for coins that need to be
> consolidated according to a
> heuristic. An instance of a heuristic is "the coin isn't allocated and
> would not have been able to
> increase the fee at the median feerate over the past 90 days of blocks".
> We had this assumption that feerate would tend to go up with time and
> therefore discarded having to
> split some UTxOs from the pool. We however overlooked that a large
> increase in the exchange price of
> BTC as we've seen during the past year could invalidate this assumption
> and that should arguably be
> reconsidered.
>
>
> ## 7. Bumping and re-bumping
>
> First of all, when to fee-bump? At fixed time intervals? At each block
> connection? It sounds like,
> given a large enough timelock, you could try to greed by "trying your
> luck" at a lower feerate and
> only re-bumping every N blocks. You would then start aggressively bumping
> at every block after M
> blocks have passed. But that's actually a bet (in disguised?) that the
> next block feerate in M blocks
> will be lower than the current one. In the absence of any predictive model
> it is more reasonable to
> just start being aggressive immediately.
> You probably want to base your estimates on `estimatesmartfee` and as a
> consequence you would re-bump
> (if needed )after each block connection, when your estimates get updated
> and you notice your
> transaction was not included in the block.
>
> In the event that you notice a consequent portion of the block is filled
> with transactions paying
> less than your own, you might want to start panicking and bump your
> transaction fees by a certain
> percentage with no consideration for your fee estimator. You might skew
> miners incentives in doing
> so: if you increase the fees by a factor of N, any miner with a fraction
> larger than 1/N of the
> network hashrate now has an incentive to censor your transaction at first
> to get you to panic. Also
> note this can happen if you want to pay the absolute fees for the
> 'pinning' attack mentioned in
> section #2, and that might actually incentivize miners to perform it
> themselves..
>
> The gist is that the most effective way to bump and rebump (RBF the Cancel
> tx) seems to just be to
> consider the `estimatesmartfee 2 CONSERVATIVE` feerate at every block your
> tx isn't included in, and
> to RBF it if the feerate is higher.
> In addition, we fallback to a block chain based estimation when estimates
> aren't available (eg if
> the user stopped their WT for say a hour and we come back up): we use the
> 85th percentile over the
> feerates in the last 6 blocks. Sure, miners can try to have an influence
> on that by stuffing their
> blocks with large fee self-paying transactions, but they would need to:
> 1. Be sure to catch a significant portion of the 6 blocks (at least 2,
> actually)
> 2. Give up on 25% of the highest fee-paying transactions (assuming they
> got the 6 blocks, it's
>    proportionally larger and incertain as they get less of them)
> 3. Hope that our estimator will fail and we need to fall back to the
> chain-based estimation
>
>
> ## 8. Our study
>
> We essentially replayed the historical data with different deployment
> configurations (number of
> participants and timelock) and probability of an event occurring (event
> being say an Unvault, an
> invalid Unvault, a new delegation, ..). We then observed different metrics
> such as the time at risk
> (when we can't enforce all our contracts at the reserve feerate at the
> same time), or the
> operational cost.
> We got the historical fee estimates data from Statoshi [9], Txstats [10]
> and the historical chain
> data from Riccardo Casatta's `blocks_iterator` [11]. Thanks!
>
> The (research-quality..) code can be found at
> https://github.com/revault/research under the section
> "Fee bumping". Again it's very Revault specific, but at least the data can
> probably be reused for
> studying other protocols.
>
>
> ## 9. Insurances
>
> Of course, given it's all hacks and workarounds and there is no good
> answer to "what is a reasonable
> feerate up to which we need to make contracts enforceable onchain?", there
> is definitely room for an
> insurance market. But this enters the realm of opinions. Although i do
> have some (having discussed
> this topic for the past years with different people), i would like to keep
> this post focused on the
> technical aspects of this problem.
>
>
>
> [0] As far as i can tell, having offchain contracts be enforceable onchain
> by confirming a
> transaction before the expiration of a timelock is a widely agreed-upon
> approach. And i don't think
> we can opt for any other fundamentally different one, as you want to know
> you can claim back your
> coins from a contract after a deadline before taking part in it.
>
> [1] The Real Revault (tm) involves more transactions, but for the sake of
> conciseness i only
> detailed a minimum instance of the problem.
>
> [2] Only presigning part of the Unvault transactions allows to only
> delegate part of the coins,
> which can be abstracted as "delegate x% of your stash" in the user
> interface.
>
> [3]
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-May/017835.html
>
> [4]
> https://github.com/revault/research/blob/1df953813708287c32a15e771ba74957ec44f354/feebumping/model/statemachine.py#L323-L329
>
> [5] https://github.com/bitcoin/bitcoin/pull/23121
>
> [6]
> https://github.com/revault/research/blob/1df953813708287c32a15e771ba74957ec44f354/feebumping/model/statemachine.py#L494-L507
>
> [7] Of course this assumes a combinatorial coin selection, but i believe
> it's ok given we limit the
> number of coins beforehand.
>
> [8] Although there is the argument to outbid a censorship, anyone
> censoring you isn't necessarily a
> miner.
>
> [9] https://www.statoshi.info/
>
> [10] https://www.statoshi.info/
>
> [11] https://github.com/RCasatta/blocks_iterator
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20211129/883846a6/attachment-0001.html>

From prayank at tutanota.de  Tue Nov 30 01:47:31 2021
From: prayank at tutanota.de (Prayank)
Date: Tue, 30 Nov 2021 02:47:31 +0100 (CET)
Subject: [bitcoin-dev] A fee-bumping model
Message-ID: <MpiWcV7--3-2@tutanota.de>

Good morning darosior,

Subject of the email looks interesting and I have few comments on the things shared:

> The part of Revault we are interested in for this study is the delegation process, and more specifically the application of spending policies by network monitors (watchtowers). Participants regularly exchange the Cancel transaction signatures for each deposit, sharing the signatures with the watchtowers they operate.Watchtowers can enforce spending policies (say, can't Unvault outside of business hours) by having the Cancel transaction be confirmed before the expiration of the timelock.

What are the privacy issues associated with such watchtowers?

> ## 4. We are still betting on future feerate
The problem is still missing one more constraint. "Ensuring confirmation at any time" involves ensuring confirmation at *any* feerate, which you *cannot* do.

Agree

> historical feerate: We currently use the maximum of the 95th percentiles over 90-days windows over historical block chain
feerates.

Disagree that fee rates used in past should matter.

> Apart from judging that 500sat/vb is probably more reasonable than 10sat/vbyte, this unfortunately sounds pretty much crystal-ball-driven.

Agree

> ## 7. Bumping and re-bumping
First of all, when to fee-bump? At fixed time intervals? At each block connection? It sounds like, given a large enough timelock, you could try to greed by "trying your luck" at a lower feerate and only re-bumping every N blocks. You would then start aggressively bumping at every block after M blocks have passed.

Agree

> You probably want to base your estimates on `estimatesmartfee`

Disagree. `estimatesmartfee` RPC has few issues: https://github.com/bitcoin/bitcoin/pull/22722#issuecomment-901907447

> ## 9. Insurances
there is definitely room for an insurance market.

Agree. I think its possible using discreet log contracts with some trust assumptions and use of multi oracles.

I had one idea about creating insurance project for LGBTQ community in India as they don't have enough options like others. Have shared the details here:?https://gist.github.com/prayank23/f30ab1ab68bffe6bcb2ceacec599cd36 
As final point, I guess you already know about this presentation by Jack Mallers in which he has described how we could create derivatives for users to hedge fees: https://youtu.be/rBCG0btUlTw

-- 
Prayank

A3B1 E430 2298 178F
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20211130/b6554626/attachment.html>

From darosior at protonmail.com  Tue Nov 30 15:19:42 2021
From: darosior at protonmail.com (darosior)
Date: Tue, 30 Nov 2021 15:19:42 +0000
Subject: [bitcoin-dev] A fee-bumping model
In-Reply-To: <CALZpt+F6h8uLw48e4FRrkjPe2ci6Uqy-o9H=++hu5fx7+bxOZw@mail.gmail.com>
References: <hBx6OYA5Mv9C_anoMQ-s-9l_XNwNFPfDVmOND9pXBJEBi7qsULF3bgPGpagtqjOsKDTXu8iOTVzvOjflz-M6EfnfwVH81Cu-nnai0kakouo=@protonmail.com>
 <CALZpt+F6h8uLw48e4FRrkjPe2ci6Uqy-o9H=++hu5fx7+bxOZw@mail.gmail.com>
Message-ID: <8wtAeG1p6qyiOWW0pIJP06_h-3ro7UTBsNO-0BMxLnSKUU6xFBMEvhyQGhjsh3gvQAjDpFajGEC0C6NSQ0Nfj8KtT1cGlaQMW_nnEkAuozM=@protonmail.com>

Hi Antoine,

Thanks for your comment. I believe for Lightning it's simpler with regard to the management of the UTxO pool, but harder with regard to choosing
a threat model.
Responses inline.

> For any opened channel, ensure the confirmation of a Commitment transaction and the children HTLC-Success/HTLC-Timeout transactions. Note, in the Lightning security game you have to consider (at least) 4 types of players moves and incentives : your node, your channel counterparties, the miners, the crowd of bitcoin users. The number of the last type of players is unknown from your node, however it should not be forgotten you're in competition for block space, therefore their block demands bids should be anticipated and reacted to in consequence. With that remark in mind, implications for your LN fee-bumping strategy will be raised afterwards.
>
> For a LN service provider, on-chain overpayments are bearing on your operational costs, thus downgrading your economic competitiveness. For the average LN user, overpayment might price out outside a LN non-custodial deployment, as you don't have the minimal security budget to be on your own.

I think this problem statement can be easily generalised to any offchain contract. And your points stand for all of them.
"For any opened contract, ensure at any point the confirmation of a (set of) transaction(s) in a given number of blocks"

> Same issue with Lightning, we can be pinned today on the basis of replace-by-fee rule 3. We can be also blinded by network mempool partitions, a pinning counterparty can segregate all the full-nodes in as many subsets by broadcasting a revoked Commitment transaction different for each. For Revault, I think you can also do unlimited partitions by mutating the ANYONECANPAY-input of the Cancel.

Well you can already do unlimited partitions by adding different inputs to it. You could malleate the witness, but since we are using Miniscript i'm confident you would only be able in a marginal way.

> That said, if you have a distributed towers deployment, spread across the p2p network topology, and they can't be clustered together through cross-layers or intra-layer heuristics, you should be able to reliably observe such partitions. I think such distributed monitors are deployed by few L1 merchants accepting 0-conf to detect naive double-spend.

We should aim to more than 0-conf (in)security level..
It seems to me the only policy-level mitigation for RBF pinning around the "don't decrease the abolute fees of a less-than-a-block mempool" would be to drop the requirement on increasing absolute fees if the mempool is "full enough" (and the feerate increases exponentially, of course).
Another approach could be by introducing new consensus rules as proposed by Jeremy last year [0]. If we go in the realm of new consensus rules, then i think that simply committing to a maximum tx size would fix pinning by RBF rule 3. Could be in the annex, or in the unused sequence bits (although they currently are by Lightning, meh). You could also check in the output script that the input commits to this.

[0] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-September/018168.html

> Have we already discussed a fee-bumping "shared cache", a CPFP variation ? Strawman idea: Alice and Bob commit collateral inputs to a separate UTXO from the main "offchain contract" one. This UTXO is locked by a multi-sig. For any Commitment transaction pre-signed, also counter-sign a CPFP with top mempool feerate included, spending a Commitment anchor output and the shared-cache UTXO. If the fees spike, you can re-sign a high-feerate CPFP, assuming interactivity. As the CPFP is counter-signed by everyone, the outputs can be CSV-1 encumbered to prevent pinnings. If the share-cache is feeded at parity, there shouldn't be an incentive to waste or maliciously inflate the feerate. I think this solution can be easily generalized to more than 2 counterparties by using a multi-signature scheme. Big issue, if the feerate is short due to fee spikes and you need to re-sign a higher-feerate CPFP, you're trusting your counterparty to interact, though arguably not worse than the current update fee mechanism.

It really looks just like `update_fee`. Except maybe with the property that you have the channel liquidity not depend on the onchain feerate.
In any case, for Lightning i think it's a bad idea to re-introduce trust on this side post anchor outputs. For Revault it's clearly out of the question to introduce trust in your counterparties (why would you bother having a fee-bumping mechanism in the first place then?). Probably the same holds for all offchain contracts.

>> For Lightning, it'd mean keeping an equivalent amount of funds as the sum of all your
> channels balances sitting there unallocated "just in case". This is not reasonable.
>
> Agree, game-theory wise, you would like to keep a full fee-bumping reserve, ready to burn as much in fees as the contested HTLC value, as it's the maximum gain of your counterparty. Though perfect equilibrium is hard to achieve because your malicious counterparty might have an edge pushing you to broadcast your Commitment first by witholding HTLC resolution.
>
> Fractional fee-bumping reserves are much more realistic to expect in the LN network. Lower fee-bumping reserve, higher liquidity deployed, in theory higher routing fees. By observing historical feerates, average offchain balances at risk and routing fees expected gains, you should be able to discover an equilibrium where higher levels of reserve aren't worth the opportunity cost. I guess this equilibrium could be your LN fee-bumping reserve max feerate.
>
> Note, I think the LN approach is a bit different from what suits a custody protocol like Revault, as you compute a direct return of the frozen fee-bumping liquidity. With Revault, if you have numerous bitcoins protected, it's might be more interesting to adopt a "buy the mempool, stupid" strategy than risking fund safety for few percentages of interest returns.

True for routing nodes. For wallets (if receiving funds), it's not about an investment: just users expectations to being able to transact without risking to lose their funds (ie being able to enforce their contract onchain). Although wallets they are much less at risk.

> This is where the "anticipate the crowd of bitcoin users move" point can be laid out. As the crowd of bitcoin users' fee-bumping reserves are ultimately unknown from your node knowledge, you should be ready to be a bit more conservative than the vanilla fee-bumping strategies shipped by default. In case of massive mempool congestion, your additional conservatism might get your time-sensitive transactions and game on the crowd of bitcoin users. First Problem: if all offchain bitcoin software adopt that strategy we might inflate the worst-case feerate rate at the benefit of the miners, without holistically improving block throughput. Second problem : your class of offchain bitcoin softwares might have ridiculous fee-bumping reserve compared
> to other classes of offchain bitcoin softwares (Revault > Lightning) and just be priced out bydesign in case of mempool congestion. Third problem : as the number of offchain bitcoin applications should go up with time, your fee-bumping reserve levels based from historical data might be always late by one "bank-run" scenario.

Black swan event 2.0? Just rule n?3 is inherent to any kind of fee estimation.

> For Lightning, if you're short in fee-bumping reserves you might still do preemptive channel closures, either cooperatively or unilaterally and get back the off-chain liquidity to protect the more economically interesting channels. Though again, that kind of automatic behavior might be compelling at the individual node-level, but make the mempol congestion worse holistically.

Yeah so we are back to the "fractional reserve" model: you can only enforce X% of the offchain contracts your participate in.. Actually it's even an added assumption: that you still have operating contracts, with honest counterparties.

> In case of massive mempool congestion, you might try to front-run the crowd of bitcoin users relying on block connections for fee-bumping, and thus start your fee-bumping as soon as you observe feerate groups fluctuations in your local mempool(s).

I don't think any kind of mempool-based estimate generalizes well, since at any point the expected time before the next block is 10 minutes (and a lot can happen in 10min).

> Also you might proceed your fee-bumping ticks on a local clock instead of block connections in case of time-dilation or deeper eclipse attacks of your local node. Your view of the chain might be compromised but not your ability to broadcast transactions thanks to emergency channels (in the non-LN sense...though in fact quid of txn wrapped in onions ?) of communication.

Oh, yeah, i didn't explicit "not getting eclipsed" (or more generally "data availability") as an assumption since it's generally one made by participants of any offchain contract. In this case you can't even have decent fee estimation, so you are screwed anyways.

> Yes, stay open the question on how you enforce this block insurance market. Reputation, which might be to avoid due to the latent centralization effect, might be hard to stack and audit reliably for an emergency mechanism running, hopefully, once in a halvening period. Maybe maybe some cryptographic or economically based mechanism on slashing or swaps could be found...

Unfortunately, given current mining centralisation, pools are in a very good position to offer pretty decent SLAs around that. With a block space insurance, you of course don't need all these convoluted fee-bumping hacks.
I'm very concerned that large stakeholders of the "offchain contracts ecosystem" would just go this (easier) way and further increase mining centralisation pressure.

I agree that a cryptography-based scheme around this type of insurance services would be the best way out.

> Antoine
>
> Le lun. 29 nov. 2021 ? 09:34, darosior via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> a ?crit :
>
>> Hi everyone,
>>
>> Fee-bumping is paramount to the security of many protocols building on Bitcoin, as they require the
>> confirmation of a transaction (which might be presigned) before the expiration of a timelock at any
>> point after the establishment of the contract.
>>
>> The part of Revault using presigned transactions (the delegation from a large to a smaller multisig)
>> is no exception. We have been working on how to approach this for a while now and i'd like to share
>> what we have in order to open a discussion on this problem so central to what seem to be The Right
>> Way [0] to build on Bitcoin but which has yet to be discussed in details (at least publicly).
>>
>> I'll discuss what we came up with for Revault (at least for what will be its first iteration) but my
>> intent with posting to the mailing list is more to frame the questions to this problem we are all
>> going to face rather than present the results of our study tailored to the Revault usecase.
>> The discussion is still pretty Revault-centric (as it's the case study) but hopefully this can help
>> future protocol designers and/or start a discussion around what everyone's doing for existing ones.
>>
>> ## 1. Reminder about Revault
>>
>> The part of Revault we are interested in for this study is the delegation process, and more
>> specifically the application of spending policies by network monitors (watchtowers).
>> Coins are received on a large multisig. Participants of this large multisig create 2 [1]
>> transactions. The Unvault, spending a deposit UTxO, creates an output paying either to the small
>> multisig after a timelock or to the large multisig immediately. The Cancel, spending the Unvault
>> output through the non-timelocked path, creates a new deposit UTxO.
>> Participants regularly exchange the Cancel transaction signatures for each deposit, sharing the
>> signatures with the watchtowers they operate. They then optionally [2] sign the Unvault transaction
>> and share the signatures with the small multisig participants who can in turn use them to proceed
>> with a spending. Watchtowers can enforce spending policies (say, can't Unvault outside of business
>> hours) by having the Cancel transaction be confirmed before the expiration of the timelock.
>>
>> ## 2. Problem statement
>>
>> For any delegated vault, ensure the confirmation of a Cancel transaction in a configured number of
>> blocks at any point. In so doing, minimize the overpayments and the UTxO set footprint. Overpayments
>> increase the burden on the watchtower operator by increasing the required frequency of refills of the
>> fee-bumping wallet, which is already the worst user experience. You are likely to manage a number of
>> UTxOs with your number of vaults, which comes at a cost for you as well as everyone running a full
>> node.
>>
>> Note that this assumes miners are economically rationale, are incentivized by *public* fees and that
>> you have a way to propagate your fee-bumped transaction to them. We also don't consider the block
>> space bounds.
>>
>> In the previous paragraph and the following text, "vault" can generally be replaced with "offchain
>> contract".
>>
>> ## 3. With presigned transactions
>>
>> As you all know, the first difficulty is to get to be able to unilaterally enforce your contract
>> onchain. That is, any participant must be able to unilaterally bump the fees of a transaction even
>> if it was co-signed by other participants.
>>
>> For Revault we can afford to introduce malleability in the Cancel transaction since there is no
>> second-stage transaction depending on its txid. Therefore it is pre-signed with ANYONECANPAY. We
>> can't use ANYONECANPAY|SINGLE since it would open a pinning vector [3]. Note how we can't leverage
>> the carve out rule, and neither can any other more-than-two-parties contract.
>> This has a significant implication for the rest, as we are entirely burning fee-bumping UTxOs.
>>
>> This opens up a pinning vector, or at least a significant nuisance: any other party can largely
>> increase the absolute fee without increasing the feerate, leveraging the RBF rules to prevent you
>> from replacing it without paying an insane fee. And you might not see it in your own mempool and
>> could only suppose it's happening by receiving non-full blocks or with transactions paying a lower
>> feerate.
>> Unfortunately i know of no other primitive that can be used by multi-party (i mean, >2) presigned
>> transactions protocols for fee-bumping that aren't (more) vulnerable to pinning.
>>
>> ## 4. We are still betting on future feerate
>>
>> The problem is still missing one more constraint. "Ensuring confirmation at any time" involves ensuring
>> confirmation at *any* feerate, which you *cannot* do. So what's the limit? In theory you should be ready
>> to burn as much in fees as the value of the funds you want to get out of the contract. So... For us
>> it'd mean keeping for each vault an equivalent amount of funds sitting there on the watchtower's hot
>> wallet. For Lightning, it'd mean keeping an equivalent amount of funds as the sum of all your
>> channels balances sitting there unallocated "just in case". This is not reasonable.
>>
>> So you need to keep a maximum feerate, above which you won't be able to ensure the enforcement of
>> all your contracts onchain at the same time. We call that the "reserve feerate" and you can have
>> different strategies for choosing it, for instance:
>> - The 85th percentile over the last year of transactions feerates
>> - The maximum historical feerate
>> - The maximum historical feerate adjusted in dollars (makes more sense but introduces a (set of?)
>> trusted oracle(s) in a security-critical component)
>> - Picking a random high feerate (why not? It's an arbitrary assumption anyways)
>>
>> Therefore, even if we don't have to bet on the broadcast-time feerate market at signing time anymore
>> (since we can unilaterally bump), we still need some kind of prediction in preparation of making
>> funds available to bump the fees at broadcast time.
>> Apart from judging that 500sat/vb is probably more reasonable than 10sat/vbyte, this unfortunately
>> sounds pretty much crystal-ball-driven.
>>
>> We currently use the maximum of the 95th percentiles over 90-days windows over historical block chain
>> feerates. [4]
>>
>> ## 5. How much funds does my watchtower need?
>>
>> That's what we call the "reserve". Depending on your reserve feerate strategy it might vary over
>> time. This is easier to reason about with a per-contract reserve. For Revault it's pretty
>> straightforward since the Cancel transaction size is static: `reserve_feerate * cancel_size`. For
>> other protocols with dynamic transaction sizes (or even packages of transactions) it's less so. For
>> your Lightning channel you would probably take the maximum size of your commitment transaction
>> according to your HTLC exposure settings + the size of as many `htlc_success` transaction?
>>
>> Then you either have your software or your user guesstimate how many offchain contracts the
>> watchtower will have to watch, time that by the per-contract reserve and refill this amount (plus
>> some slack in practice). Once again, a UX tradeoff (not even mentioning the guesstimation UX):
>> overestimating leads to too many unallocated funds sitting on a hot wallet, underestimating means
>> (at best) inability to participate in new contracts or being "at risk" (not being able to enforce
>> all your contracts onchain at your reserve feerate) before a new refill.
>>
>> For vaults you likely have large-value UTxOs and small transactions (the Cancel is one-in one-out in
>> Revault). For some other applications with large transactions and lower-value UTxOs on average it's
>> likely that only part of the offchain contracts might be enforceable at a reasonable feerate. Is it
>> reasonable?
>>
>> ## 6. UTxO pool layout
>>
>> Now that you somehow managed to settle on a refill amount, how are you going to use these funds?
>> Also, you'll need to manage your pool across time (consolidating small coins, and probably fanning
>> out large ones).
>>
>> You could keep a single large UTxO and peel it as you need to sponsor transactions. But this means
>> that you need to create a coin of a specific value according to your need at the current feerate
>> estimation, hope to have it confirmed in a few blocks (at least for now! [5]), and hope that the
>> value won't be obsolete by the time it confirmed. Also, you'd have to do that for any number of
>> Cancel, chaining feebump coin creation transactions off the change of the previous ones or replacing
>> them with more outputs. Both seem to become really un-manageable (and expensive) in many edge-cases,
>> shortening the time you have to confirm the actual Cancel transaction and creating uncertainty about
>> the reserve (how much is my just-in-time fanout going to cost me in fees that i need to refill in
>> advance on my watchtower wallet?).
>> This is less of a concern for protocols using CPFP to sponsor transactions, but they rely on a
>> policy rule specific to 2-parties contracts.
>>
>> Therefore for Revault we fan-out the coins per-vault in advance. We do so at refill time so the
>> refiller can give an excess to pay for the fees of the fanout transaction (which is reasonable since
>> it will occur just after the refilling transaction confirms). When the watchtower is asked to watch
>> for a new delegated vault it will allocate coins from the pool of fanned-out UTxOs to it (failing
>> that, it would refuse the delegation).
>> What is a good distribution of UTxOs amounts per vault? We want to minimize the number of coins,
>> still have coins small enough to not overpay (remember, we can't have change) and be able to bump a
>> Cancel up to the reserve feerate using these coins. The two latter constraints are directly in
>> contradiction as the minimal value of a coin usable at the reserve feerate (paying for its own input
>> fee + bumping the feerate by, say, 5sat/vb) is already pretty high. Therefore we decided to go with
>> two distributions per vault. The "reserve distribution" alone ensures that we can bump up to the
>> reserve feerate and is usable for high feerates. The "bonus distribution" is not, but contains
>> smaller coins useful to prevent overpayments during low and medium fee periods (which is most of the
>> time).
>> Both distributions are based on a basic geometric suite [6]. Each value is half the previous one.
>> This exponentially decreases the value, limiting the number of coins. But this also allows for
>> pretty small coins to exist and each coin's value is equal to the sum of the smaller coins,
>> or smaller by at most the value of the smallest coin. Therefore bounding the maximum overpayment to
>> the smallest coin's value [7].
>>
>> For the management of the UTxO pool across time we merged the consolidation with the fanout. When
>> fanning out a refilled UTxO, we scan the pool for coins that need to be consolidated according to a
>> heuristic. An instance of a heuristic is "the coin isn't allocated and would not have been able to
>> increase the fee at the median feerate over the past 90 days of blocks".
>> We had this assumption that feerate would tend to go up with time and therefore discarded having to
>> split some UTxOs from the pool. We however overlooked that a large increase in the exchange price of
>> BTC as we've seen during the past year could invalidate this assumption and that should arguably be
>> reconsidered.
>>
>> ## 7. Bumping and re-bumping
>>
>> First of all, when to fee-bump? At fixed time intervals? At each block connection? It sounds like,
>> given a large enough timelock, you could try to greed by "trying your luck" at a lower feerate and
>> only re-bumping every N blocks. You would then start aggressively bumping at every block after M
>> blocks have passed. But that's actually a bet (in disguised?) that the next block feerate in M blocks
>> will be lower than the current one. In the absence of any predictive model it is more reasonable to
>> just start being aggressive immediately.
>> You probably want to base your estimates on `estimatesmartfee` and as a consequence you would re-bump
>> (if needed )after each block connection, when your estimates get updated and you notice your
>> transaction was not included in the block.
>>
>> In the event that you notice a consequent portion of the block is filled with transactions paying
>> less than your own, you might want to start panicking and bump your transaction fees by a certain
>> percentage with no consideration for your fee estimator. You might skew miners incentives in doing
>> so: if you increase the fees by a factor of N, any miner with a fraction larger than 1/N of the
>> network hashrate now has an incentive to censor your transaction at first to get you to panic. Also
>> note this can happen if you want to pay the absolute fees for the 'pinning' attack mentioned in
>> section #2, and that might actually incentivize miners to perform it themselves..
>>
>> The gist is that the most effective way to bump and rebump (RBF the Cancel tx) seems to just be to
>> consider the `estimatesmartfee 2 CONSERVATIVE` feerate at every block your tx isn't included in, and
>> to RBF it if the feerate is higher.
>> In addition, we fallback to a block chain based estimation when estimates aren't available (eg if
>> the user stopped their WT for say a hour and we come back up): we use the 85th percentile over the
>> feerates in the last 6 blocks. Sure, miners can try to have an influence on that by stuffing their
>> blocks with large fee self-paying transactions, but they would need to:
>> 1. Be sure to catch a significant portion of the 6 blocks (at least 2, actually)
>> 2. Give up on 25% of the highest fee-paying transactions (assuming they got the 6 blocks, it's
>> proportionally larger and incertain as they get less of them)
>> 3. Hope that our estimator will fail and we need to fall back to the chain-based estimation
>>
>> ## 8. Our study
>>
>> We essentially replayed the historical data with different deployment configurations (number of
>> participants and timelock) and probability of an event occurring (event being say an Unvault, an
>> invalid Unvault, a new delegation, ..). We then observed different metrics such as the time at risk
>> (when we can't enforce all our contracts at the reserve feerate at the same time), or the
>> operational cost.
>> We got the historical fee estimates data from Statoshi [9], Txstats [10] and the historical chain
>> data from Riccardo Casatta's `blocks_iterator` [11]. Thanks!
>>
>> The (research-quality..) code can be found at https://github.com/revault/research under the section
>> "Fee bumping". Again it's very Revault specific, but at least the data can probably be reused for
>> studying other protocols.
>>
>> ## 9. Insurances
>>
>> Of course, given it's all hacks and workarounds and there is no good answer to "what is a reasonable
>> feerate up to which we need to make contracts enforceable onchain?", there is definitely room for an
>> insurance market. But this enters the realm of opinions. Although i do have some (having discussed
>> this topic for the past years with different people), i would like to keep this post focused on the
>> technical aspects of this problem.
>>
>> [0] As far as i can tell, having offchain contracts be enforceable onchain by confirming a
>> transaction before the expiration of a timelock is a widely agreed-upon approach. And i don't think
>> we can opt for any other fundamentally different one, as you want to know you can claim back your
>> coins from a contract after a deadline before taking part in it.
>>
>> [1] The Real Revault (tm) involves more transactions, but for the sake of conciseness i only
>> detailed a minimum instance of the problem.
>>
>> [2] Only presigning part of the Unvault transactions allows to only delegate part of the coins,
>> which can be abstracted as "delegate x% of your stash" in the user interface.
>>
>> [3] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-May/017835.html
>>
>> [4] https://github.com/revault/research/blob/1df953813708287c32a15e771ba74957ec44f354/feebumping/model/statemachine.py#L323-L329
>>
>> [5] https://github.com/bitcoin/bitcoin/pull/23121
>>
>> [6] https://github.com/revault/research/blob/1df953813708287c32a15e771ba74957ec44f354/feebumping/model/statemachine.py#L494-L507
>>
>> [7] Of course this assumes a combinatorial coin selection, but i believe it's ok given we limit the
>> number of coins beforehand.
>>
>> [8] Although there is the argument to outbid a censorship, anyone censoring you isn't necessarily a
>> miner.
>>
>> [9] https://www.statoshi.info/
>>
>> [10] https://www.statoshi.info/
>>
>> [11] https://github.com/RCasatta/blocks_iterator
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20211130/79715fe8/attachment-0001.html>

