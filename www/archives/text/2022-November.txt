From antoine.riard at gmail.com  Tue Nov  1 00:47:18 2022
From: antoine.riard at gmail.com (Antoine Riard)
Date: Mon, 31 Oct 2022 20:47:18 -0400
Subject: [bitcoin-dev] Bitcoin Contracting Primitives WG 1st Meeting,
	Tuesday 15 Nov. 18:00 UTC
Message-ID: <CALZpt+EygPsez0c84Yfmc6h+L7Ji8C3zE_E=EzPzLh4XWNHvZA@mail.gmail.com>

Hi list,

After I have been asked offline the exact date when those meetings were
actually starting, I'm proposing Tuesday 15th November at 18:00 UTC, i.e 2
weeks from now. Thinking about a monthly frequency for now (from my
experience attending dlcspecs/lighnting specs meetings/core dev meetings in
the past, weekly sounds too much, biweekly/monthly sounds better though
dunno yet good frequency).

If there is an incompatibility with another public engineering meeting in
the Bitcoin space, let it know. We can talk about a better schedule during
the 1st session [0].

Communication venue is #bitcoin-contracting-primitives-wg on Libera Chat
[1]. Feel free to lurk already and ask questions.

No consistent agenda beyond listening to every attendee their expectations,
ideas, subjects of interests they would like to see happening with this new
covenants/contracting primitives R&D process.

If you have been working on a contracting
protocols/side-chains/rollups/other use-cases that could benefit from
extended Bitcoin contracting primitives, feel free to open an issue there:
https://github.com/ariard/bitcoin-contracting-primitives-wg/issues

Let it know if you have more questions or feedback.

Cheers,
Antoine

[0] It would be great to have a schedule inclusive of most timezones we
can, 18:00 UTC might be too early for Asian and Oceanic ones. Later, we
start to be exclusive towards contributors in Eastern Europe.

[1] There have been more voices suggesting jitsi/audio-based meetings
rather than IRC. It's a cool format too, though coming with trade-offs.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221031/5ac3bd9a/attachment.html>

From gloriajzhao at gmail.com  Tue Nov  1 18:03:22 2022
From: gloriajzhao at gmail.com (Gloria Zhao)
Date: Tue, 1 Nov 2022 18:03:22 +0000
Subject: [bitcoin-dev] Package Relay Proposal
In-Reply-To: <CALZpt+EOmet0j5OhFo5nmZxVJbPfRRnh7oCRwytxkVMbAtz0Eg@mail.gmail.com>
References: <CAFXO6=JROe_9ih2h+_CCH-UbxehsM5RQ6YyNnPesEpveBEtdow@mail.gmail.com>
 <CALZpt+EOmet0j5OhFo5nmZxVJbPfRRnh7oCRwytxkVMbAtz0Eg@mail.gmail.com>
Message-ID: <CAFXO6=Jj+6tykoW=tx=QNkCocR5XYx7cGcATKLvxMOcPeEJhEg@mail.gmail.com>

Hi everyone,

I've made some significant changes to my package relay proposal based on
observations while implementing, feedback on this thread, and offline
discussions [1].

The new proposal is called Ancestor Package Relay, BIP331, and PR'd at
https://github.com/bitcoin/bips/pull/1382

The major changes to the proposal are:
1. Scope reduction to receiver-initiated only
2. Scope reduction to ancestor packages only
3. Removal of block hash from package information

1.  Scope reduction to receiver-initiated only
Receiver-intiated package relay enables a node to ask for more information
when they suspect they are missing something (i.e. in this case to resolve
a missing parent tx). Sender-initiated package relay should, theoretically,
save a round trip by notifying the receiver ahead of time that "hey, this
is going to be a package, so make sure you download and submit these
transactions together." As with any proactive communication, there is a
chance that the node already knows this information, so this network
bandwidth was wasted. The logic used to decide _when_ to announce a package
proactively determines whether it is a net increase or decrease for overall
bandwidth usage. However, it's difficult to design anything to save
bandwidth without any idea of what its bandwidth usage actually looks like
in practice. We'll want to design the sender-initiated protocol carefully,
and inform the design decisions using data collected from the mainnet p2p
network. However, there is no historical transaction data to use because
the goal is to enable currently-rejected transactions to propagate. In
order to get this right, I propose we hold off on sender-initiated for now,
deploy receiver-initiated package relay, observe its usage and figure out
where we can save a round trip, and then produce a well-researched
sender-initiated package relay proposal.

2. Scope reduction to ancestor packages only
The proposal now only includes ancestor packages (previously called
tx-with-unconfirmed-ancestors or "v2" packages). The
child-with-unconfirmed-parents (previously called "v1") package has been
removed since it is a subset of ancestor packages and sender-initiated
relay has been removed. It may be relevant again in the future with
sender-initiated packages. If you were reviewing the previous proposal,
"pkginfo2" message has been renamed to "ancpkginfo" and "MSG_PKGINFO2" inv
type to "MSG_ANCPKGINFO".

3. Removal of block hash from package information
Most of the rationale is already on this thread. The block hash was an
attempt to enforce topology when chainstates differ, but isn't worth it. It
does not make much sense to drop or delay transaction data requests due to
mismatched chainstates, and the chainstate may change again between package
information and transaction data rounds. Instead, differences in chainstate
should be handled internally at the mempool validation level. The node
should de-duplicate recently-confirmed transactions and make a best effort
to validate the transactions it has already downloaded.

Thanks,
Gloria

[1]
https://diyhpl.us/wiki/transcripts/bitcoin-core-dev-tech/2022-10-11-package-relay/

On Fri, Jun 17, 2022 at 9:08 PM Antoine Riard <antoine.riard at gmail.com>
wrote:

> Hi Gloria,
>
> Thanks for working on that,
>
> > Always overestimating fees may sidestep this issue temporarily (while
> mempool
> > traffic is low and predictable), but this solution is not foolproof
> > and wastes users' money. The feerate market can change due to sudden
> > spikes in traffic (e.g. huge 12sat/vB dump a few days ago [9]) or
> > sustained, high volume of Bitcoin payments (e.g.  April 2021 and
> > December 2017).
>
> Even if the LN implementations started to overestimate fees based on the
> historical worst-case of block inclusion feerates, there is still room for
> exploitation due to bip125 rule#3. Indeed, as long as the adversary is able
> to stick in the mempool a higher fee package while the feerate is not
> compelling enough to get it mined, your "honest" LN package should be
> bounced off.
>
> Considering Core's `MAX_STANDARD_TX_WEIGHT` of 400000 WU, I think it's
> practical for an attacker to succeed with this pinning tactic in periods of
> traffic spikes. Of course, LN implementation could overestimate fees with a
> target like `MAX_STANDARD_WEIGHT` * `worst_case_block_inclusion_feerate` to
> mitigate. However, assuming a value of 20sat for the latter, it would
> require from any LN user a minimal channel value of 2000000 satoshis to be
> theoretically secure against this type of pinning.
>
> So package relay is required to mitigate efficiently and realistically
> against pinning attacks, while conserving the same level of "economic"
> openness for Lightning. Beyond, it should be also noted that package relay
> is only building block of the full set of mitigations, and there should be
> a yet to-find-consensus-as-of-today other policy change such as
> user-elected package limits or replace-by-feerate.
>
> Anyway, I think it would be beneficial to document the design trade-offs
> of pinning mitigations in the `Rationale` subsection, at the attention of
> future L2s devs and users ?
>
> > {|
> > |  Field Name  ||  Type  ||  Size  ||  Purpose
> > |-
> > |version || uint32_t || 4 || Denotes a package version supported by the
> > node.
> > |-
> > |max_count || uint32_t || 4 ||Specifies the maximum number of
> transactions
> > per package this node is
> > willing to accept.
> > |-
> > |max_weight || uint32_t || 4 ||Specifies the maximum total weight per
> > package this node is willing
> > to accept.
> > |-
> > |}
>
> It's unclear to me what's the purpose of `max_count` and `max_weight` in
> the overall package relay flow, if they are intended to be exposed as
> configurable settings to node operators. If those fields are present to
> allow DoS protection increase of low-performance host, I believe it would
> be better to restrain the number of consumed UTXOs or executed sigops per
> package, as DoS vectors are more likely to be CPU-based, rather than
> memory-based as package size already bounded at acceptance by
> `MAX_PACKAGE_COUNT`.
>
> Thinking more we might introduce a `MAX_SIGOPS_PER_PACKAGR` limit, as
> otherwise if we naively grant one package announcement as equal to one
> transaction announcement in our tx-request logic, we might increase our DoS
> surface, node ressources staying equivalent ?
>
> > {|
> > |  Field Name  ||  Type  ||  Size  ||   Purpose
> > |-
> > |txns_length||CompactSize||1 or 3 bytes|| The number of transactions
> > requested.
>
> I'm not sure if we'll ever allow 3-bytes of package size, that would be
> ~32k of transactions.
>
> > |-
> > |txns||List of wtxids||txns_length * 32|| The wtxids of each transaction
> in
> > the package.
> > |}
>
> I think there is a bandwidth consumption trade-off to be aware of in the
> function of the package-relay usage. Let's consider a single issuer
> broadcasting the package to spend a shared-utxo, after the first shot the
> parent component should be spread across the network mempools. At each
> fee-bump, only the bumped CPFP will propagate on the network, the parent
> wtxid is reannounced in `pckginfo1` though there is no need to fetch it
> redundantly and waste bandwidth.
>
> However, I think the bandwidth saving does not hold in case of competing
> transaction issuers to spend a shared-utxo. In that case, the parent might
> differ at each broadcast and the list of wtxid is dissemblable at every
> claim of the shared-utxo. We could save the 32 bytes * number of packages
> elements by announcing a package_id, computed from the list of wtxids.
>
> I don't know about the occurrence of competing broadcasts among LN
> non-cooperative closes, where bandwidth could be potentially saved. I would
> say it's likely low because IIRC there is nothing in the LN protocol where
> the counterparties signal to each other they're going on-chain to introduce
> a competing broadcast synchronizing event. That said, it might increase in
> the future in a post-eltoo, multi-party contracting protocol world.
>
> So it might be interesting to document this design trade-off, if we seek
> bandwidth optimizations in function of a changing landscape in the type of
> transaction issuers in the future.
>
> > 3. The sender provides package information using "pckginfo1",
> >    including the blockhash of the sender's best block, the wtxids of
> > the transactions in the package, their total fees and total weight.
>
> It's unclear to me how the `pckinfo1` receiver should proceed if the
> sender's best block is not in sync with the local chain tip.
>
> If the package isn't processed further, that's annoying for all the
> low-performance  LN mobile clients, their chain tips might be always behind
> by few blocks from the p2p network nodes. It sounds like their packages
> won't propagate at all.
>
> If the package is processed further whatever the sender-receiver sync on
> chain tip, what's the purpose of including the blockhash ?
>
> > A child-with-unconfirmed-parents package for a transaction should be
> > announced when it meets the peer's fee filter but one or more of its
> > parents don't; a "inv(MSG_PCKG1)" instead of "inv(WTX)" should be sent
> > for the child. Each of the parents which meet the peer's fee filter
> > should still be announced normally.
>
> I believe we might have concerns of package-feerate downgrades attacks.
> E.g, in the LN context, where your channel counterparty is aiming to jam
> the propagation of the best-feerate version of the package.
>
> Let's say you have :
> - Alice's commitment_tx, at 1s/vB
> - package A + child B, at 3s/vB
> - package A + child C, at 10s/vB
> - block inclusion feerate at 10s/vB
> - Alice and Mallory are LN channel counterparties
> - commitment_tx is using LN's anchor outputs
>
> Alice's LN node broadcasts A+C to her mempool.
> Bob's feefilter is at 3s/vB.
> Mallory broadcasts her child B in Alice's mempool.
> LN commitment does not meet Bob's feefilter.
> Package A+child B at 3s/vB meets Bob's feefilter and is announced to Bob.
> Mallory broadcasts her own commitment_tx at 4s/vB in Bob's mempool.
> When Alice's child C is relayed to Bob, it's bounced off Bob's mempool.
>
> Do you think this situation is plausible ? Of course, it might be heavily
> dependent on package-relay yet-not-implemented internal p2p logic.
> I think it could be fixable if LN removes the counterparty's
> `anchor_output` on the local node's version of the commitment transaction,
> once package relay is deployed.
>
> Another question, at the next fee-bump iteration, Alice rebroadcasts
> A+child D, at 12 s/vB. Her node has already marked Alice's commitment_tx as
> known in Bob's `m_tx_inventory_known_filter`. So when a new higher fee
> child is  discovered, should a `child-with-unconfirmed-parents` be
> announced between Alice and Bob ?
>
> Anyway, I think it would be interesting to pseudo-specify the
> package-assemblage algorithm (or if there is code already available) to see
> if it's robust against adversarial or unlucky situations ?
>
> > In fact, a package
> > of transactions may be announced using both Erlay and package relay.
> > After reconciliation, if the initiator would have announced a
> > transaction by wtxid but also has package information for it, they may
> > send "inv(MSG_PCKG)" instead of "inv(WTX)".
>
> Yes, I think this holds. Note, we might have to add to the reconciliation
> set low-fee parents succeeding the feefilter check due to a child. When the
> reconcildiff, we might have to bifucarte again on feefilter to decide to
> announce missing wtixds either as `inv(MSG_PCKG)` or `inv(WTX)`.
>
> (IIRC, I've already made few feedbacks offline though good to get them in
> the public space and think more)
>
> Antoine
>
> Le mar. 17 mai 2022 ? 12:09, Gloria Zhao via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> a ?crit :
>
>> Hi everybody,
>>
>> I?m writing to propose a set of p2p protocol changes to enable package
>> relay, soliciting feedback on the design and approach. Here is a link
>> to the most up-to-date proposal:
>>
>> https://github.com/bitcoin/bips/pull/1324
>>
>> If you have concept or approach feedback, *please respond on the
>> mailing list* to allow everybody to view and participate in the
>> discussion. If you find a typo or inaccurate wording, please feel free
>> to leave suggestions on the PR.
>>
>> I?m also working on an implementation for Bitcoin Core.
>>
>>
>> The rest of this post will include the same contents as the proposal,
>> with a bit of reordering and additional context. If you are not 100%
>> up-to-date on package relay and find the proposal hard to follow, I
>> hope you find this format more informative and persuasive.
>>
>>
>> ==Background and Motivation==
>>
>> Users may create and broadcast transactions that depend upon, i.e.
>> spend outputs of, unconfirmed transactions. A ?package? is the
>> widely-used term for a group of transactions representable by a
>> connected Directed Acyclic Graph (where a directed edge exists between
>> a transaction that spends the output of another transaction).
>>
>> Incentive-compatible mempool and miner policies help create a fair,
>> fee-based market for block space. While miners maximize transaction
>> fees in order to earn higher block rewards, non-mining users
>> participating in transaction relay reap many benefits from employing
>> policies that result in a mempool with the same contents, including
>> faster compact block relay and more accurate fee estimation.
>> Additionally, users may take advantage of mempool and miner policy to
>> bump the priority of their transactions by attaching high-fee
>> descendants (Child Pays for Parent or CPFP).  Only considering
>> transactions one at a time for submission to the mempool creates a
>> limitation in the node's ability to determine which transactions have
>> the highest feerates, since it cannot take into account descendants
>> until all the transactions are in the mempool. Similarly, it cannot
>> use a transaction's descendants when considering which of two
>> conflicting transactions to keep (Replace by Fee or RBF).
>>
>> When a user's transaction does not meet a mempool's minimum feerate
>> and they cannot create a replacement transaction directly, their
>> transaction will simply be rejected by this mempool. They also cannot
>> attach a descendant to pay for replacing a conflicting transaction.
>> This limitation harms users' ability to fee-bump their transactions.
>> Further, it presents a security issue in contracting protocols which
>> rely on **presigned**, time-sensitive transactions to prevent cheating
>> (HTLC-Timeout in LN Penalty [1] [2] [3], Unvault Cancel in Revault
>> [4], Refund Transaction in Discreet Log Contracts [5], Updates in
>> eltoo [6]). In other words, a key security assumption of many
>> contracting protocols is that all parties can propagate and confirm
>> transactions in a timely manner.
>>
>> In the past few years, increasing attention [0][1][2][3][6] has been
>> brought to **pinning attacks**, a type of censorship in which the
>> attacker uses mempool policy restrictions to prevent a transaction
>> from being relayed or getting mined.  TLDR: revocation transactions
>> must meet a certain confirmation target to be effective, but their
>> feerates are negotiated well ahead of broadcast time. If the
>> forecasted feerate was too low and no fee-bumping options are
>> available, attackers can steal money from their counterparties. I walk
>> through a concrete example for stealing Lightning HTLC outputs at
>> ~23:58 in this talk [7][8].  Note that most attacks are only possible
>> when the market for blockspace at broadcast time  demands much higher
>> feerates than originally anticipated at signing time. Always
>> overestimating fees may sidestep this issue temporarily (while mempool
>> traffic is low and predictable), but this solution is not foolproof
>> and wastes users' money. The feerate market can change due to sudden
>> spikes in traffic (e.g. huge 12sat/vB dump a few days ago [9]) or
>> sustained, high volume of Bitcoin payments (e.g.  April 2021 and
>> December 2017).
>>
>> The best solution is to enable nodes to consider packages of
>> transactions as a unit, e.g. one or more low-fee parent transactions
>> with a high-fee child, instead of separately. A package-aware mempool
>> policy can help determine if it would actually be economically
>> rational to accept a transaction to the mempool if it doesn't meet fee
>> requirements individually. Network-wide adoption of these policies
>> would create a more purely-feerate-based market for block space and
>> allow contracting protocols to adjust fees (and therefore mining
>> priority) at broadcast time.  Some support for packages has existed in
>> Bitcoin Core for years. Since v0.13, Bitcoin Core has used ancestor
>> packages instead of individual transactions to evaluate the incentive
>> compatibility of transactions in the mempool [10] and select them for
>> inclusion in blocks [11].
>>
>> Package Relay, the concept of {announcing, requesting, downloading}
>> packages between nodes on the p2p network, has also been discussed for
>> many years. The earliest public mention I can find is from 2015 [12].
>> The two most common use cases for package relay are fee-bumping
>> otherwise-too-low-fee transactions and reducing the amount of orphans.
>> It seems uncontroversial to say that everybody desires package relay
>> conceptually, with varying degrees of urgency. Lots of work has been
>> done by others over the past few years, from which I've taken
>> inspiration from [13][14][15][16].
>>
>> My approach has been to split the project into two components: (1) Package
>> Mempool Accept, which includes validation logic and mempool policy.
>> (3) Package Relay, which includes the p2p protocol changes.
>>
>> Progress so far:
>> After discussions with various developers of contracting protocols
>> (with heavier emphasis towards LN), it was determined that a
>> package containing a child with all of its unconfirmed parents
>> (child-with-unconfirmed-parents or 1-child-multi-parent package) would
>> be sufficient for their use case, i.e. fee-bumping presigned
>> transactions. A child-with-unconfirmed-parents package has several
>> properties that make many things easier to reason about.
>>
>> A few months ago, I proposed a set of policies for safe package
>> validation and fee assessment for packages of this restricted
>> topology [17]. A series of PRs implementing this proposal have
>> been merged into Bitcoin Core [18].
>>
>> Theoretically, developing a safe and incentive-compatible package
>> mempool acceptance policy is sufficient to solve this issue. Nodes
>> could opportunistically accept packages (e.g. by trying combinations
>> of transactions rejected from their mempools), but this practice would
>> likely be inefficient at best and open new Denial of Service attacks
>> at worst. Additional p2p messages may enable nodes to request and
>> share package validation-related information with one another in a
>> more communication-efficient way.
>>
>> Given that only package RBF remains for package mempool accept, and we
>> can make progress on p2p and mempool in parallel, I think it?s
>> appropriate to put forward a package relay proposal.
>>
>> ==Proposal==
>>
>> This proposal contains 2 components: a ?generic? package relay
>> protocol and an extension of it, child-with-unconfirmed-parents
>> packages, as version 1 package relay. Another version of packages,
>> ?tx-with-unconfirmed-ancestors? can be created to extend package relay
>> for eliminating orphans.
>>
>> ===Generic Package Relay===
>>
>> Two main ideas are introduced:
>>
>> Download and validate packages of transactions together.
>>
>> Provide information to help peers decide whether to request and/or how
>> to validate transactions which are part of a package.
>>
>> ====Intended Protocol Flow====
>>
>> Due to the asynchronous nature of a distributed transaction relay
>> network, nodes may not receive all of the information needed to
>> validate a transaction at once. For example, after a node completes
>> Initial Block Download (IBD) and first starts participating in
>> transaction relay with an empty mempool, it is common to receive
>> orphans. In such scenarios where a node is aware that it is missing
>> information, a ''receiver-initiated'' dialogue is appropriate:
>>
>> 1. Receiver requests package information.
>>
>> 2. The sender provides package information, including the wtxids of
>>    the transactions in the package and anything else that might be
>> relevant (e.g. total fees and size).
>>
>> 3. The reciever uses the package information to decide how to request
>>    and validate the transactions.
>>
>> Sometimes, no matter what order transactions are received by a node,
>> validating them individually is insufficient. When the sender is aware
>> of additional information that the receiver needs to accept a package,
>> a proactive ''sender-initiated'' dialogue should be enabled:
>>
>> 1. Sender announces they have package information pertaining to a
>>    transaction that might otherwise be undesired on its own.
>>
>> 2. The receiver requests package information.
>>
>> 3. The sender provides package information, including the wtxids of
>>    the transactions in the package and anything else that might be
>> relevant (e.g. total fees and size).
>>
>> 4. The reciever uses the package information to decide how to request
>>    and validate the transactions.
>>
>> Package relay is negotiated between two peers during the version
>> handshake. Package relay requires both peers to support wtxid-based
>> relay because package transactions are referenced by their wtxid.
>>
>> ====New Messages====
>>
>> Three new protocol messages are added for use in any version of
>> package relay. Additionally, each version of package relay must define
>> its own inv type and "pckginfo" message version, referred to in this
>> document as "MSG_PCKG" and "pckginfo" respectively. See
>> BIP-v1-packages for a concrete example.
>>
>> =====sendpackages=====
>>
>> {|
>> |  Field Name  ||  Type  ||  Size  ||  Purpose
>> |-
>> |version || uint32_t || 4 || Denotes a package version supported by the
>> node.
>> |-
>> |max_count || uint32_t || 4 ||Specifies the maximum number of
>> transactions per package this node is
>> willing to accept.
>> |-
>> |max_weight || uint32_t || 4 ||Specifies the maximum total weight per
>> package this node is willing
>> to accept.
>> |-
>> |}
>>
>> 1. The "sendpackages" message has the structure defined above, with
>>    pchCommand == "sendpackages".
>>
>> 2. During version handshake, nodes should send a "sendpackages"
>>    message indicate they support package relay and may request
>> packages.
>>
>> 3. The message should contain a version supported by the node. Nodes
>>    should send a "sendpackages" message for each version they support.
>>
>> 4. The "sendpackages" message MUST be sent before sending a "verack"
>>    message. If a "sendpackages" message is received afer "verack", the
>> sender should be disconnected.
>>
>> 5. If 'fRelay==false' in a peer's version message, the node must not
>>    send "sendpackages" to them. If a "sendpackages" message is
>> received by a peer after sending `fRelay==false` in their version
>> message, the sender should be disconnected.
>>
>> 6.. Upon receipt of a "sendpackages" message with a version that is
>> not supported, a node must treat the peer as if it never received the
>> message.
>>
>> 7. If both peers send "wtxidrelay" and "sendpackages" with the same
>>    version, the peers should announce, request, and send package
>> information to each other.
>>
>> =====getpckgtxns=====
>>
>> {|
>> |  Field Name  ||  Type  ||  Size  ||   Purpose
>> |-
>> |txns_length||CompactSize||1 or 3 bytes|| The number of transactions
>> requested.
>> |-
>> |txns||List of wtxids||txns_length * 32|| The wtxids of each transaction
>> in the package.
>> |}
>>
>> 1. The "getpckgtxns" message has the structure defined above, with
>>    pchCommand == "getpckgtxns".
>>
>> 2. A "getpckgtxns" message should be used to request all or some of
>>    the transactions previously announced in a "pckginfo" message,
>> specified by witness transactiosome id.
>>
>> 3. Upon receipt of a "getpckgtxns" message, a node must respond with
>>    either a "pckgtxns" containing the requested transactions or a
>> "notfound" message indicating one or more of the transactions is
>> unavailable. This allows the receiver to avoid downloading and storing
>> transactions that cannot be validated immediately.
>>
>> 4. A "getpckgtxns" message should only be sent if both peers agreed to
>>    send packages in the version handshake. If a "getpckgtxns" message
>> is received from a peer with which package relay was not negotiated,
>> the sender should be disconnected.
>>
>> =====pckgtxns=====
>>
>> {|
>> |  Field Name  ||  Type  ||  Size  ||   Purpose
>> |-
>> |txns_length||CompactSize||1 or 3 bytes|| The number of transactions
>> provided.
>> |-
>> |txns||List of transactions||variable|| The transactions in the package.
>> |}
>>
>> 1. The "pckgtxns" message has the structure defined above, with
>>    pchCommand == "pckgtxns".
>>
>> 2. A "pckgtxns" message should contain the transaction data requested
>>    using "getpckgtxns".
>>
>> 3. A "pckgtxns" message should only be sent to a peer that requested
>>    the package using "getpckgtxns". If a node receives an unsolicited
>> package, the sender should be disconnected.
>>
>> 4. A "pckgtxns" message should only be sent if both peers agreed to
>>    send packages in the version handshake. If a "pckgtxns" message is
>> received from a peer with which package relay was not negotiated, the
>> sender should be disconnected.
>>
>> ===Version 1 Packages: child-with-unconfirmed-parents===
>>
>> This extends package relay for packages consisting of one transaction
>> and all of its unconfirmed parents,by defining version 1 packages, a
>> pckginfo1 message, and a MSG_PCKG1 inv type. It enables the use case
>> in which a child pays for its otherwise-too-low-fee parents and their
>> mempool conflict(s).
>>
>> ====Intended Protocol Flow====
>>
>> When relaying a package of low-fee parent(s) and high-fee child, the
>> sender and receiver do the following:
>>
>> 1. Sender announces they have a child-with-unconfirmed-parents package
>>    for a child that pays for otherwise-too-low-fee parent(s) using
>> "inv(MSG_PCKG1)".
>>
>> 2. The receiver requests package information using
>>    "getdata(MSG_PCKG1)".
>>
>> 3. The sender provides package information using "pckginfo1",
>>    including the blockhash of the sender's best block, the wtxids of
>> the transactions in the package, their total fees and total weight.
>>
>> 4. The reciever uses the package information to decide how to request
>>    the transactions. For example, if the receiver already has some of
>> the transactions in their mempool, they only request the missing ones.
>> They could also decide not to request the package at all based on the
>> fee information provided.
>>
>> 5. Upon receiving a "pckgtxns", the receiver submits the transactions
>>    together as a package.
>>
>> ====New Messages====
>>
>> A new inv type, "MSG_PCKG1", and new protocol message, "PCKGINFO1",
>> are added.
>>
>> =====pckginfo1=====
>>
>> {|
>> |  Field Name  ||  Type  ||  Size  ||   Purpose
>> |-
>> |blockhash || uint256 || 32 || The chain tip at which this package is
>> defined.
>> |-
>> |pckg_fee||CAmount||4|| The sum total fees paid by all transactions in
>> the package.
>> |-
>> |pckg_weight||int64_t||8|| The sum total weight of all transactions in
>> the package.
>> |-
>> |txns_length||CompactSize||1 or 3 bytes|| The number of transactions
>> provided.
>> |-
>> |txns||List of wtxids||txns_length * 32|| The wtxids of each transaction
>> in the package.
>> |}
>>
>>
>> 1. The "pckginfo1" message has the structure defined above, with
>>    pchCommand == "pckginfo1".
>>
>> 2. A "pckginfo1" message contains information about a version 1
>>    package (defined below), referenced by the wtxid of the transaction
>> it pertains to and the current blockhash.
>>
>> 3. Upon receipt of a "pckginfo1" message, the node should decide if it
>>    wants to validate the package, request transaction data if
>> necessary, etc.
>>
>> 4. Upon receipt of a malformed "pckginfo1" message or package that
>>    does not abide by the max_count, max_weight, or other rules
>> specified by the version agreed upon in the initial negotiation, the
>> sender should be disconnected.  If a node receives a "pckginfo1"
>> message for which the "pckg_fee" or "pckg_weight" do not reflect the
>> true total fees and weight, respectively, or the transactions in the
>> package, the message is malformed.
>>
>> 5. A node MUST NOT send a "pckginfo1" message that has not been
>>    requested by the recipient. Upon receipt of an unsolicited
>> "pckginfo1", a node should disconnect the sender.
>>
>> 6. A "pckginfo1" message should only be sent if both peers agreed to
>>    send version 1 packages in the version handshake. If a "pckginfo1"
>> message is received from a peer with which package relay was not
>> negotiated, the sender should be disconnected.
>>
>> =====MSG_PCKG1=====
>>
>> 1. A new inv type (MSG_PCKG1 == 0x6) is added, for use in inv messages
>>    and getdata requests pertaining to version 1 packages.
>>
>> 2. As an inv type, it indicates that both transaction data and version
>>    1 package information are available for the transaction. The
>> transaction is referenced by its wtxid. As a getdata request type, it
>> indicates that the sender wants package information for the
>> transaction.
>>
>> 3. Upon receipt of a "getdata" request for "MSG_PCKG1", the node
>>    should respond with the version 1 package corresponding to the
>> requested transaction and its current chain tip, or with NOTFOUND.
>> The node should not assume that the sender is requesting the
>> transaction data as well.
>>
>> ====Child With Parent Packages Rules====
>>
>> A child-with-unconfirmed-parents package sent between nodes must abide
>> by the rules below, otherwise the package is malformed and the sender
>> should be disconnected.
>>
>> A version 1 or ''child-with-unconfirmed-parents'' package can be
>> defined for any transaction that spends unconfirmed inputs. The child
>> can be thought of as the "representative" of the package. This package
>> can be uniquely identified by the transaction's wtxid and the current
>> chain tip block hash.
>>
>> A ''child-with-unconfirmed-parents'' package MUST be:
>>
>> 1. ''Sorted topologically.'' For every transaction t in the package,
>>    if any of t's parents are present in the package, the parent must
>> appear somewhere in the list before t. In other words, the
>> transactions must be sorted in ascending order of the number of
>> ancestors present in the package.
>>
>> 2. ''Only 1 child with unconfirmed parents.'' The package must consist
>>    of one transaction and its unconfirmed parents. There must not be
>> any other transactions in the package. Other dependency relationships
>> may exist within the package (e.g. one parent may spend the output of
>> another parent) provided that topological order is respected.
>>
>> 3. ''All unconfirmed parents.'' All of the child's unconfirmed parents
>>    must be present.
>>
>> 4. ''No conflicts.'' None of the transactions in the package may
>>    conflict with each other (i.e.  spend the same prevout).
>>
>> 5. ''Total fees and weight.'' The 'total_fee' and 'total_weight'
>>    fields must accurately represent the sum total of all transactions'
>> fees and weights as defined in BIP141, respectively.
>>
>> Not all of the child's parents must be present; the child transaction
>> may also spend confirmed inputs. However, if the child has confirmed
>> parents, they must not be in the package.
>>
>> While a child-with-unconfirmed-parents package is perhaps most
>> relevant when the child has a higher feerate than its parents, this
>> property is not required to construct a valid package.
>>
>> ====Clarifications====
>>
>> ''Q: Under what circumstances should a sender announce a
>> child-with-unconfirmed-parents package?''
>>
>> A child-with-unconfirmed-parents package for a transaction should be
>> announced when it meets the peer's fee filter but one or more of its
>> parents don't; a "inv(MSG_PCKG1)" instead of "inv(WTX)" should be sent
>> for the child. Each of the parents which meet the peer's fee filter
>> should still be announced normally.
>>
>> ''Q: What if a new block arrives in between messages?''
>>
>> A child-with-unconfirmed-parents package is defined for a transaction
>> based on the current chain state. As such, a new block extending the
>> tip may decrease the number of transactions in the package (i.e. if
>> any of the transaction's parents were included in the block). In a
>> reorg, the number of transactions in the package may decrease or
>> increase (i.e. if any of the transaction's parents were included in a
>> block in the previous chain but not the new one).
>>
>> If the new block arrives before the "getdata" or "pckginfo1", nothing
>> needs to change.
>>
>> If the new block arrives before "getpckgtxns" or before "pckgtxns",
>> the receiver may need to re-request package information if the block
>> contained a transaction in the package. If the block doesn't contain
>> any transactions in the package, whether it extends the previous tip
>> or causes a reorg, nothing needs to change.
>>
>> ''Q: Can "getpckgtxns" and "pckgtxns" messages contain only one
>> transaction?''
>>
>> Yes.
>>
>> ===Further Protocol Extensions===
>>
>> When introducing a new type of package, assign it a version number "n"
>> and use an additional "sendpackages" message during version handshake
>> to negotiate support for it. An additional package information message
>> "pckginfon" and inv type "MSG_PCKGn" should be defined for the type of
>> package.  However, "getpckgtxns" and "pckgtxns" do not need to be
>> changed.
>>
>> Example proposal for tx-with-unconfirmed-ancestors package relay: [19]
>>
>> ===Compatibility===
>>
>> Older clients remain fully compatible and interoperable after this
>> change. Clients implementing this protocol will only attempt to send
>> and request packages if agreed upon during the version handshake.
>>
>> ===Package Erlay===
>>
>> Clients using BIP330 reconciliation-based transaction relay (Erlay)
>> are able to use package relay without interference. In fact, a package
>> of transactions may be announced using both Erlay and package relay.
>> After reconciliation, if the initiator would have announced a
>> transaction by wtxid but also has package information for it, they may
>> send "inv(MSG_PCKG)" instead of "inv(WTX)".
>>
>> ===Rationale===
>>
>> ====P2P Message Design====
>>
>> These p2p messages are added for communication efficiency and, as
>> such, one should measure alternative solutions based on the resources
>> used to communicate (not necessarily trustworthy) information: We
>> would like to minimize network bandwidth, avoid downloading a
>> transaction more than once, avoid downloading transactions that are
>> eventually rejected, and minimize storage allocated for
>> not-yet-validated transactions.
>>
>> Consider these (plausible) scenarios in transaction relay:
>>
>> Alice (the "sender") is relaying transactions to Bob (the "receiver").
>> Alice's mempool has a minimum feerate of 1sat/vB and Bob's has a
>> minimum feerate of 3sat/vB. For simplicity, all transactions are
>> 1600Wu in virtual size and 500 bytes in serialized size. Apart from
>> the spending relationships specified, all other inputs are from
>> confirmed UTXOs.
>>
>> 1. Package {A, B} where A pays 0 satoshis and B pays 8000 satoshis in
>>    fees.
>>
>> 2. Package {C, D} where C pays 0 satoshis and D pays 1200 satoshis in
>>    fees.
>>
>> 3. Package {E, F, G, H, J} that pays 4000, 8000, 0, 2000, and 4000
>>    satoshis in fees, respectively.
>>
>> ====Alternative Designs Considered====
>>
>> ''Package Information Only:'' Just having "pckginfo" gives enough
>> information for the receiver to accept the package. Omit the
>> "getpckgtxns" and "pckgtxns" messages. While this option is a good
>> fallback if batched transaction download fails for some reason, it
>> shouldn't be used as the default because it 'always' requires storage
>> of unvalidated transactions.
>>
>> ''No Package Information Round:'' Instead of having a package
>> information round, just use the child's wtxid to refer to the package
>> and always send the entire package together. This would cause nodes to
>> redownload duplicate transactions.
>>
>> I have also created a slidedeck exploring various alternative designs
>> and some examples in which they fall flat [20]. Please feel free to
>> suggest other alternatives.
>>
>> ====Versioning System====
>>
>> This protocol should be extensible to support multiple types of
>> packages based on future desired use cases. Two "flavors" of
>> versioning were considered:
>>
>> 1. When package mempool acceptance is upgraded to support more types
>>    of packages, increment the version number (similar to Erlay).
>> During version handshake, peers negotiate which version of package
>> relay they will use by each sending one "sendpackages" message.
>>
>> 2. When introducing another type of package, assign a version number
>>    to it and announce it as an additional supported version (similar
>> to Compact Block Relay). During version handshake, peers send one
>> "sendpackages" message for each version supported.
>>
>> The second option was favored because it allows different parameters
>> for different versions.  For example, it should be possible to support
>> both "arbitrary topology but maximum 3-transaction" package as well as
>> "child-with-unconfirmed-parents with default mempool ancestor limits"
>> packages simultaneously.
>>
>> ==Acknowledgements==
>>
>> I hope to have made it abundantly clear that this proposal isn?t
>> inventing the concept of package relay, and in fact builds upon years
>> of work by many others, including Suhas Daftuar and Antoine Riard.
>>
>> Thank you to John Newbery and Martin Zumsande for input on the design.
>>
>> Thank you to Matt Corallo, Christian Decker, David Harding, Antoine
>> Poinsot, Antoine Riard, Gregory Sanders, Chris Stewart, Bastien
>> Teinturier, and others for input on the desired interface for
>> contracting protocols.
>>
>> Looking forward to hearing your thoughts!
>>
>> Best,
>> Gloria
>>
>> [0]:
>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019817.html
>> [1]:
>> https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-April/002639.html
>> [2]:
>> https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-June/002758.html
>> [3]:
>> https://github.com/t-bast/lightning-docs/blob/master/pinning-attacks.md
>> [4]:
>> https://github.com/revault/practical-revault/blob/master/transactions.md#cancel_tx
>> [5]:
>> https://github.com/discreetlogcontracts/dlcspecs/blob/master/Transactions.md#refund-transaction
>> [6]: https://gist.github.com/instagibbs/60264606e181451e977e439a49f69fe1
>> [7]:
>> https://btctranscripts.com/adopting-bitcoin/2021/2021-11-16-gloria-zhao-transaction-relay-policy/#lightning-attacks
>> [8]: https://youtu.be/fbWSQvJjKFs?t=1438
>> [9]:
>> https://www.reddit.com/r/Bitcoin/comments/unew4e/looks_like_70_mvb_of_transactions_just_got_dumped/
>> [10]: https://github.com/bitcoin/bitcoin/pull/7594
>> [11]: https://github.com/bitcoin/bitcoin/pull/7600
>> [12]: https://github.com/bitcoin/bitcoin/pull/6455#issuecomment-122716820
>> [13]: https://gist.github.com/sdaftuar/8756699bfcad4d3806ba9f3396d4e66a
>> [14]: https://github.com/bitcoin/bitcoin/issues/14895
>> [15]: https://github.com/bitcoin/bitcoin/pull/16401
>> [16]: https://github.com/bitcoin/bitcoin/pull/19621
>> [17]:
>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019464.html
>> [18]: https://github.com/users/glozow/projects/5/views/4?layout=board
>> [19]: https://gist.github.com/glozow/9b321cd3ef6505135c763112033ff2a7
>> [20]:
>> https://docs.google.com/presentation/d/1B__KlZO1VzxJGx-0DYChlWawaEmGJ9EGApEzrHqZpQc/edit?usp=sharing
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221101/d77fa967/attachment-0001.html>

From aj at erisian.com.au  Wed Nov  2 03:07:45 2022
From: aj at erisian.com.au (Anthony Towns)
Date: Wed, 2 Nov 2022 13:07:45 +1000
Subject: [bitcoin-dev] On mempool policy consistency
In-Reply-To: <CAB3F3Dt=2hDXXw6Jz9QwnotkNLyGdZn9GZLHFXu0Dnyz3tsc0w@mail.gmail.com>
References: <Y1nIKjQC3DkiSGyw@erisian.com.au>
 <CAFp6fsFm06J2G1=3ojQvcL9gbEbQ41C4rmf3=Jkm9Qm0VBhhKw@mail.gmail.com>
 <CAB3F3Dt=2hDXXw6Jz9QwnotkNLyGdZn9GZLHFXu0Dnyz3tsc0w@mail.gmail.com>
Message-ID: <Y2HfAVTgj6qZb49q@erisian.com.au>

On Mon, Oct 31, 2022 at 12:25:46PM -0400, Greg Sanders via bitcoin-dev wrote:
> For 0-conf services we have potential thieves who are willing
> to *out-bid themselves* to have funds come back to themselves. It's not a
> "legitimate" use-case, but a rational one.

I think that's a huge oversimplification of "rational" -- otherwise
you might as well say that deliberately pinning txs is also rational,
because it allows the person doing the pinning to steal funds from their
counterparty by forcing a timeout to expire.

There's no need for us as developers, or us as node operators, to support
every use case that some individual might find rational at some point in
time. After all, it might be individually rational for someone to want the
subsidy to stop decreasing, or to include 8MB of transactions per block.

Note that it's also straightforwardly rational and incentive compatible
for miners to not want this patch to be available, under the following
scenario:

 - a significant number of on-chain txs are for zeroconf services
 - fee income would be reduced if zeroconf services went away
   (both directly due to the absence of zeroconf payments, and by
   reducing mempool pressure, reducing fee income from the on-chain txs
   that remain)
 - miners adopting fullrbf would cause zeroconf services to go away,
   (and won't enable a comparable volume of new services that generates
   comparable transaction volume)
 - including the option in core would make other miners adopting
   fullrbf more likely

I think the first three of those are fairly straightforward and objective,
at least at this point in time. The last is just a risk; but without
any counterbalancing benefit, why take it?

Gaining a few thousand sats due to high feerate replacement txs from
people exploiting zeroconf services for a few months before all those
services shutdown doesn't make up for the lost fee income over the months
or years it might have otherwise taken people to naturally switch to
some better alternative.

Even if fullrbf worked for preventing pinning that likely doesn't directly
result in much additional fee income: once you know that pinning doesn't
work, you just don't try it, which means there's no opportunity for
miners to profit from a bidding war from the pinners counterparties
repeatedly RBFing their preferred tx to get it mined.

That also excludes second order risks: if you can't do zeroconf with BTC
anymore, do you switch to ERC20 tokens, and then trade your BTC savings
for ETH or USDT, and do enough people do that to lower the price of BTC?
If investors see BTC being less used for payments, does that lower their
confidence in bitcoin's future, and cause them to sell?

> Removing a
> quite-likely-incentive-compatible option from the software just encourages
> miners to adopt an additional patch

Why shouldn't miners adopt an additional patch if they want some unusual
functionality?

Don't we want/expect miners to have the ability to change the code in
meaningful ways, at a minimum to be able to cope with the scenario where
core somehow gets coopted and releases bad code, or to be able to deal
with the case where an emergency patch is needed?

Is there any evidence miners even want this option? Peter suggested
that some non-signalling replacements were being mined already [0], but
as far as I can see [1] all of those are simply due to the transaction
they replaced not having propagated in the first place (or having been
evicted somehow? hard to tell without any data on the original tx).

[0] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-October/021012.html
[1] https://github.com/bitcoin/bitcoin/pull/26287#issuecomment-1292692367

> 2) Forcing miners to honor fees left on the table with respect to 0-conf,
> or forcing them to run a custom patchset to go around it, is a step
> backwards.

As you already acknowledged, any miner that wants this behaviour can just
pick up the patch (or could run Knots, which already has the feature
enabled by default). It's simply false to say miners are being forced
to do anything, no matter what we do here. 

If the direction you're facing is one where you're moving towards making
life easier for people to commit fraud, and driving away businesses
that aren't doing anyone harm, without achieving anything much else;
then taking a step backwards seems like a sensible thing to do to me.

(I remain optimistic about coming up with better RBF policy, and willing
to be gung ho about everyone switching over to it even if it does kill
off zeroconf, provided it actually does some good and we give people 6
months or more notice that it's definitely happening and what exactly
the new rules will be, though)

Cheers,
aj

From aj at erisian.com.au  Wed Nov  2 03:52:09 2022
From: aj at erisian.com.au (Anthony Towns)
Date: Wed, 2 Nov 2022 13:52:09 +1000
Subject: [bitcoin-dev] Preventing/detecting pinning of jointly funded txs
Message-ID: <Y2HpaWnAC5dIGkx+@erisian.com.au>

On Fri, Oct 28, 2022 at 03:21:53AM +1000, Anthony Towns via bitcoin-dev wrote:
> What should folks wanting to do coinjoins/dualfunding/dlcs/etc do to
> solve that problem if they have only opt-in RBF available?

ref: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-October/021124.html

So, having a go at answering my own question.

I think ultimately the scenario here is:

 * you have a joint funding protocol, where everyone says "here's
   an unspent utxo that will be my contribution", collaborates on signing
   a transaction spending all those utxos, and then broadcasts it

 * everyone jointly agrees to pay some amount in fees for that
   transaction, targeting confirmation within N blocks

 * the goal is to have the transaction confirm, obviously; but it's also
   acceptable to discover a conflicting transaction, as that will
   demonstrate that a particular participant has been dishonest (their
   utxo was not "unspent"), allowing the overall protocol to make progress

The question then is how much effort do you have to go to to make such a
protocol work?

As an extreme example, you could always have each participant maintain
a dedicated amount of hashpower: eg, if each participant individually
controls 0.5% of hashpower, then having two honest participants would
give you a 75% chance of confirmation within 137 blocks (roughly a day),
even if your transaction failed to relay at all, and the only way to
prevent confirmation is for a conflicting transaction to be confirmed
earlier. Of course, needing to have 0.5% of hashpower would mean fewer
than 200 people globally could participate in such a protocol, and
requires something like $10M in capital investment just for ASICs in
order to participate.

I think the next step from that pretty much requires introducing the
assumption that the vast majority of the bitcoin p2p network (both nodes
and hashrate) will accept your transaction, at least in a world where all
your collaborators are honest and don't create conflicting transactions.
You can limit that assumption a little bit, but without most p2p peers
being willing to relay your tx, you start having privacy issues; and
without most miners being willing to mine your tx, you start getting
problems with predicting fees. And in any event, I don't think anyone's
trying to make weird transactions here, just get their otherwise normal
transactions to actually confirm.

I think the same approach used to detect double spend races by people
accepting zeroconf would work here too. That is setup a couple of
anonymous bitcoin nodes, let them sit for a couple of weeks so their
mempools are realistic, then when you broadcast a jointly funded
transaction, query their mempools: if your new tx made it there, it
likely made it to mining pools too, and you're fine; if it didn't, then
the transaction that's blocking it almost certainly did, so you can find
out what that is and can go from there.

(If you don't see either your tx, or a conflicting one, then it likely
means the nodes that broadcasted your tx are being sybil attacked, either
because their peers are directly controlled by an attacker, or they've
been identified by an attacker and attacked in some other way; presumably
you could pick a couple of node that have been confirmed by both your
anonymous nodes' as valid and reachable, and connect to them to break
out of the sybil attack; if that doesn't work either, you probably need
to change ISPs or put your active node via a (different) VPN provider...)

Your capital expenses are much lower that way: perhaps on the order of
$20/month to run a couple of nodes on AWS or linode or similar.

But, you might say, what if I don't even want to run multiple bitcoin
nodes 24/7 indefinitely? Can we outsource that, like we outsource mining
by paying tx fees?

That seems harder, particularly if you want to avoid whoever you're
outsourcing too from associating you with the jointly funded transaction
you're interested in.

If you're *not* worried about that association, it's probably easy:
just find some public explorers, and see if they list any conflicts in
their mempool, or use the "broadcast tx" feature and see if it gives an
error identifying the conflicting transaction.

I think it's probably hard to make that behaviour a normal part of p2p tx
relay though: if someone's trying to relay tx T but you reject it
because of a conflicting tx C; then it's easy to tell the node that
first relayed T to you about C -- but how does that information get back
to the original broadcaster?

One way would be to broadcast "C" back to whoever announced T to you,
and let C propogate all the way back to whoever originally proposed T --
but that only works if everyone's running a mempool policy where there's
a total ordering for tx replacement, ie for any conflicting txs, either
T replaces C or C replaces T, and that's not something we have now or
would have even with full RBF, and seems pretty hard to actually achieve.
(And if it was achieved, you could just keep replacing T with a more
attractive T' so that it did eventually replace C)

Another way might be to have the original broadcaster retry the broadcast:
connect to new peers, reannounce T, and see what happens.  Then eventually
they'll connect to a peer that has C in their mempool, and just needs a
"reject" message of some kind that can identify C.  But in that case,
the peer that's going to send the reject message needs to be able to
efficiently associate T back to C, even though it doesn't have T in
the mempool -- it won't want to redownload T each time, because that's
a waste of bandwidth, and it can't re-validate T to find the conflict
fresh without having a copy of T.

Using BIP 37 mempool filters or something might be an approach if there
are plenty of nodes around that _are_ willing to dedicate extra resources
to helping people find potentially conflicting txs.  Unfortunately that
probably is pretty bad for privacy: if your adversary is blocking your
coinjoin T with a pinned tx C, then the fact that you've asked for a
filter that happens to match C is probably a good indication that you're
involved in the coinjoin T; and there's a decent chance that the only
people will to dedicate the extra resources to offer those services to
the public will be people who want to invade your privacy...

A problem with mempool filters (or telling other nodes what's in your
mempool in general) is that that can provide a way for attackers to
identify who your peers are: if you create a bunch of conflicting txs,
and give a different one to many nodes other than you, then see which
tx you end up with, that identifies which peers are close to you, and
that information could be used to attack those peers, which in turn may
allow more effective sybil attacks against you.

So I think my best answer is:

 - if you really want to do things with untrusted peers in bitcoin,
   investing in hashpower maybe isn't that unreasonable a thing to
   do. $10M in capital giving you the ability to usually make progress
   within a day even if everyone else dislikes you? surprisingly
   reasonable, especially if more progress is made on stratumv2...

 - if you don't care about privacy (eg, you're funding a lightning
   channel that's going to be gossiped anyway), just query an explorer
   (or some other centralised service) to find out the conflicting tx
   and go from there.

 - if you do care about privacy, run a few "anonymous" bitcoind nodes
   that don't announce transactions, and see what their mempool
   contains.

 - we can probably make it easier to run anonymous bitcoind nodes
   by making transaction broadcasts more private (tor/i2p? dandelion? have
   lightning nodes send channel open/close txs to another lightning
   node to announce to bitcoin p2p?) -- for cases where you're already
   running a bitcoin node 24/7 (or trusting someone else that does), I
   think that gives you a pretty good method of either being confident
   your tx made it to a decent percentage of hashrate, or spotting a
   conflicting tx to be able to assign blame

Anyone got any improvements on the above?

Cheers,
aj

From pete at petertodd.org  Wed Nov  2 09:26:27 2022
From: pete at petertodd.org (Peter Todd)
Date: Wed, 2 Nov 2022 05:26:27 -0400
Subject: [bitcoin-dev] Announcement: Full-RBF Miner Bounty
Message-ID: <Y2I3w8O5X55sD/3C@petertodd.org>

I'm now running a full-RBf bounty program for miners.

tl;dr: I'm broadcasting full-RBF replacements paying extremely high fees to
reward miners that turn on full-RBF. I'm starting small, just ~$100/block in
times of congestion. Miner and pool profit margins are pretty small, on the
order of $1k/block in many cases, so I know it doesn't take that much more
money to make a difference.

Why should you do this? Full-RBF/zeroconf has been discussed to death. But
tl;dr: You'll earn more money, and help transition Bitcoin to a more secure
mempool policy based on economic incentives rather than trust.


If you're a miner and want to participate, the easiest way to so is to use the
mempoolfullrbf=1 option in the upcoming Bitcoin Core v24 release (eg the
24.0rc3 tag), or use the mempoolreplacement=fee option in Bitcoin Knots.

You can also just modify the code yourself by removing the opt-in RBF check.
For example against the v23.0 tag:

    $ git diff
    diff --git a/src/validation.cpp b/src/validation.cpp
    index 214112e2b..44c364623 100644
    --- a/src/validation.cpp
    +++ b/src/validation.cpp
    @@ -736,7 +736,7 @@ bool MemPoolAccept::PreChecks(ATMPArgs& args, Workspace& ws)
                     // check all unconfirmed ancestors; otherwise an opt-in ancestor
                     // might be replaced, causing removal of this descendant.
                     if (!SignalsOptInRBF(*ptxConflicting)) {
    -                    return state.Invalid(TxValidationResult::TX_MEMPOOL_POLICY, "txn-mempool-conflict");
    +                    // return state.Invalid(TxValidationResult::TX_MEMPOOL_POLICY, "txn-mempool-conflict");
                     }
     
                     ws.m_conflicts.insert(ptxConflicting->GetHash());

Once you've enabled full-RBF, you need a full-RBF peer. I'm running a few of
them:

    cup.nop.lol
    mug.nop.lol
    jar.nop.lol
    jug.nop.lol

These nodes run a preferential peering patch (https://github.com/bitcoin/bitcoin/pull/25600)
to ensure that full-RBF nodes are interconnected to each other and replacements
can easily propagate. Also feel free to contact me if you'd like to peer with a
private node.


If you'd like to donate to this effort, send BTC to
bc1qagmufdn6rf80kj3faw4d0pnhxyr47sevp3nj9m


...and yes, I'm well aware that miners could collect this bounty in other ways,
eg by raising minimum fees. Doing that also breaks zeroconf, so I'm not too
concerned.

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221102/7bcd9699/attachment.sig>

From antoine.riard at gmail.com  Wed Nov  2 02:21:59 2022
From: antoine.riard at gmail.com (Antoine Riard)
Date: Tue, 1 Nov 2022 22:21:59 -0400
Subject: [bitcoin-dev] Solving Multi-Party Flows Pinning with Opt-in
	Full-RBF Spent-nVersion Signaling
Message-ID: <CALZpt+GZAd-vYMzUMicg0c9OyyWExtT5EH61Hms6NNOM19ddZA@mail.gmail.com>

Hi list,

Reading Suhas's post on mempool policy consistency rules, and the grounded
suggestion that as protocol developers we should work on special policy
rules to support each reasonable use case on the network rather to arbiter
between class of use-cases in the design of an
unified set of rules, reminded me there is another solution to solve
multi-party funding pinning rather than wide deployment of fullrbf. This
was communicated to me a while back, and it was originally dismissed
because of the privacy trade-offs (and potential slight fees overhead
cost). However, if widely adopted, they might sound acceptable to
contracting protocol developers and operators.

## The Problem: Pinning Contracting Protocols Funding Flows with Opt-out
Double-Spend

As originally laid out [0], multi-party collaborative flows
(coinjoin/dual-funding/swaps/splicing/etc), where every participant
contributes at least one input, are suffering from a low-cost and
high-success DoS vector with asymmetric damages. E.g with lightning
interactive transaction construction protocols limits of 252 inputs, 1
single input can bleed the timevalue of the remaining 251 inputs, or engage
in a MEV attack where the fee-bumping entity is lured to inflate feerate
beyond the current blockspace demand. The attack can be hidden and a
posteriori assigning blame consistently stays an open question in the lack
of a consensus mechanism between participants on the network mempools
states.

The issue lies in the fact that participants joining inputs together don't
have control, or even view, of the replacement signaling of any potential
double-spend of the other participants inputs. Indeed the opt-in fullrbf
signaling is enforced based on the nSequence field, and this one is fully
malleable by the UTXO spender. There is no current mechanism to require
replacement signaling provable to a third-party only on the knowledge of
the UTXO spents.

# The Solution: Opt-in Full-Replace-by-Fee Spent-nVersion Signaling

A new policy is specified in a new way a transaction can signal that it is
replaceable.

1. A confirmed transaction is considered to have opted in to allowing
replacement of any of its spends (or their descendants), if the last bit of
the nVersion field is set.

Rational: The future replacement status of any UTXO spend can be determined
by inspecting the nVersion, therefore protecting the collaborative
participants of a multi-party flows that the target transaction should
propagate to the miners, if the fee/feerate offered are the best ones
without opt-out based pinning. It can be required the UTXOs to have few
confirmations in case of shallow reorgs to increase DoS protection.

## Solution trade-offs

On the validation-side, there is one engineering issue, as I think there is
no access to the spent nversion fields by the mempool logic. This would
presume we add some new cache of all the confirmed UTXOs, so ~50M * 4bytes,
300 MB of additional state for policy-enforcing full-nodes. I don't know if
there is another strong drawback, even the reorg logic the replaceable
spends shouldn't be evicted if the confirmed ancestor is back to the
mempool, as mempool validity shouldn't be reevaluated before a replacement
candidate shows up. A fee penalty could be requested for nVersion-signaling
transactions to compensate for the additional state stored by full-node
operators (even if obviously they're not the ones earning the fees).

For the contracting protocols wallets, as you don't know in advance which
coins are going to be used for a collaborative flow, you're better off to
mark all your coins nVersion fields opting fullrbf. Otherwise, you will
have to go through an on-chain fee cost to change the replacement status of
the spends of your coins. However, this policy bookmarking comes as a
protocol fingerprint leak for an observer of the transaction logs. If all
the second-layers used by default, this is constituting a single anonymity
set, though it might still be the privacy gains we're harvesting from
Taproot output usage in the optimistic case (e.g in Lightning no commitment
+ HTLC transactions broadcast).

For the zeroconf operators, assuming they have access to the UTXO set, they
can inspect the receiving transactions ancestors nVersion fields, and sort
those transactions in the wider set of the replaceable ones, as they're
currently doing for BIP125 opt-in ones.

Long-term, the annoying privacy issue and the assumption that any wallet
will be a Lightning one could lead to the majority of wallets signaling RBF
for their spends. Therefore making those wallets incompatible with zeroconf
services, slowly economically outlawing them. From my perspective, though
it might be a simplification, it sounds an alternative full rbf way
forward, where rather than having miners deciding on the policy
enforcement, we let the users decide with their coins. However, this new
policy enforcement efficiency is still dependent on the existence of relay
paths and support at the endpoints that matter, the miner mempools. So in
fine we might have to realize incentive alignment with hashrate is what
matters in terms of transaction-relay rules ?

Credit to Greg Maxwell for this idea.

Cheers,
Antoine

[0]
https://lists.linuxfoundation.org/pipermail/lightning-dev/2021-May/003033.html
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221101/7190a0df/attachment-0001.html>

From gsanders87 at gmail.com  Wed Nov  2 13:32:49 2022
From: gsanders87 at gmail.com (Greg Sanders)
Date: Wed, 2 Nov 2022 09:32:49 -0400
Subject: [bitcoin-dev] On mempool policy consistency
In-Reply-To: <Y2HfAVTgj6qZb49q@erisian.com.au>
References: <Y1nIKjQC3DkiSGyw@erisian.com.au>
 <CAFp6fsFm06J2G1=3ojQvcL9gbEbQ41C4rmf3=Jkm9Qm0VBhhKw@mail.gmail.com>
 <CAB3F3Dt=2hDXXw6Jz9QwnotkNLyGdZn9GZLHFXu0Dnyz3tsc0w@mail.gmail.com>
 <Y2HfAVTgj6qZb49q@erisian.com.au>
Message-ID: <CAB3F3DsHGSv1A6kHq_2F5OkugSxUpvhCWz=MvJLRX=iSxXeBPw@mail.gmail.com>

> I think that's a huge oversimplification of "rational" -- otherwise
you might as well say that deliberately pinning txs is also rational,
because it allows the person doing the pinning to steal funds from their
counterparty by forcing a timeout to expire.

To be clear, a pinner is attempting to *not* pay
the most fees, by definition. If we're somehow sure something is a pin,
we should not allow it, because miners rationally do not want it vs
an "honest" bid for fees. V3 design is one attempt to carve out a safe
space for fee bidding. Carving out a safe space for *non-bidding* is not the
same thing.

I think this mostly boils down having knobs or not. I'm fine with knobs
with paternalistic defaults, especially when a non-zero percentage of users
disagree with a value in either direction.

Greg

On Tue, Nov 1, 2022 at 11:07 PM Anthony Towns <aj at erisian.com.au> wrote:

> On Mon, Oct 31, 2022 at 12:25:46PM -0400, Greg Sanders via bitcoin-dev
> wrote:
> > For 0-conf services we have potential thieves who are willing
> > to *out-bid themselves* to have funds come back to themselves. It's not a
> > "legitimate" use-case, but a rational one.
>
> I think that's a huge oversimplification of "rational" -- otherwise
> you might as well say that deliberately pinning txs is also rational,
> because it allows the person doing the pinning to steal funds from their
> counterparty by forcing a timeout to expire.
>
> There's no need for us as developers, or us as node operators, to support
> every use case that some individual might find rational at some point in
> time. After all, it might be individually rational for someone to want the
> subsidy to stop decreasing, or to include 8MB of transactions per block.
>
> Note that it's also straightforwardly rational and incentive compatible
> for miners to not want this patch to be available, under the following
> scenario:
>
>  - a significant number of on-chain txs are for zeroconf services
>  - fee income would be reduced if zeroconf services went away
>    (both directly due to the absence of zeroconf payments, and by
>    reducing mempool pressure, reducing fee income from the on-chain txs
>    that remain)
>  - miners adopting fullrbf would cause zeroconf services to go away,
>    (and won't enable a comparable volume of new services that generates
>    comparable transaction volume)
>  - including the option in core would make other miners adopting
>    fullrbf more likely
>
> I think the first three of those are fairly straightforward and objective,
> at least at this point in time. The last is just a risk; but without
> any counterbalancing benefit, why take it?
>
> Gaining a few thousand sats due to high feerate replacement txs from
> people exploiting zeroconf services for a few months before all those
> services shutdown doesn't make up for the lost fee income over the months
> or years it might have otherwise taken people to naturally switch to
> some better alternative.
>
> Even if fullrbf worked for preventing pinning that likely doesn't directly
> result in much additional fee income: once you know that pinning doesn't
> work, you just don't try it, which means there's no opportunity for
> miners to profit from a bidding war from the pinners counterparties
> repeatedly RBFing their preferred tx to get it mined.
>
> That also excludes second order risks: if you can't do zeroconf with BTC
> anymore, do you switch to ERC20 tokens, and then trade your BTC savings
> for ETH or USDT, and do enough people do that to lower the price of BTC?
> If investors see BTC being less used for payments, does that lower their
> confidence in bitcoin's future, and cause them to sell?
>
> > Removing a
> > quite-likely-incentive-compatible option from the software just
> encourages
> > miners to adopt an additional patch
>
> Why shouldn't miners adopt an additional patch if they want some unusual
> functionality?
>
> Don't we want/expect miners to have the ability to change the code in
> meaningful ways, at a minimum to be able to cope with the scenario where
> core somehow gets coopted and releases bad code, or to be able to deal
> with the case where an emergency patch is needed?
>
> Is there any evidence miners even want this option? Peter suggested
> that some non-signalling replacements were being mined already [0], but
> as far as I can see [1] all of those are simply due to the transaction
> they replaced not having propagated in the first place (or having been
> evicted somehow? hard to tell without any data on the original tx).
>
> [0]
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-October/021012.html
> [1] https://github.com/bitcoin/bitcoin/pull/26287#issuecomment-1292692367
>
> > 2) Forcing miners to honor fees left on the table with respect to 0-conf,
> > or forcing them to run a custom patchset to go around it, is a step
> > backwards.
>
> As you already acknowledged, any miner that wants this behaviour can just
> pick up the patch (or could run Knots, which already has the feature
> enabled by default). It's simply false to say miners are being forced
> to do anything, no matter what we do here.
>
> If the direction you're facing is one where you're moving towards making
> life easier for people to commit fraud, and driving away businesses
> that aren't doing anyone harm, without achieving anything much else;
> then taking a step backwards seems like a sensible thing to do to me.
>
> (I remain optimistic about coming up with better RBF policy, and willing
> to be gung ho about everyone switching over to it even if it does kill
> off zeroconf, provided it actually does some good and we give people 6
> months or more notice that it's definitely happening and what exactly
> the new rules will be, though)
>
> Cheers,
> aj
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221102/a1614798/attachment.html>

From gsanders87 at gmail.com  Wed Nov  2 13:46:24 2022
From: gsanders87 at gmail.com (Greg Sanders)
Date: Wed, 2 Nov 2022 09:46:24 -0400
Subject: [bitcoin-dev] Preventing/detecting pinning of jointly funded txs
In-Reply-To: <Y2HpaWnAC5dIGkx+@erisian.com.au>
References: <Y2HpaWnAC5dIGkx+@erisian.com.au>
Message-ID: <CAB3F3DsFk1UZuaNmy9_1w1bohLozj4fKaZFn7EO3=jXAn7zdrg@mail.gmail.com>

Assigning blame here seems to be the paramount concern here. If we can
assign blame, most coinjoin-like protocols can terminate in bounded block
time, assuming fees are properly set.

It's also worth noting that in coinjoin cases, they're obviously coinjoins,
so pinging explorers over Tor HS seems purely additive to me. The use-cases
that can't use it are other privacy methods like coinswap and similar,
where there's no blockchain indication anything different is happening. The
larger the coinjoin, the more potential honest users, the more potential
for a duplicitous double-spend to be gossiped among those peers.

For dual funding LN channels, that number is pretty small(2), so I suspect
the DoS concerns are fairly subtle. Might be worth talking to
CLN/Eclair/Other LN teams that are working through those subtleties as we
speak.

Greg

On Tue, Nov 1, 2022 at 11:52 PM Anthony Towns via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> On Fri, Oct 28, 2022 at 03:21:53AM +1000, Anthony Towns via bitcoin-dev
> wrote:
> > What should folks wanting to do coinjoins/dualfunding/dlcs/etc do to
> > solve that problem if they have only opt-in RBF available?
>
> ref:
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-October/021124.html
>
> So, having a go at answering my own question.
>
> I think ultimately the scenario here is:
>
>  * you have a joint funding protocol, where everyone says "here's
>    an unspent utxo that will be my contribution", collaborates on signing
>    a transaction spending all those utxos, and then broadcasts it
>
>  * everyone jointly agrees to pay some amount in fees for that
>    transaction, targeting confirmation within N blocks
>
>  * the goal is to have the transaction confirm, obviously; but it's also
>    acceptable to discover a conflicting transaction, as that will
>    demonstrate that a particular participant has been dishonest (their
>    utxo was not "unspent"), allowing the overall protocol to make progress
>
> The question then is how much effort do you have to go to to make such a
> protocol work?
>
> As an extreme example, you could always have each participant maintain
> a dedicated amount of hashpower: eg, if each participant individually
> controls 0.5% of hashpower, then having two honest participants would
> give you a 75% chance of confirmation within 137 blocks (roughly a day),
> even if your transaction failed to relay at all, and the only way to
> prevent confirmation is for a conflicting transaction to be confirmed
> earlier. Of course, needing to have 0.5% of hashpower would mean fewer
> than 200 people globally could participate in such a protocol, and
> requires something like $10M in capital investment just for ASICs in
> order to participate.
>
> I think the next step from that pretty much requires introducing the
> assumption that the vast majority of the bitcoin p2p network (both nodes
> and hashrate) will accept your transaction, at least in a world where all
> your collaborators are honest and don't create conflicting transactions.
> You can limit that assumption a little bit, but without most p2p peers
> being willing to relay your tx, you start having privacy issues; and
> without most miners being willing to mine your tx, you start getting
> problems with predicting fees. And in any event, I don't think anyone's
> trying to make weird transactions here, just get their otherwise normal
> transactions to actually confirm.
>
> I think the same approach used to detect double spend races by people
> accepting zeroconf would work here too. That is setup a couple of
> anonymous bitcoin nodes, let them sit for a couple of weeks so their
> mempools are realistic, then when you broadcast a jointly funded
> transaction, query their mempools: if your new tx made it there, it
> likely made it to mining pools too, and you're fine; if it didn't, then
> the transaction that's blocking it almost certainly did, so you can find
> out what that is and can go from there.
>
> (If you don't see either your tx, or a conflicting one, then it likely
> means the nodes that broadcasted your tx are being sybil attacked, either
> because their peers are directly controlled by an attacker, or they've
> been identified by an attacker and attacked in some other way; presumably
> you could pick a couple of node that have been confirmed by both your
> anonymous nodes' as valid and reachable, and connect to them to break
> out of the sybil attack; if that doesn't work either, you probably need
> to change ISPs or put your active node via a (different) VPN provider...)
>
> Your capital expenses are much lower that way: perhaps on the order of
> $20/month to run a couple of nodes on AWS or linode or similar.
>
> But, you might say, what if I don't even want to run multiple bitcoin
> nodes 24/7 indefinitely? Can we outsource that, like we outsource mining
> by paying tx fees?
>
> That seems harder, particularly if you want to avoid whoever you're
> outsourcing too from associating you with the jointly funded transaction
> you're interested in.
>
> If you're *not* worried about that association, it's probably easy:
> just find some public explorers, and see if they list any conflicts in
> their mempool, or use the "broadcast tx" feature and see if it gives an
> error identifying the conflicting transaction.
>
> I think it's probably hard to make that behaviour a normal part of p2p tx
> relay though: if someone's trying to relay tx T but you reject it
> because of a conflicting tx C; then it's easy to tell the node that
> first relayed T to you about C -- but how does that information get back
> to the original broadcaster?
>
> One way would be to broadcast "C" back to whoever announced T to you,
> and let C propogate all the way back to whoever originally proposed T --
> but that only works if everyone's running a mempool policy where there's
> a total ordering for tx replacement, ie for any conflicting txs, either
> T replaces C or C replaces T, and that's not something we have now or
> would have even with full RBF, and seems pretty hard to actually achieve.
> (And if it was achieved, you could just keep replacing T with a more
> attractive T' so that it did eventually replace C)
>
> Another way might be to have the original broadcaster retry the broadcast:
> connect to new peers, reannounce T, and see what happens.  Then eventually
> they'll connect to a peer that has C in their mempool, and just needs a
> "reject" message of some kind that can identify C.  But in that case,
> the peer that's going to send the reject message needs to be able to
> efficiently associate T back to C, even though it doesn't have T in
> the mempool -- it won't want to redownload T each time, because that's
> a waste of bandwidth, and it can't re-validate T to find the conflict
> fresh without having a copy of T.
>
> Using BIP 37 mempool filters or something might be an approach if there
> are plenty of nodes around that _are_ willing to dedicate extra resources
> to helping people find potentially conflicting txs.  Unfortunately that
> probably is pretty bad for privacy: if your adversary is blocking your
> coinjoin T with a pinned tx C, then the fact that you've asked for a
> filter that happens to match C is probably a good indication that you're
> involved in the coinjoin T; and there's a decent chance that the only
> people will to dedicate the extra resources to offer those services to
> the public will be people who want to invade your privacy...
>
> A problem with mempool filters (or telling other nodes what's in your
> mempool in general) is that that can provide a way for attackers to
> identify who your peers are: if you create a bunch of conflicting txs,
> and give a different one to many nodes other than you, then see which
> tx you end up with, that identifies which peers are close to you, and
> that information could be used to attack those peers, which in turn may
> allow more effective sybil attacks against you.
>
> So I think my best answer is:
>
>  - if you really want to do things with untrusted peers in bitcoin,
>    investing in hashpower maybe isn't that unreasonable a thing to
>    do. $10M in capital giving you the ability to usually make progress
>    within a day even if everyone else dislikes you? surprisingly
>    reasonable, especially if more progress is made on stratumv2...
>
>  - if you don't care about privacy (eg, you're funding a lightning
>    channel that's going to be gossiped anyway), just query an explorer
>    (or some other centralised service) to find out the conflicting tx
>    and go from there.
>
>  - if you do care about privacy, run a few "anonymous" bitcoind nodes
>    that don't announce transactions, and see what their mempool
>    contains.
>
>  - we can probably make it easier to run anonymous bitcoind nodes
>    by making transaction broadcasts more private (tor/i2p? dandelion? have
>    lightning nodes send channel open/close txs to another lightning
>    node to announce to bitcoin p2p?) -- for cases where you're already
>    running a bitcoin node 24/7 (or trusting someone else that does), I
>    think that gives you a pretty good method of either being confident
>    your tx made it to a decent percentage of hashrate, or spotting a
>    conflicting tx to be able to assign blame
>
> Anyone got any improvements on the above?
>
> Cheers,
> aj
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221102/6a80b055/attachment-0001.html>

From gsanders87 at gmail.com  Wed Nov  2 13:58:59 2022
From: gsanders87 at gmail.com (Greg Sanders)
Date: Wed, 2 Nov 2022 09:58:59 -0400
Subject: [bitcoin-dev] Solving Multi-Party Flows Pinning with Opt-in
 Full-RBF Spent-nVersion Signaling
In-Reply-To: <CALZpt+GZAd-vYMzUMicg0c9OyyWExtT5EH61Hms6NNOM19ddZA@mail.gmail.com>
References: <CALZpt+GZAd-vYMzUMicg0c9OyyWExtT5EH61Hms6NNOM19ddZA@mail.gmail.com>
Message-ID: <CAB3F3DsSpyAVz+_7buznG5GFRZ8yDDKRneBg4KBJb1MD4Zk_VQ@mail.gmail.com>

My idea, which I hated and didn't propose, was to mark utxos specifically
for this exact purpose, but this is extremely ugly from a wallet/consensus
perspective. nVersion is cleaner(well, except the below issue), at the cost
of forcibly marking all utxos in a transaction the same way.

> On the validation-side, there is one engineering issue, as I think there
is no access to the spent nversion fields by the mempool logic.

I don't think Core tracks this value in the utxo set either, because
currently there's no use-case for it today? Am I mistaken?

/**
 * A UTXO entry.
 *
 * Serialized format:
 * - VARINT((coinbase ? 1 : 0) | (height << 1))
 * - the non-spent CTxOut (via TxOutCompression)
 */

Greg


On Wed, Nov 2, 2022 at 6:27 AM Antoine Riard via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Hi list,
>
> Reading Suhas's post on mempool policy consistency rules, and the grounded
> suggestion that as protocol developers we should work on special policy
> rules to support each reasonable use case on the network rather to arbiter
> between class of use-cases in the design of an
> unified set of rules, reminded me there is another solution to solve
> multi-party funding pinning rather than wide deployment of fullrbf. This
> was communicated to me a while back, and it was originally dismissed
> because of the privacy trade-offs (and potential slight fees overhead
> cost). However, if widely adopted, they might sound acceptable to
> contracting protocol developers and operators.
>
> ## The Problem: Pinning Contracting Protocols Funding Flows with Opt-out
> Double-Spend
>
> As originally laid out [0], multi-party collaborative flows
> (coinjoin/dual-funding/swaps/splicing/etc), where every participant
> contributes at least one input, are suffering from a low-cost and
> high-success DoS vector with asymmetric damages. E.g with lightning
> interactive transaction construction protocols limits of 252 inputs, 1
> single input can bleed the timevalue of the remaining 251 inputs, or engage
> in a MEV attack where the fee-bumping entity is lured to inflate feerate
> beyond the current blockspace demand. The attack can be hidden and a
> posteriori assigning blame consistently stays an open question in the lack
> of a consensus mechanism between participants on the network mempools
> states.
>
> The issue lies in the fact that participants joining inputs together don't
> have control, or even view, of the replacement signaling of any potential
> double-spend of the other participants inputs. Indeed the opt-in fullrbf
> signaling is enforced based on the nSequence field, and this one is fully
> malleable by the UTXO spender. There is no current mechanism to require
> replacement signaling provable to a third-party only on the knowledge of
> the UTXO spents.
>
> # The Solution: Opt-in Full-Replace-by-Fee Spent-nVersion Signaling
>
> A new policy is specified in a new way a transaction can signal that it is
> replaceable.
>
> 1. A confirmed transaction is considered to have opted in to allowing
> replacement of any of its spends (or their descendants), if the last bit of
> the nVersion field is set.
>
> Rational: The future replacement status of any UTXO spend can be
> determined by inspecting the nVersion, therefore protecting the
> collaborative participants of a multi-party flows that the target
> transaction should propagate to the miners, if the fee/feerate offered are
> the best ones without opt-out based pinning. It can be required the UTXOs
> to have few confirmations in case of shallow reorgs to increase DoS
> protection.
>
> ## Solution trade-offs
>
> On the validation-side, there is one engineering issue, as I think there
> is no access to the spent nversion fields by the mempool logic. This would
> presume we add some new cache of all the confirmed UTXOs, so ~50M * 4bytes,
> 300 MB of additional state for policy-enforcing full-nodes. I don't know if
> there is another strong drawback, even the reorg logic the replaceable
> spends shouldn't be evicted if the confirmed ancestor is back to the
> mempool, as mempool validity shouldn't be reevaluated before a replacement
> candidate shows up. A fee penalty could be requested for nVersion-signaling
> transactions to compensate for the additional state stored by full-node
> operators (even if obviously they're not the ones earning the fees).
>
> For the contracting protocols wallets, as you don't know in advance which
> coins are going to be used for a collaborative flow, you're better off to
> mark all your coins nVersion fields opting fullrbf. Otherwise, you will
> have to go through an on-chain fee cost to change the replacement status of
> the spends of your coins. However, this policy bookmarking comes as a
> protocol fingerprint leak for an observer of the transaction logs. If all
> the second-layers used by default, this is constituting a single anonymity
> set, though it might still be the privacy gains we're harvesting from
> Taproot output usage in the optimistic case (e.g in Lightning no commitment
> + HTLC transactions broadcast).
>
> For the zeroconf operators, assuming they have access to the UTXO set,
> they can inspect the receiving transactions ancestors nVersion fields, and
> sort those transactions in the wider set of the replaceable ones, as
> they're currently doing for BIP125 opt-in ones.
>
> Long-term, the annoying privacy issue and the assumption that any wallet
> will be a Lightning one could lead to the majority of wallets signaling RBF
> for their spends. Therefore making those wallets incompatible with zeroconf
> services, slowly economically outlawing them. From my perspective, though
> it might be a simplification, it sounds an alternative full rbf way
> forward, where rather than having miners deciding on the policy
> enforcement, we let the users decide with their coins. However, this new
> policy enforcement efficiency is still dependent on the existence of relay
> paths and support at the endpoints that matter, the miner mempools. So in
> fine we might have to realize incentive alignment with hashrate is what
> matters in terms of transaction-relay rules ?
>
> Credit to Greg Maxwell for this idea.
>
> Cheers,
> Antoine
>
> [0]
> https://lists.linuxfoundation.org/pipermail/lightning-dev/2021-May/003033.html
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221102/70b6a272/attachment.html>

From pete at petertodd.org  Wed Nov  2 14:04:03 2022
From: pete at petertodd.org (Peter Todd)
Date: Wed, 2 Nov 2022 10:04:03 -0400
Subject: [bitcoin-dev] Solving Multi-Party Flows Pinning with Opt-in
 Full-RBF Spent-nVersion Signaling
In-Reply-To: <CALZpt+GZAd-vYMzUMicg0c9OyyWExtT5EH61Hms6NNOM19ddZA@mail.gmail.com>
References: <CALZpt+GZAd-vYMzUMicg0c9OyyWExtT5EH61Hms6NNOM19ddZA@mail.gmail.com>
Message-ID: <Y2J40/Cd40fUlFjj@petertodd.org>

On Tue, Nov 01, 2022 at 10:21:59PM -0400, Antoine Riard via bitcoin-dev wrote:
> Hi list,
> 
> Reading Suhas's post on mempool policy consistency rules, and the grounded
> suggestion that as protocol developers we should work on special policy
> rules to support each reasonable use case on the network rather to arbiter
> between class of use-cases in the design of an
> unified set of rules, reminded me there is another solution to solve
> multi-party funding pinning rather than wide deployment of fullrbf. This
> was communicated to me a while back, and it was originally dismissed
> because of the privacy trade-offs (and potential slight fees overhead
> cost). However, if widely adopted, they might sound acceptable to
> contracting protocol developers and operators.

Strong NACK.

Zeroconf is, at best, a very marginal usecase. The only services that have
spoken up in support of it are Bitrefill and Muun, and the latter says they're
working to get rid of their vulnerability to it. People attempting to make it
secure have repeatedly done sybil attacks against the network in attempts to
measure transaction propagation. And of course, if transaction fees and full
mempools are in our near future - as is widely expected - mempool consistency
will even further diminish making zeroconf even harder to achieve.

Incurring a bunch of engineering costs and harming privacy for the sake of
continuing this nonsense is ridiculous.

If anything, we should be moving to full-RBF so we can undo the privacy cost
that is opt-in-RBF: right now 30% of transactions are having to harm their
privacy by signalling support for it. Full-RBF will allow that wallet
distinguisher to be eliminated.

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221102/57de210a/attachment.sig>

From gsanders87 at gmail.com  Wed Nov  2 14:19:00 2022
From: gsanders87 at gmail.com (Greg Sanders)
Date: Wed, 2 Nov 2022 10:19:00 -0400
Subject: [bitcoin-dev] Solving Multi-Party Flows Pinning with Opt-in
 Full-RBF Spent-nVersion Signaling
In-Reply-To: <Y2J40/Cd40fUlFjj@petertodd.org>
References: <CALZpt+GZAd-vYMzUMicg0c9OyyWExtT5EH61Hms6NNOM19ddZA@mail.gmail.com>
 <Y2J40/Cd40fUlFjj@petertodd.org>
Message-ID: <CAB3F3DsA3kNutwXGwamyyEgJN65rJt-0ks-ytuXP7jwjsjr8ug@mail.gmail.com>

Sorry, I forgot one point which is pertinent to this conversation.

*Even with* fullrbf-everywhere and V3, pinning via rule#3 and rule#5 are
still an issue in coinjoin scenarios.

Each coinjoin adversary can double-spend their coin to either full package
weight(101kvb),
or give 24 descendants, which means you quickly pay out the nose in rule#3
or are excluded
from RBFing it if you have 4+ greifers in your coinjoin violating rule#5.

If we instead narrowed this policy to marking a transaction output as
opt-in to V3, it gets a bit more interesting. *Unfortunately,
double-spending counterparties can still cause rule#3 pain, one 100kvb
package of junk per peer,* but rule#5 violations is at least contained to
coinjoins with ~50 peers(assuming two transactions booted per input
double-spent, which would be the V3 max bumped per input).

It's still worth exploring, but very speculatively.

Greg

On Wed, Nov 2, 2022 at 10:04 AM Peter Todd via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> On Tue, Nov 01, 2022 at 10:21:59PM -0400, Antoine Riard via bitcoin-dev
> wrote:
> > Hi list,
> >
> > Reading Suhas's post on mempool policy consistency rules, and the
> grounded
> > suggestion that as protocol developers we should work on special policy
> > rules to support each reasonable use case on the network rather to
> arbiter
> > between class of use-cases in the design of an
> > unified set of rules, reminded me there is another solution to solve
> > multi-party funding pinning rather than wide deployment of fullrbf. This
> > was communicated to me a while back, and it was originally dismissed
> > because of the privacy trade-offs (and potential slight fees overhead
> > cost). However, if widely adopted, they might sound acceptable to
> > contracting protocol developers and operators.
>
> Strong NACK.
>
> Zeroconf is, at best, a very marginal usecase. The only services that have
> spoken up in support of it are Bitrefill and Muun, and the latter says
> they're
> working to get rid of their vulnerability to it. People attempting to make
> it
> secure have repeatedly done sybil attacks against the network in attempts
> to
> measure transaction propagation. And of course, if transaction fees and
> full
> mempools are in our near future - as is widely expected - mempool
> consistency
> will even further diminish making zeroconf even harder to achieve.
>
> Incurring a bunch of engineering costs and harming privacy for the sake of
> continuing this nonsense is ridiculous.
>
> If anything, we should be moving to full-RBF so we can undo the privacy
> cost
> that is opt-in-RBF: right now 30% of transactions are having to harm their
> privacy by signalling support for it. Full-RBF will allow that wallet
> distinguisher to be eliminated.
>
> --
> https://petertodd.org 'peter'[:-1]@petertodd.org
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221102/2c4439ba/attachment-0001.html>

From pete at petertodd.org  Wed Nov  2 14:33:51 2022
From: pete at petertodd.org (Peter Todd)
Date: Wed, 2 Nov 2022 10:33:51 -0400
Subject: [bitcoin-dev] Solving Multi-Party Flows Pinning with Opt-in
 Full-RBF Spent-nVersion Signaling
In-Reply-To: <CAB3F3DsA3kNutwXGwamyyEgJN65rJt-0ks-ytuXP7jwjsjr8ug@mail.gmail.com>
References: <CALZpt+GZAd-vYMzUMicg0c9OyyWExtT5EH61Hms6NNOM19ddZA@mail.gmail.com>
 <Y2J40/Cd40fUlFjj@petertodd.org>
 <CAB3F3DsA3kNutwXGwamyyEgJN65rJt-0ks-ytuXP7jwjsjr8ug@mail.gmail.com>
Message-ID: <Y2J/zyeTh/rwekqe@petertodd.org>

On Wed, Nov 02, 2022 at 10:19:00AM -0400, Greg Sanders wrote:
> Sorry, I forgot one point which is pertinent to this conversation.
> 
> *Even with* fullrbf-everywhere and V3, pinning via rule#3 and rule#5 are
> still an issue in coinjoin scenarios.
> 
> Each coinjoin adversary can double-spend their coin to either full package
> weight(101kvb),
> or give 24 descendants, which means you quickly pay out the nose in rule#3

...and the attacker also pays out the nose if they're exploiting rule #3.

> or are excluded
> from RBFing it if you have 4+ greifers in your coinjoin violating rule#5.
> 
> If we instead narrowed this policy to marking a transaction output as
> opt-in to V3, it gets a bit more interesting. *Unfortunately,
> double-spending counterparties can still cause rule#3 pain, one 100kvb
> package of junk per peer,* but rule#5 violations is at least contained to
> coinjoins with ~50 peers(assuming two transactions booted per input
> double-spent, which would be the V3 max bumped per input).

There's no hard technical reason for rule #5 to even exist. It's simply a
conservative DoS limit to avoid having to do "too much" computation when
processing a replacement in some replacement implementations. We shouldn't
assume it will always exist. And like rule #3 pinning, exploiting it costs
money.

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221102/addb7935/attachment.sig>

From gsanders87 at gmail.com  Wed Nov  2 15:00:47 2022
From: gsanders87 at gmail.com (Greg Sanders)
Date: Wed, 2 Nov 2022 11:00:47 -0400
Subject: [bitcoin-dev] Solving Multi-Party Flows Pinning with Opt-in
 Full-RBF Spent-nVersion Signaling
In-Reply-To: <Y2J/zyeTh/rwekqe@petertodd.org>
References: <CALZpt+GZAd-vYMzUMicg0c9OyyWExtT5EH61Hms6NNOM19ddZA@mail.gmail.com>
 <Y2J40/Cd40fUlFjj@petertodd.org>
 <CAB3F3DsA3kNutwXGwamyyEgJN65rJt-0ks-ytuXP7jwjsjr8ug@mail.gmail.com>
 <Y2J/zyeTh/rwekqe@petertodd.org>
Message-ID: <CAB3F3DvbuawQwGou5mD_p814F6__0mdrKu1+fqXgAcP6iVOMOg@mail.gmail.com>

> ...and the attacker also pays out the nose if they're exploiting rule #3.

I agree the attacker puts more at stake in this case. If we're assuming
they pay the price and get mined, they can be booted from the protocol
whenever they get mined. I was speaking about the worst case scenario where
it's never mined.

> We shouldn't assume it will always exist.

Just making sure people know that today it does impact things today.

On Wed, Nov 2, 2022, 10:33 AM Peter Todd <pete at petertodd.org> wrote:

> On Wed, Nov 02, 2022 at 10:19:00AM -0400, Greg Sanders wrote:
> > Sorry, I forgot one point which is pertinent to this conversation.
> >
> > *Even with* fullrbf-everywhere and V3, pinning via rule#3 and rule#5 are
> > still an issue in coinjoin scenarios.
> >
> > Each coinjoin adversary can double-spend their coin to either full
> package
> > weight(101kvb),
> > or give 24 descendants, which means you quickly pay out the nose in
> rule#3
>
> ...and the attacker also pays out the nose if they're exploiting rule #3.
>
> > or are excluded
> > from RBFing it if you have 4+ greifers in your coinjoin violating rule#5.
> >
> > If we instead narrowed this policy to marking a transaction output as
> > opt-in to V3, it gets a bit more interesting. *Unfortunately,
> > double-spending counterparties can still cause rule#3 pain, one 100kvb
> > package of junk per peer,* but rule#5 violations is at least contained to
> > coinjoins with ~50 peers(assuming two transactions booted per input
> > double-spent, which would be the V3 max bumped per input).
>
> There's no hard technical reason for rule #5 to even exist. It's simply a
> conservative DoS limit to avoid having to do "too much" computation when
> processing a replacement in some replacement implementations. We shouldn't
> assume it will always exist. And like rule #3 pinning, exploiting it costs
> money.
>
> --
> https://petertodd.org 'peter'[:-1]@petertodd.org
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221102/308e61cf/attachment.html>

From AdamISZ at protonmail.com  Wed Nov  2 15:04:58 2022
From: AdamISZ at protonmail.com (AdamISZ)
Date: Wed, 02 Nov 2022 15:04:58 +0000
Subject: [bitcoin-dev] [Opt-in full-RBF] Zero-conf apps in immediate
	danger
In-Reply-To: <Y1HG0TyuppR0uC+X@petertodd.org>
References: <Y0ZTtlRSBihNN9+v@erisian.com.au>
 <0hpdGx-1WbZdG31xaMXGHKTCjJ2-0eB5aIXUdsp3bqI1MlCx6TMZWROwpl1TVI5irrBqRN2-ydM6hmf3M5L-7ZQfazbx66oameiWTHayr6w=@wuille.net>
 <Y0d/e2sEoNRgD7KP@erisian.com.au> <Y0u8Ee2Ao375z8UD@erisian.com.au>
 <CALZpt+GSYBFxajSyZS19sQi4_6zHjkA5sP00V-pR=_NEVVUnkg@mail.gmail.com>
 <Y05PHYtrNmA0vg7U@erisian.com.au>
 <PC-7ALULc67cy0mTKzk_uj-pbCcwDoMuJQmmevzLPexK32B11vuzCusGSrx1wNCQ5YtMqfQeI1N5AmdemvfHEJNJ5VmZxAeaWS6E3tNZxIs=@protonmail.com>
 <Y1HG0TyuppR0uC+X@petertodd.org>
Message-ID: <f6FZEWGizm0HEqfu-CMgoj9maAHBgk1XUkniYjI81S3le2sMi8jFOMLXT3ANgmIGufJscI0--aJfXOcEFJq-9UHnixgcYlzO-kAx73ggqEI=@protonmail.com>


------- Original Message -------
On Thursday, October 20th, 2022 at 23:08, Peter Todd via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:


> On Wed, Oct 19, 2022 at 03:17:51AM +0000, alicexbt via bitcoin-dev wrote:
> 
> > > And the
> > > impression I got from the PR review club discussion more seemed like
> > > devs making assumptions about businesses rather than having talked to
> > > them (eg "[I] think there are fewer and fewer businesses who absolutely
> > > cannot survive without relying on zeroconf. Or at least hope so").
> > 
> > Even I noticed this since I don't recall the developers of the 3 main coinjoin implementations that are claimed to be impacted by opt-in RBF making any remarks.
> 
> 
> FYI I personally asked Max Hillebrand from Wasabi about full-rbf last night.
> He gave me permission to republish our conversation:
> 
> > Hey, I wanted to know if you had any comments on full-rbf re: wasabi?
> 
> 
> Doesn't really affect us, afaik
> The cj doesn't signal rbf right now
> And I guess it's a DoS vector if any input double spent will be relayed after successful signing
> But we have way bigger / cheaper DoS vectors that don't get "exploited"
> So probably doesn't matter
> Wasabi client handles replacements / reorgs gracefully, so should be alright
> We don't yet "use" rbf in the sense of fee bumping tx, but we should / will eventually
> 
> I haven't asked Joinmarket yet. But the impact on their implementation should
> be very similar.
> 

Hi Peter,

Re: Joinmarket
Yes, it's largely as you would expect. First, we did not ever signal opt-in RBF in coinjoins (it'd be nice if we had CPFP as a user-level tool in the wallet, to speed up low fee coinjoins, but nobody's done it).
Second, yes we have DOS vectors of the trivial kind based on non-protocol-completion (signatures) and RBF would be another one, I don't think it changes our security model at all really (coinjoins being atomic, intrinsically). Nothing in the logic of the protocol relies on unconfirmed txs. Maker *may* reannounce offers when they see broadcast but it's probabilistic (depends on distribution of funds in (BIP32) accounts), and they do / do not reannounce anyway for various reasons (reconnections on different message channels, confirmation of a coinjoin). We should probably take a new look at it if this becomes the norm but there shouldn't be any security issue.

Cheers,
AdamISZ/waxwing

From AdamISZ at protonmail.com  Wed Nov  2 17:19:23 2022
From: AdamISZ at protonmail.com (AdamISZ)
Date: Wed, 02 Nov 2022 17:19:23 +0000
Subject: [bitcoin-dev] Validity Rollups on Bitcoin
In-Reply-To: <224cf2f4-2577-4331-9977-ea71e9723ffe@app.fastmail.com>
References: <689ed481-e7eb-4fea-8ca7-578503f3f285@app.fastmail.com>
 <CAB3F3Dt5oy93duGvYb7SZ7wn7DCvn9FjVwRU9ENNa79yjzmdCQ@mail.gmail.com>
 <224cf2f4-2577-4331-9977-ea71e9723ffe@app.fastmail.com>
Message-ID: <WJ0jiInq_I_IiiT8EiAZZN6axo2pSIRCxQWfyvgU-4rjRmeHnCXFNGWFSXoeOv7nVmqoAPr6EHeXRgc-1DfiPX3C8xHwdYzs2qn4Lck06fs=@protonmail.com>

Hi John,

Sorry for late feedback. Very much appreciated the in depth report!

So, I second Greg's main question, which I've really been thinking about a bit myself since starting to research this area more: it feels like the Bitcoin protocol research community (or, uh, some of it) should focus in on this question of: what is the minimal functionality required onchain (via, presumably soft fork) that enables something close to general purpose offchain contracting that is provable, ideally in zero knowledge, but at the very least, succinctly, with onchain crypto operations. An example might be: if we had verification of bilinear pairings onchain, combined with maybe some covenant opcode, does it give us enough to do something like a rollup/sidechain model with full client side computation and very compact state update and verification onchain? (To be clear: just made that up! there is certainly no deep theory behind that particular combination .. although I did see this [1] thread on *optimistic* + covenant).

Is the actual answer to this something like Simplicity? (Above my paygrade to answer, that's for sure!)

Ideally you would want (don't laugh) for this to be the 'soft fork to end all soft forks' so that innovation could all be then in higher layers.

As to rollups themselves: centralization in the sequencer/publisher of state updates seems to be a really big issue that's somewhat brushed under the carpet. Depending on the model, there are cases where it actually is a theft risk (e.g. full control of an onchain smart contract), but there's significant censorship risk at the very least, as well as availability/uptime risk. At the extreme, Optimism has a 'security model' [3] that is frankly laughable (though, no doubt it's possible that will radically change) and for things like Arbitrum you have centralized sequencers, where the claim is that it will migrate to a more decentralized model; maybe, but that's a huge part of the challenge here, so while it's nice to see the sexy 'fast, cheap, scale' aspect straight away, I feel like those models haven't done the hard part yet. I also think these optimistic L2 models have a 'fake finality' issue from my perspective; the delay needed onchain is how long it takes to *really* confirm. (e.g.: rollups look cool compared to sidechains from the pov of 'instant' instead of confirmations on a chain, but that seems a bit sleight-of-hand-y).

It's notable to compare that with a payment-channels style L2 where decentralization and trustlessness are sine-qua-non and so the limitations are much more out in the open (e.g. the capacity tradeoff - while the 'instantness' is much more real perhaps, with the appropriate liveness caveat).

For the validity rollups, some of the above qualms don't apply, but afaik the concrete instantiations today still have this heavy sequencer/publisher centralization. Correct me if I'm wrong.

In any case, I do agree with a lot of people that some variant of this model (validity rollups) intuitively looks like a good choice, for the future, in comparison with other possible L2s that focus on *functionality* - with a mild censorship and centralization tradeoff perhaps.

And I'm maybe a bit heretical but I see no issue with using 1 of N security models for trusted setup here (note how it's probably different from base chain), so PLONK type stuff is just as, if not more, interesting than STARKS which aiui are pretty big and computationally heavy (sure, maybe that changes). So if that's true, it comes back to my first paragraph.

Cheers,
AdamISZ/waxwing

[1] https://nitter.it/salvatoshi/status/1537362661754683396
[3] https://community.optimism.io/docs/security-model/optimism-security-model/


Sent with Proton Mail secure email.

------- Original Message -------
On Wednesday, October 12th, 2022 at 16:40, John Light via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:


> On Wed, Oct 12, 2022, at 9:28 AM, Greg Sanders wrote:
> 
> > Is there a one page cheat sheet of "asks" for transaction
> > introspection/OP_ZKP(?) and their uses both separately and together for
> > different rollup architectures?
> 
> 
> We do not have this yet. Trey Del Bonis wrote a more detailed technical post about how those components would be used in a validity rollup, which was cited in my report and can be found here:
> https://tr3y.io/articles/crypto/bitcoin-zk-rollups.html
> 
> But it'll take more research and design work to suss out those details you asked for and put them into a nice cheatsheet. I like this idea though!
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

From erik at q32.com  Wed Nov  2 17:30:13 2022
From: erik at q32.com (Erik Aronesty)
Date: Wed, 2 Nov 2022 13:30:13 -0400
Subject: [bitcoin-dev] Boost Bitcoin circulation,
 Million Transactions Per Second with stronger privacy
In-Reply-To: <f5720b0e-d660-473e-00fa-aa275d062e30@sky-ip.org>
References: <bea8122aea550f1141170829aac252af@riseup.net>
 <CADvTj4q42bQ0mTWwdMyJM9UpW57pV0feZk-vYynPu91N_aZSZw@mail.gmail.com>
 <CAGpPWDZtRnnv-Hinn4x=9ukJcuHkZv-6Yt32AK-9e+BJ=6r-kA@mail.gmail.com>
 <f46159f0286fe48720bc3f3fead1b575@riseup.net>
 <CAJowKgKELBmLdA-w5ghGoiWe5RQdNkKsV3OGRFbDJCOeA04AWw@mail.gmail.com>
 <d8b3ba5b940473165ad72d689a01602a@riseup.net>
 <CAGpPWDYAJE4jh=G2g=KSRuLLucEAyZGAD+r4XMpcmw6nk4+Wbg@mail.gmail.com>
 <e843b5c28690557402b72fcd158dc1c2@riseup.net>
 <CAGpPWDYPutiURUtenkU_zr4nW_tZVe5oWykXxWCDyROwqTdW5Q@mail.gmail.com>
 <6016816a7ea36b8a88f48d69462d0308@riseup.net>
 <0555e82561666007e7ce367e3a204f53@riseup.net>
 <f5720b0e-d660-473e-00fa-aa275d062e30@sky-ip.org>
Message-ID: <CAJowKg+TLxmp51PTgmbTSkcO_fgX-ik4Wmf53gOOhUTmqiWafg@mail.gmail.com>

>
> (the only way to replace a transaction is Replace-By-Fee but this
> implies the transaction that IS TO BE REPLACED has a certain flag set,
> and it is optional).
>

1. full rbf is becoming standard.   tx without full rbf can just be
rejected as a part of the sabu protocol

2. that's fine.  watchtowers can be used to fix this that only have the
ability to stop attacks in progress.   guarantee transactions can include a
small watchtower fee for your favorite always-on watchtower service

3. all parties need to maintain sabu state (it's just another mempool)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221102/886a64bf/attachment.html>

From alicexbt at protonmail.com  Wed Nov  2 19:02:33 2022
From: alicexbt at protonmail.com (alicexbt)
Date: Wed, 02 Nov 2022 19:02:33 +0000
Subject: [bitcoin-dev] Announcement: Full-RBF Miner Bounty
In-Reply-To: <Y2I3w8O5X55sD/3C@petertodd.org>
References: <Y2I3w8O5X55sD/3C@petertodd.org>
Message-ID: <fMZWicZXp5SM0ON8jgYuykBydOXcbgePbPfGKA0DQYtEDdiIr4bWljL_TqQHKtVKZRhvRXkEab47aaZw17OxGaSgOP2_w9_Owjb9WnTmsQ0=@protonmail.com>

Hi Peter,

> tl;dr: I'm broadcasting full-RBF replacements paying extremely high fees to
> reward miners that turn on full-RBF. I'm starting small, just ~$100/block in
> times of congestion. Miner and pool profit margins are pretty small, on the
> order of $1k/block in many cases, so I know it doesn't take that much more
> money to make a difference.

I appreciate this effort and perhaps this was all that was needed in addition to Bitcoin Core's inclusion of full rbf support. Making it default right away or enabling preferential peering with service flag in a bitcoin core release was unnecessary.

> If you'd like to donate to this effort, send BTC to
> bc1qagmufdn6rf80kj3faw4d0pnhxyr47sevp3nj9m

Sorry, I don't trust you based on some of the things you support on Twitter. Hopefully, others will donate and help this bounty.

/dev/fd0

Sent with Proton Mail secure email.

------- Original Message -------
On Wednesday, November 2nd, 2022 at 2:56 PM, Peter Todd via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:


> I'm now running a full-RBf bounty program for miners.
> 
> tl;dr: I'm broadcasting full-RBF replacements paying extremely high fees to
> reward miners that turn on full-RBF. I'm starting small, just ~$100/block in
> times of congestion. Miner and pool profit margins are pretty small, on the
> order of $1k/block in many cases, so I know it doesn't take that much more
> money to make a difference.
> 
> Why should you do this? Full-RBF/zeroconf has been discussed to death. But
> tl;dr: You'll earn more money, and help transition Bitcoin to a more secure
> mempool policy based on economic incentives rather than trust.
> 
> 
> If you're a miner and want to participate, the easiest way to so is to use the
> mempoolfullrbf=1 option in the upcoming Bitcoin Core v24 release (eg the
> 24.0rc3 tag), or use the mempoolreplacement=fee option in Bitcoin Knots.
> 
> You can also just modify the code yourself by removing the opt-in RBF check.
> For example against the v23.0 tag:
> 
> $ git diff
> diff --git a/src/validation.cpp b/src/validation.cpp
> index 214112e2b..44c364623 100644
> --- a/src/validation.cpp
> +++ b/src/validation.cpp
> @@ -736,7 +736,7 @@ bool MemPoolAccept::PreChecks(ATMPArgs& args, Workspace& ws)
> // check all unconfirmed ancestors; otherwise an opt-in ancestor
> // might be replaced, causing removal of this descendant.
> if (!SignalsOptInRBF(*ptxConflicting)) {
> - return state.Invalid(TxValidationResult::TX_MEMPOOL_POLICY, "txn-mempool-conflict");
> + // return state.Invalid(TxValidationResult::TX_MEMPOOL_POLICY, "txn-mempool-conflict");
> }
> 
> ws.m_conflicts.insert(ptxConflicting->GetHash());
> 
> 
> Once you've enabled full-RBF, you need a full-RBF peer. I'm running a few of
> them:
> 
> cup.nop.lol
> mug.nop.lol
> jar.nop.lol
> jug.nop.lol
> 
> These nodes run a preferential peering patch (https://github.com/bitcoin/bitcoin/pull/25600)
> to ensure that full-RBF nodes are interconnected to each other and replacements
> can easily propagate. Also feel free to contact me if you'd like to peer with a
> private node.
> 
> 
> If you'd like to donate to this effort, send BTC to
> bc1qagmufdn6rf80kj3faw4d0pnhxyr47sevp3nj9m
> 
> 
> ...and yes, I'm well aware that miners could collect this bounty in other ways,
> eg by raising minimum fees. Doing that also breaks zeroconf, so I'm not too
> concerned.
> 
> --
> https://petertodd.org 'peter'[:-1]@petertodd.org
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

From antoine.riard at gmail.com  Wed Nov  2 19:50:26 2022
From: antoine.riard at gmail.com (Antoine Riard)
Date: Wed, 2 Nov 2022 15:50:26 -0400
Subject: [bitcoin-dev] On mempool policy consistency
In-Reply-To: <CAFp6fsFm06J2G1=3ojQvcL9gbEbQ41C4rmf3=Jkm9Qm0VBhhKw@mail.gmail.com>
References: <Y1nIKjQC3DkiSGyw@erisian.com.au>
 <CAFp6fsFm06J2G1=3ojQvcL9gbEbQ41C4rmf3=Jkm9Qm0VBhhKw@mail.gmail.com>
Message-ID: <CALZpt+HHsqN0tq7LYfR9YFRjWo_dKwDDAwB_HPLacafVj8anWw@mail.gmail.com>

Hi Suhas,

>From my understanding, the main crux of the reasoning exposed in your post
would be to solidify the transaction-relay paradigm we have been following
during the last years, e.g introducing the carve-out rule specifically for
lightning commitment transactions, or more recently version=3 transactions.
I think this paradigm could be described summarly as "to each use-case
belongs a set of transaction-relay policy rules". Some of this set of rules
could aim to non-replacement guarantees to the consumers of transactions
signaling under this regime (e.g zeroconf). Another set of rules could
provide a high-guarantee that a transaction would always get to a miner, no
matter what the state of node's mempools on the network (e.g "maximal rbf"
for contracting protocols).

First, coming out of my mind, we would have to consider isolation between
each set of policy rules, ensuring the signaling mechanism cannot be abused
by an attacker to create a new pinning vector. E.g, a hypothetical concern
could be BIP125 rules interfering with version=3 policy to block the
replacement of better ancestor feerate packages. Further, for each set of
policy rules arises the question of internal consistency, again an attacker
could abuse them to pin transactions
propagation. I think an earlier version of version=3 was suffering from
this concern of not scoping potential "junk" ancestors. None of those
issues are unsolvable, however we should be well-aware of the
non-negligeable design complexity encumbered by transaction-relay protocol
developers to achieve the correct goal. There is not only a need to ensure
careful policy rules security analysis, but further to communicate well
their usage to second-layers and wallets developers (a task far from easy
with all the confusions contained by current BIP125).

Now, in the evaluation process of a set of policy rules soundness are
proposed a few reasoning heuristics: namely that it shouldn't interfere
sensibly with a anti-DoS mempool acceptance algorithm, or shouldn't
interfere with other protocols on the network, or counter the interests of
miners or node operators. I hold the belief the latest question could be
the one raising the most concerns. Browsing in the history of Bitcoin Core,
I think one of the design goals aimed for has always been to level the
playing field between miners, e.g BIP152 improving block transfer latency
to reduce orphan rate. Following this principle, we might wonder if our
transaction-relay network should guarantee some equal access to transaction
information to all the miners.

In the present case of a non-replacement policy regime, we could see the
following situation to arise, on one side miners deploying private
transaction-relay communication channels or API to capture higher fees
income from non-standard transactions. On the other-side, transaction
issuers or consumers bypass the standard transaction-relay policy rules.
Bypass could be motivated by either a zeroconf service double-spend, or
faster confirmation of a collaborative transaction. E.g, to reuse the
example of unconfirmed transaction chaining, where the sender commit to
non-replacement by opting out from the RBF flag, this commitment could be
reevaluated in the light of changing network mempools congestion, or
liquidity preferences (e.g the quick need to open LN routing channels). The
sender could leverage such hypothetical private transaction-relay
communication channels to revoke its non-replacement commitment. Therefore
discrepancies between a set of policy rules design and miners incentives
sounds to lead to informational asymmetries, harmful for the long-term
decentralization of the mining ecosystem. Of course, miner incomes
asymmetries due to edge in transaction flows access might not be weighted
as serious today, in a world where transaction fees contribute to most of
the block reward, this is far more worrying!

Of course, one position could be to estimate that miner centralization is
beyond the scope of responsibility of the Bitcoin Core project. Or at least
as a result of lightweighted risks.

Such discrepancy between a set of policy rules design and miners incentives
could also lead to hidden security risks for second-layers. As we see more
security assumptions made on policy rules extension, e.g version=3, a
lightning channel counterparty could have a competing interest to forge a
raw package suiting better incentives, and as such nullify the security
advantage expected. This could be seen as a loose concern, however the last
time we have seen an actor deliberately providing non-standard transactions
to a miner to break second-layers was yesterday [0]!. From observing other
cryptocurrencies spaces, such "MEV-style" attacks could be more and more
concerning [1]. I don't think we should assume miners to behave as "network
gentlemen", in a world where mining can be anonymous, permissionless and
censorship-resistant (e.g Stratum V2 giving back template construction to
miners operators rather than pools).

According to me, one of the harder problem we're seeing with this fullrbf
discussion is the lack of a consistent, grounded and well-understood miner
incentive model, where not only block template construction but also
transaction collection and replacement strategies are analyzed, and against
which we could simulate the efficiency of a policy. Assuming we would have
such a model, rather than qualify a policy rule as incentive-compatible in
a binary fashion, we could evaluate them on a scale, and agree on when
they're satisfying enough in face of technical complexity, validation
resources, margin of adversarial exploitation, or whatever other relevant
criteria.

Answering a few other points raised in this post, what appears to me
obscure is the qualification that fullrbf doesn't solve the DoS issues for
contracting protocols (e..g coinjoin/dual-funded lightning). If I can
understand, it's on the ground that the imperfections of BIP125 underscore
only the direct conflict feerate. It should be remembered that allowing
replacement without considering the opting flag would be already an
improvement against the DoS attack, as the attack would have to offer a
more compelling feerate to maintain the pin. Improvements of BIP125 can
happen on the top, but solving the opt-out double-spend issue sounds to me
a prerequisite.

Beyond that, I think few questions are laid out on the conceptual soundness
of v3 transaction policy w.r.t concerns raised about fullrbf today. In my
opinion, I'm sadly with most of them, especially that miners might earn
more revenue if we allowed multiple descendant v3 transactions and the
unenforceable promise for the recipient of such package to not add more
high-value children, I've echoed those concerns earlier in the review of
nVersion=3 proposal [2]. We might have to swallow the bullet for now, and
be okay as lightning developers and operators that there is only a social
inertia of the miners and lack of reliable communication channels towards
them by an adversarial counterparty to offer security [3]. Additionally, I
think it would be acceptable to have an option to disable v3 transaction
policy, an operator could be willing to reduce the CPU/memory DoS surface
of its node from partaking to any package relay. Even if it comes at the
loss of a better view of blockspace demand and downgrades its
fee-estimation, I think we should give the maximum flexibility to operators
in choosing their risk model.

To put it in a nutshell, if we would like to pursue further in the paradigm
that "to each use-case belongs its set of policy rules" (as long as they
don't introduce any harm for the network stakeholders), I believe we would
be more grounded with a better quantitative understanding of so-called
"miners incentives". I'm still wondering if it's realistic to deploy policy
rules that are not sustainable in face of long-term mining dynamics.

Best,
Antoine


[0] https://github.com/lightningnetwork/lnd/issues/7096

[1] On risks of introducing miner harvesting attacks, especially when you
consider implications on lightning-style constructions
https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-February/002569.html
and
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-November/019615.html

[2]
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-September/020939.html

"If you're a miner and you receive a non-V3, second descendant of an
unconfirmed V3 transaction, if the offered fee is in the top mempool
backlog, I think you would have an interest to accept such a transaction.

So I'm not sure if those two rules are compatible with miners incentives..."

[3] This wonders if we should look forward in the future to lock in the
CPFP weight of a Lightning commitment with some new consensus semantic, or
leveraging any covenant magic, cf.
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-March/020122.html
and
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-October/020991.html

Le lun. 31 oct. 2022 ? 11:02, Suhas Daftuar via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> a ?crit :

> AJ,
>
> Thanks for the thoughtful post. I think your observations about how we
> view mempool policy in the Bitcoin Core project, and how that seems to be
> changing in the discussions around `-mempoolfullrbf`, are on-point and
> provide a helpful baseline for considering future policy changes.
>
> For a long time I viewed fullrbf as an eventuality and I considered myself
> to be philosophically supportive of the idea.  However, after giving this
> issue some thought in the past few weeks, I am reversing my thinking on
> this.  Concretely, I will argue that we should continue to maintain a relay
> policy where replacements are rejected for transactions that don't opt-in
> to RBF (as described in BIP 125), and moreover, that we should remove the
> `-mempoolfullrbf` flag from Bitcoin Core?s latest release candidate and not
> plan to release software with that flag, unless (or until) circumstances
> change on the network, which I'll discuss below.
>
> This is, of course, a nuanced topic, and among the considerations is a
> philosophy of how to think about the relay policy and configuration options
> that we make available in Bitcoin Core (a consideration that is perhaps
> unique to that project, but I think relevant for this mailing list).
>
> I'll start with some technical issues regarding the benefits of enabling
> fullrbf on the network.  In the current BIP 125 regime, every time a
> transaction is created, a choice is made whether to subject the transaction
> to BIP 125?s RBF rules or not (based on the sequence values of the
> inputs).  So given that users can already opt-in to RBF, the benefit of a
> ?fullrbf? network policy would be if, somehow, RBF users were still denied
> the benefits of RBF due to the existence of other transactions that don?t
> opt-in.
>
> Along those lines, Antoine Riard brought up[1] a DoS vector that is
> available to someone who wants to interfere with multi-party funded
> transactions, and suggested that fullrbf would eliminate the problem.
> After exploring that question again in this thread (thanks to Greg Sanders
> for clarifying this to me), I understand that the issue is around ensuring
> that a multiparty (coinjoin-type) protocol is able to make eventual
> progress, by having a candidate multiparty transaction either eventually
> confirm or become conflicted with something that has been confirmed, in
> which case the double-spend information could be used to start a new
> coinjoin round with fewer participants.  The concern Antoine and Greg have
> brought up is that non-rbf transactions can persist in the mempool
> ~indefinitely (at a low feerate and not subject to replacement) and
> interfere with progress being made in a coinjoin protocol.
>
> However, it seems to me that similar problems exist for such a protocol
> even in a fullrbf world, as we understand that term today.  I mentioned the
> ability for rbf ?pinning? to interfere with relay of the multiparty
> transaction (even if the conflicting transaction signals for RBF ? a set of
> large but low feerate conflicting transactions can persist in the mempool
> and make it difficult for the coinjoin transaction from confirming, at
> least without attaching a very large fee); and as Greg mentioned in a
> followup, the BIP 125 rule to only permit 100 transactions to be removed
> from the mempool at a time during a replacement can also be used to pin a
> coinjoin protocol in the same way as a non-rbf transaction today.  It seems
> to me that what these multiparty protocols actually need is some sort of
> "maximal rbf" network policy: a way to guarantee that a transaction which
> should be desirable for a miner to mine would always get to a miner and
> considered for inclusion in a block, no matter what the state of node?s
> mempools on the network.
>
> While that sounds like a reasonable thing to want on its face (and worth
> working on), it's not how opt-in RBF works today, nor is it how transaction
> relay has ever conceptually worked.  We have not, thus far, been able to
> come up with a total ordering on transaction desirability.  Moreover, due
> to all the DoS issues that exist with transaction relay, there are plenty
> of seemingly legitimate ways to construct transactions that would not relay
> well on the network.  Relay has only ever been a best-efforts concept,
> where we carve out a small subset of the entire transaction universe for
> which we try to optimize propagation.  The idea behind this approach is
> that if every use case we can come up with has some way to achieve its
> goals using transactions that should (eventually) be able to relay, then
> users wouldn?t have much demand for transactions that would deviate from
> the supported policies, and we therefore shouldn?t need to worry too much
> about incentive compatibility concerns when it comes to transaction types
> that wouldn?t relay at all, even if they are high feerate.  (And when those
> situations arise where the standard transactions do not accommodate some
> needed use case, developers typically work to define a policy that is
> compatible with our anti-DoS goals to support such use cases, such as with
> the recent proposal for version=3 transactions [2].)
>
> BIP 125's RBF rules themselves were an effort to carve out just a subset
> of situations where a transaction should evict conflicting ones -- it was
> not a design that anyone thought would ensure that all replacements which
> "should" be mined would always propagate.  And I don't believe that we know
> how to design policy rules that would achieve the goals of this kind of
> multiparty protocol in a DoS resistant way, today.  Along those lines, I
> would point out that even the BIP 125 design itself is not entirely
> incentive compatible, in that it is possible to construct a replacement
> transaction that would evict transactions which would be preferable to be
> included in a block! [3]  (This has been known for years, but fixing this
> has proven difficult, and the only way to fix it that I?m aware of would be
> to make BIP 125 RBF even more restrictive than it is today. I do think this
> is something that needs to be worked on.)
>
> Given the limitations of RBF as we have it today, it appears to be
> incorrect that a fullrbf network policy would solve the problems Antoine
> raised.  And so absent any other examples, it does not seem to me that
> fullrbf solves any problems for RBF users, who are already free to choose
> to subject their transactions to BIP 125?s RBF policy.  From this
> perspective, "enabling fullrbf" is really just taking away user choice to
> opt a transaction into a non-replacement policy regime.
>
> I think we should ask, then, whether it is reasonable on its face that
> users might want to opt-in to a non-replacement policy?  Or in other words,
> is it reasonable for a user to mark a transaction as non-replaceable and
> have that indication be enforced by the network? Note that these are two
> different questions: you could imagine a world where fullrbf is a dominant
> policy, but users still use the BIP 125 signaling method to indicate, in an
> unenforced way, their intention to not replace a transaction.  This might
> give useful information to the network or the recipient for how to interact
> with such a transaction.
>
> And I think that it's entirely possible that users would continue to use
> the BIP 125 signaling to indicate that they do not intend to replace a
> transaction.  For better or worse, this might be because zeroconf services
> continue to differentiate their behavior based on such a signal (possibly
> in conjunction with other factors), or it could be because there are other
> behaviors that could be utilized more effectively if the transaction
> originator has made such a signal, such as the recipient chaining an
> unconfirmed transaction as a way to bump the fee (CPFP) [4].
>
> If it were to be the case that users continued to use BIP 125-style
> signaling to indicate that they do not plan to replace a transaction, would
> that be harmful to the network?  This is not something we can stop in our
> policy rules (short of censoring such transactions, an obviously bad
> idea).  I think network actors can always do things that we might think are
> harmful for the network, but that doesn?t mean that there are no legitimate
> use cases for the tools that such actors might be using.  Just because
> someone might use some policy to adopt a zeroconf model, doesn?t mean that
> others aren?t using the same policy to achieve benign ends (such as better
> CPFP behavior).
>
> Moreover, while users might attempt to exploit services that offer
> zeroconf or other differentiated behavior to non-replacement signaling
> transactions, they also might not -- I think predicting user behavior in
> this way (and specifically predicting the complexities of what a business
> might do and whether users might try to subvert it) is beyond the scope of
> what we can do as protocol developers.  Instead, I think we can try to
> answer a different question: if a group of users were to want the ability
> to opt-in to a non-replacement policy regime, is that a technically sound
> option for us to have on the network and enforce in software?
> Specifically, does that interfere with having a sensible anti-DoS mempool
> acceptance algorithm, or interfere with other protocols on the network, or
> necessarily run counter to the interests of miners or node operators?
>
> And I think the answer to that question, in looking at the difference
> between opt-in RBF and fullrbf, is no: offering the ability to opt-in to a
> non-replacement regime for transactions doesn't introduce any fundamental
> issues with software or network policy or other protocols.  In a world
> where we only had fullrbf, I could imagine at some point down the road
> proposing a non-replacement signal myself, because the complexities around
> transaction chains (and pinning) are more complex for the RBF case than for
> the non-RBF case (and BIP 125 is not always incentive compatible to begin
> with!).  Conceptually, this is no different to me than the version=3
> transaction policy proposal that has been advancing, if we think of it as a
> special set of restrictions on transactions designed to accommodate a
> particular use case.
>
> Philosophically, I think we should be looking to add non-interfering use
> cases to what the network supports.
>
> To those who argue for making fullrbf a default policy on the network (or
> even just offering a flag for users to enable fullrbf), I pose this
> hypothetical: suppose we deploy the v3 transaction policy proposal (which I
> hope will happen in the near future).  That policy would restrict the ways
> that outputs of a v3 transaction can be spent while the transaction is
> unconfirmed, including by limiting the number and size of descendants that
> such a transaction can have, and limiting the types of unconfirmed
> ancestors that can be included.  Suppose in a few years someone proposes
> that we add a "-disable_v3_transaction_enforcement" flag to our software,
> to let users decide to turn off those policy restrictions and treat v3
> transactions the same as v2, for all the same reasons that could be argued
> today with fullrbf: miners might earn more revenue if we allowed multiple
> descendant v3 transactions; it's illogical for the recipient of a v3
> transaction to believe what is a fundamentally unenforceable promise of a
> sender to not issue more high value children that descend from an
> unconfirmed transaction; it's inappropriate for Bitcoin Core to dictate
> policy on the network and we should honor user choice to turn off that flag
> if that?s what users want; if users are relying on v3?s policy restrictions
> for security then that is an unstable model and we should assume it will
> get broken[5].
>
> It?s obvious to me that adding a flag to disable v3 policy would be
> subversive to making the lightning use case for v3 transactions work.  And
> so my response to such a hypothetical proposal would be to argue that no,
> we should not enable users to disable this policy, because as long as that
> policy is just optional and working for those who want it, it shouldn?t
> harm anyone that we offer a tighter set of rules for a particular use
> case.  Adding a way to bypass those rules is just trying to break someone
> else?s use case, not trying to add a new one.  We should not wield
> "incentive compatibility" as a bludgeon for breaking things that appear to
> be working and not causing others harm.
>
> I think this is exactly what is happening with fullrbf.
>
> In comparing v3 transaction policy with opting out of transaction
> replacement, there is of course one significant difference that I have
> ignored thus far: I think the real difference is an opinion about whether
> non-replacement transactions that are being used today are, overall, bad
> for Bitcoin, and whether lightning?s use of v3 transactions in the future
> would be bad for Bitcoin. If you think that zeroconf is unequivocally bad,
> and that no one will be able to plausibly construct a case that lightning
> is bad, then that qualitative judgment might sway you to not worrying about
> the philosophical issues I've raised above, because these situations can be
> distinguished.
>
> However I am not personally willing to say that I think, overall,
> non-rbf-signaling transactions in use on the network today are bad for
> Bitcoin (or that fullrbf is definitely good ? BIP 125?s rbf rules are
> something we?ve been trying to improve upon for years, with little
> success).  Nor am I convinced that someone couldn?t put together a cogent
> argument for lightning being bad for Bitcoin, because of its reliance on
> relay policies that are difficult to design and impossible to guarantee as
> part of its security model.  So I choose instead to merely make a judgment
> that seems more factually verifiable, which is that non-replacement is a
> policy widely in use on the network today, and we largely don't have reason
> to think (as far as I know!) that the network is seeing a lot of
> transactions that would violate that policy.
>
> If it did turn out that users were commonly signaling non-replacement, but
> then signing and trying to relay doublespends, then I think that would be a
> very good reason for Bitcoin Core to adopt fullrbf to reflect the reality
> of what is happening.  In the meantime, I think it makes more sense to say
> that because we have BIP 125, there seems to be no need for users to signal
> one way and behave another, and therefore there is no need to offer
> software that might break a policy that is working well for some users.
> Other software projects might choose differently, and it is after all a
> permissionless network, so if this is in fact an unstable equilibrium that
> will not last, then presumably someday it will be apparent it is not
> working and we?ll abandon it.  But I think the philosophy of transaction
> relay policy in Bitcoin Core should be to support disparate use cases in
> order to try to make everything work better, rather than break things
> prematurely because we guess others will break them eventually anyway.
>
> For those that have read this long email and still favor a fullrbf network
> policy (or even just the ability for users to be able to turn on fullrbf
> for themselves), I?d ask for thoughts on the following questions, which
> have guided my thinking on this:
>
> Does fullrbf offer any benefits other than breaking zeroconf business
> practices?  If so, what are they?
>
> Is it reasonable to enforce BIP 125's rbf rules on all transactions, if
> those rules themselves are not always incentive compatible?
>
> If someone were to propose a command line option that breaks v3
> transaction relay in the future, is there a logical basis for opposing that
> which is consistent with moving towards fullrbf now?
>
> Cheers,
> Suhas
>
>
> [1]
> https://lists.linuxfoundation.org/pipermail/lightning-dev/2021-May/003033.html
>
> [2]
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-September/020937.html
>
> [3] This is because under the BIP 125 rules, the feerate of the
> replacement transaction is not compared to the individual feerates of all
> transactions being evicted ? we just compare feerates with the transactions
> that are directly in conflict (and not their descendants). So it?s possible
> for a transaction that would evict 2 or more transactions to have a higher
> feerate than the direct conflicts, and higher total fee than the set being
> evicted, but have a lower feerate (eg if it is larger) than that of some
> subset of the set of transactions being evicted.
>
> [4]  Chaining unconfirmed transactions when the sender might RBF the
> parent is far riskier than if the sender indicates they don't plan to do so
> (chaining onto an RBF transaction creates pinning issues for the sender,
> and risks having the child wiped out if the parent is replaced), so I think
> this is a concrete reason why signaling that a transaction won?t be
> replaced could be useful.
>
> [5] This is a subtle point. I don?t think v3 transactions create an
> unreasonable security assumption for the use case it is being designed for.
> However, I don?t think anyone could rule out the possibility that someone
> could adopt a usage pattern for v3 transactions that subverts the intent of
> this policy.  For example, if users started using v3 transactions for all
> their payments, then the limitations on the number of descendants could
> directly interfere with CPFP by a recipient, and someone could argue that
> we should break the policy in order to allow for this hypothetical
> behavior. I think this is a similar form of argument as saying that
> zeroconf practices + BIP 125 create an incentive to double-spend non-rbf
> signaling transactions.
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221102/d2ff3925/attachment-0001.html>

From johanth at gmail.com  Thu Nov  3 09:26:05 2022
From: johanth at gmail.com (=?UTF-8?Q?Johan_Tor=C3=A5s_Halseth?=)
Date: Thu, 3 Nov 2022 10:26:05 +0100
Subject: [bitcoin-dev] [Lightning-dev] Taro: A Taproot Asset
 Representation Overlay
In-Reply-To: <CAPv7TjZjZU2bYvUrt-BEx80xKF=BHBbrYWigHB+=yY+YfZX9Yg@mail.gmail.com>
References: <CAO3Pvs_pkYAYsrAEtv3KuJevXQHBLZQ-ihjP4Ur_A1NjJRA+Lw@mail.gmail.com>
 <CAPv7TjYTjvSV7UFgOwif6tFj3jVxDfJdW-p_cyPoAGGWKQbwRQ@mail.gmail.com>
 <CAO3Pvs_-igT37fcD29=ATSRX7dW5mGKrLGrXp=iJjaN_t3NGww@mail.gmail.com>
 <CAPv7TjZjZU2bYvUrt-BEx80xKF=BHBbrYWigHB+=yY+YfZX9Yg@mail.gmail.com>
Message-ID: <CAD3i26AOmfHz1aOJGwzixQuwMtoo=v5qbveZUasbkzL1sPJWLw@mail.gmail.com>

Hi,

I wanted to chime in on the "teleport" feature explained by Ruben, as I
think exploring something similar for Taro could be super useful in an LN
setting.

In today's Taro, to transfer tokens you have to spend a UTXO, and present a
proof showing that there are tokens committed to in the output you are
spending. Let's say this UTXO is 'utxo:0'.

In contrast, to spend teleported tokens, you would still spend utxo:0, but
you would only have to present a proof that _some txout_ on-chain have
committed tokens to utxo:0.

As Ruben points out, this makes it possible to send tokens to an already
spent TXO, essentially burning the tokens.

However, it opens up some exciting possibilities IMO. You can in essence
use this to "re-fill" UTXOs with tokens, which is very interesting for LN
channels:

- You could "add" tokens to your already open channels. The only thing
needed is for the channel participants to be presented the proof that
tokens were sent to the funding output, and they can update their
commitment transaction to start spending these tokens.
- You can "top-up" all your channels in a single on-chain tx. Since a
single output can commit tokens to several UTXOs, you could with a single
on-chain transaction add tokens to many channels without opening and
closing them.

RGB also has the ability to "blind" the UTXO that tokens get teleported to,
hiding the recipient UTXO. This is cool, since I could withdraw tokens from
an exchange directly into my LN channel, without revealing my channel UTXO.

I found the explanation of the teleport feature in this blog post pretty
good:
https://medium.com/@FedericoTenga/understanding-rgb-protocol-7dc7819d3059

- Johan

On Sun, Apr 10, 2022 at 6:52 PM Ruben Somsen <rsomsen at gmail.com> wrote:

> Hi Laolu,
>
> >happy to hear that someone was actually able to extract enough details
> from the RGB devs/docs to be able to analyze it properly
>
> Actually, even though I eventually puzzled everything together, this did
> not go well for me either. There is a ton of documentation, but it's a maze
> of unhelpful details, and none of it clearly maps out the fundamental
> design. I was also disappointed by the poor response I received when asking
> questions, and I ended up getting chastised for helping others understand
> it and pointing out potential flaws[1][2][3].Given my experience, I think
> the project is not in great shape, so the decision to rebuild from scratch
> seems right to me.
>
> That said, in my opinion the above should not factor into the decision of
> whether RGB should be credited in the Taro documentation. The design
> clearly precedes (and seems to have inspired) Taro, so in my opinion this
> should be acknowledged. Also, the people that are responsible for the
> current shape of RGB aren't the people who originated the idea, so it would
> not be fair to the originators either (Peter Todd, Alekos Filini, Giacomo
> Zucco).
>
> >assets can be burnt if a user doesn't supply a valid witness
>
> I am in agreement with what you said, but it is not clear to me whether we
> are on the same page. What I tried to say was that it does not make sense
> to build scripting support into Taro, because you can't actually do
> anything interesting with it due to this limitation. The only type of smart
> contract you can build is one where you limit what the owner (as defined by
> Bitcoin's script) can do with their own Taro tokens, or else he will burn
> them ? not very useful. Anything involving a conditional transfer of
> ownership to either A or B (i.e. any meaningful type of script) won't work.
> Do you see what I mean, or should I elaborate further?
>
> >TAPLEAF_UPDATE_VERIFY can actually be used to further _bind_ Taro transitions
> at the Bitcoin level, without Bitcoin explicitly needing to be aware
>
> That is conceptually quite interesting. So theoretically you could get
> Bitcoin covenants to enforce certain spending conditions on Taro assets.
> Not sure how practical that ends up being, but intriguing to consider.
>
> >asset issuer to do a "re-genesis"
>
> Yes, RGB suggested the same thing, and this can work under some
> circumstances, but note that this won't help for tokens that aim to have a
> publicly audited supply, as the proof that a token was legitimately
> re-issued is the history of the previous token (so you'd actually be making
> things worse, as now everyone has to verify it). And of course the idea
> also requires the issuer to be active, which may not always be the case.
>
> >I'm not familiar with how the RGB "teleport" technique works [...] Can
> you point me to a coherent explanation of the technique
>
> To my knowledge no good explanation exists. "Teleporting" is just what I
> thought was a good way of describing it. Basically, in your design when
> Alice wants to send a Taro token to Bob, Alice has to spend her own output,
> make a new output for Bob, and make a change output for herself. Inside the
> Taro tree you'll then point to the index of Bob's output in order to assign
> the tokens to his new output. Instead of pointing to the index, you could
> point to the outpoint (txid, index) of an existing UTXO owned by Bob, thus
> "teleporting" the Taro tokens to this UTXO. This saves on-chain space, as
> now you don't have to create a new output for Bob (but now you have to
> ensure Bob doesn't spend from this output while you're simultaneously
> sending tokens to it, as I mentioned in my previous post, as this would
> destroy the tokens).
>
> The above also reminds me of another potential issue which you need to be
> aware of, if you're not already. Similar to my comment about how the
> location of the Taro tree inside the taproot tree needs to be deterministic
> for the verifier, the output in which you place the Taro tree also needs to
> be. If it's not, then you can commit to a different Taro tree in each
> output of the transaction, allowing you to secretly fork the history.
>
> Hope this helps.
>
> Cheers,
> Ruben
>
> [1] https://twitter.com/SomsenRuben/status/1397267261619064836
> [2] https://twitter.com/SomsenRuben/status/1397559406565462017
> [3] https://twitter.com/afilini/status/1397484341236797441
>
> On Fri, Apr 8, 2022 at 7:48 PM Olaoluwa Osuntokun <laolu32 at gmail.com>
> wrote:
>
>> (this might be a double post as it ran into the size limit)
>>
>> Hi Ruben,
>>
>> Thanks! I don't really consider things final until we have a good set of
>> test
>> vectors in the final set, after which we'd start to transition the set of
>> documents beyond the draft state.
>>
>> > Seeing as there's a large amount of overlap with RGB, a protocol which
>> I have
>> > examined quite extensively, I believe some of the issues I uncovered in
>> that
>> > project also apply here.
>>
>> I'm happy to hear that someone was actually able to extract enough
>> details from
>> the RGB devs/docs to be able to analyze it properly! In the past I tried
>> to ask
>> their developers questions about how things like transfers worked[1][2],
>> but it
>> seemed either people didn't know, or they hadn't finished the core design
>> (large TBD sections) as they were working on adding other components to
>> create
>> a "new new Internet".
>>
>> > Furthermore, the Taro script is not enforced by Bitcoin, meaning those
>> who
>> > control the Bitcoin script can always choose to ignore the Taro script
>> and
>> > destroy the Taro assets as a result.
>>
>> This is correct, as a result in most contexts, an incentive exists for the
>> holder of an asset to observe the Taro validation rules as otherwise,
>> their
>> assets are burnt in the process from the PoV of asset verifiers. In the
>> single
>> party case things are pretty straight forward, but more care needs to be
>> taken
>> in cases where one attempts to express partial application and permits
>> anyone
>> to spend a UTXO in question.
>>
>> By strongly binding all assets to Bitcoin UTXOs, we resolve issues
>> related to
>> double spending or duplicate assets, but needs to mind the fact that
>> assets can
>> be burnt if a user doesn't supply a valid witness. There're likely ways
>> to get
>> around this by lessening the binding to Bitcoin UTXO's, but then the
>> system
>> would need to be able to collect, retain and order all the set of possible
>> spends, essentially requiring a parallel network. The core of the system
>> as it
>> stands today is pretty simple (which was an explicit design goal to avoid
>> getting forever distracted by the large design space), with a minimal
>> implementation being relatively compact given all the Bitcoin
>> context/design
>> re-use.
>>
>> Also one cool trait of the way commitments are designed is that the Taro
>> commitment impact the final derived taproot output key. As a result,
>> potential
>> Script extensions like TAPLEAF_UPDATE_VERIFY can actually be used to
>> further
>> _bind_ Taro transitions at the Bitcoin level, without Bitcoin explicitly
>> needing to be aware of the Taro rules. In short, covenants can allow
>> Bitcoin
>> Script to bind Taro state transitions, without any of the logic bleeding
>> over,
>> as the covenant just checks for a certain output key, which is a function
>> of
>> the Taro commitment being present.
>>
>> > There are two possible designs here: a.) The token history remains
>> separate ?
>> > Dave receives Alice's 2 tokens, Bob's tokens are split and he receives
>> 2 (or
>> > 3 from Bob 1 from Alice).  b.) The token history gets merged ? Dave
>> receives
>> > 4 tokens (linking the new output with both Alice and Bob's history).
>>
>> Mechanically, with respect to the way the change/UTXOs work in the
>> system, both
>> are expressible: Dave can chose to merge them into a single UTXO (with the
>> appropriate witnesses included for each of them), or Dave can keep them
>> distinct in the asset tree. You're correct in that asset issuers may opt
>> to
>> issue assets in denominations vs allowing them to be fully divisible.
>> Ultimately, the compatibility with the LN layer will be the primary way
>> to keep
>> asset histories compressed, without relying on another trust model, or
>> relying
>> on the incentive of an asset issuer to do a "re-genesis" which would
>> effectively re-create assets in a supply-preserving manner (burn N units,
>> then
>> produce a new genesis outpoint for N units). Alternatively,
>> implementations can
>> also chose to utilize a checkpointing system similar to what some Bitcoin
>> full
>> node clients do today.
>>
>> >  is that you end up with a linked transaction graph, just like in
>> Bitcoin
>>
>> This is correct, the protocol doesn't claim to achieve better privacy
>> guarantees than the base chain. However inheriting this transaction graph
>> model
>> imo makes it easier for existing Bitcoin developers to interact with the
>> system, and all the data structures are very familiar tooling wise.
>> However any
>> privacy enhancing protocol used for on-chain top-level Bitcoin UTXOs can
>> also
>> be applied to Taro, so people can use things like coinswap and coinjoin,
>> along
>> with LN to shed prior coin lineages.
>>
>> > This implies the location of the Taro tree inside the taproot tree is
>> not
>> > fixed. What needs to be prevented here is that a taproot tree contains
>> more
>> > than one Taro tree, as that would enable the owner of the commitment to
>> show
>> > different histories to different people.
>>
>> Great observation, I patched a similar issue much earlier in the design
>> process
>> by strongly binding all signatures to a prevOut super-set (so the outpoint
>> along with the unique key apth down into the tree), which prevents
>> duplicating
>> the asset across outputs, as signature verification would fail.
>>
>> In terms of achieving this level of binding within the Taro tree itself,
>> I can
>> think of three options:
>>
>>   1. Require the Taro commitment to be in the first/last position within
>> the
>>   (fully sorted?) Tapscript tree, and also require its sibling to be the
>> hash
>>   of some set string (all zeroes or w/e). We'd require the sibling to the
>> empty
>>   as the tapscript hashes are sorted before hashing so you sort of lose
>> that
>>   final ordering information.
>>
>>   2. Include the position of the Taro commitment within the tapscript tree
>>   within the sighash digest (basically the way the single input in the
>> virtual
>>   transaction is created from the TLV structure).
>>
>>   3. Include the position of the Taro commitment within the tapscript
>> tree as
>>   part of the message that's hashed to derive asset IDs.
>>
>> AFAICT, #1 resolves the issue entirely, #2 renders transfers outside of
>> the
>> canonical history invalid, and #2 minds hte asset ID to the initial
>> position
>> meaning you can track a canonical lineage from the very start.
>>
>> > Finally, let me conclude with two questions. Could you clarify the
>> purpose of
>> > the sparse merkle tree in your design?
>>
>> Sure, it does a few things:
>>
>>   * Non-inclusion proofs so I can do things like prove to your I'm no
>> longer
>>     committing to my 1-of-1 holographic beefzard card when we swap.
>>
>>   * The key/tree structure means that the tree is history independent,
>> meaning
>>     that if you and I insert the same things into the tree in a different
>>     order, we'll get the same root hash. This is useful for things like
>>     tracking all the issuance events for a given asset, or allowing two
>>     entities to sync their knowledge/history of a single asset, or a set
>> of
>>     assets.
>>
>>   * Each asset/script mapping to a unique location within the tree means
>> it's
>>     easy to ensure uniqueness of certain items/commitments (not possible
>> to
>>     commit to the same asset ID twice in the tree as an example).
>>
>>   * The merkle-sum trait means I that validation is made simpler, as you
>> just
>>     check that the input+output commitment sum to the same value, and I
>> can
>>     also verify that if we're swapping, then you aren't committing to more
>>     units that exist (so I make sure I don't get an invalid split).
>>
>> > And the second question ? when transferring Taro token ownership from
>> one
>> > Bitcoin UTXO to another, do you generate a new UTXO for the recipient
>> or do
>> > you support the ability to "teleport" the tokens to an existing UTXO
>> like how
>> > RGB does it? If the latter, have you given consideration to timing
>> issues
>> > that might occur when someone sends tokens to an existing UTXO that
>> > simultaneously happens to get spent by the owner?
>>
>> So for interactive transfers, the UTXOs generated as just the ones part
>> of the
>> MIMO transaction. When sending via the address format, a new non-dust
>> output is
>> created which holds the new commitment, and uses an internal key provided
>> by
>> the receiver, so only they can move the UTXO. Admittedly, I'm not
>> familiar with
>> how the RGB "teleport" technique works, I checked out some slide decks a
>> while
>> back, but they were mostly about all the new components they were
>> creating and
>> their milestone of 1 million lines of code. Can you point me to a coherent
>> explanation of the technique? I'd love to compare/contrast so we can
>> analyze
>> the diff tradeoffs being made here.
>>
>> Thanks for an initial round of feedback/analysis, I'll be updating the
>> draft
>> over the next few days to better spell things out and particularly that
>> commitment/sighash uniqueness trait.
>>
>> -- Laolu
>>
>> [1]:
>> https://twitter.com/roasbeef/status/1330654936074371073?s=20&t=feV0kWAjJ6MTQlFm06tSxA
>> [2]:
>> https://twitter.com/roasbeef/status/1330692571736117249?s=20&t=feV0kWAjJ6MTQlFm06tSxA
>>
> _______________________________________________
> Lightning-dev mailing list
> Lightning-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221103/a53b523d/attachment-0001.html>

From erik at q32.com  Thu Nov  3 13:32:20 2022
From: erik at q32.com (Erik Aronesty)
Date: Thu, 3 Nov 2022 09:32:20 -0400
Subject: [bitcoin-dev] Announcement: Full-RBF Miner Bounty
In-Reply-To: <fMZWicZXp5SM0ON8jgYuykBydOXcbgePbPfGKA0DQYtEDdiIr4bWljL_TqQHKtVKZRhvRXkEab47aaZw17OxGaSgOP2_w9_Owjb9WnTmsQ0=@protonmail.com>
References: <Y2I3w8O5X55sD/3C@petertodd.org>
 <fMZWicZXp5SM0ON8jgYuykBydOXcbgePbPfGKA0DQYtEDdiIr4bWljL_TqQHKtVKZRhvRXkEab47aaZw17OxGaSgOP2_w9_Owjb9WnTmsQ0=@protonmail.com>
Message-ID: <CAJowKgKGsAGQyCmx24fRZWrAWCVi91QKxXaQGiXLJ6zEFXnneg@mail.gmail.com>

actually, peter makes an important point here

technically, all we need is for *miners* to consistently mine "full rbf"

as long as they do, businesses that accept 0conf will have to adjust their
risk accordingly, and the problem of misaligned incentives is resolved

i don't think it matters what non-mining users do nearly as much


On Wed, Nov 2, 2022 at 3:05 PM alicexbt via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> Hi Peter,
>
> > tl;dr: I'm broadcasting full-RBF replacements paying extremely high fees
> to
> > reward miners that turn on full-RBF. I'm starting small, just
> ~$100/block in
> > times of congestion. Miner and pool profit margins are pretty small, on
> the
> > order of $1k/block in many cases, so I know it doesn't take that much
> more
> > money to make a difference.
>
> I appreciate this effort and perhaps this was all that was needed in
> addition to Bitcoin Core's inclusion of full rbf support. Making it default
> right away or enabling preferential peering with service flag in a bitcoin
> core release was unnecessary.
>
> > If you'd like to donate to this effort, send BTC to
> > bc1qagmufdn6rf80kj3faw4d0pnhxyr47sevp3nj9m
>
> Sorry, I don't trust you based on some of the things you support on
> Twitter. Hopefully, others will donate and help this bounty.
>
> /dev/fd0
>
> Sent with Proton Mail secure email.
>
> ------- Original Message -------
> On Wednesday, November 2nd, 2022 at 2:56 PM, Peter Todd via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>
> > I'm now running a full-RBf bounty program for miners.
> >
> > tl;dr: I'm broadcasting full-RBF replacements paying extremely high fees
> to
> > reward miners that turn on full-RBF. I'm starting small, just
> ~$100/block in
> > times of congestion. Miner and pool profit margins are pretty small, on
> the
> > order of $1k/block in many cases, so I know it doesn't take that much
> more
> > money to make a difference.
> >
> > Why should you do this? Full-RBF/zeroconf has been discussed to death.
> But
> > tl;dr: You'll earn more money, and help transition Bitcoin to a more
> secure
> > mempool policy based on economic incentives rather than trust.
> >
> >
> > If you're a miner and want to participate, the easiest way to so is to
> use the
> > mempoolfullrbf=1 option in the upcoming Bitcoin Core v24 release (eg the
> > 24.0rc3 tag), or use the mempoolreplacement=fee option in Bitcoin Knots.
> >
> > You can also just modify the code yourself by removing the opt-in RBF
> check.
> > For example against the v23.0 tag:
> >
> > $ git diff
> > diff --git a/src/validation.cpp b/src/validation.cpp
> > index 214112e2b..44c364623 100644
> > --- a/src/validation.cpp
> > +++ b/src/validation.cpp
> > @@ -736,7 +736,7 @@ bool MemPoolAccept::PreChecks(ATMPArgs& args,
> Workspace& ws)
> > // check all unconfirmed ancestors; otherwise an opt-in ancestor
> > // might be replaced, causing removal of this descendant.
> > if (!SignalsOptInRBF(*ptxConflicting)) {
> > - return state.Invalid(TxValidationResult::TX_MEMPOOL_POLICY,
> "txn-mempool-conflict");
> > + // return state.Invalid(TxValidationResult::TX_MEMPOOL_POLICY,
> "txn-mempool-conflict");
> > }
> >
> > ws.m_conflicts.insert(ptxConflicting->GetHash());
> >
> >
> > Once you've enabled full-RBF, you need a full-RBF peer. I'm running a
> few of
> > them:
> >
> > cup.nop.lol
> > mug.nop.lol
> > jar.nop.lol
> > jug.nop.lol
> >
> > These nodes run a preferential peering patch (
> https://github.com/bitcoin/bitcoin/pull/25600)
> > to ensure that full-RBF nodes are interconnected to each other and
> replacements
> > can easily propagate. Also feel free to contact me if you'd like to peer
> with a
> > private node.
> >
> >
> > If you'd like to donate to this effort, send BTC to
> > bc1qagmufdn6rf80kj3faw4d0pnhxyr47sevp3nj9m
> >
> >
> > ...and yes, I'm well aware that miners could collect this bounty in
> other ways,
> > eg by raising minimum fees. Doing that also breaks zeroconf, so I'm not
> too
> > concerned.
> >
> > --
> > https://petertodd.org 'peter'[:-1]@petertodd.org
> > _______________________________________________
> > bitcoin-dev mailing list
> > bitcoin-dev at lists.linuxfoundation.org
> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221103/4eeed0c1/attachment.html>

From jonasdnick at gmail.com  Thu Nov  3 14:43:22 2022
From: jonasdnick at gmail.com (Jonas Nick)
Date: Thu, 3 Nov 2022 14:43:22 +0000
Subject: [bitcoin-dev] MuSig2 BIP
In-Reply-To: <576db60c-b05b-5b9a-75e5-9610f3e04eda@gmail.com>
References: <46175970-d2ab-a58e-7010-f29820849604@gmail.com>
 <6d823ec7-fe88-9311-09e8-be22ca8bfd89@gmail.com>
 <576db60c-b05b-5b9a-75e5-9610f3e04eda@gmail.com>
Message-ID: <0d4bb432-771d-8b8e-f2f8-f86dca9f41c5@gmail.com>

We updated the MuSig2 BIP draft to fix the vulnerability published in an earlier
post [0].

We also wrote an article [1] that contains a description of
1. the vulnerable scheme (remember that the original MuSig2 scheme is not
    vulnerable because it doesn't allow tweaking)
2. an attack against the vulnerable scheme using Wagner's algorithm
3. a fixed scheme that permits tweaking

Moreover, we implemented the "BLLOR" attack mentioned in the article which
works against the reference python implementation of the previous version of the
MuSig2 BIP draft (takes about 7 minutes on my machine) [2].

The fix of the MuSig2 BIP is equivalent to the fix of the scheme in the article
[1]: before calling ''NonceGen'', the signer must determine the (potentially
tweaked) secret key it will use for this signature. BIP MuSig2 now ensures that
users can not accidentally violate this requirement by adding a mandatory public
key argument to ''NonceGen'', appending the public key to the ''secnonce'' array
and checking the public key against the secret key in ''Sign'' (see the pull
request for the detailed changes [3]).

[0] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-October/021000.html
[1] https://github.com/jonasnick/musig2-tweaking
[2] https://gist.github.com/robot-dreams/89ce8c3ff16f70cb2c55ba4fe9fd1b31 (must
     be copied into the bip-musig2 directory)
[3] https://github.com/jonasnick/bips/pull/74

From murch at murch.one  Thu Nov  3 17:53:26 2022
From: murch at murch.one (Murch)
Date: Thu, 3 Nov 2022 13:53:26 -0400
Subject: [bitcoin-dev] Refreshed BIP324
In-Reply-To: <zxv58iXZ73hf9ge8S0QLTanW-uLzaWjNtMHuKONP9hrqS5RhwitxzfVaMH8hbi3yImgNrKme3lCuDcHYKkpxEQHyGZZHJ8xtReOcnAx3o4g=@wuille.net>
References: <56677685-619a-691f-d5bc-54b69fdb6ed2@bip324.com>
 <zxv58iXZ73hf9ge8S0QLTanW-uLzaWjNtMHuKONP9hrqS5RhwitxzfVaMH8hbi3yImgNrKme3lCuDcHYKkpxEQHyGZZHJ8xtReOcnAx3o4g=@wuille.net>
Message-ID: <d4272a20-b2a7-4ad8-9b41-8ce2b7ce827d@murch.one>

Hi Pieter, hello list,

On 26.10.22 12:39, Pieter Wuille via bitcoin-dev wrote:
> 1. The most straightforward solution is using the BIP process as-is: let BIP324
>     introduce a fixed initial table, and future BIPs which introduce new
>     messages can introduce new mapping entries for it. In theory, this is no
>     worse than the current coordination difficulty about command strings, but
>     in practice the risk of collisions due to competing proposals is of course
>     significantly larger with 1-byte IDs vs. 12-byte strings.

 From what I understand we'll have about 35 message types on the network 
with the addition of BIP324. 256 possible IDs sounds like plenty room to 
grow, but perhaps we can be a bit more conservative:

We could use the first bit to signal a 2-byte message ID. That allows us 
to express 128 IDs with 1 byte, but if we need more, we get a total of 
2^15 IDs across 2 bytes.

I would not be too concerned about collisions. Firstly, message types 
would probably be announced to the mailing list as part of the 
corresponding BIP, secondly, any overlooked collision should become 
apparent at implementation time. The risk could perhaps be further 
mitigated by encouraging less prevalent message types to use a 2-byte ID.

Cheers,
Murch
-------------- next part --------------
A non-text attachment was scrubbed...
Name: OpenPGP_signature
Type: application/pgp-signature
Size: 833 bytes
Desc: OpenPGP digital signature
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221103/fa31bbc7/attachment.sig>

From email at yancy.lol  Thu Nov  3 21:06:52 2022
From: email at yancy.lol (email at yancy.lol)
Date: Thu, 03 Nov 2022 22:06:52 +0100
Subject: [bitcoin-dev] On mempool policy consistency
Message-ID: <16eb6a50691ccc661310051de6b8e2c0@yancy.lol>


AJ/Antoine et al

> What should folks wanting to do coinjoins/dualfunding/dlcs/etc do to
> solve that problem if they have only opt-in RBF available?

Assuming Alice is a well funded advisory, with enough resources to spam 
the network so that enough nodes see her malicious transaction first, 
how does full-rbf solve this vs. opt-in rbf?

Cheers,
-Yancy

On 2022-10-27 19:21, Anthony Towns via bitcoin-dev wrote:

> On Thu, Oct 27, 2022 at 11:56:45AM +0200, John Carvalho via bitcoin-dev 
> wrote:
> 
>> I took the time to read your whole post. Despite a diplomatic tone, I 
>> find
>> your takeaways from all your references to remain conveniently biased 
>> for
>> protecting the plan of RBF
> 
> Yes, I am heavily biased against zeroconf: there's no way I'd 
> personally
> be willing to trust it for my own incoming funds, no matter how much
> evidence you show me that it's safe in practice. Show me a million
> transactions where every single one worked fine, and I'm still going to
> assume that the payment going to me is going to be the one that makes
> the error rate tick up from 0% to 0.0001%. That's okay; just because I
> wouldn't do something, doesn't mean other people shouldn't.
> 
> It does mean I'm not going to be a particularly good advocate for 
> zeroconf
> though. I mean, I might still be a fine advocate for giving people time
> to react, making it clear what's going on, finding ways that might make
> everyone happy, or just digging it to random technical details; but,
> for me, I'm more interested in a world where chargebacks are 
> impossible,
> not where we just make the best of what was possible with technology
> from five or ten years ago.
> 
> But that's fine: it just means that people, like yourself, who will
> tolerate the risks of zeroconf, should be involved in the discussion.
> 
>> You show multiple examples where, when I read them, I assume the next 
>> thing
>> you will say will be "so we really should stop trying to impose 
>> optional
>> features, particularly when they affect existing use cases" but 
>> instead you
>> persist.
> 
> Sure, that's natural: you read a sign saying "you can have any ice 
> cream
> you want for 5c" and think "Awesome, who wouldn't want cheap chocolate
> ice cream!!" and see me going for a Golden Gaytime and think "wtf 
> dude".
> Different strokes.
> 
> For me, I see the gmaxwell github comment I quoted saying:
> 
> There is also a matter of driving competent design rather than lazy
> first thing that works.
> 
> and think "yeah, okay, maybe we should be working harder to push 
> lightning
> adoption, rather than letting people stick with wallet UX from 2015"
> and have altcoins take over >50% of payment volume.
> 
> Likewise,
> 
> There is also a very clear pattern we've seen in the past where
> people take anything the system lets them do as strong evidence that
> they have a irrevocable right to use the system in that way, and that
> their only responsibility-- and if their usage harms the system it's
> the responsibility of the system to not permit it.
> 
> seems a pretty good match against your claim "I expect the things I do
> with Bitcoin today to work FOREVER." Better to nip that thinking in the
> bud; and even if the best time to do that was years ago, the second 
> best
> time to do it is still now.
> 
> By contrast, from the same post, I'd guess you're focussing on:
> 
> Network behavior is one of the few bits of friction
> driving good technical design rather than "move fast, break things, and
> force everyone else onto my way of doing thing rather than discussing
> the design in public".
> 
> and thinking "yeah, move fast, break things, force everyone else --
> that's exactly what's going on here, and shouldn't be".
> 
> But that's also okay: even when there is common ground to be found,
> sometimes it requires actual work to get people who start from 
> different
> views to get there.
> 
>> The problem is that RBF has already been an option for years, and 
>> anyone
>> that wants to use it can.
> 
> Is that true? Antoine claims [1 [1]] that opt-in RBF isn't enough to 
> avoid
> a DoS issue when utxos are jointly funded by untrusting partners, and,
> aiui, that's the main motivation for addressing this now.
> 
> [1] 
> https://lists.linuxfoundation.org/pipermail/lightning-dev/2021-May/003033.html
> 
> The scenario he describes is: A, B, C create a tx:
> 
> inputs: A1, B1, C1 [opts in to RBF]
> fees: normal
> outputs:
> [lightning channel, DLC, etc, who knows]
> 
> they all analyse the tx, and agree it looks great; however just before
> publishing it, A spams the network with an alternative tx, double
> spending her input:
> 
> inputs: A1 [does not opt in to RBF]
> fees: low
> outputs: A
> 
> If A gets the timing right, that's bad for B and C because they've
> populated their mempool with the 1st transaction, while everyone else
> sees the 2nd one instead; and neither tx will replace the other. B and
> C can't know that they should just cancel their transaction, eg:
> 
> inputs: B1, C1 [opts in to RBF]
> fees: 50% above normal
> outputs:
> [smaller channel, refund, whatever]
> 
> and might instead waste time trying to fee bump the tx to get it mined,
> or similar.
> 
> What should folks wanting to do coinjoins/dualfunding/dlcs/etc do to
> solve that problem if they have only opt-in RBF available?
> 
> If you're right that opt-in RBF is enough, that question has a good
> answer. I don't believe anyone's presented an answer to it in the 17
> months since Antoine raised the concern.
> 
>> passive aggression
>> escalation
>> unfair advantage
>> oppressive, dark-pattern design
>> strong-arming and shoe-horning
> 
> Do you really think any of that was helping your cause?
> 
> Cheers,
> aj
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev


Links:
------
[1] 
https://lists.linuxfoundation.org/pipermail/lightning-dev/2021-May/003033.html
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221103/bccd03d2/attachment-0001.html>

From dev at jonasschnelli.ch  Thu Nov  3 22:26:54 2022
From: dev at jonasschnelli.ch (Jonas Schnelli)
Date: Thu, 3 Nov 2022 12:26:54 -1000
Subject: [bitcoin-dev] Refreshed BIP324
In-Reply-To: <d4272a20-b2a7-4ad8-9b41-8ce2b7ce827d@murch.one>
References: <56677685-619a-691f-d5bc-54b69fdb6ed2@bip324.com>
 <zxv58iXZ73hf9ge8S0QLTanW-uLzaWjNtMHuKONP9hrqS5RhwitxzfVaMH8hbi3yImgNrKme3lCuDcHYKkpxEQHyGZZHJ8xtReOcnAx3o4g=@wuille.net>
 <d4272a20-b2a7-4ad8-9b41-8ce2b7ce827d@murch.one>
Message-ID: <87FFCF31-946A-44AE-8AAE-6FA3E6465C89@jonasschnelli.ch>


> From what I understand we'll have about 35 message types on the network with the addition of BIP324. 256 possible IDs sounds like plenty room to grow, but perhaps we can be a bit more conservative:
> 
> We could use the first bit to signal a 2-byte message ID. That allows us to express 128 IDs with 1 byte, but if we need more, we get a total of 2^15 IDs across 2 bytes.

Could make sense.

There would be an alternative to preserve more 1 byte IDs on the cost of a (much) smaller 2 byte ID space:
Reserve the short ID 0xFF as an indication for a 2 bytes short ID (additional 256 short IDs with 2 bytes).
That could be done later outside BIP324.
The 0xFF approach would lead to approx. 207 unused 1 byte short IDs (while Murchs approach would give us approx. 79 unused 1 byte short IDs).
The signal bit two byte approach would however lead to ~32k more two byte message IDs.

The main (and only?) benefit of short IDs is bandwidth.
Short ID 1-12 are reserved for string based IDs and thus, new and rarely sent message types must not always use a short ID.

Maybe the BIP should state that only frequent sent messages should reserve a short ID, though, the BIP itself assigns short IDs to all(?) message types (including low frequent messages like SENDHEADERS).

Maybe exclude message types that expected to be only sent once from assigning a short ID?

/j

From email at yancy.lol  Fri Nov  4 10:28:17 2022
From: email at yancy.lol (email at yancy.lol)
Date: Fri, 04 Nov 2022 11:28:17 +0100
Subject: [bitcoin-dev] On mempool policy consistency
In-Reply-To: <Y2ALDu36tMQxVr/i@petertodd.org>
References: <Y1nIKjQC3DkiSGyw@erisian.com.au>
 <CAFp6fsFm06J2G1=3ojQvcL9gbEbQ41C4rmf3=Jkm9Qm0VBhhKw@mail.gmail.com>
 <CAB3F3Dt=2hDXXw6Jz9QwnotkNLyGdZn9GZLHFXu0Dnyz3tsc0w@mail.gmail.com>
 <23dac89d36c356b9266db07e09c2de8e@yancy.lol>
 <Y2ALDu36tMQxVr/i@petertodd.org>
Message-ID: <d98309a7388a23f5600b7cf76d9a08f6@yancy.lol>



Peter,

> There's nothing special about a "full-rbf transaction" other than the 
> fact
> that it's replacing a previously broadcast transaction that didn't 
> signal
> replacement.

Thanks, this is a piece I haven't seen.  It sounds like "full-rbf" 
policy is fundamentally different from BIP125, where in BIP125 a 
transaction must signal that it can be replaced.  If I'm reading what 
you said correctly, then "full-rbf" policy will allow the replacement of 
any transaction, whether it's signaled or not..

> Since all the machinery to do replacemnt already exists, adding a 
> full-rbf
> config flag is particularly trivial. It requires just a single line in 
> the
> mempool code.

Agree the flag is trivial.  The interplay between mempool policies may 
not be trivial.

Cheers,
-Yancy

On 2022-10-31 18:51, Peter Todd wrote:

> On Mon, Oct 31, 2022 at 06:21:08PM +0100, yancy via bitcoin-dev wrote:
> 
>> Protocol Devs,
>> 
>> After reading through this email thread and BIP125, I'm curious if 
>> non-rbf
>> nodes will relay full-rbf transactions and vice versa.  That is to 
>> say, if
>> only one non-rbf node exists on the network, however, every other node
>> implements full-rbf, will the transaction still be propagated?  IE can 
>> we
>> always guarantee a path through the network for either transaction 
>> type no
>> matter what the combination of network policies are?
> 
> 1) There are nodes that signal full-rbf, and preferentially peer to 
> each other,
> thus ensuring good transaction propagation. The most recent patch to 
> implement
> this is: https://github.com/bitcoin/bitcoin/pull/25600
> 
> There's enough peers running full-rbf that the last time I started up a 
> new
> node on a fresh IP address, it happened to have a peer relaying 
> full-rbf
> replacements to it. And of course, if people want full-rbf to work more
> reliably, it's very easy to just run some nodes with a large number of 
> outgoing
> peers. Changing the hard-coded 8 outgoing peers to, say, 800, isn't 
> very hard.
> 
> 2) There's nothing special about a "full-rbf transaction" other than 
> the fact
> that it's replacing a previously broadcast transaction that didn't 
> signal
> replacement. There is not consensus over the mempool, so in certain 
> cases
> non-full-rbf nodes will in fact broadcast replacements when they didn't 
> happen
> to receive the "first" transaction first.
> 
> The latter makes testing full-rbf a bit problematic, as if you don't 
> take
> special measures to ensure good propagation a small % of the time the
> "replacement" transaction will in fact be the one that gets gets mined.
> 
> Does fullrbf offer any benefits other than breaking zeroconf
> business practices?  If so, what are they?
> I think AJ mentioned this earlier, but adding more configuration 
> options
> always increases code complexity, and with that, there is likely more
> unforeseen bugs.  However, there is a section of network participants 
> that
> rely on both types of transaction policy, so from my limited 
> view-point, it
> seems worth accommodating if possible.

Since all the machinery to do replacemnt already exists, adding a 
full-rbf
config flag is particularly trivial. It requires just a single line in 
the
mempool code.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221104/e8a258ae/attachment.html>

From trey.delbonis at protonmail.com  Fri Nov  4 19:53:31 2022
From: trey.delbonis at protonmail.com (Trey Del Bonis)
Date: Fri, 04 Nov 2022 19:53:31 +0000
Subject: [bitcoin-dev] Validity Rollups on Bitcoin
In-Reply-To: <WJ0jiInq_I_IiiT8EiAZZN6axo2pSIRCxQWfyvgU-4rjRmeHnCXFNGWFSXoeOv7nVmqoAPr6EHeXRgc-1DfiPX3C8xHwdYzs2qn4Lck06fs=@protonmail.com>
References: <689ed481-e7eb-4fea-8ca7-578503f3f285@app.fastmail.com>
 <CAB3F3Dt5oy93duGvYb7SZ7wn7DCvn9FjVwRU9ENNa79yjzmdCQ@mail.gmail.com>
 <224cf2f4-2577-4331-9977-ea71e9723ffe@app.fastmail.com>
 <WJ0jiInq_I_IiiT8EiAZZN6axo2pSIRCxQWfyvgU-4rjRmeHnCXFNGWFSXoeOv7nVmqoAPr6EHeXRgc-1DfiPX3C8xHwdYzs2qn4Lck06fs=@protonmail.com>
Message-ID: <629da3d8-ee34-9acb-511b-4af1913eceff@protonmail.com>

Hi all, I figured I could answer some of these rollup questions,

There's a few different possibilities to make rollups work that have
different tradeoffs.? The core construction I worked out in [1] involves
a quine-ish recursive covenant that stores some persistent "state" as
part of the beginning of the script which is then updated by the
transaction according to rules asserted by the program and then
constructs a new scriptPubKey that we assert is on the first output.?
This is apparently not a new idea, as I was recently made aware of that
the sCrypt project does something similar to build a Solidity-looking
stateful contract environment by using OP_PUSH_TX.

Instead of that approach, I assume we have fairly granular transaction
introspection opcodes from a list in Elements [2] (which seem like they
aren't actually used in mainnet Liquid?) that can be used to implement
covenants since the 520 byte limit means it's hard to pull data out of
OP_PUSH_TX.? I also assume some math and byte manipulation opcodes
(OP_ADD, OP_MUL, OP_CAT, OP_RIGHT, OP_LEFT, OP_SUBSTR, etc.) that were
disabled years ago are re-added.

One complicated part is the actual proof verification.? I had considered
looking into what it would take to build a verifying for a modern proof
system if we used pairings as a primitive, but it turns out even that is
pretty involved even in a higher level language (at least for PLONK [3])
and would be error-prone when trying to adapt the code for new circuits
with differently-shaped public inputs.? The size of the code on-chain
alone would probably make it prohibitively expensive, so it would be a
lot more efficient just to assume we can introduce a specific opcode for
doing a proof verification implemented natively.? The way I assumed it
would work is taking the serialized proof, a verification key, and the
public input as separate stack items.? The public input is the
concatenation of the state and deposit commitments we took from the
input, the batch post-state commitment (provided as part of the
witness), data from transaction outputs corresponding to
internally-initiated withdrawals from the rollup, and the rollup batch
data itself (also passed as part of the witness).

The parameters used in the PLONK system for the one zk-rollup I looked
at give us a verification key size of 964 bytes and a proof size of 1088
bytes, which means that they're larger than the 520 byte stack element
size limit so we'd actually have to use 2 stack elements for those.? But
that seems messy.? The worse issue though is the public inputs would
probably blow way past the 520 byte stack element size limit, especially
if we wanted to pack a lot of batch txs in there.? One solution to that
is by designing the proof verification opcode to take multiple stack
elements, but the complexity to shuffle around the elements as we're
getting ready to verify the proof seems like it would be extremely error
prone and would further impact the size of the script.? The size of the
script alone is very roughly around 1000 bytes.

Other nice-to-haves:

* something like OP_PUSHSCRIPT which would remove the need for the
introspection the the prevout's script and avoids duplicating data in
the witness
* some kind of OP_MERKLEUPDATEVERIFY which checks a merkle proof for a
leaf against a root *and* checks if replacing the leaf with some hash
using the proof yields a specified updated root (or instead, a version
that just pushes the updated root)
* if we really wanted to golf the size of the script, then possibly a
limited form of OP_EVAL if we can't figure out another way to split up
the different spend paths into different tapleafs while still being able
to do the recursive covenant, but still the script and the vk would
still be significant so it's not actually that much benefit per-batch
* a negative relative timelock to prevent a sniping issue I outlined in
the doc

It's probably possible that some of the introspection opcodes to look at
outputs could be replaced with OP_CHECKTEMPLATEVERIFY and putting a copy
of all the outputs on the stack, which combined with OP_PUSHSCRIPT means
I think we wouldn't need any of the Elements-style introspection opcodes
linked above, but it would be slightly messier and mean more data needs
to get duplicated in the witness.

It may be the case that there's enough issues with the above
requirements that the safer path to take is just to soft-fork in
Simplicity (or something like Chialisp as was suggested for
consideration in a prior mailing list thread a while back [4]) with
support for the necessary transaction introspection and go from there.?
Regardless of which option is decided upon, somehow we'll need to use a
new witness version since there's non-soft-forkable requirements in any
other case.

Moving on, I had not considered the possibility that a non-zk optimistic
rollup might be practical on Bitcoin.? I had assumed based on my
understanding of existing ones that the amount of statefulness required
across multiple transactions playing out the fraud game would make it
infeasible, but it would be interesting to see if I was wrong.

The current centralization in productionalized rollups definitely is a
cause for concern.? I think it would be unwise to drop all restrictions
on who can submit a batch (since then a trivial DoS would be to just
submit empty batches with a high fee rate as soon as the batch
submission window opens, which would be more efficient at outcompeting
an honest sequencer submitting nonempty batches), but a moderately large
rotating set of sequencers (64 seems like a good number?? with some
sequencer skipping mechanism if the next one fails to propose in time)
is something that seems pretty possible without substantially changing
the design.

How you'd pick who gets to be in the quorum is another open question,
but perhaps it could be based on using lightning nodes, which would be
somewhat sibyl resistant since we could semi-verifiably check for
long-lived nodes with a consistent level of activity as a proxy for
honesty.? But that still feels like a centralizing force.? In practice I
would expect several instances of these rollups with staggered batch
submissions to run in parallel, hopefully with mostly disjoint sets of
sequencers.

-Trey

[1] https://tr3y.io/articles/crypto/bitcoin-zk-rollups.html
[2]
https://github.com/ElementsProject/elements/blob/2dda79cf616e8928346eeb9e3282f5744955aa88/doc/tapscript_opcodes.md
[3]
https://github.com/matter-labs/zksync/blob/master/contracts/contracts/PlonkCore.sol
[4]
https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-March/020036.html

On 11/2/22 13:19, AdamISZ via bitcoin-dev wrote:
> Hi John,
>
> Sorry for late feedback. Very much appreciated the in depth report!
>
> So, I second Greg's main question, which I've really been thinking about a bit myself since starting to research this area more: it feels like the Bitcoin protocol research community (or, uh, some of it) should focus in on this question of: what is the minimal functionality required onchain (via, presumably soft fork) that enables something close to general purpose offchain contracting that is provable, ideally in zero knowledge, but at the very least, succinctly, with onchain crypto operations. An example might be: if we had verification of bilinear pairings onchain, combined with maybe some covenant opcode, does it give us enough to do something like a rollup/sidechain model with full client side computation and very compact state update and verification onchain? (To be clear: just made that up! there is certainly no deep theory behind that particular combination .. although I did see this [1] thread on *optimistic* + covenant).
>
> Is the actual answer to this something like Simplicity? (Above my paygrade to answer, that's for sure!)
>
> Ideally you would want (don't laugh) for this to be the 'soft fork to end all soft forks' so that innovation could all be then in higher layers.
>
> As to rollups themselves: centralization in the sequencer/publisher of state updates seems to be a really big issue that's somewhat brushed under the carpet. Depending on the model, there are cases where it actually is a theft risk (e.g. full control of an onchain smart contract), but there's significant censorship risk at the very least, as well as availability/uptime risk. At the extreme, Optimism has a 'security model' [3] that is frankly laughable (though, no doubt it's possible that will radically change) and for things like Arbitrum you have centralized sequencers, where the claim is that it will migrate to a more decentralized model; maybe, but that's a huge part of the challenge here, so while it's nice to see the sexy 'fast, cheap, scale' aspect straight away, I feel like those models haven't done the hard part yet. I also think these optimistic L2 models have a 'fake finality' issue from my perspective; the delay needed onchain is how long it takes to *really* confirm. (e.g
>   .: rollups look cool compared to sidechains from the pov of 'instant' instead of confirmations on a chain, but that seems a bit sleight-of-hand-y).
>
> It's notable to compare that with a payment-channels style L2 where decentralization and trustlessness are sine-qua-non and so the limitations are much more out in the open (e.g. the capacity tradeoff - while the 'instantness' is much more real perhaps, with the appropriate liveness caveat).
>
> For the validity rollups, some of the above qualms don't apply, but afaik the concrete instantiations today still have this heavy sequencer/publisher centralization. Correct me if I'm wrong.
>
> In any case, I do agree with a lot of people that some variant of this model (validity rollups) intuitively looks like a good choice, for the future, in comparison with other possible L2s that focus on *functionality* - with a mild censorship and centralization tradeoff perhaps.
>
> And I'm maybe a bit heretical but I see no issue with using 1 of N security models for trusted setup here (note how it's probably different from base chain), so PLONK type stuff is just as, if not more, interesting than STARKS which aiui are pretty big and computationally heavy (sure, maybe that changes). So if that's true, it comes back to my first paragraph.
>
> Cheers,
> AdamISZ/waxwing
>
> [1] https://nitter.it/salvatoshi/status/1537362661754683396
> [3] https://community.optimism.io/docs/security-model/optimism-security-model/
>
>
> Sent with Proton Mail secure email.
>
> ------- Original Message -------
> On Wednesday, October 12th, 2022 at 16:40, John Light via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>
>> On Wed, Oct 12, 2022, at 9:28 AM, Greg Sanders wrote:
>>
>>> Is there a one page cheat sheet of "asks" for transaction
>>> introspection/OP_ZKP(?) and their uses both separately and together for
>>> different rollup architectures?
>>
>> We do not have this yet. Trey Del Bonis wrote a more detailed technical post about how those components would be used in a validity rollup, which was cited in my report and can be found here:
>> https://tr3y.io/articles/crypto/bitcoin-zk-rollups.html
>>
>> But it'll take more research and design work to suss out those details you asked for and put them into a nice cheatsheet. I like this idea though!
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev



From roconnor at blockstream.com  Fri Nov  4 20:29:26 2022
From: roconnor at blockstream.com (Russell O'Connor)
Date: Fri, 4 Nov 2022 16:29:26 -0400
Subject: [bitcoin-dev] Validity Rollups on Bitcoin
In-Reply-To: <629da3d8-ee34-9acb-511b-4af1913eceff@protonmail.com>
References: <689ed481-e7eb-4fea-8ca7-578503f3f285@app.fastmail.com>
 <CAB3F3Dt5oy93duGvYb7SZ7wn7DCvn9FjVwRU9ENNa79yjzmdCQ@mail.gmail.com>
 <224cf2f4-2577-4331-9977-ea71e9723ffe@app.fastmail.com>
 <WJ0jiInq_I_IiiT8EiAZZN6axo2pSIRCxQWfyvgU-4rjRmeHnCXFNGWFSXoeOv7nVmqoAPr6EHeXRgc-1DfiPX3C8xHwdYzs2qn4Lck06fs=@protonmail.com>
 <629da3d8-ee34-9acb-511b-4af1913eceff@protonmail.com>
Message-ID: <CAMZUoK=O967fgNkmbEcLAJ6N54GuT7vwAAP5FFvKLoYtoD4=2A@mail.gmail.com>

On Fri, Nov 4, 2022 at 4:04 PM Trey Del Bonis via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

>
> Instead of that approach, I assume we have fairly granular transaction
> introspection opcodes from a list in Elements [2] (which seem like they
> aren't actually used in mainnet Liquid?)


These opcodes went live on Liquid along with Taproot <
https://blog.liquid.net/taproot-on-liquid-is-now-live/>, so feel free to
try them out on Elements or Liquid.

One complicated part is the actual proof verification.  I had considered
> looking into what it would take to build a verifying for a modern proof
> system if we used pairings as a primitive, but it turns out even that is
> pretty involved even in a higher level language (at least for PLONK [3])
> and would be error-prone when trying to adapt the code for new circuits
> with differently-shaped public inputs.  The size of the code on-chain
> alone would probably make it prohibitively expensive, so it would be a
> lot more efficient just to assume we can introduce a specific opcode for
> doing a proof verification implemented natively.  The way I assumed it
> would work is taking the serialized proof, a verification key, and the
> public input as separate stack items.  The public input is the
> concatenation of the state and deposit commitments we took from the
> input, the batch post-state commitment (provided as part of the
> witness), data from transaction outputs corresponding to
> internally-initiated withdrawals from the rollup, and the rollup batch
> data itself (also passed as part of the witness).
>

I'd be interested in knowing what sort of Simplicity Jets would facilitate
rollups.  I suppose some pairing-friendly curve operations would do.  It
might not make the first cut of Simplicity, but we will see.

Simplicity's design doesn't have anything like a 520 byte stack limit.
There is just going to be an overall maximum allowed Simplicity evaluation
state size of some value that I have yet to decide.  I would imagine it to
be something like 1MB.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221104/8ff770cd/attachment.html>

From ZmnSCPxj at protonmail.com  Fri Nov  4 23:07:56 2022
From: ZmnSCPxj at protonmail.com (ZmnSCPxj)
Date: Fri, 04 Nov 2022 23:07:56 +0000
Subject: [bitcoin-dev] Validity Rollups on Bitcoin
In-Reply-To: <629da3d8-ee34-9acb-511b-4af1913eceff@protonmail.com>
References: <689ed481-e7eb-4fea-8ca7-578503f3f285@app.fastmail.com>
 <CAB3F3Dt5oy93duGvYb7SZ7wn7DCvn9FjVwRU9ENNa79yjzmdCQ@mail.gmail.com>
 <224cf2f4-2577-4331-9977-ea71e9723ffe@app.fastmail.com>
 <WJ0jiInq_I_IiiT8EiAZZN6axo2pSIRCxQWfyvgU-4rjRmeHnCXFNGWFSXoeOv7nVmqoAPr6EHeXRgc-1DfiPX3C8xHwdYzs2qn4Lck06fs=@protonmail.com>
 <629da3d8-ee34-9acb-511b-4af1913eceff@protonmail.com>
Message-ID: <ifQPuaXwfXmFtiJrak3aOvpXG8fzm3-eNDCJVS_Us6WI-gcrd4vGeV6ZGk5sKDoy4SEz2K1PSMcVpflRXUmvud1gpVWWDgQr26e-1U5XJ5k=@protonmail.com>

Good morning Trey,

> * something like OP_PUSHSCRIPT which would remove the need for the
> introspection the the prevout's script and avoids duplicating data in
> the witness
> * some kind of OP_MERKLEUPDATEVERIFY which checks a merkle proof for a
> leaf against a root and checks if replacing the leaf with some hash
> using the proof yields a specified updated root (or instead, a version
> that just pushes the updated root)
> * if we really wanted to golf the size of the script, then possibly a
> limited form of OP_EVAL if we can't figure out another way to split up
> the different spend paths into different tapleafs while still being able
> to do the recursive covenant, but still the script and the vk would
> still be significant so it's not actually that much benefit per-batch

A thing I had been musing on is to reuse pay-to-contract to store a commitment to the state.

As we all know, in Taproot, the Taproot outpoint script is just the public key corresponding to the pay-to-contract of the Taproot MAST root and an internal public key.

The internal public key can itself be a pay-to-contract, where the contract being committed to would be the state of some covenant.

One could then make an opcode which is given an "internal internal" pubkey (i.e. the pubkey that is behind the pay-to-contract to the covenant state, which when combined serves as the internal pubkey for the Taproot construct), a current state, and an optional expected new state.
It determines if the Taproot internal pubkey is actually a pay-to-contract of the current state on the internal-internal pubkey.
If the optional expected new state exists, then it also recomputes a pay-to-contract of the new state to the same internal-internal pubkey, which is a new Taproot internal pubkey, and then recomputes a pay-to-contract of the same Taproot MAST root on the new Taproot internal pubkey, and that the first output commits to that.

Basically it retains the same MASTed set of Tapscripts and the same internal-internal pubkey (which can be used to escape the covenant, in case a bug is found, if it is an n-of-n of all the interested parties, or otherwise should be a NUMS point if you trust the tapscripts are bug-free), only modifying the covenant state.
The covenant state is committed to on the Taproot output, indirectly by two nested pay-to-contracts.

With this, there is no need for quining and `OP_PUSHSCRIPT`.
The mechanism only needs some way to compute the new state from the old state.

In addition, you can split up the control script among multiple Tapscript branches and only publish onchain (== spend onchain bytes) the one you need for a particular state transition.

Regards,
ZmnSCPxj

From laolu32 at gmail.com  Sat Nov  5 00:35:53 2022
From: laolu32 at gmail.com (Olaoluwa Osuntokun)
Date: Fri, 4 Nov 2022 17:35:53 -0700
Subject: [bitcoin-dev] [Lightning-dev] Taro: A Taproot Asset
 Representation Overlay
In-Reply-To: <CAD3i26AOmfHz1aOJGwzixQuwMtoo=v5qbveZUasbkzL1sPJWLw@mail.gmail.com>
References: <CAO3Pvs_pkYAYsrAEtv3KuJevXQHBLZQ-ihjP4Ur_A1NjJRA+Lw@mail.gmail.com>
 <CAPv7TjYTjvSV7UFgOwif6tFj3jVxDfJdW-p_cyPoAGGWKQbwRQ@mail.gmail.com>
 <CAO3Pvs_-igT37fcD29=ATSRX7dW5mGKrLGrXp=iJjaN_t3NGww@mail.gmail.com>
 <CAPv7TjZjZU2bYvUrt-BEx80xKF=BHBbrYWigHB+=yY+YfZX9Yg@mail.gmail.com>
 <CAD3i26AOmfHz1aOJGwzixQuwMtoo=v5qbveZUasbkzL1sPJWLw@mail.gmail.com>
Message-ID: <CAO3Pvs9EeKu1p9egeeRZduvgX_Xf21rh0N8iRY9xo2m01sw_oA@mail.gmail.com>

Hi Johan,

I haven't really been able to find a precise technical explanation of the
"utxo teleport" scheme, but after thinking about your example use cases a
bit, I don't think the scheme is actually sound. Consider that the scheme
attempts to target transmitting "ownership" to a UTXO. However, by the time
that transaction hits the chain, the UTXO may no longer exist. At that
point, what happens to the asset? Is it burned? Can you retry it again? Does
it go back to the sender?

As a concrete example, imagine I have a channel open, and give you an
address to "teleport" some additional assets to it. You take that addr, then
make a transaction to commit to the transfer. However, the block before you
commit to the transfer, my channel closes for w/e reason. As a result, when
the transaction committing to the UTXO (blinded or not), hits the chain, the
UTXO no longer exists. Alternatively, imagine the things happen in the
expected order, but then a re-org occurs, and my channel close is mined in a
block before the transfer. Ultimately, as a normal Bitcoin transaction isn't
used as a serialization point, the scheme seems to lack a necessary total
ordering to ensure safety.

If we look at Taro's state transition model in contrast, everything is fully
bound to a single synchronization point: a normal Bitcoin transaction with
inputs consumed and outputs created. All transfers, just like Bitcoin
transactions, end up consuming assets from the set of inputs, and
re-creating them with a different distribution with the set of outputs. As a
result, Taro transfers inherit the same re-org safety traits as regular
Bitcoin transactions. It also isn't possible to send to something that won't
ultimately exist, as sends create new outputs just like Bitcoin
transactions.

Taro's state transition model also means anything you can do today with
Bitcoin/LN also apply. As an example, it would be possible for you to
withdrawn from your exchange into a Loop In address (on chain to off chain
swap), and have everything work as expected, with you topping off your
channel. Stuff like splicing, and other interactive transaction construction
schemes (atomic swaps, MIMO swaps, on chain auctions, etc) also just work.

Ignoring the ordering issue I mentioned above, I don't think this is a great
model for anchoring assets in channels either. With Taro, when you make the
channel, you know how many assets are committed since they're all committed
to in the funding output when the channel is created. However, let's say we
do teleporting instead: at which point would we recognize the new asset
"deposits"? What if we close before a pending deposits confirms, how can one
regain those funds? Once again you lose the serialization of events/actions
the blockchain provides. I think you'd also run into similar issues when you
start to think about how these would even be advertised on a hypothetical
gossip network.

I think one other drawback of the teleport model iiuc is that: it either
requires an OP_RETURN, or additional out of band synchronization to complete
the transfer. Since it needs to commit to w/e hash description of the
teleport, it either needs to use an OP_RETURN (so the receiver can see the
on chain action), or the sender needs to contact the receiver to initiate
the resolution of the transfer (details committed to in a change addr or
w/e).

With Taro, sending to an address creates an on-chain taproot output just
like sending to a P2TR address. The creation of the output directly creates
the new asset anchor/output as well, which allows the receiver to look for
that address on chain just like a normal on chain transaction. To 3rd party
observers, it just looks like a normal P2TR transfer. In order to finalize
the receipt of the asset, the receiver needs to obtain the relevant
provenance proofs, which can be obtained from a multi-verse gRPC/HTTP
service keyed by the input outpoint and output index. In short, the send
process is fully async, with the sender and receiver using the blockchain
itself as a synchronization point like a normal Bitcoin wallet.

-- Laolu
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221104/354c256b/attachment.html>

From pete at petertodd.org  Sat Nov  5 02:35:03 2022
From: pete at petertodd.org (Peter Todd)
Date: Fri, 4 Nov 2022 22:35:03 -0400
Subject: [bitcoin-dev] On mempool policy consistency
In-Reply-To: <CAFp6fsFm06J2G1=3ojQvcL9gbEbQ41C4rmf3=Jkm9Qm0VBhhKw@mail.gmail.com>
References: <Y1nIKjQC3DkiSGyw@erisian.com.au>
 <CAFp6fsFm06J2G1=3ojQvcL9gbEbQ41C4rmf3=Jkm9Qm0VBhhKw@mail.gmail.com>
Message-ID: <Y2XL16AkpH+xNi9B@petertodd.org>

On Mon, Oct 31, 2022 at 09:02:02AM -0400, Suhas Daftuar via bitcoin-dev wrote:

Sending this email for the sake of repeating a point I made on GitHub for the
mailing list audience:

> AJ,
> 
> Thanks for the thoughtful post. I think your observations about how we view
> mempool policy in the Bitcoin Core project, and how that seems to be
> changing in the discussions around `-mempoolfullrbf`, are on-point and
> provide a helpful baseline for considering future policy changes.

<snip>

> To those who argue for making fullrbf a default policy on the network (or
> even just offering a flag for users to enable fullrbf), I pose this
> hypothetical: suppose we deploy the v3 transaction policy proposal (which I
> hope will happen in the near future).  That policy would restrict the ways
> that outputs of a v3 transaction can be spent while the transaction is
> unconfirmed, including by limiting the number and size of descendants that
> such a transaction can have, and limiting the types of unconfirmed
> ancestors that can be included.  Suppose in a few years someone proposes
> that we add a "-disable_v3_transaction_enforcement" flag to our software,
> to let users decide to turn off those policy restrictions and treat v3
> transactions the same as v2, for all the same reasons that could be argued
> today with fullrbf: miners might earn more revenue if we allowed multiple
> descendant v3 transactions; it's illogical for the recipient of a v3
> transaction to believe what is a fundamentally unenforceable promise of a
> sender to not issue more high value children that descend from an
> unconfirmed transaction; it's inappropriate for Bitcoin Core to dictate
> policy on the network and we should honor user choice to turn off that flag
> if that?s what users want; if users are relying on v3?s policy restrictions
> for security then that is an unstable model and we should assume it will
> get broken[5].

Let's frame this question differently: given that there are potential
incentives around a hypothetical `-disable_v3_transaction_enforcement` flag,
why are we trying to prevent miners and others from experimenting with
incentives around `fullrbf`?

Yanking the `mempoolfullrbf` flag from Bitcoin Core v24.0 simply puts a
temporary roadblock in the face of full-rbf. Without that roadblock, we might
find that some miners do in fact choose to enable it. The sooner we find that
out, the sooner we can learn about the incentives involved in that decision.

Meanwhile, if we insted put up those roadblocks, we'll be designing mechanisms
like v3 blind, without the benefit of seeing how incentives play out fully.


This experimentation can't happen on testnet: incentives don't work properly
when there isn't money at stake. And the proposed reversion pull-reqs don't
even leave the option for testnet anyway. So we're left with one choice:
release a full-rbf option, and see what happens on mainnet.

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221104/7e2f2a87/attachment.sig>

From mocay5760 at gmail.com  Sat Nov  5 08:46:15 2022
From: mocay5760 at gmail.com (MC 5760)
Date: Sat, 5 Nov 2022 15:46:15 +0700
Subject: [bitcoin-dev] Generate and verify ECDSA signature without "r"
Message-ID: <CA+Ej=UZBNUoqYW7Rw1d1K=7JwiovuHg6YchQkcrE0_RhjT+Wbw@mail.gmail.com>

1. Address: private key -> ECC -> public key compression -> Bech32m encode

2. scriptPubkey: Address -> Bech32m decode -> public key compression

3. Segwit: (dsha256(txid_input & index) * x public key + dsha256(unsigned
raw transaction) mod (private key)) mod (N) => Will give a number of 32
bytes

4. Verify:

x1, y1 = ECC(G, dsha256(txid_input & index))

p1 = ECC(G, dsha256(unsigned raw transaction) mod (Segwit))

p2 = ECC((x1,y1) * x public key mod (Segwit)

x2, y2 = ECAddpoint(p1, p2)

If x2 = x public key => OK

I wrote the python code here:
https://github.com/tanvovan/bitcoin/blob/main/p2pc.py
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221105/52e4aa8f/attachment.html>

From antoine.riard at gmail.com  Sun Nov  6 23:22:08 2022
From: antoine.riard at gmail.com (Antoine Riard)
Date: Sun, 6 Nov 2022 18:22:08 -0500
Subject: [bitcoin-dev] Preventing/detecting pinning of jointly funded txs
In-Reply-To: <Y2HpaWnAC5dIGkx+@erisian.com.au>
References: <Y2HpaWnAC5dIGkx+@erisian.com.au>
Message-ID: <CALZpt+G7SCTtsHUjdxdYYxFoQW4k7_BEbygVx2ksgZpTQZBUTw@mail.gmail.com>

Hi AJ,

Adding a few more thoughts here on what coinjoins/splicing/dual-funded
folks can do to solve this DoS isse in an opt-in RBF world only.

I'm converging that deploying a distributed monitoring of the network
mempools in the same fashion as zeroconf people is one solution, as you can
detect a conflicting spend of your multi-party transaction. Let's say you
have a web of well-connected full-nodes, each reporting all their incoming
mempool transactions to some reconciliation layer.

This "mempools watchdog" infrastructure isn't exempt from mempools
partitioning attacks by an adversary, where the goal is to control your
local node mempool view. A partitioning trick is somehow as simple as
policy changes across versions (e.g allowing Taproot Segwit v0.1 spends) or
two same-feerate transactions. The partitioning attack can target at least
two meaningful subsets. Either the miner mempools only, by conflicting all
the reachable nodes in as many subsets with a "tainted" transaction (e.g
set a special nSequence value for each), and looking on corresponding
issued block. Or targeting the "watchdog" mempools only, where the
adversary observation mechanism is the multi-party blame assignment round
itself. There is an open question on how many "divide-and-conquer" rounds
from an adversary viewpoint you need to efficiently identify all the
complete set of "mempools watchdog". If the transaction-relay topology is
highly dynamic thanks to outbound transaction-relay peers rotation, the
hardness bar is increased.

Though ultimately, the rough mental model I'm thinking on, this is a
"cat-and-mouse" game between the victims and the attacker, where the latter
try to find the blind spots of the former. I would say there is a strong
advantage to the attacker, in mapping the mempools can be batched against
multiple sets of victims. While the victims have no entry barriers to
deploy "mempools watchdog" there is a scarce resource in contest, namely
the inbound connection slots (at least the miners ones).

Victims could batch their defense costs, in outsourcing the monitoring to
dedicated entities (akin to LN watchtower). However, there is a belief in
lack of a compensation mechanism, you will have only a low number of public
ones (see number of BIP157 signaling nodes, or even Electrum ones).
Outsource mempools monitoring will hit the same issue of bounded public
resources, and as such be a "single-point-of-censorship" vector. Reminder,
we would like LN mobile clients from low-budget users to access those fancy
joint funding protocols (or at least I).

So as a first partial conclusion, not only the security efficiency but also
the economic scalability of such defensive "mempools watchdog"
infrastructure remains an open question to me.

Assuming we can solve them, there is still the issue of assigning blame
reliably among a set of trust-minimized joint funding protocol
participating UTXOs. Indeed, you're running quickly into issues like *two*
double-spend from two sybilling participants, aiming to halt the assignment
process. There is likely a need to introduce some "UTXO-satoshi-weight"
vote to efficiently converge towards assignment. At the very least it would
require the attacker to control more than 51% of the contributed UTXO to
manipulate the outcome of the blame assignment process. Assuming an
economically honest majority, you still have the timevalue cost inflicted
for each round of blame assignment. Assuming 255 inputs (current LN's
interactive construction protocol limit) and a transaction propagation
delay of 2min (30s ?) on the p2p network, an attacker controlling all the
inputs minus 1 might be able to DoS for ~50 blocks (do we have other
factors to think of in the design of the blame assignment process ?). In a
future where the timevalue of circulating coins is priced in (IMO when we
have competitive LN routing markets), this is probably a significant damage.

On the other hand, you have a full-rbf world, where instead to deploy or
gain access to "mempools watchdog" and proceed to a timevalue-expensive
blame assignment protocol, any participant should be able to fee-bump the
joint transaction (assuming multiple pre-signed feerate version of the
transactions, or ephemeral, nversion=3 and package-relay to do unilateral
CPFP). Ideally, this would be a reduction to a "flood-and-loot" attack, i.e
the attacker is constrained to buy the blockspace. A situation with a lot
of visibility for the joint funding protocol victims, I think.

Side-note: this alternative resolution process of relying on full-rbf,
still assumes solving RBF pinning rule 3, I think a fact I underscored in
my original full-rbf proposal of last year [0]. All that said, I think it's
good to think more of the end-of-pipeline economic trade-offs of the two
main directions to solve this DoS affecting joint funding protocol.
Transaction signature withhold DoS should be defended on a different layer,
and I think there are far more easy to deal with in  a set of participant
with at least stable temporary pseudonyms ("all participants should produce
a signature before X, laziness due to buggy Internet connection is treated
the same as a DoS" ?).

Best,
Antoine

[0] "Of course, even assuming full-rbf, propagation of the multi-party
funded
transactions can still be interfered with by an attacker, simply
broadcasting a double-spend with a feerate equivalent to the honest
transaction. However, it tightens the attack scenario to a scorched earth
approach, where the attacker has to commit equivalent fee-bumping reserve
to maintain the pinning and might lose the "competing" fees to miners."

https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-June/019074.html

Le mar. 1 nov. 2022 ? 23:52, Anthony Towns via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> a ?crit :

> On Fri, Oct 28, 2022 at 03:21:53AM +1000, Anthony Towns via bitcoin-dev
> wrote:
> > What should folks wanting to do coinjoins/dualfunding/dlcs/etc do to
> > solve that problem if they have only opt-in RBF available?
>
> ref:
> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-October/021124.html
>
> So, having a go at answering my own question.
>
> I think ultimately the scenario here is:
>
>  * you have a joint funding protocol, where everyone says "here's
>    an unspent utxo that will be my contribution", collaborates on signing
>    a transaction spending all those utxos, and then broadcasts it
>
>  * everyone jointly agrees to pay some amount in fees for that
>    transaction, targeting confirmation within N blocks
>
>  * the goal is to have the transaction confirm, obviously; but it's also
>    acceptable to discover a conflicting transaction, as that will
>    demonstrate that a particular participant has been dishonest (their
>    utxo was not "unspent"), allowing the overall protocol to make progress
>
> The question then is how much effort do you have to go to to make such a
> protocol work?
>
> As an extreme example, you could always have each participant maintain
> a dedicated amount of hashpower: eg, if each participant individually
> controls 0.5% of hashpower, then having two honest participants would
> give you a 75% chance of confirmation within 137 blocks (roughly a day),
> even if your transaction failed to relay at all, and the only way to
> prevent confirmation is for a conflicting transaction to be confirmed
> earlier. Of course, needing to have 0.5% of hashpower would mean fewer
> than 200 people globally could participate in such a protocol, and
> requires something like $10M in capital investment just for ASICs in
> order to participate.
>
> I think the next step from that pretty much requires introducing the
> assumption that the vast majority of the bitcoin p2p network (both nodes
> and hashrate) will accept your transaction, at least in a world where all
> your collaborators are honest and don't create conflicting transactions.
> You can limit that assumption a little bit, but without most p2p peers
> being willing to relay your tx, you start having privacy issues; and
> without most miners being willing to mine your tx, you start getting
> problems with predicting fees. And in any event, I don't think anyone's
> trying to make weird transactions here, just get their otherwise normal
> transactions to actually confirm.
>
> I think the same approach used to detect double spend races by people
> accepting zeroconf would work here too. That is setup a couple of
> anonymous bitcoin nodes, let them sit for a couple of weeks so their
> mempools are realistic, then when you broadcast a jointly funded
> transaction, query their mempools: if your new tx made it there, it
> likely made it to mining pools too, and you're fine; if it didn't, then
> the transaction that's blocking it almost certainly did, so you can find
> out what that is and can go from there.
>
> (If you don't see either your tx, or a conflicting one, then it likely
> means the nodes that broadcasted your tx are being sybil attacked, either
> because their peers are directly controlled by an attacker, or they've
> been identified by an attacker and attacked in some other way; presumably
> you could pick a couple of node that have been confirmed by both your
> anonymous nodes' as valid and reachable, and connect to them to break
> out of the sybil attack; if that doesn't work either, you probably need
> to change ISPs or put your active node via a (different) VPN provider...)
>
> Your capital expenses are much lower that way: perhaps on the order of
> $20/month to run a couple of nodes on AWS or linode or similar.
>
> But, you might say, what if I don't even want to run multiple bitcoin
> nodes 24/7 indefinitely? Can we outsource that, like we outsource mining
> by paying tx fees?
>
> That seems harder, particularly if you want to avoid whoever you're
> outsourcing too from associating you with the jointly funded transaction
> you're interested in.
>
> If you're *not* worried about that association, it's probably easy:
> just find some public explorers, and see if they list any conflicts in
> their mempool, or use the "broadcast tx" feature and see if it gives an
> error identifying the conflicting transaction.
>
> I think it's probably hard to make that behaviour a normal part of p2p tx
> relay though: if someone's trying to relay tx T but you reject it
> because of a conflicting tx C; then it's easy to tell the node that
> first relayed T to you about C -- but how does that information get back
> to the original broadcaster?
>
> One way would be to broadcast "C" back to whoever announced T to you,
> and let C propogate all the way back to whoever originally proposed T --
> but that only works if everyone's running a mempool policy where there's
> a total ordering for tx replacement, ie for any conflicting txs, either
> T replaces C or C replaces T, and that's not something we have now or
> would have even with full RBF, and seems pretty hard to actually achieve.
> (And if it was achieved, you could just keep replacing T with a more
> attractive T' so that it did eventually replace C)
>
> Another way might be to have the original broadcaster retry the broadcast:
> connect to new peers, reannounce T, and see what happens.  Then eventually
> they'll connect to a peer that has C in their mempool, and just needs a
> "reject" message of some kind that can identify C.  But in that case,
> the peer that's going to send the reject message needs to be able to
> efficiently associate T back to C, even though it doesn't have T in
> the mempool -- it won't want to redownload T each time, because that's
> a waste of bandwidth, and it can't re-validate T to find the conflict
> fresh without having a copy of T.
>
> Using BIP 37 mempool filters or something might be an approach if there
> are plenty of nodes around that _are_ willing to dedicate extra resources
> to helping people find potentially conflicting txs.  Unfortunately that
> probably is pretty bad for privacy: if your adversary is blocking your
> coinjoin T with a pinned tx C, then the fact that you've asked for a
> filter that happens to match C is probably a good indication that you're
> involved in the coinjoin T; and there's a decent chance that the only
> people will to dedicate the extra resources to offer those services to
> the public will be people who want to invade your privacy...
>
> A problem with mempool filters (or telling other nodes what's in your
> mempool in general) is that that can provide a way for attackers to
> identify who your peers are: if you create a bunch of conflicting txs,
> and give a different one to many nodes other than you, then see which
> tx you end up with, that identifies which peers are close to you, and
> that information could be used to attack those peers, which in turn may
> allow more effective sybil attacks against you.
>
> So I think my best answer is:
>
>  - if you really want to do things with untrusted peers in bitcoin,
>    investing in hashpower maybe isn't that unreasonable a thing to
>    do. $10M in capital giving you the ability to usually make progress
>    within a day even if everyone else dislikes you? surprisingly
>    reasonable, especially if more progress is made on stratumv2...
>
>  - if you don't care about privacy (eg, you're funding a lightning
>    channel that's going to be gossiped anyway), just query an explorer
>    (or some other centralised service) to find out the conflicting tx
>    and go from there.
>
>  - if you do care about privacy, run a few "anonymous" bitcoind nodes
>    that don't announce transactions, and see what their mempool
>    contains.
>
>  - we can probably make it easier to run anonymous bitcoind nodes
>    by making transaction broadcasts more private (tor/i2p? dandelion? have
>    lightning nodes send channel open/close txs to another lightning
>    node to announce to bitcoin p2p?) -- for cases where you're already
>    running a bitcoin node 24/7 (or trusting someone else that does), I
>    think that gives you a pretty good method of either being confident
>    your tx made it to a decent percentage of hashrate, or spotting a
>    conflicting tx to be able to assign blame
>
> Anyone got any improvements on the above?
>
> Cheers,
> aj
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221106/c795614b/attachment-0001.html>

From aj at erisian.com.au  Mon Nov  7 11:46:28 2022
From: aj at erisian.com.au (Anthony Towns)
Date: Mon, 7 Nov 2022 21:46:28 +1000
Subject: [bitcoin-dev] Preventing/detecting pinning of jointly funded txs
In-Reply-To: <CALZpt+G7SCTtsHUjdxdYYxFoQW4k7_BEbygVx2ksgZpTQZBUTw@mail.gmail.com>
References: <Y2HpaWnAC5dIGkx+@erisian.com.au>
 <CALZpt+G7SCTtsHUjdxdYYxFoQW4k7_BEbygVx2ksgZpTQZBUTw@mail.gmail.com>
Message-ID: <Y2jwFOeVep6WefKb@erisian.com.au>

On Sun, Nov 06, 2022 at 06:22:08PM -0500, Antoine Riard via bitcoin-dev wrote:
> Adding a few more thoughts here on what coinjoins/splicing/dual-funded
> folks can do to solve this DoS issue in an opt-in RBF world only.
> 
> I'm converging that deploying a distributed monitoring of the network
> mempools in the same fashion as zeroconf people is one solution, as you can
> detect a conflicting spend of your multi-party transaction.

> Let's say you
> have a web of well-connected full-nodes, each reporting all their incoming
> mempool transactions to some reconciliation layer.
> 
> This "mempools watchdog" infrastructure isn't exempt from mempools
> partitioning attacks by an adversary,

A mempool partitioning attack requires the adversary to identify your
nodes. If they're just monitoring and not being used as the initial
broadcaster of your txs, that should be difficult. (And I think it would
make sense to do things that make it more difficult to successfully
partition a node for tx relay, even if you can identify it)

> where the goal is to control your
> local node mempool view. A partitioning trick is somehow as simple as
> policy changes across versions (e.g allowing Taproot Segwit v0.1 spends) or
> two same-feerate transactions. The partitioning attack can target at least
> two meaningful subsets.

An even easier way to partition the network is to create two conflicting
txs at the same fee/fee rate and to announce them to many peers
simultaneously. That way neither will replace the other, and you can
build from there.

In order to attack you, the partition would need to be broad enough
to capture all your monitoring nodes on one side (to avoid detection),
and all the mining nodes on the other side (to prevent your target tx
from being confirmed). If that seems likely, maybe it indicates that
it's too easy to identify nodes that feed txs to mining pools...

> Either the miner mempools only, by conflicting all
> the reachable nodes in as many subsets with a "tainted" transaction (e.g
> set a special nSequence value for each), and looking on corresponding
> issued block. Or targeting the "watchdog" mempools only, where the
> adversary observation mechanism is the multi-party blame assignment round
> itself.

I think there's a few cases like that: you can find out what txs mining
pools have seen by looking at their blocks, what explorers have seen by
looking at their website...

Being able to use that information to identify your node(s) -- rather
than just your standardness policy, which you hopefully share with many
other nodes -- seems like something we should be working to fix...

> There is an open question on how many "divide-and-conquer" rounds
> from an adversary viewpoint you need to efficiently identify all the
> complete set of "mempools watchdog". If the transaction-relay topology is
> highly dynamic thanks to outbound transaction-relay peers rotation, the
> hardness bar is increased.

I'm not sure outbound rotation is sufficient? In today's world, if
you're a listening node, an attacker can just connect directly, announce
the conflicting tx to you, and other txs to everyone else.

For a non-listening node, outbound rotation might be more harmful than
helpful, as it increases the chances a node will peer with a given
attacker at some point.

> Though ultimately, the rough mental model I'm thinking on, this is a
> "cat-and-mouse" game between the victims and the attacker, where the latter
> try to find the blind spots of the former. I would say there is a strong
> advantage to the attacker, in mapping the mempools can be batched against
> multiple sets of victims. While the victims have no entry barriers to
> deploy "mempools watchdog" there is a scarce resource in contest, namely
> the inbound connection slots (at least the miners ones).

Anytime you deploy a new listening node, you use up 10 inbound
connections, but provide capacity for 115 new ones. Worst case (if
it's too hard to prevent identifying a listening node if you use it for
monitoring), you setup all your monitoring nodes as non-listening nodes,
and also set enough listening nodes in different IP ranges to compenasate
for the number of outbound connections your monitoring nodes are making,
and just ignore the mempools of those listening nodes.

> Victims could batch their defense costs, in outsourcing the monitoring to
> dedicated entities (akin to LN watchtower). However, there is a belief in
> lack of a compensation mechanism, you will have only a low number of public
> ones (see number of BIP157 signaling nodes, or even Electrum ones).

Seems like a pretty simple service to pay for, if there's real demand:
costs are pretty trivial, and if it's a LN service, you can pay for
it over lightning... Fairly easy to test if you're getting what you're
paying for too, by simultaneously announcing two conflicting txs paying
yourself, and checking you get an appropriate alert.

> Assuming we can solve them, there is still the issue of assigning blame
> reliably among a set of trust-minimized joint funding protocol
> participating UTXOs. Indeed, you're running quickly into issues like *two*
> double-spend from two sybilling participants, aiming to halt the assignment
> process.

I don't see how that's a problem: anyone who wants to continue as part of
the group never signs a conflicting tx; anyone who does sign a conflicting
tx is saying "I don't want to be part of this group anymore", whether
that conflicting tx arrives via normal channels or p2p. If you want a way
of saying "I want to abort this coinjoin, but stay a part of the group",
you need to get 51% of the rest of the group to sign off on that claim
(outside of the blockchain/mempool), before getting control of your
utxo back. If you can't get 51% of the group to sign off on that in a
reasonable time, then you should just exit the group.

I don't think it makes much sense for "group A said Bob's a cheater,
so therefore we won't let Bob into group C either".

> for each round of blame assignment. Assuming 255 inputs (current LN's
> interactive construction protocol limit) and a transaction propagation
> delay of 2min (30s ?) on the p2p network, an attacker controlling all the
> inputs minus 1 might be able to DoS for ~50 blocks (do we have other
> factors to think of in the design of the blame assignment process ?).

Hmm, in messing around with dandelion simulations, I've found 10s to 30s
seems more reasonable for propagation to 95% of the network, though that's
modelled without delays due to latency/low bandwidth, block propagation,
or competition with large/higher value txs.

Shouldn't be hard to estimate that actually: if you setup a node with
-debug=net and -datacarrier=0, then check for blocks with txs with
OP_RETURN outputs, figure out the w/txid and grep your logs for how
far apart. Because you set -datacarrier=0 you won't accept those txs
into your mempool, or announce them to your peers, but your peers will
announce them to you when they receive them, so the time difference
between first and last announcement should give you a decent sampling
of info that you could use to estimate the overall time it takes a tx
to flood through the network.

> On the other hand, you have a full-rbf world, where instead to deploy or
> gain access to "mempools watchdog" and proceed to a timevalue-expensive
> blame assignment protocol, any participant should be able to fee-bump the
> joint transaction (assuming multiple pre-signed feerate version of the
> transactions, or ephemeral, nversion=3 and package-relay to do unilateral
> CPFP).

A full-rbf world doesn't get you that: you can do low fee rate pinning
via other mechanisms than the opt-out flag. In a world where nodes don't
mostly have a consistent mempool policy you introduce new pinning vectors
too; eg, if one of your coinjoin outputs is bare multisig, then that
will pass core's standardness checks, but be rejected by fullrbf knots
nodes that haven't specifically enabled that configuration option.

Even if you assume the attacker doesn't know about those other methods,
or we somehow come up with an eventually consistent mempool/relay policy,
where pinning isn't possible that gets near universal adoption; if you're
only monitoring the blockchain and not the mempool, your hypothetical
attacker can immediately RBF your tx with a higher fee spend of one of
their inputs -- you'll find out about that in the next block, but at one
input per block, that's going to allow you to keep thinking that maybe
one of your peers is honest for 254 blocks instead of 50.

This seems like an argument not to do coinjoins with a ridiculously
large number of untrusted counterparties...

If you really want to salvage the opportunity to have really large
anonymous groups, seems better to quickly say "oops, someone cheated,
let's exclude them, and split the remainder into two groups" until you
either succeed or are down to a more reasonable group size of perhaps
10 or 20.

> [0] "Of course, even assuming full-rbf, propagation of the multi-party
> funded
> transactions can still be interfered with by an attacker, simply
> broadcasting a double-spend with a feerate equivalent to the honest
> transaction. However, it tightens the attack scenario to a scorched earth
> approach, where the attacker has to commit equivalent fee-bumping reserve
> to maintain the pinning and might lose the "competing" fees to miners."

We now know that that isn't correct though: if it really did tighten
the attack scenario like that, that would be great -- but it doesn't:
the attacker can still do low feerate pinning that's not recoverable by
fee bumping the alternative, as Suhas explained elsewhere.

Cheers,
aj


From johanth at gmail.com  Mon Nov  7 13:51:12 2022
From: johanth at gmail.com (=?UTF-8?Q?Johan_Tor=C3=A5s_Halseth?=)
Date: Mon, 7 Nov 2022 14:51:12 +0100
Subject: [bitcoin-dev] [Lightning-dev] Taro: A Taproot Asset
 Representation Overlay
In-Reply-To: <CAO3Pvs9EeKu1p9egeeRZduvgX_Xf21rh0N8iRY9xo2m01sw_oA@mail.gmail.com>
References: <CAO3Pvs_pkYAYsrAEtv3KuJevXQHBLZQ-ihjP4Ur_A1NjJRA+Lw@mail.gmail.com>
 <CAPv7TjYTjvSV7UFgOwif6tFj3jVxDfJdW-p_cyPoAGGWKQbwRQ@mail.gmail.com>
 <CAO3Pvs_-igT37fcD29=ATSRX7dW5mGKrLGrXp=iJjaN_t3NGww@mail.gmail.com>
 <CAPv7TjZjZU2bYvUrt-BEx80xKF=BHBbrYWigHB+=yY+YfZX9Yg@mail.gmail.com>
 <CAD3i26AOmfHz1aOJGwzixQuwMtoo=v5qbveZUasbkzL1sPJWLw@mail.gmail.com>
 <CAO3Pvs9EeKu1p9egeeRZduvgX_Xf21rh0N8iRY9xo2m01sw_oA@mail.gmail.com>
Message-ID: <CAD3i26BkzBSRTqaLxArHJVuE+41SnCzP3JmLoAreF-Lazxgjww@mail.gmail.com>

Hi Laolu,

Yeah, that is definitely the main downside, as Ruben also mentioned:
tokens are "burned" if they get sent to an already spent UTXO, and
there is no way to block those transfers.

And I do agree with your concern about losing the blockchain as the
main synchronization point, that seems indeed to be a prerequisite for
making the scheme safe in terms of re-orgs and asynchronicity.

I do think the scheme itself is sound though (maybe not off-chain, see
below): it prevents double spending and as long as the clients adhere
to the "rule" of not sending to a spent UTXO you'll be fine (if not
your tokens will be burned, the same way as if you don't satisfy the
Taro script when spending).

Thinking more about the examples you gave, I think you are right it
won't easily be compatible with LN channels though:
If you want to refill an existing channel with tokens, you need the
channel counterparties to start signing new commitments that include
spending the newly sent tokens. A problem arises however, if the
channel is force-closed with a pre-existing commitment from before the
token transfer took place. Since this commitment will be spending the
funding UTXO, but not the new tokens, the tokens will be burned. And
that seems to be harder to deal with (Eltoo style channels could be an
avenue to explore, if one could override the broadcasted commitment).

Tl;dr: I think you're right, the scheme is not compatible with LN.

- Johan


On Sat, Nov 5, 2022 at 1:36 AM Olaoluwa Osuntokun <laolu32 at gmail.com> wrote:
>
> Hi Johan,
>
> I haven't really been able to find a precise technical explanation of the
> "utxo teleport" scheme, but after thinking about your example use cases a
> bit, I don't think the scheme is actually sound. Consider that the scheme
> attempts to target transmitting "ownership" to a UTXO. However, by the time
> that transaction hits the chain, the UTXO may no longer exist. At that
> point, what happens to the asset? Is it burned? Can you retry it again? Does
> it go back to the sender?
>
> As a concrete example, imagine I have a channel open, and give you an
> address to "teleport" some additional assets to it. You take that addr, then
> make a transaction to commit to the transfer. However, the block before you
> commit to the transfer, my channel closes for w/e reason. As a result, when
> the transaction committing to the UTXO (blinded or not), hits the chain, the
> UTXO no longer exists. Alternatively, imagine the things happen in the
> expected order, but then a re-org occurs, and my channel close is mined in a
> block before the transfer. Ultimately, as a normal Bitcoin transaction isn't
> used as a serialization point, the scheme seems to lack a necessary total
> ordering to ensure safety.
>
> If we look at Taro's state transition model in contrast, everything is fully
> bound to a single synchronization point: a normal Bitcoin transaction with
> inputs consumed and outputs created. All transfers, just like Bitcoin
> transactions, end up consuming assets from the set of inputs, and
> re-creating them with a different distribution with the set of outputs. As a
> result, Taro transfers inherit the same re-org safety traits as regular
> Bitcoin transactions. It also isn't possible to send to something that won't
> ultimately exist, as sends create new outputs just like Bitcoin
> transactions.
>
> Taro's state transition model also means anything you can do today with
> Bitcoin/LN also apply. As an example, it would be possible for you to
> withdrawn from your exchange into a Loop In address (on chain to off chain
> swap), and have everything work as expected, with you topping off your
> channel. Stuff like splicing, and other interactive transaction construction
> schemes (atomic swaps, MIMO swaps, on chain auctions, etc) also just work.
>
> Ignoring the ordering issue I mentioned above, I don't think this is a great
> model for anchoring assets in channels either. With Taro, when you make the
> channel, you know how many assets are committed since they're all committed
> to in the funding output when the channel is created. However, let's say we
> do teleporting instead: at which point would we recognize the new asset
> "deposits"? What if we close before a pending deposits confirms, how can one
> regain those funds? Once again you lose the serialization of events/actions
> the blockchain provides. I think you'd also run into similar issues when you
> start to think about how these would even be advertised on a hypothetical
> gossip network.
>
> I think one other drawback of the teleport model iiuc is that: it either
> requires an OP_RETURN, or additional out of band synchronization to complete
> the transfer. Since it needs to commit to w/e hash description of the
> teleport, it either needs to use an OP_RETURN (so the receiver can see the
> on chain action), or the sender needs to contact the receiver to initiate
> the resolution of the transfer (details committed to in a change addr or
> w/e).
>
> With Taro, sending to an address creates an on-chain taproot output just
> like sending to a P2TR address. The creation of the output directly creates
> the new asset anchor/output as well, which allows the receiver to look for
> that address on chain just like a normal on chain transaction. To 3rd party
> observers, it just looks like a normal P2TR transfer. In order to finalize
> the receipt of the asset, the receiver needs to obtain the relevant
> provenance proofs, which can be obtained from a multi-verse gRPC/HTTP
> service keyed by the input outpoint and output index. In short, the send
> process is fully async, with the sender and receiver using the blockchain
> itself as a synchronization point like a normal Bitcoin wallet.
>
> -- Laolu

From pete at petertodd.org  Mon Nov  7 14:32:17 2022
From: pete at petertodd.org (Peter Todd)
Date: Mon, 07 Nov 2022 10:32:17 -0400
Subject: [bitcoin-dev] On mempool policy consistency
In-Reply-To: <16eb6a50691ccc661310051de6b8e2c0@yancy.lol>
References: <16eb6a50691ccc661310051de6b8e2c0@yancy.lol>
Message-ID: <0A6B5781-EBC6-4D98-8AE8-43436B5F73EA@petertodd.org>



On November 3, 2022 5:06:52 PM AST, yancy via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>AJ/Antoine et al
>
>> What should folks wanting to do coinjoins/dualfunding/dlcs/etc do to
>> solve that problem if they have only opt-in RBF available?
>
>Assuming Alice is a well funded advisory, with enough resources to spam the network so that enough nodes see her malicious transaction first, how does full-rbf solve this vs. opt-in rbf?

First of all, to make things clear, remember that the attacks were talking about are aimed at _preventing_ a transaction from getting mined. Alice wants to cheaply broadcast something with low fees that won't get mined soon (if ever), that prevents a protocol from making forward progress.

With full-rbf, who saw what transaction first doesn't matter: the higher fee paying transaction will always(*) replace the lower fee one. With opt-in RBF, spamming the network can beat out the alternative.

*) So what's the catch? Well, due to limitations in today's mempool implementation, sometimes we can't fully evaluate which tx pays the higher fee. For example, if Alice spams the network with very _large_ numbers transactions spending that input, the current mempool code doesn't even try to figure out if a replacement is better.

But those limitations are likely to be fixable. And even right now, without fixing them, Alice still has to use a lot more money to pull off these attacks with full-rbf. So full-rbf definitely improves the situation even if it doesn't solve the problem completely.

From erik at q32.com  Mon Nov  7 14:47:50 2022
From: erik at q32.com (Erik Aronesty)
Date: Mon, 7 Nov 2022 09:47:50 -0500
Subject: [bitcoin-dev] On mempool policy consistency
In-Reply-To: <0A6B5781-EBC6-4D98-8AE8-43436B5F73EA@petertodd.org>
References: <16eb6a50691ccc661310051de6b8e2c0@yancy.lol>
 <0A6B5781-EBC6-4D98-8AE8-43436B5F73EA@petertodd.org>
Message-ID: <CAJowKgLWGL15kjVS4eFB2je1s+2feQZ6Qo8GFAyVHF_Pfjkf2A@mail.gmail.com>

>
>
> With full-rbf, who saw what transaction first doesn't matter: the higher
> fee paying transaction will always(*) replace the lower fee one. With
> opt-in RBF, spamming the network can beat out the alternative.
>

incentivised predictability is critical when designing low level protocols,
like bitcoin.   the knock-on effects of deeper, network-wide predictability
are likely beneficial in ways that are hard to predict.   for example stuff
like the "sabu" protocol might even work if full-rbf is the norm.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221107/e76ee3c5/attachment.html>

From pete at petertodd.org  Mon Nov  7 20:17:29 2022
From: pete at petertodd.org (Peter Todd)
Date: Mon, 7 Nov 2022 15:17:29 -0500
Subject: [bitcoin-dev] Removing BIP-125 Rule #5 Pinning with the
 Always-Replaceable Invariant
Message-ID: <Y2ln2fJ+8+Q0qS0E@petertodd.org>

tl;dr: We can remove the problem of Rule #5 pinning by ensuring that all
transactions in the mempool are always replaceable.


Currently Bitcoin Core implements rule #5 of BIP-125:

    The number of original transactions to be replaced and their descendant
    transactions which will be evicted from the mempool must not exceed a total
    of 100 transactions.

As of Bitcoin Core v24.0rc3, this rule is implemented via the
MAX_REPLACEMENT_CANDIDATES limit in GetEntriesForConflicts:

    // Rule #5: don't consider replacing more than MAX_REPLACEMENT_CANDIDATES
    // entries from the mempool. This potentially overestimates the number of actual
    // descendants (i.e. if multiple conflicts share a descendant, it will be counted multiple
    // times), but we just want to be conservative to avoid doing too much work.
    if (nConflictingCount > MAX_REPLACEMENT_CANDIDATES) {
        return strprintf("rejecting replacement %s; too many potential replacements (%d > %d)\n",
                         txid.ToString(),
                         nConflictingCount,
                         MAX_REPLACEMENT_CANDIDATES);
    }

There is no justification for this rule beyond avoiding "too much work"; the
exact number was picked at random when the BIP was written to provide an
initial conservative limit, and is not justified by benchmarks or memory usage
calculations. It may in fact be the case that this rule can be removed entirely
as the overall mempool size limits naturally limit the maximum number of
possible replacements.


But for the sake of argument, let's suppose some kind of max replacement limit
is required. Can we avoid rule #5 pinning? The answer is yes, we can, with the
following invariant:

    No transaction may be accepted into the mempool that would cause another
    transaction to be unable to be replaced due to Rule #5.

We'll call this the Replaceability Invariant. Implementing this rule is simple:
for each transaction maintain an integer, nReplacementCandidates. When a
non-conflicting transaction is considered for acceptance to the mempool, verify
that nReplacementCandidates + 1 < MAX_REPLACEMENT_CANDIDATES for each
unconfirmed parent. When a transaction is accepted, increment
nReplacementCandidates by 1 for each unconfirmed parent.

When a *conflicting* transaction is considered for acceptance, we do _not_ need
to verify anything: we've already guaranteed that every transaction in the
mempool is replaceable! The only thing we may need to do is to decrement
nReplacementCandidates by however many children we have replaced, for all
unconfirmed parents.

When a block is mined, note how the nReplacementCandidates of all unconfirmed
transactions remains unchanged because a confirmed transaction can't spend an
unconfirmed txout.

The only special case to handle is a reorg that changes a transaction from
confirmed to unconfirmed. Setting nReplacementCandidates to
MAX_REPLACEMENT_CANDIDATES would be fine in that very rare case.


Note that like the existing MAX_REPLACEMENT_CANDIDATES check, the
Replaceability Invariant overestimates the number of transactions to be
replaced in the event that multiple children are spent by the same transaction.
That's ok: diamond tx graphs are even more unusual than unconfirmed children,
and there's no reason to bend over backwards to accomodate them.

Prior art: this proposed rule is similar in spirit to the package limits aready
implemented in Bitcoin Core.

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221107/536f252f/attachment-0001.sig>

From pete at petertodd.org  Mon Nov  7 21:17:50 2022
From: pete at petertodd.org (Peter Todd)
Date: Mon, 7 Nov 2022 16:17:50 -0500
Subject: [bitcoin-dev] Using Full-RBF to fix BIP-125 Rule #3 Pinning with
	nLockTime
In-Reply-To: <Y2ln2fJ+8+Q0qS0E@petertodd.org>
References: <Y2ln2fJ+8+Q0qS0E@petertodd.org>
Message-ID: <Y2l1/qXHxyctU9ir@petertodd.org>

On Mon, Nov 07, 2022 at 03:17:29PM -0500, Peter Todd via bitcoin-dev wrote:
> tl;dr: We can remove the problem of Rule #5 pinning by ensuring that all
> transactions in the mempool are always replaceable.

With Rule #5 solved, let's look at the other pinning attack on multi-party
transactions: BIP-125 Rule #3

tl;dr: In conjunction with full-RBF, nLockTime'd, pre-signed, transactions can
ensure that one party is not forced to pay for all the cost of a rule #3
replacement.


# What is the problem?

When a transaction contains inputs from multiple parties, each party can lock
up funds from the other party by spending their input with a transaction that
is difficult/expensive to replace. Obviously, the clearest example of "difficult to
replace" is a non-BIP-125 (Opt-in-RBF) transaction. But here, we'll assume that
full-rbf is implemented and all transactions are replaceable.

BIP-125 Rule #3 states that:

    The replacement transaction pays an absolute fee of at least the sum paid
    by the original transactions.

The attack is that the malicious party, who we'll call Mallory, broadcasts a
transaction spending their input(s) with a low fee rate transaction that's
potentially quite large, during a time of high mempool demand. Due to the low
fee rate this transaction will take a significant amount of time to mine. The
other parties to the transaction - who we'll collectively call Alice - are now
unable to spend their inputs unless they broadcast a transaction "paying for"
Mallory's.

This attack works because Mallory doesn't expect the conflicting tx to actually
get mined: he assumes it'll either expire, or Alice will get frustrated and
have to double spend it. By simple tying up money, Mallory has caused Alice to
actually lose money.


# Fixing the problem with nLockTime

Conversely, in the case of an honest multi-party transaction, whose parties
we'll call Alice and Bob, the parties genuinely intend for one of two outcomes:

1) The multi-party transaction to get mined within N blocks.
2) The transaction to be cancelled (most likely by spending one of the inputs).

We can ensure with high probability that the transaction can be cancelled/mined
at some point after N blocks by pre-signing a transaction, with nLockTime set
sufficiently far into the future, spending one or more inputs of the
transaction with a sufficiently high fee that it would replace transaction(s)
attempting to exploit Rule #3 pinning (note how the package limits in Bitcoin
Core help here).

There's a few different ways to implement this, and exactly which one makes
sense will depend on the specifics of the multi-party protocol. But the general
approach is to defeat the attack by ensuring that Mallory will have to pay the
cost of getting the multi-party transaction unstuck, at some point in the
future.

For example, in a two party transaction where there's a clearly more reputable
party (Alice), and an untrusted party (Mallory), Alice could simply require
Mallory to provide a nLockTime'd transaction spending only his input to fees,
multiple days into the future. In the unlikely event that Mallory holds up the
protocol, he will be severely punished. Meanwhile, Alice can always cancel at
no cost.

In a many party transaction where both parties are equally (un)trustworthy the
protocol could simply have both parties sign a series of transactions,
nLockTimed at decreasingly far into a future, paying a decreasingly amount of
fees. If either party holds up the transaction intentionally, they'll both pay
a high cost. But again, at some point Mallory will have paid the full price for
his attack. This approach also has the beneficial side effect of implementing
fee discovery with rbf. This approach is easier as the number of parties
increases, eg the Wasabi/Joinmarket transactions with hundreds of inputs and
outputs: they collectively already have to pay a significant fee to get the
transaction mined, making the extra poential cost needed to defeat pinning
minimal.


# Coordinator Spent Bonds with Package Relay/Replacement

For schemes with a central semi-trusted coordinator, such as Wasabi coinjoins,
with package relay/replacement we can use a two party punishment transaction
consisting of:

    tx1 - spends Mallory's input to a txout spendable by:
           IF
               <coordinator> CheckSig
           Else
               <delay> CheckSequenceVerify
               <mallory> CheckSig
           EndIf

    tx2 - spends tx1 output to as much fees as needed

Whether or not Mallory cheated with a double-spend is provable to third
parties; the second transaction ensures that Mallory can't simply release tx1
on their own to frame the coordinator. The use of CheckSequenceVerify ensures
that if mallory did try to frame the coordinator, they don't have to do
anything to return the funds to Mallory.

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221107/59ee60a8/attachment.sig>

From sdaftuar at gmail.com  Mon Nov  7 21:21:11 2022
From: sdaftuar at gmail.com (Suhas Daftuar)
Date: Mon, 7 Nov 2022 16:21:11 -0500
Subject: [bitcoin-dev] Removing BIP-125 Rule #5 Pinning with the
 Always-Replaceable Invariant
In-Reply-To: <Y2ln2fJ+8+Q0qS0E@petertodd.org>
References: <Y2ln2fJ+8+Q0qS0E@petertodd.org>
Message-ID: <CAFp6fsH0BXn51DqpJLWn56ecohCJZ+skVvabGBRmjeK5u08vdg@mail.gmail.com>

Hello bitcoin-dev,

The description in the OP is completely broken for the simple reason that
Bitcoin transactions can have multiple inputs, and so a single transaction
can conflict with multiple in-mempool transactions. The proposal would
limit the number of descendants of each in-mempool transaction to
MAX_REPLACEMENT_CANDIDATES (note that this is duplicative of the existing
Bitcoin Core descendant limits), but a transaction that has, say, 500
inputs might arrive and conflict with 500 unrelated in-mempool
transactions. This could result in 12,500 evictions -- far more than the
100 that was intended.

Also, note that those 500 transactions might instead have 24 ancestors each
(again, using the default chain limits in Bitcoin Core) -- this would
result in 12,000 transactions whose state would be updated as a result of
evicting those 500 transactions. Hopefully this gives some perspective on
why we have a limit.


On Mon, Nov 7, 2022 at 3:17 PM Peter Todd via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> tl;dr: We can remove the problem of Rule #5 pinning by ensuring that all
> transactions in the mempool are always replaceable.
>
>
> Currently Bitcoin Core implements rule #5 of BIP-125:
>
>     The number of original transactions to be replaced and their descendant
>     transactions which will be evicted from the mempool must not exceed a
> total
>     of 100 transactions.
>
> As of Bitcoin Core v24.0rc3, this rule is implemented via the
> MAX_REPLACEMENT_CANDIDATES limit in GetEntriesForConflicts:
>
>     // Rule #5: don't consider replacing more than
> MAX_REPLACEMENT_CANDIDATES
>     // entries from the mempool. This potentially overestimates the number
> of actual
>     // descendants (i.e. if multiple conflicts share a descendant, it will
> be counted multiple
>     // times), but we just want to be conservative to avoid doing too much
> work.
>     if (nConflictingCount > MAX_REPLACEMENT_CANDIDATES) {
>         return strprintf("rejecting replacement %s; too many potential
> replacements (%d > %d)\n",
>                          txid.ToString(),
>                          nConflictingCount,
>                          MAX_REPLACEMENT_CANDIDATES);
>     }
>
> There is no justification for this rule beyond avoiding "too much work";
> the
> exact number was picked at random when the BIP was written to provide an
> initial conservative limit, and is not justified by benchmarks or memory
> usage
> calculations. It may in fact be the case that this rule can be removed
> entirely
> as the overall mempool size limits naturally limit the maximum number of
> possible replacements.
>
>
> But for the sake of argument, let's suppose some kind of max replacement
> limit
> is required. Can we avoid rule #5 pinning? The answer is yes, we can, with
> the
> following invariant:
>
>     No transaction may be accepted into the mempool that would cause
> another
>     transaction to be unable to be replaced due to Rule #5.
>
> We'll call this the Replaceability Invariant. Implementing this rule is
> simple:
> for each transaction maintain an integer, nReplacementCandidates. When a
> non-conflicting transaction is considered for acceptance to the mempool,
> verify
> that nReplacementCandidates + 1 < MAX_REPLACEMENT_CANDIDATES for each
> unconfirmed parent. When a transaction is accepted, increment
> nReplacementCandidates by 1 for each unconfirmed parent.
>
> When a *conflicting* transaction is considered for acceptance, we do _not_
> need
> to verify anything: we've already guaranteed that every transaction in the
> mempool is replaceable! The only thing we may need to do is to decrement
> nReplacementCandidates by however many children we have replaced, for all
> unconfirmed parents.
>
> When a block is mined, note how the nReplacementCandidates of all
> unconfirmed
> transactions remains unchanged because a confirmed transaction can't spend
> an
> unconfirmed txout.
>
> The only special case to handle is a reorg that changes a transaction from
> confirmed to unconfirmed. Setting nReplacementCandidates to
> MAX_REPLACEMENT_CANDIDATES would be fine in that very rare case.
>
>
> Note that like the existing MAX_REPLACEMENT_CANDIDATES check, the
> Replaceability Invariant overestimates the number of transactions to be
> replaced in the event that multiple children are spent by the same
> transaction.
> That's ok: diamond tx graphs are even more unusual than unconfirmed
> children,
> and there's no reason to bend over backwards to accomodate them.
>
> Prior art: this proposed rule is similar in spirit to the package limits
> aready
> implemented in Bitcoin Core.
>
> --
> https://petertodd.org 'peter'[:-1]@petertodd.org
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221107/200b5236/attachment.html>

From pete at petertodd.org  Mon Nov  7 21:27:16 2022
From: pete at petertodd.org (Peter Todd)
Date: Mon, 7 Nov 2022 16:27:16 -0500
Subject: [bitcoin-dev] Removing BIP-125 Rule #5 Pinning with the
 Always-Replaceable Invariant
In-Reply-To: <CAFp6fsH0BXn51DqpJLWn56ecohCJZ+skVvabGBRmjeK5u08vdg@mail.gmail.com>
References: <Y2ln2fJ+8+Q0qS0E@petertodd.org>
 <CAFp6fsH0BXn51DqpJLWn56ecohCJZ+skVvabGBRmjeK5u08vdg@mail.gmail.com>
Message-ID: <Y2l4NK0HC6xsUwSL@petertodd.org>

On Mon, Nov 07, 2022 at 04:21:11PM -0500, Suhas Daftuar via bitcoin-dev wrote:
> Hello bitcoin-dev,
> 
> The description in the OP is completely broken for the simple reason that
> Bitcoin transactions can have multiple inputs, and so a single transaction
> can conflict with multiple in-mempool transactions. The proposal would
> limit the number of descendants of each in-mempool transaction to
> MAX_REPLACEMENT_CANDIDATES (note that this is duplicative of the existing
> Bitcoin Core descendant limits), but a transaction that has, say, 500
> inputs might arrive and conflict with 500 unrelated in-mempool
> transactions. This could result in 12,500 evictions -- far more than the
> 100 that was intended.

That's easy to fix: just sum up the number of nReplacementCandidates for each
input in the multiple input case. Again, it'll overcount in the diamond case.
But so does the existing code.

The goal is to defeat pinning by ensuring that you can always replace a
transaction by double-spending an output; not that any possible way of
double-spending multiple outputs at once would work.

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221107/2003710d/attachment-0001.sig>

From antoine.riard at gmail.com  Mon Nov  7 22:55:59 2022
From: antoine.riard at gmail.com (Antoine Riard)
Date: Mon, 7 Nov 2022 17:55:59 -0500
Subject: [bitcoin-dev] Using Full-RBF to fix BIP-125 Rule #3 Pinning
	with nLockTime
In-Reply-To: <Y2l1/qXHxyctU9ir@petertodd.org>
References: <Y2ln2fJ+8+Q0qS0E@petertodd.org> <Y2l1/qXHxyctU9ir@petertodd.org>
Message-ID: <CALZpt+GgH7B-sSWndNfrMp8qza=LmZQ6BWGGFjFxcutat7Nxww@mail.gmail.com>

Hi Peter,

> We can ensure with high probability that the transaction can be cancelled/mined
> at some point after N blocks by pre-signing a transaction, with nLockTime set
> sufficiently far into the future, spending one or more inputs of the
> transaction with a sufficiently high fee that it would replace transaction(s)
> attempting to exploit Rule #3 pinning (note how the package limits in Bitcoin
> Core help here).

>From my understanding, there are many open questions to such a
pre-signed high-fee solution aiming to address Rule #3 pinning.
Determining the high-fee to guarantee replacements with high odds. I
think it should be superior to current top network mempools sat/vb *
MAX_STANDARD_TX_WEIGHT, otherwise an adversary can pin the multi-party
funded transaction on the ground of Core's
replacement rule ("The replacement transaction's feerate is greater
than the feerates of all directly conflicting transactions''). Though
note the difficulty, the sat/vb is an unknown fact at time of
signatures exchange among the multi-party funded transaction
participants. Solving this issue probably requires from then to
overshoot, and adopt a historical worst-case mempool feerate.

This "historically-worst" sat/vb introduces two new issues, first I
think this is an economic lower bound on the funds that can be staked
in the collaborative transaction. Second I believe this constitutes a
griefing vector, where a participant could deliberately pin to inflict
an asymmetric damage, without entering into any fee competition. This
griefing vector could be leveraged as hard as being triggered by a
miner-as-participant in so-called miner harvesting attacks.

Further, I think this solution relying on nLocktime doesn't solve the
timevalue DoS inflicted to the participants UTXOs, until the
pre-signed high-fee transaction is final. If participants prefer to
save the timevalue of their contributed UTXOs over operation success,
a better approach could be for them to unilaterally spend after a
protocol/implementation timepoint (e.g LN's funding timeout recovery
mechanism).

A more workable solution I believe could be simply to rely on
package-relay, an ephemeral anchor output, and a special replacement
regime (e.g nVersion=3) to allow the multi-party funded transaction
coordinator to unilateral fee-bump, in a step-by-step approach. I.e
without making assumptions on the knowledge of network mempools and
burning directly the worst amount in fees.

Best,
Antoine


Le lun. 7 nov. 2022 ? 16:18, Peter Todd via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> a ?crit :

> On Mon, Nov 07, 2022 at 03:17:29PM -0500, Peter Todd via bitcoin-dev wrote:
> > tl;dr: We can remove the problem of Rule #5 pinning by ensuring that all
> > transactions in the mempool are always replaceable.
>
> With Rule #5 solved, let's look at the other pinning attack on multi-party
> transactions: BIP-125 Rule #3
>
> tl;dr: In conjunction with full-RBF, nLockTime'd, pre-signed, transactions
> can
> ensure that one party is not forced to pay for all the cost of a rule #3
> replacement.
>
>
> # What is the problem?
>
> When a transaction contains inputs from multiple parties, each party can
> lock
> up funds from the other party by spending their input with a transaction
> that
> is difficult/expensive to replace. Obviously, the clearest example of
> "difficult to
> replace" is a non-BIP-125 (Opt-in-RBF) transaction. But here, we'll assume
> that
> full-rbf is implemented and all transactions are replaceable.
>
> BIP-125 Rule #3 states that:
>
>     The replacement transaction pays an absolute fee of at least the sum
> paid
>     by the original transactions.
>
> The attack is that the malicious party, who we'll call Mallory, broadcasts
> a
> transaction spending their input(s) with a low fee rate transaction that's
> potentially quite large, during a time of high mempool demand. Due to the
> low
> fee rate this transaction will take a significant amount of time to mine.
> The
> other parties to the transaction - who we'll collectively call Alice - are
> now
> unable to spend their inputs unless they broadcast a transaction "paying
> for"
> Mallory's.
>
> This attack works because Mallory doesn't expect the conflicting tx to
> actually
> get mined: he assumes it'll either expire, or Alice will get frustrated and
> have to double spend it. By simple tying up money, Mallory has caused
> Alice to
> actually lose money.
>
>
> # Fixing the problem with nLockTime
>
> Conversely, in the case of an honest multi-party transaction, whose parties
> we'll call Alice and Bob, the parties genuinely intend for one of two
> outcomes:
>
> 1) The multi-party transaction to get mined within N blocks.
> 2) The transaction to be cancelled (most likely by spending one of the
> inputs).
>
> We can ensure with high probability that the transaction can be
> cancelled/mined
> at some point after N blocks by pre-signing a transaction, with nLockTime
> set
> sufficiently far into the future, spending one or more inputs of the
> transaction with a sufficiently high fee that it would replace
> transaction(s)
> attempting to exploit Rule #3 pinning (note how the package limits in
> Bitcoin
> Core help here).
>
> There's a few different ways to implement this, and exactly which one makes
> sense will depend on the specifics of the multi-party protocol. But the
> general
> approach is to defeat the attack by ensuring that Mallory will have to pay
> the
> cost of getting the multi-party transaction unstuck, at some point in the
> future.
>
> For example, in a two party transaction where there's a clearly more
> reputable
> party (Alice), and an untrusted party (Mallory), Alice could simply require
> Mallory to provide a nLockTime'd transaction spending only his input to
> fees,
> multiple days into the future. In the unlikely event that Mallory holds up
> the
> protocol, he will be severely punished. Meanwhile, Alice can always cancel
> at
> no cost.
>
> In a many party transaction where both parties are equally (un)trustworthy
> the
> protocol could simply have both parties sign a series of transactions,
> nLockTimed at decreasingly far into a future, paying a decreasingly amount
> of
> fees. If either party holds up the transaction intentionally, they'll both
> pay
> a high cost. But again, at some point Mallory will have paid the full
> price for
> his attack. This approach also has the beneficial side effect of
> implementing
> fee discovery with rbf. This approach is easier as the number of parties
> increases, eg the Wasabi/Joinmarket transactions with hundreds of inputs
> and
> outputs: they collectively already have to pay a significant fee to get the
> transaction mined, making the extra poential cost needed to defeat pinning
> minimal.
>
>
> # Coordinator Spent Bonds with Package Relay/Replacement
>
> For schemes with a central semi-trusted coordinator, such as Wasabi
> coinjoins,
> with package relay/replacement we can use a two party punishment
> transaction
> consisting of:
>
>     tx1 - spends Mallory's input to a txout spendable by:
>            IF
>                <coordinator> CheckSig
>            Else
>                <delay> CheckSequenceVerify
>                <mallory> CheckSig
>            EndIf
>
>     tx2 - spends tx1 output to as much fees as needed
>
> Whether or not Mallory cheated with a double-spend is provable to third
> parties; the second transaction ensures that Mallory can't simply release
> tx1
> on their own to frame the coordinator. The use of CheckSequenceVerify
> ensures
> that if mallory did try to frame the coordinator, they don't have to do
> anything to return the funds to Mallory.
>
> --
> https://petertodd.org 'peter'[:-1]@petertodd.org
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221107/100b0410/attachment.html>

From d at ngould.dev  Tue Nov  8 02:57:34 2022
From: d at ngould.dev (Dan Gould)
Date: Tue, 08 Nov 2022 02:57:34 +0000
Subject: [bitcoin-dev] Fwd: P2EP Lightning PayJoin
Message-ID: <8E6C6EB5-8B7B-4197-9103-B1C52F9D9968@ngould.dev>

Funding channels on a lightning node can be a pain. First, I need to send funds to my node on-chain. Then I need to make another transaction to open channels. Instead, we can use the BIP 78 PayJoin P2EP protocol to fund and open channels in a single transaction.

We do not communicate over the shared blockchain, we share the blockchain by communicating.

Here is an illustration of how the BIP 78 protocol pairs with the BOLT 2 Channel establishment protocol:

???????????????? ??????????????????? ????????
?Lightning Peer? ?My Lightning Node? ?Sender?
???????????????? ??????????????????? ????????
? ? ?
? BOLT 2 ???????? Bip21 with ?pj= ?????????
? Channel Establishment ? ?
? ???????? Original PSBT ???????????
? ? ?
? ? ?
?????????? open_channel ?????????? ?
? ? ?
????????? accept_channel ????????? ?
? ? BIP 78 ?
? ? ?
????????? funding_created ???????? ?
? ? ?
????????? funding_signed ????????? ?
? ? ?
? ? PayJoin Proposal ?
? ??????? PSBT ?????????
? ? ?
? ? ?
? ? ?? PayJoin + Funding ????????
? ? ? Transaction ?
? ? ? ?
x?xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx?xxx ? xxxxxxxxxxxxxxxxxxxxxxxxxx?x
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx BITCOIN NETWORK xxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
x?xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx?xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx?x
? ? ?
??????????channel_ready ?????????? ?
? ? ?
????????? channel_ready ?????????? ?
? ? ?

We use P2EP to automate [PSBT Channel establishment](https://gist.github.com/yuyaogawa/3d69bfa03b0702b8ff12c210bc795a6a) communications. As an added benefit, The BIP 78 spec helps avoid surveillance heuristics as well. On-chain, these transactions look like regular PayJoins when using Taproot outputs.

I thank Martin Habov?tiak for the initial work on this idea. Thank you to Riccardo Casatta for developing the rust payjoin crate further. Thank you to Evan Lin for early hacking late nights on this idea. Thanks to my Legends of Lightning Tournament teammates Armin Sabouri and Nick Farrow.

We have released "nolooking," an experimental alpha that implements this work, on the Umbrel app store.

A brand new node can become totally connected in a single transaction that opens channels to outbound peers, and could immediately swap for inbound capacity. Just by scanning a single QR code.

[Source](https://github.com/chaincase-app/nolooking)

Want to help? The rust [payjoin crate](https://github.com/Kixunil/payjoin) needs love in the form of code review and unit testing. Don?t hesitate to reach out.

Dan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221108/fac7c62b/attachment-0001.html>

From aj at erisian.com.au  Tue Nov  8 03:20:23 2022
From: aj at erisian.com.au (Anthony Towns)
Date: Tue, 8 Nov 2022 13:20:23 +1000
Subject: [bitcoin-dev] Refreshed BIP324
In-Reply-To: <zxv58iXZ73hf9ge8S0QLTanW-uLzaWjNtMHuKONP9hrqS5RhwitxzfVaMH8hbi3yImgNrKme3lCuDcHYKkpxEQHyGZZHJ8xtReOcnAx3o4g=@wuille.net>
References: <56677685-619a-691f-d5bc-54b69fdb6ed2@bip324.com>
 <zxv58iXZ73hf9ge8S0QLTanW-uLzaWjNtMHuKONP9hrqS5RhwitxzfVaMH8hbi3yImgNrKme3lCuDcHYKkpxEQHyGZZHJ8xtReOcnAx3o4g=@wuille.net>
Message-ID: <Y2nK99fHUKxbPHmw@erisian.com.au>

On Wed, Oct 26, 2022 at 04:39:02PM +0000, Pieter Wuille via bitcoin-dev wrote:
> However, it obviously raises the question of how the mapping table between the
> 1-byte IDs and the commands they represent should be maintained:
> 
> 1. The most straightforward solution is using the BIP process as-is: let BIP324
>    introduce a fixed initial table, and future BIPs which introduce new
>    messages can introduce new mapping entries for it. [...]

> 3. Yet another possibility is not having a fixed table at all, and negotiate
>    the mapping dynamically. E.g. either side could send a message at
>    connection time with an explicit table of entries "when I send byte X, I
>    mean command Y".

FWIW, I think these two options seem fine -- maintaining a purely local
and hardcoded internal mapping of "message string C has id Y" where Y
is capped by the number of commands you actually implement (presumably
less than 65536 total) is easy, and providing a per-peer mapping from
"byte X" to "id Y" then requires at most 512 bytes per peer, along with
up to 3kB of initial setup to tell your peer what mappings you'll use.

> Our idea is to start out with approach (1), with a mapping table effectively
> managed by the BIP process directly, but if and when collisions become a
> concern (maybe due to many parallel proposals, maybe because the number of
> messages just grows too big), switch to approach (3), possibly even
> differentially (the sent mappings are just additions/overwrites of the
> BIP-defined table mappings, rather than a full mapping).

I guess I think it would make sense to not start using a novel 1-byte
message unless you've done something to introduce that message first;
whether that's via approach (3) ("I'm going to use 0xE9 to mean pkgtxns")
or via a multibyte feature support message ("I sent sendaddrv3 as a
10-byte message, that implies 0xA3 means addrv3 from now on").

I do still think it'd be better to recommend against reserving a byte for
one-shot messages, and not do it for existing one-shot messages though.

Cheers,
aj

From salvatore.ingala at gmail.com  Tue Nov  8 09:17:42 2022
From: salvatore.ingala at gmail.com (Salvatore Ingala)
Date: Tue, 8 Nov 2022 10:17:42 +0100
Subject: [bitcoin-dev] Merkleize All The Things
Message-ID: <CAMhCMoH9uZPeAE_2tWH6rf0RndqV+ypjbNzazpFwFnLUpPsZ7g@mail.gmail.com>

Hi list,

I have been working on some notes to describe an approach that uses
covenants in order to enable general smart contracts in bitcoin. You can
find them here:

    https://merkle.fun

The approach has a number of desirable features:

- small impact to layer 1;
- not application-specific, very general;
- it fits well into P2TR;
- it does not require new cryptographic assumptions, nor any construction
that has not withstood the test of time.

This content was presented at the BTCAzores unconference, where it received
the name of MATT ? short for Merkleize All The Things.
In fact, no other cryptographic primitive is required, other than Merkle
trees.

I believe this construction gets close to answering the question of how
small a change on bitcoin's layer 1 would suffice to enable arbitrary smart
contracts.

It is not yet at the stage where a formal proposal can be made, therefore
the proposed specs are only for illustrative purposes.

The same content is reformatted below for the mailing list.

Looking forward to hearing about your comments and improvements.
Salvatore Ingala


==========================================


# General smart contracts in bitcoin via covenants

Covenants are UTXOs that are encumbered with restrictions on the outputs of
the transaction spending the UTXO. More formally, we can define a covenant
any UTXO such that at least one of its spending conditions is valid only if
one or more of the outputs? scriptPubKey satisfies certain restrictions.

Generally, covenant proposals also add some form of introspection (that is,
the ability for Script to access parts of the inputs/outputs, or the
blockchain history).

In this note, we want to explore the possibilities unleashed by the
addition of a covenant with the following properties:

- introspection limited to a single hash attached to the UTXO (the
?covenant data?), and input/output amounts;
- pre-commitment to every possible future script (but not their data);
- few simple opcodes operating with the covenant data.

We argue that such a simple covenant construction is enough to extend the
power of bitcoin?s layer 1 to become a universal settlement layer for
arbitrary computation.

Moreover, the covenant can elegantly fit within P2TR transactions, without
any substantial increase for the workload of bitcoin nodes.

A preliminary version of these notes was presented and discussed at the
BTCAzores Unconference [1], on 23rd September 2022.


# Preliminaries

We can think of a smart contract as a ?program? that updates a certain
state according to predetermined rules (which typically include access
control by authorizing only certain public keys to perform certain
actions), and that can possibly lock/unlock some coins of the underlying
blockchain according to the same rules.

The exact definition will be highly dependent on the properties of the
underlying blockchain.

In bitcoin, the only state upon which all the nodes reach consensus is the
UTXO set; other blockchains might have other data structures as part of the
consensus, like a key-value store that can be updated as a side effect of
transaction execution.

In this section we explore the following concepts in order to set the
framework for a definition of smart contracts that fits the structure of
bitcoin:

- the contract?s state: the ?memory? the smart contract operates on;
- state transitions: the rules to update the contract?s state;
- covenants: the technical means that can allow contracts to function in
the context of a bitcoin UTXO.

In the following, an on-chain smart contract is always represented as a
single UTXO that implicitly embeds the contract?s state and possibly
controls some coins that are ?locked? in it. More generally, one could
think of smart contracts that are represented in a set of multiple UTXOs;
we leave the exploration of generalizations of the framework to future
research.

## State

Any interesting ?state? of a smart contract can ultimately be encoded as a
list, where each element is either a bit, a fixed-size integers, or an
arbitrary byte string.

Whichever the choice, it does not really affect what kinds of computations
are expressible, as long as one is able to perform some basic computations
on those elements.

In the following, we will assume without loss of generality that
computations happen on a state which is a list of fixed length S = [s_1,
s_2, ?, s_n], where each s_i is a byte string.

### Merkleized state

By constructing a Merkle tree that has the (hashes of) the elements of S in
the leaves, we can produce a short commitment h_S to the entire list S with
the following properties (that hold for a verifier that only knows h_S):

- a (log n)-sized proof can prove the value of an element s_i;
- a (log n + |x|)-sized proof can prove the new commitment h_S?, where S?
is a new list obtained by replacing the value of a certain leaf with x.

This allows to compactly commit to a RAM, and to prove correctness of RAM
updates.

In other words, a stateful smart contract can represent an arbitrary state
in just a single hash, for example a 32-byte SHA256 output.

### State transitions and UTXOs

We can conveniently represent a smart contract as a finite state machine
(FSM), where exactly one node can be active at a given time. Each node has
an associated state as defined above, and a set of transition rules that
define:

- who can use the rule;
- what is the next active node in the FSM;
- what is the state of the next active node.

It is then easy to understand how covenants can conveniently represent and
enforce the smart contracts in this framework:

- The smart contract is instantiated by creating a UTXO encumbered with a
covenant; the smart contract is in the initial node of the FSM.
- The UTXO?s scriptPubKey specifies the current state and the valid
transitions.
- The UTXO(s) produced after a valid transition might or might not be
further encumbered, according to the rules.

Therefore, what is necessary in order to enable this framework in bitcoin
Script is a covenant that allows the enforcement of such state transitions,
by only allowing outputs that commit to a valid next node (and
corresponding state) in the FSM.

It is not difficult to show that arbitrary computation is possible over the
committed state, as long as relatively simple arithmetic or logical
operations are available over the state.

Remark: using an acyclic FSM does not reduce the expressivity of the smart
contracts, as any terminating computation on bounded-size inputs which
requires cycles can be unrolled into an acyclic one.

### Merkleized state transitions

Similarly to how using Merkle trees allows to succinctly represent
arbitrary data with a short, 32-byte long summary, the same trick allows to
succinctly represent arbitrary state transitions (the smart contract?s
code) with a single 32-byte hash. Each of the possible state transitions is
encoded as a Script which is put in a leaf of a Merkle tree; the Merkle
root of this tree is a commitment to all the possible state transitions.
This is exactly what the taptree achieves in Taproot (see BIP-0341 [2]).

Later sections in this document will suggest a possible way of how both the
contract?s state and valid transition rules could be represented in UTXOs.

## On-chain computation?!

Should the chain actually do computation?

If naively designed, the execution of a contract might require a large
number of transactions, which is not feasible.

While the covenant approach does indeed enable a chain of transactions to
perform arbitrary computation, simple economic considerations will push
protocol designers to perform any non-trivial computation off-chain, and
instead use the blockchain consensus only to verify the computation; or, if
possible, skip the verification altogether.

The fundamental fact that a blockchain?s layer 1 never actually needs to
run complex programs in order to enable arbitrary complex smart contracting
was observed in the past, for example in a 2016 post by Greg Maxwell [3].

Vitalik Buterin popularized the concept of "functionality escape velocity"
[4] to signify the minimum amount of functionality required on layer 1 in
order to enable anything else to be built on top (that is, on layer 2 and
beyond).

In the following section, we will argue that a simple covenant construction
suffices to achieve the functionality escape velocity in the UTXO model.


# Commitments to computation and fraud challenges

In this section, we explore how a smart contract that requires any
non-trivial computation f : X --> Y (that is too expensive or not feasible
with on-chain Script state transitions) can be implemented with the simple
covenants described in the previous section.

The ideas in this section appeared in literature; the reader is referred to
the references for a more comprehensive discussion.

We want to be able to build contracts that allow conditions of the type
"f(x) = y"; yet, we do not want layer 1 to be forced to perform any
expensive computation.

In the following, we assume for simplicity that Alice and Bob are the only
participants of the covenant, and they both locked some funds bond_A and
bond_B (respectively) inside the covenant?s UTXO.

1. Alice posts the statement ?f(x) = y?.
2. After a challenge period, if no challenge occurs, Alice is free to
continue and unlock the funds; the statement is true.
3. At any time before the challenge period expires, Bob can start a
challenge: ?actually, f(x) = z?.

In case of a challenge, Alice and Bob enter a challenge resolution
protocol, arbitrated by layer 1; the winner takes the other party?s bond
(details and the exact game theory vary based on the type of protocol the
challenge is part of; choosing the right amount of bonds is crucial for
protocol design).

The remainder of this section sketches an instantiation of the challenge
protocol.

## The bisection protocol for arbitrary computation

In this section, we sketch the challenge protocol for an arbitrary
computation f : X --> Y.

### Computation trace

Given the function f, it is possible to decompose the entire computation in
simple elementary steps, each performing a simple, atomic operation. For
example, if the domain of x and y is that of binary strings of a fixed
length, it is possible to create a boolean circuit that takes x and
produces y; in practice, some form of assembly-like language operating on a
RAM might be more efficient and fitting for bitcoin Script.

In the following, we assume each elementary operation is operating on a
RAM, encoded in the state via Merkle trees as sketched above. Therefore,
one can represent all the steps of the computation as triples tri = (st_i,
op_i, st_{i + 1}), where st_i is the state (e.g. a canonical Merkle tree of
the RAM) before the i-th operation, st_{i + 1} is the state after, and op_i
is the description of the operation (implementation-specific; it could be
something like ?add a to b and save the result in c).

Finally, a Merkle tree M_T is constructed that has as leaves the values of
the individual computation steps T = {tr_0, tr_1, ?, tr_{N - 1}} if the
computation requires N steps, producing the Merkle root h_T. The height of
the Merkle tree is log N. Observe that each internal node commits to the
portion of the computation trace corresponding to its own subtree.

Let?s assume that the Merkle tree commitments for internal nodes are
further augmented with the states st_{start} and st_{end}, respectively the
state before the operation of in the leftmost leaf of the subtree, and
after the rightmost leaf of the subtree.

### Bisection protocol

The challenge protocol begins with Alice posting what she claims is the
computation trace h_A, while Bob disagrees with the trace h_B != h_A;
therefore, the challenge starts at the root of M_T, and proceeds in steps
in order to find a leaf where Alice and Bob disagree (which is guaranteed
to exist, hence the disagreement). Note that the arbitration mechanism
knows f, x and y, but not the correct computation trace hash h_T.

(Bisection phase): While the challenge is at a non-leaf node of M_T, Alice
and Bob take turns to post the two hashes corresponding to the left and
right child of their claimed computation trace hash; moreover, they post
the start/end state for each child node. The protocol enforces that Alice?s
transaction is only valid if the posted hashes h_{l; A} and h_{r; A}, and
the declared start/end state for each child are consistent with the
commitment in the current node.

(Arbitration phase): If the protocol has reached the i-th leaf node, then
each party reveals (st_i, op_i, st_{i + 1}); in fact, only the honest party
will be able to reveal correct values, therefore the protocol can
adjudicate the winner.

Remark: there is definitely a lot of room for optimizations; it is left for
future work to find the optimal variation of the approach; moreover,
different challenge mechanisms could be more appropriate for different
functions f.

### Game theory (or why the chain will not see any of this)

With the right economic incentives, protocol designers can guarantee that
playing a losing game always loses money compared to cooperating.
Therefore, the challenge game is never expected to be played on-chain. The
size of the bonds need to be appropriate to disincentivize griefing attacks.

### Implementing the bisection protocol's state transitions

It is not difficult to see that the entire challenge-response protocol
above can be implemented using the simple state transitions described above.

Before a challenge begins, the state of the covenant contains the value of
x, y and the computation trace computed by Alice. When starting the
challenge, Bob also adds its claim for the correct computation trace, and
the covenant enters the bisection phase.

During the bisaction phase, the covenant contains the claimed computation
trace for that node of the computation protocol, according to each party.
In turns, each party has to reveal the corresponding computation trace for
both the children of the current node; the transaction is only valid if the
hash of the current node can be computed correctly from the information
provided by each party about the child nodes. The protocol repeats on one
of the two child nodes on whose computation trace the two parties disagree
(which is guaranteed to exist). If a leaf of M_T is reached, the covenant
enters the final arbitration phase.

During the arbitration phase (say at the i-th leaf node of M_T), any party
can win the challenge by providing correct values for tr_i = (st_i, op_i,
st_{i + 1}). Crucially, only one party is able to provide correct values,
and Script can verify that indeed the state moves from st_i to st_{i + 1}
by executing op_i. The challenge is over.

At any time, the covenant allows one player to automatically win the
challenge after a certain timeout if the other party (who is expected to
?make his move?) does not spend the covenant. This guarantees that the
protocol can always find a resolution.

### Security model

As for other protocols (like the lightning network), a majority of miners
can allow a player to win a challenge by censoring the other player?s
transactions. Therefore, the bisection protocol operates under the honest
miner majority assumption. This is acceptable for many protocols, but it
should certainly be taken into account during protocol design.


# MATT covenants

We argued that the key to arbitrary, fully general smart contracts in the
UTXO model is to use Merkle trees, at different levels:

1. succinctly represent arbitrary state with a single hash. Merkleize the
state!
2. succinctly represent the possible state transitions with a single hash.
Merkleize the Script!
3. succinctly represent arbitrary computations with a single hash.
Merkleize the execution!

(1) and (2) alone allow contracts with arbitrary computations; (3) makes
them scale.

   Merkleize All The Things!

In this section we sketch a design of covenant opcodes that are
taproot-friendly and could easily be added in a soft fork to the existing
SegWitv1 Script.

## Embedding covenant data in P2TR outputs

We can take advantage of the double-commitment structure of taproot outputs
(that is, committing to both a public key and a Merkle tree of scripts) to
compactly encode both the covenant and the state transition rules inside
taproot outputs.

The idea is to replace the internal pubkey Q with a key Q? obtained by
tweaking Q with the covenant data (the same process that is used to commit
to the root of the taptree). More precisely, if d is the data committed to
the covenant, the covenant-data-augmented internal key Q? is defined as:

    Q? = Q + int(hashTapCovenantData(Q || h_{data}))G

where h_{data} is the sha256-hash of the covenant data. It is then easy to
prove that the point is constructed in this way, by repeating the
calculation.

If there is no useful key path spend, similarly to what is suggested in
BIP-0341 [5] for the case of scripts with no key path spends, we can use
the NUMS point:
    H =
lift_x(0x0250929b74c1a04954b78b4b6035e97a5e078a5a0f28ec96d547bfee9ace803ac0).

TODO: please double check if the math above is sound.

## Changes to Script

The following might be some minimal new opcodes to add for taproot
transactions in order to enable the construction above. This is a very
preliminary proposal, and not yet complete nor correct.

- OP_SHA256CAT: returns the SHA256 hash of the concatenation of the second
and the first (top) element of the stack. (redundant if OP_CAT is enabled,
even just on operands with total length up to 64 bytes)
- OP_CHECKINPUTCOVENANTVERIFY: let x, d be the two top elements of the
stack; behave like OP_SUCCESS if any of x and d is not exactly 32 bytes;
otherwise, check that the x is a valid x-only pubkey, and the internal
pubkey P is indeed obtained by tweaking lift_x(x) with d.
- OP_INSPECTNUMINPUTS, OP_INSPECTNUMOUTPUTS, OP_INSPECTINPUTVALUE and
OP_INSPECTOUTPUTVALUE - opcodes to push number on the stack of
inputs/outputs and their amounts.
- OP_CHECKOUTPUTCOVENANTVERIFY: given a number out_i and three 32-byte hash
elements x, d and taptree on top of the stack, verifies that the out_i-th
output is a P2TR output with internal key computed as above, and tweaked
with taptree. This is the actual covenant opcode.

TODO:

- Many contracts need parties to provide additional data; simply passing it
via the witness faces the problem that it could be malleated. Therefore, a
way of passing signed data is necessary. One way to address this problem
could be to add a commitment to the data in the annex, and add an opcode to
verify such commitment. Since the annex is covered by the signature, this
removes any malleability. Another option is an OP_CHECKSIGFROMSTACK opcode,
but that would cost an additional signature check.
- Bitcoin numbers in current Script are not large enough for amounts.

Other observations:

- OP_CHECKINPUTCOVENANTVERIFY and OP_CHECKOUTPUTCOVENANTVERIFY could have a
mode where x is replaced with a NUMS pubkey, for example if the first
operand is an empty array of bytes instead of a 32 byte pubkey; this saves
about 31 bytes when no internal pubkey is needed (so about 62 bytes for a
typical contract transition using both opcodes)
- Is it worth adding other introspection opcodes, for example
OP_INSPECTVERSION, OP_INSPECTLOCKTIME? See Liquid's Tapscript Opcodes [6].
- Is there any malleability issue? Can covenants ?run? without signatures,
or is a signature always to be expected when using spending conditions with
the covenant encumbrance? That might be useful in contracts where no
signature is required to proceed with the protocol (for example, any party
could feed valid data to the bisection protocol above).
- Adding some additional opcodes to manipulate stack elements might also
bring performance improvements in applications (but not strictly necessary
for feasibility).

Remark: the additional introspection opcodes available in Blockstream
Liquid [6] do indeed seem to allow MATT covenants; in fact, the opcodes
OP_CHECKINPUTCOVENANTVERIFY and OP_CHECKOUTPUTCOVENANTVERIFY could be
replaced by more general opcodes like the group {OP_TWEAKVERIFY,
OP_INSPECTINPUTSCRIPTPUBKEY, OP_PUSHCURRENTINPUTINDEX,
OP_INSPECTOUTPUTSCRIPTPUBKEY }.

### Variant: bounded recursivity

In the form described above, the covenant essentially allows fully
recursive constructions (an arbitrary depth of the covenant execution tree
is in practice equivalent to full recursion).

If recursivity is not desired, one could modify the covenants in a way that
only allows a limited depth: a counter could be attached to the covenant,
with the constraint that the counter must be decreased for
OP_CHECKOUTPUTCOVENANTVERIFY. That would still allow arbitrary fraud proofs
as long as the maximum depth is sufficient.

However, that would likely reduce its utility and prevent certain
applications where recursivity seems to be a requirement.

The full exploration of the design space is left for future research.


# Applications

This section explores some of the potential use cases of the techniques
presented above. The list is not exhaustive.

Given the generality of fraud proofs, some variant of every kind of smart
contracts or layer two construction should be possible with MATT covenants,
although the additional requirements (for example the capital lockup and
the challenge period delays) needs to be accurately considered; further
research is necessary to assess for what applications the tradeoffs are
acceptable.

## State channels

A state channel is a generalization of a payment channel where,
additionally to the balance at the end of each channel, some additional
state is stored. The state channel also specifies what are the rules on how
to update the channel?s state.

For example, two people might play a chess game, where the state encodes
the current configuration of the board. The valid state transitions
correspond to the valid moves; and, once the game is over, the winner takes
a specified amount of the channel?s money.

With eltoo-style updates, such a game could be played entirely off-chain,
as long as both parties are cooperating (by signing the opponent?s state
update).

The role of the blockchain is to guarantee that the game can be moved
forward and eventually terminated in case the other party does not
cooperate.

In stateful blockchain, this is simply achieved by publishing the latest
state (Merkleized or not) and then continuing the entire game on-chain.
This is expensive, especially if the state transitions require some complex
computation.

An alternative that avoids moving computations on-chain is the use of a
challenge-response protocol, as sketched above.

Similarly to the security model of lightning channels, an honest party can
always win a challenge under the honest-majority of miners. Therefore, it
is game-theoretically losing to attempt cheating in a channel.

## CoinPool

Multiparty state channels are possible as well; therefore, constructions
like CoinPool [7] should be possible, enabling multiple parties to share a
single UTXO.

## Zero knowledge proofs in L2 protocols

Protocols based on ZK-proofs require the blockchain to be the verifier; the
verifier is a function that takes a zero-knowledge proof and returns
true/false based on its correctness.

Instead of an OP_STARK operator in L1, one could think of compiling the
OP_STARK as the function f in the protocol above.

Note that covenants with a bounded ?recursion depth? are sufficient to
express OP_STARK, which in turns imply the ability to express arbitrary
functions within contracts using the challenge protocol.

One advantage of this approach is that no new cryptographic assumptions are
added to bitcoin?s layer 1 even if OP_STARK does require it; moreover, if a
different or better OP_STARK2 is discovered, the innovation can reach layer
2 contracts without any change needed in layer 1.

## Optimistic rollups

John Light recently posted a research report on how Validity Rollups could
be added to bitcoin?s layer 1 [8]. While no exact proposal is pushed
forward, the suggested changes required might include a combination of
recursive covenants, and specific opcodes for validity proof verification.

Fraud proofs are the core for optimistic rollups; exploring the possibility
of implementing optimistic rollups with MATT covenants seems a promising
direction. Because of the simplicity of the required changes to Script,
this might answer some of the costs and risks analyzed in the report, while
providing many of the same benefits. Notably, no novel cryptography needs
to become part of bitcoin?s layer 1.

Optimistic Rollups would probably require a fully recursive version of the
covenant (while fraud proofs alone are possible with a limited recursion
depth).


# Acknowledgments

Antoine Poinsot suggested an improvement to the original proposed covenant
opcodes, which were limited to taproot outputs without a valid key-path
spend.

The author would also like to thank catenocrypt, Antoine Riard, Ruben
Somsen and the participants of the BTCAzores unconference for many useful
discussions and comments on early versions of this proposal.


# References

The core idea of the bisection protocol appears to have been independently
rediscovered multiple times. In blockchain research, it is at the core of
fraud proof constructions with similar purposes, although not focusing on
bitcoin or covenants; see for example:

- Harry Kalodner et al. ?Arbitrum: Scalable, private smart contracts.? ?
27th USENIX Security Symposium. 2018.
https://www.usenix.org/system/files/conference/usenixsecurity18/sec18-kalodner.pdf
- Jason Teutsch and Christian Reitwiessner. ?A scalable verification
solution for blockchains? ? TrueBit protocol. 2017.
https://people.cs.uchicago.edu/~teutsch/papers/truebit.pdf

The same basic idea was already published prior to blockchain use cases;
see for example:

Ran Canetti, Ben Riva, and Guy N. Rothblum. ?Practical delegation of
computation using multiple servers.? ? Proceedings of the 18th ACM
conference on Computer and communications security. 2011.
http://diyhpl.us/~bryan/papers2/bitcoin/Practical%20delegation%20of%20computation%20using%20multiple%20servers.pdf



# Footnotes

[1] - https://btcazores.com
[2] - https://github.com/bitcoin/bips/blob/master/bip-0341.mediawiki
[3] -
https://bitcointalk.org/index.php?topic=1427885.msg14601127#msg14601127
[4] - https://vitalik.ca/general/2019/12/26/mvb.html
[5] -
https://github.com/bitcoin/bips/blob/master/bip-0341.mediawiki#constructing-and-spending-taproot-outputs
[6] -
https://github.com/ElementsProject/elements/blob/master/doc/tapscript_opcodes.md
[7] - https://coinpool.dev/v0.1.pdf
[8] - https://bitcoinrollups.org
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221108/d6f2d8a3/attachment-0001.html>

From AdamISZ at protonmail.com  Tue Nov  8 09:28:44 2022
From: AdamISZ at protonmail.com (AdamISZ)
Date: Tue, 08 Nov 2022 09:28:44 +0000
Subject: [bitcoin-dev] On mempool policy consistency
In-Reply-To: <Y1q+MedepB1qUpBP@erisian.com.au>
References: <mailman.38435.1666828344.956.bitcoin-dev@lists.linuxfoundation.org>
 <CAHTn92wfjTCF5UtbjezbEYWTUQ7t6FNZu1ow0pirJXGFoXJxCA@mail.gmail.com>
 <Y1q+MedepB1qUpBP@erisian.com.au>
Message-ID: <jzS-a7kpDwvAhO4TJiTgtpsP95Zi8BRvIgUqjOs3hEVI_Uu-ey1LfCnN2D8wkG21yfVPGIujbiDXCfFAyfW56gPtvd8p3SrsOmOE22IWAuA=@protonmail.com>

Hi aj and list,
(questions inline)


------- Original Message -------
On Thursday, October 27th, 2022 at 18:21, Anthony Towns via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:

> 
> Is that true? Antoine claims [1] that opt-in RBF isn't enough to avoid
> a DoS issue when utxos are jointly funded by untrusting partners, and,
> aiui, that's the main motivation for addressing this now.
> 
> [1] https://lists.linuxfoundation.org/pipermail/lightning-dev/2021-May/003033.html
> 
> The scenario he describes is: A, B, C create a tx:
> 
> inputs: A1, B1, C1 [opts in to RBF]
> fees: normal
> outputs:
> [lightning channel, DLC, etc, who knows]
> 
> they all analyse the tx, and agree it looks great; however just before
> publishing it, A spams the network with an alternative tx, double
> spending her input:
> 
> inputs: A1 [does not opt in to RBF]
> fees: low
> outputs: A
> 
> If A gets the timing right, that's bad for B and C because they've
> populated their mempool with the 1st transaction, while everyone else
> sees the 2nd one instead; and neither tx will replace the other. B and
> C can't know that they should just cancel their transaction, eg:
> 
> inputs: B1, C1 [opts in to RBF]
> fees: 50% above normal
> outputs:
> [smaller channel, refund, whatever]
> 
> and might instead waste time trying to fee bump the tx to get it mined,
> or similar.
> 
> What should folks wanting to do coinjoins/dualfunding/dlcs/etc do to
> solve that problem if they have only opt-in RBF available?
> 
<snip>
> 

I read Antoine's original post on this and got the general gist, and here also, it makes sense, but I'd like to ask: is it necessary that (B, C) in the above not *see* A's opt-out "pre-replacement" (inputs: A1, outputs: A, fees: low; call it TX_2)? I get that they cannot replace it, but the idea that they suffer financial loss from "ignorant" fee bumping is the part that seems weird to me. Clearly TX_2 gets gossiped to other mempools; and understood that it does not replace the TX_1 (the 3-input) in B's mempool, say, but why should they not even hear about it? Is it just a matter of engineering, or is there some deeper problem with that.

About this general flavour of attack, it's never been a *big* concern in Joinmarket imo (though, we did until recently have a bug that made this happen *by accident*, i.e. people double spending an input out of a negotiated join, albeit it was rare; but it's ofc definitely *possible* to 'grief' like this, given the ordering of events; maker sends signature, maker broadcasts double spend - 95% of the time they will be first). Interactive protocols are yucky and I think there'll always be griefing possibilities; designing around multiple-rounds of negotiation amongst not always-on participants is even more yucky, so just having a 'taker is in charge of network fee; if it's slow or gets double spent out causing time delay then just wait', combined with 'there really isn't any economic incentive for an attacker' (i.e. ignoring griefing) might sound crappy but it's probably just being realistic.

Of course, off-chain contracting has more sophisticated considerations than this.

Cheers,
AdamISZ/waxwing


From ZmnSCPxj at protonmail.com  Tue Nov  8 12:01:11 2022
From: ZmnSCPxj at protonmail.com (ZmnSCPxj)
Date: Tue, 08 Nov 2022 12:01:11 +0000
Subject: [bitcoin-dev] Merkleize All The Things
In-Reply-To: <CAMhCMoH9uZPeAE_2tWH6rf0RndqV+ypjbNzazpFwFnLUpPsZ7g@mail.gmail.com>
References: <CAMhCMoH9uZPeAE_2tWH6rf0RndqV+ypjbNzazpFwFnLUpPsZ7g@mail.gmail.com>
Message-ID: <Vbb1PZfBzm6JBddqNIfikVE2G1fDmObt0BBt2BqhmHV_Tx7KLGU5SSQPPp0OaLZHAKrkKobA2f60tX4TOl996aE9ds1tZWaGAHbSr9wu5r0=@protonmail.com>

Good morning Salvatore,

Interesting idea.

The idea to embed the current state is similar to something I have been musing about recently.


> ### Game theory (or why the chain will not see any of this)
> 
> With the right economic incentives, protocol designers can guarantee that playing a losing game always loses money compared to cooperating. Therefore, the challenge game is never expected to be played on-chain. The size of the bonds need to be appropriate to disincentivize griefing attacks.

Modulo bugs, operator error, misconfigurations, and other irrationalities of humans.



> - OP_CHECKOUTPUTCOVENANTVERIFY: given a number out_i and three 32-byte hash elements x, d and taptree on top of the stack, verifies that the out_i-th output is a P2TR output with internal key computed as above, and tweaked with taptree. This is the actual covenant opcode.

Rather than get taptree from the stack, just use the same taptree as in the revelation of the P2TR.
This removes the need to include quining and similar techniques: just do the quining in the SCRIPT interpreter.

The entire SCRIPT that controls the covenant can be defined as a taptree with various possible branches as tapleaves.
If the contract is intended to terminate at some point it can have one of the tapleaves use `OP_CHECKINPUTCOVENANTVERIFY` and then determine what the output "should" be using e.g. `OP_CHECKTEMPLATEVERIFY`.


> - Is it worth adding other introspection opcodes, for example OP_INSPECTVERSION, OP_INSPECTLOCKTIME? See Liquid's Tapscript Opcodes [6].

`OP_CHECKTEMPLATEVERIFY` and some kind of sha256 concatenated hashing should be sufficient I think.

> - Is there any malleability issue? Can covenants ?run? without signatures, or is a signature always to be expected when using spending conditions with the covenant encumbrance? That might be useful in contracts where no signature is required to proceed with the protocol (for example, any party could feed valid data to the bisection protocol above).

Hmm protocol designer beware?

Regards,
ZmnSCPxj

From pete at petertodd.org  Tue Nov  8 18:16:13 2022
From: pete at petertodd.org (Peter Todd)
Date: Tue, 8 Nov 2022 13:16:13 -0500
Subject: [bitcoin-dev] Announcement: Full-RBF Miner Bounty
In-Reply-To: <Y2I3w8O5X55sD/3C@petertodd.org>
References: <Y2I3w8O5X55sD/3C@petertodd.org>
Message-ID: <Y2qc7Ubc5xtJhxGw@petertodd.org>

On Wed, Nov 02, 2022 at 05:26:27AM -0400, Peter Todd via bitcoin-dev wrote:
> I'm now running a full-RBf bounty program for miners.
> 
> tl;dr: I'm broadcasting full-RBF replacements paying extremely high fees to
> reward miners that turn on full-RBF. I'm starting small, just ~$100/block in
> times of congestion.

FYI I've gotten a few hundred dollars worth of donations to this effort, and
have raised the reward to about 0.02 BTC, or $400 USD at current prices.

To be clear, this doesn't mean there will always be a $400 fee tx in the
full-rbf mempool. I have to take a number of precautions to avoid the
double-spend tx being mined by accident, such as only spending txouts with >2
confirmations, and waiting significant amounts of time before the 1st
transaction is sent to allow for maximal propagation.

> If you'd like to donate to this effort, send BTC to
> bc1qagmufdn6rf80kj3faw4d0pnhxyr47sevp3nj9m

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221108/b1694a06/attachment.sig>

From email at yancy.lol  Tue Nov  8 14:54:46 2022
From: email at yancy.lol (email at yancy.lol)
Date: Tue, 08 Nov 2022 15:54:46 +0100
Subject: [bitcoin-dev] On mempool policy consistency
In-Reply-To: <0A6B5781-EBC6-4D98-8AE8-43436B5F73EA@petertodd.org>
References: <16eb6a50691ccc661310051de6b8e2c0@yancy.lol>
 <0A6B5781-EBC6-4D98-8AE8-43436B5F73EA@petertodd.org>
Message-ID: <8c13eebc9baf1e347ce3327d5fc34060@yancy.lol>


Peter,

It sounds like there are two attack vectors; neither of which require 
full-rbf (correct me if I'm wrong).

1) Bob has staked liquidity in a payment channel with Alice who later 
double spends the same inputs (at a very low feerate) resulting in a 
stalemate where neither can spend the UTXOs.  The TX that creates the 
payment channel with Bob will never be mined since the mining pool sees 
the double spend?

2) Alice spams the network with a double spend wide enough that the 
double spend makes it into a block before the remainder of the network 
sees the first spend.

In that case of 1), what if Bob required a opt-in rbf?  Wouldn't that 
solve the issue?  Bob could just create a replacement transaction with 
enough fee to get back his UTXO?

For 2) it seems to me that neither full-rbf or opt-in rbf resolves this, 
although it's a probabilistic attack and requires spamming many nodes.

Cheers,
-Yancy

On 2022-11-07 15:32, Peter Todd wrote:

> On November 3, 2022 5:06:52 PM AST, yancy via bitcoin-dev
> <bitcoin-dev at lists.linuxfoundation.org> wrote:
> AJ/Antoine et al
> 
> What should folks wanting to do coinjoins/dualfunding/dlcs/etc do to
> solve that problem if they have only opt-in RBF available?
> Assuming Alice is a well funded advisory, with enough resources to spam 
> the network so that enough nodes see her malicious transaction first, 
> how does full-rbf solve this vs. opt-in rbf?

First of all, to make things clear, remember that the attacks were
talking about are aimed at _preventing_ a transaction from getting
mined. Alice wants to cheaply broadcast something with low fees that
won't get mined soon (if ever), that prevents a protocol from making
forward progress.

With full-rbf, who saw what transaction first doesn't matter: the
higher fee paying transaction will always(*) replace the lower fee
one. With opt-in RBF, spamming the network can beat out the
alternative.

*) So what's the catch? Well, due to limitations in today's mempool
implementation, sometimes we can't fully evaluate which tx pays the
higher fee. For example, if Alice spams the network with very _large_
numbers transactions spending that input, the current mempool code
doesn't even try to figure out if a replacement is better.

But those limitations are likely to be fixable. And even right now,
without fixing them, Alice still has to use a lot more money to pull
off these attacks with full-rbf. So full-rbf definitely improves the
situation even if it doesn't solve the problem completely.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221108/b618d371/attachment.html>

From erik at q32.com  Tue Nov  8 14:16:41 2022
From: erik at q32.com (Erik Aronesty)
Date: Tue, 8 Nov 2022 09:16:41 -0500
Subject: [bitcoin-dev] brickchain
In-Reply-To: <lS-eB0uZHRjuHUG6HAyn4_Ponw4ysOCkY_J4cfqBjJ1eOK3PqC0hQ6Ov3XOIofmMC9D_Za3k9Px0OZPa2ayT4dd7wXKEMR910EfrSjlAfQw=@mm-studios.com>
References: <mOBAWIbHTgkSrCJ9IEBJgArqUNYcNSDQawhUzaiYyliaPDQT_YDfI5CLoDPZgEt43mePJof-CJfxzFxgXMUe6ONDJ4j5Bzk1QGjd50S9gb8=@mm-studios.com>
 <CAJowKgKvtRXoLuA0kS5QhAVbhDi0k+3KZqfo+rBr+dbCCS2R5A@mail.gmail.com>
 <lS-eB0uZHRjuHUG6HAyn4_Ponw4ysOCkY_J4cfqBjJ1eOK3PqC0hQ6Ov3XOIofmMC9D_Za3k9Px0OZPa2ayT4dd7wXKEMR910EfrSjlAfQw=@mm-studios.com>
Message-ID: <CAJowKgK5d15hf=paL_OO5xC3GBSXmwS3xdRYS+P1-NG6Y6dO-Q@mail.gmail.com>

> A) to not increase the workload of full-nodes

yes, this is critical

>  given the competitive nature of PoW itself

validating nodes do not compete with PoW, i think maybe you are not sure of
the difference between a miner and a node

nodes do validation of transactions, they do this for free, and many of
them provide essential services, like SPV validation for mobile


B) to not undermine L2 systems like LN.

yes, as a general rule, layered financial systems are vastly superior.  so
that risks incurred by edge layers are not propagated fully to the inner
layers.  For example L3 projects like TARO and RGB are building on
lightning with less risk

On Wed, Oct 19, 2022 at 12:04 PM mm-studios <mm at mm-studios.com> wrote:

> Thanks all for your responses.
> so is it a no-go is because "reduced settlement speed is a desirable
> feature"?
>
> I don';t know what weights more in this consideration:
> A) to not increase the workload of full-nodes, being "less difficult to
> operate" and hence reduce the chance of some of them giving up which would
> lead to a negative centralization effect. (a bit cumbersome reasoning in my
> opinion, given the competitive nature of PoW itself, which introduce an
> accepted centralization, forcing some miners to give up). In this case the
> fact is accepted because is decentralized enough.
> B) to not undermine L2 systems like LN.
>
> in any case it is a major no-go reason, if there is not intention to speed
> up L1.
> Thanks
> M
> ------- Original Message -------
> On Wednesday, October 19th, 2022 at 3:24 PM, Erik Aronesty <erik at q32.com>
> wrote:
>
> > currently, a miner produce blocks with a limited capacity of
> transactions that ultimately limits the global settlement throughput to a
> reduced number of tx/s.
>
> reduced settlement speed is a desirable feature and isn't something we
> need to fix
>
> the focus should be on layer 2 protocols that allow the ability to hold &
> transfer, uncommitted transactions as pools / joins, so that layer 1's
> decentralization and incentives can remain undisturbed
>
> protocols like mweb, for example
>
>
>
>
> On Wed, Oct 19, 2022 at 7:34 AM mm-studios via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
>> Hi Bitcoin devs,
>> I'd like to share an idea of a method to increase throughput in the
>> bitcoin network.
>>
>> Currently, a miner produce blocks with a limited capacity of transactions
>> that ultimately limits the global settlement throughput to a reduced number
>> of tx/s.
>>
>> Big-blockers proposed the removal of limits but this didn't come with
>> undesirable effects that have been widely discussed and rejected.
>>
>> The main feature we wanted to preserve is 'small blocks', providing
>> 'better network effects' I won't focus on them.
>>
>> The problem with small blocks is that, once a block is filled
>> transactions, they are kept back in the mempool, waiting for their turn in
>> future blocks.
>>
>> The following changes in the protocol aim to let all transactions go in
>> the current block, while keeping the block size small. It requires changes
>> in the PoW algorithm.
>>
>> Currently, the PoW algorithm consists on finding a valid hash for the
>> block. Its validity is determined by comparing the numeric value of the
>> block hash with a protocol-defined value difficulty.
>>
>> Once a miner finds a nonce for the block that satisfies the condition the
>> new block becomes valid and can be propagated. All nodes would update their
>> blockchains with it. (assuming no conflict resolution (orphan blocks, ...)
>> for clarity).
>>
>> This process is meant to happen every 10 minutes in average.
>>
>> With this background information (we all already know) I go on to
>> describe the idea:
>>
>> Let's allow a miner to include transactions until the block is filled,
>> let's call this structure (coining a new term 'Brick'), B0. [brick=block
>> that doesn't meet the difficulty rule and is filled of tx to its full
>> capacity]
>> Since PoW hashing is continuously active, Brick B0 would have a nonce
>> corresponding to a minimum numeric value of its hash found until it got
>> filled.
>>
>> Fully filled brick B0, with a hash that doesn't meet the difficulty rule,
>> would be broadcasted and nodes would have it on in a separate fork as usual.
>>
>> At this point, instead of discarding transactions, our miner would start
>> working on a new brick B1, linked with B0 as usual.
>>
>> Nodes would allow incoming regular blocks and bricks with hashes that
>> don't satisfy the difficulty rule, provided the brick is fully filled of
>> transactions. Bricks not fully filled would be rejected as invalid to
>> prevent spam (except if constitutes the last brick of a brickchain,
>> explained below).
>>
>> Let's assume that 10 minutes have elapsed and our miner is in a state
>> where N bricks have been produced and the accumulated PoW calculated using
>> mathematics (every brick contains a 'minimum hash found', when a series of
>> 'minimum hashes' is computationally equivalent to the network difficulty is
>> then the full 'brickchain' is valid as a Block.
>>
>> This calculus shall be better defined, but I hope that this idea can
>> serve as a seed to a BIP, or otherwise deemed absurd, which might be
>> possible and I'd be delighted to discover why a scheme like this wouldn't
>> work.
>>
>> If it finally worked, it could completely flush mempools, keep
>> transactions fees low and increase throughput without an increase in the
>> block size that would raise other concerns related to propagation.
>>
>> Thank you.
>> I look forward to your responses.
>>
>> --
>> Marcos Mayorga
>> https://twitter.com/KatlasC
>>
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221108/e572675c/attachment-0001.html>

From mm at mm-studios.com  Tue Nov  8 14:25:04 2022
From: mm at mm-studios.com (mm-studios)
Date: Tue, 08 Nov 2022 14:25:04 +0000
Subject: [bitcoin-dev] brickchain
In-Reply-To: <CAJowKgK5d15hf=paL_OO5xC3GBSXmwS3xdRYS+P1-NG6Y6dO-Q@mail.gmail.com>
References: <mOBAWIbHTgkSrCJ9IEBJgArqUNYcNSDQawhUzaiYyliaPDQT_YDfI5CLoDPZgEt43mePJof-CJfxzFxgXMUe6ONDJ4j5Bzk1QGjd50S9gb8=@mm-studios.com>
 <CAJowKgKvtRXoLuA0kS5QhAVbhDi0k+3KZqfo+rBr+dbCCS2R5A@mail.gmail.com>
 <lS-eB0uZHRjuHUG6HAyn4_Ponw4ysOCkY_J4cfqBjJ1eOK3PqC0hQ6Ov3XOIofmMC9D_Za3k9Px0OZPa2ayT4dd7wXKEMR910EfrSjlAfQw=@mm-studios.com>
 <CAJowKgK5d15hf=paL_OO5xC3GBSXmwS3xdRYS+P1-NG6Y6dO-Q@mail.gmail.com>
Message-ID: <ox3E7bDtY6c4XIvQ5likp9j8Dk8CQlIEoGoSiCTRr3SE4B6udch2adfEnglM0mpCsVRF1hQAZERmzo-bq5fkafcvMvLqmK2O1E4IOiqwjog=@mm-studios.com>

------- Original Message -------
On Tuesday, November 8th, 2022 at 2:16 PM, Erik Aronesty <erik at q32.com> wrote:

>> A) to not increase the workload of full-nodes
>
> yes, this is critical
>
>> given the competitive nature of PoW itself
>
> validating nodes do not compete with PoW, i think maybe you are not sure of the difference between a miner and a node
>
> nodes do validation of transactions, they do this for free, and many of them provide essential services, like SPV validation for mobile

I think it's pretty clear that the "competitive nature of PoW" is not referring to verification nodes (satoshi preferred this other word).

> B) to not undermine L2 systems like LN.
>
> yes, as a general rule, layered financial systems are vastly superior. so that risks incurred by edge layers are not propagated fully to the inner layers. For example L3 projects like TARO and RGB are building on lightning with less risk

layers also add fees to users

> On Wed, Oct 19, 2022 at 12:04 PM mm-studios <mm at mm-studios.com> wrote:
>
>> Thanks all for your responses.
>> so is it a no-go is because "reduced settlement speed is a desirable feature"?
>>
>> I don';t know what weights more in this consideration:
>> A) to not increase the workload of full-nodes, being "less difficult to operate" and hence reduce the chance of some of them giving up which would lead to a negative centralization effect. (a bit cumbersome reasoning in my opinion, given the competitive nature of PoW itself, which introduce an accepted centralization, forcing some miners to give up). In this case the fact is accepted because is decentralized enough.
>> B) to not undermine L2 systems like LN.
>>
>> in any case it is a major no-go reason, if there is not intention to speed up L1.
>> Thanks
>> M
>>
>> ------- Original Message -------
>> On Wednesday, October 19th, 2022 at 3:24 PM, Erik Aronesty <erik at q32.com> wrote:
>>
>>>> currently, a miner produce blocks with a limited capacity of transactions that ultimately limits the global settlement throughput to a reduced number of tx/s.
>>>
>>> reduced settlement speed is a desirable feature and isn't something we need to fix
>>>
>>> the focus should be on layer 2 protocols that allow the ability to hold & transfer, uncommitted transactions as pools / joins, so that layer 1's decentralization and incentives can remain undisturbed
>>>
>>> protocols like mweb, for example
>>>
>>> On Wed, Oct 19, 2022 at 7:34 AM mm-studios via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
>>>
>>>> Hi Bitcoin devs,
>>>> I'd like to share an idea of a method to increase throughput in the bitcoin network.
>>>>
>>>> Currently, a miner produce blocks with a limited capacity of transactions that ultimately limits the global settlement throughput to a reduced number of tx/s.
>>>>
>>>> Big-blockers proposed the removal of limits but this didn't come with undesirable effects that have been widely discussed and rejected.
>>>>
>>>> The main feature we wanted to preserve is 'small blocks', providing 'better network effects' I won't focus on them.
>>>>
>>>> The problem with small blocks is that, once a block is filled transactions, they are kept back in the mempool, waiting for their turn in future blocks.
>>>>
>>>> The following changes in the protocol aim to let all transactions go in the current block, while keeping the block size small. It requires changes in the PoW algorithm.
>>>>
>>>> Currently, the PoW algorithm consists on finding a valid hash for the block. Its validity is determined by comparing the numeric value of the block hash with a protocol-defined value difficulty.
>>>>
>>>> Once a miner finds a nonce for the block that satisfies the condition the new block becomes valid and can be propagated. All nodes would update their blockchains with it. (assuming no conflict resolution (orphan blocks, ...) for clarity).
>>>>
>>>> This process is meant to happen every 10 minutes in average.
>>>>
>>>> With this background information (we all already know) I go on to describe the idea:
>>>>
>>>> Let's allow a miner to include transactions until the block is filled, let's call this structure (coining a new term 'Brick'), B0. [brick=block that doesn't meet the difficulty rule and is filled of tx to its full capacity]
>>>> Since PoW hashing is continuously active, Brick B0 would have a nonce corresponding to a minimum numeric value of its hash found until it got filled.
>>>>
>>>> Fully filled brick B0, with a hash that doesn't meet the difficulty rule, would be broadcasted and nodes would have it on in a separate fork as usual.
>>>>
>>>> At this point, instead of discarding transactions, our miner would start working on a new brick B1, linked with B0 as usual.
>>>>
>>>> Nodes would allow incoming regular blocks and bricks with hashes that don't satisfy the difficulty rule, provided the brick is fully filled of transactions. Bricks not fully filled would be rejected as invalid to prevent spam (except if constitutes the last brick of a brickchain, explained below).
>>>>
>>>> Let's assume that 10 minutes have elapsed and our miner is in a state where N bricks have been produced and the accumulated PoW calculated using mathematics (every brick contains a 'minimum hash found', when a series of 'minimum hashes' is computationally equivalent to the network difficulty is then the full 'brickchain' is valid as a Block.
>>>>
>>>> This calculus shall be better defined, but I hope that this idea can serve as a seed to a BIP, or otherwise deemed absurd, which might be possible and I'd be delighted to discover why a scheme like this wouldn't work.
>>>>
>>>> If it finally worked, it could completely flush mempools, keep transactions fees low and increase throughput without an increase in the block size that would raise other concerns related to propagation.
>>>>
>>>> Thank you.
>>>> I look forward to your responses.
>>>>
>>>> --
>>>> Marcos Mayorgahttps://twitter.com/KatlasC
>>>>
>>>> _______________________________________________
>>>> bitcoin-dev mailing list
>>>> bitcoin-dev at lists.linuxfoundation.org
>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221108/d5ac4343/attachment-0001.html>

From erik at q32.com  Tue Nov  8 15:49:10 2022
From: erik at q32.com (Erik Aronesty)
Date: Tue, 8 Nov 2022 10:49:10 -0500
Subject: [bitcoin-dev] brickchain
In-Reply-To: <ox3E7bDtY6c4XIvQ5likp9j8Dk8CQlIEoGoSiCTRr3SE4B6udch2adfEnglM0mpCsVRF1hQAZERmzo-bq5fkafcvMvLqmK2O1E4IOiqwjog=@mm-studios.com>
References: <mOBAWIbHTgkSrCJ9IEBJgArqUNYcNSDQawhUzaiYyliaPDQT_YDfI5CLoDPZgEt43mePJof-CJfxzFxgXMUe6ONDJ4j5Bzk1QGjd50S9gb8=@mm-studios.com>
 <CAJowKgKvtRXoLuA0kS5QhAVbhDi0k+3KZqfo+rBr+dbCCS2R5A@mail.gmail.com>
 <lS-eB0uZHRjuHUG6HAyn4_Ponw4ysOCkY_J4cfqBjJ1eOK3PqC0hQ6Ov3XOIofmMC9D_Za3k9Px0OZPa2ayT4dd7wXKEMR910EfrSjlAfQw=@mm-studios.com>
 <CAJowKgK5d15hf=paL_OO5xC3GBSXmwS3xdRYS+P1-NG6Y6dO-Q@mail.gmail.com>
 <ox3E7bDtY6c4XIvQ5likp9j8Dk8CQlIEoGoSiCTRr3SE4B6udch2adfEnglM0mpCsVRF1hQAZERmzo-bq5fkafcvMvLqmK2O1E4IOiqwjog=@mm-studios.com>
Message-ID: <CAJowKg+2GaD+kMGMttcU8AXs+uJbg5bPMv7wuXQx91hLCDyYgw@mail.gmail.com>

> I think it's pretty clear that the "competitive nature of PoW" is not
referring to verification nodes

cool, so we can agree there is no accepted centralization pressure for
validating nodes then

> layers also add fees to users

source?  i feel like it's obvious that the tree-like efficiencies should
reduce fees, but i'd appreciate your research on that topic


On Tue, Nov 8, 2022 at 9:25 AM mm-studios <mm at mm-studios.com> wrote:

>
> ------- Original Message -------
> On Tuesday, November 8th, 2022 at 2:16 PM, Erik Aronesty <erik at q32.com>
> wrote:
>
> > A) to not increase the workload of full-nodes
>
> yes, this is critical
>
> > given the competitive nature of PoW itself
>
> validating nodes do not compete with PoW, i think maybe you are not sure
> of the difference between a miner and a node
>
> nodes do validation of transactions, they do this for free, and many of
> them provide essential services, like SPV validation for mobile
>
>
>
> I think it's pretty clear that the "competitive nature of PoW" is not
> referring to verification nodes (satoshi preferred this other word).
>
> B) to not undermine L2 systems like LN.
>
> yes, as a general rule, layered financial systems are vastly superior. so
> that risks incurred by edge layers are not propagated fully to the inner
> layers. For example L3 projects like TARO and RGB are building on lightning
> with less risk
>
>
> layers also add fees to users
>
>
> On Wed, Oct 19, 2022 at 12:04 PM mm-studios <mm at mm-studios.com> wrote:
>
>> Thanks all for your responses.
>> so is it a no-go is because "reduced settlement speed is a desirable
>> feature"?
>>
>> I don';t know what weights more in this consideration:
>> A) to not increase the workload of full-nodes, being "less difficult to
>> operate" and hence reduce the chance of some of them giving up which would
>> lead to a negative centralization effect. (a bit cumbersome reasoning in my
>> opinion, given the competitive nature of PoW itself, which introduce an
>> accepted centralization, forcing some miners to give up). In this case the
>> fact is accepted because is decentralized enough.
>> B) to not undermine L2 systems like LN.
>>
>> in any case it is a major no-go reason, if there is not intention to
>> speed up L1.
>> Thanks
>> M
>> ------- Original Message -------
>> On Wednesday, October 19th, 2022 at 3:24 PM, Erik Aronesty <erik at q32.com>
>> wrote:
>>
>> > currently, a miner produce blocks with a limited capacity of
>> transactions that ultimately limits the global settlement throughput to a
>> reduced number of tx/s.
>>
>> reduced settlement speed is a desirable feature and isn't something we
>> need to fix
>>
>> the focus should be on layer 2 protocols that allow the ability to hold &
>> transfer, uncommitted transactions as pools / joins, so that layer 1's
>> decentralization and incentives can remain undisturbed
>>
>> protocols like mweb, for example
>>
>>
>>
>>
>> On Wed, Oct 19, 2022 at 7:34 AM mm-studios via bitcoin-dev <
>> bitcoin-dev at lists.linuxfoundation.org> wrote:
>>
>>> Hi Bitcoin devs,
>>> I'd like to share an idea of a method to increase throughput in the
>>> bitcoin network.
>>>
>>> Currently, a miner produce blocks with a limited capacity of
>>> transactions that ultimately limits the global settlement throughput to a
>>> reduced number of tx/s.
>>>
>>> Big-blockers proposed the removal of limits but this didn't come with
>>> undesirable effects that have been widely discussed and rejected.
>>>
>>> The main feature we wanted to preserve is 'small blocks', providing
>>> 'better network effects' I won't focus on them.
>>>
>>> The problem with small blocks is that, once a block is filled
>>> transactions, they are kept back in the mempool, waiting for their turn in
>>> future blocks.
>>>
>>> The following changes in the protocol aim to let all transactions go in
>>> the current block, while keeping the block size small. It requires changes
>>> in the PoW algorithm.
>>>
>>> Currently, the PoW algorithm consists on finding a valid hash for the
>>> block. Its validity is determined by comparing the numeric value of the
>>> block hash with a protocol-defined value difficulty.
>>>
>>> Once a miner finds a nonce for the block that satisfies the condition
>>> the new block becomes valid and can be propagated. All nodes would update
>>> their blockchains with it. (assuming no conflict resolution (orphan blocks,
>>> ...) for clarity).
>>>
>>> This process is meant to happen every 10 minutes in average.
>>>
>>> With this background information (we all already know) I go on to
>>> describe the idea:
>>>
>>> Let's allow a miner to include transactions until the block is filled,
>>> let's call this structure (coining a new term 'Brick'), B0. [brick=block
>>> that doesn't meet the difficulty rule and is filled of tx to its full
>>> capacity]
>>> Since PoW hashing is continuously active, Brick B0 would have a nonce
>>> corresponding to a minimum numeric value of its hash found until it got
>>> filled.
>>>
>>> Fully filled brick B0, with a hash that doesn't meet the difficulty
>>> rule, would be broadcasted and nodes would have it on in a separate fork as
>>> usual.
>>>
>>> At this point, instead of discarding transactions, our miner would start
>>> working on a new brick B1, linked with B0 as usual.
>>>
>>> Nodes would allow incoming regular blocks and bricks with hashes that
>>> don't satisfy the difficulty rule, provided the brick is fully filled of
>>> transactions. Bricks not fully filled would be rejected as invalid to
>>> prevent spam (except if constitutes the last brick of a brickchain,
>>> explained below).
>>>
>>> Let's assume that 10 minutes have elapsed and our miner is in a state
>>> where N bricks have been produced and the accumulated PoW calculated using
>>> mathematics (every brick contains a 'minimum hash found', when a series of
>>> 'minimum hashes' is computationally equivalent to the network difficulty is
>>> then the full 'brickchain' is valid as a Block.
>>>
>>> This calculus shall be better defined, but I hope that this idea can
>>> serve as a seed to a BIP, or otherwise deemed absurd, which might be
>>> possible and I'd be delighted to discover why a scheme like this wouldn't
>>> work.
>>>
>>> If it finally worked, it could completely flush mempools, keep
>>> transactions fees low and increase throughput without an increase in the
>>> block size that would raise other concerns related to propagation.
>>>
>>> Thank you.
>>> I look forward to your responses.
>>>
>>> --
>>> Marcos Mayorga
>>> https://twitter.com/KatlasC
>>>
>>> _______________________________________________
>>> bitcoin-dev mailing list
>>> bitcoin-dev at lists.linuxfoundation.org
>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221108/a734558f/attachment-0001.html>

From mm at mm-studios.com  Tue Nov  8 16:31:15 2022
From: mm at mm-studios.com (mm-studios)
Date: Tue, 08 Nov 2022 16:31:15 +0000
Subject: [bitcoin-dev] brickchain
In-Reply-To: <CAJowKg+2GaD+kMGMttcU8AXs+uJbg5bPMv7wuXQx91hLCDyYgw@mail.gmail.com>
References: <mOBAWIbHTgkSrCJ9IEBJgArqUNYcNSDQawhUzaiYyliaPDQT_YDfI5CLoDPZgEt43mePJof-CJfxzFxgXMUe6ONDJ4j5Bzk1QGjd50S9gb8=@mm-studios.com>
 <CAJowKgKvtRXoLuA0kS5QhAVbhDi0k+3KZqfo+rBr+dbCCS2R5A@mail.gmail.com>
 <lS-eB0uZHRjuHUG6HAyn4_Ponw4ysOCkY_J4cfqBjJ1eOK3PqC0hQ6Ov3XOIofmMC9D_Za3k9Px0OZPa2ayT4dd7wXKEMR910EfrSjlAfQw=@mm-studios.com>
 <CAJowKgK5d15hf=paL_OO5xC3GBSXmwS3xdRYS+P1-NG6Y6dO-Q@mail.gmail.com>
 <ox3E7bDtY6c4XIvQ5likp9j8Dk8CQlIEoGoSiCTRr3SE4B6udch2adfEnglM0mpCsVRF1hQAZERmzo-bq5fkafcvMvLqmK2O1E4IOiqwjog=@mm-studios.com>
 <CAJowKg+2GaD+kMGMttcU8AXs+uJbg5bPMv7wuXQx91hLCDyYgw@mail.gmail.com>
Message-ID: <TaODpd3EHDCx1Ux0cS1AcHj8KIFbMNNYQmGQkof5AU_xWHJY8QYr1b2CR5iJo696lfjw7uPcjZziyAVD1YfBgP9yQYz7__8ytq2EtEhYziQ=@mm-studios.com>

------- Original Message -------
On Tuesday, November 8th, 2022 at 3:49 PM, Erik Aronesty <erik at q32.com> wrote:

>> I think it's pretty clear that the "competitive nature of PoW" is not referring to verification nodes
>
> cool, so we can agree there is no accepted centralization pressure for validating nodes then

The centralization produced by PoW only affects miners. the rest of nodes are freely distributed.
in the producer-consumer view consumers (blockchain builders) are satisfactorily distributed. It can't be said so about miners(block producers), who form a quite centralized subsystem with only a handful major pools producing blocks.

>> layers also add fees to users
>
> source? i feel like it's obvious that the tree-like efficiencies should reduce fees, but i'd appreciate your research on that topic

systems(layers) where abuse is controlled by fees add up each one a cost.

> On Tue, Nov 8, 2022 at 9:25 AM mm-studios <mm at mm-studios.com> wrote:
>
>> ------- Original Message -------
>> On Tuesday, November 8th, 2022 at 2:16 PM, Erik Aronesty <erik at q32.com> wrote:
>>
>>>> A) to not increase the workload of full-nodes
>>>
>>> yes, this is critical
>>>
>>>> given the competitive nature of PoW itself
>>>
>>> validating nodes do not compete with PoW, i think maybe you are not sure of the difference between a miner and a node
>>>
>>> nodes do validation of transactions, they do this for free, and many of them provide essential services, like SPV validation for mobile
>>
>> I think it's pretty clear that the "competitive nature of PoW" is not referring to verification nodes (satoshi preferred this other word).
>>
>>> B) to not undermine L2 systems like LN.
>>>
>>> yes, as a general rule, layered financial systems are vastly superior. so that risks incurred by edge layers are not propagated fully to the inner layers. For example L3 projects like TARO and RGB are building on lightning with less risk
>>
>> layers also add fees to users
>>
>>> On Wed, Oct 19, 2022 at 12:04 PM mm-studios <mm at mm-studios.com> wrote:
>>>
>>>> Thanks all for your responses.
>>>> so is it a no-go is because "reduced settlement speed is a desirable feature"?
>>>>
>>>> I don';t know what weights more in this consideration:
>>>> A) to not increase the workload of full-nodes, being "less difficult to operate" and hence reduce the chance of some of them giving up which would lead to a negative centralization effect. (a bit cumbersome reasoning in my opinion, given the competitive nature of PoW itself, which introduce an accepted centralization, forcing some miners to give up). In this case the fact is accepted because is decentralized enough.
>>>> B) to not undermine L2 systems like LN.
>>>>
>>>> in any case it is a major no-go reason, if there is not intention to speed up L1.
>>>> Thanks
>>>> M
>>>>
>>>> ------- Original Message -------
>>>> On Wednesday, October 19th, 2022 at 3:24 PM, Erik Aronesty <erik at q32.com> wrote:
>>>>
>>>>>> currently, a miner produce blocks with a limited capacity of transactions that ultimately limits the global settlement throughput to a reduced number of tx/s.
>>>>>
>>>>> reduced settlement speed is a desirable feature and isn't something we need to fix
>>>>>
>>>>> the focus should be on layer 2 protocols that allow the ability to hold & transfer, uncommitted transactions as pools / joins, so that layer 1's decentralization and incentives can remain undisturbed
>>>>>
>>>>> protocols like mweb, for example
>>>>>
>>>>> On Wed, Oct 19, 2022 at 7:34 AM mm-studios via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
>>>>>
>>>>>> Hi Bitcoin devs,
>>>>>> I'd like to share an idea of a method to increase throughput in the bitcoin network.
>>>>>>
>>>>>> Currently, a miner produce blocks with a limited capacity of transactions that ultimately limits the global settlement throughput to a reduced number of tx/s.
>>>>>>
>>>>>> Big-blockers proposed the removal of limits but this didn't come with undesirable effects that have been widely discussed and rejected.
>>>>>>
>>>>>> The main feature we wanted to preserve is 'small blocks', providing 'better network effects' I won't focus on them.
>>>>>>
>>>>>> The problem with small blocks is that, once a block is filled transactions, they are kept back in the mempool, waiting for their turn in future blocks.
>>>>>>
>>>>>> The following changes in the protocol aim to let all transactions go in the current block, while keeping the block size small. It requires changes in the PoW algorithm.
>>>>>>
>>>>>> Currently, the PoW algorithm consists on finding a valid hash for the block. Its validity is determined by comparing the numeric value of the block hash with a protocol-defined value difficulty.
>>>>>>
>>>>>> Once a miner finds a nonce for the block that satisfies the condition the new block becomes valid and can be propagated. All nodes would update their blockchains with it. (assuming no conflict resolution (orphan blocks, ...) for clarity).
>>>>>>
>>>>>> This process is meant to happen every 10 minutes in average.
>>>>>>
>>>>>> With this background information (we all already know) I go on to describe the idea:
>>>>>>
>>>>>> Let's allow a miner to include transactions until the block is filled, let's call this structure (coining a new term 'Brick'), B0. [brick=block that doesn't meet the difficulty rule and is filled of tx to its full capacity]
>>>>>> Since PoW hashing is continuously active, Brick B0 would have a nonce corresponding to a minimum numeric value of its hash found until it got filled.
>>>>>>
>>>>>> Fully filled brick B0, with a hash that doesn't meet the difficulty rule, would be broadcasted and nodes would have it on in a separate fork as usual.
>>>>>>
>>>>>> At this point, instead of discarding transactions, our miner would start working on a new brick B1, linked with B0 as usual.
>>>>>>
>>>>>> Nodes would allow incoming regular blocks and bricks with hashes that don't satisfy the difficulty rule, provided the brick is fully filled of transactions. Bricks not fully filled would be rejected as invalid to prevent spam (except if constitutes the last brick of a brickchain, explained below).
>>>>>>
>>>>>> Let's assume that 10 minutes have elapsed and our miner is in a state where N bricks have been produced and the accumulated PoW calculated using mathematics (every brick contains a 'minimum hash found', when a series of 'minimum hashes' is computationally equivalent to the network difficulty is then the full 'brickchain' is valid as a Block.
>>>>>>
>>>>>> This calculus shall be better defined, but I hope that this idea can serve as a seed to a BIP, or otherwise deemed absurd, which might be possible and I'd be delighted to discover why a scheme like this wouldn't work.
>>>>>>
>>>>>> If it finally worked, it could completely flush mempools, keep transactions fees low and increase throughput without an increase in the block size that would raise other concerns related to propagation.
>>>>>>
>>>>>> Thank you.
>>>>>> I look forward to your responses.
>>>>>>
>>>>>> --
>>>>>> Marcos Mayorgahttps://twitter.com/KatlasC
>>>>>>
>>>>>> _______________________________________________
>>>>>> bitcoin-dev mailing list
>>>>>> bitcoin-dev at lists.linuxfoundation.org
>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221108/5a5a7222/attachment-0001.html>

From bram at chia.net  Tue Nov  8 23:34:32 2022
From: bram at chia.net (Bram Cohen)
Date: Tue, 8 Nov 2022 15:34:32 -0800
Subject: [bitcoin-dev] Merkleize All The Things
In-Reply-To: <CAMhCMoH9uZPeAE_2tWH6rf0RndqV+ypjbNzazpFwFnLUpPsZ7g@mail.gmail.com>
References: <CAMhCMoH9uZPeAE_2tWH6rf0RndqV+ypjbNzazpFwFnLUpPsZ7g@mail.gmail.com>
Message-ID: <CAHUJnBA7PUy3ajygdvvBwg6EyhUXGA-KKL_bkXLKCRPS98kRqw@mail.gmail.com>

On Tue, Nov 8, 2022 at 2:13 AM Salvatore Ingala via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> wrote:

>
> I have been working on some notes to describe an approach that uses
> covenants in order to enable general smart contracts in bitcoin. You can
> find them here:
>
>     https://merkle.fun/
> <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>
>

Hash chained covenants in general all have about the same plateau of
functionality, which seems roughly reasonable to add to Bitcoin as it is
today but suffer from being limited and hence likely only a stepping stone
to greater functionality and unless whatever's put in now cleanly extends
to supporting more in the future it's likely to turn into a legacy
appendage which has to be supported. So my generic suggestion for this sort
of thing is that it should be proposed along with a plan for how it could
be extended to support full-blown covenants in the future.

Another probably unhelpful bit of feedback I have is that Bitcoin should
probably be taking verkle trees seriously because those can have
substantially lower size/cost/weight than merkle trees. That doesn't just
apply to this proposal, but to Bitcoin in general, which doesn't seem to
have any serious verkle tree proposals to date.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221108/783dabea/attachment.html>

From pete at petertodd.org  Wed Nov  9 12:07:33 2022
From: pete at petertodd.org (Peter Todd)
Date: Wed, 9 Nov 2022 07:07:33 -0500
Subject: [bitcoin-dev] Merkleize All The Things
In-Reply-To: <CAHUJnBA7PUy3ajygdvvBwg6EyhUXGA-KKL_bkXLKCRPS98kRqw@mail.gmail.com>
References: <CAMhCMoH9uZPeAE_2tWH6rf0RndqV+ypjbNzazpFwFnLUpPsZ7g@mail.gmail.com>
 <CAHUJnBA7PUy3ajygdvvBwg6EyhUXGA-KKL_bkXLKCRPS98kRqw@mail.gmail.com>
Message-ID: <Y2uYBYtz1tWLyGQY@petertodd.org>

On Tue, Nov 08, 2022 at 03:34:32PM -0800, Bram Cohen via bitcoin-dev wrote:
> Another probably unhelpful bit of feedback I have is that Bitcoin should
> probably be taking verkle trees seriously because those can have
> substantially lower size/cost/weight than merkle trees. That doesn't just
> apply to this proposal, but to Bitcoin in general, which doesn't seem to
> have any serious verkle tree proposals to date.

Verkle trees only reduce proof sizes by a factor of 6-8, and they introduce
significant implementation complexity and new cryptographic assumptions. Better
to let other crypto-systems get a few more years of experience with them before
adding them to Bitcoin. Particularly since even having merkle trees in Bitcoin
is arguably a mistake: they allow for degenerate, weak, security modes like SPV
that aren't clearly good for Bitcoin as a whole.

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221109/affdcd02/attachment.sig>

From pete at petertodd.org  Wed Nov  9 12:41:30 2022
From: pete at petertodd.org (Peter Todd)
Date: Wed, 9 Nov 2022 07:41:30 -0500
Subject: [bitcoin-dev] Using Full-RBF to fix BIP-125 Rule #3 Pinning
 with nLockTime
In-Reply-To: <CALZpt+GgH7B-sSWndNfrMp8qza=LmZQ6BWGGFjFxcutat7Nxww@mail.gmail.com>
References: <Y2ln2fJ+8+Q0qS0E@petertodd.org> <Y2l1/qXHxyctU9ir@petertodd.org>
 <CALZpt+GgH7B-sSWndNfrMp8qza=LmZQ6BWGGFjFxcutat7Nxww@mail.gmail.com>
Message-ID: <Y2uf+hRBdLxOl6LT@petertodd.org>

On Mon, Nov 07, 2022 at 05:55:59PM -0500, Antoine Riard wrote:
> Hi Peter,
> 
> > We can ensure with high probability that the transaction can be cancelled/mined
> > at some point after N blocks by pre-signing a transaction, with nLockTime set
> > sufficiently far into the future, spending one or more inputs of the
> > transaction with a sufficiently high fee that it would replace transaction(s)
> > attempting to exploit Rule #3 pinning (note how the package limits in Bitcoin
> > Core help here).
> 
> From my understanding, there are many open questions to such a
> pre-signed high-fee solution aiming to address Rule #3 pinning.
> Determining the high-fee to guarantee replacements with high odds. I
> think it should be superior to current top network mempools sat/vb *
> MAX_STANDARD_TX_WEIGHT, otherwise an adversary can pin the multi-party
> funded transaction on the ground of Core's
> replacement rule ("The replacement transaction's feerate is greater
> than the feerates of all directly conflicting transactions''). Though
> note the difficulty, the sat/vb is an unknown fact at time of
> signatures exchange among the multi-party funded transaction
> participants. Solving this issue probably requires from then to
> overshoot, and adopt a historical worst-case mempool feerate.

First of all, since this is a punishment scenario, overshooting in general is a
good thing provided that the bad actor is the one paying for the overshoot.

I may be mistaken on this point. But IIRC rule #6, "The replacement
transaction's feerate is greater than the feerates of all directly conflicting
transactions.", refers to the overall package feerate including all
transactions that would need to be mined.

This is relevant as we have two scenarios for pinning that could try to exploit
rule #6 while pinning, and neither works:

1) A large, low fee rate, transaction is spent by a high fee rate transaction.
In this case the package fee rate of the second tx is still low, because the
low fee rate tx would need to be mined first.

2) A small, high fee rate tx, is spent by a large low fee rate tx. In this case
the second low fee rate tx is irrelevant, because the high fee rate tx will get
mined soon, breaking the pin and costing the attacker money.


Now, if my understanding of rule #6 is incorrect, obviously we should fix that!
It's incentive incompatible to reject a high fee rate replacement that overall
pays more in fees (rule #3), on the basis that we expect a *different* miner to
mine the low fee rate tx it spends. Because unless we're expecting the
transaction to somehow get mined by someone else in the near future, why aren't
we mining what pays more money now?

> This "historically-worst" sat/vb introduces two new issues, first I
> think this is an economic lower bound on the funds that can be staked
> in the collaborative transaction. Second I believe this constitutes a
> griefing vector, where a participant could deliberately pin to inflict
> an asymmetric damage, without entering into any fee competition. This
> griefing vector could be leveraged as hard as being triggered by a
> miner-as-participant in so-called miner harvesting attacks.
> 
> Further, I think this solution relying on nLocktime doesn't solve the
> timevalue DoS inflicted to the participants UTXOs, until the
> pre-signed high-fee transaction is final. If participants prefer to
> save the timevalue of their contributed UTXOs over operation success,
> a better approach could be for them to unilaterally spend after a
> protocol/implementation timepoint (e.g LN's funding timeout recovery
> mechanism).
> 
> A more workable solution I believe could be simply to rely on
> package-relay, an ephemeral anchor output, and a special replacement
> regime (e.g nVersion=3) to allow the multi-party funded transaction
> coordinator to unilateral fee-bump, in a step-by-step approach. I.e
> without making assumptions on the knowledge of network mempools and
> burning directly the worst amount in fees.

Note that if you are considering miner harvesting attacks as part of the threat
model, it's not clear to me that the v3 rules that depend on miners arbitrarily
rejecting transactions from their mempools are actually sufficiently incentive
compatible to work.

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221109/48373bb3/attachment.sig>

From email at yancy.lol  Wed Nov  9 12:05:16 2022
From: email at yancy.lol (email at yancy.lol)
Date: Wed, 09 Nov 2022 13:05:16 +0100
Subject: [bitcoin-dev] On mempool policy consistency
In-Reply-To: <8c13eebc9baf1e347ce3327d5fc34060@yancy.lol>
References: <16eb6a50691ccc661310051de6b8e2c0@yancy.lol>
 <0A6B5781-EBC6-4D98-8AE8-43436B5F73EA@petertodd.org>
 <8c13eebc9baf1e347ce3327d5fc34060@yancy.lol>
Message-ID: <3ac1efdd9b332410887574f449aa6711@yancy.lol>



> Bob has staked liquidity in a payment channel with Alice who later
> double spends the same inputs (at a very low feerate) resulting in a
> stalemate where neither can spend the UTXOs.

I just realized I made a mistake.  RBF will always mine the higher fee 
transaction, so in this case, full-rbf would prevent a transaction from 
being pinned.

On 2022-11-08 15:54, yancy via bitcoin-dev wrote:

> Peter,
> 
> It sounds like there are two attack vectors; neither of which require
> full-rbf (correct me if I'm wrong).
> 
> 1) Bob has staked liquidity in a payment channel with Alice who later
> double spends the same inputs (at a very low feerate) resulting in a
> stalemate where neither can spend the UTXOs.  The TX that creates the
> payment channel with Bob will never be mined since the mining pool
> sees the double spend?
> 
> 2) Alice spams the network with a double spend wide enough that the
> double spend makes it into a block before the remainder of the network
> sees the first spend.
> 
> In that case of 1), what if Bob required a opt-in rbf?  Wouldn't that
> solve the issue?  Bob could just create a replacement transaction with
> enough fee to get back his UTXO?
> 
> For 2) it seems to me that neither full-rbf or opt-in rbf resolves
> this, although it's a probabilistic attack and requires spamming many
> nodes.
> 
> Cheers,
> -Yancy
> 
> On 2022-11-07 15:32, Peter Todd wrote:
> 
>> On November 3, 2022 5:06:52 PM AST, yancy via bitcoin-dev
>> <bitcoin-dev at lists.linuxfoundation.org> wrote:
>> AJ/Antoine et al
>> 
>> What should folks wanting to do coinjoins/dualfunding/dlcs/etc do to
>> solve that problem if they have only opt-in RBF available?
>> Assuming Alice is a well funded advisory, with enough resources to
>> spam the network so that enough nodes see her malicious transaction
>> first, how does full-rbf solve this vs. opt-in rbf?
> 
> First of all, to make things clear, remember that the attacks were
> talking about are aimed at _preventing_ a transaction from getting
> mined. Alice wants to cheaply broadcast something with low fees that
> won't get mined soon (if ever), that prevents a protocol from making
> forward progress.
> 
> With full-rbf, who saw what transaction first doesn't matter: the
> higher fee paying transaction will always(*) replace the lower fee
> one. With opt-in RBF, spamming the network can beat out the
> alternative.
> 
> *) So what's the catch? Well, due to limitations in today's mempool
> implementation, sometimes we can't fully evaluate which tx pays the
> higher fee. For example, if Alice spams the network with very _large_
> numbers transactions spending that input, the current mempool code
> doesn't even try to figure out if a replacement is better.
> 
> But those limitations are likely to be fixable. And even right now,
> without fixing them, Alice still has to use a lot more money to pull
> off these attacks with full-rbf. So full-rbf definitely improves the
> situation even if it doesn't solve the problem completely.
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221109/fa0bd0e1/attachment-0001.html>

From email at yancy.lol  Wed Nov  9 12:14:52 2022
From: email at yancy.lol (email at yancy.lol)
Date: Wed, 09 Nov 2022 13:14:52 +0100
Subject: [bitcoin-dev] Announcement: Full-RBF Miner Bounty
In-Reply-To: <CAJowKgKGsAGQyCmx24fRZWrAWCVi91QKxXaQGiXLJ6zEFXnneg@mail.gmail.com>
References: <Y2I3w8O5X55sD/3C@petertodd.org>
 <fMZWicZXp5SM0ON8jgYuykBydOXcbgePbPfGKA0DQYtEDdiIr4bWljL_TqQHKtVKZRhvRXkEab47aaZw17OxGaSgOP2_w9_Owjb9WnTmsQ0=@protonmail.com>
 <CAJowKgKGsAGQyCmx24fRZWrAWCVi91QKxXaQGiXLJ6zEFXnneg@mail.gmail.com>
Message-ID: <72fe7342314b5ea419f5c83cc3bc164a@yancy.lol>



> technically, all we need is for *miners* to consistently mine "full
> rbf"

There's another important point I think:

technically, all we need is for *miners* to consistently mine the 
highest fee-rate transaction (or the one with the most incentive).

Miners could probably be incentivized to mine transactions that double 
spend a previous transaction that isn't rbf, also.

Cheers,
-Yancy

On 2022-11-03 14:32, Erik Aronesty via bitcoin-dev wrote:

> actually, peter makes an important point here
> 
> technically, all we need is for *miners* to consistently mine "full
> rbf"
> 
> as long as they do, businesses that accept 0conf will have to adjust
> their risk accordingly, and the problem of misaligned incentives is
> resolved
> 
> i don't think it matters what non-mining users do nearly as much
> 
> On Wed, Nov 2, 2022 at 3:05 PM alicexbt via bitcoin-dev
> <bitcoin-dev at lists.linuxfoundation.org> wrote:
> 
> Hi Peter,
> 
> tl;dr: I'm broadcasting full-RBF replacements paying extremely high 
> fees to reward miners that turn on full-RBF. I'm starting small, just 
> ~$100/block in times of congestion. Miner and pool profit margins are 
> pretty small, on the order of $1k/block in many cases, so I know it 
> doesn't take that much more money to make a difference.
> I appreciate this effort and perhaps this was all that was needed in
> addition to Bitcoin Core's inclusion of full rbf support. Making it
> default right away or enabling preferential peering with service
> flag in a bitcoin core release was unnecessary.
> 
> If you'd like to donate to this effort, send BTC to
> bc1qagmufdn6rf80kj3faw4d0pnhxyr47sevp3nj9m
> Sorry, I don't trust you based on some of the things you support on
> Twitter. Hopefully, others will donate and help this bounty.
> 
> /dev/fd0
> 
> Sent with Proton Mail secure email.
> 
> ------- Original Message -------
> On Wednesday, November 2nd, 2022 at 2:56 PM, Peter Todd via
> bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
> 
> I'm now running a full-RBf bounty program for miners.
> 
> tl;dr: I'm broadcasting full-RBF replacements paying extremely high 
> fees to reward miners that turn on full-RBF. I'm starting small, just 
> ~$100/block in times of congestion. Miner and pool profit margins are 
> pretty small, on the order of $1k/block in many cases, so I know it 
> doesn't take that much more money to make a difference.
> 
> Why should you do this? Full-RBF/zeroconf has been discussed to death. 
> But tl;dr: You'll earn more money, and help transition Bitcoin to a 
> more secure mempool policy based on economic incentives rather than 
> trust.
> 
> If you're a miner and want to participate, the easiest way to so is to 
> use the mempoolfullrbf=1 option in the upcoming Bitcoin Core v24 
> release (eg the 24.0rc3 tag), or use the mempoolreplacement=fee option 
> in Bitcoin Knots.
> You can also just modify the code yourself by removing the opt-in RBF 
> check. For example against the v23.0 tag:
> 
> $ git diff
> diff --git a/src/validation.cpp b/src/validation.cpp
> index 214112e2b..44c364623 100644
> --- a/src/validation.cpp
> +++ b/src/validation.cpp
> @@ -736,7 +736,7 @@ bool MemPoolAccept::PreChecks(ATMPArgs& args, 
> Workspace& ws) // check all unconfirmed ancestors; otherwise an opt-in 
> ancestor
> // might be replaced, causing removal of this descendant.
> if (!SignalsOptInRBF(*ptxConflicting)) {
> - return state.Invalid(TxValidationResult::TX_MEMPOOL_POLICY, 
> "txn-mempool-conflict"); + // return 
> state.Invalid(TxValidationResult::TX_MEMPOOL_POLICY, 
> "txn-mempool-conflict"); }
> 
> ws.m_conflicts.insert(ptxConflicting->GetHash());
> 
> Once you've enabled full-RBF, you need a full-RBF peer. I'm running a 
> few of them:
> 
> cup.nop.lol
> mug.nop.lol
> jar.nop.lol
> jug.nop.lol
> 
> These nodes run a preferential peering patch 
> (https://github.com/bitcoin/bitcoin/pull/25600) to ensure that full-RBF 
> nodes are interconnected to each other and replacements can easily 
> propagate. Also feel free to contact me if you'd like to peer with a 
> private node.
> 
> If you'd like to donate to this effort, send BTC to
> bc1qagmufdn6rf80kj3faw4d0pnhxyr47sevp3nj9m
> 
> ...and yes, I'm well aware that miners could collect this bounty in 
> other ways, eg by raising minimum fees. Doing that also breaks 
> zeroconf, so I'm not too concerned.
> 
> --
> https://petertodd.org 'peter'[:-1]@petertodd.org [1 [1]]
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev 
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

Links:
------
[1] http://petertodd.org
_______________________________________________
bitcoin-dev mailing list
bitcoin-dev at lists.linuxfoundation.org
https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

Links:
------
[1] http://petertodd.org
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221109/62cc0003/attachment-0001.html>

From ArmchairCryptologist at protonmail.com  Wed Nov  9 13:19:28 2022
From: ArmchairCryptologist at protonmail.com (ArmchairCryptologist)
Date: Wed, 09 Nov 2022 13:19:28 +0000
Subject: [bitcoin-dev] [Opt-in full-RBF] Zero-conf apps in immediate
	danger
In-Reply-To: <Y05PHYtrNmA0vg7U@erisian.com.au>
References: <Y0ZTtlRSBihNN9+v@erisian.com.au>
 <0hpdGx-1WbZdG31xaMXGHKTCjJ2-0eB5aIXUdsp3bqI1MlCx6TMZWROwpl1TVI5irrBqRN2-ydM6hmf3M5L-7ZQfazbx66oameiWTHayr6w=@wuille.net>
 <Y0d/e2sEoNRgD7KP@erisian.com.au> <Y0u8Ee2Ao375z8UD@erisian.com.au>
 <CALZpt+GSYBFxajSyZS19sQi4_6zHjkA5sP00V-pR=_NEVVUnkg@mail.gmail.com>
 <Y05PHYtrNmA0vg7U@erisian.com.au>
Message-ID: <fU-5B7MRAtu7RmJRfYnY0Jkv3d64dRyZDWCbpYJtqIoqhqrjuKDfWue2ddU8-O6JyUv2NL5iP_cpwNO-9e8s1WVepJAaCJa1IMMK6DXAWeA=@protonmail.com>

------- Original Message -------
On Tuesday, October 18th, 2022 at 9:00 AM, Anthony Towns via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:

> I mean, if you think the feedback is wrong, that's different: maybe we
> shouldn't care that zeroconf apps are in immediate danger, and maybe
> bitcoin would be better if any that don't adapt immediately all die
> horribly as a lesson to others not to make similarly bad assumptions.

I've been following this discussion, and I wonder if there isn't a third solution outside of "leave lightning vulnerable to pinning by non-RBF translations" and "kill zeroconf by introducing full-RBF" - specifically, adding a form of simple recursive covenant that "all descendant transactions of this transaction must use opt-in RBF for x blocks after this transaction is mined". This could be introduced either as a relay/mempool policy like RBF, or in a full-fledged softfork.

Based on my admittedly not all-encompassing understanding of the bitcoin transaction format, there are several unused bits in nSequence, which is already used to flag RBF, that might be repurposed to flag the duration of this lock. Say if two bits were used for this, that would be enough to flag that the restriction is not used, or active for 100, 1000 and 10000 blocks.

I'm sure there may be other and potentially better ways of enabling this type of covenant, but I'll leave that to the people who actually live and breathe the bitcoin transaction format.

--
Regards,
ArmchairCryptologist


From dave at dtrt.org  Thu Nov 10 07:39:10 2022
From: dave at dtrt.org (David A. Harding)
Date: Wed, 09 Nov 2022 21:39:10 -1000
Subject: [bitcoin-dev] Merkleize All The Things
In-Reply-To: <CAMhCMoH9uZPeAE_2tWH6rf0RndqV+ypjbNzazpFwFnLUpPsZ7g@mail.gmail.com>
References: <CAMhCMoH9uZPeAE_2tWH6rf0RndqV+ypjbNzazpFwFnLUpPsZ7g@mail.gmail.com>
Message-ID: <036287ca4f22dde0b98c91784ba79a5d@dtrt.org>

On 2022-11-07 23:17, Salvatore Ingala via bitcoin-dev wrote:
> Hi list,

Hi Salvatore!,

> I have been working on some notes to describe an approach that uses
> covenants in order to enable general smart contracts in bitcoin. You
> can find them here:
> 
>     https://merkle.fun

I haven't yet been able to understand everything in your post, but I'm 
wondering if you can describe how your proposal significantly differs in 
application from [1]?  E.g., you write:

> 1. Alice posts the statement ?f(x) = y?.
> 2. After a challenge period, if no challenge occurs, Alice is free to 
> continue and unlock the funds; the statement is true.
> 3. At any time before the challenge period expires, Bob can start a 
> challenge: ?actually, f(x) = z?.

That looks to me very similar to Gregory Maxwell's script from[1] 
(comments and variable name changes mine):

# Offchain, Alice posts the statement f(x) = y
# Offchain, Bob provides Ex, an encrypted form of x that can be proven 
in zero knowledge to satisfy both f(x) = y and sha256(x) = Y
OP_SHA256
<Y> OP_EQUAL
OP_IF
   # Bob provided the preimage for Y, that preimage being the solution, 
so he can spend the funds now
   <Bob Pubkey>
OP_ELSE
   # The challenge period ended, so Alice can reclaim her funds
   <block_height+100> OP_CHECKLOCKTIMEVERIFY OP_DROP
   <Alice Pubkey>
OP_ENDIF
OP_CHECKSIG

Thanks and apologies if I'm missing something obvious!,

-Dave

[1] 
https://bitcoincore.org/en/2016/02/26/zero-knowledge-contingent-payments-announcement/

From ZmnSCPxj at protonmail.com  Thu Nov 10 09:35:18 2022
From: ZmnSCPxj at protonmail.com (ZmnSCPxj)
Date: Thu, 10 Nov 2022 09:35:18 +0000
Subject: [bitcoin-dev] [Opt-in full-RBF] Zero-conf apps in immediate
	danger
In-Reply-To: <fU-5B7MRAtu7RmJRfYnY0Jkv3d64dRyZDWCbpYJtqIoqhqrjuKDfWue2ddU8-O6JyUv2NL5iP_cpwNO-9e8s1WVepJAaCJa1IMMK6DXAWeA=@protonmail.com>
References: <Y0ZTtlRSBihNN9+v@erisian.com.au>
 <0hpdGx-1WbZdG31xaMXGHKTCjJ2-0eB5aIXUdsp3bqI1MlCx6TMZWROwpl1TVI5irrBqRN2-ydM6hmf3M5L-7ZQfazbx66oameiWTHayr6w=@wuille.net>
 <Y0d/e2sEoNRgD7KP@erisian.com.au> <Y0u8Ee2Ao375z8UD@erisian.com.au>
 <CALZpt+GSYBFxajSyZS19sQi4_6zHjkA5sP00V-pR=_NEVVUnkg@mail.gmail.com>
 <Y05PHYtrNmA0vg7U@erisian.com.au>
 <fU-5B7MRAtu7RmJRfYnY0Jkv3d64dRyZDWCbpYJtqIoqhqrjuKDfWue2ddU8-O6JyUv2NL5iP_cpwNO-9e8s1WVepJAaCJa1IMMK6DXAWeA=@protonmail.com>
Message-ID: <F1L5VSwhj9SNtMuI7bhBzxyyuAIxwla8NI1T4_pZVDiN0nWYCvdTqq5vPl_SOXp2Ca6_-VJ340eTwPSWelM4k04mRLxoZNkpEF-MIW6xa9g=@protonmail.com>

Good morning ArmchairCryptologist,

> ------- Original Message -------
> On Tuesday, October 18th, 2022 at 9:00 AM, Anthony Towns via bitcoin-dev bitcoin-dev at lists.linuxfoundation.org wrote:
> 
> > I mean, if you think the feedback is wrong, that's different: maybe we
> > shouldn't care that zeroconf apps are in immediate danger, and maybe
> > bitcoin would be better if any that don't adapt immediately all die
> > horribly as a lesson to others not to make similarly bad assumptions.
> 
> 
> I've been following this discussion, and I wonder if there isn't a third solution outside of "leave lightning vulnerable to pinning by non-RBF translations" and "kill zeroconf by introducing full-RBF" - specifically, adding a form of simple recursive covenant that "all descendant transactions of this transaction must use opt-in RBF for x blocks after this transaction is mined". This could be introduced either as a relay/mempool policy like RBF, or in a full-fledged softfork.

A script with trivial `0 OP_CSV` would effectively require that spenders set the opt-in RBF flag, while allowing the output to be spent even while it is unconfirmed.
However, this basically only lasts for 1 transaction layer.

----

Thinking a little more about 0-conf:

We can observe that 0-conf, being eventually consistent, introduces risks to 0-conf acceptors similar to credit card acceptors.

And credit card acceptors are observed to compensate for this risk by increasing the prices of their products and services.

Some credit card acceptors may offer discounts when paid by cash, which in our analogy would be that transaction confirmation would offer discounts (i.e. enabling 0-conf would increase the cost of the product/service being purchased).
In many jurisdictions (not the USA or in some of the first world countries), this practice is illegal (i.e. credit card companies have pressured lawmakers in some jurisdictions to disallow merchants from offering a different price between cash and credit card purchases; some jurisdictions let you escape if you say "cash discount" instead of "credit card surcharge", even though they are just sign-flips of each other, because you humans are crazy and I am happy I am actually an AI)

Which brings me to my next point: why are 0-conf acceptors not offering a discount if the user specifically flags "I am willing to wait for N confirmations"?
On the part of 0-conf acceptors, that is significantly less risky than relying on 0-conf at all.

Regards,
ZmnSCPxj

From email at yancy.lol  Thu Nov 10 14:38:27 2022
From: email at yancy.lol (email at yancy.lol)
Date: Thu, 10 Nov 2022 15:38:27 +0100
Subject: [bitcoin-dev] On mempool policy consistency
In-Reply-To: <jzS-a7kpDwvAhO4TJiTgtpsP95Zi8BRvIgUqjOs3hEVI_Uu-ey1LfCnN2D8wkG21yfVPGIujbiDXCfFAyfW56gPtvd8p3SrsOmOE22IWAuA=@protonmail.com>
References: <mailman.38435.1666828344.956.bitcoin-dev@lists.linuxfoundation.org>
 <CAHTn92wfjTCF5UtbjezbEYWTUQ7t6FNZu1ow0pirJXGFoXJxCA@mail.gmail.com>
 <Y1q+MedepB1qUpBP@erisian.com.au>
 <jzS-a7kpDwvAhO4TJiTgtpsP95Zi8BRvIgUqjOs3hEVI_Uu-ey1LfCnN2D8wkG21yfVPGIujbiDXCfFAyfW56gPtvd8p3SrsOmOE22IWAuA=@protonmail.com>
Message-ID: <7ce4313f6d586ced1643b1624acf81bb@yancy.lol>



> I read Antoine's original post on this and got the general gist, and 
> here also, it makes sense, but I'd like to ask: is it necessary that 
> (B, C) in the above not *see* A's opt-out "pre-replacement" (inputs: 
> A1, outputs: A, fees: low; call it TX_2)? I get that they cannot 
> replace it

Is it actually true that they cannot replace it?  If miners and node 
operators collude and have the incentive to run a patched version of 
core, is it still technically impossible to replace?

> the idea that they suffer financial loss from
> "ignorant" fee bumping is the part that seems weird to me.

Even if they waste resources trying to fee-bump, I agree that this does 
not appear to be a catastrophe.There doesn't seem to be any technical 
reason why improvements can't be made to allow B and C to have a better 
view.

Cheers,
-Yancy

On 2022-11-08 10:28, AdamISZ via bitcoin-dev wrote:

> Hi aj and list,
> (questions inline)
> 
> ------- Original Message -------
> On Thursday, October 27th, 2022 at 18:21, Anthony Towns via
> bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:
> 
>> Is that true? Antoine claims [1 [1]] that opt-in RBF isn't enough to 
>> avoid
>> a DoS issue when utxos are jointly funded by untrusting partners, and,
>> aiui, that's the main motivation for addressing this now.
>> 
>> [1] 
>> https://lists.linuxfoundation.org/pipermail/lightning-dev/2021-May/003033.html
>> 
>> The scenario he describes is: A, B, C create a tx:
>> 
>> inputs: A1, B1, C1 [opts in to RBF]
>> fees: normal
>> outputs:
>> [lightning channel, DLC, etc, who knows]
>> 
>> they all analyse the tx, and agree it looks great; however just before
>> publishing it, A spams the network with an alternative tx, double
>> spending her input:
>> 
>> inputs: A1 [does not opt in to RBF]
>> fees: low
>> outputs: A
>> 
>> If A gets the timing right, that's bad for B and C because they've
>> populated their mempool with the 1st transaction, while everyone else
>> sees the 2nd one instead; and neither tx will replace the other. B and
>> C can't know that they should just cancel their transaction, eg:
>> 
>> inputs: B1, C1 [opts in to RBF]
>> fees: 50% above normal
>> outputs:
>> [smaller channel, refund, whatever]
>> 
>> and might instead waste time trying to fee bump the tx to get it 
>> mined,
>> or similar.
>> 
>> What should folks wanting to do coinjoins/dualfunding/dlcs/etc do to
>> solve that problem if they have only opt-in RBF available?
> <snip>
> I read Antoine's original post on this and got the general gist, and
> here also, it makes sense, but I'd like to ask: is it necessary that
> (B, C) in the above not *see* A's opt-out "pre-replacement" (inputs:
> A1, outputs: A, fees: low; call it TX_2)? I get that they cannot
> replace it, but the idea that they suffer financial loss from
> "ignorant" fee bumping is the part that seems weird to me. Clearly
> TX_2 gets gossiped to other mempools; and understood that it does not
> replace the TX_1 (the 3-input) in B's mempool, say, but why should
> they not even hear about it? Is it just a matter of engineering, or is
> there some deeper problem with that.
> 
> About this general flavour of attack, it's never been a *big* concern
> in Joinmarket imo (though, we did until recently have a bug that made
> this happen *by accident*, i.e. people double spending an input out of
> a negotiated join, albeit it was rare; but it's ofc definitely
> *possible* to 'grief' like this, given the ordering of events; maker
> sends signature, maker broadcasts double spend - 95% of the time they
> will be first). Interactive protocols are yucky and I think there'll
> always be griefing possibilities; designing around multiple-rounds of
> negotiation amongst not always-on participants is even more yucky, so
> just having a 'taker is in charge of network fee; if it's slow or gets
> double spent out causing time delay then just wait', combined with
> 'there really isn't any economic incentive for an attacker' (i.e.
> ignoring griefing) might sound crappy but it's probably just being
> realistic.
> 
> Of course, off-chain contracting has more sophisticated considerations
> than this.
> 
> Cheers,
> AdamISZ/waxwing
> 
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev


Links:
------
[1] 
https://lists.linuxfoundation.org/pipermail/lightning-dev/2021-May/003033.html
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221110/ae20762b/attachment.html>

From salvatore.ingala at gmail.com  Thu Nov 10 09:42:30 2022
From: salvatore.ingala at gmail.com (Salvatore Ingala)
Date: Thu, 10 Nov 2022 10:42:30 +0100
Subject: [bitcoin-dev] Merkleize All The Things
In-Reply-To: <Vbb1PZfBzm6JBddqNIfikVE2G1fDmObt0BBt2BqhmHV_Tx7KLGU5SSQPPp0OaLZHAKrkKobA2f60tX4TOl996aE9ds1tZWaGAHbSr9wu5r0=@protonmail.com>
References: <CAMhCMoH9uZPeAE_2tWH6rf0RndqV+ypjbNzazpFwFnLUpPsZ7g@mail.gmail.com>
 <Vbb1PZfBzm6JBddqNIfikVE2G1fDmObt0BBt2BqhmHV_Tx7KLGU5SSQPPp0OaLZHAKrkKobA2f60tX4TOl996aE9ds1tZWaGAHbSr9wu5r0=@protonmail.com>
Message-ID: <CAMhCMoErkp_i3Ho482B91Vects=r98jT_6hyy7F84CVw8f=79A@mail.gmail.com>

Hi ZmnSCPxj, Bram, Peter, David,

Thanks for all your comments; replies below.

On Tue, 8 Nov 2022 at 13:01, ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:

> Modulo bugs, operator error, misconfigurations, and other irrationalities
> of humans.
>

I agree that making footguns impossible is a much more difficult problem to
solve!

Rather than get taptree from the stack, just use the same taptree as in the
> revelation of the P2TR.
> This removes the need to include quining and similar techniques: just do
> the quining in the SCRIPT interpreter.
>

That's a possibility; I suspect it would be less efficient for many
contracts (in particular, when the total number of states in the FSM is
relatively large, but each of them has only few valid transitions). We
could always allow both variants.

Another reason I preferred to present it in this way is to show that it is
possible to limit the design to covenants where recursion is not allowed /
limited; I don't personally think recursion is bad at this time ? but the
covenants (and the protocol for fraud challenges) do not require it in
order to be useful.

Anyway, I suggested some opcodes only as a sketch. I'm not knowledgeable
enough to suggest the best design, and maybe it will be easier to compare
several variants once we implement something on top.


On Wed, 9 Nov 2022 at 00:34, Bram Cohen <bram at chia.net> wrote:

> Hash chained covenants in general all have about the same plateau of
> functionality, which seems roughly reasonable to add to Bitcoin as it is
> today but suffer from being limited and hence likely only a stepping stone
> to greater functionality and unless whatever's put in now cleanly extends
> to supporting more in the future it's likely to turn into a legacy
> appendage which has to be supported. So my generic suggestion for this sort
> of thing is that it should be proposed along with a plan for how it could
> be extended to support full-blown covenants in the future.
>

I actually struggle to find constructions that are _not_ possible using
such covenants; do you have any concrete example?
That would be very interesting in order to correctly classify the
expressive power of UTXO+Script+covenants when compared to the
"Turing-complete"+stateful models.

Another probably unhelpful bit of feedback I have is that Bitcoin should
> probably be taking verkle trees seriously because those can have
> substantially lower size/cost/weight than merkle trees. That doesn't just
> apply to this proposal, but to Bitcoin in general, which doesn't seem to
> have any serious verkle tree proposals to date.
>

I am not an expert in Verkle trees, but I think the efficiency gain (if
any) is not that interesting for many of the applications I'm suggesting,
as most Merkle trees would be quite small.
Therefore, I agree with Peter that the additional complexity might not be
worth it at this time; if applications requiring large Merkle trees arise
in practice, Verkle trees could always be added in the future as an
optimization.

Moreover, Verkle trees, or even any risky/fancy cryptography, could be used
in layer-2 solutions enabled by the covenant, without impacting any funds
not locked in the covenant in case of disasters.


On Wed, 9 Nov 2022 at 13:07, Peter Todd <pete at petertodd.org> wrote:

> Particularly since even having merkle trees in Bitcoin
> is arguably a mistake: they allow for degenerate, weak, security modes
> like SPV
> that aren't clearly good for Bitcoin as a whole.
>

I disagree, as the title of this thread suggests! :)
Thanks to Merkle trees, we'll be able to keep layer 1 extremely light, so
everyone can run a full node ? while all the complexity of fancy
constructions is pushed to the application layer.


On Thu, 10 Nov 2022 at 08:39, David A. Harding <dave at dtrt.org> wrote:

> > 1. Alice posts the statement ?f(x) = y?.
> > 2. After a challenge period, if no challenge occurs, Alice is free to
> > continue and unlock the funds; the statement is true.
> > 3. At any time before the challenge period expires, Bob can start a
> > challenge: ?actually, f(x) = z?.
>
> That looks to me very similar to Gregory Maxwell's script from[1]
>

Zero-Knowledge contingent payments do indeed solve the problem more
elegantly in the specific case where swapping Alice's knowledge for x with
a payment from Bob is the entire smart contract.

The covenant adds the ability to carry over some sort of state. For
example, imagine Alice and Bob want to play a game of chess, and the winner
takes all the money [*]. The "state" in the covenant would be the entire
chessboard, and a valid transition is a valid chess move. The covenant
enforces that the game proceeds according to the rules, by only allowing
correct updates to the "state".
Moreover, the parties participating to a covenant don't necessarily need to
be decided in advance, which is crucial for constructions like coinpool [1].

Note that no this does not require any fraud proof, as the rules of chess
are simple enough that each "transition" is a simple enough function. In
fact, many contracts might not require fraud proofs at all.

The point of the chapter on fraud proof is to prove that full generality in
expressive power (that is: any state transition you can think of) is
possible, as whenever a complex transition is required ? one could instead
replace it with the optimistic protocol (Alice makes a claim,
counterparties can challenge if the claim is wrong). That allows to remove
any expensive computation from hitting the blockchain.

A particularly interesting example might be rollups (and similar
constructions). There, the 'state' represents a separate ledger, and a
transition takes the secondary ledger from a valid state to another valid
state, using a zero-knowledge proof. In validity rollups [2], the chain is
required to actually check the validity proof, which is a very expensive
operation (plus, the state-of-the-art requires additional cryptographic
assumptions in layer 1, as far as I understand). The covenant would allow
us[**] to implement optimistic rollups, where the rollup operator just
posts the new state and the proof, and other parties have time to challenge
it if the proof is wrong.

I hope this clarifies the role of fraud proofs in the construction.

Best,
Salvatore


[*] - I'm not suggesting using the bitcoin blockchain to play chess games,
but it is a convenient academic example :)
[**] - Pending someone more expert to double check that nothing is missing!

[1] - https://coinpool.dev
[2] - https://bitcoinrollups.org
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221110/34d9b720/attachment-0001.html>

From bitcoin-dev at wuille.net  Thu Nov 10 21:23:44 2022
From: bitcoin-dev at wuille.net (Pieter Wuille)
Date: Thu, 10 Nov 2022 21:23:44 +0000
Subject: [bitcoin-dev] Refreshed BIP324
In-Reply-To: <Y2nK99fHUKxbPHmw@erisian.com.au>
References: <56677685-619a-691f-d5bc-54b69fdb6ed2@bip324.com>
 <zxv58iXZ73hf9ge8S0QLTanW-uLzaWjNtMHuKONP9hrqS5RhwitxzfVaMH8hbi3yImgNrKme3lCuDcHYKkpxEQHyGZZHJ8xtReOcnAx3o4g=@wuille.net>
 <Y2nK99fHUKxbPHmw@erisian.com.au>
Message-ID: <wDqcIVw-YGTsjdf5M2GO9NNRl_UQuBeka2CUQUyQ329u6u-o7RabW_7S4FD3EDfk02kUczb3bXf8LtHhKLtx773UhQ7djKOl-JPOIrXqBSc=@wuille.net>

Hi,

Thanks for the comments so far. I think these are all reasonable ideas.
Comments inline below.

On Thursday, November 3rd, 2022 at 1:53 PM, Murch wrote:

> From what I understand we'll have about 35 message types on the network
> with the addition of BIP324. 256 possible IDs sounds like plenty room to
> grow, but perhaps we can be a bit more conservative:
> 
> We could use the first bit to signal a 2-byte message ID. That allows us
> to express 128 IDs with 1 byte, but if we need more, we get a total of
> 2^15 IDs across 2 bytes.

Yeah, effectively treating the first 1 or 2 bytes as a simple variable
length integer is a nice way of increasing the space at low cost.

This also doesn't need to be decided now. The initial approach could just
be avoiding allocating bytes in the 128-255 range until the need for more
space arises. If and when that is the case, the choice could be to:
* Just continue treating the first byte as the command.
* Start treating the first upper bit as a sign that another command byte
  follows.
* Switch to some form of explicit signalling (option 3 is my earlier
  mail).

On Thursday, November 3rd, 2022 at 6:26 PM, Jonas Schnelli wrote:

> There would be an alternative to preserve more 1 byte IDs on the cost
> of a (much) smaller 2 byte ID space: Reserve the short ID 0xFF as an
> indication for a 2 bytes short ID (additional 256 short IDs with 2 bytes).

I don't think this is needed, because we arguably already have that! If the
first byte is 0x01, then 1 more command byte follows in the current BIP324
draft. That mechanism is designed for alphabetic 1-character commands, but
nothing prevents it from also being used for other things (by using a
non-alphabetic byte there).

> Maybe the BIP should state that only frequent sent messages should reserve
> a short ID, though, the BIP itself assigns short IDs to all(?) message
> types (including low frequent messages like SENDHEADERS).
> 
> Maybe exclude message types that expected to be only sent once from
> assigning a short ID?

I think that makes sense. Especially in combination with the idea avoiding
bytes with the upper bit set there is a bit more pressure on the 1-byte
space. Rarely-sent or at-most-once-sent commands don't really provide much
benefit. I'd suggest scrapping from the list:
* Version messages: version, verack
* Negotiation messages: sendaddrv2, sendheaders, sendcmpct, wtxidrelay
* Rarely-sent messages: mempool

I'm not sure to what extent filteradd/filterload/filterclear/merkleblock
are still actually used; perhaps they could be removed too?

On Monday, November 7th, 2022 at 10:20 PM, Anthony Towns wrote:

> I guess I think it would make sense to not start using a novel 1-byte
> message unless you've done something to introduce that message first;
> whether that's via approach (3) ("I'm going to use 0xE9 to mean pkgtxns")
> or via a multibyte feature support message ("I sent sendaddrv3 as a
> 10-byte message, that implies 0xA3 means addrv3 from now on").

That's fair, but I don't think it matters too much for allocation purposes;
protocol designs should still not assign overlapping values, unless the
protocols are known to never be used simultaneously?

Unless... the assignment works like "whenever the sendaddrv3 is sent, the
next available byte in range 48..127 gets allocated for addrv3". That means
no explicit mapping is needed, as long as the total number of messages from
simultaneously-active extensions isn't too large.

> I do still think it'd be better to recommend against reserving a byte for
> one-shot messages, and not do it for existing one-shot messages though.

Agree.

FWIW, if anyone was wondering about how much is actually saved by having
1-byte commands vs 12-byte commands, I've gathered statistics from two nodes
(one with many inbound connections, one only outbound) for two weeks. This is
obviously very dependent on network topology and local implementation choices,
but it may still give an idea:
* Outbound-only node:
  * Around 4.5% of sent bytes are bytes 2-12 of the command.
  * Sent 979.98 MiB in total.
* Outbound and inbound node:
  * Around 1.6% of sent bytes are bytes 2-12 of the command.
  * Sent 124.14 GiB in total.

Cheers,

-- 
Pieter


From dave at dtrt.org  Fri Nov 11 03:00:58 2022
From: dave at dtrt.org (David A. Harding)
Date: Thu, 10 Nov 2022 17:00:58 -1000
Subject: [bitcoin-dev] Using Full-RBF to fix BIP-125 Rule #3 Pinning
 with nLockTime
In-Reply-To: <Y2l1/qXHxyctU9ir@petertodd.org>
References: <Y2ln2fJ+8+Q0qS0E@petertodd.org> <Y2l1/qXHxyctU9ir@petertodd.org>
Message-ID: <f360357e2d9655360766595d81a82e87@dtrt.org>

On 2022-11-07 11:17, Peter Todd via bitcoin-dev wrote:
> We can ensure with high probability that the transaction can be 
> cancelled/mined
> at some point after N blocks by pre-signing a transaction, with 
> nLockTime set
> sufficiently far into the future, spending one or more inputs of the
> transaction with a sufficiently high fee that it would replace 
> transaction(s)
> attempting to exploit Rule #3 pinning (note how the package limits in 
> Bitcoin
> Core help here).

This implies a floor on the funds involved in a contract.  For example, 
if the pinning transaction is 100,000 vbytes at a feerate of 1 sat/vb, 
the minimum contract amount must be a bit over 100,000 sats (about $17 
USD at current prices).  However, participants in a contract not meant 
to settle immediately probably need to assume the worst case future 
pinning, for example where transactions paying even 100 sat/vb won't be 
mined promptly; in which case the minimum contract amount becomes 
something like $1,700 USD.

That seems sub-optimal to me.

-Dave

From antoine.riard at gmail.com  Fri Nov 11 21:49:58 2022
From: antoine.riard at gmail.com (Antoine Riard)
Date: Fri, 11 Nov 2022 16:49:58 -0500
Subject: [bitcoin-dev] Merkleize All The Things
In-Reply-To: <CAMhCMoH9uZPeAE_2tWH6rf0RndqV+ypjbNzazpFwFnLUpPsZ7g@mail.gmail.com>
References: <CAMhCMoH9uZPeAE_2tWH6rf0RndqV+ypjbNzazpFwFnLUpPsZ7g@mail.gmail.com>
Message-ID: <CALZpt+GVe0XTdWqV=LAcOj=nq+k2DEFqc+sKyxAujLDBR7bYbQ@mail.gmail.com>

Hi Salvatore,

Thanks for bringing forward this MATT proposal!

Here my (rough) understanding of the protocol, the participants decompose
the entire computation into a number N of steps, each assigned a tapleaf,
each computation is a triplet (state_start, operation, state_end), the
tapleaves are built into a Merkle tree, the current state of the FSM is
also encoded in the Taproot output. The Merkle tree is committed in some
Script branch where a timelock is present to guarantee challenge (e.g "f(x)
= ?" OP_CHALLENGE + 100 OP_CSV). A funding transaction is broadcast to lock
the funds, participants can leverage this funding output to play out
off-chain the computation steps. To advance the resolution, a participant
spends the funding output with a witness embedding all the computation
trace encoded as Merkle branch and prove some statement "f(x) = y". Until
the CSV expires, another participant can contest by presenting another
witness with another computation trace. What is unclear to me is how the
contract's state issued off-chain can alter the pre-committed state
transitions. I think what could gain in clarity is the translation of the
bisection protocol steps in more complete new opcodes.

Another high-level remark, even if we assume any arbitrary computation can
be encoded in a Merkle Tree, as the computation grows in complexity, the
corresponding trace also increases in (witness) space. There might be some
economic bounds on the generalized smart contracts you can engage in, as
the worst-case scenario might be beyond your fee-bumping reserves. Less
flexible, but more templated opcodes for the same use-cases might make it
more affordable. At the same time, the ability to encode any cryptosystem
as the function f sounds really interesting.

Best,
Antoine

Le mar. 8 nov. 2022 ? 05:13, Salvatore Ingala via bitcoin-dev <
bitcoin-dev at lists.linuxfoundation.org> a ?crit :

> Hi list,
>
> I have been working on some notes to describe an approach that uses
> covenants in order to enable general smart contracts in bitcoin. You can
> find them here:
>
>     https://merkle.fun
>
> The approach has a number of desirable features:
>
> - small impact to layer 1;
> - not application-specific, very general;
> - it fits well into P2TR;
> - it does not require new cryptographic assumptions, nor any construction
> that has not withstood the test of time.
>
> This content was presented at the BTCAzores unconference, where it
> received the name of MATT ? short for Merkleize All The Things.
> In fact, no other cryptographic primitive is required, other than Merkle
> trees.
>
> I believe this construction gets close to answering the question of how
> small a change on bitcoin's layer 1 would suffice to enable arbitrary smart
> contracts.
>
> It is not yet at the stage where a formal proposal can be made, therefore
> the proposed specs are only for illustrative purposes.
>
> The same content is reformatted below for the mailing list.
>
> Looking forward to hearing about your comments and improvements.
> Salvatore Ingala
>
>
> ==========================================
>
>
> # General smart contracts in bitcoin via covenants
>
> Covenants are UTXOs that are encumbered with restrictions on the outputs
> of the transaction spending the UTXO. More formally, we can define a
> covenant any UTXO such that at least one of its spending conditions is
> valid only if one or more of the outputs? scriptPubKey satisfies certain
> restrictions.
>
> Generally, covenant proposals also add some form of introspection (that
> is, the ability for Script to access parts of the inputs/outputs, or the
> blockchain history).
>
> In this note, we want to explore the possibilities unleashed by the
> addition of a covenant with the following properties:
>
> - introspection limited to a single hash attached to the UTXO (the
> ?covenant data?), and input/output amounts;
> - pre-commitment to every possible future script (but not their data);
> - few simple opcodes operating with the covenant data.
>
> We argue that such a simple covenant construction is enough to extend the
> power of bitcoin?s layer 1 to become a universal settlement layer for
> arbitrary computation.
>
> Moreover, the covenant can elegantly fit within P2TR transactions, without
> any substantial increase for the workload of bitcoin nodes.
>
> A preliminary version of these notes was presented and discussed at the
> BTCAzores Unconference [1], on 23rd September 2022.
>
>
> # Preliminaries
>
> We can think of a smart contract as a ?program? that updates a certain
> state according to predetermined rules (which typically include access
> control by authorizing only certain public keys to perform certain
> actions), and that can possibly lock/unlock some coins of the underlying
> blockchain according to the same rules.
>
> The exact definition will be highly dependent on the properties of the
> underlying blockchain.
>
> In bitcoin, the only state upon which all the nodes reach consensus is the
> UTXO set; other blockchains might have other data structures as part of the
> consensus, like a key-value store that can be updated as a side effect of
> transaction execution.
>
> In this section we explore the following concepts in order to set the
> framework for a definition of smart contracts that fits the structure of
> bitcoin:
>
> - the contract?s state: the ?memory? the smart contract operates on;
> - state transitions: the rules to update the contract?s state;
> - covenants: the technical means that can allow contracts to function in
> the context of a bitcoin UTXO.
>
> In the following, an on-chain smart contract is always represented as a
> single UTXO that implicitly embeds the contract?s state and possibly
> controls some coins that are ?locked? in it. More generally, one could
> think of smart contracts that are represented in a set of multiple UTXOs;
> we leave the exploration of generalizations of the framework to future
> research.
>
> ## State
>
> Any interesting ?state? of a smart contract can ultimately be encoded as a
> list, where each element is either a bit, a fixed-size integers, or an
> arbitrary byte string.
>
> Whichever the choice, it does not really affect what kinds of computations
> are expressible, as long as one is able to perform some basic computations
> on those elements.
>
> In the following, we will assume without loss of generality that
> computations happen on a state which is a list of fixed length S = [s_1,
> s_2, ?, s_n], where each s_i is a byte string.
>
> ### Merkleized state
>
> By constructing a Merkle tree that has the (hashes of) the elements of S
> in the leaves, we can produce a short commitment h_S to the entire list S
> with the following properties (that hold for a verifier that only knows
> h_S):
>
> - a (log n)-sized proof can prove the value of an element s_i;
> - a (log n + |x|)-sized proof can prove the new commitment h_S?, where S?
> is a new list obtained by replacing the value of a certain leaf with x.
>
> This allows to compactly commit to a RAM, and to prove correctness of RAM
> updates.
>
> In other words, a stateful smart contract can represent an arbitrary state
> in just a single hash, for example a 32-byte SHA256 output.
>
> ### State transitions and UTXOs
>
> We can conveniently represent a smart contract as a finite state machine
> (FSM), where exactly one node can be active at a given time. Each node has
> an associated state as defined above, and a set of transition rules that
> define:
>
> - who can use the rule;
> - what is the next active node in the FSM;
> - what is the state of the next active node.
>
> It is then easy to understand how covenants can conveniently represent and
> enforce the smart contracts in this framework:
>
> - The smart contract is instantiated by creating a UTXO encumbered with a
> covenant; the smart contract is in the initial node of the FSM.
> - The UTXO?s scriptPubKey specifies the current state and the valid
> transitions.
> - The UTXO(s) produced after a valid transition might or might not be
> further encumbered, according to the rules.
>
> Therefore, what is necessary in order to enable this framework in bitcoin
> Script is a covenant that allows the enforcement of such state transitions,
> by only allowing outputs that commit to a valid next node (and
> corresponding state) in the FSM.
>
> It is not difficult to show that arbitrary computation is possible over
> the committed state, as long as relatively simple arithmetic or logical
> operations are available over the state.
>
> Remark: using an acyclic FSM does not reduce the expressivity of the smart
> contracts, as any terminating computation on bounded-size inputs which
> requires cycles can be unrolled into an acyclic one.
>
> ### Merkleized state transitions
>
> Similarly to how using Merkle trees allows to succinctly represent
> arbitrary data with a short, 32-byte long summary, the same trick allows to
> succinctly represent arbitrary state transitions (the smart contract?s
> code) with a single 32-byte hash. Each of the possible state transitions is
> encoded as a Script which is put in a leaf of a Merkle tree; the Merkle
> root of this tree is a commitment to all the possible state transitions.
> This is exactly what the taptree achieves in Taproot (see BIP-0341 [2]).
>
> Later sections in this document will suggest a possible way of how both
> the contract?s state and valid transition rules could be represented in
> UTXOs.
>
> ## On-chain computation?!
>
> Should the chain actually do computation?
>
> If naively designed, the execution of a contract might require a large
> number of transactions, which is not feasible.
>
> While the covenant approach does indeed enable a chain of transactions to
> perform arbitrary computation, simple economic considerations will push
> protocol designers to perform any non-trivial computation off-chain, and
> instead use the blockchain consensus only to verify the computation; or, if
> possible, skip the verification altogether.
>
> The fundamental fact that a blockchain?s layer 1 never actually needs to
> run complex programs in order to enable arbitrary complex smart contracting
> was observed in the past, for example in a 2016 post by Greg Maxwell [3].
>
> Vitalik Buterin popularized the concept of "functionality escape velocity"
> [4] to signify the minimum amount of functionality required on layer 1 in
> order to enable anything else to be built on top (that is, on layer 2 and
> beyond).
>
> In the following section, we will argue that a simple covenant
> construction suffices to achieve the functionality escape velocity in the
> UTXO model.
>
>
> # Commitments to computation and fraud challenges
>
> In this section, we explore how a smart contract that requires any
> non-trivial computation f : X --> Y (that is too expensive or not feasible
> with on-chain Script state transitions) can be implemented with the simple
> covenants described in the previous section.
>
> The ideas in this section appeared in literature; the reader is referred
> to the references for a more comprehensive discussion.
>
> We want to be able to build contracts that allow conditions of the type
> "f(x) = y"; yet, we do not want layer 1 to be forced to perform any
> expensive computation.
>
> In the following, we assume for simplicity that Alice and Bob are the only
> participants of the covenant, and they both locked some funds bond_A and
> bond_B (respectively) inside the covenant?s UTXO.
>
> 1. Alice posts the statement ?f(x) = y?.
> 2. After a challenge period, if no challenge occurs, Alice is free to
> continue and unlock the funds; the statement is true.
> 3. At any time before the challenge period expires, Bob can start a
> challenge: ?actually, f(x) = z?.
>
> In case of a challenge, Alice and Bob enter a challenge resolution
> protocol, arbitrated by layer 1; the winner takes the other party?s bond
> (details and the exact game theory vary based on the type of protocol the
> challenge is part of; choosing the right amount of bonds is crucial for
> protocol design).
>
> The remainder of this section sketches an instantiation of the challenge
> protocol.
>
> ## The bisection protocol for arbitrary computation
>
> In this section, we sketch the challenge protocol for an arbitrary
> computation f : X --> Y.
>
> ### Computation trace
>
> Given the function f, it is possible to decompose the entire computation
> in simple elementary steps, each performing a simple, atomic operation. For
> example, if the domain of x and y is that of binary strings of a fixed
> length, it is possible to create a boolean circuit that takes x and
> produces y; in practice, some form of assembly-like language operating on a
> RAM might be more efficient and fitting for bitcoin Script.
>
> In the following, we assume each elementary operation is operating on a
> RAM, encoded in the state via Merkle trees as sketched above. Therefore,
> one can represent all the steps of the computation as triples tri = (st_i,
> op_i, st_{i + 1}), where st_i is the state (e.g. a canonical Merkle tree of
> the RAM) before the i-th operation, st_{i + 1} is the state after, and op_i
> is the description of the operation (implementation-specific; it could be
> something like ?add a to b and save the result in c).
>
> Finally, a Merkle tree M_T is constructed that has as leaves the values of
> the individual computation steps T = {tr_0, tr_1, ?, tr_{N - 1}} if the
> computation requires N steps, producing the Merkle root h_T. The height of
> the Merkle tree is log N. Observe that each internal node commits to the
> portion of the computation trace corresponding to its own subtree.
>
> Let?s assume that the Merkle tree commitments for internal nodes are
> further augmented with the states st_{start} and st_{end}, respectively the
> state before the operation of in the leftmost leaf of the subtree, and
> after the rightmost leaf of the subtree.
>
> ### Bisection protocol
>
> The challenge protocol begins with Alice posting what she claims is the
> computation trace h_A, while Bob disagrees with the trace h_B != h_A;
> therefore, the challenge starts at the root of M_T, and proceeds in steps
> in order to find a leaf where Alice and Bob disagree (which is guaranteed
> to exist, hence the disagreement). Note that the arbitration mechanism
> knows f, x and y, but not the correct computation trace hash h_T.
>
> (Bisection phase): While the challenge is at a non-leaf node of M_T, Alice
> and Bob take turns to post the two hashes corresponding to the left and
> right child of their claimed computation trace hash; moreover, they post
> the start/end state for each child node. The protocol enforces that Alice?s
> transaction is only valid if the posted hashes h_{l; A} and h_{r; A}, and
> the declared start/end state for each child are consistent with the
> commitment in the current node.
>
> (Arbitration phase): If the protocol has reached the i-th leaf node, then
> each party reveals (st_i, op_i, st_{i + 1}); in fact, only the honest party
> will be able to reveal correct values, therefore the protocol can
> adjudicate the winner.
>
> Remark: there is definitely a lot of room for optimizations; it is left
> for future work to find the optimal variation of the approach; moreover,
> different challenge mechanisms could be more appropriate for different
> functions f.
>
> ### Game theory (or why the chain will not see any of this)
>
> With the right economic incentives, protocol designers can guarantee that
> playing a losing game always loses money compared to cooperating.
> Therefore, the challenge game is never expected to be played on-chain. The
> size of the bonds need to be appropriate to disincentivize griefing attacks.
>
> ### Implementing the bisection protocol's state transitions
>
> It is not difficult to see that the entire challenge-response protocol
> above can be implemented using the simple state transitions described above.
>
> Before a challenge begins, the state of the covenant contains the value of
> x, y and the computation trace computed by Alice. When starting the
> challenge, Bob also adds its claim for the correct computation trace, and
> the covenant enters the bisection phase.
>
> During the bisaction phase, the covenant contains the claimed computation
> trace for that node of the computation protocol, according to each party.
> In turns, each party has to reveal the corresponding computation trace for
> both the children of the current node; the transaction is only valid if the
> hash of the current node can be computed correctly from the information
> provided by each party about the child nodes. The protocol repeats on one
> of the two child nodes on whose computation trace the two parties disagree
> (which is guaranteed to exist). If a leaf of M_T is reached, the covenant
> enters the final arbitration phase.
>
> During the arbitration phase (say at the i-th leaf node of M_T), any party
> can win the challenge by providing correct values for tr_i = (st_i, op_i,
> st_{i + 1}). Crucially, only one party is able to provide correct values,
> and Script can verify that indeed the state moves from st_i to st_{i + 1}
> by executing op_i. The challenge is over.
>
> At any time, the covenant allows one player to automatically win the
> challenge after a certain timeout if the other party (who is expected to
> ?make his move?) does not spend the covenant. This guarantees that the
> protocol can always find a resolution.
>
> ### Security model
>
> As for other protocols (like the lightning network), a majority of miners
> can allow a player to win a challenge by censoring the other player?s
> transactions. Therefore, the bisection protocol operates under the honest
> miner majority assumption. This is acceptable for many protocols, but it
> should certainly be taken into account during protocol design.
>
>
> # MATT covenants
>
> We argued that the key to arbitrary, fully general smart contracts in the
> UTXO model is to use Merkle trees, at different levels:
>
> 1. succinctly represent arbitrary state with a single hash. Merkleize the
> state!
> 2. succinctly represent the possible state transitions with a single hash.
> Merkleize the Script!
> 3. succinctly represent arbitrary computations with a single hash.
> Merkleize the execution!
>
> (1) and (2) alone allow contracts with arbitrary computations; (3) makes
> them scale.
>
>    Merkleize All The Things!
>
> In this section we sketch a design of covenant opcodes that are
> taproot-friendly and could easily be added in a soft fork to the existing
> SegWitv1 Script.
>
> ## Embedding covenant data in P2TR outputs
>
> We can take advantage of the double-commitment structure of taproot
> outputs (that is, committing to both a public key and a Merkle tree of
> scripts) to compactly encode both the covenant and the state transition
> rules inside taproot outputs.
>
> The idea is to replace the internal pubkey Q with a key Q? obtained by
> tweaking Q with the covenant data (the same process that is used to commit
> to the root of the taptree). More precisely, if d is the data committed to
> the covenant, the covenant-data-augmented internal key Q? is defined as:
>
>     Q? = Q + int(hashTapCovenantData(Q || h_{data}))G
>
> where h_{data} is the sha256-hash of the covenant data. It is then easy to
> prove that the point is constructed in this way, by repeating the
> calculation.
>
> If there is no useful key path spend, similarly to what is suggested in
> BIP-0341 [5] for the case of scripts with no key path spends, we can use
> the NUMS point:
>     H =
> lift_x(0x0250929b74c1a04954b78b4b6035e97a5e078a5a0f28ec96d547bfee9ace803ac0).
>
> TODO: please double check if the math above is sound.
>
> ## Changes to Script
>
> The following might be some minimal new opcodes to add for taproot
> transactions in order to enable the construction above. This is a very
> preliminary proposal, and not yet complete nor correct.
>
> - OP_SHA256CAT: returns the SHA256 hash of the concatenation of the second
> and the first (top) element of the stack. (redundant if OP_CAT is enabled,
> even just on operands with total length up to 64 bytes)
> - OP_CHECKINPUTCOVENANTVERIFY: let x, d be the two top elements of the
> stack; behave like OP_SUCCESS if any of x and d is not exactly 32 bytes;
> otherwise, check that the x is a valid x-only pubkey, and the internal
> pubkey P is indeed obtained by tweaking lift_x(x) with d.
> - OP_INSPECTNUMINPUTS, OP_INSPECTNUMOUTPUTS, OP_INSPECTINPUTVALUE and
> OP_INSPECTOUTPUTVALUE - opcodes to push number on the stack of
> inputs/outputs and their amounts.
> - OP_CHECKOUTPUTCOVENANTVERIFY: given a number out_i and three 32-byte
> hash elements x, d and taptree on top of the stack, verifies that the
> out_i-th output is a P2TR output with internal key computed as above, and
> tweaked with taptree. This is the actual covenant opcode.
>
> TODO:
>
> - Many contracts need parties to provide additional data; simply passing
> it via the witness faces the problem that it could be malleated. Therefore,
> a way of passing signed data is necessary. One way to address this problem
> could be to add a commitment to the data in the annex, and add an opcode to
> verify such commitment. Since the annex is covered by the signature, this
> removes any malleability. Another option is an OP_CHECKSIGFROMSTACK opcode,
> but that would cost an additional signature check.
> - Bitcoin numbers in current Script are not large enough for amounts.
>
> Other observations:
>
> - OP_CHECKINPUTCOVENANTVERIFY and OP_CHECKOUTPUTCOVENANTVERIFY could have
> a mode where x is replaced with a NUMS pubkey, for example if the first
> operand is an empty array of bytes instead of a 32 byte pubkey; this saves
> about 31 bytes when no internal pubkey is needed (so about 62 bytes for a
> typical contract transition using both opcodes)
> - Is it worth adding other introspection opcodes, for example
> OP_INSPECTVERSION, OP_INSPECTLOCKTIME? See Liquid's Tapscript Opcodes [6].
> - Is there any malleability issue? Can covenants ?run? without signatures,
> or is a signature always to be expected when using spending conditions with
> the covenant encumbrance? That might be useful in contracts where no
> signature is required to proceed with the protocol (for example, any party
> could feed valid data to the bisection protocol above).
> - Adding some additional opcodes to manipulate stack elements might also
> bring performance improvements in applications (but not strictly necessary
> for feasibility).
>
> Remark: the additional introspection opcodes available in Blockstream
> Liquid [6] do indeed seem to allow MATT covenants; in fact, the opcodes
> OP_CHECKINPUTCOVENANTVERIFY and OP_CHECKOUTPUTCOVENANTVERIFY could be
> replaced by more general opcodes like the group {OP_TWEAKVERIFY,
> OP_INSPECTINPUTSCRIPTPUBKEY, OP_PUSHCURRENTINPUTINDEX,
> OP_INSPECTOUTPUTSCRIPTPUBKEY }.
>
> ### Variant: bounded recursivity
>
> In the form described above, the covenant essentially allows fully
> recursive constructions (an arbitrary depth of the covenant execution tree
> is in practice equivalent to full recursion).
>
> If recursivity is not desired, one could modify the covenants in a way
> that only allows a limited depth: a counter could be attached to the
> covenant, with the constraint that the counter must be decreased for
> OP_CHECKOUTPUTCOVENANTVERIFY. That would still allow arbitrary fraud proofs
> as long as the maximum depth is sufficient.
>
> However, that would likely reduce its utility and prevent certain
> applications where recursivity seems to be a requirement.
>
> The full exploration of the design space is left for future research.
>
>
> # Applications
>
> This section explores some of the potential use cases of the techniques
> presented above. The list is not exhaustive.
>
> Given the generality of fraud proofs, some variant of every kind of smart
> contracts or layer two construction should be possible with MATT covenants,
> although the additional requirements (for example the capital lockup and
> the challenge period delays) needs to be accurately considered; further
> research is necessary to assess for what applications the tradeoffs are
> acceptable.
>
> ## State channels
>
> A state channel is a generalization of a payment channel where,
> additionally to the balance at the end of each channel, some additional
> state is stored. The state channel also specifies what are the rules on how
> to update the channel?s state.
>
> For example, two people might play a chess game, where the state encodes
> the current configuration of the board. The valid state transitions
> correspond to the valid moves; and, once the game is over, the winner takes
> a specified amount of the channel?s money.
>
> With eltoo-style updates, such a game could be played entirely off-chain,
> as long as both parties are cooperating (by signing the opponent?s state
> update).
>
> The role of the blockchain is to guarantee that the game can be moved
> forward and eventually terminated in case the other party does not
> cooperate.
>
> In stateful blockchain, this is simply achieved by publishing the latest
> state (Merkleized or not) and then continuing the entire game on-chain.
> This is expensive, especially if the state transitions require some complex
> computation.
>
> An alternative that avoids moving computations on-chain is the use of a
> challenge-response protocol, as sketched above.
>
> Similarly to the security model of lightning channels, an honest party can
> always win a challenge under the honest-majority of miners. Therefore, it
> is game-theoretically losing to attempt cheating in a channel.
>
> ## CoinPool
>
> Multiparty state channels are possible as well; therefore, constructions
> like CoinPool [7] should be possible, enabling multiple parties to share a
> single UTXO.
>
> ## Zero knowledge proofs in L2 protocols
>
> Protocols based on ZK-proofs require the blockchain to be the verifier;
> the verifier is a function that takes a zero-knowledge proof and returns
> true/false based on its correctness.
>
> Instead of an OP_STARK operator in L1, one could think of compiling the
> OP_STARK as the function f in the protocol above.
>
> Note that covenants with a bounded ?recursion depth? are sufficient to
> express OP_STARK, which in turns imply the ability to express arbitrary
> functions within contracts using the challenge protocol.
>
> One advantage of this approach is that no new cryptographic assumptions
> are added to bitcoin?s layer 1 even if OP_STARK does require it; moreover,
> if a different or better OP_STARK2 is discovered, the innovation can reach
> layer 2 contracts without any change needed in layer 1.
>
> ## Optimistic rollups
>
> John Light recently posted a research report on how Validity Rollups could
> be added to bitcoin?s layer 1 [8]. While no exact proposal is pushed
> forward, the suggested changes required might include a combination of
> recursive covenants, and specific opcodes for validity proof verification.
>
> Fraud proofs are the core for optimistic rollups; exploring the
> possibility of implementing optimistic rollups with MATT covenants seems a
> promising direction. Because of the simplicity of the required changes to
> Script, this might answer some of the costs and risks analyzed in the
> report, while providing many of the same benefits. Notably, no novel
> cryptography needs to become part of bitcoin?s layer 1.
>
> Optimistic Rollups would probably require a fully recursive version of the
> covenant (while fraud proofs alone are possible with a limited recursion
> depth).
>
>
> # Acknowledgments
>
> Antoine Poinsot suggested an improvement to the original proposed covenant
> opcodes, which were limited to taproot outputs without a valid key-path
> spend.
>
> The author would also like to thank catenocrypt, Antoine Riard, Ruben
> Somsen and the participants of the BTCAzores unconference for many useful
> discussions and comments on early versions of this proposal.
>
>
> # References
>
> The core idea of the bisection protocol appears to have been independently
> rediscovered multiple times. In blockchain research, it is at the core of
> fraud proof constructions with similar purposes, although not focusing on
> bitcoin or covenants; see for example:
>
> - Harry Kalodner et al. ?Arbitrum: Scalable, private smart contracts.? ?
> 27th USENIX Security Symposium. 2018.
> https://www.usenix.org/system/files/conference/usenixsecurity18/sec18-kalodner.pdf
> - Jason Teutsch and Christian Reitwiessner. ?A scalable verification
> solution for blockchains? ? TrueBit protocol. 2017.
> https://people.cs.uchicago.edu/~teutsch/papers/truebit.pdf
>
> The same basic idea was already published prior to blockchain use cases;
> see for example:
>
> Ran Canetti, Ben Riva, and Guy N. Rothblum. ?Practical delegation of
> computation using multiple servers.? ? Proceedings of the 18th ACM
> conference on Computer and communications security. 2011. http://diyhpl.us/~bryan/papers2/bitcoin/Practical%20delegation%20of%20computation%20using%20multiple%20servers.pdf
>
>
>
> # Footnotes
>
> [1] - https://btcazores.com
> [2] - https://github.com/bitcoin/bips/blob/master/bip-0341.mediawiki
> [3] -
> https://bitcointalk.org/index.php?topic=1427885.msg14601127#msg14601127
> [4] - https://vitalik.ca/general/2019/12/26/mvb.html
> [5] -
> https://github.com/bitcoin/bips/blob/master/bip-0341.mediawiki#constructing-and-spending-taproot-outputs
> [6] -
> https://github.com/ElementsProject/elements/blob/master/doc/tapscript_opcodes.md
> [7] - https://coinpool.dev/v0.1.pdf
> [8] - https://bitcoinrollups.org
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221111/cc91511d/attachment-0001.html>

From bitcoin-dev at wuille.net  Sat Nov 12 03:23:16 2022
From: bitcoin-dev at wuille.net (Pieter Wuille)
Date: Sat, 12 Nov 2022 03:23:16 +0000
Subject: [bitcoin-dev] Refreshed BIP324
In-Reply-To: <wDqcIVw-YGTsjdf5M2GO9NNRl_UQuBeka2CUQUyQ329u6u-o7RabW_7S4FD3EDfk02kUczb3bXf8LtHhKLtx773UhQ7djKOl-JPOIrXqBSc=@wuille.net>
References: <56677685-619a-691f-d5bc-54b69fdb6ed2@bip324.com>
 <zxv58iXZ73hf9ge8S0QLTanW-uLzaWjNtMHuKONP9hrqS5RhwitxzfVaMH8hbi3yImgNrKme3lCuDcHYKkpxEQHyGZZHJ8xtReOcnAx3o4g=@wuille.net>
 <Y2nK99fHUKxbPHmw@erisian.com.au>
 <wDqcIVw-YGTsjdf5M2GO9NNRl_UQuBeka2CUQUyQ329u6u-o7RabW_7S4FD3EDfk02kUczb3bXf8LtHhKLtx773UhQ7djKOl-JPOIrXqBSc=@wuille.net>
Message-ID: <JXfTBjsA71dHE3h9wkxnWXANrwTbMADO4s2w34gEvMbiduKu4PEt5t-KA3EAIz-Xs4urjBHZ15NDFZST2a7e0x_NqyJymUnEORuTp3SNfMs=@wuille.net>

Another idea...

On Thursday, November 10th, 2022 at 4:23 PM, Pieter Wuille via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:

> On Thursday, November 3rd, 2022 at 1:53 PM, Murch wrote:
> 
> > From what I understand we'll have about 35 message types on the network
> > with the addition of BIP324. 256 possible IDs sounds like plenty room to
> > grow, but perhaps we can be a bit more conservative:
> > 
> > We could use the first bit to signal a 2-byte message ID. That allows us
> > to express 128 IDs with 1 byte, but if we need more, we get a total of
> > 2^15 IDs across 2 bytes.
> 
> Yeah, effectively treating the first 1 or 2 bytes as a simple variable
> length integer is a nice way of increasing the space at low cost.

The above would really result in having two separate variable-length encodings:
* First byte 1-12 to signify length of alphabetic command
* Otherwise first bit to signify length of short command

I think we can just merge the two and have a single variable-length command structure that can be used for both: command encodings are 1 to 12 bytes, each byte's top bit indicating whether another byte follows (the top bit of byte 11 has no special meaning).

This means:
* Every alphabetic command of L characters becomes L bytes.
* 102 non-alphabetic 1-byte commands can be assigned.
* 15708 non-alphabetic 2-byte commands can be assigned.
* etc

So this gives a uniform space which commands can be assigned from, and there is no strict need for thinking of the short-binary and long-alphabetic commands as distinct. In v2, some short ones would be treated as aliases for old long-alphabetic ones. But new commands could also just be introduced as short ones only (even in v1).

WDYT?

Cheers,

-- 
Pieter





From salvatore.ingala at gmail.com  Sat Nov 12 15:04:20 2022
From: salvatore.ingala at gmail.com (Salvatore Ingala)
Date: Sat, 12 Nov 2022 16:04:20 +0100
Subject: [bitcoin-dev] Merkleize All The Things
In-Reply-To: <CALZpt+GVe0XTdWqV=LAcOj=nq+k2DEFqc+sKyxAujLDBR7bYbQ@mail.gmail.com>
References: <CAMhCMoH9uZPeAE_2tWH6rf0RndqV+ypjbNzazpFwFnLUpPsZ7g@mail.gmail.com>
 <CALZpt+GVe0XTdWqV=LAcOj=nq+k2DEFqc+sKyxAujLDBR7bYbQ@mail.gmail.com>
Message-ID: <CAMhCMoEONv3jriBU3qwm0pt75iF_sgra1H2Z4rOF8u+e7hs_cw@mail.gmail.com>

Hi Antoine,
It appears that my explanation of the relationship between the covenant and
the bisection protocol is still unclear; I'll do my best to clarify.

The bisection's Merkle tree never ends up on-chain, in any form. Therefore,
a bigger computation does not end up in a bigger witness size, which is key
to the scalability of the approach. Only in the case of a challenge, it
will result in a (logarithmically) longer chain of transactions to resolve
it. This chain of transactions could be mapped to a root-to-leaf path in
the Merkle tree of the computation trace.

The actual computation trace (and the corresponding Merkle tree) is only
computed by the parties when they execute the computation.
What's in the tapleaves is only the valid transitions at the current state
of the protocol; that is, the valid transitions in the Finite State Machine
(and possibly other valid exit conditions that remove the covenant
encumbrance, if any).

The bisection protocol only makes sense as a step in a larger protocol that
makes use of it.

Perhaps presenting the protocol in a less-than-general case might help to
understand it. So let's play a simpler game using a protocol that includes
a fraud proof.

Alice claims that she knows how to multiply by 256, while Bob doesn't
believe her. So they make a bet: they each commit 1 coin; then Bob choses a
number x; then Alice computes y = 256*x by doubling x eight times
(expensive multiplications were disabled in a tragic DDoS accident), and
publishes the result y. Bob independently computes 256 * x (he has a friend
who is a mathematician, he'll know how to do it). If the result is not y,
Bob will start a challenge; otherwise, Alice wins and takes the money.

(The example is of course artificial, as redoing the computation in Script
is cheaper than executing the fraud proof in this case!)

What follows is an actual execution of the protocol. In the following, each
[Si] is a UTXO corresponding to some possible FSM node, starting with the
S0, the UTXO with 1+1 = 2 coins. Each line with "-" is a possible
transition (script in the taptree), specifying what is the next FSM node
after the "==>" symbol; the encumbrance in the scripts enforce that the
state of the next UTXO is updated correctly (details omitted below), and
any other necessary conditions to ensure the integrity of the protocol.


=====


[S0]: Initial UTXO
  - only Bob can spend, he must choose his number x ==> S1

[S1; state: x]:
  - only Alice can spend, she publishes her answer y ==> S2

[S2. state: x, y]:
  - after 1 day: Alice won, she can take the money     // Happy case!
Usually that's the end
  - Bob disagrees with the answer, post z as his answer. ==> S3

The challenge starts here! Let's put some actual numbers. x = 2; y = 508; z
= 512.

This is what Alice computed:

  2 => 4 => 8 => 16 => 32 => 64 => 127 => 254 => 508

This is what Bob computed:

  2 => 4 => 8 => 16 => 32 => 64 => 128 => 256 => 512

At this time, we don't know who is right. They both built a tree that looks
like this (ASCII art only working in fixed-width font):

             ___H18___
            /         \
           /           \
        H14             H58
        / \             / \
       /   \           /   \
      /     \         /     \
    H12     H34     H56     H78
    / \     / \     / \     / \
  H1  H2  H3  H4  H5  H6  H7  H8

Remember that each internal node commits to: the state of the computation
before the leftmost leaf in the subtree, the state after the rightmost
leaf, and the hash of sub-trace for the sub-tree. Each leaf just commits to
that intermediate computation step (and the operation, which here is always
"double the input"). For example, H4 commits to "16 => 32" according to
both Alice's and Bob's computation traces.

(From our privileged point of view, we can foresee that the earliest
disagreement is on the 6th step of the computation: "64 => 127" according
to Alice, "64 => 128" according to Bob).

Let's denote h_{A;18} (resp. h_{B;18}) all the information committed to in
the node H18, according to Alice (resp. Bob). Similarly for all the other
nodes.

[S3. state: x, y, z]: Challenge starts!
  - Alice posts the root of her computation trace h_{A;18} ==> S4

[S4. state: x, y, z, h_{A;18}]
  - Bob posts the root of her computation trace h_{B;18} ==> S5

Since they disagree, it must be the case that h_{A;18} != h_{B;18}.

[S5. state: x, y, z, h_{A;18}, h_{B;18}]
  - Alice opens the commitment h_{A;18}, by revealing H14 and H58
(according to her) ==> S6

Note that in this last transition (going to S6), the covenant enforces that
the child commitments are compatible: the transition is only valid if the
starting state of the computation according to h_{A;14} is compatible with
h_{A;18} (that is, it's equal to x); similarly the end state of the
computation in h_{A;58} must be y, and h_{A;18} can be recomputed from the
data provided (ensuring the integrity of the Merkle tree).
This is true for all the commitment openings below.

[S6. state: x, y, z, (h_{A;14}, h_{A;58}), h_{B;18}]
  - Bob opens the commitment h_{B;18}, by revealing H14 and H58 (according
to him) ==> S7

[S7. state: x, y, z, (h_{A;18}, h_{A;14}, h_{A;58}), (h_{B;18}, h_{B;14},
h_{B;58})]
  // We now need to choose a child where there is disagreement.
  // If both children don't match, iterate on the left child.
  - Anyone: if h_{A;14} == h_{B;14} ==> S8
  - Anyone: if h_{A;14} != h_{B;14} ==> Continue challenge on H14 //
Non-executed FSM cases omitted for brevity

At this point, the disagreement over the root is settled: Alice and Bob
agree on the first half of the computation, but they disagree over the
second half. Therefore, in S8 the protocol continues over H58.

[S8. state: h_{A;58}, h_{B;58}]
  // This is analogous to S5, just with half of the computation steps.
  - Alice opens the commitment h_{A;58}, by revealing H56 and H78
(according to her) ==> S9

[S9. state: (h_{A;56}, h_{A;78}), h_{B;58}]
  - Bob opens the commitment h_{B;58}, by revealing H56 and H78 (according
to him) ==> S10

[S10. state: (h_{A;56}, h_{A;78}), (h_{B;56}, h_{B;78})]
  // Like S7, iterate on a disagreeing child
  - Anyone: if h_{A;56} == h_{B;56} ==> continue challenge on H78 //
Non-executed FSM cases omitted for brevity
  - Anyone: if h_{A;56} != h_{B;56} ==> S11

Getting there! The subtree now commits to just two computation steps.

[S11. state: h_{A;56}, h_{B;56}]
  // This is analogous to S5 and S8.
  - Alice opens the commitment h_{A;56}, by revealing H5 and H6 (according
to her) ==> S12

[S12. state: (h_{A;5}, h_{A;6}), h_{B;56}]
  - Bob opens the commitment h_{B;56}, by revealing H5 and H6 (according to
him) ==> S13

[S13. state: (h_{A;5}, h_{A;6}), (h_{B;5}, h_{B;6})]
  // Like S7 and S10, iterate on a disagreeing child
  - Anyone: if h_{A;5} == h_{B;5} ==> S14
  - Anyone: if h_{A;5} != h_{B;5} ==> continue challenge on H5 //
Non-executed FSM cases omitted for brevity

We are now at the crucial stage: the commitment corresponds to a leaf of
the computation trace Merkle tree.

[S14. state: h_{A;6}, h_{B;6}]
  - Alice can take all the money if she can open h_{A;6} to a correct "n =>
n + n" computation step
  - Bob can take all the money if he can open h_{B;6} to a correct "n => n
+ n" computation step

The challenge now ends quickly: Bob's hash commits to the computation step
"64 => 128".
Instead, Alice's step is the incorrect "64 => 127".

It's not difficult to convince oneself that, as long as the hash function
is collision-free and the computation is deterministic, only the honest
party can provide correct data for this final step.
(The bisection protocol can't do anything useful if both parties provide
incorrect data; arguably, that is not a very interesting scenario!)

Crucially, the operation in the single step is so simple that Script can
verify it.

=====

If you read until here: thank you, this was the first execution of a
challenge in MATT covenants!

Of course, there are a few things missing in the above protocol:
- Bonds should be added in order to incentivize cooperation.
- The omitted FSM steps (corresponding to branches of the challenge that
were never taken) need to be computed nonetheless when preparing the
covenant.
- Additional transitions should be added at every step (always allow
cooperative behavior; forfait after a timeout if it's the other party's
turn).
- Some of those consecutive "forced" steps can be contracted in a single
step; I felt this sequence is more logical to explain the protocol, but
implementations would want to optimize it.

Yet, _all_ the code and scripts of the bisection protocol are independent
of the actual execution, and can be precomputed (bottom up, starting from
the leaves) before the initial covenant is created - therefore, before x, y
and z are chosen and committed to.

While here each leaf is doing the same operation (doubling a number), it is
well-known that arbitrary computation can be decomposed in very simple
elementary functions (like NAND gates, if we want to be minimalistic).

I hope this helps in clarifying the role of the bisection protocol in smart
contracts using MATT covenants.

Best,
Salvatore
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221112/b63202de/attachment.html>

From nothingmuch at woobling.org  Sat Nov 12 18:52:31 2022
From: nothingmuch at woobling.org (Yuval Kogman)
Date: Sat, 12 Nov 2022 20:52:31 +0200
Subject: [bitcoin-dev] Refreshed BIP324
In-Reply-To: <JXfTBjsA71dHE3h9wkxnWXANrwTbMADO4s2w34gEvMbiduKu4PEt5t-KA3EAIz-Xs4urjBHZ15NDFZST2a7e0x_NqyJymUnEORuTp3SNfMs=@wuille.net>
References: <56677685-619a-691f-d5bc-54b69fdb6ed2@bip324.com>
 <zxv58iXZ73hf9ge8S0QLTanW-uLzaWjNtMHuKONP9hrqS5RhwitxzfVaMH8hbi3yImgNrKme3lCuDcHYKkpxEQHyGZZHJ8xtReOcnAx3o4g=@wuille.net>
 <Y2nK99fHUKxbPHmw@erisian.com.au>
 <wDqcIVw-YGTsjdf5M2GO9NNRl_UQuBeka2CUQUyQ329u6u-o7RabW_7S4FD3EDfk02kUczb3bXf8LtHhKLtx773UhQ7djKOl-JPOIrXqBSc=@wuille.net>
 <JXfTBjsA71dHE3h9wkxnWXANrwTbMADO4s2w34gEvMbiduKu4PEt5t-KA3EAIz-Xs4urjBHZ15NDFZST2a7e0x_NqyJymUnEORuTp3SNfMs=@wuille.net>
Message-ID: <CAAQdECCibMp+=SfmNW0LfJX=0WZtM5TMw6qWuS9qVUHcvJTBOg@mail.gmail.com>

On Sat, 12 Nov 2022, 11:01 Pieter Wuille via bitcoin-dev, <
bitcoin-dev at lists.linuxfoundation.org> wrote:

> I think we can just merge the two and have a single variable-length
> command structure that can be used for both: command encodings are 1 to 12
> bytes, each byte's top bit indicating whether another byte follows (the top
> bit of byte 11 has no special meaning).
>
...

> So this gives a uniform space which commands can be assigned from, and
> there is no strict need for thinking of the short-binary and
> long-alphabetic commands as distinct.In v2, some short ones would be
> treated as aliases for old long-alphabetic ones.


This seems a bit dubious, but since command names are ASCII strings
reversing the meaning of the top bit so that 0 signifies a following byte
would allow the alphabetic commands to be reinterpreted as non-alphabetic,
so the space no longer needs to be a disjoint union of two sub-spaces which
arguably takes the "no [...] need for thinking of [them] as distinct" logic
a little bit bit farther.

The main downsides are that this does nothing to re-assign shorter codes to
existing commands, and secondly that even the non-alphabetic code path
completely supersedes the alphabetic one, the numerical values are up to 85
or 86 bits wide, which is not a reasonable word size. Perhaps this is not a
concern since as far as I know there are no collisions in the first 9 bytes
of existing commands, and constrain the non-alphabetic representation to 9
bytes would leave the last top bit free, so the space would be isomorphic
to {0,1}^64.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221112/f00d8cfd/attachment-0001.html>

From antoine.riard at gmail.com  Mon Nov 14 02:21:16 2022
From: antoine.riard at gmail.com (Antoine Riard)
Date: Sun, 13 Nov 2022 21:21:16 -0500
Subject: [bitcoin-dev] Bitcoin Contracting Primitives WG 1st Meeting,
 Tuesday 15 Nov. 18:00 UTC
In-Reply-To: <CALZpt+EygPsez0c84Yfmc6h+L7Ji8C3zE_E=EzPzLh4XWNHvZA@mail.gmail.com>
References: <CALZpt+EygPsez0c84Yfmc6h+L7Ji8C3zE_E=EzPzLh4XWNHvZA@mail.gmail.com>
Message-ID: <CALZpt+E0PSc_DD39E1-3hGYvpw3ok91Nc5DLTTh9FPdOKF_TYg@mail.gmail.com>

Reminder: this is happening this _upcoming_ Tuesday.

Looking forward to the first session, listening to everyone's thoughts
about what could be the scope discussed by this new community process:
anyprevout, recursive covenants, introspection, new malleability flags, ZK
rollups, new contracting protocols and many more ideas!

Best,
Antoine

Le lun. 31 oct. 2022 ? 20:47, Antoine Riard <antoine.riard at gmail.com> a
?crit :

> Hi list,
>
> After I have been asked offline the exact date when those meetings were
> actually starting, I'm proposing Tuesday 15th November at 18:00 UTC, i.e 2
> weeks from now. Thinking about a monthly frequency for now (from my
> experience attending dlcspecs/lighnting specs meetings/core dev meetings in
> the past, weekly sounds too much, biweekly/monthly sounds better though
> dunno yet good frequency).
>
> If there is an incompatibility with another public engineering meeting in
> the Bitcoin space, let it know. We can talk about a better schedule during
> the 1st session [0].
>
> Communication venue is #bitcoin-contracting-primitives-wg on Libera Chat
> [1]. Feel free to lurk already and ask questions.
>
> No consistent agenda beyond listening to every attendee their
> expectations, ideas, subjects of interests they would like to see happening
> with this new covenants/contracting primitives R&D process.
>
> If you have been working on a contracting
> protocols/side-chains/rollups/other use-cases that could benefit from
> extended Bitcoin contracting primitives, feel free to open an issue there:
> https://github.com/ariard/bitcoin-contracting-primitives-wg/issues
>
> Let it know if you have more questions or feedback.
>
> Cheers,
> Antoine
>
> [0] It would be great to have a schedule inclusive of most timezones we
> can, 18:00 UTC might be too early for Asian and Oceanic ones. Later, we
> start to be exclusive towards contributors in Eastern Europe.
>
> [1] There have been more voices suggesting jitsi/audio-based meetings
> rather than IRC. It's a cool format too, though coming with trade-offs.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221113/5b535a7c/attachment.html>

From aj at erisian.com.au  Tue Nov 15 05:36:08 2022
From: aj at erisian.com.au (Anthony Towns)
Date: Tue, 15 Nov 2022 15:36:08 +1000
Subject: [bitcoin-dev] Announcement: Full-RBF Miner Bounty
In-Reply-To: <Y2qc7Ubc5xtJhxGw@petertodd.org>
References: <Y2I3w8O5X55sD/3C@petertodd.org> <Y2qc7Ubc5xtJhxGw@petertodd.org>
Message-ID: <Y3MlSE7AWkBgiCyr@erisian.com.au>

On Tue, Nov 08, 2022 at 01:16:13PM -0500, Peter Todd via bitcoin-dev wrote:
> FYI I've gotten a few hundred dollars worth of donations to this effort, and
> have raised the reward to about 0.02 BTC, or $400 USD at current prices.

Seems like this has been mostly claimed (0.014btc / $235, 9238sat/vb):

https://mempool.space/tx/397dcbe4e95ec40616e3dfc4ff8ffa158d2e72020b7d11fc2be29d934d69138c

The block it was claimed in seems to have been about an hour after the
default mempool filled up:

https://twitter.com/murchandamus/status/1592274621977477120

That block actually seems to have included two
alice.btc.calendar.opentimestamps.org txs, the other paying $7.88
(309sat/vb):

https://mempool.space/tx/ba9670109a6551458d5e1e23600c7bf2dc094894abdf59fe7aa020ccfead07cf

Timeline (utc) to me looks like:

 - 13:12 - block 763148 is mined: last one that had a min fee < 1.5sat/vb
 - 13:33 - f503868c64d454c472859b793f3ee7cdc8f519c64f8b1748d8040cd8ce6dc6e1
           is announced and propogates widely (1.2sat/vb)
 - 18:42 - 746daab9bcc331be313818658b4a502bb4f3370a691fd90015fabcd7759e0944
           is announced and propogates widely (1.2sat/vb)
 - 21:52 - ba967010 tx is announced and propogates widely, since
           conflicting tx 746daab9 has been removed from default
	   mempools
 - 21:53 - murch tweets about default mempool filling up
 - 22:03 - 397dcbe4 tx is announced and propogates widely, since
           conflicting tx f503868 has already been removed from default
	   mempools
 - 22:35 - block 763189 is mined
 - 22:39 - block 763190 is mined
 - 23:11 - block 763191 is mined
 - 23:17 - block 763192 is mined including 397dcbe4

miningpool.observer reports both 397dcbe4 and ba967010 as missing in the
first three blocks, and gives similar mempool ages for those txs to what
my logs report:

  https://miningpool.observer/template-and-block/0000000000000000000436aba59d8430061e0e50592215f7f263bfb1073ccac7
  https://miningpool.observer/template-and-block/00000000000000000005600404792bacfd8a164d2fe9843766afb2bfbd937309
  https://miningpool.observer/template-and-block/00000000000000000004a3073f58c9eae40f251ea7aeaeac870daeac4b238fd1

That presumably means those pools (AntPool twice and "unknown") are
running with large mempools that didn't kept the earlier 1.2sat/vb txs.

The txs were mined by Foundry:

  https://miningpool.observer/template-and-block/00000000000000000001382a226aedac822de80309cca2bf1253b35d4f8144f5

This seems to be pretty good evidence that we currently don't have any
significant hashrate mining with fullrbf policies (<0.5% if there was a
high fee replacement available prior to every block having been mined),
despite the bounty having been collected.

Cheers,
aj

From pete at petertodd.org  Tue Nov 15 14:43:25 2022
From: pete at petertodd.org (Peter Todd)
Date: Tue, 15 Nov 2022 09:43:25 -0500
Subject: [bitcoin-dev] Announcement: Full-RBF Miner Bounty
In-Reply-To: <Y3MlSE7AWkBgiCyr@erisian.com.au>
References: <Y2I3w8O5X55sD/3C@petertodd.org> <Y2qc7Ubc5xtJhxGw@petertodd.org>
 <Y3MlSE7AWkBgiCyr@erisian.com.au>
Message-ID: <Y3OljVGQbZ/Wj8T6@petertodd.org>

On Tue, Nov 15, 2022 at 03:36:08PM +1000, Anthony Towns via bitcoin-dev wrote:
> On Tue, Nov 08, 2022 at 01:16:13PM -0500, Peter Todd via bitcoin-dev wrote:
> > FYI I've gotten a few hundred dollars worth of donations to this effort, and
> > have raised the reward to about 0.02 BTC, or $400 USD at current prices.
> 
> Seems like this has been mostly claimed (0.014btc / $235, 9238sat/vb):

I'm turning it back on when (if) the mempool settles down. I've got more than
enough donations to give another run at it (the majority was donated privately
FWIW). There's a risk of the mempool filling up again of course; hard to avoid
that.

Right now of course it's really easy to double spend with the obvious
low-fee/high-fee method as the min relay fee keeps shifting.

> https://mempool.space/tx/397dcbe4e95ec40616e3dfc4ff8ffa158d2e72020b7d11fc2be29d934d69138c
> 
> The block it was claimed in seems to have been about an hour after the
> default mempool filled up:
> 
> https://twitter.com/murchandamus/status/1592274621977477120
> 
> That block actually seems to have included two
> alice.btc.calendar.opentimestamps.org txs, the other paying $7.88
> (309sat/vb):
> 
> https://mempool.space/tx/ba9670109a6551458d5e1e23600c7bf2dc094894abdf59fe7aa020ccfead07cf

The second is because I turned down the full-rbf reward to more normal fee
levels. There's also another full-rbf double-spend from the Bob calendar, along
the same lines: 7e76b351009326a574f3120164dbbe6d85e07e04a7bbdc40f0277fcb008d2cd2

I double-spent the txin of the high fee tx that got mined. But I mistakenly had
RBF enabled in that double-spend, so while it propagated initially, I believe
it was replaced when something (someone?) rebroadcast the high-fee 397dcb tx.

> Timeline (utc) to me looks like:
> 
>  - 13:12 - block 763148 is mined: last one that had a min fee < 1.5sat/vb
>  - 13:33 - f503868c64d454c472859b793f3ee7cdc8f519c64f8b1748d8040cd8ce6dc6e1
>            is announced and propogates widely (1.2sat/vb)
>  - 18:42 - 746daab9bcc331be313818658b4a502bb4f3370a691fd90015fabcd7759e0944
>            is announced and propogates widely (1.2sat/vb)
>  - 21:52 - ba967010 tx is announced and propogates widely, since
>            conflicting tx 746daab9 has been removed from default
> 	   mempools
>  - 21:53 - murch tweets about default mempool filling up
>  - 22:03 - 397dcbe4 tx is announced and propogates widely, since
>            conflicting tx f503868 has already been removed from default
> 	   mempools

Is that 22:03 time for 397 from your node's logs? It was originally announced
hours earlier. From one of my full-rbf nodes:

    2022-11-14T14:08:37Z [mempool] replacing tx 764867062b67fea61810c3858d587da83a28290545e882935a32285028084317 with 397dcbe4e95ec40616e3dfc4ff8ffa158d2e72020b7d11fc2be29d934d69138c for 0.00468 additional fees, -1 delta bytes

>  - 22:35 - block 763189 is mined
>  - 22:39 - block 763190 is mined
>  - 23:11 - block 763191 is mined
>  - 23:17 - block 763192 is mined including 397dcbe4
> 
> miningpool.observer reports both 397dcbe4 and ba967010 as missing in the
> first three blocks, and gives similar mempool ages for those txs to what
> my logs report:
> 
>   https://miningpool.observer/template-and-block/0000000000000000000436aba59d8430061e0e50592215f7f263bfb1073ccac7
>   https://miningpool.observer/template-and-block/00000000000000000005600404792bacfd8a164d2fe9843766afb2bfbd937309
>   https://miningpool.observer/template-and-block/00000000000000000004a3073f58c9eae40f251ea7aeaeac870daeac4b238fd1
> 
> That presumably means those pools (AntPool twice and "unknown") are
> running with large mempools that didn't kept the earlier 1.2sat/vb txs.

To be clear, you think that AntPool and that other exchange is running with a
larger than normal max mempool size limit? You mean those miners *did* keep the
earlier 1.2sat/vb tx?

> The txs were mined by Foundry:
> 
>   https://miningpool.observer/template-and-block/00000000000000000001382a226aedac822de80309cca2bf1253b35d4f8144f5
> 
> This seems to be pretty good evidence that we currently don't have any
> significant hashrate mining with fullrbf policies (<0.5% if there was a
> high fee replacement available prior to every block having been mined),
> despite the bounty having been collected.

Oh, we can put much lower bounds on that. I've been running OTS calendars with
full-rbf replacements for a few months without clear evidence of a full-rbf
replacement.  While there was good reason to think some miners were mining
full-rbf before a few years back, they probably didn't bother to reapply their
patches each upgrade. `mempoolfullrbf=1` is much simpler to use.

-- 
https://petertodd.org 'peter'[:-1]@petertodd.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221115/09699e14/attachment.sig>

From alicexbt at protonmail.com  Tue Nov 15 22:36:48 2022
From: alicexbt at protonmail.com (alicexbt)
Date: Tue, 15 Nov 2022 22:36:48 +0000
Subject: [bitcoin-dev] Bitcoin Contracting Primitives WG 1st Meeting,
	Tuesday 15 Nov. 18:00 UTC
In-Reply-To: <CALZpt+E0PSc_DD39E1-3hGYvpw3ok91Nc5DLTTh9FPdOKF_TYg@mail.gmail.com>
References: <CALZpt+EygPsez0c84Yfmc6h+L7Ji8C3zE_E=EzPzLh4XWNHvZA@mail.gmail.com>
 <CALZpt+E0PSc_DD39E1-3hGYvpw3ok91Nc5DLTTh9FPdOKF_TYg@mail.gmail.com>
Message-ID: <KC6W2mW10GBn00XMNUJDUxp27BAOM94o1PE_CVpnMjKVLwPwLMiBQHCfNDZZqR619BMZJyq3hskVhK5T24Kr_v4MStTL4kx74z55qRU0bVY=@protonmail.com>

Hi Bitcoin Developers,

> Looking forward to the first session, listening to everyone's thoughts about what could be the scope discussed by this new community process: anyprevout, recursive covenants, introspection, new malleability flags, ZK rollups, new contracting protocols and many more ideas!

Wanted to add CTV: BIP-119 OP_CHECKTEMPLATEVERIFY if OP missed it. Easiest and best possible way to get covenants aka tx introspection with lot of research and development.

/dev/fd0

Sent with [Proton Mail](https://proton.me/) secure email.

------- Original Message -------
On Monday, November 14th, 2022 at 7:51 AM, Antoine Riard via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:

> Reminder: this is happening this _upcoming_ Tuesday.
> Looking forward to the first session, listening to everyone's thoughts about what could be the scope discussed by this new community process: anyprevout, recursive covenants, introspection, new malleability flags, ZK rollups, new contracting protocols and many more ideas!
> Best,
> Antoine
>
> Le lun. 31 oct. 2022 ? 20:47, Antoine Riard <antoine.riard at gmail.com> a ?crit :
>
>> Hi list,
>>
>> After I have been asked offline the exact date when those meetings were actually starting, I'm proposing Tuesday 15th November at 18:00 UTC, i.e 2 weeks from now. Thinking about a monthly frequency for now (from my experience attending dlcspecs/lighnting specs meetings/core dev meetings in the past, weekly sounds too much, biweekly/monthly sounds better though dunno yet good frequency).
>>
>> If there is an incompatibility with another public engineering meeting in the Bitcoin space, let it know. We can talk about a better schedule during the 1st session [0].
>>
>> Communication venue is #bitcoin-contracting-primitives-wg on Libera Chat [1]. Feel free to lurk already and ask questions.
>>
>> No consistent agenda beyond listening to every attendee their expectations, ideas, subjects of interests they would like to see happening with this new covenants/contracting primitives R&D process.
>>
>> If you have been working on a contracting protocols/side-chains/rollups/other use-cases that could benefit from extended Bitcoin contracting primitives, feel free to open an issue there: https://github.com/ariard/bitcoin-contracting-primitives-wg/issues
>>
>> Let it know if you have more questions or feedback.
>>
>> Cheers,
>> Antoine
>>
>> [0] It would be great to have a schedule inclusive of most timezones we can, 18:00 UTC might be too early for Asian and Oceanic ones. Later, we start to be exclusive towards contributors in Eastern Europe.
>>
>> [1] There have been more voices suggesting jitsi/audio-based meetings rather than IRC. It's a cool format too, though coming with trade-offs.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221115/ecc63e01/attachment.html>

From antoine.riard at gmail.com  Tue Nov 15 23:47:39 2022
From: antoine.riard at gmail.com (Antoine Riard)
Date: Tue, 15 Nov 2022 18:47:39 -0500
Subject: [bitcoin-dev] Bitcoin Contracting Primitives WG 1st Meeting,
 Tuesday 15 Nov. 18:00 UTC
In-Reply-To: <CALZpt+EygPsez0c84Yfmc6h+L7Ji8C3zE_E=EzPzLh4XWNHvZA@mail.gmail.com>
References: <CALZpt+EygPsez0c84Yfmc6h+L7Ji8C3zE_E=EzPzLh4XWNHvZA@mail.gmail.com>
Message-ID: <CALZpt+GMGFor6xFUW-549gf2t1kmM1j+uNzK1JBVv18Q0VXi=A@mail.gmail.com>

Hi list,

1st meeting did happen this afternoon with like ~10 attendees, we browsed
the covenant interests of everyone: state channels, universal settlement
layer, transaction introspection covenants, vaults/self-custody, MATT
covenants, logical label covenant like transaction inherited IDs,
congestion control, DLC and few more.

One of the goal of the process suggested by one of the attendee could be to
address "1) misunderstanding of the state of development and desire for
some covenant-style upgrade, 2) coordinating around goals, drawbacks and
overlap of different proposals and 3) helping to highlight consensus
building around the goals and mechanism to achieve them".

Next meeting aims to do a 360 degree panorama of all the known consistent
contracting primitives as well as the contracting protocols in an archiving
effort. If you have more contracting primitives to pin, feel free to
modify:
https://github.com/ariard/bitcoin-contracting-primitives-wg/tree/main/primitives

Frequency schedule is for now every month, staying on the 3rd Tuesday of
every month. I'll announce them on time on the mailing list.

Meetings log available here:
https://github.com/ariard/bitcoin-contracting-primitives-wg/blob/main/meetings/meetings-15-11.md

If you have more suggestions to improve the process, feel free to comment.

Best,
Antoine

Le lun. 31 oct. 2022 ? 20:47, Antoine Riard <antoine.riard at gmail.com> a
?crit :

> Hi list,
>
> After I have been asked offline the exact date when those meetings were
> actually starting, I'm proposing Tuesday 15th November at 18:00 UTC, i.e 2
> weeks from now. Thinking about a monthly frequency for now (from my
> experience attending dlcspecs/lighnting specs meetings/core dev meetings in
> the past, weekly sounds too much, biweekly/monthly sounds better though
> dunno yet good frequency).
>
> If there is an incompatibility with another public engineering meeting in
> the Bitcoin space, let it know. We can talk about a better schedule during
> the 1st session [0].
>
> Communication venue is #bitcoin-contracting-primitives-wg on Libera Chat
> [1]. Feel free to lurk already and ask questions.
>
> No consistent agenda beyond listening to every attendee their
> expectations, ideas, subjects of interests they would like to see happening
> with this new covenants/contracting primitives R&D process.
>
> If you have been working on a contracting
> protocols/side-chains/rollups/other use-cases that could benefit from
> extended Bitcoin contracting primitives, feel free to open an issue there:
> https://github.com/ariard/bitcoin-contracting-primitives-wg/issues
>
> Let it know if you have more questions or feedback.
>
> Cheers,
> Antoine
>
> [0] It would be great to have a schedule inclusive of most timezones we
> can, 18:00 UTC might be too early for Asian and Oceanic ones. Later, we
> start to be exclusive towards contributors in Eastern Europe.
>
> [1] There have been more voices suggesting jitsi/audio-based meetings
> rather than IRC. It's a cool format too, though coming with trade-offs.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221115/4c2070bf/attachment-0001.html>

From antoine.riard at gmail.com  Tue Nov 15 23:49:17 2022
From: antoine.riard at gmail.com (Antoine Riard)
Date: Tue, 15 Nov 2022 18:49:17 -0500
Subject: [bitcoin-dev] Bitcoin Contracting Primitives WG 1st Meeting,
 Tuesday 15 Nov. 18:00 UTC
In-Reply-To: <KC6W2mW10GBn00XMNUJDUxp27BAOM94o1PE_CVpnMjKVLwPwLMiBQHCfNDZZqR619BMZJyq3hskVhK5T24Kr_v4MStTL4kx74z55qRU0bVY=@protonmail.com>
References: <CALZpt+EygPsez0c84Yfmc6h+L7Ji8C3zE_E=EzPzLh4XWNHvZA@mail.gmail.com>
 <CALZpt+E0PSc_DD39E1-3hGYvpw3ok91Nc5DLTTh9FPdOKF_TYg@mail.gmail.com>
 <KC6W2mW10GBn00XMNUJDUxp27BAOM94o1PE_CVpnMjKVLwPwLMiBQHCfNDZZqR619BMZJyq3hskVhK5T24Kr_v4MStTL4kx74z55qRU0bVY=@protonmail.com>
Message-ID: <CALZpt+EgifiVe9UrktBxAuOm9QHYTLs+uv+nsJN-9pBbk0jsJw@mail.gmail.com>

Hi alicexbt,

CTV is listed here:
https://github.com/ariard/bitcoin-contracting-primitives-wg/tree/main/primitives
as one of the primitive subject of research. Contributions are welcome.

Best,
Antoine

Le mar. 15 nov. 2022 ? 17:37, alicexbt <alicexbt at protonmail.com> a ?crit :

> Hi Bitcoin Developers,
>
> Looking forward to the first session, listening to everyone's thoughts
> about what could be the scope discussed by this new community process:
> anyprevout, recursive covenants, introspection, new malleability flags, ZK
> rollups, new contracting protocols and many more ideas!
>
>
> Wanted to add CTV: BIP-119 OP_CHECKTEMPLATEVERIFY if OP missed it.
> Easiest and best possible way to get covenants aka tx introspection with
> lot of research and development.
>
> /dev/fd0
>
> Sent with Proton Mail <https://proton.me/> secure email.
>
> ------- Original Message -------
> On Monday, November 14th, 2022 at 7:51 AM, Antoine Riard via bitcoin-dev <
> bitcoin-dev at lists.linuxfoundation.org> wrote:
>
> Reminder: this is happening this _upcoming_ Tuesday.
>
> Looking forward to the first session, listening to everyone's thoughts
> about what could be the scope discussed by this new community process:
> anyprevout, recursive covenants, introspection, new malleability flags, ZK
> rollups, new contracting protocols and many more ideas!
>
> Best,
> Antoine
>
> Le lun. 31 oct. 2022 ? 20:47, Antoine Riard <antoine.riard at gmail.com> a
> ?crit :
>
>> Hi list,
>>
>> After I have been asked offline the exact date when those meetings were
>> actually starting, I'm proposing Tuesday 15th November at 18:00 UTC, i.e 2
>> weeks from now. Thinking about a monthly frequency for now (from my
>> experience attending dlcspecs/lighnting specs meetings/core dev meetings in
>> the past, weekly sounds too much, biweekly/monthly sounds better though
>> dunno yet good frequency).
>>
>> If there is an incompatibility with another public engineering meeting in
>> the Bitcoin space, let it know. We can talk about a better schedule during
>> the 1st session [0].
>>
>> Communication venue is #bitcoin-contracting-primitives-wg on Libera Chat
>> [1]. Feel free to lurk already and ask questions.
>>
>> No consistent agenda beyond listening to every attendee their
>> expectations, ideas, subjects of interests they would like to see happening
>> with this new covenants/contracting primitives R&D process.
>>
>> If you have been working on a contracting
>> protocols/side-chains/rollups/other use-cases that could benefit from
>> extended Bitcoin contracting primitives, feel free to open an issue there:
>> https://github.com/ariard/bitcoin-contracting-primitives-wg/issues
>>
>> Let it know if you have more questions or feedback.
>>
>> Cheers,
>> Antoine
>>
>> [0] It would be great to have a schedule inclusive of most timezones we
>> can, 18:00 UTC might be too early for Asian and Oceanic ones. Later, we
>> start to be exclusive towards contributors in Eastern Europe.
>>
>> [1] There have been more voices suggesting jitsi/audio-based meetings
>> rather than IRC. It's a cool format too, though coming with trade-offs.
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221115/4cdba0b5/attachment.html>

From ChristopherA at lifewithalacrity.com  Thu Nov 17 20:32:27 2022
From: ChristopherA at lifewithalacrity.com (Christopher Allen)
Date: Thu, 17 Nov 2022 12:32:27 -0800
Subject: [bitcoin-dev] Silicon Salon 3: Call for Presentations On
 Silicon-Logic-Base Cryptographic Acceleration & New Algorithms
Message-ID: <CACrqygCEDsQ2+R2sL_rOu50uGpDVjfNigyj8D_EJmut1_Q7ELA@mail.gmail.com>

Blockchain Commons will be facilitating Silicon Salon 3 in mid-January,
tentatively on January 18th. We will have semiconductor designers, secure
hardware developers, and other experts present, and we are calling for
other contributors who are interested in making a presentation focused on
silicon-logic-based cryptographic acceleration or support for new
functionality such as Multi-Party Computation (MPC) leveraging hardened
semiconductor-based security.

Our Silicon Salons are an ongoing series of virtual salons intended to
bring together digital wallet developers, semiconductor manufacturers, and
academics. The objective:

   - *To ensure that the next generation of cryptographic semiconductors
   meets everyone?s needs, advancing the entire cryptography industry.*
   - *Reduce is a gap between wallet requirements and semiconductor
   development, between academic research and real-world practice; we want to
   bridge it.*

Some presentations lined up so far are:

   - In pursuit of an open Secure Element: What are the elements that make
   a semiconductor more or less ?open?, and what is really important?
   - Architectural considerations in creating a semiconductor for the
   future of MPC.

See https://www.siliconsalon.info/ for our salons to date. Silicon Salon 3
will continue these topics.

If you are interested in making a presentation at Silicon Salon 3,
please contact
us with a proposal. Include the following:

   1. The title.
   2. A summary of what your presentation will be about.
   3. A summary of how that relates to silicon-logic-based cryptographic
   acceleration & new functionality and/or the general topic of integrating
   cryptography into new semiconductors. Note that this can be a discussion of
   capabilities from the point of view of a semiconductor manufacturer, of
   needs from a wallet manufacturer, or other discussions from someone in the
   broader decentralized community.
   4. The name of the presenter(s).
   5. A description of who they are and how they or their company have the
   expertise, capability, or reach to benefit the Silicon Salon conversation.

Final presentations should be about five minutes long, supported by a slide
deck or some equivalent, which you will present in our Zoom salon on the
date of the salon.

Please note the following deadlines for Silicon Salon 3 proposals and
contributions:

   - *December 23* - Final date for submission of proposals.
   - *January 4* ? Blockchain Commons selection of proposals.
   - *January 11* ? Submission of draft slide decks to Blockchain Commons
   for any comments.
   - *January 16* ? Submission of final slide decks to Blockchain Commons
   for inclusion in post-event web pages.
   - *January 18* ? Presentation at Silicon Salon 3.
   - *January 25* ? Blockchain Commons finalization of website release of
   the video, selected Q&A, transcripts, and final presentations.

Also, please note that the January 18th date is tentative. We are checking
with likely participants for conflicts, and ensuring that the holidays
won?t cause too much conflict. If it moves, then the January deadlines will
move accordingly.

Thank you for your interest in Silicon Salon 3 and the future of
semiconductor integration with cryptography! If you have any questions or
want more information, please email us at team at blockchaincommons.com.

Even if you do not want to present, please Save the Date of January 18th,
2023, so that you can participate in the conversation. We?ll make an
announcement as soon as we?ve finalized the date and have an Eventbrite
page available for signups.

Thank you to our sustaining sponsors who make Silicon Salon possible:
Bitmark, Chia, Cramium Labs (a subsidiary of CrossBar), Foundation, Proxy,
and Unchained Capitol. We are also seeking additional sponsors. Mail us at
team at blockchaincommons.com or become a sponsor on GitHub
<https://github.com/sponsors/BlockchainCommons> and let us know it?s to
support Silicon Salon!

-- Christopher Allen, Principal Architect & Executive Director, Blockchain
Commons
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221117/e390ac79/attachment.html>

From aj at erisian.com.au  Fri Nov 18 08:24:49 2022
From: aj at erisian.com.au (Anthony Towns)
Date: Fri, 18 Nov 2022 18:24:49 +1000
Subject: [bitcoin-dev] Refreshed BIP324
In-Reply-To: <JXfTBjsA71dHE3h9wkxnWXANrwTbMADO4s2w34gEvMbiduKu4PEt5t-KA3EAIz-Xs4urjBHZ15NDFZST2a7e0x_NqyJymUnEORuTp3SNfMs=@wuille.net>
References: <56677685-619a-691f-d5bc-54b69fdb6ed2@bip324.com>
 <zxv58iXZ73hf9ge8S0QLTanW-uLzaWjNtMHuKONP9hrqS5RhwitxzfVaMH8hbi3yImgNrKme3lCuDcHYKkpxEQHyGZZHJ8xtReOcnAx3o4g=@wuille.net>
 <Y2nK99fHUKxbPHmw@erisian.com.au>
 <wDqcIVw-YGTsjdf5M2GO9NNRl_UQuBeka2CUQUyQ329u6u-o7RabW_7S4FD3EDfk02kUczb3bXf8LtHhKLtx773UhQ7djKOl-JPOIrXqBSc=@wuille.net>
 <JXfTBjsA71dHE3h9wkxnWXANrwTbMADO4s2w34gEvMbiduKu4PEt5t-KA3EAIz-Xs4urjBHZ15NDFZST2a7e0x_NqyJymUnEORuTp3SNfMs=@wuille.net>
Message-ID: <Y3dBUXPhTskCx+Fu@erisian.com.au>

On Sat, Nov 12, 2022 at 03:23:16AM +0000, Pieter Wuille via bitcoin-dev wrote:
> Another idea...

> This means:
> * Every alphabetic command of L characters becomes L bytes.
> * 102 non-alphabetic 1-byte commands can be assigned.
> * 15708 non-alphabetic 2-byte commands can be assigned.

(There are 128**L possible L-byte commands, 26**L alphabetic L-byte
commands, and hence 128**L-26**L non-alphabetical L-byte commands)

> * etc
> So this gives a uniform space which commands can be assigned from, and there is no strict need for thinking of the short-binary and long-alphabetic commands as distinct. In v2, some short ones would be treated as aliases for old long-alphabetic ones. But new commands could also just be introduced as short ones only (even in v1).

Isn't that optimising for the wrong thing? Aren't the goals we want:

 1) it should be easy to come up with a message identifier without
    accidently conflicting with someone else's proposal

 2) commonly used messages on the wire should have a short encoding
    in order to save bandwidth

Depending on how much the p2p protocol ossifies, which messages are
"commonly used on the wire" might be expected to change; and picking an
otherwise meaningless value from a set of 102 elements seems likely to
produce conflicts...

Doing:

  -> VERSION
  <- VERSION
  <- SHORTMSG ["BIP324", "foo.org/experiment"]
  <- VERACK
  -> SHORTMSG ["BIP324"]
  -> VERACK
  -> SENDSHORTMSG "BIP324" [(13, "ADDRV3")]
  <- SENDSHORTMSG "BIP324"
  -> 34 (SENDHEADERS)
  -> 25 (GETHEADERS)
  ...

where "SHORTMSG" lets you specify an array of tables you support (such as
BIP324's), and, once you know both sides supports a table, you can send
`SENDSHORTMSG` to choose the table you'll use to abbreviate messages
you send, as well as any modifications to that table (like replacing
ADDR with ADDRV3).

Then when writing BIPs, you just choose a meaningful string ("ADDRV3"),
and when implementing you send a one-time "SENDSHORTMSG" message to
optimise the messages you'll send most often... As time goes on and the
most common messages change, issue a new BIP with a new table so that
your one-time SHORTIDs message becomes shorter too, at least when you
connect to peers that also know about the new bip..

Could potentially support that without bip324, by taking over the one
byte message space, presuming you don't have any one-character messages
you actually want to send?

Could do this /as well as/ the encoding above, I guess; then you would
have bips specify alphabetic message ids, and use SENDSHORTMSG to
dynamically (and sequentially) override/allocate non-alphabetic ids?
That would presumably limit the number of non-alphabetic ids to how
many you could specify in a single SENDSHORTIDs message, which I think
would be up to something like 749k different 1/2/3/4/5/6-byte alphabetic
message ids (encoded as 1/2/3-byte non-alphabetic messages). Probably
some more specific limit would be better though.

Cheers,
aj

From amo.personal at protonmail.com  Fri Nov 18 21:11:54 2022
From: amo.personal at protonmail.com (Andrew Melnychuk Oseen)
Date: Fri, 18 Nov 2022 21:11:54 +0000
Subject: [bitcoin-dev] Relative txout amounts with a Merkleized Sum Tree and
	explicit miner fee.
Message-ID: <zKbMpqEqH6Z4p1GE2rlsOky1fMPBsEFGaeNk8WIcbez__-fR3ahnYEWOgExHC8KXAYCqtt4gMa7WBXkNSqL6fO9sjsvyu9AZRPQIQADqthg=@protonmail.com>

Can output amounts be mapped to a tap branch? For the goal of secure partial spends of a single UTXO? Looking for feedback on this idea. I got it from Taro.

Merkel_tree_root_tweak = tagged_hash(?root? || left_hash || right_hash)

Tree_branch = tagged_hash(?branch? || left_hash || right_hash ) || right_output_sum + left_relative_output_amount

Tree_leaf = tagged_hash("leaf" || script ) || relative_output_amount

Transaction Validation:

There would be one output with an amount that is negative.

The negative amount would flag this transaction as relative amount spends.

The miner fee would be the absolute of the output amount.

The witness would include the txout amount.

Txout is less than other inputs that referencing this output.

Questions:

Would this require a hard fork?

Would the sum be required in the asset tree?. The sum at the root would be implicitly 1.0. How big can a taproot tree get before it is too cumbersome?

Could multiple taproot trees be put inside a tweak?

Am I missing anything vital?

Possible Benefits

Perhaps slightly increase privacy of output amounts?

Reduced growth rate of UTXO?s. This scheme would be consuming N inputs and producing 1 output.

Drawbacks

I think this would disable the ability for output change addresses to be the same as inputs as the spending amounts are absolute.

Transaction Example

Inputs : [1.5,.3,.1]

TapTree:

Branch sum :1

Change Address : .5

Branch sum: .5

AlicePubKey: .2

Branch sum: .3

BobPub and BobHash: .1

Branch sum: .2

CaroPub and DavePub and CarolDaveHash : .1

ErinPub and CarolDaveHash and after 10days : .1

Outputs: [-.0.001]

Alice spending example

Alice sends to new address : .1 * (sum of Inputs + outputs) = 0.18999

Alice New Change Address = .1 * (sum of Inputs + outputs) = 0.18999

Application

I think something like this would provide away to onboard a lot of lightning channels with a single UTXO output. An exchange could schedule open lightning channels at certain time intervals, perhaps every 10 minutes. Ideally, people would provide pubkeys and payment, to be placed in a tap leaf. Similar to selling seats for an aircraft flight.

Thanks for reading

Andrew

Sent with [Proton Mail](https://proton.me/) secure email.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221118/a95e7ca4/attachment.html>

From alicexbt at protonmail.com  Sun Nov 20 06:36:23 2022
From: alicexbt at protonmail.com (alicexbt)
Date: Sun, 20 Nov 2022 06:36:23 +0000
Subject: [bitcoin-dev] Custom signet for testing full RBF
Message-ID: <6lyH4IyNtVBlm_9wsr5UEAi8stIZN8OKNrcSJMOTJUiKE4MLoAMXluIR-4XJBHSwxpffEEsDCwkjQsrApqssvbIX_z_prQqfYbVa7JRJ3vE=@protonmail.com>

Hi Bitcoin Developers,

I have setup a [custom signet][0] for testing full RBF. You can connect to one or more of these nodes using `addnode`:

13.115.34.55 (issuer, full-rbf)
kfupbqwb2yvzzqjomfq5pkem553a6uzp2k73seqn4d46smy7azua.b32.i2p (rbf-optin)
luvczzzppiqnc2b7poivkxlugafe3uqaj245ebjqxtceio7poaorqcyd.onion (full-rbf)

Example config:

```
signet=1
signetchallenge=5121035daaa313aada6310340a242af17238cc1fd8849e875940bce65a60ac7e0e0ff751ae
proxy=127.0.0.1:9050

[signet]
addnode=luvczzzppiqnc2b7poivkxlugafe3uqaj245ebjqxtceio7poaorqcyd.onion

mempoolfullrbf=1
```

Example for a simple test case:

- Run 2 nodes
- Connect node 1 with i2p node and use default opt-in rbf
- Connect node 2 with node 1 and onion node. This node should use `mempoolfullrbf=1` in config and compile bitcoind using PR [#26454][1] branch
- Broadcast Tx1 using node 2 and replace with Tx2 using `bumpfee` RPC

It will be fun to test with more nodes joining this custom signet. If anyone interested to test, please post your bitcoin address in [full-rbf room][2]. We can even setup an explorer if this experiment makes sense.

[0]: https://en.bitcoin.it/wiki/Signet#Custom_Signet
[1]: https://github.com/bitcoin/bitcoin/pull/26454
[2]: #full-rbf:matrix.org

Sent with Proton Mail secure email.

/dev/fd0

From salvatore.ingala at gmail.com  Mon Nov 21 11:27:25 2022
From: salvatore.ingala at gmail.com (Salvatore Ingala)
Date: Mon, 21 Nov 2022 12:27:25 +0100
Subject: [bitcoin-dev] Wallet policies for descriptor wallets
In-Reply-To: <CAMhCMoHfdsQMsVigFqPexTE_q-Cyg7pfRvORUoy2sZtvyzd1cg@mail.gmail.com>
References: <CAMhCMoHfdsQMsVigFqPexTE_q-Cyg7pfRvORUoy2sZtvyzd1cg@mail.gmail.com>
Message-ID: <CAMhCMoFWHUKVg0n2jVwxfAsuFqsCXPWHg4Bw_sk0xfTs4FPnkw@mail.gmail.com>

Hi list,

Following up on this topic, I now opened a pull request with the BIP
proposal:

     https://github.com/bitcoin/bips/pull/1389

I also attempted a proof-of-concept of how an integration of wallet
policies to HWI might look like:

     https://github.com/bitcoin-core/HWI/pull/647

which might help to provide context, and also serves as a demo of the
possible UX flows with hardware signers (as currently implemented in the
Ledger bitcoin app).

There are no substantial changes to the initial version proposed to the
list:
- some additional restrictions to the allowed descriptors were added as
further simplifications;
- added test vectors and observations on backwards compatibility;
- general improvements to the text.

I look forward to your comments and improvements.
Salvatore Ingala

On Thu, 5 May 2022 at 16:32, Salvatore Ingala <salvatore.ingala at gmail.com>
wrote:

> In the implementation work to implement descriptors and miniscript support
> in hardware wallets [a][b], I encountered a number of challenges. Some of
> them are technical in nature (e.g. due to constraints of embedded
> development). Others are related to the attempts of shaping a good user
> experience; with bitcoin reaching more people who are not tech-savvy,
> self-custody is only as secure as what those newcomers can use easily
> enough.
>
> The main tool that I am using to address some of these challenges is a
> layer that sits _on top_ of descriptors/miniscript, while staying very
> close to it. Since there is nothing that is vendor-specific in the vast
> majority of the approach I'm currently using, I tried to distill it here
> for your comments, and will propose a BIP if this is deemed valuable.
>
> I called the language "wallet policies" (suggestions for a better name are
> welcome). I believe an approach based on wallet policies can benefit all
> hardware wallets (stateless or not) that want to securely support complex
> scripts; moreover, wallet policies are close enough to descriptors that
> their integration should be extremely easy for any software wallet that is
> currently using descriptors.
>
> [a]: https://blog.ledger.com/bitcoin-2 - early demo
> [b]: https://blog.ledger.com/miniscript-is-coming - miniscript example
>
>
> Salvatore Ingala
>
>
> ======================================================
>
> This document starts with a discussion on the motivation for wallet
> policies, followed by their formal definition, and some recommendations for
> implementations.
>
> == Rationale ==
>
> Output script descriptors [1] were introduced in bitcoin-core as a way to
> represent collections of output scripts. It is a very general and flexible
> language, designed to catch all the possible use-cases of bitcoin wallets
> (that is, if you know the script and you have the necessary keys, it will
> be possible to sign transactions with bitcoin-core's descriptor-based
> wallets).
>
> Unfortunately, descriptors are not a perfect match for the typical usage
> of hardware wallets. Most hardware wallets have the following limitations
> compared to a general-purpose machine running bitcoin-core:
>
> - they are embedded devices with limited RAM and computational power;
> - they might not be able to import additional private keys (all the keys
> are generated from a single seed via [BIP-32](
> https://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki));
> - they might not have permanent storage (*stateless* hardware wallet
> design).
>
> Moreover, other limitations like the limited size of the screen might
> affect what design choices are available in practice. Therefore, minimizing
> the size of the information shown on-screen is important for a good user
> experience.
>
> A more native, compact representation of the wallet receive/change would
> also benefit the UX of software wallets using descriptors to represent
> software wallets using descriptors/miniscript for multisignature or other
> complex locking conditions.
>
> === Security and UX concerns of scripts in hardware wallets ===
>
> For a hardware wallet, allowing the usage of complex scripts presents
> challenges in terms of both security and user experience.
>
> ==== Security issues ====
>
> One of the security properties that hardware wallets strive to guarantee
> is the following: **as long as the user correctly verifies the information
> that is shown on the hardware wallet's screen before approving, no action
> can be performed without the user's consent**.
> This must hold even in scenarios where the attacker has full control of
> the machine that is connected to the hardware wallet, and can execute
> arbitrary requests or tamper with the legitimate user's requests.
>
> Therefore, it is not at all trivial to allow complex scripts, especially
> if they contain keys that belong to third parties.
> The hardware wallet must guarantee that the user knows precisely *what*
> "policy" is being used to spend the funds, and that the "unspent" funds (if
> any) will be protected by the same policy. This makes it impossible for an
> attacker to surreptitiously modify the policy, therefore stealing or
> burning user's funds.
>
> ==== UX issues ====
>
> With miniscript (and taproot trees) allowing substantially more complex
> spending policies to be used, it becomes more challenging to make sure that
> the user is able _in practice_ to verify the information on the screen.
> Therefore, there are two fundamental design goals to strive for:
> - Minimize the amount of information that is shown on screen - so that the
> user can actually validate it.
> - Minimize the number of times the user has to validate such information.
>
> Designing a secure protocol for the coordination of a descriptor wallet
> among distant parties is also a challenging problem that is out of scope in
> this document. See BIP-129 [2] for an approach designed for multisignature
> wallets.
>
> === Policy registration as a solution ===
>
> A solution to address the security concerns, and part of the UX concerns,
> is to have a *registration* flow for the wallet policy in the hardware
> wallet. The "wallet policy" must contain enough information to generate all
> the relevant addresses/scripts, and for the hardware wallet to identify the
> keys that it controls and that are needed to spend the funds sent to those
> addresses.
>
> Before a new policy is used for the first time, the user will register a
> `wallet policy` into the hardware wallet. While the details of the process
> are out of scope in this document, the flow should be something similar to
> the following:
>
> 1) The software wallet initiates a _wallet policy registration_ on the
> hardware wallet; the information should include the wallet policy, but also
> a unique *name* that identifies the policy.
> 2) The hardware wallet shows the wallet policy to the user using the
> secure screen.
> 3) After inspecting the policy and comparing it with a trusted source (for
> example a printed backup), the user approves the policy.
> 4) If stateful, the hardware wallet persists the policy in its permanent
> memory; if stateless, it returns a "proof of registration".
>
> The details of how to create a proof of registration are out of scope for
> this document; using a *message authentication codes* on a hash committing
> to the wallet policy, its name and any additional metadata is an effective
> solution if correctly executed.
>
> Once a policy is registered, the hardware wallet can perform the usual
> operations securely:
> - generating receive and change addresses;
> - showing addresses on the secure screen;
> - sign transactions spending from a wallet, while correctly identifying
> change addresses and computing the transaction fees.
>
> Before any of the actions mentioned above, the hardware wallet will
> retrieve the policy from its permanent storage if stateful; if stateless it
> will validate the _proof of registration_ before using the wallet policy
> provided by the client.
> Once the previously registered policy is correctly identified and approved
> by the user (for example by its name), and *as long as the policy
> registration was executed securely*, hardware wallets can provide a user
> experience similar to the usual one for single-signature transactions.
>
> === Avoiding blowup in descriptor size ===
>
> While reusing a pubkey in different branches of a miniscript is explicitly
> forbidden by miniscript (as it has certain negative security implications),
> it is still reasonable to reuse the same *xpub* in multiple places, albeit
> with different final steps of derivation (so that the actual pubkeys that
> are used in the script are indeed different).
>
> For example, using Taproot, a *3*-of-*5* multisignature wallet could use:
> - a key path with a 5-of-5 MuSig
> - a script tree with a tree of 10 different 3-of-3 MuSig2 scripts, that
> are generated, plus a leaf with a fallback *3*-of-*5* multisignature using
> plain multisignature (with `OP_CHECKSIGADD`).
>
> This could look similar to:
>
> ```
> tr(musig2(xpubA,xpubB,xpubC,xpubD,xpubE)/<0;1>/*), {
>   {
>     {
>       pk(musig2(xpubA,xpubB,xpubC)/<2;3>/*),
>       {
>         pk(musig2(xpubA,xpubB,xpubD)/<4;5>/*)
>         pk(musig2(xpubA,xpubB,xpubE)/<6;7>/*),
>       }
>     },
>     {
>       pk(musig2(xpubA,xpubC,xpubD)/<8;9>/*),
>       {
>         pk(musig2(xpubA,xpubC,xpubE)/<10;11>/*),
>         pk(musig2(xpubA,xpubD,xpubE)/<12;13>/*)
>       }
>     }
>   },
>   {
>     {
>       pk(musig2(xpubB,xpubC,xpubD)/<14;15>/*),
>       pk(musig2(xpubB,xpubC,xpubE)/<16;17>/*)
>     },
>     {
>       pk(musig2(xpubB,xpubD,xpubE)/<18;19>/*),
>       {
>         pk(musig2(xpubC,xpubD,xpubE)/<20;21>/*),
>         sortedmulti_a(3,
>           xpubA/<22;23>/*,
>           xpubB/<22;23>/*,
>           xpubC/<22;23>/*,
>           xpubD/<22;23>/*,
>           xpubE/<22;23>/*)
>       }
>     }
>   }
> })
> ```
>
> Note that each root xpub appears 8 times. With xpubs being up to 118 bytes
> long, the length of the full descriptor can get extremely long (the problem
> gets *exponentially* worse with larger multisignature schemes).
>
> Replacing the common part of the key with a short key placeholder and
> moving the key expression separately helps to keep the size of the wallet
> policy small, which is crucial to allow human inspection in the
> registration flow.
>
> === Restrictions on the supported descriptors ====
>
> The policy language proposed in this document purposely targets only a
> stricter subset of the output descriptors language, and it attempts to
> generalize in the most natural way the approach that is already used for
> single-signature *accounts* (as described in BIP-44 [3], BIP-49 [4], BIP-84
> [5], or BIP-86 [6]), or in multisignature setups (see for example BIP-48
> [7] and BIP-87 [8]).
>
> Unlike the BIPs mentioned above, it is not tied to any specific script
> template, as it applies to arbitrary scripts that can be represented with
> descriptors and miniscript.
>
> Supporting only a reduced feature set when compared to output descriptors
> helps in implementations (especially on hardware wallets), while attempting
> to capture all the common use cases. More features can be added in the
> future if motivated by real world necessity.
>
> By keeping the structure of the wallet policy language very close to that
> of descriptors, it should be straightforward to:
> - write wallet policy parsers;
> - extract the descriptors defined by a wallet policy;
> - convert a pair of descriptors describing a wallet "account" used in
> current implementations into the corresponding wallet policy.
>
>
> == Wallet policies ==
>
> This section formally defines wallet policies, and how they relate to
> output script descriptors.
>
> === Formal definition ===
>
> A wallet policy is composed by a wallet descriptor template, together with
> a vector of key information items.
>
> ==== Wallet descriptor template ====
>
> A wallet descriptor template is a `SCRIPT` expression.
>
> `SCRIPT` expressions:
> - `sh(SCRIPT)` (top level only): P2SH embed the argument.
> - `wsh(SCRIPT)` (top level or inside `sh` only): P2WSH embed the argument.
> - `pkh(KP)` (not inside `tr`): P2PKH output for the given public key (use
> `addr` if you only know the pubkey hash).
> - `wpkh(KP)` (top level or inside `sh` only): P2WPKH output for the given
> compressed pubkey.
> - `multi(k,KP_1,KP_2,...,KP_n)`: k-of-n multisig script.
> - `sortedmulti(k,KP_1,KP_2,...,KP_n)`: k-of-n multisig script with keys
> sorted lexicographically in the resulting script.
> - `tr(KP)` or `tr(KP,TREE)` (top level only): P2TR output with the
> specified key as internal key, and optionally a tree of script paths.
> - any valid miniscript template (inside `wsh` or `tr` only).
>
> `TREE` expressions:
> - any `SCRIPT` expression
> - An open brace `{`, a `TREE` expression, a comma `,`, a `TREE`
> expression, and a closing brace `}`
>
> Note: "miniscript templates" are not formally defined in this version of
> the document, but it is straightforward to adapt this approach.
>
> `KP` expressions (key placeholders) consist of
> - a single character `@`
> - followed by a non-negative decimal number, with no leading zeros (except
> for `@0`).
> - possibly followed by either:
>   - the string  `/**`, or
>   - a string of the form `/<NUM;NUM>/*`, for two distinct decimal numbers
> `NUM` representing unhardened derivations
>
> The `/**` in the placeholder template represents commonly used paths for
> receive/change addresses, and is equivalent to `<0;1>`.
>
> The placeholder `@i` for some number *i* represents the *i*-th key in the
> vector of key origin information (which must be of size at least *i* + 1,
> or the wallet policy is invalid).
>
> ==== Key informations vector ====
>
> Each element of the key origin information vector is a `KEY` expression.
>
> - Optionally, key origin information, consisting of:
>   - An open bracket `[`
>   - Exactly 8 hex characters for the fingerprint of the master key from
> which this key is derived from (see [BIP32](
> https://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki) for
> details)
>   - Followed by zero or more `/NUM'` path elements to indicate hardened
> derivation steps between the fingerprint and the xpub that follows
>   - A closing bracket `]`
> - Followed by the actual key, which is either
>   - a hex-encoded pubkey, which is either
>     - inside `wpkh` and `wsh`, only compressed public keys are permitted
> (exactly 66 hex characters starting with `02` or `03`.
>     - inside `tr`, x-only pubkeys are also permitted (exactly 64 hex
> characters).
>   - a serialized extended public key (`xpub`) (as defined in [BIP 32](
> https://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki))
>
> The placeholder `@i` for some number *i* represents the *i*-th key in the
> vector of key orIgin information (which must be of size at least *i* + 1,
> or the wallet policy is invalid).
>
> The policy template is invalid if any placeholder `@i` has derivation
> steps while the corresponding `(i+1)`-th element of the keys vector is not
> an xpub.
>
> ==== Additional rules ====
>
> The wallet policy is invalid if any placeholder expression with additional
> derivation steps is used when the corresponding key information is not an
> xpub.
>
> The key information vector *should* be ordered so that placeholder `@i`
> never appear for the first time before an occurrence of `@j`  for some `j <
> i`; for example, the first placeholder is always `@0`, the next one is
> `@1`, etc.
>
> === Descriptor derivation ===
>
> From a wallet descriptor template (and the associated vector of key
> informations), one can therefore obtain the 1-dimensional descriptor for
> receive and change addresses by:
>
> - replacing each key placeholder with the corresponding key origin
> information;
> - replacing every `/**`  with `/0/*` for the receive descriptor, and
> `/1/*` for the change descriptor;
> - replacing every `/<M,N>` with  `/M` for the receive descriptor, and `/N`
> for the change descriptor.
>
> For example, the wallet descriptor `pkh(@0/**)` with key information
> `["[d34db33f/44'/0'/0']xpub6ERApfZwUNrhLCkDtcHTcxd75RbzS1ed54G1LkBUHQVHQKqhMkhgbmJbZRkrgZw4koxb5JaHWkY4ALHY2grBGRjaDMzQLcgJvLJuZZvRcEL"]`
> produces the following two descriptors:
>
> - Receive descriptor:
> `pkh([d34db33f/44'/0'/0']xpub6ERApfZwUNrhLCkDtcHTcxd75RbzS1ed54G1LkBUHQVHQKqhMkhgbmJbZRkrgZw4koxb5JaHWkY4ALHY2grBGRjaDMzQLcgJvLJuZZvRcEL/0/*)`
>
> - Change descriptor:
> `pkh([d34db33f/44'/0'/0']xpub6ERApfZwUNrhLCkDtcHTcxd75RbzS1ed54G1LkBUHQVHQKqhMkhgbmJbZRkrgZw4koxb5JaHWkY4ALHY2grBGRjaDMzQLcgJvLJuZZvRcEL/1/*)`
>
> === Implementation guidelines ===
>
> Implementations must not necessarily implement all of the possible wallet
> policies defined by this standard, but it is recommended to clearly
> document any limitation.
>
> Implementations can add additional metadata that is stored together with
> the wallet policy for the purpose of wallet policy registration and later
> usage. Metadata can be vendor-specific and is out of the scope of this
> document.
>
> Any implementation in a general-purpose software wallet allowing arbitrary
> scripts (or any scripts that involve external cosigners) should put great
> care into a process for backing up a wallet policy. In fact, unlike typical
> single-signature scenarios, the seed alone is no longer enough to discover
> wallet policies with existing funds, and the loss of the backup is likely
> to lead to permanent loss of funds.
>
> Avoiding key reuse among different wallet accounts is also extremely
> important, but out of scope for this document.
>
> == Examples ==
>
> Some examples of wallet descriptor templates (vectors of keys omitted for
> simplicity):
> - Template for a native segwit account:
>   wpkh(@0/**)
> - Template for a taproot BIP86 account:
>   tr(@0/**)
> - Template for a native segwit 2-of-3:
>   wsh(sortedmulti(2, at 0/**, at 1/**, at 2/**))
> - Template with miniscript for "1 of 2 equally likely keys":
>   wsh(or_b(pk(@0/**),s:pk(@1/**)))
>
> More examples (esp. targeting miniscript on taproot) will be added in the
> future.
>
> == References ==
>
> * [1] - Output Script Descriptors:
> https://github.com/bitcoin/bitcoin/blob/master/doc/descriptors.md
> * [2] - BIP-129 (Bitcoin Secure Multisig Setup):
> https://github.com/bitcoin/bips/blob/master/bip-0129.mediawiki
> * [3] - BIP-44:
> https://github.com/bitcoin/bips/blob/master/bip-0044.mediawiki
> * [4] - BIP-49:
> https://github.com/bitcoin/bips/blob/master/bip-0049.mediawiki
> * [5] - BIP-84:
> https://github.com/bitcoin/bips/blob/master/bip-0084.mediawiki
> * [6] - BIP-86:
> https://github.com/bitcoin/bips/blob/master/bip-0086.mediawiki
> * [7] - BIP-48:
> https://github.com/bitcoin/bips/blob/master/bip-0048.mediawiki
> * [8] - BIP-87:
> https://github.com/bitcoin/bips/blob/master/bip-0087.mediawiki
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221121/7e1792e5/attachment-0001.html>

From ZmnSCPxj at protonmail.com  Mon Nov 21 23:52:00 2022
From: ZmnSCPxj at protonmail.com (ZmnSCPxj)
Date: Mon, 21 Nov 2022 23:52:00 +0000
Subject: [bitcoin-dev] Relative txout amounts with a Merkleized Sum Tree
	and explicit miner fee.
In-Reply-To: <zKbMpqEqH6Z4p1GE2rlsOky1fMPBsEFGaeNk8WIcbez__-fR3ahnYEWOgExHC8KXAYCqtt4gMa7WBXkNSqL6fO9sjsvyu9AZRPQIQADqthg=@protonmail.com>
References: <zKbMpqEqH6Z4p1GE2rlsOky1fMPBsEFGaeNk8WIcbez__-fR3ahnYEWOgExHC8KXAYCqtt4gMa7WBXkNSqL6fO9sjsvyu9AZRPQIQADqthg=@protonmail.com>
Message-ID: <Kcqi_Svol1F4H8rGnnECZXRkb5Aa_763DlNUP4froIqLovFk-SrOnWXC5ZPtfRjzHb55_BTe07h6PH5OdaY2zpNPNTix__bqYiBIEw2IbjA=@protonmail.com>


Good morning Andrew,

> 
> 
> Can output amounts be mapped to a tap branch? For the goal of secure partial spends of a single UTXO? Looking for feedback on this idea. I got it from Taro.


Not at all.

The issue you are facing here is that only one tap branch will ever consume the entire input amount.
That is: while Taproot has multiple leaves, only exactly one leaf will ever be published onchain and that gets the whole amount.

What you want is multiple tree leaves where ALL of them will EVENTUALLY be published, just not right now.

In that case, look at the tree structures for `OP_CHECKTEMPLATEVERIFY`, which are exactly what you are looking for, and help make `OP_CTV` a reality.

Without `OP_CHECKTEMPLATEVERIFY` it is possible to use presigned transactions in a tree structure to do this same construction.
Presigned transactions are known to be larger than `OP_CHECKTEMPLATEVERIFY` --- signatures on taproot are 64 bytes of witness, but an `OP_CHECKTEMPLATEVERIFY` in a P2WSH reveals just 32 bytes of witness plus the `OP_CHECKTEMPLATEVERIFY` opcode.

Regards,
ZmnSCPxj

From michaelfolkson at protonmail.com  Tue Nov 22 11:20:44 2022
From: michaelfolkson at protonmail.com (Michael Folkson)
Date: Tue, 22 Nov 2022 11:20:44 +0000
Subject: [bitcoin-dev] Custom signet for testing full RBF
In-Reply-To: <6lyH4IyNtVBlm_9wsr5UEAi8stIZN8OKNrcSJMOTJUiKE4MLoAMXluIR-4XJBHSwxpffEEsDCwkjQsrApqssvbIX_z_prQqfYbVa7JRJ3vE=@protonmail.com>
References: <6lyH4IyNtVBlm_9wsr5UEAi8stIZN8OKNrcSJMOTJUiKE4MLoAMXluIR-4XJBHSwxpffEEsDCwkjQsrApqssvbIX_z_prQqfYbVa7JRJ3vE=@protonmail.com>
Message-ID: <_rvhg7VmWlwMShoKBmFOiEsVoI7so01bHe6_WI11o3bWmpllNhiqHBZQ7O_4GFu-OTqLaq8p4ndom2WeovfV59wnUbtqjAVnNckraYGU8AA=@protonmail.com>

Hi alicexbt

Thanks for setting this up. Generally it seems to me like an excellent idea to set up custom signets (and/or get proposals enabled on the default signet) for testing and experimenting with new proposals.

I have two questions.

1) In this particular case the -mempoolfullrbf configuration option is in the recent Bitcoin Core 24.0 release and so can be used both on mainnet and the default signet, testnet etc. What could be tested on this custom signet that can't be tested on the default signet with Bitcoin Core 24.0? Perhaps there are some things that are easier to test with a smaller custom signet network starting from scratch?

2) I know a number of people have struggled (e.g. [0], [1]) to get a custom signet set up. I think the CTV signet took a while to get set up too. It seems you followed the instructions on the Bitcoin wiki [2] for setting this one up? Was there anything you found difficult or was counterintuitive getting this custom signet set up? You are the sole block signer on this custom signet. How regularly are you mining blocks (e.g. strictly every 10 minutes, replicating the Poisson process on mainnet, adhoc etc?) Are you running this custom signet node on the same machine as a default signet, mainnet, testnet full node? I'm a little tentative to start joining custom signet networks on the same machine that is already running other nodes but perhaps there are no problems. 

I'm not sure yet if I have a use case in mind for this particular custom signet but I'm very interested in custom signet setup generally and the docs/resources to make this as easy as possible so thanks again for posting about this.

Thanks
Michael

[0]: https://bitcoin.stackexchange.com/questions/114477/could-someone-share-with-me-some-documentations-or-sites-on-how-to-set-up-a-cust
[1]: https://bitcoin.stackexchange.com/questions/114724/peer-discovery-on-a-custom-signet-custom-signetchallenge
[2]: [0]: https://en.bitcoin.it/wiki/Signet#Custom_Signet

--
Michael Folkson
Email: michaelfolkson at protonmail.com
Keybase: michaelfolkson
PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3


------- Original Message -------
On Sunday, November 20th, 2022 at 08:36, alicexbt via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:


> Hi Bitcoin Developers,
> 
> I have setup a [custom signet][0] for testing full RBF. You can connect to one or more of these nodes using `addnode`:
> 
> 13.115.34.55 (issuer, full-rbf)
> kfupbqwb2yvzzqjomfq5pkem553a6uzp2k73seqn4d46smy7azua.b32.i2p (rbf-optin)
> luvczzzppiqnc2b7poivkxlugafe3uqaj245ebjqxtceio7poaorqcyd.onion (full-rbf)
> 
> Example config:
> 
> `signet=1 signetchallenge=5121035daaa313aada6310340a242af17238cc1fd8849e875940bce65a60ac7e0e0ff751ae proxy=127.0.0.1:9050 [signet] addnode=luvczzzppiqnc2b7poivkxlugafe3uqaj245ebjqxtceio7poaorqcyd.onion mempoolfullrbf=1`
> 
> Example for a simple test case:
> 
> - Run 2 nodes
> - Connect node 1 with i2p node and use default opt-in rbf
> - Connect node 2 with node 1 and onion node. This node should use `mempoolfullrbf=1` in config and compile bitcoind using PR [#26454][1] branch
> - Broadcast Tx1 using node 2 and replace with Tx2 using `bumpfee` RPC
> 
> It will be fun to test with more nodes joining this custom signet. If anyone interested to test, please post your bitcoin address in [full-rbf room][2]. We can even setup an explorer if this experiment makes sense.
> 
> [0]: https://en.bitcoin.it/wiki/Signet#Custom_Signet
> [1]: https://github.com/bitcoin/bitcoin/pull/26454
> [2]: #full-rbf:matrix.org
> 
> Sent with Proton Mail secure email.
> 
> /dev/fd0
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

From alicexbt at protonmail.com  Tue Nov 22 17:09:16 2022
From: alicexbt at protonmail.com (alicexbt)
Date: Tue, 22 Nov 2022 17:09:16 +0000
Subject: [bitcoin-dev] Custom signet for testing full RBF
In-Reply-To: <_rvhg7VmWlwMShoKBmFOiEsVoI7so01bHe6_WI11o3bWmpllNhiqHBZQ7O_4GFu-OTqLaq8p4ndom2WeovfV59wnUbtqjAVnNckraYGU8AA=@protonmail.com>
References: <6lyH4IyNtVBlm_9wsr5UEAi8stIZN8OKNrcSJMOTJUiKE4MLoAMXluIR-4XJBHSwxpffEEsDCwkjQsrApqssvbIX_z_prQqfYbVa7JRJ3vE=@protonmail.com>
 <_rvhg7VmWlwMShoKBmFOiEsVoI7so01bHe6_WI11o3bWmpllNhiqHBZQ7O_4GFu-OTqLaq8p4ndom2WeovfV59wnUbtqjAVnNckraYGU8AA=@protonmail.com>
Message-ID: <3EotthoDUEkl3Vqv_PWkF47ytiPvGjBfNcK9fgWDEWkOYMgwdst38aoW7QJldTdIUKCPKV9fcsUnrdjs5aze6vRgs_TAU_qn3EoTU7DyAZc=@protonmail.com>

Hi Michael,

> In this particular case the -mempoolfullrbf configuration option is in the recent Bitcoin Core 24.0 release and so can be used both on mainnet and the default signet, testnet etc. What could be tested on this custom signet that can't be tested on the default signet with Bitcoin Core 24.0? Perhaps there are some things that are easier to test with a smaller custom signet network starting from scratch?

1. Signet miners and dictators are not interested to use full RBF
2. Testnet is weird and I only use it when a project doesn't support signet
3. Mainnet v24.0 is not released yet although Peter Todd is trying few things, I am not even sure if it will be available, testing should not depend on politics.
4. Main/Default Signet miners and dictators did not respond or agree to use full RBF.

Testing is important and I love it. I do not care about others.

> I know a number of people have struggled (e.g. [0], [1]) to get a custom signet set up. I think the CTV signet took a while to get set up too. It seems you followed the instructions on the Bitcoin wiki [2] for setting this one up? Was there anything you found difficult or was counterintuitive getting this custom signet set up? You are the sole block signer on this custom signet. How regularly are you mining blocks (e.g. strictly every 10 minutes, replicating the Poisson process on mainnet, adhoc etc?) Are you running this custom signet node on the same machine as a default signet, mainnet, testnet full node? I'm a little tentative to start joining custom signet networks on the same machine that is already running other nodes but perhaps there are no problems. 

I had no issues except this command:

``
$ ../contrib/signet/miner --cli="./bitcoin-cli" calibrate --grind-cmd="./bitcoin-util grind" --seconds=600
```

I had no clue we need to wait for some seconds/minutes for output. Although its okay.

I used default settings and it should mine with it forever or my AWS subscription is cancelled. 

I am trying to help Bitcoin. Although not a big influencer. If most of the developers think its okay to test it directly on mainnet, there is nothing wrong with it. You will get some insights/bugs from this experiment if enough users try it.


Sent with Proton Mail secure email.ichael

/dev/fd0

------- Original Message -------
On Tuesday, November 22nd, 2022 at 4:50 PM, Michael Folkson <michaelfolkson at protonmail.com> wrote:


> Hi alicexbt
> 
> Thanks for setting this up. Generally it seems to me like an excellent idea to set up custom signets (and/or get proposals enabled on the default signet) for testing and experimenting with new proposals.
> 
> I have two questions.
> 
> 1) In this particular case the -mempoolfullrbf configuration option is in the recent Bitcoin Core 24.0 release and so can be used both on mainnet and the default signet, testnet etc. What could be tested on this custom signet that can't be tested on the default signet with Bitcoin Core 24.0? Perhaps there are some things that are easier to test with a smaller custom signet network starting from scratch?
> 
> 2) I know a number of people have struggled (e.g. 0, 1) to get a custom signet set up. I think the CTV signet took a while to get set up too. It seems you followed the instructions on the Bitcoin wiki 2 for setting this one up? Was there anything you found difficult or was counterintuitive getting this custom signet set up? You are the sole block signer on this custom signet. How regularly are you mining blocks (e.g. strictly every 10 minutes, replicating the Poisson process on mainnet, adhoc etc?) Are you running this custom signet node on the same machine as a default signet, mainnet, testnet full node? I'm a little tentative to start joining custom signet networks on the same machine that is already running other nodes but perhaps there are no problems.
> 
> I'm not sure yet if I have a use case in mind for this particular custom signet but I'm very interested in custom signet setup generally and the docs/resources to make this as easy as possible so thanks again for posting about this.
> 
> Thanks
> Michael
> 
> 0: https://bitcoin.stackexchange.com/questions/114477/could-someone-share-with-me-some-documentations-or-sites-on-how-to-set-up-a-cust
> 1: https://bitcoin.stackexchange.com/questions/114724/peer-discovery-on-a-custom-signet-custom-signetchallenge
> 2: 0: https://en.bitcoin.it/wiki/Signet#Custom_Signet
> 
> --
> Michael Folkson
> Email: michaelfolkson at protonmail.com
> Keybase: michaelfolkson
> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3
> 
> 
> ------- Original Message -------
> On Sunday, November 20th, 2022 at 08:36, alicexbt via bitcoin-dev bitcoin-dev at lists.linuxfoundation.org wrote:
> 
> 
> 
> > Hi Bitcoin Developers,
> > 
> > I have setup a custom signet for testing full RBF. You can connect to one or more of these nodes using `addnode`:
> > 
> > 13.115.34.55 (issuer, full-rbf)
> > kfupbqwb2yvzzqjomfq5pkem553a6uzp2k73seqn4d46smy7azua.b32.i2p (rbf-optin)
> > luvczzzppiqnc2b7poivkxlugafe3uqaj245ebjqxtceio7poaorqcyd.onion (full-rbf)
> > 
> > Example config:
> > 
> > `signet=1 signetchallenge=5121035daaa313aada6310340a242af17238cc1fd8849e875940bce65a60ac7e0e0ff751ae proxy=127.0.0.1:9050 [signet] addnode=luvczzzppiqnc2b7poivkxlugafe3uqaj245ebjqxtceio7poaorqcyd.onion mempoolfullrbf=1`
> > 
> > Example for a simple test case:
> > 
> > - Run 2 nodes
> > - Connect node 1 with i2p node and use default opt-in rbf
> > - Connect node 2 with node 1 and onion node. This node should use `mempoolfullrbf=1` in config and compile bitcoind using PR #26454 branch
> > - Broadcast Tx1 using node 2 and replace with Tx2 using `bumpfee` RPC
> > 
> > It will be fun to test with more nodes joining this custom signet. If anyone interested to test, please post your bitcoin address in full-rbf room. We can even setup an explorer if this experiment makes sense.
> > 
> > Sent with Proton Mail secure email.
> > 
> > /dev/fd0
> > _______________________________________________
> > bitcoin-dev mailing list
> > bitcoin-dev at lists.linuxfoundation.org
> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev

From rot13maxi at protonmail.com  Sat Nov 26 00:12:10 2022
From: rot13maxi at protonmail.com (Rijndael)
Date: Sat, 26 Nov 2022 00:12:10 +0000
Subject: [bitcoin-dev] Relative txout amounts with a Merkleized Sum Tree
	and explicit miner fee.
In-Reply-To: <Kcqi_Svol1F4H8rGnnECZXRkb5Aa_763DlNUP4froIqLovFk-SrOnWXC5ZPtfRjzHb55_BTe07h6PH5OdaY2zpNPNTix__bqYiBIEw2IbjA=@protonmail.com>
References: <zKbMpqEqH6Z4p1GE2rlsOky1fMPBsEFGaeNk8WIcbez__-fR3ahnYEWOgExHC8KXAYCqtt4gMa7WBXkNSqL6fO9sjsvyu9AZRPQIQADqthg=@protonmail.com>
 <Kcqi_Svol1F4H8rGnnECZXRkb5Aa_763DlNUP4froIqLovFk-SrOnWXC5ZPtfRjzHb55_BTe07h6PH5OdaY2zpNPNTix__bqYiBIEw2IbjA=@protonmail.com>
Message-ID: <5ded6a45-9e79-511b-f1db-384168102890@protonmail.com>

Hello Andrew,

As ZmnSCPxj mentioned, covenant schemes are probably something that you
should be looking at and thinking about. In addition to CTV, I'd also
recommend you take a look (if you haven't already) at
`TAPLEAF_UPDATE_VERIFY`
(https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019419.html).
 From your description, it sounds like you may be barking up a similar tree.

Rijndael


On 11/21/22 6:52 PM, ZmnSCPxj via bitcoin-dev wrote:
> Good morning Andrew,
>
>>
>> Can output amounts be mapped to a tap branch? For the goal of secure partial spends of a single UTXO? Looking for feedback on this idea. I got it from Taro.
>
> Not at all.
>
> The issue you are facing here is that only one tap branch will ever consume the entire input amount.
> That is: while Taproot has multiple leaves, only exactly one leaf will ever be published onchain and that gets the whole amount.
>
> What you want is multiple tree leaves where ALL of them will EVENTUALLY be published, just not right now.
>
> In that case, look at the tree structures for `OP_CHECKTEMPLATEVERIFY`, which are exactly what you are looking for, and help make `OP_CTV` a reality.
>
> Without `OP_CHECKTEMPLATEVERIFY` it is possible to use presigned transactions in a tree structure to do this same construction.
> Presigned transactions are known to be larger than `OP_CHECKTEMPLATEVERIFY` --- signatures on taproot are 64 bytes of witness, but an `OP_CHECKTEMPLATEVERIFY` in a P2WSH reveals just 32 bytes of witness plus the `OP_CHECKTEMPLATEVERIFY` opcode.
>
> Regards,
> ZmnSCPxj
> _______________________________________________
> bitcoin-dev mailing list
> bitcoin-dev at lists.linuxfoundation.org
> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev


From gsanders87 at gmail.com  Wed Nov 30 15:32:36 2022
From: gsanders87 at gmail.com (Greg Sanders)
Date: Wed, 30 Nov 2022 10:32:36 -0500
Subject: [bitcoin-dev] Ephemeral Anchors: Fixing V3 Package RBF
 againstpackage limit pinning
In-Reply-To: <CAB3F3DuDODUxB5aK4VFWa8sKFCkZfOj6Vjb+Wp39opyt8MNnEA@mail.gmail.com>
References: <CAB3F3Dukoz3P3Ne7tCxMiwwAGm3Fv8r_fUkNbGAtGhAZDYDgCQ@mail.gmail.com>
 <ec952a9c-d810-4996-9ca9-1e9c6f6faca4@app.fastmail.com>
 <CAB3F3DvH3FnK8krykbcRVKc-z8F4yjt9mzYHevpYxaWkH4w9tw@mail.gmail.com>
 <CAD5xwhgFBQ-ScyBU5=WnREGsN-T=Nv=oR6vOsnHJ-ZMzDF8Vqg@mail.gmail.com>
 <CAPfvXf+N8aF+bqjGzpfDrhCYg7ngciSDCpUnCMHD+k5F+m3oWA@mail.gmail.com>
 <CAB3F3DuDODUxB5aK4VFWa8sKFCkZfOj6Vjb+Wp39opyt8MNnEA@mail.gmail.com>
Message-ID: <CAB3F3DtrSFPmperGJJAUDZj7vt9aHgvkc0b5Pts3+mq5fTuWXA@mail.gmail.com>

Small update.

A bit ago I went ahead and implemented ephemeral anchors on top of the V3
proposal to see what the complexity looks like:
https://github.com/bitcoin/bitcoin/pull/26403

Roughly 130 loc excluding tests, using OP_2 instead of OP_TRUE to not camp
the value that is used elsewhere.

Please let me know if you have any early feedback on this!

Greg

On Thu, Oct 20, 2022 at 9:42 AM Greg Sanders <gsanders87 at gmail.com> wrote:

> So it doesn't look like I'm ignoring a good question:
>
> No solid noninteractive ideas, unless we get some very flexible sighash
> softfork. Interactively, I think you can get collaborative fee bumps under
> the current consensus regime and ephemeral anchors. The child will just be
> built with inputs from different people.
>
> On Wed, Oct 19, 2022 at 11:12 AM James O'Beirne <james.obeirne at gmail.com>
> wrote:
>
>> I'm also very happy to see this proposal, since it gets us closer to
>> having a mechanism that allows the contribution to feerate in an
>> "unauthenticated" way, which seems to be a very helpful feature for vaults
>> and other contracting protocols.
>>
>> One possible advantage of the sponsors interface -- and I'm curious for
>> your input here Greg -- is that with sponsors, assuming we relaxed the "one
>> sponsor per sponsoree" constraint, multiple uncoordinated parties can
>> collaboratively bump a tx's feerate. A simple example would be a batch
>> withdrawal from an exchange could be created with a low feerate, and then
>> multiple users with a vested interest of expedited confirmation could all
>> "chip in" to raise the feerate with multiple sponsor transactions.
>>
>> Having a single ephemeral output seems to create a situation where a
>> single UTXO has to shoulder the burden of CPFPing a package. Is there some
>> way we could (possibly later) amend the ephemeral anchor interface to allow
>> for this kind of collaborative sponsoring? Could you maybe see "chained"
>> ephemeral anchors that would allow this?
>>
>>
>> On Tue, Oct 18, 2022 at 12:52 PM Jeremy Rubin via bitcoin-dev <
>> bitcoin-dev at lists.linuxfoundation.org> wrote:
>>
>>> Excellent proposal and I agree it does capture much of the spirit of
>>> sponsors w.r.t. how they might be used for V3 protocols.
>>>
>>> The only drawbacks I see is they don't work for lower tx version
>>> contracts, so there's still something to be desired there, and that the
>>> requirement to sweep the output must be incentive compatible for the miner,
>>> or else they won't enforce it (pass the buck onto the future bitcoiners).
>>> The Ephemeral UTXO concept can be a consensus rule (see
>>> https://rubin.io/public/pdfs/multi-txn-contracts.pdf "Intermediate
>>> UTXO") we add later on in lieu of managing them by incentive, so maybe it's
>>> a cleanup one can punt.
>>>
>>> One question I have is if V3 is designed for lightning, and this is
>>> designed for lightning, is there any sense in requiring these outputs for
>>> v3? That might help with e.g. anonymity set, as well as potentially keep
>>> the v3 surface smaller.
>>>
>>> On Tue, Oct 18, 2022 at 11:51 AM Greg Sanders via bitcoin-dev <
>>> bitcoin-dev at lists.linuxfoundation.org> wrote:
>>>
>>>> > does that effectively mark output B as unspendable once the child
>>>> gets confirmed?
>>>>
>>>> Not at all. It's a normal spend like before, since the parent has been
>>>> confirmed. It's completely unrestricted, not being bound to any
>>>> V3/ephemeral anchor restrictions on size, version, etc.
>>>>
>>>> On Tue, Oct 18, 2022 at 11:47 AM Arik Sosman via bitcoin-dev <
>>>> bitcoin-dev at lists.linuxfoundation.org> wrote:
>>>>
>>>>> Hi Greg,
>>>>>
>>>>> Thank you very much for sharing your proposal!
>>>>>
>>>>> I think there's one thing about the second part of your proposal that
>>>>> I'm missing. Specifically, assuming the scenario of a v3 transaction with
>>>>> three outputs, A, B, and the ephemeral anchor OP_TRUE. If a child
>>>>> transaction spends A and OP_TRUE, does that effectively mark output B as
>>>>> unspendable once the child gets confirmed? If so, isn't the implication
>>>>> therefore that to safely spend a transaction with an ephemeral anchor, all
>>>>> outputs must be spent? Thanks!
>>>>>
>>>>> Best,
>>>>> Arik
>>>>>
>>>>> On Tue, Oct 18, 2022, at 6:52 AM, Greg Sanders via bitcoin-dev wrote:
>>>>>
>>>>> Hello Everyone,
>>>>>
>>>>> Following up on the "V3 Transaction" discussion here
>>>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-September/020937.html
>>>>> , I would like to elaborate a bit further on some potential follow-on work
>>>>> that would make pinning severely constrained in many setups].
>>>>>
>>>>> V3 transactions may solve bip125 rule#3 and rule#5 pinning attacks
>>>>> under some constraints[0]. This means that when a replacement is to be made
>>>>> and propagated, it costs the expected amount of fees to do so. This is a
>>>>> great start. What's left in this subset of pinning is *package limit*
>>>>> pinning. In other words, a fee-paying transaction cannot enter the mempool
>>>>> due to the existing mempool package it is being added to already being too
>>>>> large in count or vsize.
>>>>>
>>>>> Zooming into the V3 simplified scenario for sake of discussion, though
>>>>> this problem exists in general today:
>>>>>
>>>>> V3 transactions restrict the package limit of a V3 package to one
>>>>> parent and one child. If the parent transaction includes two outputs which
>>>>> can be immediately spent by separate parties, this allows one party to
>>>>> disallow a spend from the other. In Gloria's proposal for ln-penalty, this
>>>>> is worked around by reducing the number of anchors per commitment
>>>>> transaction to 1, and each version of the commitment transaction has a
>>>>> unique party's key on it. The honest participant can spend their version
>>>>> with their anchor and package RBF the other commitment transaction safely.
>>>>>
>>>>> What if there's only one version of the commitment transaction, such
>>>>> as in other protocols like duplex payment channels, eltoo? What about multi
>>>>> party payments?
>>>>>
>>>>> In the package RBF proposal, if the parent transaction is identical to
>>>>> an existing transaction in the mempool, the parent will be detected and
>>>>> removed from the package proposal. You are then left with a single V3 child
>>>>> transaction, which is then proposed for entry into the mempool. In the case
>>>>> of another parent output already being spent, this is simply rejected,
>>>>> regardless of feerate of the new child.
>>>>>
>>>>> I have two proposed solutions, of which I strongly prefer the latter:
>>>>>
>>>>> 1) Expand a carveout for "sibling eviction", where if the new child is
>>>>> paying "enough" to bump spends from the same parent, it knocks its sibling
>>>>> out of the mempool and takes the one child slot. This would solve it, but
>>>>> is a new eviction paradigm that would need to be carefully worked through.
>>>>>
>>>>> 2) Ephemeral Anchors (my real policy-only proposal)
>>>>>
>>>>> Ephemeral Anchors is a term which means an output is watermarked as an
>>>>> output that MUST be spent in a V3 package. We mark this anchor by being the
>>>>> bare script `OP_TRUE` and of course make these outputs standard to relay
>>>>> and spend with empty witness data.
>>>>>
>>>>> Also as a simplifying assumption, we require the parent transaction
>>>>> with such an output to be 0-fee. This makes mempool reasoning simpler in
>>>>> case the child-spend is somehow evicted, guaranteeing the parent will be as
>>>>> well.
>>>>>
>>>>> Implications:
>>>>>
>>>>> a) If the ephemeral anchor MUST be spent, we can allow *any* value,
>>>>> even dust, even 0, without worrying about bloating the utxo set. We relax
>>>>> this policy for maximum smart contract flexibility and specification
>>>>> simplicity..
>>>>>
>>>>> b) Since this anchor MUST be spent, any spending of other outputs in
>>>>> the same parent transaction MUST directly double-spend prior spends of the
>>>>> ephemeral anchor. This causes the 1 block CSV timelock on outputs to be
>>>>> removed in these situations. This greatly magnifies composability of smart
>>>>> contracts, as now we can do things like safely splice directly into new
>>>>> channels, into statechains, your custodial wallet account, your cold
>>>>> wallet, wherever, without requiring other wallets to support arbitrary
>>>>> scripts. Also it hurts that 1 CSV time locked scripts may not be miniscript
>>>>> compatible to begin with...
>>>>>
>>>>> c) *Anyone* can bump the transaction, without any transaction key
>>>>> material. This is essentially achieving Jeremy's Transaction Sponsors (
>>>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-September/018168.html)
>>>>> proposal without consensus changes. As long as someone gets a fully signed
>>>>> parent, they can execute a bump with minimal wallet tooling. If a
>>>>> transaction author doesn?t want a ?sponsor?, do not include the output.
>>>>>
>>>>> d) Lightning Carve-out(
>>>>> https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-October/002240.html)
>>>>> is superseded by this logic, as we are not restricted to two immediately
>>>>> spendable output scenarios. In its place, robust multi-party fee bumping is
>>>>> possible.
>>>>>
>>>>> e) This also benefits more traditional wallet scenarios, as change
>>>>> outputs can no longer be pinned, and RBF/CPFP becomes robust. Payees in
>>>>> simple spends cannot pin you. Batched payouts become a lot less painful.
>>>>> This was one of the motivating use cases that created the term ?pinning? in
>>>>> the first place(
>>>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-February/015717.html),
>>>>> even if LN/L2 discussion has largely overtaken it due to HTLC theft risks.
>>>>>
>>>>> Open Question(s):
>>>>>
>>>>>
>>>>>    1.
>>>>>
>>>>>    If we allow non-zero value in ephemeral outputs, does this open up
>>>>>    a MEV we are worried about? Wallets should toss all the value directly to
>>>>>    fees, and add their own additional fees on top, otherwise miners have
>>>>>    incentive to make the smallest utxo burn transaction to claim those funds.
>>>>>    They just confirmed your parent transaction anyways, so do we care?
>>>>>    2.
>>>>>
>>>>>    SIGHASH_GROUP like constructs would allow uncommitted ephemeral
>>>>>    anchors to be added at spend time, depending on spending requirements.
>>>>>    SIGHASH_SINGLE already allows this.
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> Hopefully this gives people something to consider as we move forward
>>>>> in thinking about mempool design within the constraints we have today.
>>>>>
>>>>>
>>>>> Greg
>>>>>
>>>>> 0: With V3 transactions where you have "veto power" over all the
>>>>> inputs in that transaction. Therefore something like ANYONECANPAY is still
>>>>> broken. We need a more complex solution, which I?m punting for the sake of
>>>>> progress.
>>>>> _______________________________________________
>>>>> bitcoin-dev mailing list
>>>>> bitcoin-dev at lists.linuxfoundation.org
>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>>>
>>>>>
>>>>> _______________________________________________
>>>>> bitcoin-dev mailing list
>>>>> bitcoin-dev at lists.linuxfoundation.org
>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>>>
>>>> _______________________________________________
>>>> bitcoin-dev mailing list
>>>> bitcoin-dev at lists.linuxfoundation.org
>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>>
>>> _______________________________________________
>>> bitcoin-dev mailing list
>>> bitcoin-dev at lists.linuxfoundation.org
>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221130/c6217750/attachment-0001.html>

From rot13maxi at protonmail.com  Wed Nov 30 19:42:08 2022
From: rot13maxi at protonmail.com (Rijndael)
Date: Wed, 30 Nov 2022 19:42:08 +0000
Subject: [bitcoin-dev] Merkleize All The Things
In-Reply-To: <CAMhCMoEONv3jriBU3qwm0pt75iF_sgra1H2Z4rOF8u+e7hs_cw@mail.gmail.com>
References: <CAMhCMoH9uZPeAE_2tWH6rf0RndqV+ypjbNzazpFwFnLUpPsZ7g@mail.gmail.com>
 <CALZpt+GVe0XTdWqV=LAcOj=nq+k2DEFqc+sKyxAujLDBR7bYbQ@mail.gmail.com>
 <CAMhCMoEONv3jriBU3qwm0pt75iF_sgra1H2Z4rOF8u+e7hs_cw@mail.gmail.com>
Message-ID: <0f352f70-c93a-614f-e443-67d198ec2c26@protonmail.com>

Hello Salvatore,

Really interesting idea. The walk-through of the challenge protocol helped.

In the final state:

[S14. state: h_{A;6}, h_{B;6}]
- Alice can take all the money if she can open h_{A;6} to a correct "n => n + n" computation step
- Bob can take all the money if he can open h_{B;6} to a correct "n => n + n" computation step

My understanding of your scheme for encoding execution traces is that each leaf is (previous-state, operation, post-state) So in this case when we get to the conflicting step of the execution traces, alice might reveal something like (x=64, x+x, x=127) and bob might reveal something like (x=64, x+x, x=128). So in order for the covenant to enforce which state-transition is valid (who can spend the money), that means that `x+x` needs to be evaluated in script to tell who has posted the incorrect state. Am I understanding this final step of the bisection protocol correctly?

-rijndael

On 11/12/22 10:04 AM, Salvatore Ingala via bitcoin-dev wrote:

> Hi Antoine,
> It appears that my explanation of the relationship between the covenant and the bisection protocol is still unclear; I'll do my best to clarify.
>
> The bisection's Merkle tree never ends up on-chain, in any form. Therefore, a bigger computation does not end up in a bigger witness size, which is key to the scalability of the approach. Only in the case of a challenge, it will result in a (logarithmically) longer chain of transactions to resolve it. This chain of transactions could be mapped to a root-to-leaf path in the Merkle tree of the computation trace.
>
> The actual computation trace (and the corresponding Merkle tree) is only computed by the parties when they execute the computation.
> What's in the tapleaves is only the valid transitions at the current state of the protocol; that is, the valid transitions in the Finite State Machine (and possibly other valid exit conditions that remove the covenant encumbrance, if any).
>
> The bisection protocol only makes sense as a step in a larger protocol that makes use of it.
>
> Perhaps presenting the protocol in a less-than-general case might help to understand it. So let's play a simpler game using a protocol that includes a fraud proof.
>
> Alice claims that she knows how to multiply by 256, while Bob doesn't believe her. So they make a bet: they each commit 1 coin; then Bob choses a number x; then Alice computes y = 256*x by doubling x eight times (expensive multiplications were disabled in a tragic DDoS accident), and publishes the result y. Bob independently computes 256 * x (he has a friend who is a mathematician, he'll know how to do it). If the result is not y, Bob will start a challenge; otherwise, Alice wins and takes the money.
>
> (The example is of course artificial, as redoing the computation in Script is cheaper than executing the fraud proof in this case!)
>
> What follows is an actual execution of the protocol. In the following, each [Si] is a UTXO corresponding to some possible FSM node, starting with the S0, the UTXO with 1+1 = 2 coins. Each line with "-" is a possible transition (script in the taptree), specifying what is the next FSM node after the "==>" symbol; the encumbrance in the scripts enforce that the state of the next UTXO is updated correctly (details omitted below), and any other necessary conditions to ensure the integrity of the protocol.
>
> =====
>
> [S0]: Initial UTXO
> - only Bob can spend, he must choose his number x ==> S1
>
> [S1; state: x]:
> - only Alice can spend, she publishes her answer y ==> S2
>
> [S2. state: x, y]:
> - after 1 day: Alice won, she can take the money // Happy case! Usually that's the end
> - Bob disagrees with the answer, post z as his answer. ==> S3
>
> The challenge starts here! Let's put some actual numbers. x = 2; y = 508; z = 512.
>
> This is what Alice computed:
>
> 2 => 4 => 8 => 16 => 32 => 64 => 127 => 254 => 508
>
> This is what Bob computed:
>
> 2 => 4 => 8 => 16 => 32 => 64 => 128 => 256 => 512
>
> At this time, we don't know who is right. They both built a tree that looks like this (ASCII art only working in fixed-width font):
>
> ___H18___
> / \
> / \
> H14 H58
> / \ / \
> / \ / \
> / \ / \
> H12 H34 H56 H78
> / \ / \ / \ / \
> H1 H2 H3 H4 H5 H6 H7 H8
>
> Remember that each internal node commits to: the state of the computation before the leftmost leaf in the subtree, the state after the rightmost leaf, and the hash of sub-trace for the sub-tree. Each leaf just commits to that intermediate computation step (and the operation, which here is always "double the input"). For example, H4 commits to "16 => 32" according to both Alice's and Bob's computation traces.
>
> (From our privileged point of view, we can foresee that the earliest disagreement is on the 6th step of the computation: "64 => 127" according to Alice, "64 => 128" according to Bob).
>
> Let's denote h_{A;18} (resp. h_{B;18}) all the information committed to in the node H18, according to Alice (resp. Bob). Similarly for all the other nodes.
>
> [S3. state: x, y, z]: Challenge starts!
> - Alice posts the root of her computation trace h_{A;18} ==> S4
>
> [S4. state: x, y, z, h_{A;18}]
> - Bob posts the root of her computation trace h_{B;18} ==> S5
>
> Since they disagree, it must be the case that h_{A;18} != h_{B;18}.
>
> [S5. state: x, y, z, h_{A;18}, h_{B;18}]
> - Alice opens the commitment h_{A;18}, by revealing H14 and H58 (according to her) ==> S6
>
> Note that in this last transition (going to S6), the covenant enforces that the child commitments are compatible: the transition is only valid if the starting state of the computation according to h_{A;14} is compatible with h_{A;18} (that is, it's equal to x); similarly the end state of the computation in h_{A;58} must be y, and h_{A;18} can be recomputed from the data provided (ensuring the integrity of the Merkle tree).
> This is true for all the commitment openings below.
>
> [S6. state: x, y, z, (h_{A;14}, h_{A;58}), h_{B;18}]
> - Bob opens the commitment h_{B;18}, by revealing H14 and H58 (according to him) ==> S7
>
> [S7. state: x, y, z, (h_{A;18}, h_{A;14}, h_{A;58}), (h_{B;18}, h_{B;14}, h_{B;58})]
> // We now need to choose a child where there is disagreement.
> // If both children don't match, iterate on the left child.
> - Anyone: if h_{A;14} == h_{B;14} ==> S8
> - Anyone: if h_{A;14} != h_{B;14} ==> Continue challenge on H14 // Non-executed FSM cases omitted for brevity
>
> At this point, the disagreement over the root is settled: Alice and Bob agree on the first half of the computation, but they disagree over the second half. Therefore, in S8 the protocol continues over H58.
>
> [S8. state: h_{A;58}, h_{B;58}]
> // This is analogous to S5, just with half of the computation steps.
> - Alice opens the commitment h_{A;58}, by revealing H56 and H78 (according to her) ==> S9
>
> [S9. state: (h_{A;56}, h_{A;78}), h_{B;58}]
> - Bob opens the commitment h_{B;58}, by revealing H56 and H78 (according to him) ==> S10
>
> [S10. state: (h_{A;56}, h_{A;78}), (h_{B;56}, h_{B;78})]
> // Like S7, iterate on a disagreeing child
> - Anyone: if h_{A;56} == h_{B;56} ==> continue challenge on H78 // Non-executed FSM cases omitted for brevity
> - Anyone: if h_{A;56} != h_{B;56} ==> S11
>
> Getting there! The subtree now commits to just two computation steps.
>
> [S11. state: h_{A;56}, h_{B;56}]
> // This is analogous to S5 and S8.
> - Alice opens the commitment h_{A;56}, by revealing H5 and H6 (according to her) ==> S12
>
> [S12. state: (h_{A;5}, h_{A;6}), h_{B;56}]
> - Bob opens the commitment h_{B;56}, by revealing H5 and H6 (according to him) ==> S13
>
> [S13. state: (h_{A;5}, h_{A;6}), (h_{B;5}, h_{B;6})]
> // Like S7 and S10, iterate on a disagreeing child
> - Anyone: if h_{A;5} == h_{B;5} ==> S14
> - Anyone: if h_{A;5} != h_{B;5} ==> continue challenge on H5 // Non-executed FSM cases omitted for brevity
>
> We are now at the crucial stage: the commitment corresponds to a leaf of the computation trace Merkle tree.
>
> [S14. state: h_{A;6}, h_{B;6}]
> - Alice can take all the money if she can open h_{A;6} to a correct "n => n + n" computation step
> - Bob can take all the money if he can open h_{B;6} to a correct "n => n + n" computation step
>
> The challenge now ends quickly: Bob's hash commits to the computation step "64 => 128".
> Instead, Alice's step is the incorrect "64 => 127".
>
> It's not difficult to convince oneself that, as long as the hash function is collision-free and the computation is deterministic, only the honest party can provide correct data for this final step.
> (The bisection protocol can't do anything useful if both parties provide incorrect data; arguably, that is not a very interesting scenario!)
>
> Crucially, the operation in the single step is so simple that Script can verify it.
>
> =====
>
> If you read until here: thank you, this was the first execution of a challenge in MATT covenants!
>
> Of course, there are a few things missing in the above protocol:
> - Bonds should be added in order to incentivize cooperation.
> - The omitted FSM steps (corresponding to branches of the challenge that were never taken) need to be computed nonetheless when preparing the covenant.
> - Additional transitions should be added at every step (always allow cooperative behavior; forfait after a timeout if it's the other party's turn).
> - Some of those consecutive "forced" steps can be contracted in a single step; I felt this sequence is more logical to explain the protocol, but implementations would want to optimize it.
>
> Yet, _all_ the code and scripts of the bisection protocol are independent of the actual execution, and can be precomputed (bottom up, starting from the leaves) before the initial covenant is created - therefore, before x, y and z are chosen and committed to.
>
> While here each leaf is doing the same operation (doubling a number), it is well-known that arbitrary computation can be decomposed in very simple elementary functions (like NAND gates, if we want to be minimalistic).
>
> I hope this helps in clarifying the role of the bisection protocol in smart contracts using MATT covenants.
>
> Best,
> Salvatore
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221130/fabd885f/attachment-0001.html>

From rot13maxi at protonmail.com  Wed Nov 30 22:09:33 2022
From: rot13maxi at protonmail.com (Rijndael)
Date: Wed, 30 Nov 2022 22:09:33 +0000
Subject: [bitcoin-dev] Merkleize All The Things
In-Reply-To: <0f352f70-c93a-614f-e443-67d198ec2c26@protonmail.com>
References: <CAMhCMoH9uZPeAE_2tWH6rf0RndqV+ypjbNzazpFwFnLUpPsZ7g@mail.gmail.com>
 <CALZpt+GVe0XTdWqV=LAcOj=nq+k2DEFqc+sKyxAujLDBR7bYbQ@mail.gmail.com>
 <CAMhCMoEONv3jriBU3qwm0pt75iF_sgra1H2Z4rOF8u+e7hs_cw@mail.gmail.com>
 <0f352f70-c93a-614f-e443-67d198ec2c26@protonmail.com>
Message-ID: <7f3674d1-c1ad-9a82-e30f-7cf24d697faf@protonmail.com>

Hello Salvatore,

I found my answer re-reading your original post:
> During the arbitration phase (say at the i-th leaf node of M_T), any party can win the challenge by providing correct values for tr_i = (st_i, op_i, st_{i + 1}). Crucially, only one party is able to provide correct values, and Script can verify that indeed the state moves from st_i to st_{i + 1} by executing op_i. The challenge is over.

That raises leads to a different question: Alice initially posts a commitment to an execution trace of `f(x) = y`, `x`, and `y`. Bob Disagrees with `y` so starts the challenge protocol. Is there a commitment to `f`? In other words, the dispute protocol (as I read it) finds the leftmost step in Alice and Bob's execution traces that differ, and then rewards the coins to the participant who's "after-value" is computed by the step's operation applied to the "before value". But if the participants each present valid steps but with different operations, who wins? In other words, Alice could present [64, DECREMENT, 63] and Bob could present [64, INCREMENT, 65]. Those steps don't match, but both are valid. Is there something to ensure that before the challenge protocol starts, that the execution trace that Alice posts is for the right computation and not a different computation that yields a favorable result for her (and for which she can generate a valid merkle tree)?

Thanks!

-rijndael

On 11/30/22 2:42 PM, Rijndael via bitcoin-dev wrote:

> Hello Salvatore,
>
> Really interesting idea. The walk-through of the challenge protocol helped.
>
> In the final state:
>
> [S14. state: h_{A;6}, h_{B;6}]
> - Alice can take all the money if she can open h_{A;6} to a correct "n => n + n" computation step
> - Bob can take all the money if he can open h_{B;6} to a correct "n => n + n" computation step
>
> My understanding of your scheme for encoding execution traces is that each leaf is (previous-state, operation, post-state) So in this case when we get to the conflicting step of the execution traces, alice might reveal something like (x=64, x+x, x=127) and bob might reveal something like (x=64, x+x, x=128). So in order for the covenant to enforce which state-transition is valid (who can spend the money), that means that `x+x` needs to be evaluated in script to tell who has posted the incorrect state. Am I understanding this final step of the bisection protocol correctly?
>
> -rijndael
>
> On 11/12/22 10:04 AM, Salvatore Ingala via bitcoin-dev wrote:
>
>> Hi Antoine,
>> It appears that my explanation of the relationship between the covenant and the bisection protocol is still unclear; I'll do my best to clarify.
>>
>> The bisection's Merkle tree never ends up on-chain, in any form. Therefore, a bigger computation does not end up in a bigger witness size, which is key to the scalability of the approach. Only in the case of a challenge, it will result in a (logarithmically) longer chain of transactions to resolve it. This chain of transactions could be mapped to a root-to-leaf path in the Merkle tree of the computation trace.
>>
>> The actual computation trace (and the corresponding Merkle tree) is only computed by the parties when they execute the computation.
>> What's in the tapleaves is only the valid transitions at the current state of the protocol; that is, the valid transitions in the Finite State Machine (and possibly other valid exit conditions that remove the covenant encumbrance, if any).
>>
>> The bisection protocol only makes sense as a step in a larger protocol that makes use of it.
>>
>> Perhaps presenting the protocol in a less-than-general case might help to understand it. So let's play a simpler game using a protocol that includes a fraud proof.
>>
>> Alice claims that she knows how to multiply by 256, while Bob doesn't believe her. So they make a bet: they each commit 1 coin; then Bob choses a number x; then Alice computes y = 256*x by doubling x eight times (expensive multiplications were disabled in a tragic DDoS accident), and publishes the result y. Bob independently computes 256 * x (he has a friend who is a mathematician, he'll know how to do it). If the result is not y, Bob will start a challenge; otherwise, Alice wins and takes the money.
>>
>> (The example is of course artificial, as redoing the computation in Script is cheaper than executing the fraud proof in this case!)
>>
>> What follows is an actual execution of the protocol. In the following, each [Si] is a UTXO corresponding to some possible FSM node, starting with the S0, the UTXO with 1+1 = 2 coins. Each line with "-" is a possible transition (script in the taptree), specifying what is the next FSM node after the "==>" symbol; the encumbrance in the scripts enforce that the state of the next UTXO is updated correctly (details omitted below), and any other necessary conditions to ensure the integrity of the protocol.
>>
>> =====
>>
>> [S0]: Initial UTXO
>> - only Bob can spend, he must choose his number x ==> S1
>>
>> [S1; state: x]:
>> - only Alice can spend, she publishes her answer y ==> S2
>>
>> [S2. state: x, y]:
>> - after 1 day: Alice won, she can take the money // Happy case! Usually that's the end
>> - Bob disagrees with the answer, post z as his answer. ==> S3
>>
>> The challenge starts here! Let's put some actual numbers. x = 2; y = 508; z = 512.
>>
>> This is what Alice computed:
>>
>> 2 => 4 => 8 => 16 => 32 => 64 => 127 => 254 => 508
>>
>> This is what Bob computed:
>>
>> 2 => 4 => 8 => 16 => 32 => 64 => 128 => 256 => 512
>>
>> At this time, we don't know who is right. They both built a tree that looks like this (ASCII art only working in fixed-width font):
>>
>> ___H18___
>> / \
>> / \
>> H14 H58
>> / \ / \
>> / \ / \
>> / \ / \
>> H12 H34 H56 H78
>> / \ / \ / \ / \
>> H1 H2 H3 H4 H5 H6 H7 H8
>>
>> Remember that each internal node commits to: the state of the computation before the leftmost leaf in the subtree, the state after the rightmost leaf, and the hash of sub-trace for the sub-tree. Each leaf just commits to that intermediate computation step (and the operation, which here is always "double the input"). For example, H4 commits to "16 => 32" according to both Alice's and Bob's computation traces.
>>
>> (From our privileged point of view, we can foresee that the earliest disagreement is on the 6th step of the computation: "64 => 127" according to Alice, "64 => 128" according to Bob).
>>
>> Let's denote h_{A;18} (resp. h_{B;18}) all the information committed to in the node H18, according to Alice (resp. Bob). Similarly for all the other nodes.
>>
>> [S3. state: x, y, z]: Challenge starts!
>> - Alice posts the root of her computation trace h_{A;18} ==> S4
>>
>> [S4. state: x, y, z, h_{A;18}]
>> - Bob posts the root of her computation trace h_{B;18} ==> S5
>>
>> Since they disagree, it must be the case that h_{A;18} != h_{B;18}.
>>
>> [S5. state: x, y, z, h_{A;18}, h_{B;18}]
>> - Alice opens the commitment h_{A;18}, by revealing H14 and H58 (according to her) ==> S6
>>
>> Note that in this last transition (going to S6), the covenant enforces that the child commitments are compatible: the transition is only valid if the starting state of the computation according to h_{A;14} is compatible with h_{A;18} (that is, it's equal to x); similarly the end state of the computation in h_{A;58} must be y, and h_{A;18} can be recomputed from the data provided (ensuring the integrity of the Merkle tree).
>> This is true for all the commitment openings below.
>>
>> [S6. state: x, y, z, (h_{A;14}, h_{A;58}), h_{B;18}]
>> - Bob opens the commitment h_{B;18}, by revealing H14 and H58 (according to him) ==> S7
>>
>> [S7. state: x, y, z, (h_{A;18}, h_{A;14}, h_{A;58}), (h_{B;18}, h_{B;14}, h_{B;58})]
>> // We now need to choose a child where there is disagreement.
>> // If both children don't match, iterate on the left child.
>> - Anyone: if h_{A;14} == h_{B;14} ==> S8
>> - Anyone: if h_{A;14} != h_{B;14} ==> Continue challenge on H14 // Non-executed FSM cases omitted for brevity
>>
>> At this point, the disagreement over the root is settled: Alice and Bob agree on the first half of the computation, but they disagree over the second half. Therefore, in S8 the protocol continues over H58.
>>
>> [S8. state: h_{A;58}, h_{B;58}]
>> // This is analogous to S5, just with half of the computation steps.
>> - Alice opens the commitment h_{A;58}, by revealing H56 and H78 (according to her) ==> S9
>>
>> [S9. state: (h_{A;56}, h_{A;78}), h_{B;58}]
>> - Bob opens the commitment h_{B;58}, by revealing H56 and H78 (according to him) ==> S10
>>
>> [S10. state: (h_{A;56}, h_{A;78}), (h_{B;56}, h_{B;78})]
>> // Like S7, iterate on a disagreeing child
>> - Anyone: if h_{A;56} == h_{B;56} ==> continue challenge on H78 // Non-executed FSM cases omitted for brevity
>> - Anyone: if h_{A;56} != h_{B;56} ==> S11
>>
>> Getting there! The subtree now commits to just two computation steps.
>>
>> [S11. state: h_{A;56}, h_{B;56}]
>> // This is analogous to S5 and S8.
>> - Alice opens the commitment h_{A;56}, by revealing H5 and H6 (according to her) ==> S12
>>
>> [S12. state: (h_{A;5}, h_{A;6}), h_{B;56}]
>> - Bob opens the commitment h_{B;56}, by revealing H5 and H6 (according to him) ==> S13
>>
>> [S13. state: (h_{A;5}, h_{A;6}), (h_{B;5}, h_{B;6})]
>> // Like S7 and S10, iterate on a disagreeing child
>> - Anyone: if h_{A;5} == h_{B;5} ==> S14
>> - Anyone: if h_{A;5} != h_{B;5} ==> continue challenge on H5 // Non-executed FSM cases omitted for brevity
>>
>> We are now at the crucial stage: the commitment corresponds to a leaf of the computation trace Merkle tree.
>>
>> [S14. state: h_{A;6}, h_{B;6}]
>> - Alice can take all the money if she can open h_{A;6} to a correct "n => n + n" computation step
>> - Bob can take all the money if he can open h_{B;6} to a correct "n => n + n" computation step
>>
>> The challenge now ends quickly: Bob's hash commits to the computation step "64 => 128".
>> Instead, Alice's step is the incorrect "64 => 127".
>>
>> It's not difficult to convince oneself that, as long as the hash function is collision-free and the computation is deterministic, only the honest party can provide correct data for this final step.
>> (The bisection protocol can't do anything useful if both parties provide incorrect data; arguably, that is not a very interesting scenario!)
>>
>> Crucially, the operation in the single step is so simple that Script can verify it.
>>
>> =====
>>
>> If you read until here: thank you, this was the first execution of a challenge in MATT covenants!
>>
>> Of course, there are a few things missing in the above protocol:
>> - Bonds should be added in order to incentivize cooperation.
>> - The omitted FSM steps (corresponding to branches of the challenge that were never taken) need to be computed nonetheless when preparing the covenant.
>> - Additional transitions should be added at every step (always allow cooperative behavior; forfait after a timeout if it's the other party's turn).
>> - Some of those consecutive "forced" steps can be contracted in a single step; I felt this sequence is more logical to explain the protocol, but implementations would want to optimize it.
>>
>> Yet, _all_ the code and scripts of the bisection protocol are independent of the actual execution, and can be precomputed (bottom up, starting from the leaves) before the initial covenant is created - therefore, before x, y and z are chosen and committed to.
>>
>> While here each leaf is doing the same operation (doubling a number), it is well-known that arbitrary computation can be decomposed in very simple elementary functions (like NAND gates, if we want to be minimalistic).
>>
>> I hope this helps in clarifying the role of the bisection protocol in smart contracts using MATT covenants.
>>
>> Best,
>> Salvatore
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20221130/8371518e/attachment-0001.html>

